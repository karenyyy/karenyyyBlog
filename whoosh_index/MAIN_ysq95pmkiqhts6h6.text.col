CS224n_NLP- Lecture 1,2-Notes
&lt;h3 id=&quot;intro-to-nlp&quot;&gt;Intro to NLP&lt;/h3&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://raw.githubusercontent.com/karenyyy/Advanced_ML_HSE/master/Bayesian_Methods_for_Machine_Learning/images/1.png&quot; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://raw.githubusercontent.com/karenyyy/Advanced_ML_HSE/master/Bayesian_Methods_for_Machine_Learning/images/2.png&quot; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://raw.githubusercontent.com/karenyyy/Advanced_ML_HSE/master/Bayesian_Methods_for_Machine_Learning/images/3.png&quot; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://raw.githubusercontent.com/karenyyy/Advanced_ML_HSE/master/Bayesian_Methods_for_Machine_Learning/images/4.png&quot; /&gt;&lt;/p&gt;
&lt;h3 id=&quot;applications-of-nlp&quot;&gt;Applications of NLP&lt;/h3&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://raw.githubusercontent.com/karenyyy/Advanced_ML_HSE/master/Bayesian_Methods_for_Machine_Learning/images/5.png&quot; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://raw.githubusercontent.com/karenyyy/Advanced_ML_HSE/master/Bayesian_Methods_for_Machine_Learning/images/6.png&quot; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://raw.githubusercontent.com/karenyyy/Advanced_ML_HSE/master/Bayesian_Methods_for_Machine_Learning/images/7.png&quot; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://raw.githubusercontent.com/karenyyy/Advanced_ML_HSE/master/Bayesian_Methods_for_Machine_Learning/images/8.png&quot; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://raw.githubusercontent.com/karenyyy/Advanced_ML_HSE/master/Bayesian_Methods_for_Machine_Learning/images/9.png&quot; /&gt;&lt;/p&gt;
&lt;h3 id=&quot;word2vec&quot;&gt;word2vec&lt;/h3&gt;
&lt;div class=&quot;codehilite&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;nltk.corpus&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;wordnet&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;wn&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;panda&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;wn&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;synset&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;panda.n.01&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;_&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;_&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;panda&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;closure&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;lambda&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;hypernyms&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;())])&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;# closure used as apply?&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div class=&quot;codehilite&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;[Synset(&amp;#39;procyonid.n.01&amp;#39;), Synset(&amp;#39;carnivore.n.01&amp;#39;), Synset(&amp;#39;placental.n.01&amp;#39;), Synset(&amp;#39;mammal.n.01&amp;#39;), Synset(&amp;#39;vertebrate.n.01&amp;#39;), Synset(&amp;#39;chordate.n.01&amp;#39;), Synset(&amp;#39;animal.n.01&amp;#39;), Synset(&amp;#39;organism.n.01&amp;#39;), Synset(&amp;#39;living_thing.n.01&amp;#39;), Synset(&amp;#39;whole.n.02&amp;#39;), Synset(&amp;#39;object.n.01&amp;#39;), Synset(&amp;#39;physical_entity.n.01&amp;#39;), Synset(&amp;#39;entity.n.01&amp;#39;)]
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://raw.githubusercontent.com/karenyyy/Advanced_ML_HSE/master/Bayesian_Methods_for_Machine_Learning/images/10.png&quot; /&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Since we can not calculate the word similarities using one-hot vectors&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Therefore we use another approach, by calculating distributional similarity based on representation. &lt;strong&gt;We can get a lot of value by representing a word by means of its neighbors&lt;/strong&gt;&lt;/p&gt;
&lt;h3 id=&quot;basic-idea-of-learning-neural-neetwork-word-embeddings&quot;&gt;Basic idea of learning neural neetwork word embeddings&lt;/h3&gt;
&lt;p&gt;$$p(context\:\mid w_t) = ...$$&lt;/p&gt;
&lt;p&gt;which has a loss function, e.g.,&lt;/p&gt;
&lt;p&gt;$$J = 1- p(w_{i \text{ where } i \neq t } \mid w_t )$$&lt;/p&gt;
&lt;p&gt;where we will:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;look at many positions t in a big language corpus&lt;/li&gt;
&lt;li&gt;keep adjusting the vector representations of words to minimize the loss&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&quot;main-idea-of-word2vec&quot;&gt;Main idea of Word2vec&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Two algorithms&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Skip-grams&lt;/strong&gt; (SG): Predict context words given target (position independent)&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Continuous Bag of Words (CBOW)&lt;/strong&gt;: Predict target word from bag-of-words context&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Two (moderately efficient) training methods&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;hierarchial softmax&lt;/li&gt;
&lt;li&gt;negative sampling&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://raw.githubusercontent.com/karenyyy/Advanced_ML_HSE/master/Bayesian_Methods_for_Machine_Learning/images/11.png&quot; /&gt;&lt;/p&gt;
&lt;h3 id=&quot;details-of-word2vec&quot;&gt;Details of word2vec&lt;/h3&gt;
&lt;p&gt;For each word t=1 ... T, predict surrounding words in a window of radius m of every word.&lt;/p&gt;
&lt;p&gt;Objective function: Maximize the probability of any context word given the current center word.&lt;/p&gt;
&lt;p&gt;$$J&#39;(\theta) = \prod^T_{t=1} \prod &lt;em t_j=&quot;t+j&quot;&gt;{-m \le j \le m, j \neq 0} p(w&lt;/em&gt; \mid w_t; \theta)$$&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Negative Log Likelihood&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;$$J(\theta) = - \frac{1}{T} \sum^T_{t=1} \sum_{-m \le j \le m, j \neq 0} \log p(w_{t+j} \mid w_t)$$&lt;/p&gt;
&lt;p&gt;$$\text{ where } \theta \text{ represents all variables we will optimize } $$&lt;/p&gt;
&lt;p&gt;$$p(o \mid c) = \frac{exp (u_o^T v_c)}{\sum^v_{w=1} exp(u_w^T v_c)}, \text{ where o: outside, c: center}$$&lt;/p&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://raw.githubusercontent.com/karenyyy/Advanced_ML_HSE/master/Bayesian_Methods_for_Machine_Learning/images/12.png&quot; /&gt;&lt;/p&gt;deeplearning.ai - CNN - Week 1 Assignment 1
# Convolutional Neural Networks: Step by Step

Welcome to Course 4&#39;s first assignment! In this assignment, you will implement convolutional (CONV) and pooling (POOL) layers in numpy, including both forward propagation and (optionally) backward propagation. 

**Notation**:
- Superscript $[l]$ denotes an object of the $l^{th}$ layer. 
    - Example: $a^{[4]}$ is the $4^{th}$ layer activation. $W^{[5]}$ and $b^{[5]}$ are the $5^{th}$ layer parameters.


- Superscript $(i)$ denotes an object from the $i^{th}$ example. 
    - Example: $x^{(i)}$ is the $i^{th}$ training example input.
    
    
- Lowerscript $i$ denotes the $i^{th}$ entry of a vector.
    - Example: $a^{[l]}_i$ denotes the $i^{th}$ entry of the activations in layer $l$, assuming this is a fully connected (FC) layer.
    
    
- $n_H$, $n_W$ and $n_C$ denote respectively the height, width and number of channels of a given layer. If you want to reference a specific layer $l$, you can also write $n_H^{[l]}$, $n_W^{[l]}$, $n_C^{[l]}$. 
- $n_{H_{prev}}$, $n_{W_{prev}}$ and $n_{C_{prev}}$ denote respectively the height, width and number of channels of the previous layer. If referencing a specific layer $l$, this could also be denoted $n_H^{[l-1]}$, $n_W^{[l-1]}$, $n_C^{[l-1]}$. 

We assume that you are already familiar with `numpy` and/or have completed the previous courses of the specialization. Let&#39;s get started!

## 1 - Packages

Let&#39;s first import all the packages that you will need during this assignment. 
- [numpy](www.numpy.org) is the fundamental package for scientific computing with Python.
- [matplotlib](http://matplotlib.org) is a library to plot graphs in Python.
- np.random.seed(1) is used to keep all the random function calls consistent. It will help us grade your work.


```python
import numpy as np
import h5py
import matplotlib.pyplot as plt

%matplotlib inline
plt.rcParams[&#39;figure.figsize&#39;] = (5.0, 4.0) # set default size of plots
plt.rcParams[&#39;image.interpolation&#39;] = &#39;nearest&#39;
plt.rcParams[&#39;image.cmap&#39;] = &#39;gray&#39;

%load_ext autoreload
%autoreload 2

np.random.seed(1)
```

## 2 - Outline of the Assignment

You will be implementing the building blocks of a convolutional neural network! Each function you will implement will have detailed instructions that will walk you through the steps needed:

- Convolution functions, including:
    - Zero Padding
    - Convolve window 
    - Convolution forward
    - Convolution backward (optional)
- Pooling functions, including:
    - Pooling forward
    - Create mask 
    - Distribute value
    - Pooling backward (optional)
    
This notebook will ask you to implement these functions from scratch in `numpy`. In the next notebook, you will use the TensorFlow equivalents of these functions to build the following model:

&lt;img src=&quot;https://raw.githubusercontent.com/karenyyy/Coursera_and_Udemy/master/deeplearningai_coursera/Convolutional%20Neural%20Networks/images/model.png&quot; style=&quot;width:800px;height:300px;&quot;&gt;

**Note** that for every forward function, there is its corresponding backward equivalent. Hence, at every step of your forward module you will store some parameters in a cache. These parameters are used to compute gradients during backpropagation. 

## 3 - Convolutional Neural Networks

Although programming frameworks make convolutions easy to use, they remain one of the hardest concepts to understand in Deep Learning. A convolution layer transforms an input volume into an output volume of different size, as shown below. 

&lt;img src=&quot;https://raw.githubusercontent.com/karenyyy/Coursera_and_Udemy/master/deeplearningai_coursera/Convolutional%20Neural%20Networks/images/conv_nn.png&quot; style=&quot;width:350px;height:200px;&quot;&gt;

In this part, you will build every step of the convolution layer. You will first implement two helper functions: one for zero padding and the other for computing the convolution function itself. 

### 3.1 - Zero-Padding

Zero-padding adds zeros around the border of an image:

&lt;img src=&quot;https://raw.githubusercontent.com/karenyyy/Coursera_and_Udemy/master/deeplearningai_coursera/Convolutional%20Neural%20Networks/images/PAD.png&quot; style=&quot;width:600px;height:400px;&quot;&gt;
&lt;caption&gt;&lt;center&gt; &lt;u&gt;  **Figure 1** &lt;/u&gt;  : **Zero-Padding**&lt;br&gt; Image (3 channels, RGB) with a padding of 2. &lt;/center&gt;&lt;/caption&gt;

The main benefits of padding are the following:

- It allows you to use a CONV layer without necessarily shrinking the height and width of the volumes. This is important for building deeper networks, since otherwise the height/width would shrink as you go to deeper layers. An important special case is the &quot;same&quot; convolution, in which the height/width is exactly preserved after one layer. 

- It helps us keep more of the information at the border of an image. Without padding, very few values at the next layer would be affected by pixels as the edges of an image.

**Exercise**: Implement the following function, which pads all the images of a batch of examples X with zeros. [Use np.pad](https://docs.scipy.org/doc/numpy/reference/generated/numpy.pad.html). Note if you want to pad the array &quot;a&quot; of shape $(5,5,5,5,5)$ with `pad = 1` for the 2nd dimension, `pad = 3` for the 4th dimension and `pad = 0` for the rest, you would do:
```python
a = np.pad(a, ((0,0), (1,1), (0,0), (3,3), (0,0)), &#39;constant&#39;, constant_values = (..,..))
```


```python
# GRADED FUNCTION: zero_pad

def zero_pad(X, pad):
    &quot;&quot;&quot;
    Pad with zeros all images of the dataset X. The padding is applied to the height and width of an image, 
    as illustrated in Figure 1.
    
    Argument:
    X -- python numpy array of shape (m, n_H, n_W, n_C) representing a batch of m images
    pad -- integer, amount of padding around each image on vertical and horizontal dimensions
    
    Returns:
    X_pad -- padded image of shape (m, n_H + 2*pad, n_W + 2*pad, n_C)
    &quot;&quot;&quot;
    
    
    X_pad = np.pad(X, ((0, 0), (pad, pad), (pad, pad), (0, 0)), &#39;constant&#39;, constant_values=0)
    
    
    return X_pad
```


```python
np.random.seed(1)
x = np.random.randn(4, 3, 3, 2)
x_pad = zero_pad(x, 2)
print (&quot;x.shape =&quot;, x.shape)
print (&quot;x_pad.shape =&quot;, x_pad.shape)
print (&quot;x[1, 1] =&quot;, x[1, 1])
print (&quot;x_pad[1, 1] =&quot;, x_pad[1, 1])

fig, axarr = plt.subplots(1, 2)
axarr[0].set_title(&#39;x&#39;)
axarr[0].imshow(x[0,:,:,0])
axarr[1].set_title(&#39;x_pad&#39;)
axarr[1].imshow(x_pad[0,:,:,0])
```

    x.shape = (4, 3, 3, 2)
    x_pad.shape = (4, 7, 7, 2)
    x[1, 1] = [[ 0.90085595 -0.68372786]
     [-0.12289023 -0.93576943]
     [-0.26788808  0.53035547]]
    x_pad[1, 1] = [[ 0.  0.]
     [ 0.  0.]
     [ 0.  0.]
     [ 0.  0.]
     [ 0.  0.]
     [ 0.  0.]
     [ 0.  0.]]





    &lt;matplotlib.image.AxesImage at 0x7facfe2b51d0&gt;




![png](https://raw.githubusercontent.com/karenyyy/Coursera_and_Udemy/master/deeplearningai_coursera/Convolutional%20Neural%20Networks/images/step/output_7_2.png)


**Expected Output**:

&lt;table&gt;
    &lt;tr&gt;
        &lt;td&gt;
            **x.shape**:
        &lt;/td&gt;
        &lt;td&gt;
           (4, 3, 3, 2)
        &lt;/td&gt;
    &lt;/tr&gt;
        &lt;tr&gt;
        &lt;td&gt;
            **x_pad.shape**:
        &lt;/td&gt;
        &lt;td&gt;
           (4, 7, 7, 2)
        &lt;/td&gt;
    &lt;/tr&gt;
        &lt;tr&gt;
        &lt;td&gt;
            **x[1,1]**:
        &lt;/td&gt;
        &lt;td&gt;
           [[ 0.90085595 -0.68372786]
 [-0.12289023 -0.93576943]
 [-0.26788808  0.53035547]]
        &lt;/td&gt;
    &lt;/tr&gt;
        &lt;tr&gt;
        &lt;td&gt;
            **x_pad[1,1]**:
        &lt;/td&gt;
        &lt;td&gt;
           [[ 0.  0.]
 [ 0.  0.]
 [ 0.  0.]
 [ 0.  0.]
 [ 0.  0.]
 [ 0.  0.]
 [ 0.  0.]]
        &lt;/td&gt;
    &lt;/tr&gt;

&lt;/table&gt;

### 3.2 - Single step of convolution 

In this part, implement a single step of convolution, in which you apply the filter to a single position of the input. This will be used to build a convolutional unit, which: 

- Takes an input volume 
- Applies a filter at every position of the input
- Outputs another volume (usually of different size)

&lt;img src=&quot;https://raw.githubusercontent.com/karenyyy/Coursera_and_Udemy/master/deeplearningai_coursera/Convolutional%20Neural%20Networks/images/Convolution_schematic.gif&quot; style=&quot;width:500px;height:300px;&quot;&gt;
&lt;caption&gt;&lt;center&gt; &lt;u&gt; **Figure 2** &lt;/u&gt;  : **Convolution operation**&lt;br&gt; with a filter of 2x2 and a stride of 1 (stride = amount you move the window each time you slide) &lt;/center&gt;&lt;/caption&gt;

In a computer vision application, each value in the matrix on the left corresponds to a single pixel value, and we convolve a 3x3 filter with the image by multiplying its values element-wise with the original matrix, then summing them up. In this first step of the exercise, you will implement a single step of convolution, corresponding to applying a filter to just one of the positions to get a single real-valued output. 

Later in this notebook, you&#39;ll apply this function to multiple positions of the input to implement the full convolutional operation. 

**Exercise**: Implement conv_single_step(). [Hint](https://docs.scipy.org/doc/numpy-1.13.0/reference/generated/numpy.sum.html).



```python
# GRADED FUNCTION: conv_single_step

def conv_single_step(a_slice_prev, W, b):
    &quot;&quot;&quot;
    Apply one filter defined by parameters W on a single slice (a_slice_prev) of the output activation 
    of the previous layer.
    
    Arguments:
    a_slice_prev -- slice of input data of shape (f, f, n_C_prev)
    W -- Weight parameters contained in a window - matrix of shape (f, f, n_C_prev)
    b -- Bias parameters contained in a window - matrix of shape (1, 1, 1)
    
    Returns:
    Z -- a scalar value, result of convolving the sliding window (W, b) on a slice x of the input data
    &quot;&quot;&quot;

    
    # Element-wise product between a_slice and W. Add bias.
    s = np.multiply(a_slice_prev, W) + b
    # Sum over all entries of the volume s
    Z = np.sum(s)
    

    return Z
```


```python
np.random.seed(1)
a_slice_prev = np.random.randn(4, 4, 3)
W = np.random.randn(4, 4, 3)
b = np.random.randn(1, 1, 1)

Z = conv_single_step(a_slice_prev, W, b)
print(&quot;Z =&quot;, Z)
```

    Z = -23.1602122025


**Expected Output**:
&lt;table&gt;
    &lt;tr&gt;
        &lt;td&gt;
            **Z**
        &lt;/td&gt;
        &lt;td&gt;
            -23.1602122025
        &lt;/td&gt;
    &lt;/tr&gt;

&lt;/table&gt;

### 3.3 - Convolutional Neural Networks - Forward pass

In the forward pass, you will take many filters and convolve them on the input. Each &#39;convolution&#39; gives you a 2D matrix output. You will then stack these outputs to get a 3D volume: 

&lt;center&gt;
&lt;video width=&quot;620&quot; height=&quot;440&quot; src=&quot;https://raw.githubusercontent.com/karenyyy/Coursera_and_Udemy/master/deeplearningai_coursera/Convolutional%20Neural%20Networks/../images/conv_kiank.mp4&quot; type=&quot;video/mp4&quot; controls&gt;
&lt;/video&gt;
&lt;/center&gt;

**Exercise**: Implement the function below to convolve the filters W on an input activation A_prev. This function takes as input A_prev, the activations output by the previous layer (for a batch of m inputs), F filters/weights denoted by W, and a bias vector denoted by b, where each filter has its own (single) bias. Finally you also have access to the hyperparameters dictionary which contains the stride and the padding. 

**Hint**: 
1. To select a 2x2 slice at the upper left corner of a matrix &quot;a_prev&quot; (shape (5,5,3)), you would do:
```python
a_slice_prev = a_prev[0:2,0:2,:]
```
This will be useful when you will define `a_slice_prev` below, using the `start/end` indexes you will define.
2. To define a_slice you will need to first define its corners `vert_start`, `vert_end`, `horiz_start` and `horiz_end`. This figure may be helpful for you to find how each of the corner can be defined using h, w, f and s in the code below.

&lt;img src=&quot;https://raw.githubusercontent.com/karenyyy/Coursera_and_Udemy/master/deeplearningai_coursera/Convolutional%20Neural%20Networks/../images/vert_horiz_kiank.png&quot; style=&quot;width:400px;height:300px;&quot;&gt;
&lt;caption&gt;&lt;center&gt; &lt;u&gt; **Figure 3** &lt;/u&gt;  : **Definition of a slice using vertical and horizontal start/end (with a 2x2 filter)** &lt;br&gt; This figure shows only a single channel.  &lt;/center&gt;&lt;/caption&gt;


**Reminder**:
The formulas relating the output shape of the convolution to the input shape is:
$$ n_H = \lfloor \frac{n_{H_{prev}} - f + 2 \times pad}{stride} \rfloor +1 $$
$$ n_W = \lfloor \frac{n_{W_{prev}} - f + 2 \times pad}{stride} \rfloor +1 $$
$$ n_C = \text{number of filters used in the convolution}$$

For this exercise, we won&#39;t worry about vectorization, and will just implement everything with for-loops.


```python
# GRADED FUNCTION: conv_forward

def conv_forward(A_prev, W, b, hparameters):
    &quot;&quot;&quot;
    Implements the forward propagation for a convolution function
    
    Arguments:
    A_prev -- output activations of the previous layer, numpy array of shape (m, n_H_prev, n_W_prev, n_C_prev)
    W -- Weights, numpy array of shape (f, f, n_C_prev, n_C)
    b -- Biases, numpy array of shape (1, 1, 1, n_C)
    hparameters -- python dictionary containing &quot;stride&quot; and &quot;pad&quot;
        
    Returns:
    Z -- conv output, numpy array of shape (m, n_H, n_W, n_C)
    cache -- cache of values needed for the conv_backward() function
    &quot;&quot;&quot;
    
    
    # Retrieve dimensions from A_prev&#39;s shape (≈1 line)  
    (m, n_H_prev, n_W_prev, n_C_prev) = A_prev.shape
    
    # Retrieve dimensions from W&#39;s shape (≈1 line)
    (f, f, n_C_prev, n_C) = W.shape

    # Retrieve information from &quot;hparameters&quot; (≈2 lines)
    stride = hparameters[&#39;stride&#39;]
    pad = hparameters[&#39;pad&#39;]
    
    # Compute the dimensions of the CONV output volume using the formula given above. Hint: use int() to floor. (≈2 lines)
    n_H = int((n_H_prev - f + 2 * pad) / stride) + 1
    n_W = int((n_W_prev - f + 2 * pad) / stride) + 1
    
    # Initialize the output volume Z with zeros. (≈1 line)
    Z = np.zeros((m, n_H, n_W, n_C))
    
    # Create A_prev_pad by padding A_prev
    A_prev_pad = zero_pad(A_prev, pad)
    
    for i in range(m):                                 # loop over the batch of training examples
        a_prev_pad = A_prev_pad[i]                     # Select ith training example&#39;s padded activation
        for h in range(n_H):                           # loop over vertical axis of the output volume
            for w in range(n_W):                       # loop over horizontal axis of the output volume
                for c in range(n_C):                   # loop over channels (= #filters) of the output volume
                    # Find the corners of the current &quot;slice&quot; (≈4 lines)
                    vert_start = h * stride
                    vert_end = vert_start + f
                    horiz_start = w * stride
                    horiz_end = horiz_start + f
                    # Use the corners to define the (3D) slice of a_prev_pad (See Hint above the cell). (≈1 line)
                    a_slice_prev = a_prev_pad[vert_start:vert_end, horiz_start:horiz_end, :]
                    # Convolve the (3D) slice with the correct filter W and bias b, to get back one output neuron. (≈1 line)
                    Z[i, h, w, c] = conv_single_step(a_slice_prev, W[...,c], b[...,c])
                                        
    

    # Making sure your output shape is correct
    assert(Z.shape == (m, n_H, n_W, n_C))
    
    # Save information in &quot;cache&quot; for the backprop
    cache = (A_prev, W, b, hparameters)
    
    return Z, cache
```


```python
np.random.seed(1)
A_prev = np.random.randn(10, 4, 4, 3)
W = np.random.randn(2, 2, 3, 8)
b = np.random.randn(1, 1, 1, 8)
hparameters = {&quot;pad&quot; : 2,
               &quot;stride&quot;: 1}

Z, cache_conv = conv_forward(A_prev, W, b, hparameters)
print(&quot;Z&#39;s mean =&quot;, np.mean(Z))
print(&quot;cache_conv[0][1][2][3] =&quot;, cache_conv[0][1][2][3])
```

    Z&#39;s mean = 0.155859324889
    cache_conv[0][1][2][3] = [-0.20075807  0.18656139  0.41005165]


**Expected Output**:

&lt;table&gt;
    &lt;tr&gt;
        &lt;td&gt;
            **Z&#39;s mean**
        &lt;/td&gt;
        &lt;td&gt;
            0.155859324889
        &lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
        &lt;td&gt;
            **cache_conv[0][1][2][3]**
        &lt;/td&gt;
        &lt;td&gt;
            [-0.20075807  0.18656139  0.41005165]
        &lt;/td&gt;
    &lt;/tr&gt;

&lt;/table&gt;


Finally, CONV layer should also contain an activation, in which case we would add the following line of code:

```python
# Convolve the window to get back one output neuron
Z[i, h, w, c] = ...
# Apply activation
A[i, h, w, c] = activation(Z[i, h, w, c])
```

You don&#39;t need to do it here. 


## 4 - Pooling layer 

The pooling (POOL) layer reduces the height and width of the input. It helps reduce computation, as well as helps make feature detectors more invariant to its position in the input. The two types of pooling layers are: 

- Max-pooling layer: slides an ($f, f$) window over the input and stores the max value of the window in the output.

- Average-pooling layer: slides an ($f, f$) window over the input and stores the average value of the window in the output.

&lt;table&gt;
&lt;td&gt;
&lt;img src=&quot;https://raw.githubusercontent.com/karenyyy/Coursera_and_Udemy/master/deeplearningai_coursera/Convolutional%20Neural%20Networks/images/max_pool1.png&quot; style=&quot;width:500px;height:300px;&quot;&gt;
&lt;td&gt;

&lt;td&gt;
&lt;img src=&quot;https://raw.githubusercontent.com/karenyyy/Coursera_and_Udemy/master/deeplearningai_coursera/Convolutional%20Neural%20Networks/images/a_pool.png&quot; style=&quot;width:500px;height:300px;&quot;&gt;
&lt;td&gt;
&lt;/table&gt;

These pooling layers have no parameters for backpropagation to train. However, they have hyperparameters such as the window size $f$. This specifies the height and width of the fxf window you would compute a max or average over. 

### 4.1 - Forward Pooling
Now, you are going to implement MAX-POOL and AVG-POOL, in the same function. 

**Exercise**: Implement the forward pass of the pooling layer. Follow the hints in the comments below.

**Reminder**:
As there&#39;s no padding, the formulas binding the output shape of the pooling to the input shape is:
$$ n_H = \lfloor \frac{n_{H_{prev}} - f}{stride} \rfloor +1 $$
$$ n_W = \lfloor \frac{n_{W_{prev}} - f}{stride} \rfloor +1 $$
$$ n_C = n_{C_{prev}}$$


```python
# GRADED FUNCTION: pool_forward

def pool_forward(A_prev, hparameters, mode = &quot;max&quot;):
    &quot;&quot;&quot;
    Implements the forward pass of the pooling layer
    
    Arguments:
    A_prev -- Input data, numpy array of shape (m, n_H_prev, n_W_prev, n_C_prev)
    hparameters -- python dictionary containing &quot;f&quot; and &quot;stride&quot;
    mode -- the pooling mode you would like to use, defined as a string (&quot;max&quot; or &quot;average&quot;)
    
    Returns:
    A -- output of the pool layer, a numpy array of shape (m, n_H, n_W, n_C)
    cache -- cache used in the backward pass of the pooling layer, contains the input and hparameters 
    &quot;&quot;&quot;
    
    # Retrieve dimensions from the input shape
    (m, n_H_prev, n_W_prev, n_C_prev) = A_prev.shape
    
    # Retrieve hyperparameters from &quot;hparameters&quot;
    f = hparameters[&quot;f&quot;]
    stride = hparameters[&quot;stride&quot;]
    
    # Define the dimensions of the output
    n_H = int(1 + (n_H_prev - f) / stride)
    n_W = int(1 + (n_W_prev - f) / stride)
    n_C = n_C_prev
    
    # Initialize output matrix A
    A = np.zeros((m, n_H, n_W, n_C))              
    
    
    for i in range(m):                           # loop over the training examples
        for h in range(n_H):                     # loop on the vertical axis of the output volume
            for w in range(n_W):                 # loop on the horizontal axis of the output volume
                for c in range (n_C):            # loop over the channels of the output volume
                    
                    # Find the corners of the current &quot;slice&quot; (≈4 lines)
                    vert_start = h * stride
                    vert_end = vert_start + f
                    horiz_start = w * stride
                    horiz_end = horiz_start + f
                    
                    # Use the corners to define the current slice on the ith training example of A_prev, channel c. (≈1 line)
                    a_prev_slice = A_prev[i, vert_start:vert_end, horiz_start:horiz_end, c]
                    
                    # Compute the pooling operation on the slice. Use an if statment to differentiate the modes. Use np.max/np.mean.
                    if mode == &quot;max&quot;:
                        A[i, h, w, c] = np.max(a_prev_slice)
                    elif mode == &quot;average&quot;:
                        A[i, h, w, c] = np.mean(a_prev_slice)
    
    
    
    # Store the input and hparameters in &quot;cache&quot; for pool_backward()
    cache = (A_prev, hparameters)
    
    # Making sure your output shape is correct
    assert(A.shape == (m, n_H, n_W, n_C))
    
    return A, cache

```


```python
np.random.seed(1)
A_prev = np.random.randn(2, 4, 4, 3)
hparameters = {&quot;stride&quot; : 1, &quot;f&quot;: 4}

A, cache = pool_forward(A_prev, hparameters)
print(&quot;mode = max&quot;)
print(&quot;A =&quot;, A)
print()
A, cache = pool_forward(A_prev, hparameters, mode = &quot;average&quot;)
print(&quot;mode = average&quot;)
print(&quot;A =&quot;, A)
```

    mode = max
    A = [[[[ 1.74481176  1.6924546   2.10025514]]]
    
    
     [[[ 1.19891788  1.51981682  2.18557541]]]]
    
    mode = average
    A = [[[[-0.09498456  0.11180064 -0.14263511]]]
    
    
     [[[-0.09525108  0.28325018  0.33035185]]]]


**Expected Output:**
&lt;table&gt;

    &lt;tr&gt;
    &lt;td&gt;
    A  =
    &lt;/td&gt;
        &lt;td&gt;
         [[[[ 1.74481176  1.6924546   2.10025514]]] &lt;br/&gt;


 [[[ 1.19891788  1.51981682  2.18557541]]]]

        &lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
    &lt;td&gt;
    A  =
    &lt;/td&gt;
        &lt;td&gt;
         [[[[-0.09498456  0.11180064 -0.14263511]]] &lt;br/&gt;


 [[[-0.09525108  0.28325018  0.33035185]]]]

        &lt;/td&gt;
    &lt;/tr&gt;

&lt;/table&gt;


Congratulations! You have now implemented the forward passes of all the layers of a convolutional network. 

The remainer of this notebook is optional, and will not be graded.


## 5 - Backpropagation in convolutional neural networks (OPTIONAL / UNGRADED)

In modern deep learning frameworks, you only have to implement the forward pass, and the framework takes care of the backward pass, so most deep learning engineers don&#39;t need to bother with the details of the backward pass. The backward pass for convolutional networks is complicated. If you wish however, you can work through this optional portion of the notebook to get a sense of what backprop in a convolutional network looks like. 

When in an earlier course you implemented a simple (fully connected) neural network, you used backpropagation to compute the derivatives with respect to the cost to update the parameters. Similarly, in convolutional neural networks you can to calculate the derivatives with respect to the cost in order to update the parameters. The backprop equations are not trivial and we did not derive them in lecture, but we briefly presented them below.

### 5.1 - Convolutional layer backward pass 

Let&#39;s start by implementing the backward pass for a CONV layer. 

#### 5.1.1 - Computing dA:
This is the formula for computing $dA$ with respect to the cost for a certain filter $W_c$ and a given training example:

$$ dA += \sum _{h=0} ^{n_H} \sum_{w=0} ^{n_W} W_c \times dZ_{hw} \tag{1}$$

Where $W_c$ is a filter and $dZ_{hw}$ is a scalar corresponding to the gradient of the cost with respect to the output of the conv layer Z at the hth row and wth column (corresponding to the dot product taken at the ith stride left and jth stride down). Note that at each time, we multiply the the same filter $W_c$ by a different dZ when updating dA. We do so mainly because when computing the forward propagation, each filter is dotted and summed by a different a_slice. Therefore when computing the backprop for dA, we are just adding the gradients of all the a_slices. 

In code, inside the appropriate for-loops, this formula translates into:
```python
da_prev_pad[vert_start:vert_end, horiz_start:horiz_end, :] += W[:,:,:,c] * dZ[i, h, w, c]
```

#### 5.1.2 - Computing dW:
This is the formula for computing $dW_c$ ($dW_c$ is the derivative of one filter) with respect to the loss:

$$ dW_c  += \sum _{h=0} ^{n_H} \sum_{w=0} ^ {n_W} a_{slice} \times dZ_{hw}  \tag{2}$$

Where $a_{slice}$ corresponds to the slice which was used to generate the acitivation $Z_{ij}$. Hence, this ends up giving us the gradient for $W$ with respect to that slice. Since it is the same $W$, we will just add up all such gradients to get $dW$. 

In code, inside the appropriate for-loops, this formula translates into:
```python
dW[:,:,:,c] += a_slice * dZ[i, h, w, c]
```

#### 5.1.3 - Computing db:

This is the formula for computing $db$ with respect to the cost for a certain filter $W_c$:

$$ db = \sum_h \sum_w dZ_{hw} \tag{3}$$

As you have previously seen in basic neural networks, db is computed by summing $dZ$. In this case, you are just summing over all the gradients of the conv output (Z) with respect to the cost. 

In code, inside the appropriate for-loops, this formula translates into:
```python
db[:,:,:,c] += dZ[i, h, w, c]
```

**Exercise**: Implement the `conv_backward` function below. You should sum over all the training examples, filters, heights, and widths. You should then compute the derivatives using formulas 1, 2 and 3 above. 


```python
def conv_backward(dZ, cache):
    &quot;&quot;&quot;
    Implement the backward propagation for a convolution function
    
    Arguments:
    dZ -- gradient of the cost with respect to the output of the conv layer (Z), numpy array of shape (m, n_H, n_W, n_C)
    cache -- cache of values needed for the conv_backward(), output of conv_forward()
    
    Returns:
    dA_prev -- gradient of the cost with respect to the input of the conv layer (A_prev),
               numpy array of shape (m, n_H_prev, n_W_prev, n_C_prev)
    dW -- gradient of the cost with respect to the weights of the conv layer (W)
          numpy array of shape (f, f, n_C_prev, n_C)
    db -- gradient of the cost with respect to the biases of the conv layer (b)
          numpy array of shape (1, 1, 1, n_C)
    &quot;&quot;&quot;
    
    
    # Retrieve information from &quot;cache&quot;
    (A_prev, W, b, hparameters) = cache
    
    # Retrieve dimensions from A_prev&#39;s shape
    (m, n_H_prev, n_W_prev, n_C_prev) = A_prev.shape
    
    # Retrieve dimensions from W&#39;s shape
    (f, f, n_C_prev, n_C) = W.shape
    
    # Retrieve information from &quot;hparameters&quot;
    stride = hparameters[&quot;stride&quot;]
    pad = hparameters[&quot;pad&quot;]
    
    # Retrieve dimensions from dZ&#39;s shape
    (m, n_H, n_W, n_C) = dZ.shape
    
    # Initialize dA_prev, dW, db with the correct shapes
    dA_prev = np.zeros((m, n_H_prev, n_W_prev, n_C_prev))                           
    dW = np.zeros((f, f, n_C_prev, n_C))
    db = np.zeros((1, 1, 1, n_C))

    # Pad A_prev and dA_prev
    A_prev_pad = zero_pad(A_prev, pad)
    dA_prev_pad = zero_pad(dA_prev, pad)
    
    for i in range(m):                       # loop over the training examples
        
        # select ith training example from A_prev_pad and dA_prev_pad
        a_prev_pad = A_prev_pad[i]
        da_prev_pad = dA_prev_pad[i]
        
        for h in range(n_H):                   # loop over vertical axis of the output volume
            for w in range(n_W):               # loop over horizontal axis of the output volume
                for c in range(n_C):           # loop over the channels of the output volume
                    
                    # Find the corners of the current &quot;slice&quot;
                    vert_start = h
                    vert_end = vert_start + f
                    horiz_start = w
                    horiz_end = horiz_start + f
                    
                    # Use the corners to define the slice from a_prev_pad
                    a_slice = a_prev_pad[vert_start:vert_end, horiz_start:horiz_end, :]

                    # Update gradients for the window and the filter&#39;s parameters using the code formulas given above
                    da_prev_pad[vert_start:vert_end, horiz_start:horiz_end, :] += W[:,:,:,c] * dZ[i, h, w, c]
                    dW[:,:,:,c] += a_slice * dZ[i, h, w, c]
                    db[:,:,:,c] += dZ[i, h, w, c]
                    
        # Set the ith training example&#39;s dA_prev to the unpaded da_prev_pad (Hint: use X[pad:-pad, pad:-pad, :])
        dA_prev[i, :, :, :] = da_prev_pad[pad:-pad, pad:-pad, :]
    
    
    # Making sure your output shape is correct
    assert(dA_prev.shape == (m, n_H_prev, n_W_prev, n_C_prev))
    
    return dA_prev, dW, db
```


```python
np.random.seed(1)
dA, dW, db = conv_backward(Z, cache_conv)
print(&quot;dA_mean =&quot;, np.mean(dA))
print(&quot;dW_mean =&quot;, np.mean(dW))
print(&quot;db_mean =&quot;, np.mean(db))
# print(dA.shape)
```

    dA_mean = 9.60899067587
    dW_mean = 10.5817412755
    db_mean = 76.3710691956


** Expected Output: **
&lt;table&gt;
    &lt;tr&gt;
        &lt;td&gt;
            **dA_mean**
        &lt;/td&gt;
        &lt;td&gt;
            9.60899067587
        &lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
        &lt;td&gt;
            **dW_mean**
        &lt;/td&gt;
        &lt;td&gt;
            10.5817412755
        &lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
        &lt;td&gt;
            **db_mean**
        &lt;/td&gt;
        &lt;td&gt;
            76.3710691956
        &lt;/td&gt;
    &lt;/tr&gt;

&lt;/table&gt;


## 5.2 Pooling layer - backward pass

Next, let&#39;s implement the backward pass for the pooling layer, starting with the MAX-POOL layer. Even though a pooling layer has no parameters for backprop to update, you still need to backpropagation the gradient through the pooling layer in order to compute gradients for layers that came before the pooling layer. 

### 5.2.1 Max pooling - backward pass  

Before jumping into the backpropagation of the pooling layer, you are going to build a helper function called `create_mask_from_window()` which does the following: 

$$ X = \begin{bmatrix}
1 &amp;&amp; 3 \\
4 &amp;&amp; 2
\end{bmatrix} \quad \rightarrow  \quad M =\begin{bmatrix}
0 &amp;&amp; 0 \\
1 &amp;&amp; 0
\end{bmatrix}\tag{4}$$

As you can see, this function creates a &quot;mask&quot; matrix which keeps track of where the maximum of the matrix is. True (1) indicates the position of the maximum in X, the other entries are False (0). You&#39;ll see later that the backward pass for average pooling will be similar to this but using a different mask.  

**Exercise**: Implement `create_mask_from_window()`. This function will be helpful for pooling backward. 
Hints:
- [np.max()]() may be helpful. It computes the maximum of an array.
- If you have a matrix X and a scalar x: `A = (X == x)` will return a matrix A of the same size as X such that:
```
A[i,j] = True if X[i,j] = x
A[i,j] = False if X[i,j] != x
```
- Here, you don&#39;t need to consider cases where there are several maxima in a matrix.


```python
def create_mask_from_window(x):
    &quot;&quot;&quot;
    Creates a mask from an input matrix x, to identify the max entry of x.
    
    Arguments:
    x -- Array of shape (f, f)
    
    Returns:
    mask -- Array of the same shape as window, contains a True at the position corresponding to the max entry of x.
    &quot;&quot;&quot;
    
    
    mask = x == np.max(x)
    
    
    return mask
```


```python
np.random.seed(1)
x = np.random.randn(2,3)
mask = create_mask_from_window(x)
print(&#39;x = &#39;, x)
print(&quot;mask = &quot;, mask)
```

    x =  [[ 1.62434536 -0.61175641 -0.52817175]
     [-1.07296862  0.86540763 -2.3015387 ]]
    mask =  [[ True False False]
     [False False False]]


**Expected Output:** 

&lt;table&gt; 
&lt;tr&gt; 
&lt;td&gt;

**x =**
&lt;/td&gt;

&lt;td&gt;

[[ 1.62434536 -0.61175641 -0.52817175] &lt;br&gt;
 [-1.07296862  0.86540763 -2.3015387 ]]

  &lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt; 
&lt;td&gt;
**mask =**
&lt;/td&gt;
&lt;td&gt;
[[ True False False] &lt;br&gt;
 [False False False]]
&lt;/td&gt;
&lt;/tr&gt;


&lt;/table&gt;

Why do we keep track of the position of the max? It&#39;s because this is the input value that ultimately influenced the output, and therefore the cost. Backprop is computing gradients with respect to the cost, so anything that influences the ultimate cost should have a non-zero gradient. So, backprop will &quot;propagate&quot; the gradient back to this particular input value that had influenced the cost. 

### 5.2.2 - Average pooling - backward pass 

In max pooling, for each input window, all the &quot;influence&quot; on the output came from a single input value--the max. In average pooling, every element of the input window has equal influence on the output. So to implement backprop, you will now implement a helper function that reflects this.

For example if we did average pooling in the forward pass using a 2x2 filter, then the mask you&#39;ll use for the backward pass will look like: 
$$ dZ = 1 \quad \rightarrow  \quad dZ =\begin{bmatrix}
1/4 &amp;&amp; 1/4 \\
1/4 &amp;&amp; 1/4
\end{bmatrix}\tag{5}$$

This implies that each position in the $dZ$ matrix contributes equally to output because in the forward pass, we took an average. 

**Exercise**: Implement the function below to equally distribute a value dz through a matrix of dimension shape. [Hint](https://docs.scipy.org/doc/numpy-1.13.0/reference/generated/numpy.ones.html)


```python
def distribute_value(dz, shape):
    &quot;&quot;&quot;
    Distributes the input value in the matrix of dimension shape
    
    Arguments:
    dz -- input scalar
    shape -- the shape (n_H, n_W) of the output matrix for which we want to distribute the value of dz
    
    Returns:
    a -- Array of size (n_H, n_W) for which we distributed the value of dz
    &quot;&quot;&quot;
    
    
    # Retrieve dimensions from shape (≈1 line)
    (n_H, n_W) = shape
    
    # Compute the value to distribute on the matrix (≈1 line)
    average = dz / (n_H * n_W)
    
    # Create a matrix where every entry is the &quot;average&quot; value (≈1 line)
    a = np.ones(shape) * average
    
    
    return a
```


```python
a = distribute_value(2, (2,2))
print(&#39;distributed value =&#39;, a)
```

    distributed value = [[ 0.5  0.5]
     [ 0.5  0.5]]


**Expected Output**: 

&lt;table&gt; 
&lt;tr&gt; 
&lt;td&gt;
distributed_value =
&lt;/td&gt;
&lt;td&gt;
[[ 0.5  0.5]
&lt;br\&gt; 
[ 0.5  0.5]]
&lt;/td&gt;
&lt;/tr&gt;
&lt;/table&gt;

### 5.2.3 Putting it together: Pooling backward 

You now have everything you need to compute backward propagation on a pooling layer.

**Exercise**: Implement the `pool_backward` function in both modes (`&quot;max&quot;` and `&quot;average&quot;`). You will once again use 4 for-loops (iterating over training examples, height, width, and channels). You should use an `if/elif` statement to see if the mode is equal to `&#39;max&#39;` or `&#39;average&#39;`. If it is equal to &#39;average&#39; you should use the `distribute_value()` function you implemented above to create a matrix of the same shape as `a_slice`. Otherwise, the mode is equal to &#39;`max`&#39;, and you will create a mask with `create_mask_from_window()` and multiply it by the corresponding value of dZ.


```python

def pool_backward(dA, cache, mode = &quot;max&quot;):
    &quot;&quot;&quot;
    Implements the backward pass of the pooling layer
    
    Arguments:
    dA -- gradient of cost with respect to the output of the pooling layer, same shape as A
    cache -- cache output from the forward pass of the pooling layer, contains the layer&#39;s input and hparameters 
    mode -- the pooling mode you would like to use, defined as a string (&quot;max&quot; or &quot;average&quot;)
    
    Returns:
    dA_prev -- gradient of cost with respect to the input of the pooling layer, same shape as A_prev
    &quot;&quot;&quot;
    
    
    
    # Retrieve information from cache (≈1 line)
    (A_prev, hparameters) = cache
    
    # Retrieve hyperparameters from &quot;hparameters&quot; (≈2 lines)
    stride = hparameters[&quot;stride&quot;]
    f = hparameters[&quot;f&quot;]
    
    # Retrieve dimensions from A_prev&#39;s shape and dA&#39;s shape (≈2 lines)
    m, n_H_prev, n_W_prev, n_C_prev = A_prev.shape
    m, n_H, n_W, n_C = dA.shape
    
    # Initialize dA_prev with zeros (≈1 line)
    dA_prev = np.zeros(A_prev.shape)
    
    for i in range(m):                       # loop over the training examples
        # select training example from A_prev (≈1 line)
        a_prev = A_prev[i]
        for h in range(n_H):                   # loop on the vertical axis
            for w in range(n_W):               # loop on the horizontal axis
                for c in range(n_C):           # loop over the channels (depth)
                    # Find the corners of the current &quot;slice&quot; (≈4 lines)
                    vert_start = h
                    vert_end = vert_start + f
                    horiz_start = w
                    horiz_end = horiz_start + f
                    
                    # Compute the backward propagation in both modes.
                    if mode == &quot;max&quot;:
                        # Use the corners and &quot;c&quot; to define the current slice from a_prev (≈1 line)
                        a_prev_slice = a_prev[vert_start:vert_end, horiz_start:horiz_end, c]
                        # Create the mask from a_prev_slice (≈1 line)
                        mask = create_mask_from_window(a_prev_slice)
                        # Set dA_prev to be dA_prev + (the mask multiplied by the correct entry of dA) (≈1 line)
                        dA_prev[i, vert_start:vert_end, horiz_start:horiz_end, c] += np.multiply(mask, dA[i, h, w, c])
                        
                    elif mode == &quot;average&quot;:
                        # Get the value a from dA (≈1 line)
                        da = dA[i, h, w, c]
                        # Define the shape of the filter as fxf (≈1 line)
                        shape = (f, f)
                        # Distribute it to get the correct slice of dA_prev. i.e. Add the distributed value of da. (≈1 line)
                        dA_prev[i, vert_start:vert_end, horiz_start:horiz_end, c] += distribute_value(da, shape)
                        
    
    
    # Making sure your output shape is correct
    assert(dA_prev.shape == A_prev.shape)
    
    return dA_prev
```


```python
np.random.seed(1)
A_prev = np.random.randn(5, 5, 3, 2)
hparameters = {&quot;stride&quot; : 1, &quot;f&quot;: 2}
A, cache = pool_forward(A_prev, hparameters)
dA = np.random.randn(5, 4, 2, 2)

dA_prev = pool_backward(dA, cache, mode = &quot;max&quot;)
print(&quot;mode = max&quot;)
print(&#39;mean of dA = &#39;, np.mean(dA))
print(&#39;dA_prev[1,1] = &#39;, dA_prev[1,1])  
print()
dA_prev = pool_backward(dA, cache, mode = &quot;average&quot;)
print(&quot;mode = average&quot;)
print(&#39;mean of dA = &#39;, np.mean(dA))
print(&#39;dA_prev[1,1] = &#39;, dA_prev[1,1]) 
```

    mode = max
    mean of dA =  0.145713902729
    dA_prev[1,1] =  [[ 0.          0.        ]
     [ 5.05844394 -1.68282702]
     [ 0.          0.        ]]
    
    mode = average
    mean of dA =  0.145713902729
    dA_prev[1,1] =  [[ 0.08485462  0.2787552 ]
     [ 1.26461098 -0.25749373]
     [ 1.17975636 -0.53624893]]


**Expected Output**: 

mode = max:
&lt;table&gt; 
&lt;tr&gt; 
&lt;td&gt;

**mean of dA =**
&lt;/td&gt;

&lt;td&gt;

0.145713902729

  &lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt; 
&lt;td&gt;
**dA_prev[1,1] =** 
&lt;/td&gt;
&lt;td&gt;
[[ 0.          0.        ] &lt;br&gt;
 [ 5.05844394 -1.68282702] &lt;br&gt;
 [ 0.          0.        ]]
&lt;/td&gt;
&lt;/tr&gt;
&lt;/table&gt;

mode = average
&lt;table&gt; 
&lt;tr&gt; 
&lt;td&gt;

**mean of dA =**
&lt;/td&gt;

&lt;td&gt;

0.145713902729

  &lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt; 
&lt;td&gt;
**dA_prev[1,1] =** 
&lt;/td&gt;
&lt;td&gt;
[[ 0.08485462  0.2787552 ] &lt;br&gt;
 [ 1.26461098 -0.25749373] &lt;br&gt;
 [ 1.17975636 -0.53624893]]
&lt;/td&gt;
&lt;/tr&gt;
&lt;/table&gt;deeplearning.ai - CNN - Week 1 Assignment 2
&lt;h1 id=&quot;convolutional-neural-networks-application&quot;&gt;Convolutional Neural Networks: Application&lt;/h1&gt;
&lt;p&gt;Welcome to Course 4&#39;s second assignment! In this notebook, you will:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Implement helper functions that you will use when implementing a TensorFlow model&lt;/li&gt;
&lt;li&gt;Implement a fully functioning ConvNet using TensorFlow &lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;After this assignment you will be able to:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Build and train a ConvNet in TensorFlow for a classification problem &lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;We assume here that you are already familiar with TensorFlow. If you are not, please refer the &lt;em&gt;TensorFlow Tutorial&lt;/em&gt; of the third week of Course 2 (&quot;&lt;em&gt;Improving deep neural networks&lt;/em&gt;&quot;).&lt;/p&gt;
&lt;h2 id=&quot;10-tensorflow-model&quot;&gt;1.0 - TensorFlow model&lt;/h2&gt;
&lt;p&gt;In the previous assignment, you built helper functions using numpy to understand the mechanics behind convolutional neural networks. Most practical applications of deep learning today are built using programming frameworks, which have many built-in functions you can simply call. &lt;/p&gt;
&lt;p&gt;As usual, we will start by loading in the packages. &lt;/p&gt;
&lt;div class=&quot;codehilite&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;math&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;numpy&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;np&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;h5py&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;matplotlib.pyplot&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;plt&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;scipy&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;PIL&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Image&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;scipy&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ndimage&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;tensorflow&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;tf&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;tensorflow.python.framework&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ops&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;cnn_utils&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;

&lt;span class=&quot;o&quot;&gt;%&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;matplotlib&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;inline&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;random&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;seed&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Run the next cell to load the &quot;SIGNS&quot; dataset you are going to use.&lt;/p&gt;
&lt;div class=&quot;codehilite&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;c1&quot;&gt;# Loading the data (signs)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;X_train_orig&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Y_train_orig&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X_test_orig&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Y_test_orig&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;classes&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;load_dataset&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;As a reminder, the SIGNS dataset is a collection of 6 signs representing numbers from 0 to 5.&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/karenyyy/Coursera_and_Udemy/master/deeplearningai_coursera/Convolutional%20Neural%20Networks/images/SIGNS.png&quot; style=&quot;width:800px;height:300px;&quot;&gt;&lt;/p&gt;
&lt;p&gt;The next cell will show you an example of a labelled image in the dataset. Feel free to change the value of &lt;code&gt;index&lt;/code&gt; below and re-run to see different examples. &lt;/p&gt;
&lt;div class=&quot;codehilite&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;c1&quot;&gt;# Example of a picture&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;index&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;6&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;imshow&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X_train_orig&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;index&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;y = &amp;quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;squeeze&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Y_train_orig&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[:,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;index&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])))&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div class=&quot;codehilite&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;y = 2
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;img alt=&quot;png&quot; src=&quot;https://raw.githubusercontent.com/karenyyy/Coursera_and_Udemy/master/deeplearningai_coursera/Convolutional%20Neural%20Networks/images/application/output_6_1.png&quot; /&gt;&lt;/p&gt;
&lt;p&gt;In Course 2, you had built a fully-connected network for this dataset. But since this is an image dataset, it is more natural to apply a ConvNet to it.&lt;/p&gt;
&lt;p&gt;To get started, let&#39;s examine the shapes of your data. &lt;/p&gt;
&lt;div class=&quot;codehilite&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X_train&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X_train_orig&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;255.&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;X_test&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X_test_orig&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;255.&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;Y_train&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;convert_to_one_hot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Y_train_orig&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;6&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;T&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;Y_test&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;convert_to_one_hot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Y_test_orig&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;6&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;T&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;number of training examples = &amp;quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X_train&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]))&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;number of test examples = &amp;quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X_test&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]))&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;X_train shape: &amp;quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X_train&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;Y_train shape: &amp;quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Y_train&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;X_test shape: &amp;quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X_test&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;Y_test shape: &amp;quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Y_test&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;conv_layers&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div class=&quot;codehilite&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;number of training examples = 1080
number of test examples = 120
X_train shape: (1080, 64, 64, 3)
Y_train shape: (1080, 6)
X_test shape: (120, 64, 64, 3)
Y_test shape: (120, 6)
&lt;/pre&gt;&lt;/div&gt;


&lt;h3 id=&quot;11-create-placeholders&quot;&gt;1.1 - Create placeholders&lt;/h3&gt;
&lt;p&gt;TensorFlow requires that you create placeholders for the input data that will be fed into the model when running the session.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Exercise&lt;/strong&gt;: Implement the function below to create placeholders for the input image X and the output Y. You should not define the number of training examples for the moment. To do so, you could use &quot;None&quot; as the batch size, it will give you the flexibility to choose it later. Hence X should be of dimension &lt;strong&gt;[None, n_H0, n_W0, n_C0]&lt;/strong&gt; and Y should be of dimension &lt;strong&gt;[None, n_y]&lt;/strong&gt;.  &lt;a href=&quot;https://www.tensorflow.org/api_docs/python/tf/placeholder&quot;&gt;Hint&lt;/a&gt;.&lt;/p&gt;
&lt;div class=&quot;codehilite&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;c1&quot;&gt;# GRADED FUNCTION: create_placeholders&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;create_placeholders&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n_H0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n_W0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n_C0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n_y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;sd&quot;&gt;&amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    Creates the placeholders for the tensorflow session.&lt;/span&gt;

&lt;span class=&quot;sd&quot;&gt;    Arguments:&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    n_H0 -- scalar, height of an input image&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    n_W0 -- scalar, width of an input image&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    n_C0 -- scalar, number of channels of the input&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    n_y -- scalar, number of classes&lt;/span&gt;

&lt;span class=&quot;sd&quot;&gt;    Returns:&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    X -- placeholder for the data input, of shape [None, n_H0, n_W0, n_C0] and dtype &amp;quot;float&amp;quot;&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    Y -- placeholder for the input labels, of shape [None, n_y] and dtype &amp;quot;float&amp;quot;&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    &amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;

    &lt;span class=&quot;c1&quot;&gt;### START CODE HERE ### (≈2 lines)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;placeholder&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;None&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n_H0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n_W0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n_C0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dtype&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;float32&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;X&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;Y&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;placeholder&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;None&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n_y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dtype&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;float32&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;Y&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;c1&quot;&gt;### END CODE HERE ###&lt;/span&gt;

    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Y&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div class=&quot;codehilite&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Y&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;create_placeholders&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;64&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;64&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;6&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;X = &amp;quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;Y = &amp;quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div class=&quot;codehilite&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;X = Tensor(&amp;quot;X:0&amp;quot;, shape=(?, 64, 64, 3), dtype=float32)
Y = Tensor(&amp;quot;Y:0&amp;quot;, shape=(?, 6), dtype=float32)
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;strong&gt;Expected Output&lt;/strong&gt;&lt;/p&gt;
&lt;table&gt; 
&lt;tr&gt;
&lt;td&gt;
    X = Tensor(&quot;Placeholder:0&quot;, shape=(?, 64, 64, 3), dtype=float32)

&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;
    Y = Tensor(&quot;Placeholder_1:0&quot;, shape=(?, 6), dtype=float32)

&lt;/td&gt;
&lt;/tr&gt;
&lt;/table&gt;

&lt;h3 id=&quot;12-initialize-parameters&quot;&gt;1.2 - Initialize parameters&lt;/h3&gt;
&lt;p&gt;You will initialize weights/filters $W1$ and $W2$ using &lt;code&gt;tf.contrib.layers.xavier_initializer(seed = 0)&lt;/code&gt;. You don&#39;t need to worry about bias variables as you will soon see that TensorFlow functions take care of the bias. Note also that you will only initialize the weights/filters for the conv2d functions. TensorFlow initializes the layers for the fully connected part automatically. We will talk more about that later in this assignment.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Exercise:&lt;/strong&gt; Implement initialize_parameters(). The dimensions for each group of filters are provided below. Reminder - to initialize a parameter $W$ of shape [1,2,3,4] in Tensorflow, use:&lt;/p&gt;
&lt;div class=&quot;codehilite&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;W&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;get_variable&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;W&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;initializer&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;...&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;a href=&quot;https://www.tensorflow.org/api_docs/python/tf/get_variable&quot;&gt;More Info&lt;/a&gt;.&lt;/p&gt;
&lt;div class=&quot;codehilite&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;c1&quot;&gt;# GRADED FUNCTION: initialize_parameters&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;initialize_parameters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;():&lt;/span&gt;
    &lt;span class=&quot;sd&quot;&gt;&amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    Initializes weight parameters to build a neural network with tensorflow. The shapes are:&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;                        W1 : [4, 4, 3, 8]&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;                        W2 : [2, 2, 8, 16]&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    Returns:&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    parameters -- a dictionary of tensors containing W1, W2&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    &amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;

    &lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;set_random_seed&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;                              &lt;span class=&quot;c1&quot;&gt;# so that your &amp;quot;random&amp;quot; numbers match ours&lt;/span&gt;

    &lt;span class=&quot;c1&quot;&gt;### START CODE HERE ### (approx. 2 lines of code)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;W1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;get_variable&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;W1&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;8&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;initializer&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;contrib&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;layers&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;xavier_initializer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;seed&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;W2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;get_variable&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;W2&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;8&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;16&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;initializer&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;contrib&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;layers&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;xavier_initializer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;seed&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
    &lt;span class=&quot;c1&quot;&gt;### END CODE HERE ###&lt;/span&gt;

    &lt;span class=&quot;n&quot;&gt;parameters&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;W1&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;W1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                  &lt;span class=&quot;s2&quot;&gt;&amp;quot;W2&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;W2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;

    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;parameters&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div class=&quot;codehilite&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;reset_default_graph&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;with&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Session&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sess_test&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;parameters&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;initialize_parameters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;init&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;global_variables_initializer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;sess_test&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;run&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;init&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;W1 = &amp;quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;parameters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;W1&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;eval&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]))&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;W2 = &amp;quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;parameters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;W2&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;eval&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]))&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div class=&quot;codehilite&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;W1 = [ 0.00131723  0.14176141 -0.04434952  0.09197326  0.14984085 -0.03514394
 -0.06847463  0.05245192]
W2 = [-0.08566415  0.17750949  0.11974221  0.16773748 -0.0830943  -0.08058
 -0.00577033 -0.14643836  0.24162132 -0.05857408 -0.19055021  0.1345228
 -0.22779644 -0.1601823  -0.16117483 -0.10286498]
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;strong&gt; Expected Output:&lt;/strong&gt;&lt;/p&gt;
&lt;table&gt;

    &lt;tr&gt;
        &lt;td&gt;
        W1 = 
        &lt;/td&gt;
        &lt;td&gt;
[ 0.00131723  0.14176141 -0.04434952  0.09197326  0.14984085 -0.03514394 &lt;br&gt;
 -0.06847463  0.05245192]
        &lt;/td&gt;
    &lt;/tr&gt;

    &lt;tr&gt;
        &lt;td&gt;
        W2 = 
        &lt;/td&gt;
        &lt;td&gt;
[-0.08566415  0.17750949  0.11974221  0.16773748 -0.0830943  -0.08058 &lt;br&gt;
 -0.00577033 -0.14643836  0.24162132 -0.05857408 -0.19055021  0.1345228 &lt;br&gt;
 -0.22779644 -0.1601823  -0.16117483 -0.10286498]
        &lt;/td&gt;
    &lt;/tr&gt;

&lt;/table&gt;

&lt;h3 id=&quot;12-forward-propagation&quot;&gt;1.2 - Forward propagation&lt;/h3&gt;
&lt;p&gt;In TensorFlow, there are built-in functions that carry out the convolution steps for you.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;tf.nn.conv2d(X,W1, strides = [1,s,s,1], padding = &#39;SAME&#39;):&lt;/strong&gt; given an input $X$ and a group of filters $W1$, this function convolves $W1$&#39;s filters on X. The third input ([1,f,f,1]) represents the strides for each dimension of the input (m, n_H_prev, n_W_prev, n_C_prev). You can read the full documentation &lt;a href=&quot;https://www.tensorflow.org/api_docs/python/tf/nn/conv2d&quot;&gt;here&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;tf.nn.max_pool(A, ksize = [1,f,f,1], strides = [1,s,s,1], padding = &#39;SAME&#39;):&lt;/strong&gt; given an input A, this function uses a window of size (f, f) and strides of size (s, s) to carry out max pooling over each window. You can read the full documentation &lt;a href=&quot;https://www.tensorflow.org/api_docs/python/tf/nn/max_pool&quot;&gt;here&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;tf.nn.relu(Z1):&lt;/strong&gt; computes the elementwise ReLU of Z1 (which can be any shape). You can read the full documentation &lt;a href=&quot;https://www.tensorflow.org/api_docs/python/tf/nn/relu&quot;&gt;here.&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;tf.contrib.layers.flatten(P)&lt;/strong&gt;: given an input P, this function flattens each example into a 1D vector it while maintaining the batch-size. It returns a flattened tensor with shape [batch_size, k]. You can read the full documentation &lt;a href=&quot;https://www.tensorflow.org/api_docs/python/tf/contrib/layers/flatten&quot;&gt;here.&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;tf.contrib.layers.fully_connected(F, num_outputs):&lt;/strong&gt; given a the flattened input F, it returns the output computed using a fully connected layer. You can read the full documentation &lt;a href=&quot;https://www.tensorflow.org/api_docs/python/tf/contrib/layers/fully_connected&quot;&gt;here.&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;In the last function above (&lt;code&gt;tf.contrib.layers.fully_connected&lt;/code&gt;), the fully connected layer automatically initializes weights in the graph and keeps on training them as you train the model. Hence, you did not need to initialize those weights when initializing the parameters. &lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Exercise&lt;/strong&gt;: &lt;/p&gt;
&lt;p&gt;Implement the &lt;code&gt;forward_propagation&lt;/code&gt; function below to build the following model: &lt;code&gt;CONV2D -&amp;gt; RELU -&amp;gt; MAXPOOL -&amp;gt; CONV2D -&amp;gt; RELU -&amp;gt; MAXPOOL -&amp;gt; FLATTEN -&amp;gt; FULLYCONNECTED&lt;/code&gt;. You should use the functions above. &lt;/p&gt;
&lt;p&gt;In detail, we will use the following parameters for all the steps:
     - Conv2D: stride 1, padding is &quot;SAME&quot;
     - ReLU
     - Max pool: Use an 8 by 8 filter size and an 8 by 8 stride, padding is &quot;SAME&quot;
     - Conv2D: stride 1, padding is &quot;SAME&quot;
     - ReLU
     - Max pool: Use a 4 by 4 filter size and a 4 by 4 stride, padding is &quot;SAME&quot;
     - Flatten the previous output.
     - FULLYCONNECTED (FC) layer: Apply a fully connected layer without an non-linear activation function. Do not call the softmax here. This will result in 6 neurons in the output layer, which then get passed later to a softmax. In TensorFlow, the softmax and cost function are lumped together into a single function, which you&#39;ll call in a different function when computing the cost. &lt;/p&gt;
&lt;div class=&quot;codehilite&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;c1&quot;&gt;# GRADED FUNCTION: forward_propagation&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;forward_propagation&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;parameters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;sd&quot;&gt;&amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    Implements the forward propagation for the model:&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    CONV2D -&amp;gt; RELU -&amp;gt; MAXPOOL -&amp;gt; CONV2D -&amp;gt; RELU -&amp;gt; MAXPOOL -&amp;gt; FLATTEN -&amp;gt; FULLYCONNECTED&lt;/span&gt;

&lt;span class=&quot;sd&quot;&gt;    Arguments:&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    X -- input dataset placeholder, of shape (input size, number of examples)&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    parameters -- python dictionary containing your parameters &amp;quot;W1&amp;quot;, &amp;quot;W2&amp;quot;&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;                  the shapes are given in initialize_parameters&lt;/span&gt;

&lt;span class=&quot;sd&quot;&gt;    Returns:&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    Z3 -- the output of the last LINEAR unit&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    &amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;

    &lt;span class=&quot;c1&quot;&gt;# Retrieve the parameters from the dictionary &amp;quot;parameters&amp;quot; &lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;W1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;parameters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;W1&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;W2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;parameters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;W2&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;

    &lt;span class=&quot;c1&quot;&gt;### START CODE HERE ###&lt;/span&gt;
    &lt;span class=&quot;c1&quot;&gt;# CONV2D: stride of 1, padding &amp;#39;SAME&amp;#39;&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;Z1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;conv2d&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;W1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;strides&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;padding&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&amp;#39;SAME&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;c1&quot;&gt;# RELU&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;A1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;relu&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Z1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;c1&quot;&gt;# MAXPOOL: window 8x8, sride 8, padding &amp;#39;SAME&amp;#39;&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;P1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;max_pool&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;A1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ksize&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;8&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;8&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;strides&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;8&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;8&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;padding&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&amp;#39;SAME&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;c1&quot;&gt;# CONV2D: filters W2, stride 1, padding &amp;#39;SAME&amp;#39;&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;Z2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;conv2d&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;P1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;W2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;strides&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;padding&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;SAME&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;c1&quot;&gt;# RELU&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;A2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;relu&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Z2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;c1&quot;&gt;# MAXPOOL: window 4x4, stride 4, padding &amp;#39;SAME&amp;#39;&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;P2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;max_pool&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;A2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ksize&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;strides&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;padding&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;SAME&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;c1&quot;&gt;# FLATTEN&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;P2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;contrib&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;layers&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;flatten&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;P2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;c1&quot;&gt;# FULLY-CONNECTED without non-linear activation function (not not call softmax).&lt;/span&gt;
    &lt;span class=&quot;c1&quot;&gt;# 6 neurons in output layer. Hint: one of the arguments should be &amp;quot;activation_fn=None&amp;quot; &lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;Z3&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;contrib&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;layers&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fully_connected&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;P2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;num_outputs&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;6&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;activation_fn&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;None&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;c1&quot;&gt;### END CODE HERE ###&lt;/span&gt;

    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Z3&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div class=&quot;codehilite&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;reset_default_graph&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;with&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Session&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sess&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;random&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;seed&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Y&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;create_placeholders&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;64&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;64&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;6&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;parameters&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;initialize_parameters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;Z3&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;forward_propagation&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;parameters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;init&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;global_variables_initializer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;sess&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;run&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;init&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;a&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sess&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;run&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Z3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;random&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;randn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;64&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;64&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;random&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;randn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;6&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)})&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;Z3 = &amp;quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div class=&quot;codehilite&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;Z3 = [[-0.44670227 -1.57208765 -1.53049231 -2.31013036 -1.29104376  0.46852064]
 [-0.17601591 -1.57972014 -1.4737016  -2.61672091 -1.00810647  0.5747785 ]]
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;strong&gt;Expected Output&lt;/strong&gt;:&lt;/p&gt;
&lt;table&gt; 
    &lt;td&gt; 
    Z3 =
    &lt;/td&gt;
    &lt;td&gt;
    [[-0.44670227 -1.57208765 -1.53049231 -2.31013036 -1.29104376  0.46852064] &lt;br&gt;
 [-0.17601591 -1.57972014 -1.4737016  -2.61672091 -1.00810647  0.5747785 ]]
    &lt;/td&gt;
&lt;/table&gt;

&lt;h3 id=&quot;13-compute-cost&quot;&gt;1.3 - Compute cost&lt;/h3&gt;
&lt;p&gt;Implement the compute cost function below. You might find these two functions helpful: &lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;tf.nn.softmax_cross_entropy_with_logits(logits = Z3, labels = Y):&lt;/strong&gt; computes the softmax entropy loss. This function both computes the softmax activation function as well as the resulting loss. You can check the full documentation  &lt;a href=&quot;https://www.tensorflow.org/api_docs/python/tf/nn/softmax_cross_entropy_with_logits&quot;&gt;here.&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;tf.reduce_mean:&lt;/strong&gt; computes the mean of elements across dimensions of a tensor. Use this to sum the losses over all the examples to get the overall cost. You can check the full documentation &lt;a href=&quot;https://www.tensorflow.org/api_docs/python/tf/reduce_mean&quot;&gt;here.&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt; Exercise&lt;/strong&gt;: Compute the cost below using the function above.&lt;/p&gt;
&lt;div class=&quot;codehilite&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;c1&quot;&gt;# GRADED FUNCTION: compute_cost &lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;compute_cost&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Z3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;sd&quot;&gt;&amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    Computes the cost&lt;/span&gt;

&lt;span class=&quot;sd&quot;&gt;    Arguments:&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    Z3 -- output of forward propagation (output of the last LINEAR unit), of shape (6, number of examples)&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    Y -- &amp;quot;true&amp;quot; labels vector placeholder, same shape as Z3&lt;/span&gt;

&lt;span class=&quot;sd&quot;&gt;    Returns:&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    cost - Tensor of the cost function&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    &amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;

    &lt;span class=&quot;c1&quot;&gt;### START CODE HERE ### (1 line of code)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;cost&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;reduce_mean&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;softmax_cross_entropy_with_logits&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;logits&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Z3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;labels&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
    &lt;span class=&quot;c1&quot;&gt;### END CODE HERE ###&lt;/span&gt;

    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cost&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div class=&quot;codehilite&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;reset_default_graph&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;with&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Session&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sess&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;random&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;seed&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Y&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;create_placeholders&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;64&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;64&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;6&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;parameters&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;initialize_parameters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;Z3&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;forward_propagation&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;parameters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;cost&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;compute_cost&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Z3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;init&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;global_variables_initializer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;sess&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;run&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;init&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;a&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sess&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;run&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cost&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;random&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;randn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;64&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;64&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;random&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;randn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;6&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)})&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;cost = &amp;quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div class=&quot;codehilite&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;cost = 2.91034
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;strong&gt;Expected Output&lt;/strong&gt;: &lt;/p&gt;
&lt;table&gt;
    &lt;td&gt; 
    cost =
    &lt;/td&gt;

    &lt;td&gt; 
    2.91034
    &lt;/td&gt; 
&lt;/table&gt;

&lt;h2 id=&quot;14-model&quot;&gt;1.4 Model&lt;/h2&gt;
&lt;p&gt;Finally you will merge the helper functions you implemented above to build a model. You will train it on the SIGNS dataset. &lt;/p&gt;
&lt;p&gt;You have implemented &lt;code&gt;random_mini_batches()&lt;/code&gt; in the Optimization programming assignment of course 2. Remember that this function returns a list of mini-batches. &lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Exercise&lt;/strong&gt;: Complete the function below. &lt;/p&gt;
&lt;p&gt;The model below should:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;create placeholders&lt;/li&gt;
&lt;li&gt;initialize parameters&lt;/li&gt;
&lt;li&gt;forward propagate&lt;/li&gt;
&lt;li&gt;compute the cost&lt;/li&gt;
&lt;li&gt;create an optimizer&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Finally you will create a session and run a for loop  for num_epochs, get the mini-batches, and then for each mini-batch you will optimize the function. &lt;a href=&quot;https://www.tensorflow.org/api_docs/python/tf/global_variables_initializer&quot;&gt;Hint for initializing the variables&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;codehilite&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;c1&quot;&gt;# GRADED FUNCTION: model&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X_train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Y_train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X_test&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Y_test&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;learning_rate&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.009&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
          &lt;span class=&quot;n&quot;&gt;num_epochs&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;100&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;minibatch_size&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;64&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;print_cost&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;sd&quot;&gt;&amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    Implements a three-layer ConvNet in Tensorflow:&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    CONV2D -&amp;gt; RELU -&amp;gt; MAXPOOL -&amp;gt; CONV2D -&amp;gt; RELU -&amp;gt; MAXPOOL -&amp;gt; FLATTEN -&amp;gt; FULLYCONNECTED&lt;/span&gt;

&lt;span class=&quot;sd&quot;&gt;    Arguments:&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    X_train -- training set, of shape (None, 64, 64, 3)&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    Y_train -- test set, of shape (None, n_y = 6)&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    X_test -- training set, of shape (None, 64, 64, 3)&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    Y_test -- test set, of shape (None, n_y = 6)&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    learning_rate -- learning rate of the optimization&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    num_epochs -- number of epochs of the optimization loop&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    minibatch_size -- size of a minibatch&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    print_cost -- True to print the cost every 100 epochs&lt;/span&gt;

&lt;span class=&quot;sd&quot;&gt;    Returns:&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    train_accuracy -- real number, accuracy on the train set (X_train)&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    test_accuracy -- real number, testing accuracy on the test set (X_test)&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    parameters -- parameters learnt by the model. They can then be used to predict.&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    &amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;

    &lt;span class=&quot;n&quot;&gt;ops&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;reset_default_graph&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;                         &lt;span class=&quot;c1&quot;&gt;# to be able to rerun the model without overwriting tf variables&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;set_random_seed&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;                             &lt;span class=&quot;c1&quot;&gt;# to keep results consistent (tensorflow seed)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;seed&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;                                          &lt;span class=&quot;c1&quot;&gt;# to keep results consistent (numpy seed)&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;m&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n_H0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n_W0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n_C0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X_train&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;             
    &lt;span class=&quot;n&quot;&gt;n_y&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Y_train&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;                            
    &lt;span class=&quot;n&quot;&gt;costs&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[]&lt;/span&gt;                                        &lt;span class=&quot;c1&quot;&gt;# To keep track of the cost&lt;/span&gt;

    &lt;span class=&quot;c1&quot;&gt;# Create Placeholders of the correct shape&lt;/span&gt;
    &lt;span class=&quot;c1&quot;&gt;### START CODE HERE ### (1 line)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Y&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;create_placeholders&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n_H0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n_W0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n_C0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n_y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;c1&quot;&gt;### END CODE HERE ###&lt;/span&gt;

    &lt;span class=&quot;c1&quot;&gt;# Initialize parameters&lt;/span&gt;
    &lt;span class=&quot;c1&quot;&gt;### START CODE HERE ### (1 line)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;parameters&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;initialize_parameters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
    &lt;span class=&quot;c1&quot;&gt;### END CODE HERE ###&lt;/span&gt;

    &lt;span class=&quot;c1&quot;&gt;# Forward propagation: Build the forward propagation in the tensorflow graph&lt;/span&gt;
    &lt;span class=&quot;c1&quot;&gt;### START CODE HERE ### (1 line)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;Z3&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;forward_propagation&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;parameters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;c1&quot;&gt;### END CODE HERE ###&lt;/span&gt;

    &lt;span class=&quot;c1&quot;&gt;# Cost function: Add cost function to tensorflow graph&lt;/span&gt;
    &lt;span class=&quot;c1&quot;&gt;### START CODE HERE ### (1 line)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;cost&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;compute_cost&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Z3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;c1&quot;&gt;### END CODE HERE ###&lt;/span&gt;

    &lt;span class=&quot;c1&quot;&gt;# Backpropagation: Define the tensorflow optimizer. Use an AdamOptimizer that minimizes the cost.&lt;/span&gt;
    &lt;span class=&quot;c1&quot;&gt;### START CODE HERE ### (1 line)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;optimizer&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;train&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;AdamOptimizer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;learning_rate&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;minimize&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cost&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;c1&quot;&gt;### END CODE HERE ###&lt;/span&gt;

    &lt;span class=&quot;c1&quot;&gt;# Initialize all the variables globally&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;init&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;global_variables_initializer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;

    &lt;span class=&quot;c1&quot;&gt;# Start the session to compute the tensorflow graph&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;with&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Session&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sess&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;

        &lt;span class=&quot;c1&quot;&gt;# Run the initialization&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;sess&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;run&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;init&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

        &lt;span class=&quot;c1&quot;&gt;# Do the training loop&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;epoch&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;num_epochs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;

            &lt;span class=&quot;n&quot;&gt;minibatch_cost&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;num_minibatches&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;int&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;m&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;minibatch_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;# number of minibatches of size minibatch_size in the train set&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;seed&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;seed&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;minibatches&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;random_mini_batches&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X_train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Y_train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;minibatch_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;seed&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

            &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;minibatch&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;minibatches&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;

                &lt;span class=&quot;c1&quot;&gt;# Select a minibatch&lt;/span&gt;
                &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;minibatch_X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;minibatch_Y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;minibatch&lt;/span&gt;
                &lt;span class=&quot;c1&quot;&gt;# IMPORTANT: The line that runs the graph on a minibatch.&lt;/span&gt;
                &lt;span class=&quot;c1&quot;&gt;# Run the session to execute the optimizer and the cost, the feedict should contain a minibatch for (X,Y).&lt;/span&gt;
                &lt;span class=&quot;c1&quot;&gt;### START CODE HERE ### (1 line)&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;_&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;temp_cost&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sess&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;run&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;optimizer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cost&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;feed_dict&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;minibatch_X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                                                       &lt;span class=&quot;n&quot;&gt;Y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;minibatch_Y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;})&lt;/span&gt;
                &lt;span class=&quot;c1&quot;&gt;### END CODE HERE ###&lt;/span&gt;

                &lt;span class=&quot;n&quot;&gt;minibatch_cost&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;temp_cost&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;num_minibatches&lt;/span&gt;


            &lt;span class=&quot;c1&quot;&gt;# Print the cost every epoch&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;print_cost&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;and&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;epoch&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;%&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
                &lt;span class=&quot;k&quot;&gt;print&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;Cost after epoch &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;%i&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;: &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;%f&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;%&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;epoch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;minibatch_cost&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;print_cost&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;and&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;epoch&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;%&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;costs&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;append&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;minibatch_cost&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;


        &lt;span class=&quot;c1&quot;&gt;# plot the cost&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;plot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;squeeze&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;costs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ylabel&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;cost&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;xlabel&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;iterations (per tens)&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;title&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;Learning rate =&amp;quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;learning_rate&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;show&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;

        &lt;span class=&quot;c1&quot;&gt;# Calculate the correct predictions&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;predict_op&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;argmax&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Z3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;correct_prediction&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;equal&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;predict_op&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;argmax&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;

        &lt;span class=&quot;c1&quot;&gt;# Calculate accuracy on the test set&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;accuracy&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;reduce_mean&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cast&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;correct_prediction&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&amp;quot;float&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;accuracy&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;train_accuracy&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;accuracy&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;eval&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;({&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X_train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Y_train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;})&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;test_accuracy&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;accuracy&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;eval&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;({&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X_test&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Y_test&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;})&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;Train Accuracy:&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;train_accuracy&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;Test Accuracy:&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;test_accuracy&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;train_accuracy&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;test_accuracy&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;parameters&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Run the following cell to train your model for 100 epochs. Check if your cost after epoch 0 and 5 matches our output. If not, stop the cell and go back to your code!&lt;/p&gt;
&lt;div class=&quot;codehilite&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;_&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;_&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;parameters&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X_train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Y_train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X_test&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Y_test&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div class=&quot;codehilite&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;Cost after epoch 0: 1.917929
Cost after epoch 5: 1.506757
Cost after epoch 10: 0.955359
Cost after epoch 15: 0.845802
Cost after epoch 20: 0.701174
Cost after epoch 25: 0.571977
Cost after epoch 30: 0.518435
Cost after epoch 35: 0.495806
Cost after epoch 40: 0.429827
Cost after epoch 45: 0.407291
Cost after epoch 50: 0.366394
Cost after epoch 55: 0.376922
Cost after epoch 60: 0.299491
Cost after epoch 65: 0.338870
Cost after epoch 70: 0.316400
Cost after epoch 75: 0.310413
Cost after epoch 80: 0.249549
Cost after epoch 85: 0.243457
Cost after epoch 90: 0.200031
Cost after epoch 95: 0.175452
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;img alt=&quot;png&quot; src=&quot;https://raw.githubusercontent.com/karenyyy/Coursera_and_Udemy/master/deeplearningai_coursera/Convolutional%20Neural%20Networks/images/application/output_28_1.png&quot; /&gt;&lt;/p&gt;
&lt;div class=&quot;codehilite&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;Tensor(&amp;quot;Mean_1:0&amp;quot;, shape=(), dtype=float32)
Train Accuracy: 0.940741
Test Accuracy: 0.783333
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;strong&gt;Expected output&lt;/strong&gt;: although it may not match perfectly, your expected output should be close to ours and your cost value should decrease.&lt;/p&gt;
&lt;table&gt; 
&lt;tr&gt;
    &lt;td&gt; 
    **Cost after epoch 0 =**
    &lt;/td&gt;

    &lt;td&gt; 
      1.917929
    &lt;/td&gt; 
&lt;/tr&gt;
&lt;tr&gt;
    &lt;td&gt; 
    **Cost after epoch 5 =**
    &lt;/td&gt;

    &lt;td&gt; 
      1.506757
    &lt;/td&gt; 
&lt;/tr&gt;
&lt;tr&gt;
    &lt;td&gt; 
    **Train Accuracy   =**
    &lt;/td&gt;

    &lt;td&gt; 
      0.940741
    &lt;/td&gt; 
&lt;/tr&gt; 

&lt;tr&gt;
    &lt;td&gt; 
    **Test Accuracy   =**
    &lt;/td&gt;

    &lt;td&gt; 
      0.783333
    &lt;/td&gt; 
&lt;/tr&gt; 
&lt;/table&gt;deeplearning.ai - CNN - Week 1 Notes
## Intro

![](https://raw.githubusercontent.com/karenyyy/Coursera_and_Udemy/master/deeplearningai_coursera/Convolutional%20Neural%20Networks/images/1.png)

If working with very large images, like the images on lower right, shape: 1000x1000x3

![](https://raw.githubusercontent.com/karenyyy/Coursera_and_Udemy/master/deeplearningai_coursera/Convolutional%20Neural%20Networks/images/2.png)

That means X here will be three million dimensional, so in the first hidden layer maybe you have just a 1000 hidden units then the total number of weights that is the matrix W1, which will be (1000, 3m) dimensional matrix. Training a NN with 3m parameters is just infeasible.

__Thus convolution is needed.__

## Edge Detection Example

![](https://raw.githubusercontent.com/karenyyy/Coursera_and_Udemy/master/deeplearningai_coursera/Convolutional%20Neural%20Networks/images/3.png)

&gt; How does Convolution work?
![](https://raw.githubusercontent.com/karenyyy/Coursera_and_Udemy/master/deeplearningai_coursera/Convolutional%20Neural%20Networks/images/4.png)

### Vertical Edge Detection

![](https://raw.githubusercontent.com/karenyyy/Coursera_and_Udemy/master/deeplearningai_coursera/Convolutional%20Neural%20Networks/images/5.png)

&gt; Why does the vertical edge here appears to be extra thick?

Because the image we are using is too small. If we are using a 1000x1000 image rather than a 6x6 image like we use in the case, we will find that this actually does a pretty good job.

![](https://raw.githubusercontent.com/karenyyy/Coursera_and_Udemy/master/deeplearningai_coursera/Convolutional%20Neural%20Networks/images/7.png)




## Padding

To avoid image shrinking if NN is very deep.

![](https://raw.githubusercontent.com/karenyyy/Coursera_and_Udemy/master/deeplearningai_coursera/Convolutional%20Neural%20Networks/images/8.png)

- __Valid__ and __Same__ convolutions
    - Valid: __No padding__
        - nxn * fxf -&gt; n-(f-1) =  (n -f +1) x (n -f +1)
    - Same: __Pad__ so that output size is the same as the input size
        - (n+2p - (f-1)) x (n+2p - (f-1)) -&gt; (n+2p -f+1) x (n+2p -f+1)
        - n+2p - (f-1) = n , so p=(f-1)/2, thus f is usually odd


## Strided Convolutions

![](https://raw.githubusercontent.com/karenyyy/Coursera_and_Udemy/master/deeplearningai_coursera/%20Convolutional%20Neural%20Networks/images/9.png)

![](https://raw.githubusercontent.com/karenyyy/Coursera_and_Udemy/master/deeplearningai_coursera/%20Convolutional%20Neural%20Networks/images/10.png)




## Convolution Over volumes


__Note: the depth of filters should equal to the depth of the input__

![](https://raw.githubusercontent.com/karenyyy/Coursera_and_Udemy/master/deeplearningai_coursera/Convolutional%20Neural%20Networks/images/11.png)

- If your task is to detect a vertical edge in only one of the color channel, then just assign the filter to that channel, and set the filters of the other channels to be zeros.

![](https://raw.githubusercontent.com/karenyyy/Coursera_and_Udemy/master/deeplearningai_coursera/Convolutional%20Neural%20Networks/images/12.png)

- If multiple filters are used, then:
    - Input : 
        - First layer: height x width x __color channel__
        - Later layer: height x width x __number of filters__ 
    - Filter: 
        - First layer: filter_height x filter_width x __color channel__
        - Later layer: filter_height x filter_width x __number of filters__
    - Output: height x width x __number of filters__
 

## One layer of CNN

![](https://raw.githubusercontent.com/karenyyy/Coursera_and_Udemy/master/deeplearningai_coursera/%20Convolutional%20Neural%20Networks/images/14.png)
![](https://raw.githubusercontent.com/karenyyy/Coursera_and_Udemy/master/deeplearningai_coursera/%20Convolutional%20Neural%20Networks/images/15.png)


$$\text{ height/width of the next hidden layer} = \frac{n+2p-f}{s} + 1$$


![](https://raw.githubusercontent.com/karenyyy/Coursera_and_Udemy/master/deeplearningai_coursera/%20Convolutional%20Neural%20Networks/images/16.png)




### CNN Example - LeNet 

![](https://raw.githubusercontent.com/karenyyy/Coursera_and_Udemy/master/deeplearningai_coursera/%20Convolutional%20Neural%20Networks/images/18.png)



## Why convolutions? 





- Too many parameters


![](https://raw.githubusercontent.com/karenyyy/Coursera_and_Udemy/master/deeplearningai_coursera/Convolutional%20Neural%20Networks/images/19.png)



-  Parameter sharing

  -  A feature detector (such as a vertical edge detector), that&#39;s useful in one part of the image is probably useful in another part of the image.

- Sparsity of connections
  
  - In each layer, each output value depends only on a small number of inputsdeeplearning.ai - Sequence Model - Week 2 Assignment 2
&lt;h1 id=&quot;emojify&quot;&gt;Emojify!&lt;/h1&gt;
&lt;p&gt;Welcome to the second assignment of Week 2. You are going to use word vector representations to build an Emojifier. &lt;/p&gt;
&lt;p&gt;Have you ever wanted to make your text messages more expressive? Your emojifier app will help you do that. So rather than writing &quot;Congratulations on the promotion! Lets get coffee and talk. Love you!&quot; the emojifier can automatically turn this into &quot;Congratulations on the promotion! 👍 Lets get coffee and talk. ☕️ Love you! ❤️&quot;&lt;/p&gt;
&lt;p&gt;You will implement a model which inputs a sentence (such as &quot;Let&#39;s go see the baseball game tonight!&quot;) and finds the most appropriate emoji to be used with this sentence (⚾️). In many emoji interfaces, you need to remember that ❤️ is the &quot;heart&quot; symbol rather than the &quot;love&quot; symbol. But using word vectors, you&#39;ll see that even if your training set explicitly relates only a few words to a particular emoji, your algorithm will be able to generalize and associate words in the test set to the same emoji even if those words don&#39;t even appear in the training set. This allows you to build an accurate classifier mapping from sentences to emojis, even using a small training set. &lt;/p&gt;
&lt;p&gt;In this exercise, you&#39;ll start with a baseline model (Emojifier-V1) using word embeddings, then build a more sophisticated model (Emojifier-V2) that further incorporates an LSTM. &lt;/p&gt;
&lt;p&gt;Lets get started! Run the following cell to load the package you are going to use. &lt;/p&gt;
&lt;div class=&quot;codehilite&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;numpy&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;np&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;emo_utils&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;emoji&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;matplotlib.pyplot&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;plt&lt;/span&gt;

&lt;span class=&quot;o&quot;&gt;%&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;matplotlib&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;inline&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;h2 id=&quot;1-baseline-model-emojifier-v1&quot;&gt;1 - Baseline model: Emojifier-V1&lt;/h2&gt;
&lt;h3 id=&quot;11-dataset-emojiset&quot;&gt;1.1 - Dataset EMOJISET&lt;/h3&gt;
&lt;p&gt;Let&#39;s start by building a simple baseline classifier. &lt;/p&gt;
&lt;p&gt;You have a tiny dataset (X, Y) where:
- X contains 127 sentences (strings)
- Y contains a integer label between 0 and 4 corresponding to an emoji for each sentence&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/karenyyy/Coursera_and_Udemy/master/deeplearningai_coursera/Sequence%20Models/images/data_set.png&quot; style=&quot;width:700px;height:300px;&quot;&gt;
&lt;caption&gt;&lt;center&gt; &lt;strong&gt;Figure 1&lt;/strong&gt;: EMOJISET - a classification problem with 5 classes. A few examples of sentences are given here. &lt;/center&gt;&lt;/caption&gt;&lt;/p&gt;
&lt;p&gt;Let&#39;s load the dataset using the code below. We split the dataset between training (127 examples) and testing (56 examples).&lt;/p&gt;
&lt;div class=&quot;codehilite&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X_train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Y_train&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;read_csv&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;data/train_emoji.csv&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;X_test&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Y_test&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;read_csv&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;data/tesss.csv&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div class=&quot;codehilite&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;maxLen&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;max&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X_train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;key&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;split&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;())&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Run the following cell to print sentences from X_train and corresponding labels from Y_train. Change &lt;code&gt;index&lt;/code&gt; to see different examples. Because of the font the iPython notebook uses, the heart emoji may be colored black rather than red.&lt;/p&gt;
&lt;div class=&quot;codehilite&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;index&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X_train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;index&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;label_to_emoji&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Y_train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;index&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]))&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div class=&quot;codehilite&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;I am proud of your achievements 😄
&lt;/pre&gt;&lt;/div&gt;


&lt;h3 id=&quot;12-overview-of-the-emojifier-v1&quot;&gt;1.2 - Overview of the Emojifier-V1&lt;/h3&gt;
&lt;p&gt;In this part, you are going to implement a baseline model called &quot;Emojifier-v1&quot;.  &lt;/p&gt;
&lt;p&gt;&lt;center&gt;
&lt;img src=&quot;https://raw.githubusercontent.com/karenyyy/Coursera_and_Udemy/master/deeplearningai_coursera/Sequence%20Models/images/image_1.png&quot; style=&quot;width:900px;height:300px;&quot;&gt;
&lt;caption&gt;&lt;center&gt; &lt;strong&gt;Figure 2&lt;/strong&gt;: Baseline model (Emojifier-V1).&lt;/center&gt;&lt;/caption&gt;
&lt;/center&gt;&lt;/p&gt;
&lt;p&gt;The input of the model is a string corresponding to a sentence (e.g. &quot;I love you). In the code, the output will be a probability vector of shape (1,5), that you then pass in an argmax layer to extract the index of the most likely emoji output.&lt;/p&gt;
&lt;p&gt;To get our labels into a format suitable for training a softmax classifier, lets convert $Y$ from its current shape  current shape $(m, 1)$ into a &quot;one-hot representation&quot; $(m, 5)$, where each row is a one-hot vector giving the label of one example, You can do so using this next code snipper. Here, &lt;code&gt;Y_oh&lt;/code&gt; stands for &quot;Y-one-hot&quot; in the variable names &lt;code&gt;Y_oh_train&lt;/code&gt; and &lt;code&gt;Y_oh_test&lt;/code&gt;: &lt;/p&gt;
&lt;div class=&quot;codehilite&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Y_oh_train&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;convert_to_one_hot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Y_train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;C&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;Y_oh_test&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;convert_to_one_hot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Y_test&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;C&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Let&#39;s see what &lt;code&gt;convert_to_one_hot()&lt;/code&gt; did. Feel free to change &lt;code&gt;index&lt;/code&gt; to print out different values. &lt;/p&gt;
&lt;div class=&quot;codehilite&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;index&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;50&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Y_train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;index&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&amp;quot;is converted into one hot&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Y_oh_train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;index&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div class=&quot;codehilite&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;0 is converted into one hot [ 1.  0.  0.  0.  0.]
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;All the data is now ready to be fed into the Emojify-V1 model. Let&#39;s implement the model!&lt;/p&gt;
&lt;h3 id=&quot;13-implementing-emojifier-v1&quot;&gt;1.3 - Implementing Emojifier-V1&lt;/h3&gt;
&lt;p&gt;As shown in Figure (2), the first step is to convert an input sentence into the word vector representation, which then get averaged together. Similar to the previous exercise, we will use pretrained 50-dimensional GloVe embeddings. Run the following cell to load the &lt;code&gt;word_to_vec_map&lt;/code&gt;, which contains all the vector representations.&lt;/p&gt;
&lt;div class=&quot;codehilite&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;word_to_index&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;index_to_word&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;word_to_vec_map&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;read_glove_vecs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;data/glove.6B.50d.txt&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;You&#39;ve loaded:
- &lt;code&gt;word_to_index&lt;/code&gt;: dictionary mapping from words to their indices in the vocabulary (400,001 words, with the valid indices ranging from 0 to 400,000)
- &lt;code&gt;index_to_word&lt;/code&gt;: dictionary mapping from indices to their corresponding words in the vocabulary
- &lt;code&gt;word_to_vec_map&lt;/code&gt;: dictionary mapping words to their GloVe vector representation.&lt;/p&gt;
&lt;p&gt;Run the following cell to check if it works.&lt;/p&gt;
&lt;div class=&quot;codehilite&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;word&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&amp;quot;cucumber&amp;quot;&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;index&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;289846&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;the index of&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;word&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&amp;quot;in the vocabulary is&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;word_to_index&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;word&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;the&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;index&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&amp;quot;th word in the vocabulary is&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;index_to_word&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;index&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div class=&quot;codehilite&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;the index of cucumber in the vocabulary is 113317
the 289846th word in the vocabulary is potatos
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;strong&gt;Exercise&lt;/strong&gt;: Implement &lt;code&gt;sentence_to_avg()&lt;/code&gt;. You will need to carry out two steps:
1. Convert every sentence to lower-case, then split the sentence into a list of words. &lt;code&gt;X.lower()&lt;/code&gt; and &lt;code&gt;X.split()&lt;/code&gt; might be useful. 
2. For each word in the sentence, access its GloVe representation. Then, average all these values.&lt;/p&gt;
&lt;div class=&quot;codehilite&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;c1&quot;&gt;# GRADED FUNCTION: sentence_to_avg&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;sentence_to_avg&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sentence&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;word_to_vec_map&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;sd&quot;&gt;&amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    Converts a sentence (string) into a list of words (strings). Extracts the GloVe representation of each word&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    and averages its value into a single vector encoding the meaning of the sentence.&lt;/span&gt;

&lt;span class=&quot;sd&quot;&gt;    Arguments:&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    sentence -- string, one training example from X&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    word_to_vec_map -- dictionary mapping every word in a vocabulary into its 50-dimensional vector representation&lt;/span&gt;

&lt;span class=&quot;sd&quot;&gt;    Returns:&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    avg -- average vector encoding information about the sentence, numpy-array of shape (50,)&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    &amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;


    &lt;span class=&quot;c1&quot;&gt;# Step 1: Split sentence into list of lower case words (≈ 1 line)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;words&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;lower&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sentence&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;split&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()]&lt;/span&gt;

    &lt;span class=&quot;c1&quot;&gt;# Initialize the average word vector, should have the same shape as your word vectors.&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;avg&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;zeros&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;((&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;50&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,))&lt;/span&gt;

    &lt;span class=&quot;c1&quot;&gt;# Step 2: average the word vectors. You can loop over the words in the list &amp;quot;words&amp;quot;.&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;w&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;words&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;avg&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;word_to_vec_map&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;w&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;avg&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;avg&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;words&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;



    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;avg&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div class=&quot;codehilite&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;avg&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sentence_to_avg&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;Morrocan couscous is my favorite dish&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;word_to_vec_map&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;avg = &amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;avg&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div class=&quot;codehilite&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;avg =  [-0.008005    0.56370833 -0.50427333  0.258865    0.55131103  0.03104983
 -0.21013718  0.16893933 -0.09590267  0.141784   -0.15708967  0.18525867
  0.6495785   0.38371117  0.21102167  0.11301667  0.02613967  0.26037767
  0.05820667 -0.01578167 -0.12078833 -0.02471267  0.4128455   0.5152061
  0.38756167 -0.898661   -0.535145    0.33501167  0.68806933 -0.2156265
  1.797155    0.10476933 -0.36775333  0.750785    0.10282583  0.348925
 -0.27262833  0.66768    -0.10706167 -0.283635    0.59580117  0.28747333
 -0.3366635   0.23393817  0.34349183  0.178405    0.1166155  -0.076433
  0.1445417   0.09808667]
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;strong&gt;Expected Output&lt;/strong&gt;:&lt;/p&gt;
&lt;table&gt;
    &lt;tr&gt;
        &lt;td&gt;
            **avg= **
        &lt;/td&gt;
        &lt;td&gt;
           [-0.008005    0.56370833 -0.50427333  0.258865    0.55131103  0.03104983
 -0.21013718  0.16893933 -0.09590267  0.141784   -0.15708967  0.18525867
  0.6495785   0.38371117  0.21102167  0.11301667  0.02613967  0.26037767
  0.05820667 -0.01578167 -0.12078833 -0.02471267  0.4128455   0.5152061
  0.38756167 -0.898661   -0.535145    0.33501167  0.68806933 -0.2156265
  1.797155    0.10476933 -0.36775333  0.750785    0.10282583  0.348925
 -0.27262833  0.66768    -0.10706167 -0.283635    0.59580117  0.28747333
 -0.3366635   0.23393817  0.34349183  0.178405    0.1166155  -0.076433
  0.1445417   0.09808667]
        &lt;/td&gt;
    &lt;/tr&gt;
&lt;/table&gt;

&lt;h4 id=&quot;model&quot;&gt;Model&lt;/h4&gt;
&lt;p&gt;You now have all the pieces to finish implementing the &lt;code&gt;model()&lt;/code&gt; function. After using &lt;code&gt;sentence_to_avg()&lt;/code&gt; you need to pass the average through forward propagation, compute the cost, and then backpropagate to update the softmax&#39;s parameters. &lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Exercise&lt;/strong&gt;: Implement the &lt;code&gt;model()&lt;/code&gt; function described in Figure (2). Assuming here that $Yoh$ (&quot;Y one hot&quot;) is the one-hot encoding of the output labels, the equations you need to implement in the forward pass and to compute the cross-entropy cost are:
$$ z^{(i)} = W . avg^{(i)} + b$$
$$ a^{(i)} = softmax(z^{(i)})$$
$$ \mathcal{L}^{(i)} = - \sum_{k = 0}^{n_y - 1} Yoh^{(i)}_k * log(a^{(i)}_k)$$&lt;/p&gt;
&lt;p&gt;It is possible to come up with a more efficient vectorized implementation. But since we are using a for-loop to convert the sentences one at a time into the avg^{(i)} representation anyway, let&#39;s not bother this time. &lt;/p&gt;
&lt;p&gt;We provided you a function &lt;code&gt;softmax()&lt;/code&gt;.&lt;/p&gt;
&lt;div class=&quot;codehilite&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;c1&quot;&gt;# GRADED FUNCTION: model&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;word_to_vec_map&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;learning_rate&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.01&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;num_iterations&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;400&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;sd&quot;&gt;&amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    Model to train word vector representations in numpy.&lt;/span&gt;

&lt;span class=&quot;sd&quot;&gt;    Arguments:&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    X -- input data, numpy array of sentences as strings, of shape (m, 1)&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    Y -- labels, numpy array of integers between 0 and 7, numpy-array of shape (m, 1)&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    word_to_vec_map -- dictionary mapping every word in a vocabulary into its 50-dimensional vector representation&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    learning_rate -- learning_rate for the stochastic gradient descent algorithm&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    num_iterations -- number of iterations&lt;/span&gt;

&lt;span class=&quot;sd&quot;&gt;    Returns:&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    pred -- vector of predictions, numpy-array of shape (m, 1)&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    W -- weight matrix of the softmax layer, of shape (n_y, n_h)&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    b -- bias of the softmax layer, of shape (n_y,)&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    &amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;

    &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;random&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;seed&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

    &lt;span class=&quot;c1&quot;&gt;# Define number of training examples&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;m&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Y&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;                          &lt;span class=&quot;c1&quot;&gt;# number of training examples&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;n_y&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;                                 &lt;span class=&quot;c1&quot;&gt;# number of classes  &lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;n_h&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;50&lt;/span&gt;                                &lt;span class=&quot;c1&quot;&gt;# dimensions of the GloVe vectors &lt;/span&gt;

    &lt;span class=&quot;c1&quot;&gt;# Initialize parameters using Xavier initialization&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;W&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;random&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;randn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n_y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n_h&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sqrt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n_h&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;b&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;zeros&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;((&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n_y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,))&lt;/span&gt;

    &lt;span class=&quot;c1&quot;&gt;# Convert Y to Y_onehot with n_y classes&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;Y_oh&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;convert_to_one_hot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;C&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n_y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; 

    &lt;span class=&quot;c1&quot;&gt;# Optimization loop&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;t&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;num_iterations&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;                       &lt;span class=&quot;c1&quot;&gt;# Loop over the number of iterations&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;m&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;                                &lt;span class=&quot;c1&quot;&gt;# Loop over the training examples&lt;/span&gt;


            &lt;span class=&quot;c1&quot;&gt;# Average the word vectors of the words from the i&amp;#39;th training example&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;avg&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sentence_to_avg&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;word_to_vec_map&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

            &lt;span class=&quot;c1&quot;&gt;# Forward propagate the avg through the softmax layer&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;z&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;W&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;avg&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;b&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;a&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;softmax&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;z&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

            &lt;span class=&quot;c1&quot;&gt;# Compute cost using the i&amp;#39;th training label&amp;#39;s one hot representation and &amp;quot;A&amp;quot; (the output of the softmax)&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;cost&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;multiply&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Y_oh&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;log&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)))&lt;/span&gt;


            &lt;span class=&quot;c1&quot;&gt;# Compute gradients &lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;dz&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;a&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Y_oh&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;dW&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dz&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;reshape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n_y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;avg&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;reshape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n_h&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;db&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dz&lt;/span&gt;

            &lt;span class=&quot;c1&quot;&gt;# Update parameters with Stochastic Gradient Descent&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;W&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;W&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;learning_rate&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dW&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;b&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;b&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;learning_rate&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;db&lt;/span&gt;

        &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;t&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;%&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;100&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;Epoch: &amp;quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&amp;quot; --- cost = &amp;quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cost&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;pred&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;predict&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;W&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;b&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;word_to_vec_map&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pred&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;W&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;b&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div class=&quot;codehilite&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X_train&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Y_train&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;eye&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Y_train&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;reshape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)]&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X_train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;type&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X_train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;Y&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;asarray&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;6&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;6&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;6&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;6&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;6&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Y&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;asarray&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;I am going to the bar tonight&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&amp;#39;I love you&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&amp;#39;miss you my dear&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
 &lt;span class=&quot;s1&quot;&gt;&amp;#39;Lets go party and drinks&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;Congrats on the new job&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;Congratulations&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
 &lt;span class=&quot;s1&quot;&gt;&amp;#39;I am so happy for you&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&amp;#39;Why are you feeling bad&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&amp;#39;What is wrong with you&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
 &lt;span class=&quot;s1&quot;&gt;&amp;#39;You totally deserve this prize&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&amp;#39;Let us go play football&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
 &lt;span class=&quot;s1&quot;&gt;&amp;#39;Are you down for football this afternoon&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&amp;#39;Work hard play harder&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
 &lt;span class=&quot;s1&quot;&gt;&amp;#39;It is suprising how people can be dumb sometimes&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
 &lt;span class=&quot;s1&quot;&gt;&amp;#39;I am very disappointed&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;It is the best day in my life&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
 &lt;span class=&quot;s1&quot;&gt;&amp;#39;I think I will end up alone&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;My life is so boring&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;Good job&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
 &lt;span class=&quot;s1&quot;&gt;&amp;#39;Great so awesome&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;eye&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Y_train&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;reshape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)]&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;type&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X_train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div class=&quot;codehilite&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;(132,)
(132,)
(132, 5)
never talk to me again
&amp;lt;class &amp;#39;numpy.ndarray&amp;#39;&amp;gt;
(20,)
(20,)
(132, 5)
&amp;lt;class &amp;#39;numpy.ndarray&amp;#39;&amp;gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Run the next cell to train your model and learn the softmax parameters (W,b). &lt;/p&gt;
&lt;div class=&quot;codehilite&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pred&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;W&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;b&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X_train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Y_train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;word_to_vec_map&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pred&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div class=&quot;codehilite&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Epoch&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;---&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cost&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;1.95204988128&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;Accuracy&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.348484848485&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;Epoch&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;100&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;---&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cost&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.0797181872601&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;Accuracy&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.931818181818&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;Epoch&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;200&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;---&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cost&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.0445636924368&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;Accuracy&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.954545454545&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;Epoch&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;300&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;---&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cost&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.0343226737879&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;Accuracy&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.969696969697&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;[[&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.]&lt;/span&gt;
 &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.]&lt;/span&gt;
 &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.]&lt;/span&gt;
 &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.]&lt;/span&gt;
 &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.]&lt;/span&gt;
 &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.]&lt;/span&gt;
 &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.]&lt;/span&gt;
 &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.]&lt;/span&gt;
 &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.]&lt;/span&gt;
 &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.]&lt;/span&gt;
 &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.]&lt;/span&gt;
 &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.]&lt;/span&gt;
 &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.]&lt;/span&gt;
 &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.]&lt;/span&gt;
 &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.]&lt;/span&gt;
 &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.]&lt;/span&gt;
 &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.]&lt;/span&gt;
 &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.]&lt;/span&gt;
 &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.]&lt;/span&gt;
 &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.]&lt;/span&gt;
 &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.]&lt;/span&gt;
 &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.]&lt;/span&gt;
 &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.]&lt;/span&gt;
 &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.]&lt;/span&gt;
 &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.]&lt;/span&gt;
 &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.]&lt;/span&gt;
 &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.]&lt;/span&gt;
 &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.]&lt;/span&gt;
 &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.]&lt;/span&gt;
 &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.]&lt;/span&gt;
 &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.]&lt;/span&gt;
 &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.]&lt;/span&gt;
 &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.]&lt;/span&gt;
 &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.]&lt;/span&gt;
 &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.]&lt;/span&gt;
 &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.]&lt;/span&gt;
 &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.]&lt;/span&gt;
 &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.]&lt;/span&gt;
 &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.]&lt;/span&gt;
 &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.]&lt;/span&gt;
 &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.]&lt;/span&gt;
 &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.]&lt;/span&gt;
 &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.]&lt;/span&gt;
 &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.]&lt;/span&gt;
 &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.]&lt;/span&gt;
 &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.]&lt;/span&gt;
 &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.]&lt;/span&gt;
 &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.]&lt;/span&gt;
 &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.]&lt;/span&gt;
 &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.]&lt;/span&gt;
 &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.]&lt;/span&gt;
 &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.]&lt;/span&gt;
 &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.]&lt;/span&gt;
 &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.]&lt;/span&gt;
 &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.]&lt;/span&gt;
 &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.]&lt;/span&gt;
 &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.]&lt;/span&gt;
 &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.]&lt;/span&gt;
 &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.]&lt;/span&gt;
 &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.]&lt;/span&gt;
 &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.]&lt;/span&gt;
 &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.]&lt;/span&gt;
 &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.]&lt;/span&gt;
 &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.]&lt;/span&gt;
 &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.]&lt;/span&gt;
 &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.]&lt;/span&gt;
 &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.]&lt;/span&gt;
 &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.]&lt;/span&gt;
 &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.]&lt;/span&gt;
 &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.]&lt;/span&gt;
 &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.]&lt;/span&gt;
 &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.]&lt;/span&gt;
 &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.]&lt;/span&gt;
 &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.]&lt;/span&gt;
 &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.]&lt;/span&gt;
 &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.]&lt;/span&gt;
 &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.]&lt;/span&gt;
 &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.]&lt;/span&gt;
 &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.]&lt;/span&gt;
 &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.]&lt;/span&gt;
 &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.]&lt;/span&gt;
 &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.]&lt;/span&gt;
 &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.]&lt;/span&gt;
 &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.]&lt;/span&gt;
 &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.]&lt;/span&gt;
 &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.]&lt;/span&gt;
 &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.]&lt;/span&gt;
 &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.]&lt;/span&gt;
 &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.]&lt;/span&gt;
 &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.]&lt;/span&gt;
 &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.]&lt;/span&gt;
 &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.]&lt;/span&gt;
 &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.]&lt;/span&gt;
 &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.]&lt;/span&gt;
 &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.]&lt;/span&gt;
 &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.]&lt;/span&gt;
 &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.]&lt;/span&gt;
 &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.]&lt;/span&gt;
 &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.]&lt;/span&gt;
 &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.]&lt;/span&gt;
 &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.]&lt;/span&gt;
 &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.]&lt;/span&gt;
 &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.]&lt;/span&gt;
 &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.]&lt;/span&gt;
 &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.]&lt;/span&gt;
 &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.]&lt;/span&gt;
 &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.]&lt;/span&gt;
 &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.]&lt;/span&gt;
 &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.]&lt;/span&gt;
 &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.]&lt;/span&gt;
 &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.]&lt;/span&gt;
 &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.]&lt;/span&gt;
 &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.]&lt;/span&gt;
 &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.]&lt;/span&gt;
 &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.]&lt;/span&gt;
 &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.]&lt;/span&gt;
 &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.]&lt;/span&gt;
 &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.]&lt;/span&gt;
 &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.]&lt;/span&gt;
 &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.]&lt;/span&gt;
 &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.]&lt;/span&gt;
 &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.]&lt;/span&gt;
 &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.]&lt;/span&gt;
 &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.]&lt;/span&gt;
 &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.]&lt;/span&gt;
 &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.]&lt;/span&gt;
 &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.]&lt;/span&gt;
 &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.]&lt;/span&gt;
 &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.]&lt;/span&gt;
 &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.]&lt;/span&gt;
 &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.]&lt;/span&gt;
 &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.]]&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;strong&gt;Expected Output&lt;/strong&gt; (on a subset of iterations):&lt;/p&gt;
&lt;table&gt;
    &lt;tr&gt;
        &lt;td&gt;
            **Epoch: 0**
        &lt;/td&gt;
        &lt;td&gt;
           cost = 1.95204988128
        &lt;/td&gt;
        &lt;td&gt;
           Accuracy: 0.348484848485
        &lt;/td&gt;
    &lt;/tr&gt;

&lt;tr&gt;
        &lt;td&gt;
            **Epoch: 100**
        &lt;/td&gt;
        &lt;td&gt;
           cost = 0.0797181872601
        &lt;/td&gt;
        &lt;td&gt;
           Accuracy: 0.931818181818
        &lt;/td&gt;
    &lt;/tr&gt;

&lt;tr&gt;
        &lt;td&gt;
            **Epoch: 200**
        &lt;/td&gt;
        &lt;td&gt;
           cost = 0.0445636924368
        &lt;/td&gt;
        &lt;td&gt;
           Accuracy: 0.954545454545
        &lt;/td&gt;
    &lt;/tr&gt;

    &lt;tr&gt;
        &lt;td&gt;
            **Epoch: 300**
        &lt;/td&gt;
        &lt;td&gt;
           cost = 0.0343226737879
        &lt;/td&gt;
        &lt;td&gt;
           Accuracy: 0.969696969697
        &lt;/td&gt;
    &lt;/tr&gt;
&lt;/table&gt;

&lt;p&gt;Great! Your model has pretty high accuracy on the training set. Lets now see how it does on the test set. &lt;/p&gt;
&lt;h3 id=&quot;14-examining-test-set-performance&quot;&gt;1.4 - Examining test set performance&lt;/h3&gt;
&lt;div class=&quot;codehilite&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;Training set:&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;pred_train&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;predict&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X_train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Y_train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;W&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;b&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;word_to_vec_map&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;Test set:&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;pred_test&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;predict&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X_test&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Y_test&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;W&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;b&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;word_to_vec_map&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div class=&quot;codehilite&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;Training set:
Accuracy: 0.977272727273
Test set:
Accuracy: 0.857142857143
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;strong&gt;Expected Output&lt;/strong&gt;:&lt;/p&gt;
&lt;table&gt;
    &lt;tr&gt;
        &lt;td&gt;
            **Train set accuracy**
        &lt;/td&gt;
        &lt;td&gt;
           97.7
        &lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
        &lt;td&gt;
            **Test set accuracy**
        &lt;/td&gt;
        &lt;td&gt;
           85.7
        &lt;/td&gt;
    &lt;/tr&gt;
&lt;/table&gt;

&lt;p&gt;Random guessing would have had 20% accuracy given that there are 5 classes. This is pretty good performance after training on only 127 examples. &lt;/p&gt;
&lt;p&gt;In the training set, the algorithm saw the sentence &quot;&lt;em&gt;I love you&lt;/em&gt;&quot; with the label ❤️. You can check however that the word &quot;adore&quot; does not appear in the training set. Nonetheless, lets see what happens if you write &quot;&lt;em&gt;I adore you&lt;/em&gt;.&quot;&lt;/p&gt;
&lt;div class=&quot;codehilite&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X_my_sentences&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;array&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;i adore you&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&amp;quot;i love you&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&amp;quot;funny lol&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&amp;quot;lets play with a ball&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&amp;quot;food is ready&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&amp;quot;not feeling happy&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;Y_my_labels&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;array&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]])&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;pred&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;predict&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X_my_sentences&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Y_my_labels&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;W&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;b&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;word_to_vec_map&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;print_predictions&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X_my_sentences&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pred&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div class=&quot;codehilite&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Accuracy&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.833333333333&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;adore&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;you&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;❤️&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;love&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;you&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;❤️&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;funny&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;lol&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;😄&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;lets&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;play&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;with&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;a&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ball&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;⚾&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;food&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;is&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ready&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;🍴&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;not&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;feeling&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;happy&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;😄&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Amazing! Because &lt;em&gt;adore&lt;/em&gt; has a similar embedding as &lt;em&gt;love&lt;/em&gt;, the algorithm has generalized correctly even to a word it has never seen before. Words such as &lt;em&gt;heart&lt;/em&gt;, &lt;em&gt;dear&lt;/em&gt;, &lt;em&gt;beloved&lt;/em&gt; or &lt;em&gt;adore&lt;/em&gt; have embedding vectors similar to &lt;em&gt;love&lt;/em&gt;, and so might work too---feel free to modify the inputs above and try out a variety of input sentences. How well does it work?&lt;/p&gt;
&lt;p&gt;Note though that it doesn&#39;t get &quot;not feeling happy&quot; correct. This algorithm ignores word ordering, so is not good at understanding phrases like &quot;not happy.&quot; &lt;/p&gt;
&lt;p&gt;Printing the confusion matrix can also help understand which classes are more difficult for your model. A confusion matrix shows how often an example whose label is one class (&quot;actual&quot; class) is mislabeled by the algorithm with a different class (&quot;predicted&quot; class). &lt;/p&gt;
&lt;div class=&quot;codehilite&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Y_test&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;           &amp;#39;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;label_to_emoji&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&amp;#39;    &amp;#39;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;label_to_emoji&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&amp;#39;    &amp;#39;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;  &lt;span class=&quot;n&quot;&gt;label_to_emoji&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&amp;#39;    &amp;#39;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;label_to_emoji&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;   &amp;#39;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;label_to_emoji&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pd&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;crosstab&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Y_test&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pred_test&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;reshape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;56&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;rownames&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;Actual&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;colnames&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;Predicted&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;margins&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;plot_confusion_matrix&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Y_test&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pred_test&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div class=&quot;codehilite&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;(56,)
           ❤️    ⚾    😄    😞   🍴
Predicted  0.0  1.0  2.0  3.0  4.0  All
Actual                                 
0            6    0    0    1    0    7
1            0    8    0    0    0    8
2            2    0   16    0    0   18
3            1    1    2   12    0   16
4            0    0    1    0    6    7
All          9    9   19   13    6   56
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;img alt=&quot;png&quot; src=&quot;output_34_1.png&quot; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;What you should remember from this part&lt;/strong&gt;:
- Even with a 127 training examples, you can get a reasonably good model for Emojifying. This is due to the generalization power word vectors gives you. 
- Emojify-V1 will perform poorly on sentences such as &lt;em&gt;&quot;This movie is not good and not enjoyable&quot;&lt;/em&gt; because it doesn&#39;t understand combinations of words--it just averages all the words&#39; embedding vectors together, without paying attention to the ordering of words. You will build a better algorithm in the next part. &lt;/p&gt;
&lt;h2 id=&quot;2-emojifier-v2-using-lstms-in-keras&quot;&gt;2 - Emojifier-V2: Using LSTMs in Keras:&lt;/h2&gt;
&lt;p&gt;Let&#39;s build an LSTM model that takes as input word sequences. This model will be able to take word ordering into account. Emojifier-V2 will continue to use pre-trained word embeddings to represent words, but will feed them into an LSTM, whose job it is to predict the most appropriate emoji. &lt;/p&gt;
&lt;p&gt;Run the following cell to load the Keras packages.&lt;/p&gt;
&lt;div class=&quot;codehilite&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;numpy&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;np&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;random&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;seed&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;keras.models&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Model&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;keras.layers&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Dense&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Input&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Dropout&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;LSTM&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Activation&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;keras.layers.embeddings&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Embedding&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;keras.preprocessing&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sequence&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;keras.initializers&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;glorot_uniform&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;random&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;seed&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div class=&quot;codehilite&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;Using TensorFlow backend.
&lt;/pre&gt;&lt;/div&gt;


&lt;h3 id=&quot;21-overview-of-the-model&quot;&gt;2.1 - Overview of the model&lt;/h3&gt;
&lt;p&gt;Here is the Emojifier-v2 you will implement:&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/karenyyy/Coursera_and_Udemy/master/deeplearningai_coursera/Sequence%20Models/images/emojifier-v2.png&quot; style=&quot;width:700px;height:400px;&quot;&gt; &lt;br&gt;
&lt;caption&gt;&lt;center&gt; &lt;strong&gt;Figure 3&lt;/strong&gt;: Emojifier-V2. A 2-layer LSTM sequence classifier. &lt;/center&gt;&lt;/caption&gt;&lt;/p&gt;
&lt;h3 id=&quot;22-keras-and-mini-batching&quot;&gt;2.2 Keras and mini-batching&lt;/h3&gt;
&lt;p&gt;In this exercise, we want to train Keras using mini-batches. However, most deep learning frameworks require that all sequences in the same mini-batch have the same length. This is what allows vectorization to work: If you had a 3-word sentence and a 4-word sentence, then the computations needed for them are different (one takes 3 steps of an LSTM, one takes 4 steps) so it&#39;s just not possible to do them both at the same time.&lt;/p&gt;
&lt;p&gt;The common solution to this is to use padding. Specifically, set a maximum sequence length, and pad all sequences to the same length. For example, of the maximum sequence length is 20, we could pad every sentence with &quot;0&quot;s so that each input sentence is of length 20. Thus, a sentence &quot;i love you&quot; would be represented as $(e_{i}, e_{love}, e_{you}, \vec{0}, \vec{0}, \ldots, \vec{0})$. In this example, any sentences longer than 20 words would have to be truncated. One simple way to choose the maximum sequence length is to just pick the length of the longest sentence in the training set. &lt;/p&gt;
&lt;h3 id=&quot;23-the-embedding-layer&quot;&gt;2.3 - The Embedding layer&lt;/h3&gt;
&lt;p&gt;In Keras, the embedding matrix is represented as a &quot;layer&quot;, and maps positive integers (indices corresponding to words) into dense vectors of fixed size (the embedding vectors). It can be trained or initialized with a pretrained embedding. In this part, you will learn how to create an &lt;a href=&quot;https://keras.io/layers/embeddings/&quot;&gt;Embedding()&lt;/a&gt; layer in Keras, initialize it with the GloVe 50-dimensional vectors loaded earlier in the notebook. Because our training set is quite small, we will not update the word embeddings but will instead leave their values fixed. But in the code below, we&#39;ll show you how Keras allows you to either train or leave fixed this layer.  &lt;/p&gt;
&lt;p&gt;The &lt;code&gt;Embedding()&lt;/code&gt; layer takes an integer matrix of size (batch size, max input length) as input. This corresponds to sentences converted into lists of indices (integers), as shown in the figure below.&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/karenyyy/Coursera_and_Udemy/master/deeplearningai_coursera/Sequence%20Models/images/embedding1.png&quot; style=&quot;width:700px;height:250px;&quot;&gt;
&lt;caption&gt;&lt;center&gt; &lt;strong&gt;Figure 4&lt;/strong&gt;: Embedding layer. This example shows the propagation of two examples through the embedding layer. Both have been zero-padded to a length of &lt;code&gt;max_len=5&lt;/code&gt;. The final dimension of the representation is  &lt;code&gt;(2,max_len,50)&lt;/code&gt; because the word embeddings we are using are 50 dimensional. &lt;/center&gt;&lt;/caption&gt;&lt;/p&gt;
&lt;p&gt;The largest integer (i.e. word index) in the input should be no larger than the vocabulary size. The layer outputs an array of shape (batch size, max input length, dimension of word vectors).&lt;/p&gt;
&lt;p&gt;The first step is to convert all your training sentences into lists of indices, and then zero-pad all these lists so that their length is the length of the longest sentence. &lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Exercise&lt;/strong&gt;: Implement the function below to convert X (array of sentences as strings) into an array of indices corresponding to words in the sentences. The output shape should be such that it can be given to &lt;code&gt;Embedding()&lt;/code&gt; (described in Figure 4). &lt;/p&gt;
&lt;div class=&quot;codehilite&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;c1&quot;&gt;# GRADED FUNCTION: sentences_to_indices&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;sentences_to_indices&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;word_to_index&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;max_len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;sd&quot;&gt;&amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    Converts an array of sentences (strings) into an array of indices corresponding to words in the sentences.&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    The output shape should be such that it can be given to `Embedding()` (described in Figure 4). &lt;/span&gt;

&lt;span class=&quot;sd&quot;&gt;    Arguments:&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    X -- array of sentences (strings), of shape (m, 1)&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    word_to_index -- a dictionary containing the each word mapped to its index&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    max_len -- maximum number of words in a sentence. You can assume every sentence in X is no longer than this. &lt;/span&gt;

&lt;span class=&quot;sd&quot;&gt;    Returns:&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    X_indices -- array of indices corresponding to words in the sentences from X, of shape (m, max_len)&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    &amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;

    &lt;span class=&quot;n&quot;&gt;m&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;                                   &lt;span class=&quot;c1&quot;&gt;# number of training examples&lt;/span&gt;


    &lt;span class=&quot;c1&quot;&gt;# Initialize X_indices as a numpy matrix of zeros and the correct shape (≈ 1 line)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;X_indices&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;zeros&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;((&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;m&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;max_len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;

    &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;m&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;                               &lt;span class=&quot;c1&quot;&gt;# loop over training examples&lt;/span&gt;

        &lt;span class=&quot;c1&quot;&gt;# Convert the ith training sentence in lower case and split is into words. You should get a list of words.&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;sentence_words&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;w&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;lower&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;w&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;split&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()]&lt;/span&gt;

        &lt;span class=&quot;c1&quot;&gt;# Initialize j to 0&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;j&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;

        &lt;span class=&quot;c1&quot;&gt;# Loop over the words of sentence_words&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;w&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sentence_words&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;c1&quot;&gt;# Set the (i,j)th entry of X_indices to the index of the correct word.&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;X_indices&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;j&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;word_to_index&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;w&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
            &lt;span class=&quot;c1&quot;&gt;# Increment j to j + 1&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;j&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;



    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X_indices&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Run the following cell to check what &lt;code&gt;sentences_to_indices()&lt;/code&gt; does, and check your results.&lt;/p&gt;
&lt;div class=&quot;codehilite&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;array&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;funny lol&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&amp;quot;lets play baseball&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&amp;quot;food is ready for you&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;X1_indices&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sentences_to_indices&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;word_to_index&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;max_len&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;X1 =&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;X1_indices =&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X1_indices&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div class=&quot;codehilite&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;X1 = [&amp;#39;funny lol&amp;#39; &amp;#39;lets play baseball&amp;#39; &amp;#39;food is ready for you&amp;#39;]
X1_indices = [[ 155345.  225122.       0.       0.       0.]
 [ 220930.  286375.   69714.       0.       0.]
 [ 151204.  192973.  302254.  151349.  394475.]]
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;strong&gt;Expected Output&lt;/strong&gt;:&lt;/p&gt;
&lt;table&gt;
    &lt;tr&gt;
        &lt;td&gt;
            **X1 =**
        &lt;/td&gt;
        &lt;td&gt;
           [&#39;funny lol&#39; &#39;lets play football&#39; &#39;food is ready for you&#39;]
        &lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
        &lt;td&gt;
            **X1_indices =**
        &lt;/td&gt;
        &lt;td&gt;
           [[ 155345.  225122.       0.       0.       0.] &lt;br&gt;
            [ 220930.  286375.  151266.       0.       0.] &lt;br&gt;
            [ 151204.  192973.  302254.  151349.  394475.]]
        &lt;/td&gt;
    &lt;/tr&gt;
&lt;/table&gt;

&lt;p&gt;Let&#39;s build the &lt;code&gt;Embedding()&lt;/code&gt; layer in Keras, using pre-trained word vectors. After this layer is built, you will pass the output of &lt;code&gt;sentences_to_indices()&lt;/code&gt; to it as an input, and the &lt;code&gt;Embedding()&lt;/code&gt; layer will return the word embeddings for a sentence. &lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Exercise&lt;/strong&gt;: Implement &lt;code&gt;pretrained_embedding_layer()&lt;/code&gt;. You will need to carry out the following steps:
1. Initialize the embedding matrix as a numpy array of zeroes with the correct shape.
2. Fill in the embedding matrix with all the word embeddings extracted from &lt;code&gt;word_to_vec_map&lt;/code&gt;.
3. Define Keras embedding layer. Use &lt;a href=&quot;https://keras.io/layers/embeddings/&quot;&gt;Embedding()&lt;/a&gt;. Be sure to make this layer non-trainable, by setting &lt;code&gt;trainable = False&lt;/code&gt; when calling &lt;code&gt;Embedding()&lt;/code&gt;. If you were to set &lt;code&gt;trainable = True&lt;/code&gt;, then it will allow the optimization algorithm to modify the values of the word embeddings. 
4. Set the embedding weights to be equal to the embedding matrix &lt;/p&gt;
&lt;div class=&quot;codehilite&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;c1&quot;&gt;# GRADED FUNCTION: pretrained_embedding_layer&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;pretrained_embedding_layer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;word_to_vec_map&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;word_to_index&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;sd&quot;&gt;&amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    Creates a Keras Embedding() layer and loads in pre-trained GloVe 50-dimensional vectors.&lt;/span&gt;

&lt;span class=&quot;sd&quot;&gt;    Arguments:&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    word_to_vec_map -- dictionary mapping words to their GloVe vector representation.&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    word_to_index -- dictionary mapping from words to their indices in the vocabulary (400,001 words)&lt;/span&gt;

&lt;span class=&quot;sd&quot;&gt;    Returns:&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    embedding_layer -- pretrained layer Keras instance&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    &amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;

    &lt;span class=&quot;n&quot;&gt;vocab_len&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;word_to_index&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;                  &lt;span class=&quot;c1&quot;&gt;# adding 1 to fit Keras embedding (requirement)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;emb_dim&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;word_to_vec_map&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;cucumber&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;      &lt;span class=&quot;c1&quot;&gt;# define dimensionality of your GloVe word vectors (= 50)&lt;/span&gt;


    &lt;span class=&quot;c1&quot;&gt;# Initialize the embedding matrix as a numpy array of zeros of shape (vocab_len, dimensions of word vectors = emb_dim)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;emb_matrix&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;zeros&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;((&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;vocab_len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;emb_dim&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;

    &lt;span class=&quot;c1&quot;&gt;# Set each row &amp;quot;index&amp;quot; of the embedding matrix to be the word vector representation of the &amp;quot;index&amp;quot;th word of the vocabulary&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;word&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;index&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;word_to_index&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;items&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;():&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;emb_matrix&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;index&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;:]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;word_to_vec_map&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;word&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;

    &lt;span class=&quot;c1&quot;&gt;# Define Keras embedding layer with the correct output/input sizes, make it trainable. Use Embedding(...). Make sure to set trainable=False. &lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;embedding_layer&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Embedding&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;vocab_len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;emb_dim&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;trainable&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;False&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;


    &lt;span class=&quot;c1&quot;&gt;# Build the embedding layer, it is required before setting the weights of the embedding layer. Do not modify the &amp;quot;None&amp;quot;.&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;embedding_layer&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;build&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;((&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;None&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,))&lt;/span&gt;

    &lt;span class=&quot;c1&quot;&gt;# Set the weights of the embedding layer to the embedding matrix. Your layer is now pretrained.&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;embedding_layer&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;set_weights&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;emb_matrix&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;

    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;embedding_layer&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div class=&quot;codehilite&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;embedding_layer&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pretrained_embedding_layer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;word_to_vec_map&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;word_to_index&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;weights[0][1][3] =&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;embedding_layer&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;get_weights&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;][&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;][&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div class=&quot;codehilite&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;weights[0][1][3] = -0.3403
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;strong&gt;Expected Output&lt;/strong&gt;:&lt;/p&gt;
&lt;table&gt;
    &lt;tr&gt;
        &lt;td&gt;
            **weights[0][1][3] =**
        &lt;/td&gt;
        &lt;td&gt;
           -0.3403
        &lt;/td&gt;
    &lt;/tr&gt;
&lt;/table&gt;

&lt;h2 id=&quot;23-building-the-emojifier-v2&quot;&gt;2.3 Building the Emojifier-V2&lt;/h2&gt;
&lt;p&gt;Lets now build the Emojifier-V2 model. You will do so using the embedding layer you have built, and feed its output to an LSTM network. &lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/karenyyy/Coursera_and_Udemy/master/deeplearningai_coursera/Sequence%20Models/images/emojifier-v2.png&quot; style=&quot;width:700px;height:400px;&quot;&gt; &lt;br&gt;
&lt;caption&gt;&lt;center&gt; &lt;strong&gt;Figure 3&lt;/strong&gt;: Emojifier-v2. A 2-layer LSTM sequence classifier. &lt;/center&gt;&lt;/caption&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Exercise:&lt;/strong&gt; Implement &lt;code&gt;Emojify_V2()&lt;/code&gt;, which builds a Keras graph of the architecture shown in Figure 3. The model takes as input an array of sentences of shape (&lt;code&gt;m&lt;/code&gt;, &lt;code&gt;max_len&lt;/code&gt;, ) defined by &lt;code&gt;input_shape&lt;/code&gt;. It should output a softmax probability vector of shape (&lt;code&gt;m&lt;/code&gt;, &lt;code&gt;C = 5&lt;/code&gt;). You may need &lt;code&gt;Input(shape = ..., dtype = &#39;...&#39;)&lt;/code&gt;, &lt;a href=&quot;https://keras.io/layers/recurrent/#lstm&quot;&gt;LSTM()&lt;/a&gt;, &lt;a href=&quot;https://keras.io/layers/core/#dropout&quot;&gt;Dropout()&lt;/a&gt;, &lt;a href=&quot;https://keras.io/layers/core/#dense&quot;&gt;Dense()&lt;/a&gt;, and &lt;a href=&quot;https://keras.io/activations/&quot;&gt;Activation()&lt;/a&gt;.&lt;/p&gt;
&lt;div class=&quot;codehilite&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;c1&quot;&gt;# GRADED FUNCTION: Emojify_V2&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;Emojify_V2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;input_shape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;word_to_vec_map&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;word_to_index&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;sd&quot;&gt;&amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    Function creating the Emojify-v2 model&amp;#39;s graph.&lt;/span&gt;

&lt;span class=&quot;sd&quot;&gt;    Arguments:&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    input_shape -- shape of the input, usually (max_len,)&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    word_to_vec_map -- dictionary mapping every word in a vocabulary into its 50-dimensional vector representation&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    word_to_index -- dictionary mapping from words to their indices in the vocabulary (400,001 words)&lt;/span&gt;

&lt;span class=&quot;sd&quot;&gt;    Returns:&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    model -- a model instance in Keras&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    &amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;


    &lt;span class=&quot;c1&quot;&gt;# Define sentence_indices as the input of the graph, it should be of shape input_shape and dtype &amp;#39;int32&amp;#39; (as it contains indices).&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;sentence_indices&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Input&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;input_shape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dtype&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;int32&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

    &lt;span class=&quot;c1&quot;&gt;# Create the embedding layer pretrained with GloVe Vectors (≈1 line)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;embedding_layer&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pretrained_embedding_layer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;word_to_vec_map&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;word_to_index&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

    &lt;span class=&quot;c1&quot;&gt;# Propagate sentence_indices through your embedding layer, you get back the embeddings&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;embeddings&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;embedding_layer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sentence_indices&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;   

    &lt;span class=&quot;c1&quot;&gt;# Propagate the embeddings through an LSTM layer with 128-dimensional hidden state&lt;/span&gt;
    &lt;span class=&quot;c1&quot;&gt;# Be careful, the returned output should be a batch of sequences.&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;LSTM&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;128&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;return_sequences&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;embeddings&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;c1&quot;&gt;# Add dropout with a probability of 0.5&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Dropout&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;c1&quot;&gt;# Propagate X trough another LSTM layer with 128-dimensional hidden state&lt;/span&gt;
    &lt;span class=&quot;c1&quot;&gt;# Be careful, the returned output should be a single hidden state, not a batch of sequences.&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;LSTM&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;128&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;return_sequences&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;False&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;c1&quot;&gt;# Add dropout with a probability of 0.5&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Dropout&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;c1&quot;&gt;# Propagate X through a Dense layer with softmax activation to get back a batch of 5-dimensional vectors.&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Dense&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;c1&quot;&gt;# Add a softmax activation&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Activation&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;softmax&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

    &lt;span class=&quot;c1&quot;&gt;# Create Model instance which converts sentence_indices into X.&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;model&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;inputs&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sentence_indices&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;outputs&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;



    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Run the following cell to create your model and check its summary. Because all sentences in the dataset are less than 10 words, we chose &lt;code&gt;max_len = 10&lt;/code&gt;.  You should see your architecture, it uses &quot;20,223,927&quot; parameters, of which 20,000,050 (the word embeddings) are non-trainable, and the remaining 223,877 are. Because our vocabulary size has 400,001 words (with valid indices from 0 to 400,000) there are 400,001*50 = 20,000,050 non-trainable parameters. &lt;/p&gt;
&lt;div class=&quot;codehilite&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Emojify_V2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;((&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;maxLen&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;word_to_vec_map&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;word_to_index&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;summary&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div class=&quot;codehilite&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         (None, 10)                0         
_________________________________________________________________
embedding_2 (Embedding)      (None, 10, 50)            20000050  
_________________________________________________________________
lstm_1 (LSTM)                (None, 10, 128)           91648     
_________________________________________________________________
dropout_1 (Dropout)          (None, 10, 128)           0         
_________________________________________________________________
lstm_2 (LSTM)                (None, 128)               131584    
_________________________________________________________________
dropout_2 (Dropout)          (None, 128)               0         
_________________________________________________________________
dense_1 (Dense)              (None, 5)                 645       
_________________________________________________________________
activation_1 (Activation)    (None, 5)                 0         
=================================================================
Total params: 20,223,927
Trainable params: 223,877
Non-trainable params: 20,000,050
_________________________________________________________________
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;As usual, after creating your model in Keras, you need to compile it and define what loss, optimizer and metrics your are want to use. Compile your model using &lt;code&gt;categorical_crossentropy&lt;/code&gt; loss, &lt;code&gt;adam&lt;/code&gt; optimizer and &lt;code&gt;[&#39;accuracy&#39;]&lt;/code&gt; metrics:&lt;/p&gt;
&lt;div class=&quot;codehilite&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;compile&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;loss&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;categorical_crossentropy&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;optimizer&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;adam&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;metrics&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;accuracy&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;It&#39;s time to train your model. Your Emojifier-V2 &lt;code&gt;model&lt;/code&gt; takes as input an array of shape (&lt;code&gt;m&lt;/code&gt;, &lt;code&gt;max_len&lt;/code&gt;) and outputs probability vectors of shape (&lt;code&gt;m&lt;/code&gt;, &lt;code&gt;number of classes&lt;/code&gt;). We thus have to convert X_train (array of sentences as strings) to X_train_indices (array of sentences as list of word indices), and Y_train (labels as indices) to Y_train_oh (labels as one-hot vectors).&lt;/p&gt;
&lt;div class=&quot;codehilite&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X_train_indices&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sentences_to_indices&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X_train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;word_to_index&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;maxLen&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;Y_train_oh&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;convert_to_one_hot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Y_train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;C&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Fit the Keras model on &lt;code&gt;X_train_indices&lt;/code&gt; and &lt;code&gt;Y_train_oh&lt;/code&gt;. We will use &lt;code&gt;epochs = 50&lt;/code&gt; and &lt;code&gt;batch_size = 32&lt;/code&gt;.&lt;/p&gt;
&lt;div class=&quot;codehilite&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fit&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X_train_indices&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Y_train_oh&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;epochs&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;50&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;batch_size&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;32&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;shuffle&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div class=&quot;codehilite&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;Epoch 1/50
132/132 [==============================] - 1s - loss: 1.6084 - acc: 0.1970     
Epoch 2/50
132/132 [==============================] - 0s - loss: 1.5322 - acc: 0.2955     
Epoch 3/50
132/132 [==============================] - 0s - loss: 1.5012 - acc: 0.3258     
Epoch 4/50
132/132 [==============================] - 0s - loss: 1.4387 - acc: 0.3561     
Epoch 5/50
132/132 [==============================] - 0s - loss: 1.3472 - acc: 0.4545     
Epoch 6/50
132/132 [==============================] - 0s - loss: 1.2334 - acc: 0.5076     
Epoch 7/50
132/132 [==============================] - 0s - loss: 1.1768 - acc: 0.4394     
Epoch 8/50
132/132 [==============================] - 0s - loss: 1.0552 - acc: 0.5682     
Epoch 9/50
132/132 [==============================] - 0s - loss: 0.8778 - acc: 0.7121     
Epoch 10/50
132/132 [==============================] - 0s - loss: 0.8236 - acc: 0.6970     
Epoch 11/50
132/132 [==============================] - 0s - loss: 0.7037 - acc: 0.7500     
Epoch 12/50
132/132 [==============================] - 0s - loss: 0.6010 - acc: 0.8030     
Epoch 13/50
132/132 [==============================] - 0s - loss: 0.4934 - acc: 0.8333     
Epoch 14/50
132/132 [==============================] - 0s - loss: 0.5100 - acc: 0.8333     
Epoch 15/50
132/132 [==============================] - 0s - loss: 0.4788 - acc: 0.8258     
Epoch 16/50
132/132 [==============================] - 0s - loss: 0.3554 - acc: 0.8636     
Epoch 17/50
132/132 [==============================] - 0s - loss: 0.3913 - acc: 0.8636     
Epoch 18/50
132/132 [==============================] - 0s - loss: 0.6454 - acc: 0.8106     
Epoch 19/50
132/132 [==============================] - 0s - loss: 0.5181 - acc: 0.8182     
Epoch 20/50
132/132 [==============================] - 0s - loss: 0.3935 - acc: 0.8409     
Epoch 21/50
132/132 [==============================] - 0s - loss: 0.4747 - acc: 0.8106     
Epoch 22/50
132/132 [==============================] - 0s - loss: 0.3924 - acc: 0.8636     
Epoch 23/50
132/132 [==============================] - 0s - loss: 0.3828 - acc: 0.8561     
Epoch 24/50
132/132 [==============================] - 0s - loss: 0.3074 - acc: 0.9091     
Epoch 25/50
132/132 [==============================] - 0s - loss: 0.3535 - acc: 0.8864     
Epoch 26/50
132/132 [==============================] - 0s - loss: 0.2403 - acc: 0.9394     
Epoch 27/50
132/132 [==============================] - 0s - loss: 0.3213 - acc: 0.8788     
Epoch 28/50
132/132 [==============================] - 0s - loss: 0.2400 - acc: 0.9318     
Epoch 29/50
132/132 [==============================] - 0s - loss: 0.3944 - acc: 0.8712     
Epoch 30/50
132/132 [==============================] - 0s - loss: 0.2714 - acc: 0.9091     
Epoch 31/50
132/132 [==============================] - 0s - loss: 0.2958 - acc: 0.8864     
Epoch 32/50
132/132 [==============================] - 0s - loss: 0.2099 - acc: 0.9242     
Epoch 33/50
132/132 [==============================] - 0s - loss: 0.2142 - acc: 0.9470     
Epoch 34/50
132/132 [==============================] - 0s - loss: 0.1542 - acc: 0.9545     
Epoch 35/50
132/132 [==============================] - 0s - loss: 0.1639 - acc: 0.9621     
Epoch 36/50
132/132 [==============================] - 0s - loss: 0.1840 - acc: 0.9394     
Epoch 37/50
132/132 [==============================] - 0s - loss: 0.1618 - acc: 0.9470     
Epoch 38/50
132/132 [==============================] - 0s - loss: 0.1994 - acc: 0.9394     
Epoch 39/50
132/132 [==============================] - 0s - loss: 0.1347 - acc: 0.9697     
Epoch 40/50
132/132 [==============================] - 0s - loss: 0.1415 - acc: 0.9621     
Epoch 41/50
132/132 [==============================] - 0s - loss: 0.0849 - acc: 0.9848     
Epoch 42/50
132/132 [==============================] - 0s - loss: 0.0747 - acc: 0.9924     
Epoch 43/50
132/132 [==============================] - 0s - loss: 0.0760 - acc: 0.9848     
Epoch 44/50
132/132 [==============================] - 0s - loss: 0.0466 - acc: 0.9924     
Epoch 45/50
132/132 [==============================] - 0s - loss: 0.0853 - acc: 0.9848     
Epoch 46/50
132/132 [==============================] - 0s - loss: 0.1311 - acc: 0.9773     
Epoch 47/50
132/132 [==============================] - 0s - loss: 0.1673 - acc: 0.9470     
Epoch 48/50
132/132 [==============================] - 0s - loss: 0.2479 - acc: 0.9242     
Epoch 49/50
132/132 [==============================] - 0s - loss: 0.1215 - acc: 0.9773     
Epoch 50/50
132/132 [==============================] - 0s - loss: 0.1742 - acc: 0.9470





&amp;lt;keras.callbacks.History at 0x7f70fbc53b00&amp;gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Your model should perform close to &lt;strong&gt;100% accuracy&lt;/strong&gt; on the training set. The exact accuracy you get may be a little different. Run the following cell to evaluate your model on the test set. &lt;/p&gt;
&lt;div class=&quot;codehilite&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X_test_indices&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sentences_to_indices&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X_test&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;word_to_index&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;max_len&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;maxLen&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;Y_test_oh&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;convert_to_one_hot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Y_test&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;C&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;loss&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;acc&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;evaluate&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X_test_indices&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Y_test_oh&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;Test accuracy = &amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;acc&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div class=&quot;codehilite&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;32/56 [================&amp;gt;.............] - ETA: 0s
Test accuracy =  0.821428562914
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;You should get a test accuracy between 80% and 95%. Run the cell below to see the mislabelled examples. &lt;/p&gt;
&lt;div class=&quot;codehilite&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;c1&quot;&gt;# This code allows you to see the mislabelled examples&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;C&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;y_test_oh&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;eye&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;C&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Y_test&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;reshape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)]&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;X_test_indices&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sentences_to_indices&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X_test&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;word_to_index&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;maxLen&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;pred&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;predict&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X_test_indices&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X_test&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)):&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X_test_indices&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;num&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;argmax&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pred&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;num&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;!=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Y_test&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]):&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;Expected emoji:&amp;#39;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;label_to_emoji&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Y_test&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&amp;#39; prediction: &amp;#39;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X_test&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;label_to_emoji&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;num&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;strip&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;())&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div class=&quot;codehilite&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;Expected emoji:😄 prediction: she got me a nice present  ❤️
Expected emoji:😞 prediction: work is hard   😄
Expected emoji:😞 prediction: This girl is messing with me   ❤️
Expected emoji:🍴 prediction: any suggestions for dinner 😄
Expected emoji:❤️ prediction: I love taking breaks  😞
Expected emoji:😄 prediction: you brighten my day    ❤️
Expected emoji:😄 prediction: will you be my valentine   ❤️
Expected emoji:🍴 prediction: See you at the restaurant  😄
Expected emoji:😞 prediction: go away    ⚾
Expected emoji:🍴 prediction: I did not have breakfast ❤️
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Now you can try it on your own example. Write your own sentence below. &lt;/p&gt;
&lt;div class=&quot;codehilite&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;c1&quot;&gt;# Change the sentence below to see your prediction. Make sure all the words are in the Glove embeddings.  &lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;x_test&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;array&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;not feeling happy&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;X_test_indices&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sentences_to_indices&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x_test&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;word_to_index&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;maxLen&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x_test&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39; &amp;#39;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;  &lt;span class=&quot;n&quot;&gt;label_to_emoji&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;argmax&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;predict&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X_test_indices&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))))&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div class=&quot;codehilite&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;not feeling happy 😞
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Previously, Emojify-V1 model did not correctly label &quot;not feeling happy,&quot; but our implementation of Emojiy-V2 got it right. (Keras&#39; outputs are slightly random each time, so you may not have obtained the same result.) The current model still isn&#39;t very robust at understanding negation (like &quot;not happy&quot;) because the training set is small and so doesn&#39;t have a lot of examples of negation. But if the training set were larger, the LSTM model would be much better than the Emojify-V1 model at understanding such complex sentences. &lt;/p&gt;
&lt;h3 id=&quot;congratulations&quot;&gt;Congratulations!&lt;/h3&gt;
&lt;p&gt;You have completed this notebook! ❤️❤️❤️&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;What you should remember&lt;/strong&gt;:
- If you have an NLP task where the training set is small, using word embeddings can help your algorithm significantly. Word embeddings allow your model to work on words in the test set that may not even have appeared in your training set. 
- Training sequence models in Keras (and in most other deep learning frameworks) requires a few important details:
    - To use mini-batches, the sequences need to be padded so that all the examples in a mini-batch have the same length. 
    - An &lt;code&gt;Embedding()&lt;/code&gt; layer can be initialized with pretrained values. These values can be either fixed or trained further on your dataset. If however your labeled dataset is small, it&#39;s usually not worth trying to train a large pre-trained set of embeddings. &lt;br /&gt;
    - &lt;code&gt;LSTM()&lt;/code&gt; has a flag called &lt;code&gt;return_sequences&lt;/code&gt; to decide if you would like to return every hidden states or only the last one. 
    - You can use &lt;code&gt;Dropout()&lt;/code&gt; right after &lt;code&gt;LSTM()&lt;/code&gt; to regularize your network. &lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/karenyyy/Coursera_and_Udemy/master/deeplearningai_coursera/Sequence%20Models/images/woebot.png&quot; style=&quot;width:600px;height:300px;&quot;&gt;&lt;/p&gt;deeplearning.ai - Sequence Model - Week 1 Notes
&lt;h2 id=&quot;notation&quot;&gt;Notation&lt;/h2&gt;
&lt;h3 id=&quot;name-entity&quot;&gt;Name Entity&lt;/h3&gt;
&lt;h4 id=&quot;one-hot&quot;&gt;One-Hot&lt;/h4&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://raw.githubusercontent.com/karenyyy/Coursera_and_Udemy/master/deeplearningai_coursera/Sequence%20Models/images/1.png&quot; /&gt;&lt;/p&gt;
&lt;h2 id=&quot;rnn&quot;&gt;RNN&lt;/h2&gt;
&lt;blockquote&gt;
&lt;p&gt;Why not use a standard network?&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://raw.githubusercontent.com/karenyyy/Coursera_and_Udemy/master/deeplearningai_coursera/Sequence%20Models/images/2.png&quot; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Problems:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;the input and output might thbe different lengths and different examples;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;a naive neural network architecture like this, it doesn&#39;t share features learned across different positions of texts&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;the input layer would be really large&lt;/li&gt;
&lt;li&gt;A weight matrix of this first layer will end up having an enormous number of parameters&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://raw.githubusercontent.com/karenyyy/Coursera_and_Udemy/master/deeplearningai_coursera/Sequence%20Models/images/3.png&quot; /&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;RNN scans through the data from left to right&lt;/li&gt;
&lt;li&gt;The parameters it uses for each time step are shared&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Process:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;when making the prediction for y3, it gets info not only from x3 but also the info from x1 and x2 &lt;ul&gt;
&lt;li&gt;because the info on x1 can pass through activation functions that connected each 2 layers to help to predict with y3&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Weakness:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Only use the info that is earlier appeared in the sequence to make predictions&lt;ul&gt;
&lt;li&gt;when predicting y3, it does not use x4, x5, x6 ... (appear later)&lt;ul&gt;
&lt;li&gt;it is a problem because in a sentence:   words follows later are more useful fo name detecting this case&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://raw.githubusercontent.com/karenyyy/Coursera_and_Udemy/master/deeplearningai_coursera/Sequence%20Models/images/4.png&quot; /&gt; &lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;How to fix this problem?&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Introduce &lt;strong&gt;Bidirectional RNN (BRNN)&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Forward Propagation&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://raw.githubusercontent.com/karenyyy/Coursera_and_Udemy/master/deeplearningai_coursera/Sequence%20Models/images/5.png&quot; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://raw.githubusercontent.com/karenyyy/Coursera_and_Udemy/master/deeplearningai_coursera/Sequence%20Models/images/6.png&quot; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Cost Function&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://raw.githubusercontent.com/karenyyy/Coursera_and_Udemy/master/deeplearningai_coursera/Sequence%20Models/images/7.png&quot; /&gt;&lt;/p&gt;
&lt;p&gt;After computing the total cost, then back prop:&lt;/p&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://raw.githubusercontent.com/karenyyy/Coursera_and_Udemy/master/deeplearningai_coursera/Sequence%20Models/images/8.png&quot; /&gt;&lt;/p&gt;
&lt;h3 id=&quot;different-types-fo-rnn&quot;&gt;Different types fo RNN&lt;/h3&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://raw.githubusercontent.com/karenyyy/Coursera_and_Udemy/master/deeplearningai_coursera/Sequence%20Models/images/9.png&quot; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://raw.githubusercontent.com/karenyyy/Coursera_and_Udemy/master/deeplearningai_coursera/Sequence%20Models/images/10.png&quot; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://raw.githubusercontent.com/karenyyy/Coursera_and_Udemy/master/deeplearningai_coursera/Sequence%20Models/images/11.png&quot; /&gt;&lt;/p&gt;
&lt;h2 id=&quot;language-model&quot;&gt;Language Model&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;Language model tells what the probability of a sentence is(how likely does it make snese?)&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://raw.githubusercontent.com/karenyyy/Coursera_and_Udemy/master/deeplearningai_coursera/Sequence%20Models/images/13.png&quot; /&gt;&lt;/p&gt;
&lt;p&gt;Training set: large corpus of english text&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;First Step: &lt;strong&gt;Tokenize the sentence&lt;/strong&gt;&lt;ul&gt;
&lt;li&gt;that means forming a vocabulary&lt;/li&gt;
&lt;li&gt;then map each of these words to one-hot vectors&lt;/li&gt;
&lt;li&gt;model when sentences end: add a extra token called a EOS (End of Sentence)&lt;/li&gt;
&lt;li&gt;replace unknown words in the sentence with &#39;UNK&#39; (unknown)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Next Step: build a RNN to model the chance of these different sentences&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://raw.githubusercontent.com/karenyyy/Coursera_and_Udemy/master/deeplearningai_coursera/Sequence%20Models/images/14.png&quot; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://raw.githubusercontent.com/karenyyy/Coursera_and_Udemy/master/deeplearningai_coursera/Sequence%20Models/images/15.png&quot; /&gt;&lt;/p&gt;
&lt;h2 id=&quot;sampling-a-sequence-from-a-trained-rnn&quot;&gt;Sampling a sequence from a trained RNN&lt;/h2&gt;
&lt;p&gt;Recap that a sequence model models the chances of any particular sequence of words as follows, so what we like to do is sample from this distribution to generate noble sequences fo words.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;First Step: sample what is the first word that you want your model to generate&lt;ul&gt;
&lt;li&gt;your first time stamp will have some max probability over possible outputs&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Second Step: randomly sample according to the softmax distribution&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://raw.githubusercontent.com/karenyyy/Coursera_and_Udemy/master/deeplearningai_coursera/Sequence%20Models/images/16.png&quot; /&gt;&lt;/p&gt;
&lt;h2 id=&quot;vanishing-gradients-rnn&quot;&gt;Vanishing Gradients RNN&lt;/h2&gt;
&lt;h3 id=&quot;fail-to-capture-very-long-term-dependencies&quot;&gt;Fail to capture very long-term dependencies&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;The cat, which ..., was ...&lt;/li&gt;
&lt;li&gt;The cats, which ..., were ...&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;Why?&lt;/p&gt;
&lt;p&gt;Vanishing  gradient while training&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;strong&gt;Because of this problem, the basic RNN model has many local influences, meaning that the output is mainly influenced by values close to it.&lt;/strong&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;How to detect gradient explosion?&lt;/p&gt;
&lt;/blockquote&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;&#39;Nans&#39;&lt;/strong&gt; in your results, indicating that results of a numerical overflow in your NN computation&lt;ul&gt;
&lt;li&gt;Fix: &lt;strong&gt;apply gradient clipping&lt;/strong&gt;. Look at your gradient vectors, and if it is bigger than some threshold, &lt;em&gt;rescale some of the gradients so that it is not too big&lt;/em&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;How to fix vanishing gradient?&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Use &lt;strong&gt;GRU&lt;/strong&gt;&lt;/p&gt;
&lt;h2 id=&quot;gru&quot;&gt;GRU&lt;/h2&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://raw.githubusercontent.com/karenyyy/Coursera_and_Udemy/master/deeplearningai_coursera/Sequence%20Models/images/17.png&quot; /&gt;&lt;/p&gt;
&lt;p&gt;Using the cat example above:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;C: memory cell, to memorize whether it is single or plural so that when it gets much further into the sentence it can still work under consideration&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;$$c^{&lt;t&gt;} = a^{&lt;t&gt;}$$&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;At each time step, overwrite c with :&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;$$\hat c^{&lt;t&gt;} = \tanh (w_c [c^{t-1}, x^{t}] + b_c)$$&lt;/p&gt;
&lt;p&gt;$$\Gamma_u = \sigma (w_u[c^{t-1}, x^{t}] + b_u)$$&lt;/p&gt;
&lt;p&gt;$$c^{&lt;t&gt;} = 1 \text{ if single } $$&lt;/p&gt;
&lt;p&gt;$$c^{&lt;t&gt;} = 0 \text{ if plural } $$&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;And then the GRU unit will memorize the value of the c all the way until verb appears&lt;/li&gt;
&lt;li&gt;The job of the gate (Gamma u) is to decide when to update these values&lt;ul&gt;
&lt;li&gt;In particular, when we see the phrase, &#39;the cat&#39;, then a new concept the especially subject of the sentence cat. So this would be a good time to update this bit&lt;/li&gt;
&lt;li&gt;When we done using it, say, after &#39;The cat... was...&#39; this sentence is finished, then it is time to trigger the Gamma to forget the subject &#39;cat&#39;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;$$\Gamma_{u} = 1 \text{ if subject remains } $$&lt;/p&gt;
&lt;p&gt;$$\Gamma_{u} = 0 \text{ if sentence ends and subject changes } $$    &lt;/p&gt;
&lt;p&gt;$$c^{&lt;t&gt;} = \Gamma_u * \hat c^{&lt;t&gt;} + (1-\Gamma_u) * c^{&lt;t-1&gt;}$$&lt;/p&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://raw.githubusercontent.com/karenyyy/Coursera_and_Udemy/master/deeplearningai_coursera/Sequence%20Models/images/18.png&quot; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://raw.githubusercontent.com/karenyyy/Coursera_and_Udemy/master/deeplearningai_coursera/Sequence%20Models/images/19.png&quot; /&gt;&lt;/p&gt;
&lt;h3 id=&quot;full-gru&quot;&gt;Full GRU&lt;/h3&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://raw.githubusercontent.com/karenyyy/Coursera_and_Udemy/master/deeplearningai_coursera/Sequence%20Models/images/20.png&quot; /&gt;&lt;/p&gt;
&lt;p&gt;$$ \Gamma r \text{ tells how relevant is } c^{&lt;t-1&gt;}$$&lt;/p&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://raw.githubusercontent.com/karenyyy/Coursera_and_Udemy/master/deeplearningai_coursera/Sequence%20Models/images/21.png&quot; /&gt;&lt;/p&gt;
&lt;h2 id=&quot;lstm&quot;&gt;LSTM&lt;/h2&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://raw.githubusercontent.com/karenyyy/Coursera_and_Udemy/master/deeplearningai_coursera/Sequence%20Models/images/22.png&quot; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://raw.githubusercontent.com/karenyyy/Coursera_and_Udemy/master/deeplearningai_coursera/Sequence%20Models/images/23.png&quot; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://raw.githubusercontent.com/karenyyy/Coursera_and_Udemy/master/deeplearningai_coursera/Sequence%20Models/images/24.png&quot; /&gt;&lt;/p&gt;
&lt;h2 id=&quot;brnn&quot;&gt;BRNN&lt;/h2&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://raw.githubusercontent.com/karenyyy/Coursera_and_Udemy/master/deeplearningai_coursera/Sequence%20Models/images/25.png&quot; /&gt;&lt;/p&gt;deeplearning.ai - Sequence Model - Week 2 Notes
&lt;h3 id=&quot;word-representation&quot;&gt;Word Representation&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;Note: the problem of one-hot is that it can not address to the order of the words in a sentence.&lt;/strong&gt;&lt;/p&gt;
&lt;h3 id=&quot;featurized-representation-word-embedding&quot;&gt;Featurized representation: word embedding&lt;/h3&gt;
&lt;h4 id=&quot;words-get-embeddedt-as-a-point-into-high-dimensional-space&quot;&gt;words get embeddedt as a point into high-dimensional space&lt;/h4&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://raw.githubusercontent.com/karenyyy/Coursera_and_Udemy/master/deeplearningai_coursera/Sequence%20Models/images/26.png&quot; /&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;How can we determine two words are similar to each other by reading tons of corpus?&lt;/p&gt;
&lt;p&gt;Take the word embedding and apply it to the task, though which we can have a much smaller training set&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;strong&gt;For a name entity task, use BRNN&lt;/strong&gt;&lt;/p&gt;
&lt;h4 id=&quot;transfer-learning-and-word-embeddings&quot;&gt;Transfer Learning and Word Embeddings&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;learn word embeddings from large text corpus (1-100B words)&lt;ul&gt;
&lt;li&gt;or download pre-trained embedding online&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;transform embedding to new task with smaller training set&lt;/li&gt;
&lt;li&gt;continue to fine tune the word embeddings with new data&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://raw.githubusercontent.com/karenyyy/Coursera_and_Udemy/master/deeplearningai_coursera/Sequence%20Models/images/27.png&quot; /&gt;&lt;/p&gt;
&lt;h3 id=&quot;cosine-similarity-most-commonly-used&quot;&gt;Cosine similarity - most commonly used&lt;/h3&gt;
&lt;p&gt;$$sim(u,v) = \frac{u^Tv}{||u||_2||v||_2}$$&lt;/p&gt;
&lt;h3 id=&quot;embedding-matrix&quot;&gt;Embedding Matrix&lt;/h3&gt;
&lt;p&gt;When implementing an algorithm to learn a word embedding, what you end up learning is an embedding matrix.&lt;/p&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://raw.githubusercontent.com/karenyyy/Coursera_and_Udemy/master/deeplearningai_coursera/Sequence%20Models/images/28.png&quot; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://raw.githubusercontent.com/karenyyy/Coursera_and_Udemy/master/deeplearningai_coursera/Sequence%20Models/images/29.png&quot; /&gt;&lt;/p&gt;
&lt;p&gt;if the window length is 4, so the words used to predict the next word is the previous 4.&lt;/p&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://raw.githubusercontent.com/karenyyy/Coursera_and_Udemy/master/deeplearningai_coursera/Sequence%20Models/images/30.png&quot; /&gt;&lt;/p&gt;
&lt;h2 id=&quot;word2vec&quot;&gt;Word2Vec&lt;/h2&gt;
&lt;h3 id=&quot;skip-grams&quot;&gt;Skip-grams&lt;/h3&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://raw.githubusercontent.com/karenyyy/Coursera_and_Udemy/master/deeplearningai_coursera/Sequence%20Models/images/31.png&quot; /&gt;&lt;/p&gt;
&lt;p&gt;$$p(t | c) = \frac{e^{\theta_t^Te_c}}{\sum_{j=1}^{10000} e^{\theta_j^Te_c}}$$&lt;/p&gt;
&lt;p&gt;Problem:
- computational speed
    - have to carry out a sum over all 10000 words in the vocab&lt;/p&gt;
&lt;h3 id=&quot;negative-sampling&quot;&gt;negative sampling&lt;/h3&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://raw.githubusercontent.com/karenyyy/Coursera_and_Udemy/master/deeplearningai_coursera/Sequence%20Models/images/32.png&quot; /&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;How to choose the negative examples?&lt;/p&gt;
&lt;/blockquote&gt;
&lt;ul&gt;
&lt;li&gt;A heuristic approach:&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;$$P(w_i) = \frac{f(w_i)^{\frac{3}{4}}}{\sum_{j=1}^{10000} f(w_j)^{\frac{3}{4}}}$$&lt;/p&gt;
&lt;h3 id=&quot;glove-algorithm&quot;&gt;GloVe Algorithm&lt;/h3&gt;
&lt;h4 id=&quot;global-vectors-for-word-repersentation&quot;&gt;global vectors for word repersentation&lt;/h4&gt;
&lt;p&gt;$$X_{ij} = \text{ times i } \rightarrow t \text{ appears in context of } j \rightarrow c$$&lt;/p&gt;
&lt;p&gt;$$X_{ij} = X_{ji} \rightarrow \text{ captures the counts of i and j appear together}$$&lt;/p&gt;
&lt;p&gt;what the GloVe model does is that it optimize the following:&lt;/p&gt;
&lt;p&gt;$$\min (\theta_i^T e_j - \log X_{ij})^2 \rightarrow \min (\theta_t^T e_c - \log X_{tc})^2, \text{ where t: target word; c: context word }$$&lt;/p&gt;
&lt;p&gt;$$\text{How related are words t and c are measured by how often they occur with each other}$$&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;How to solve theta and e?&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;$$\text{solve for the parameters } \theta \text{ and } e \text{ using gradient descent to minimize the sum}$$&lt;/p&gt;
&lt;p&gt;$$\text{weighting term: } f(X_{ij}) $$&lt;/p&gt;
&lt;p&gt;$$\min \sum_{i=1}^{10000} \sum_{j=1}^{10000} f(X_{ij})(\theta_i^T e_j +b_i +b_j&#39;  \log X_{ij})^2$$&lt;/p&gt;
&lt;h3 id=&quot;sentiment-analysis&quot;&gt;Sentiment Analysis&lt;/h3&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://raw.githubusercontent.com/karenyyy/Coursera_and_Udemy/master/deeplearningai_coursera/Sequence%20Models/images/33.png&quot; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://raw.githubusercontent.com/karenyyy/Coursera_and_Udemy/master/deeplearningai_coursera/Sequence%20Models/images/34.png&quot; /&gt;&lt;/p&gt;deeplearning.ai - Sequence Model - Week 1 Assignment 3
&lt;h1 id=&quot;improvise-a-jazz-solo-with-an-lstm-network&quot;&gt;Improvise a Jazz Solo with an LSTM Network&lt;/h1&gt;
&lt;p&gt;Welcome to your final programming assignment of this week! In this notebook, you will implement a model that uses an LSTM to generate music. You will even be able to listen to your own music at the end of the assignment. &lt;/p&gt;
&lt;p&gt;&lt;strong&gt;You will learn to:&lt;/strong&gt;
- Apply an LSTM to music generation.
- Generate your own jazz music with deep learning.&lt;/p&gt;
&lt;p&gt;Please run the following cell to load all the packages required in this assignment. This may take a few minutes. &lt;/p&gt;
&lt;div class=&quot;codehilite&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;__future__&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;print_function&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;IPython&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;sys&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;music21&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;numpy&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;np&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;grammar&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;qa&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;preprocess&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; 
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;music_utils&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;data_utils&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;keras.models&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;load_model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Model&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;keras.layers&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Dense&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Activation&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Dropout&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Input&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;LSTM&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Reshape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Lambda&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;RepeatVector&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;keras.initializers&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;glorot_uniform&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;keras.utils&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;to_categorical&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;keras.optimizers&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Adam&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;keras&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;backend&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;K&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div class=&quot;codehilite&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;Using TensorFlow backend.
&lt;/pre&gt;&lt;/div&gt;


&lt;h2 id=&quot;1-problem-statement&quot;&gt;1 - Problem statement&lt;/h2&gt;
&lt;p&gt;You would like to create a jazz music piece specially for a friend&#39;s birthday. However, you don&#39;t know any instruments or music composition. Fortunately, you know deep learning and will solve this problem using an LSTM netwok.  &lt;/p&gt;
&lt;p&gt;You will train a network to generate novel jazz solos in a style representative of a body of performed work.&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/karenyyy/Coursera_and_Udemy/master/deeplearningai_coursera/Sequence%20Models/images/jazz.jpg&quot; style=&quot;width:450;height:300px;&quot;&gt;&lt;/p&gt;
&lt;h3 id=&quot;11-dataset&quot;&gt;1.1 - Dataset&lt;/h3&gt;
&lt;p&gt;You will train your algorithm on a corpus of Jazz music. Run the cell below to listen to a snippet of the audio from the training set:&lt;/p&gt;
&lt;div class=&quot;codehilite&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;IPython&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;display&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Audio&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;./data/30s_seq.mp3&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div class=&quot;codehilite&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;            &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;audio&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;controls&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;controls&amp;quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt;
                &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;source&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;src&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;https://raw.githubusercontent.com/karenyyy/Coursera_and_Udemy/master/deeplearningai_coursera/Sequence%20Models/data:audio/mpeg;base64,AAAAFGZ0eXBxdCAgAAAAAHF0ICAAAAAId2lkZQAK1EZtZGF0//uwRAAAA5syzh09gABzaYlQpJgAVH2PW7mGAAqFsiqDMPABAAABeAgEkMMC+ARgHYSMTcXMQwXAuB0IYhisiMYNAaCQYCQIAiExz5nGDgwEgGgEwPiWZr169f9/YODAwWVXkgmGCxYsWLHH7zM3bvjb/zSlNusWOUmZnL/Mze/4vXn6wcDHy4fLn/5QMRPB//esHw+Iw+3OkAoBAEBQ6EMpQgFAoJAsmTJ7BBDIx7Pu7uI73d371ojP//2gwghF3vaIiLu7s8ndxne7u9///7QTJk09aMPAAAQc8mAwGTIEAAQQc8mTIECBAgQIIRd9oIECAAAYDJ20GQBh4fwADw8fg7MPDzw8PDw9ANFwWVtkAklIpNCsasqzbAo1D4nJCmuyFk6giQEmoGss3j7IIJKodGBYBiEIrjJxPP1KZUYPHx2qYOHh+cPVzvr1p/cSmzY3PmlUMOvtVgpe2D6rg3Dt/5h3eu8za9IrbSO7bU37Wq9t3/2O23p80lZ390v3nPX0btq++f783vudekMdt3ZvnTN3OfnKUyemZmWVs7h3z8P5Xu9e/d9s+tL98NFyE6DSExGJVhQkmaYTEVKWsMY7svYey983pVD8JQ0CkENZ3TG9gshYIaNc84ouULIXMwocry2xnmqdSO3N03tifUKlj3eU/pPW8GSt2tOKiHSl8/Gd2+IUSLIxw8ZhN8KnvXVPnUuqYy5zQrNs38O0dzlj7+MfGNa8bVcX9/iTHmmxmHmLSFA3nfxr/X//+t414+tb+//5oyvcNQnCHae9fQCAAAQBzM8cKgDJYGnUNWaupjbRFzuK3RxFK4DzUZMTUVD/+7JEEQhUdV5Vt2VgAICLytjsLABSlX1STOEhykgtKqWkojANGqZmSh0nifZBm9popxrFiu1sWx2+ZZ7HVbVfO1DEB3RzbX9sSekVk9lnmsZ1DeluaYpE26KY+KqaZDoe5GVGuVfxJ9G3Wfr1HIubHbJe7u03XGZH14q2uPL9uKScdpRxD1L2ulirASJW3XC4EgAQDAprI7ZfEbO6EVZgtmAV3N0VkaQ0prUuVqI1A2RySTmDuHSYW4iwdKzW7Ty3mW1DodEWzmj32rbrlm9Oojq+YYu00N62tQZ7k5ljo4iXQ5T3x3VT04/LHmFtRnmHtOS9et8Oc9u+o4bNud/Bs1fuW+24e5c7L4P1tu32i4QECBH4MdoKJI4gFQJ4oRrCEhnJRyS6Bpy8soXpH107gFejLdIQmMIBS5cmVaPNZIPwyE8qwqsvbH6yfWk3nZlcSJts4O+8ut8e1pdpbVcTLqxpAaennzzKm8S1PPas/1n5KNLJK261fcLaVTt08jHJzTXhJ/7Kau5Sl1iT4bH+mG4xRLqhKh4vroxV6z1Y4oG6PG1fCAgKIzmgZJICx4eYwAZAShqXSCwRoJWGWBL3pGqEK0zbBGozLQ1qlzg4UDiZZGBRKyYaOuJQsSl4yKFybq6htJJ/qSL3GUKSbWEJA3sdafGufTOMLX8umOME+sx5YZFsW2qaLbyhJUVS2JmXriiDlMWLRqq4xqn1VLEWqusD4pNi33V1H5QbcwUYlzjBgIhqkKe5AFAAAALCCciZDy+CQ0IfDQhsyoSAQeDgsoW1jDwarAYUGhwYgnLtqNF1VmwG01AVqBZE9DJIhDN9UDP/+7JkHYAFbF7T42xNsobLqt1liGgSOXVXTTCxggssqd2njfhcn2mH04wuDdNjmLI/PWn5yNzoCOV96YjVozdOXAfAw/LLH0xDJ16RIv+gVy+WP/ocyipUmjcUOW0a92dBHF8Z3oid2tMuySFlmmFW6tWP0+2ts24atlsKsVKlBNLkKSz77ClaAamGjSKNVfhA3ZzTpjcgJgwAiW4ykoh4ZYBqnKakw4CGERRJNB0Bo9F7Yi7zQTGEc4yoGyJMKx6Lkbx3z7Wfq6AHVHFGci4xrzXtWyjDUNyZOJqQwCo3eV5p6ylr+fJb7v/4PpveuGetS78bELD1ysXwlwuP4dagW44quSn4iHmyHHQOnxCCFTZk6IqbkSkHzrWtQzoAjA4pyNpQ5wcWlpKlEITBPwiQSixwDLGRsTBIFOZ+nwnhYe5tZdLPSsVyYXgYPkYyD8seJ69iyY5Mv3ENPHLSilsO6TAkpHndDc9W7YJTWu5DeuNxNyh+YW1ID3ZqqJBk4qVSk5AYTSzYcbU+ioyOLPcXMyuLZGvKtIk6OR6lMZHEzGGiLMgqDOhnFYMHboSvkQoABUgAg3GREi94CKOKKlQABIQcJdUOWJXBQ0nOkmjHHUbZw+g630hvjxV1VyfMORgmZqN8RgjVlhaxBxXe7W+L+SLCzE3My7pqzcIGswsK1yrAgT1mqJOQE3DbKBv4fCT7f+6NfKK50u1OoTRs96pdW8jZGh5I10hZqcXfChSWqxhBAwAAAUCOjlow4EjBYFMJAcwA1BCVwQFkAAUPxZMiK6yDFSTMdkEmLpoGhes/7iLkLBFlBnKNJBvviTAXkBDWzDL/+7JkIITFjV5Qy5lLUHzrOmNpBahTQX1LTeUJwiYt6U2kjpiZtSLIQIqr5umz1FiAcb16s2o2Qt/QZT4eQx/to0mjPOkBTF10eQnFprZkCLcFBqunJE3/WR1Oes9fypLPJNF5rS2gfVPbDq34xhJluXx6cbMquoijvXqVxqcrdBSeOnldacgWNq4rC34UnDdZNvf8mADESmZx0c6uZoKRdQUBEhoQSfJZ6HAwgFM0u8iyMhHYigMBw5EgcHeHBw5Y0eVyRur5yEEQ9JGGsC4o+pWIFzel/9vmtJkuyg/AQWiiy9oNopjP1VNBhWnl2lzfo7PsYGjHPQ5MyPdCtEeZzPOab1fMwrW7uQeK1hrx68GgIQCW2nTcssxocAAEYISkZIjWLFQWEzGRFEdJZaaORE2GJk0RVJOQBjrSFEQuLBL53Fg3dhqCLCQCn7Lvv5L7NWGmm4Z9oKDDssNtMHxiEEZfzMSGY5ESoxm88qMyQqtjIhe0I8SrWyHQ9zeWs/C1BDXAfPcMnoPPrbn6n2Gjolk5m+Zn4H9u0rDlxIh2bBQ7HS3f2Pq9YariIAtRt416E/ho5fU54MMLgxAFgAhDPgvoOnqSWiWkDgCgK5BwSrS4YONNaxjZMEZxI4nSMekQGYihcQNAuyiWS/mbLMdvaSq6YQLmVzJukD1aFPI8/y4DOKIv0o8ueC5m0h/S89laHQBKUsYvjQfeauRRY+z28fjufSP6TExmaAWKIEKgHQIQxl+XAgAABK2ScyP4fEiA4cGQeNua8xkICJhi7ESYpIAANNCMGACEDyCSxfldRECAILlkVit2ZcJ/GHqfqyBhUEf/+7JkHwQFA2BTU0k1wnwq6jJpIrYUTYtLTT0vAcKs67WGCXycFAutG/sCWlFfyCXpEt/cmaIGt0B4IqX7f8CdDBEDO0kXRZJxMQ9RRvfU9iqOzuyXY5s7bz8IVi5zCgt24hLO53xyFzzu/7Z/v5bHfn4Rr/D3BJRyWIq4W9uLj/rXkBn2e2A9tnGqDB4YFABEIxCgQCGg1CtUdCmfDK2gVCm2GKlhmUAEKRAB0e6y26sEKajoB3HcRkY+zBrPaWUz9JIVuXLmNxYbhNj9e/3STxN3627MtUkq84TtvObejdEreroaSWhyPlOVgS1U360Tf/TM7ejb0Z7yPUzR2hV7Mh7QMAAnY5xF9NUVCqo6ic66gWxCxEVDCFkjkpS7QIqAJuNEUG1kCAEYpRi+A9nSVj4QRlUigOEXyj2pmdxjRn5FQ8VrBcssel+fjihhFlU1dCprNUqshDZ9IhzBBtxqKcPhhLYFUtqdK9ZRp3Z1j/5WIo+Nwb+bHPuu4w//It+vv6V7tVe5d8vca5WGZsbIrEZSmyIGUU9mbYxNDCrv7Umz62QmAIiCCI7brL0agcdXyAdzFZUe0hZl0UmLgFTswDCIllBKHjksHh3FYpZyI+RMFd06s7VjZYOjDsvMu027g2BsMrNUSModU1laUDVlFG3U93/mUryv0REU1DlepdTI+K38yHkvq+nRdmJ2qU+cSduU/qUAQAAAAmRxOmOfQ0PgUaMvITjBUwInEkdHIxUjUCHvvoAxGYJPctMkYYGO8vtOkeTaaDBy77NKytsw8lblG8KBb44kEliIctsQFZ0T0p+5N4WNE4ruHuvE4o+gFtf/+7JkLoAFgF7Sa3hiYH5K+jZpIrRWTZtTTT2PCpEwaqmXsOnkqL6+1mfCeK4HziP9XOfNeMKezky0tVT9zvdY+LtT7Sy2ZxIm+aWmZUWrrSLpnbz+P/NnHJ3rT9az2wNcnUu/v84w6uWbIzR0vyOOdfgWYizNbRABVLZxgJ4ZJyjxsZilY0VTrMSKhgkCGkCrRFRwBDDg9ucAwsiGwAHIX3wUcUBSVvzI6CaA0N0pVPR6WWwTEh84fjqJANHqOZ4mqZhJPCtR6ztIKOjTPzoQWObKdNuvprpRXXMRrTyOtfvk79p+dXUhKz3apxBNKYgf8umCKECEBAnHLLjOyQU2C4UyRwUMhhRKJxU6VisOh8KCBACU0RJZg5UPYdAX1LMZbWl6n3iFnhZqZH1aMgzZMaf/2XT5+atx+VCOddnP9rxEWWHBxf83m8wGDmtqjydchvM2KkSRRamrUZ5RO2vjpm1m8Ql206LN18axfcntVzbr/1pm8rzNH9T9X0ysbpi8wo5aulyJxHV98lm7Ma78Xg4e8SAOGta0vSSoWH76xed1+fmc7IR4ECgBSbWThyQyccbgCdTOEJi7ASS6N4Cmii6HGP8uze2G0kB+uupkcwRtNEWsHXvBLbb3uzmnraiy2usN4nplat5BbfgDxbGcOV+W0ZgveZMFlkhIUMTzcJ2YIZ/v7m2Q38Yu7MrHJxQf/FByyjTkRx/L7Zz6/exmaX/3Msvmar75t0/zq9+7dKcsSn9NcTmac8KhZM6qDNfR+yVWyeZFxKs/8BYDJAC6gMi6XyVVLZkUmjJiLoUWkrhOqpJiKwsb6rqlgyRxHOm09DX/+7JEE4AEil7WSwlE6pcMaw09iV0RtXNMTKUUgjetaiWWIpkxllYcx5SXOEy+yqJd0KMb9ytWr/qZ8Vm2WNQklGr2E6cWAer7cUH3VispGsupJ6dou3GROMTtTIFcTNJK6wbI9CB1vRsjD1svdXiKVWaXDpR9OsHW1DTA5KEe0IC6Qhw9VEIXPOUx6f/WgREUDA9Y4kaBUCDmeGaDzIQkwkwpysIawAToWzfCMgwmpJjOWjB6efOorNkBCtZIHaYqxpTN5RgxntmeJVX5TO2umsqdh7lV1saVVFIm3WYmG6bRI8IN/qCqCoSX24qT9JZXc7VtFO1bOSs8mxpRmWazarKc6q8q/l7Cr6rn3/WwzE4oh4NrRWRsdFT20lisvmZsun7WCEJQCO889E1/GoAbwRhRr0TsAodQmQZMCDQ4USDQlKdjoliPJnp2TckXu605xRfbeBllkmIe9IeTTxiGg9FC7wOLVjtc53J4HSFO/vrzYLleLkqLog+2efgQjbGMVc40f8l732MGtfXFMNeY6daWExsl/NfTMRzcTUM8QOGbINEFrNMYQ04sYHQbItHjmdIEgAR8gxt7gk4hRD7wAkkIhqmOW/SWQXgNQkva5SdD6ts90QU4T8ylrUGMRqngyTrUBk0tKJ60yqI16SxR8zUQtziRrWKQWxc3jUwJZBI860rrgRZhxs1MlTA8gfUd+wkWmiL4LT5K/4zbbji5JlOqjqk0UaneuXVufM1NDl0SLmrmCzmHiEhfksyvFv5aGE3BNNUFAEWA6BJywx4vR7SUAFyYI/dXA245UKMgKK5U6ER5INbEK6V7IGcOH3+fBkz/+7JkGQzE/l7Ri3hZ8IJrunNp6FoULXtCLekJweyhaQ2kjqGXaZ9mJJ2uzeNQQR6a6HuXKTUf3cHnwkXp3aKvaqCTwVIS6UPWzcrUNOu9Y3hRqRdUG1/oP5jr3VsaTau3TK5KXZZ1mivZ3N0mxvrcfPt1lWW20XNan6BOqyohlF5ldRio6U3QT31MV08tlbHoqAciRKBoM1g8RxzCkR4OYAAj+i++jdBIiuklhex7GdYKg+jZEyXpanEOVnfics8xk7mhQLjZeE8a4njOppFctpNaR4uw58JgGBWRiwtko9iy/pNYtV1PNc7m3fKPxcb2Lp2rJK1f1Net6d8of8c8LPBz/MVwNr6j3EX4YfETHjTYV4uFJqdEDvgcVjpSg48pC5ARCxIWBdWEIWAQRd8yltm5gwoZeT/KDQ0KW2gHMASjT5Rl+Ew3DS8YOkUknXeGMtKuvg+6LEorzlWZYJBCFvxYREYZ3sOrMMigWiarkVOnIKNuobm3elGCPwdWx44PsesDoKJrYVJokedwFDON4xtNWM4hx68HlJndxDJcSN8aKVcXDTihsB2dcFGh1rBpvB7SMVATgJBMhGMquSiBqBI4hUJvl/URk9gEzLfJzK2l0GyukWczTvcxot16U10jIVGVUVOXJBk1ictZNH5tZ6bIT70ttNKbSGSa9PnRyVigB7jUk45jtRRt7Dl8iy/SVyT4X/NGPzl+H2OdBV3lYzcmtb6XbOyL+VYxOCrb/+0ARDMTIcx4TyQuBlAOEogz+ODCQKMDgYyGUV7D9gICKHwBaISjqYGHyVweGEQYiMFt3UddT44gy9XAVCggBUu5A7D/+7JkIQRFaV5Pk5lacH7LGiJrBVpTSXlLrbEUwcMe6d2UCqHBQBiUnjbAkFc5ZanHgMhVkZ3kUs3D6ZblFjkEQ04JZkbcHb+CSbPUMjtUsbO5+5fPSq5btPzUypzKR/s7VJE8lL8Q2qWUtzmP21UbFmyitfE/MOllUdh5pdftcbEgqtaorcW10eDZdyx1lAANOLaj8oTL0QI/JlgJShjECknDQ7gKUJAQsAwCA1i9SVRVJPOiT5ZxbTLL5IJnEgJrCMbJ3+jUpksfpQgCjBEIvODIDuuh1ZjLu91KUWevRH6XWqamFO1amKW5XUzdlSqQaIjisphMkx1lRVjDr13b+VlQxvZTHFRcwy+UnhIAgIDlkkxhEENJ4FGBEinGEBjYiChQuQAgVrCRK2yE5QTKgRviI0gIlPqr1PG3fjjIpBpnkOKBgM+MlFXGVAzvbseRKz1XFPus77devAsdk/NfoPrPV2f7EgnOCYcZxTaZQgUggTxIg00ljfG0/kGXM3WMLNxk1waWPkeZXmkctVSKXHEVxfwxH0sLtDW4la7IH2i1dUOOrrfHiAKe23GQWa4ZuOHmNOBQuBi4ddmIcI56u4FVUUQd5MaH2yKep7sBw6tu9dZg+dKC6Co5lR0DP7DF1/NdRDj46xWJNCkMWzuroLqxkVnqqSCeNbIR2Vu/MngxDjX31R138VM6w/nH1QgrX9YbHulbN/oB263877w1IRqivQi5S/ZuKBAVJoRMHDRcQeKYsg8qkHKtClS3FMsZybZnUnfirpPJhZm53igjJqu/Z4QojV/+rVbXzra+yU2pgK7vrdrxHXvOBd86XYuuHlf/+7JkLQTEo1pTmylFwHrpCkJl43tSuWdPrTExAear6U2kCpQSfn5Kdhg0+4c+/s7ou5lQ5nqU3Vzsk2O6u5EATJyi08D6KlIk8WqFPFWyCqYUBc+aYIY4JtERDKq94TpWZYhkSHKcB6EUwsoZJCPosGzAHSqICjqirAWet+WeLUaQ53S7Lqlicn23A4mIdpxOKrkXtvVdLuPn0oW9qrX/25E53haXECW8BNiUEJHLpXLP43mv7n8hZxvjll4kElxcMww5iM09pbQecQdjoZ/IDwdVW9zOpP/5wBQwZNttzgASKUIg5liJO2FQiGaKwqHi5daAUk13sMQtSWCA7buk+7g8RWglJzRPQA2NaPF1rWjtAnJzlI0GRpMydPTjkGbJmXbbnAVNrzqms8ESX0Cn/UazpctHZM7/FRT66b/Bpj9Wqm6G28baqsrp1cKK5P5kNpRnenlfF691WYm6/NG3lVOpLiR3RCyHog08Y6/vIDbSMFIZpCRgEhkR4KFAUYoAMAn6Z8JB2ptJViSvdyG1Om/fBEaXXXJUgolPW1OoQ5YTg1GHuwognc1Zag5PtvicBGdw2sOiiAIZEYImpyODDEQ46PmF0l4QjGZWkPRI3agoKzkLgvYbnax3Nt7dO+rt9RIJoSJl/0UAFJJQ+keBWAASs7lJOQaDIhoOFZsxQOL4kx63Qyw2JQhAsIIygKFqpC5mQs8Vk2JprekBGJMjSpeQmEw+zG1oPfbg1szHaGns6qaibFMPZu8UZVn9w9ohQJRUE5aUEv6LKGaLt37LevEoObNaUvA0r9QJP8uxV3P9pnZmSN97tfrU65mpVdu/yX7/+7JkRQQFNV7Pm3hLwG4nuidpJaIW3Z9HTeGFQliyKqmEJj2uurfvrPi0dhcEmZ/tSpiLrSE6WRahXqDzQtQ7UEAApFlwzWY2Ss1qw1iIFTASbBg1jKeSg4QqhhcgkKLioBYNjyMTxjw94ew6wVrUCxR/mOuKAFNIhGcpWWEWVo4KcjaEnbONuogtpNz6IQ9S6099Oi4mtqbkIjHJxp7KPxV9oQe9DDIqHq4BhZ2oBIFJFx03KPA0QChQy4iOERzEBFPkRgRuboXtfQPUt1RlVRLdxG/iKsTKzh9UDdaXg1QxUH77A1HNKvE/9fbQ/O2DbplLSS5R2Oaa3onHfLz8tn98nrycHjFa9TqOZM9q+Nhjr7VS3ZY5WP+V7NYSXH4gKIyQQjRXUqGzt7HKZQhmRRpp+VBY5SGPqZe+Vsxz7mVXvyT8o8cON7DFczA2YPhIWFCuhwcKePyWqfs3b5mmfkWdp2/4FwgIqNtvBA0JoMGGBbqslBO4qwa2VecbJL4NeerYkUdpNXh4JVgsTDQhPFbSlsynr6al/2suURFtHeBAAUBoYiWnFFnuKZrvbz7wKSLvCX6UTRz1Gg/gl4EDPXa66kILEl0UQQUYbyHX2Ot340jbpOW5OYUdyhI5uLd5AgJIU9AyVHyQ9q50nnamkCBdBHem3tzd+h8BBglmM0NNPNnHhCkuAcgD8yguMg4JK4mBgYoDiaRLywlyc2Gh0imw2O1hFJZunY6Q2L3huNDFFxBO61ZWHcl7zr933p8doKeLX6W8ur/uSisULEsARnmjkqHnPIwaYhFfLTRNbIGUP+YPPnWIM2M8lecBQg8PK2b/+7JkO4AFZGLX+ytj6osLOjBp6FgSBWtIzbEQwcmv6iWECmhYIhW2hcJynXyVzlTp/MWR07W78zS/6dqmJ2A+vSJRVOSiSt9CCWOYJU2khrHP57vzW756wlNo4OCeMOJAxoOpEIyaCoJjUUFgstL0gEt1SFyQ5ElpmGih+qlzXJVsqFDB5hAykGG5npQl3ief+EuOx248eEtFM19jzHGBkBA3xAOm9M7PO9a4HMyWXTIbexXbEg2yiRjXuZeIhtEpmKSHAf8i8Pli30HF1jAPQ1hQfqaHrtZ4iXBED1GVgsAwLV7hBFAABgMSSiIyHAoAMLIB0CSGZqwudcqaJg5ajhrfvorz0fWY/yRxsSQ/UmqoKyl1CrB/k0gQ7rpWHiQ4cvCPOqXAcoOiCSXE/HMXXQ6MVBr3llrSiAJqKhPcJRPDrTQNEePFj/a5UOw6nW34FRZopE1SWgQDx0NBNRcXLS2LmxuVCDIFuSQt2RBFpAJUNWTADZAX0CYusTUI6pIoULDKYOfF2xJrw9MyqKNbfROWT6eXd2UWo5CBlxQPoGv7IfDfbq91c8K/CpcyS2OCUZevXrzinVtTsVWv0Qs1Op+DfYoNLKtXI9iOsrSXVT3sq8+68vdnuYSQgsK50dJBR6glopqoDHfbsmvbaJoA8EDGwFDCZVYZgDoYr07CEgPJ/vsNpL1s7GhY6gcFNTcN3lqcIz1/saJhjajRYwD55B76eUzmMJhgPyvRB6OJFfZSipVZWN1QHYsyIUrVGjks6Sux3bOjrcp7sabLSSiMdnXU0hXVk1EzRHKCrNS8tSrXM+FGNUBoABdaQAQi3A4shWb/+7JERgAD+17XaeU1+IJrymppiGwQJWdNTKRxigouaamkoeiACClBfZSlBEq2Qq04iALJpSMSGTpZLKmBeuWR0gqwMJvT93gYy1mo3/Tx3WUZXcVlXUDKo45xgDhdOavxh+0it9GPQsuOa2qeZb9p9a+RWU2n2mrr1a2jluq+qSe2W7iYZ5qMW5gfFfY0hxCihy/LxDY8WW2kDKEDLG0Uz7jJAiQcKpAZ9BteYgGVul0CtOQartwhmMsRpoIaXDSSAnI0ETh9lV0yl9xEKVkmKUnM5uIlgWuF1leUk5kNdwgNTy5zyvKGmC0BATzWJqZ8c5vOS3yOCoR+9K/c+Gc/M82MaGpQ1KV9T4mV1UyYCHDqFJggqLTkw7/2RfoAlbjShnYZNPBokGhFZVL1cpDohJpJzzCObtpevvJVQJMCURQRjgiUiswER3uWj4AsDay/5J4lkWxWIm/2tRsdjbuwVHXwXz0cO6i52ZYoocxT+82O5aJlZ+B5ax/BtVHM+03TSvF3xQ6lX9aXWSaiE777nGXRax2IQh/MDwyCPSoEoDPgFDKQwAIJngaRSY4AoLqpgwvihMNs5GUceAlaiYSgB6TSvsiMz2agajISwBHH8yS6fXsarzmFNOQu/jrU00FCZ/LShomO4dGyhpyA1EeV7qO2K6GjmgTCNUVzVIlr1XDEdcXtj9Rq0wLmN0hLlm95Tg6+DovKf5uPmK6tNBnzip1CALk0KjDlYSlfBp+Y+QAESQRBScRAQMufBCiEt3cTQQ5v0zGKMVeRlTYH8vXoBsXWnUhzBSr0xaJryczHQjV58lV3+yqrIbKguOA6IUat1FP/+7JkaoQElF5Pk3hDUGWGin1gxYcSrWk6zeUHwZYeqKmnlLhlWYx26iqVz44o6LjKlNNiQSDxjZe+KPKkuuDUQu1lXCNTqQQ1Ucf/gecgwtOFOyoaGPGyJyWxzaCIUZEZsBlBr4uoiyDDCBd+GXjxaS0ugacYKy5p79UKPDL5PAMfmtg+GQeGsiqYLjg5FJcaTSCIGZYaaPgXQcgjTORbzoLTYSH3jCkrYe3i0XEMPhcimjv2M96okRaiIXvNS+Kn0m9Rl4nj534j9G8a7c1E4uFh3ZRR50ieFMK9AASQANJJOBbQZoeZM4ARAsNZ8ITMJBCCvLGbhOSxqhoDjK0w1WdcJ2o0V4KShLsMOEDlvBrLVxjmGLGshSI/LUqRJkquttPf47v7JX76duIpULC9pFwqk3DaspQnPEA8Tg0fK93ZBEVz1q0fMTDiAwgyOEHUiAwMQzMLBg4CHi17DFTUMN3UYeiAEE4To7xZCd2kWgOz3BdFAZIxlpeVLl4r44KXjRYMVreOWfLif2nclk3DSNgIJN4ho2Fxa5Bmqy5/cU5X8odEDKmvG/EXXS4yRW9p7gxupM/etLT6u/445vHDK3PIuZc6BFMHIaTF5n4ZaD8eoBZECG42Xg6c0XwcgRqqxjBL5IIkL4WE0aALMnLCoESXsrFKMxGzwziu4yLiqiZNtrXnqd6ZXIhC0CukZF2VJGcpXRuZw4pL6E7I+r8mi3or6q05NE/sun/V9fbqys2dbUZVGCmlFrULqc7WCUCBmnc8LJgRGIaNRWczBpVhQWEJhAyoqAAFlx9FD8wkUossKc440C0UOEBAEekM0hmqVnX/+7JkmIQEhFxOk29D0mtrOipl4kwT6Xs2zmUJwZar6jWEiewJhJQMoF7xw1N4PUo0jjhjK5RGhMaHQPHY0eH7uKv5JdRYoVAWdribnLoewTyPaS3eB6h6OLKr5IN3yfsivtPGtvAfj5Sv7i4kRK6qeYq8q/jT0+R1eSPuO0HMHwmO3AUNpVxuNHbzaw10hGSxpq/yRuYEKDtFr1L2TQlUzrAwLOViOG01xme2IZdUOKDhFIhidy/EkECQkZRJ0AUUNlzKY02+aOVSZfbn99Lmc+79ENUnMbu9vr2Nq3poXReXqqUT+VTWfnf3o71Xz4lWCZmpBUByGFmTRCKlAYCRosTAYFlZrxmZEpErLbCc8QOyTYRoESItsmw4AQi28ARehGA27vy5z8qtHYWD4icq1glMq1eYIsuIPpPg4nPTlrQOo0sX12h9lJ5itFrLyqva9GuP7VL7nq+XV5i/p19IuP6l/JdV+TW+yKbrcqdatP54zFsKMVhlMp7M1IZd6RSnwmshqvFE5gDFWnLLopTlPOUQRviRiRCOylTkoeWm9lALB8Vw+gH0Yl5KOK4qoJD9YrPD8fnFRAt665Eyn9G8lbNqzKFHo+OObXoYzhc4+aiZyK6CSa5U2mSDRiv8zp7VvQ989e/+3f5iI3M/o2tW7UIZeRBFIBTWvIFeYcRGnHJuB8YmWK3koqI1LfSKSWPiiaSt74DjQVhTyqj+PxWb+HmcPfKXdfh6Wm3pdWqcGg3AMw0vAbIhog/YVm6qfLhcYVZ5Q7PkzeRccaVBk8VX6h4YKVPoPHxTXvKT6i9yKCkuIANEGCgf/Szue/s5+iCnC9z/+7Jkv4QEol5OE5lZcGxLCjplh14TnX06zeEHwZWUqTWUiaiMFI6eEMWRexpQpwq3B4Ph+woeJ63k/cYZajKjlsPgAiIAhRpIos1LVh4FL5pmuvArWFpxJncNsAd+BVpC4skLnFi5IxLxiiJ4R2PXIiOFYlbIUl5tWVyd3OEEBzpvtnFnas/Pg+H9Cp/ghQVNgPAY5xdrqKyEu9psMIE7JwgfEAfUcF0AAQAAAtREmH3ODgAoiZKAymsdpLCS4tRikCg1JrsjjVhEhKSFOn+txTOgaTOqK35+tarbN5cSbg7e++/Wt4t8Zm3I8vFYCRjAa1AzsblDcorghSMNAqEhTZwt3vNF5XZOkPc6Wcp9Ib9ffpSU18apRE0cIpVz7EDieOHl79cTtOfen2lzX6WvRZf9JDlHrzAhsK65GhAcEBBYMggs6cJVTTtTeJWwtvePBzmwskoGYUSkm5YgCzHcekgPSYBgWHMsSNYnLm9iKlWNvKkV60WbOY1IYqk+JhLxSNVLFwY2GQ84UvsE0vp0WenFATEptRkSCgMiaTYHC3f1w4B0LA7KgNFspkv79mzeChretvQ9vVret7dr/sGeuc1MwYN4h996LG3KXO/vGnx9ZCsYZbcWKLWjqfVfsJdWkJY+hPnqKJI8UycTGquiJO+6qWWSPzz7p4vH3qMbEHfcVdnbaJhsChoywiqUGlLktDWAybVlTsoORSCniismp4tSI8QCskoVzOCU1pDGMomL9YjWWJ9R5iat3V7RTbztLxR+o9PKlKcWwsvsHzVWu5ympL/saB9T4x3CB7lUZjQ6ck7ymdI9mcl16RlKnnkVynn/+7JE5YAFcWJRay9j8qjsCn1hLH1QZXtRrCRxwiOvajWEjmidcYSB0MEaxn1aARiDXrUAMu3I9NGilAFBEtAtrg0N00kIWqrIImuZ3XIcWBHwXfLY030bvZW3qFEUa4UMyKJkK1wM16p7ZRp0N2ql3L+YebaaiiPpDlw3xzI+6YUBlKg1Mg67T+ghGRgysieEPmdBjhi7/BquJd+HPdIS59ImYqdUTrW3SUUHQDQBCKBkSm6ggJiaY8ytSgGgWtgAAAOegDpIoBMqbKoIiGq+ekqjm+c5gJKElsXhcLR+gR8WbSyA1qhj48CJGWABFopgXbUslwG6NuA/JMbQ5r+mp5XO++yh9waOYLClcH/yJ+hhY/6ZpGg6vl14wsNUM0ubFRF8sRXtW1BqNM0MOtw6mthiQubjTbflOyVm3SeSRCvEpxLQ23gkvZoyv44Mfx9gIx9ac1wRICBHlLRCREpXrpIIEJxUHSF6X4fZ5FINcfZyHdLBb8sD6JI/naleZEzzwal0d7DF3epi0h0Vr72hy3fmnaDcIm1fPspZn56OPvc5juquzTkutco7VWqzG52c70v3zeiPqSzkRVPdkfj5xrSI2c5OcWNi+SIb5ljVCIAQElQSAmWEjLkbTPlZK0xmRgxmgqqsg9CgyR1FHUDZVHLtEvCxJ4m50KZNyvDGWMvh9bfqZP6VnEUDzL067acZo9La2DxpD3usx0U3xjIFz8wGV79x231L174Gz3KQ49sH1xOeS+tW7W5PMdqt3PhpkWHx1+PROZc1I3ymet7T/fBxj+rUBvm1rM5xbZdOzFz7PpP6C72fGdFzsUlqABhAABH/+7Bk24EEpV5Q00xEQHnrql1hh3oUeXk4LeWHwfOsqDWFjfiiyACH+AMQooJgWTSHMzgE4BEflizhoc1oxaSxZiVIDpHSbHMRF2PXIwoKJGyzWkg12vhGqUqVurr+OdV7rtEnFqbUGzCNU+gk3CtMz3ZT4h0YjPn/zgNT1KPzNqRW6VSbNm+OXKRgp8PXvrGTwESWGCoI1uaeRuUqBASAAGMbwPD0ADwWDJi0arlEgrIzEwGDBSNEoMgKgzplmk0AVKQGtji4YQz6MLPqjIi6aBDkx+A2PTthpUx+TPV+U1Wu+MOvHFLzsJ5b22K9m1dl3VlRoRRTKl2eOWltENuCuOx37kqj8avMK54+9d9o83vlkvn32fr6UOGjDux7t9O718hlCbrFJi9HidyfYxda80pU+PpcSnHdums6k9qVpievSw3UaDT8S9ADgpBBfxgzukA+wGHMAUkKHSSJIWNBRTJmHKaMRTIeaAobU6o4AjDKpVTWIC1bgymn569Vm8fvUbU7eHcZdTmlvNFfcXUlVDOtFchp/b9+//ctd/trZ/ubmoLQKJNPqbIcPEqZUrkdCr6TNYxy7f/xvNStR//iCQEcyA1CvTDe7oESSqkZPtmgioVNDLwo6sUBJmgyYCGmWnSawkDsCMXI1XJhFpyICIod1W7Iqt3iLQpxpbEZgvJWYaA3R6bNfYiBhLLCOih85V9uoUOF+Lumiqk+6totUuTf/rJfvFpTGT98MjrpXXde87rONGmWOxa5u780xao3GAKkE4dCq1SOJsQmbnnQWq4JWuO+Vx3cLVz+bcZ4Rj0OHmplHPEruK8qAeYACE2oQP/7smTqhAVnXMyzmWJwgEtZ7GTDxFQZcTUtsRVB6K1oNZWN/AxM8DfCqadgEDQEETbagRt5FWMPbmyaBW1zaYZpCDEU8Pxve1CS4b1lDV1MKxBTN0Uvq3Tyut+277f90gHT6h5K26iTXMtLzz+t88uNrIR3P81r7AhcC1ekvmsN/mw98qUaH3Lve7G+XfZVgahWDSA0A+oBIEA0UkTDXrgO5hoONoHzNEZY5EPI8mAq78JdLAgIxFB1LhPYCh5jY07Kqi+k/H1jV1KeUyFSp1JKnjPw2p3N3pWz5h9fCfzjCAlKHPzrcUtsv9KRe7Jxa04aLeQ2aU05O+Ul8DzlpMzms2L6v7xf1o0o8usRf+eVhwnh3M7MeTy4X8okVdbje/xvKVftIob79eMvn1SHVunfoUKRKIn4KWFTKfhvt7jbcImct8gEYAGIpElGdTZkICODYCDQwzAQAHBKQ5hBVpiaxGSgkDXeCDZkuj2MvRUM6iZsOcJXRDVX479ujeATkCg87BCOQWQSI7IEWeKo+/U8EN2sqnHxJHxgw9mFWQj8TNdy7n6qZHZaCTzJsyHZjNWtDaJ+rdK7KuiEjhsO8ma/sAiAAFQGO51RJ+MDNSqSnnE5iKkYKBCM0MUUgsEpkBUw6TjSmAyZuDlWU/jCgJpg1GsG8q/JQxtoUURCShXMUCyeQwiBpl2wZ3bgKtlOl4stSzMWpXTGuHTSK597EpSxX4YaVlIMH9QwhrMryl0+hli+Ks2WUP5dtH01URTmsdq+0uHi++dS05vRYXH3557K62jyW4uv293fPYq7+KeM12zT0CofFLx3ZdtazeZVG0SIT//7smTuAAVvXs1TbE4yfOrpum3lahZBeS8t5YmB6KzodZWKNLwjpgEgrJEU4SDESBkEjY5egtaPAiI02wUxhIeB3SiW3crttaksPOmmTD4fHTDDc4uxTzEdwGZcm00XIBMt4tF+8+he+p5tBx4trk1v2sXqIXDU0e3ybSZLdKMtAgddn1BHuL4m0IohEZO96qri3cpT8tAEMfHJIcs51wBP+VRAeELiMTR8q+BoIiIWqG2nA0fLVEBZuUmSYVQDjNfUNtQuVRYcX0XQ02QRgIGZmhNKwkTG8kUNJ/O1P4JYuZWn5OKsRwdm/ZJJmVpp/Sma+8J13IQsdj2ZzHylBywaWNwqN0lbCWJcbr0vvdMvNzLTXzNkOcd/niumexM/8wj/imSEYWzYXZ6yvtTzW8F/mCbUSLmH6p0Bq06zOsn6KtAhMLZyOIKBAodpONcV//+gCIABIQMxbM/xoKmAuUA0U0gMWBKZmYOoKpkStoIGFN6SA2xoBJO3FZrTKNzYsosECAZQgkBG1OMmREG5ztyvXus+ZXtpLaUr+9OqAK/NohIQDSrI+KLMV8i9edG798xX3epkNRNP216/ey9r6OjiHS4ihrT/OcmAkIABHWmAHJDIisw9/NpPDBh9CB/SFbUEj5gIQDgowoZMMD2gUwcCA/iMxyA9MUoMMniUDfiiFgxJBCwqzclRWxVLyBARmDQwLhNFhMvkVNkqkFLMyqXWqMDdjA1dAuk6g90rolUqJlI3N3l81rRY/retAipqosIK00nqKLOndmYoOtNLMTUwrnt0UHXK9aDJaDXQUySkUVosiylnDqZWNz54mDYgrJTZJP/7smTqBEWWXMsLeWJkd2tJmWkimBYdeTE1uIACAC1mZrLQAA4m8ilBGisAIMkTNTg9BxTxF86SiwANDjoJJY+IkbAagRZNUYQc4A0SNw/g2BFjsGBKYVMSBLD3NA8EoxdMUUDAxGUlWggeHq516zh9Oyq6eplKH5etS3y89M26DstZx3Um+tb1t2Q17UdRiZan0UL2Pc2eqrbqtbrmz7N3ZA6SrJIqO4ye6kBSEQwIBgMBwOBQOBAAMxdR7AhMIY5udgWFJemSGI2GaahjQIAKaqkQhIlwYsWHa47K0wZE4tlDOWrt+XTcc0oAihgSibywdLbU85FlLwTmyMtrKNTX2y5CPkmTohxCcPcE0gErKNPs7ki1lFGvz1I/DxoA2oDwoiGFU1ls1ds0s/7T0rINddxJzwEwqRQxUwWFUDcTXOc13CSWf3m49NLL8onHvdtuStjjKZvEmO4dmm7Icpm1hWvcpnYnMKTnInF3/h9W6B3JcJyJ3Ncqc0gfTHfd6/L/////t09Pbw3nLP+kw/nW2jTZotdhl/4BciWw/QzkRoP///////////////////Df//8/////////////69DY/W71fUcgAgBTChBBBlBwZgwRhwfAoUBhNKAV0ljx+UybwFpqAJ/kUIKAS1LImmCWiHk0IRUhTylSCImOgpw48GEAKBnarSgFK19XEaSy9MAWOARIckMgN5InTtSl+3XpADUcxYdUYJCDiy0cVmomwJe5fwdhopfgKjkw7TBpYsysiCnU405gMvkd6nn9eYIBquGYaW2LtQ20xW1sLKYQ+TAXx/v3ssJzKxKYbddAe/CD7P/7skTkAAjYhtJuawADGgzKj8zkABD1eWP89AAKDqzr87CAALWQMjh2rAkGyypSuq12czwsZ77ztvBRdHhL9KuH3XgtdQCMVInXKYzPTep+VwX+EM1IflU5IKOkile3f5vmwEIw9G5OFnoWAbiWzrS5azKU12HwFefWZ/tPHZTKalXmeN3//BI4tTjn+PKGgm1AEiWBMQRAJRMPg7z9CCLgIyMUR0TIyQjpcTcNwvq7mUo8aAwOxgfB8MEglppEpxJg84YwuRbG2NUkV4crjHVcPQ0ZeWQeru8mohLy1aPqOqSorNrzyhdhbVazEGJnGtBXpus7XWkW2729XP3Ezcb/pfZ99TSVdX4wPCLY0e00rvwOwZ+uid7dDptRAAEAnaTxbqWuBrHfUHWehdArOH7VjawsJGJ54RGYCYgiYwVwUCMvMDiBQWpkODWNFSBZy1MxMMYaNMG7TQw9cokRTS0HFmklmnyowwcmYZXFTve45i6XX0hKd2Vdr7pqp+7pO+j4rq0eL5Lub/7qcyKr4Xt/LOMPmz5AdOCzlKpVxh2lbSqQGQcEeiAjISoORVEhgCwk0C0izt5eR0N6Gwmw8VCBI5FwOmoLtRp59pZL2ZT6pGj5ViMGp3eTJiCM20z05+EJQShHPOdUkWJ03UiuKy2k6zYtNZr1abkfUVTQsjQ3C3Uz5oda+TaqZ6r5kbmmZ7Hp/FLNRLsYkzI/NK6EZbvZf3S6+oikgAIc5wmaIiCyMEcJVg118wRODPnoeb09art84CRm2EaS649FnEays4ViTdnBFMUmG3zbS1HM4dmjfqJieI2pRQydk2Ll1Xr3P+umpf/7skRrABQrWVhh6Rxyhova/D0jjlBxa2GHmHNKDK0sOPSZ2LTJWtcoc5EcFptRbi6dIVVDg+1zlpQF28FG0c5E8gWLzzkY5bwnzTIH4G0NVySiSfp/Hq2nT+eb20FFACBAARwZQvwVY6CVA4yOHEPAaADYP5JigLgd062oFE0QcQAsjko6XJmpZyfaTRpcpLM+MfZZA1y0UsKHQYUjVl6dFM6EYQMh8hkDt+pYOrpsJXZJKMgt6BtSWR9nzWubok09rAebcmzMuXl2+uuIYQKNAEgu64gr/X4wtfNvbHCqyIwFIgBoV2glJSgFpBQwRSj4JOhw7EcP4h64SRkw0CRLLlA2ta6FosiOLZfTy4kA110771saYnTplPaMIGttHZuP8Q62ImtnyYzD7uOdHeadF8dvetgdnPKZoh8fV+Z8R8d5j7mdJsqH/8zPuvmd9+vOuWkHo9uWl4DIvkoaDTq1dmo2ZhNIUAAC0JbTCoJpKFjDWsIvtmswYrYrFNNeEsLBXnWOcfobkBS2ywOCLHTFu/LTT0GPRiUTUCQ59O7ljWmsNhC+3l91qMitiis79c1aO09fd+xcTyv/tXeHxV6ZN5vbJaoa/b/+tqqnJ/lmiKdqyXxnffo0j7ujMdKGjSxCbX/m+Xjq8u7shrWSSCYMcr1cC8G+BTEuNEMAjaJEPD7lX2F4UuvkMcaZZOPjrB2flo7dfvFmugBGjzkc8Np+GYhtrgsiWdeHOc8ItmxjHQnuy5+Ot0Z7HXrY100xT7435uRPpHvUnWjt3hsycyVS8farI89r7u7Z/W5t/024cP76UeUXqjLQUNESqdvz7bVV1v/7skSJAQQvWdh7DDMyiatbHz2GaFC1eV3MGHPKDq1r/YSN6XRiUcAEQWSOMJSVesEmegwmYypQJJNOCBYU30CwPy3HeWYhF5yFvxg8X5TBcvy59mNOzFm8iglB3/ajHx8X8Rq4Nr3byxxAvSqfbjWLKRphG0Zl7PP3W8v+iol9QQUzN2kUjjJSisQzPYMswwoohJM1KQyXD5ELIQKORILccO3qrvT+y7SaMqmUKIBBZiSRPdxLEv80hCNIVqModVkLSH9kDa1I6JDCEiZOsk5TUuYHjiOaMikvL1J7KqlpM4wkbPg0g9Pw4Wi2GKMQNIu47Zgg6YT9wvrHUwg4UUML5vqOZQyWM+1LhEe+RrzKsyKgnQeS0KUpyf/SKwIhBUNA0qRgCYE6e2/Nh0pEZ1M9YAscQiSm6NGFhLUTSIQp5uzVYSoWvRedAgOiyoMSOHhbWGrhvdC+j0UU50jfcg70PeUXSSrXQILlTRokokx1d6mZ38Rbypo03qejHov7vVvi16v7p8v/l93xvbRKv6ZdT/r4/dEISS3JOO3bhMxqisbtm6V+kfUTr4+yagK7vXXtGWUdCOJAHS7bRtywNZCzJGgkZfQsjXQseQvQ/L/NXls/Wk8M1rcgMWYyKo2aXP38lNohJM5iqS+QYqCkIfFfbZimnMdUMjWTO1hsWxJSWG+FIaVAuSzJP6d5yZHJgobiNeEWcUgaZmxy6wUuSIfzLhSUtxJyHGx8hYV97ULLBMrIhiSoKWLGSUDeGCRAiIxgV5BhbFKNUR2GdJOGE8cO6JB5vD5dzvqOp5BCb6B7ZHJCUzUzbPJYSWmXzl6yBzNu7P/7skSkAAQuV1dzDDMyfqu67mDDnFExX1nHmHWKIKzrdYYZmc4w1m3XcCFpaskO6KZ6JxQGaWbrSUkc76Z0aYD+Qzbxcsw8YNBzF3Y4CeOIBoOjDkYLdHxbPblXO7TFYqakzi3ju2p+XRGkklkUKKBIcCzU8HrGh0itriJ7pxO6v5pS6Z+gHcklhQoJwmOZrywtLUSlDNQmjWPlPVMc6a0ok7VDT9wxSdhaTW06+6yM7/tWJXUpJdNHcPYi5hVtbo1MdufkAc29f58j/1L12w+e/bKaUAqvk42qrGuFNdMf/GOzviVpp9GOLWuA812++JN9hTM6iEiAWA6bbxqBqQtZoBLSOaoRhCNF1NhKwWE/fCY1RBjK0FxmNFkVrm7+djQpD4rnZTrAiaSGsSWmWQzUHMOaUr01ifvFIXOfl/YO3YUgxBI5UOu0bY8myiQZedUBOuAlKT3aJK4vTgeMWWXMKWTu8KjwWMMDxxAWcZAMWr1KE/SUmAAHCkNoWUsoBBm0aJOhMDkEjKOOnUFFOFRp1Fw1iM2yxVXDy9OZHZSy8h+SnCZnRqlnFmh0cKM2GOkq4rbi6IHFE5ikAxhXYEZQqEjnKHMbwkoq3ae0OSK2dmJ2XIs3z03iHHON0u09C8vtQ4KJDKsp9jDNaY1Ex6ocmJjVTKEEALY0NTsv8EDddmiCqkZbQrqbXDLF6G700AxmVAEOaoWOxRIGG2F4mzovqkqYv3ysMmDVC30PMk1seFF7ZqMvGcWRHuiym0Ucz94zH65fCyJEON5HkdNq666Uox5mQ9I1c19WUYga5E5PifC0y8mEjRogLaVKor3v0CxT1f/7skTAgSQDWtXh5hzgfWvKvDzDqA+hYVnsGHFCCS3qpPMO4S9DeCTuadCWmTKVhIU0zuaqO4/2KFEYmFkhPZWaGwagRlIwxfuTs0lb51wLRIF6jQ9hDyohPopHldUofnc9B83c1GaVXJIYltBwEVcpC3eG5sEhA7CQJmyRwkP3E62kwgM5kRujbhSOCZKRI1rXC8I+BamK9akZoKVbeb31xRtAKAAYfIRfoml20YGPtPQaVA/UPp6smT6fCCIVBQQISFGHI8inFdYfLoSx9pdmWylmx9LNIOhbphZI1qzRiKzULW2MUL252vN9jzzlQhHvXW5S2ZT2GEpoPeHukhmUBX4l8NNNJI+m1izLzvZ90/mS1/w87ju3jW/l3+bCRtF26TJGIxX/n/ksTkCNLk2hCkAoABABwh4X4F8uoFQRAV0Zi8XcO5BF6SLu5KjgUyckErEzQrWiPhMFihFLnGkaOdsSK1SxEhxk+zKjDbaUjBq/AjXXmgWc2fSQdEyEEMRuzEHi3FFHVGay1ATkD6SLPpOMQEhk0IjzQFSKGbb1U/t3aW76xPfuf9n+9VZjbl18ilnv3jS6b7j5n52fX2Bud+aASkxBgAAkMo5kVsDitdkCsiRbiixFISkbo5j1HcaaNY0kimh1Vc2f3VJ+sNX6k83NQ2SWAWJgM8FKozIWe45jjyQ3iUiQk0MXJEuTiEgqGhTMZh7FGpl/S9IpuOlBCrSx0wL6TQizZkp0POlm3ZM5A4DU0Wfl2dTSbDNuriG7QufN6ok++2ULq3C0a8bcFrCgY9Gxw/opJ2FwgJxMeh0SwCDoSVop7LJYiqxpAxESp//7skTpgDR4YFRjKTPwk+wafD0mjFLdeU+MPMmKSS8p0YeZGVweaAVKcbl5CeRMc2wVSjQJeGgEax09C8TWS2ASbNsS+lCzyUAdmhKJGt27NJMWToKTs9BMvbTpXNgoMwCSTJWfLYTI+TyK3Gu9yhR1nlmc8o+SKn1zzWQBmunp7+07R3OQV6zZloOouheQUDzhdaVsLCYVhlf39RZMwolAACOHc0sAc4HDZ0n2qYmM4r4KLKfp4CM4wPHJiJgoirCrfWPanKqqp98NEhnAwvYiXNwtr45S7idMcLpSCIqOkJhUbqZLoMUkqRQEUiOKHwBadppfAxl0agcErvLSOYUlAxjToFrQKJnklxm0kXuf0VDI+q1eRqeFEpxrKu9OHB4e8gRRRrsWkgrUjOTDWjiA3+LNurRpFAACAoo8jQCoH+CJLQcwV5ongJuHPRoYE8dmmJHoYuZ4SrhuL1639ZhvrRuUeMua6jDi2VZ/yTi7PJBqNMIGQmfWVkENcGaxSTQeZCEc9yhWsltEVtJN5c4lAfmmbMqdVkmd9Ldh329jXZeYZ5f4oVnqHqa0H03VDUhT5UIhw/Yi2h3pii4isIn9iIpbKQQVAS6kK1p9ceNOlEZzVcxgvLEn51DbjH1x0EFiJCJQQJpdA2hiJNNIl5maQmXOgTQaUVbapoolIupSXaZHWRa22JWwSxKzTVEAbGy5Iai5rJEj4vlQmZKLTSazSbCANB6+OCZcl6xJ8jZRdNC6zkpao8mxLrLup7VnaHbGrbp4fVHOmgDNf2BDY+R6MxEpQAAJWeFIpKEFt10YqcruaAyRMtgMJxuTDBr9176aT//7skTrAQSzWtLbDDNyjgvKfDzIvBHVaUtsJM/KVa8pcYSasUXYdZpIcLNI2ibPKQizNOazB5gaRQzcnBIycdaEiabtGeQ0CyaisYpNVbaBZorBpeZFNqCGLuvnnLkys02JJrtPdMPIveRxgFbUaijLZlfdK3KxpUYVvwx0J06ad2ZF7Klk+2lTJW8klbeIbcRsIk9TMYp7/qIAAFhOMlEiiVE45kLDCDNZkSsqH0DvyrAmQFjBoNR+iLmJkTDyy5KhO1rO1R2ejgWRQPHst4S3bBSkYeHKJpwLNBjiExwYiXY1BGV3ZMaTZOzz0JB8ZVEmRNp5e6WtSJGi0if2WyZPhio2GRTf+/O3Jph8zhzod/2p1ttbVdrlECgMBEkgvFxFrt3pKOURJCApcupBQKbEVC04FA1xTKpWcI/UUoCAOxKwpl4kE5TKEKl/rzgiJIpat9C0UTRVIikhtkErDRKDkS3lyNoAIweU6VkAEszhKiVp1BFYW+KFpuCH3odwZSXpmfL2YR5GYP1SKL65ZG8heYgmrveMhM0mjm7WK31rvied9b/LbSbvlHH/+UsLrEmFhfLlDqQlBGTJGQvyiQTDTlABUnJI1trbd4JaPFom5C6o7oRaNVaGJpaQjRxJyJp223SLKtuXYQrLNWQqXNu9jkVCRCX1vuIowPZFYySBSSWDDgD8CYTLhRRZIBkNJuRQ1Plyp3o8PTS6J20cX4xfOvp5p6c1kO9E92zFt4rrxJmu6y5zczO7o1l+ijizZo0tmgvoDEaQAEEMlmwcjUiSJSEiqXMRT4V80iBZa6lPEWGPNJYdpW+5i/IrAouQKDhsLP/7skTuARRwVtLLDDNgj2uqS2GGZhIVaUaMMM+CfSkobYSaef4r7chIckSICUjVHFnxKnWGwoKOjNBE1h9srIMQE3IiI8FCdgiIoEwwGTE1KSdgsJCgoFcNJBSSjikdJ/p2MyisirUGQ9UEgP2M8EXCybqlLJwqjjBexiVz17uatB2dM1sAgfsMKyvJdUOnQy5lf39O6oQxSmgKAFmGL/p3CIAQJScFDIWc2WuKYKLQRFxtAHqp8ASS2WYCvGzHY5UV5IqLbECQLXJlBJEKP7bKCJai8wSmYaQsOYHzLtpLDb3eBpCUNgjfxRBZc9rTPv9b4+XTQlue8Z3pqR8zjbX2Njful6xZp9YbP27aPrtFzqorrI7OlzCnbVOHa3rM22G6XpSJUAAFJWyoAFIM8GlsrRwQkNmlTfqVORDFNHGcwfi/MlH6jJmGqw8SuqEenBCKV46RqLIatRahbboJHJW9xc6uIjaWA4uQHTF53KbcrLnedWXIhMjVVEhlxa6sT0ljLsdRgo8el5NMRiR2dJfw01C4Cd0u503ubmtM8vfik37Rvjclq+Xk7Ns1VaNnJsi1yoPB9EvMXOoghgAAQeRxyQgo0dkhU3yEtaDTXsbGl+/OTq3ICkcqgGwe3fC0CpZyg7sXoWi4xDd7TDjpmJKhkg3gBsTD4T2Dse8cHLoz2/lU0o6uYwyj1CYGto9c9ajOLnMa9XOMQplDkQImPYMEMiOKUg4+lNOKg8iaLFSozyoYzL7KW1c82hsRxbcO/sxvPd8Sj48eq0MwqGo1KF+xqlVsAEX0auksKDEaE5mVJGp1s5UYeRqrXIFWHiD9Ra44tP/7skTugCRuXNJjDDNClouKGGGGjhLlaUEMMRHCXzAoZYSaeC+lLHYJB1Kba6BaTZEzgr2SM4WWclTEptGFlFmzqE4KmMJtaRUgsPG6NESO5jLCCsIXmjI2egzNCzZyCeNiVCyQES7cqXJfKJb6y+Tzym1EjrssVeQTZ91sZ9XRHM/pLapNvsT///3LY5OtqALbrN353Y1m9szVIUdJYQAAOIQN+hyG1E6EUGJgra6U/i6KW+bEYtJ4Mo3mep44JfeT7cCguKwYB0h1YQt2dBUMsWRxeYoLlWrISf4YIghzglJ/yBscpqR7OxNrrg8Lx83NJpFPBJ88GGopcPnvYeGF5dyCfp8b+Q+DLu4ms3W32v92N9yjjbW5LEO0L36SX3zG8oxS10xrn1LHrw/Ut1nbvL/lvBphRlkECAAwBUVixriUVG7JNhlSUdR62mpfsAA7RZs8VFxipPNhfbeqmqqOz16GCE/XIbj1XD97oStyo9KCAU6E4T/jzJGPR+V4tKu45F8MIYTAwy0U/bU32SS20Svc0s2bUXLNV/tDdlryH+G8rvC5yUvNyXGPPjv9qm+tHe+sAFSwnaWp7lwhCgAAIMKNqVvEdjLvBnoMAJoukV1kJftAhNR4GIsfmoadObprDhBEKLkJIZI0is9RsFMI1u2LYtiuVx1PKrzx6kZiJflJCqqjRjNTGhrTG8MAYqJSrmuKZePlNFqb7GA6HPXP9b4vLX5YP6R0giVzYy7GV+YVRYNwIIPuTFM5JKdQmtl8cpBo/y8YopoyG+f51z2dS41M1QoMFnixJCZGGPqgBPgcIiqLBjkw87bSlTyjc+RHCP/7smTsAhTYZVDjCTTwhqsqHGGGbBRVaT9sMNPB0qUokYMOccJn0y0G/wtv3En5aU+1JcgbkI0kc74kBkZeDcfIajklpJQWYs62o15d8MX0UIKooqW97BphN2hPlvX1HIscy1uu6oYIXcHtw6X0Lulbkvv2GCNJ7pZ1mPnad5hHSkm9/fiEI1BEAAAaiiFURCBpBNBUsEQklHuxV8pFuDHIf2wdvqzhwgmjMnAAJ4nzpAlpMjaNNnm1yg9VtpMHZoQFiwusgZaIgGTiKMi0RuJqtFrDKMmQTVpDpuDtkNRJnRvFK1JSAm2AANjARAtjoVWNqHCHBVAVIt+MLvDJoaxVVeoywjpMVzKAmFPK7JDind/8X8rod+TxBhoEAAACFVrQSpEio/pWl12qF+GdKxKouGq2Hn5kLK4tfdeDYzSioNl7Z+oPTvCcVVsS9Yb40jKaNFvI2XZtZbY4ssVF5d6aG0letrrBIRutF+RFgudFesVvXVtEfTCuVOkjh7QZRMPHJqdCh5rGmRn1SNJO/NzaBe3Kn40sjQtTV53PG9oXrbmb8q5o9P3RzzuRDfe7H6rIcO/soayJAC1xf4xNMITK8MKC5guWlRRQPX0ovGXvg1l9NKXCr3NbgQgahIhci9FYppHd0gTRPOHUDS6CWyXaLY/VVWE0B+CrieVVhjBuDTZUeHnwN7Fty4fbLidDqaFGvmj9bJZC62qqfiuxBjUYYhTzuaYJNXK6vDgQ/Nu2+ZGKtva7T9997vGwem2RhUf5BkKlnl8o4atSQCQXCqAwnMQx6jOUai/KPrXUMFQqZs5UqPLgXpCFR2aOyVDQ6hg1rf/7skT3AhSbYNBjCRxynEwp/GGGjlJpe0FsJNPCTK9osYYhsdl9zmBxXywiWI/IKi/LNcZmW5Hyx90MJCd2Rx44tkOYZIW0gUiEGSHdYfsxEyfuePaUqiJHl26uouPG3QoQ0TY17G1tMnvBF6S6uzpUVcET36Chkv2KDgfOcQA8U2y7WRIKLxz832R6hBKZgQgAEBMoeSkEAMsvTEToHIyMo7QxSCIWhiGngj06hqGvaURRypeZuYTvhE3M4EZQrSOsm9MtaMIG2KtdS2WE0xsSxIcjJSTayUTgLtM1hNd9EmgmXSVjUFMmXaUu0lYtdElVokci8SRtgs/E4MKNzI05XijS6CU16XlU/duajDDJPKEYahQutXCATihQosPwjJlzaZyM2YP82zmpyllKqiE6AARliViqos8DMCYahkheLxWkuIywKBRIk8VCo4mLQ4eEAVkCx030ZCqvbSU+3Mn2RGyfkofRkcpKZZesfSbyhyKcak1WNIJlUITIdksV3vRi0lybc6lL7Nq3wWTdHS0PixPbC4silJrZXC34dXy3yes1k0qjKcqi3NmMKIlTVyf2fLFYaSkiq9I8pOLloSZD4dy+wcjJKWpsYwgjpFI0kGNHSuFGGEaB65lax4qGTYJ5vYQmC2SUFwHHOTorIMVpZHtLrbqrL97aLciKshiDp0xdzVhjcElEI/SW7cLV8Xoywla5SAmZ7VJHfEaTHdGjmpiUTyz9qWqDzp/aO00k8685m29Jl/apms6qn4yctsKe42kZBjTB86jMl9TJk7g4eNvf7qEAHIgogbC1gthxBpsoPsWOcQEyDpPAvaqVpkxJUP/7skTzgQUBYFFh5k0imUvKPGHpGhIJdUfMJNGKUy1oUPSascTKai7hn2sQHaqb9xUnh094KDxZqjq0tv3KNzcqykwgkUEpYlQZ4GMpKZC9BNhE1cyBfozRhqDclZrhdZ5zlGq0tGUFz7sXxE4iK7nmTp4SnbamQp5Si0gsh09rlfLFuUujSM9kXKrKwoCG4wJReYs1hcKXmVv/tXUBSACZVCmwiLGwTKWKA7o4mEIt4mewggRLww0hXEhF41IYXh8twz3VJM7JooHB3VSMlttcngWdJrdlt/XwUMp4Z4Exn09Rb59laRnCod6TAWnEGjgmUlDEwQomySJ0tVP3Xk1uRSJ5i5sZxbvSmqrLEUsyyWPi94bu6tfh9kyVveksh4yt3UtEa2sBxbvaW2WwQWgcBs59x1ZmcfjouF0VFyNquXsxrZ5aCfTjrawqKxuqvWIhl102AIZA54WOzyjjde2m6QXM0Tc2lK/JJCYJhlnmxIBBQNDv8Kza3wZ9oGkyyVUyy73QxjFK+wiHXQiGI6S3l7rRj/uiDy6pLUrzI9Vy39d0S19Wb69HK3XYz3TCxjsceLIjLuHSK31ICAogAOmVoZ8JhJyqfYGOdOgGPzTGmzNIZ6XSOY4jK6Jn04+lYgjJVbfhXmZGilwbL0Y0A3SQi2FsWpGdHszVAOvd4BeyidrhlL9DssKzPFZBW7cgqbtvH0yiPFbqRIVWPUD+OswnDcbZTEFy7hJpm489MC9a96ZY7wsU9JyVkWcep3tKqt60Zbe1lZR26HNez4vbsZTAuPK2tndCpMHeWLUOJrlQGLHxr3mpmenaHhZBmMiBAQSA7P/7sGTrgwVxXk8jL2NycEu6bmElehXdaTiMPY3BwCvouZQN+Ycqnm1JjqND3C0cisvU2yNLBmiRbGTjGEmAcdQQFTPcs+NW+ph8SshDMhyt8D/Hx2vuIh0QLFlfAybsBxcvvwfpAmKElp/n8BGs136c2Y/cY+TJ8i2Zu/yz+Tn+TfkDtZG7oq3X/xWEQIAAG8hixlfQODGdGhjomQoootpFlYBG8KkQcqh6XtwIjjQHeTDk6Is5NvrFGbhGHqiaHsl1JEjLpKM9TuP0iUKfHfrSkNk7HbGklwDBwum1Sp98QmFTq1mTyuhkoQR0LtWn6SS56LC2tvi/nRPV2/i7lcoMZtObK3ZhJmtJr3hLNY8h57q/TspgjePZE9a1z3P3ZaOLasaRvsHOddPbtiQyNtVU291W7bkNjtjvmLrv8zbZ6XvliOo6V2y9Jt92cKJAAMOvG9kqWL2NdclBdnTfIkIT2VIbNJTjg6CYfeNejEHnnc5c3ezqW5LuKKgvQGluEClsYhPUtoKCYvaH1LSxA+GkEnoLMjs2FTyNYgbMtDZoX8/NSykNjKHaXyl561VLpKRcv6l8+Mf/7beGH6Ld87ZMsSmAEIjiFnBQAwADJpKO1QLYMUFXyxWAoBC8beKBJ3MAf1y0SoGcmQVIips9tSgaL+OUYfepM3LDf9lro5dmGRtcluTB1DIHpyQjAUblwGooXcSCeuaEwQhQPtSOMiylMB0H/xquvcoPQdywcn51hdNVD0qgIJqCtQ4apkg9mtGkJJ7gSUzSUa5ta0rQ9X53PN7H0PsYVjlMmwFSOwcR7RUs3ZnQIXyKWVuRmnJf87G3//uyZPOGBe1eTKNPZPB6a2odYMOmFmV7Mwyw2wnAHuk9lJXZG4/p9MszQzMhpEEinceCYKbUwh1XbAYbSPCBHcglzEVJW7avoeg4m0Smj7onRIxgmRNLWaJYVZjK5XYzM+fDRrKpFVENa6ONuzJdTEJolk3NsqyolbV2Nq6RUqScZw5m39+snbZxIdKeFbp5lw1Ev8zH+P0qhgAIWrQAjJxqMjVoENh0wQhkxQxPtJQKlI8MrUETSDmmWLzdxspKEqkBNEuSxDIoyj2c7jGQtDXxcEmnmsw0AJ7FShiI1GLtXEBOOsxCkZdsDrQuj5dpxmYHBPni5sahUF4pgFMdMJXIosTucvxoQ4jbMy1X9T04Ll9wbJxKukKg0dghA9uBEoZyg8RI5KQjaMUGopniepnVZ9sFVJUIWJQWLmpP1Hs0FXijkTvMedZMLDmXl7cowxLDSgw8WOmt1RZLYZAAAjH+EtlZFFVXIHSwABtrIoeqA0BgTN0cHAi79phBQswCeCIUeolyyBx/wMbB6R+lARnckgSnSBtnjUbcgp4EvqUgmJ3J7+TApvd9ofdxJ7p920tr9piuUX8Kh+InCk4pxhQNhRuaD+iIGqAQHOkCrNP+2cABAA8t+HgkGaQUDqD1gQUEEFSKFtaIATJmxSd5wSEguSr8h5m9usxNK9gdh53FL76QlBHCleHBbUayUbewiCr4R1Ig/VPoC9jQVFCPUyGaLD4tHzVTcY3wuHgy7EQZeqdKzgMkmZCKNnNBAz3ge6lDomNfUU8g3nTRiFKoIT04+/cje9ntbibL+9qHXfHxp/TyGemcj/u4dfC4Es+nep25//uyZO0CJgNdzCsvTHB4J2ncZYZyFKVzNM0xNQFtmmfw8w2o8M1xI0STAAAHCryJES4Wk+zhRhSqKOniUMLI+haDJYhe0w5sfKw5NvSSWbU+CtJgJjjq9z+1+GXuKygIkNpqkO2meZ/daIgU1XhKsK3ld5utB8Bte2deOVpIPeSOq5hU6CMzc0CdiG0cNWYMgbC0dhaBrBiRocPaYWjBQBQcBDxUIBACgYsdQYHgCP8kQ1ApEWMLtSNamrC1tc7WmOIJHUZcsQvGzJbih5fMD+RSeUJYQqw5ixD+HwPwK8DGJgmgJMOoWQl5OCcCfsylPI4S3sqgJAR6vLMogmWQlaKHqRlykHUQpYRrUPN4h7Imy5occRKY1T3b4DJovhz3gv9p2HATiHRIiAVz9OJgkpWO3zSqcx3isliP3T+SzkS+xQmbYKHkBhcfMWViICDQ80jgQYib5R6s2x98OrJb0xHc8XljshVK9P/m2AAYAaAACTMGJMYU7GKInticVz3YuZ2XvZC1qMQHPQ/KOZUN+YsNblDj4OJ06CECEuXUMnt6hmW0OZCdxLpsFmS7kbZbT6bjIzWIc2CqZ0ZTqjWd7UWdCMU8kl/dn77Vqz3RLK7HeMajum5nCuc6Mnq4IsFeqAEZEFtJAlKHTx5mTQOm5oIUZgCGXGRhIGYCAFYwDScBaxoVwTFhkAkZmkiQcZEiApJRVaJKjNQXCn3C4CPnGfmMJfcOMUAWEGRhhyz5ceJpgnuIoJbCQoqMa2/bgN+8MNyx9CzcYfaOl0GJRGG26qLPLwgMWtj3vJb5J6G/TCmWTCOTuadkjZVjFNElJQ6rkI4L//uyZPgAB0JhSoNPTlB1S7otYMKmGvmLQ63hj4OALuf5zDH5RptWn+hbRWznGfgZVywySFWJVqK8wOrKLmq9dil2+RdjTkU2p9U8DdJyV/2dfX27ew4JjtjDnb12q/U7Z/O/3zdt6SFCyABhBEBSVQbMigI2gfjEpOHnIYOBhgs9G3hsFBodb4ZgAcGI1Ca9W5icGhQWGPBkCgSYBFZhkIFokCjohnr/JeJ/FrTqUzDVIArEQIdYChs0Qvai67zJFoL5CFltISyBkam0VdBuKGDSKcv4PKSJpmyOO2ufteWAbO3sMsilNe5DjpwZMZvZXmqsxezB5zdVxdL9cXnj69ENz6iGvhu0nrEzeZlg0VZS52skvEPOWnGa2yhR0eZ7Y6Vxs8fXv5W/3ZOKehoXfS0XwQHlMhu/ixtv4Vjv45AeAAwgP8T/R/6qAEzEsCoTQIXzNRaDRMaOLwQBDAQdMWB8WGhhwJCwuFj0YyGAAGAsTR0LGXxGgMQ4HA5z6FgqkjgiSB0piJOOQcAtacgRCeBOt/lsLvUAlrPFMkvmV32qpGslf6VNKbZpsulbNWoz1WMSqn2uqHJc4+Qs3yFv0KRQ1IH0I6rBFFSriDd6fUlTzt2kunvLm871C3pRHrTABI2NG3eBh5idiRu3k5LusQhRSM9nN/jKGLxOJZBMzK7QWsIwsfosAs5L0LqcH5b+4+mdxTxrAQgAEIAICcMMJz91QEEJUIwcGhhWBS9uSvoBOxDBCrBQDR7GhocCG/nE+2cFAGwyApW2r1LyVEBgSyXSAWfDuhpxrB1c8NIks1qNDyK5fd1nuCXEIpXg3B80aSIV//uyZJSMBl1gUAuYS+ani+pdbYikE8l7SE29D4ICL6sphJY0w7dVR+QWQO4eLnjWaT6pIf4+vf+fqQ47MFza2HY22eK6qBcU3PK8UNjoOBVcaAsHisMnKBsfdsDoWUmDhGqyqoeNYc5p5ZwUzEgCILDlIb8JAIbNLRTUnAzgfLwMLMIVFeFrRoRBiyCR0OHRYnfWCAag7BNwAAiyGxifiociwuAFtGrI6lYXVoN5UCgXMbodBdzRI7Lp8yvdrtAW3lufuUpZstUHWvAzrsRh9kh7dWwyoov1n9RhmyxfmV7DfqLUXsdx1UCZzcelzV1XBldVFjeLp0klRX4mfY7YQgrKECzXVW/IqvGPXWBSIYScRAoUgK3QlIvNjSNHhDIGnpvqkTbh+Pu4r202OFaaHQpaDBQsISaTCOcNKNA80bQIm40qqpkNxeMTs1UHvrzQySSfWVcKmWhiSBWo6qNOyXGr6jJIylCcrld1VFSlaOpVbVvqvdPXZmqz5D4eD8XUDB9xNhVZUPjWJOXWUwBAI2snD4AFFhjcgfENmgE4sHIdTVTMwUQDC8oF1ulmSZiMMEBgMNCBRoJcIvWNH7uQWtxVMvw2iXTWUBAkAytPVx05J0exQPZcsjIJwjQgmQUecq7dGBdj7o3JcVZAdg0ncOVfJSGkZNcyOihvSNfwLDrnbmzh/Kjr+p6dIV6qRa6146TqBGHL3PprbTFyNEKMpYuGuoEIJ+hZw5vivsXDVEwABQAAAIpG5gD4ZYpvSm4Kr8RCK0Fn3eesmgVWVwmkm7A1OnPImfq1Sis+ziyTGVQBlVOuIJKAX5Re88DUtRswgSsv//uyZHMGRRleURNsRaCIy6qdZMWqE5FzRs3hDUnALKqdlAp4YM97TEtfAFkPEtDs9bXzc2ejLbT5rY0jdEykxJG2Uq2fvsjT3qorUVpVy0ExjyqQp0FB6NwoFMJQKHnUqugkHT5BCmKf0CdWaMcmWmIMYBgDG7IyEeSuCwEZQTomiRcnCYe1mVkhhQQAGkmDfkia18zmKMZqif9N1XkPOo/A8VOGeWwonD0jiMLURmpj5bLx+SKGag60lnFHRbVAnEbgJzUlM6+TRPNjg+mCHVhALL2u4mD7txsdU3y9WNbiJJWGi+GGeKkm7a8n3zUTTV3TNzQ7UhmaKKOYgWKyhIbW0nZUa0IAXdpMCUTtoFhR7OkT+bshJe5ojMXFGQoJYO6kfZnPN1bWH/gKXROSwcMPEDNYbId1TpfIyJ2/fJZhlS6Qv4NhzJszrouPViRtWnTHsd8xcpdT1XGryQX2hndaPraRvfZtHL7pXZS5b3TR3wrDMP0qAhAAAuSWczGYBpwCOOihMzoGvxeECihiAXfLuK7GnpsxIMDgYc18Fhh4i0dlwFBQ660oUXpI2wmkRqPvDssAn5cOR+T80hOUZUuv533kTTBPSBrH2iwja44ihcfSxvY0sgjOGfnF7GemQ3fXuzNDR3rYzjWuHPuBnVgGozcct2x0YzrIOvkc1wcO/praHuLOTZ/nFbGCdGomg6HZBq1YijobkekIACUct4UvNmsyTxEALEiAV5VEqSOE0bLmBpIqwtbjaVNJMoDJxsVGpYXuGSA4WKZsVy1V3oBnUxcliqqEGmaIbAqlGVW13/r5vlq7rsqfa1mVpmuy6ont//uyZH4ERSBe0tNMRVBmazqXZYWEFElpR03lacHJkakNrCT4qzSqnbplbl/3EnsPsrGAYAAtSTm+hhtpAYiRHfIx9gSZyTmGhZMKGRoaDw2KxAnWN80izCNCV0AsEwigIYKYhrdWIPqjy4cSWHdNDgnFgyxJaKyGedFblethPvosHwgCepv+ZEhjUKamI0WtK1Uc9/b3WkbNuKXq0t22L7cYnYeVTSDzVaHGyHdXCI7deUWPvlLm3R7Ira64fF8t7iq44rZVfURrHGsSQz7cO2JPw/DQACLk5dE4xs4nQzKsHCwMdFAIqVX6WFglScpKkuYCSh0mvGCLFVoBmY1E1Hh45CCTU0EscpW9lkbmYI2Cxo+czakbVe5/vy9zUqMXvuefTW1F2L2Y2uGFAZZzVFGlViqnrESGoEJiduq92OHl1BYJXEXLAAacnO6VTFyAcDTRQk6vBIk4mGyqSGWBqAALgafZqSgZuhDSQbJIq2eiA9AvQmhC9T8kxjLhwJ1XTQdYMHGkQ0430DKAXnpa0q2OW8t37EnmqaV83EK3zpX4oMpwGNmQFlYSAIKtwUBp8o87XJRm1D/upB3FYxz1jPD9sL7UlLOr+W/4R4t4fy/23zsc///bs1N4zlNf/LDuDLT5E1a+TzkQbt8dXrv6AGrrsMkTpCgqaCpww4IREl7BQCztmI9ImCUqjmSgHZbkWAK3CUA/Lu5yhnTlwiWrLeWHgR7SjaFc8/Vn+Ey267+78UXpiJPKkNdhGlKa5Sqdr6uTBkMsGeLtIhyk8cIg0wlJRfy7DZ5ou2eXvRHAAlu3gsjNMAwAnmGHh06EYEgNGHRA//uyZJYMxT9cUJt5M2JuhlpjaSKmFBV7RG3hDUHFkikNrCS4xFWIhoaQmUGawRMLhcRAMEZzMpWFO4tKFaroVa9inK9XYhtfwOuzeyzEqhl8nnHQXXanO3IiFRFA8KXqEpNEi4jDqIKWBVXzanUZXssdCODW1FhFrg4+6GRW4ezlVPrb9XH6/Au+eRrCjlVzvm0tBWb0QfUcc7cRV5SmVLDKUVP7ODw2Ijvk2YSX6wCk5bzIcgFUGyp1DIQ4BR4GMHWQMQCMxYDBTAwYRAOGzpDmRRWCDVulhioOOBtzSH826gVJzRwPnRSVJDp2WECALrtbuWx4OjTufPVfvtw6Y42tATAg0uSF3dDQXUyrCgmF4e3o0ltdvS9TLxMaWe3itQAU25zgrM4AVMPSzRH8+AVJmAeJGUGGqcRLiQs0GzqrBKRsEuUa0zgJvFtjEafCNsvEQ+4fRCYOpgpG2vJ8lb7MebKoVH6bfyrAWEUXVEyi4ySEsapQ1QbVWwiM5ay3rFkF2ilJ/s3f9O/U2F83Dy8P/e+K6/pXP2S0/cv7R56TP58r/rzy9rcrP6uMJVCuo+e/JsQWDLrgVZuaW50w1oU/Vsf4AVHLuPPjR3zgoBo0gJCp1eiCOnWkPP2NBUQlsGBmAVHbQJU5EDaXg7aaz8RaA1gXugMoLlMhYgcjAFrUgauG/qukvehVI82nUKLLnRaSJ++7Ubtav7/21Zy0bNoXpfaz00VabUXR0XtUftKhpub/iGQJBEvTRmhQmYoW/qjSUKtK3YoIQRZxzUL2fKWXba3m3sUdxmFNZfys10NrpyEkqdhOFFN+ux4dPRz7ccrT//uyZKkMxR9d0Jt5SnJrivpTaMWmGBGfUG0x9cJdsemNkya5WP9Y2OVqNY5DHFMxd3Xf+XIbzryynUk/fYibviscCY5JUUn7CEpP9jPCoiOgJn687RsH696x5raYsWYHAP+SOEAPOKhMXlQ/b24uEVSHRCiSfvGBQKc6FRh4pFBLH1mAuQvw67MauVj+PdXs8BWNajmgKxkzuHHpf5h3w8m2AiC3KZgh0pm1+DrBKOBS34QLFlF0ATpo6UiNiGtFNJYMzUCoNvvFWFWKmLnw+K0gaKyCFse7PkUjPoo3G2Het31h9xm///xlp22e73/sYhe/w1nk6ekLmsT7FhfggrUGkHC1W0YyBivZ6b66d2cJLt6B05nAQMVBN8JvQQTDZxj5OgoeeFDKMUEmKEhGT0gb96plZbDhEdUAqxqc0ZTxMCxQqKDtgEA1dRYRkbY7cFR4Fct/I4mspE0PSLCnVjseNDUqVliil6l2XUXdnw1fhnJxiZtXLuNzEoadOwUgS8yjpQtjNOz1pGGRgdAth7Jpmik/UV86nZC6NaGF/zGeXjPbubZFZp6M8JkowKdkuhj54hEsOfJ+N+WyLROOo7xD49nakZU+q1fK3nPdVxVIyTt6HmW603BHEqo19QVayXlwMuKo0YXwwyQi1C6DTJgcqXPUg6eRxOBTBQKIthyNeYS+xqRt8GfqN45On7rIGAAAIySbiIIWXNqQKTIAeMzRcgxUcPrAw07ziRJv3urP3IN1LL4XNTc4/WPal+pr6dYxq97Qd6/keX8PWfaH8zwNSH+MRClzAeKePtxRJnLCRO9XrrCgQcksdvThLISHHTeI//uyRJyEBq1o1Bsse+DczRqqYfi+FDl9TwyxM4o0r2r1liGwx0Uz1sUqmTMeDlzmVc6cQ5viHI5MZ1IbIZFS5J+OvqdpUCPZWAcc9IpPF89EYi1whh0Jg43JMtTs4yUD0u3mgE9EjHMdVlwN0K4lI8EMJfebEEEUxbA3VaKZ07HmANJfZ9IfnlQV4ZjkC16eOVY5Wv7n7ta1L6W1b6AESISQCxy/o1eZgCii9XXEIr0MrZyr1aMeTplKCaQUqzHa7DMUaKtuF3LIlli/DZz3Nt92Lpfzbfal9gg3UP18++oTFLM3K2vXo4SuTwY1b7Squq5QxiPD67dpMoFiPkD4pnkri0YSnppQ0RhVNntV4ixReL5SitkLkvFltbW0MmZMr3cpEpintfbae5gmCQmVLMCVi0m8Qt0rBiVcaMf8tQAgJJIagJABFJELxkZAWlovADBFvGBzavog0Rnq6BWuHY2QyMFVGDc6Ue2tHgjXeGuOlnc+s+eecKlNqzAspMd5LtFOSNC7VejMzCMwgApDUxbhLTMR0ITPfBI3W1uFNr2Gv5zkiGINc32NRDoV5a60h0pGspnqOX6GkmTCV2imqg0RoNLNMvnepJVSZZUERAH3eYoBgjHIYT2BgbTFEhY1S1hj3AklYRpafVMmo895ZrKUSFCAqfFJgSi+FSEvHXhO4XjUnmk/+9v91PlUXy5gVJgQelKk9/TUtmQg/s7BqmAG3KI/5bCwjehXTWyhO2YSqQs6NzGVhm/i1a96UurH/XHjE0uq7z3Xfo3DKHFFKzdU6cm8fl4sQ41/a0XTB3kqxfHPbBNfpOZP57rFVEQOY2rE//uyZFMABQ5i0yspZHBnayrJYSVmEcl5T6yk0YG2q2s1hAoxAnCA1UODiy9sLX3hcKJL/hp4pc4p1UYBkDgAorQoRAb4HObApHOShGZXjXkudlK36KY1RQAT99EqKE/iJZSX6WYv1Lzs+pSpd++X01U1SP75C1pohHiyPECOWOHgElBgwW02BCgggAOIEAA7lUlE9WumeKBQUtxlQVSe5VsJUJd5xigGCGv25I/jMqm0MEbQ3gTN9Ioc4yFQKSW1cWwhNK+aEVQ/taV1kLLkreAc1L/Z74maou47ig/qCDf3lc0odrO2M7bz9yNvH9ktbdb0nOuUc/nbdkRzcvPrWZW1ePiK7iS88TGuCobsn983fKLLouCJLJAk7IyCmNi2F1qugaOF1iwJx27lvlMYiylVNdTuoBLzYnLlPIoHRih0FRFFbubtUvI4Zxoi9i1wVMXb2kD3vJKFAtKwm8RvCJQ4nFM7EPu/vr/Uhsv3/2lR9ejPR20NXLQyPMmGNaCc5/XdAiAAekTNi0COooHVSOiELbDwtL0CpXCVO75gwbc1Wo9viEFq70MHbGt9QZLVqG2WVPxkJy1CmEF9pZo8XTJGf2z/TRRjGTTPL23hVr3ZC7+ay+RYnXXb/gWN1KV+lUOdFVZdb/GKfyUemGkJvZwl6nkk9lfXYW2SdT6m/1Lfnjl7bey/8YkTpAq8tIoRBozlI40k2ysrETyVImWApRtFGBaT+BCB4lE6SuIXyZVA/0NtpLrMohz8oVW7qKx+IPGHrs6L86v7/NWpbzsXT1vfHx8a6HL+N+z15ZWuX8r+XM6bP+zd1EIr6qWgakhkuFd7//uyZHgEBMte0ktMTDBl66qqYMKaVCmdRU3hCcGdLOnphgmpGX6qXRe6fqYdpAc1txS+wIA0USRDFIUzIJGQ8xYxOCHgqLLULAUCjxiJMK8aipZoSy+xAEEAZteURZhYkEfUfpZh9Y0yltL/HxlOUNOUyl/9WqZ3hNQSEpWI5EyHptQ5njNbFg+m5UlvEz4wR45Ka/FD6xer4EKc1Baokd+IQfdwtSBFE1HLUjLuUGNrTVYhIdjDn7n42v7+imuVUVQOhzJYj43EI6oYWteR/636R9DxvggDciSUDNG1Yt8t2GMQ6r7TNRbepOltU/4tIBmVCURxrD9PrFjGO5DUxqv3OmCsVWf20HIyuiZyHZ1HcM5ilRnQK7qRvXX5Ok21Za/0MlEVAyK62ex2dV5fT0/L0cvtayqCFJBS8QAgABpVzGs5TZ1DVS4xhTYWgNR+MJLhIDS0hoAgScTxA4JW6EKDUmiqXPfMPLMOS60Ez8nWsHmPENPsJgN8vSJtE1n/LB47vvledhif9c5FohbDSQ+ncXFlYIx/OW+2Keb+m8Fw/rA72XlpnaB3S9CVRaOKniE4VrVXT0v17myr4UipoYmWTFIURcJUcGW8jKVDgy+ZgU5BYNBKSFiECjaoOSCFA26Dwti6qqOb7Gc8EKSy7LhJtWIAjE8Q2boaJlo4G9gksOjEWwgJhioXQ5rvcphMrFF2upHmibq6ll6MjyXrRndWbttLI0geEyr1IipGHkPAIVnXxh4qz0jrUKARAjg7ESpwoOGeCh5IYYETtsOAIMV1UgwuAtxWZNUpmKSBRSZah6EDePhZf1DxX1lkD3qQfmzQ//uyZJuEBIte0MtsRTBuKHo2aeVoEx1xPE3hCcm7rOmlhIm0uRDW6WA3O1ZwmMTRDAbM+YmokKdTXE8mo+LQ0y4/8QR8h2DasaSIrRNDdTuuNtSu93dsbHQwzIY0RO5bJN3kYb9qjYs3xc8xVRP5xs4kHVO6m4gQuWLvbE2WgxMZJgr6/4B1Aid8mHONLEqgIEWsz5yVClgILS6kytihTCmbEA+qJckUE4qdIq8jRMaq/3Kfv+sRONy8U/zmN1L3KJFpVnlUBNR0wAfZSXZ6K9ChwjKHDrhplOdHYZJlfIpIIemzyL/XZOh8yl5Me9AoZUNnupUEAAIEcs3D2GDFIAtplyMY0DAoGmTCiJZiLbPDDyQaAFRlzE/gxaTilxEIMqlUnjTXnSfN4I03N/71IwKHK1yFRCvcywjGyEzG+CfmANbZe0SWVhq3bmxnAgKIQGH4xAKrTrJ6WLnz0tWLJfTne9xI33NC4i/ScDTx+JAQvTH8o/BFvo81MpjGGXYgDTIjQew2VVwwH6yIY9ObLoVc0VsmgDXS0UTG2QGDNs0LkpsgaDDk0CoFOeLiUJ5N5wsAmeEsbpCLz7S4vxbD9NQNYtn1fzYXl0kq6IW+6//r73iEx29irxnvMwbWMedD5G1r2sQUZKoxZxPJKd7hSvqqW9cQQ68s4oM6wRAQugI5I03TQIRihQ6QkZGGFGgU2WWUKUwZCQnS7LTGGtfR6bduEJhmkB4bq85IqliT9rSSlZ4BcDdcm1ykSiWNBPn2rWwchDTLULOyGI06LeLhLoP8fCpyxTqaK1MqH0wu2dnhtycjxOt2i5ZT7QM8dgb8IZxZ//uyZL8EBQJfTzNmRjBmBXp9YYZlFIlpQ408scHhGOlplhn4iHve9CJY4yQYNKqdA8fOK0LD9Ivvae3TUVR0RWRhcSiqiA5gBEnkxwaQnFrQLUEBajJEDnhcBmwQYBAU51ZEQC7qXittG0ahn2CR9zx3aKMB/YD6nzhN57LcFsRqKXLhyFb0SIkKUgdpmC6DcPTfG36dV4pKbenJ/mC8nmFnIEVkyLCDKKmrQCLPMNvUVjzkW2wKgoXDBjsddu1e+/eQSEQgMjhdFigAjG19JU6Qw03xVxtxekvTFVQNkZggZBS6raXLFo9G5iLYW6URnyRQlNvsZJSaSREshCoImJNFxaUiILBpkqtvm5XPa6kUDl/SWx+lGNUufvY7e2j6SCX9IT+UmvtyQQ/kb80KLr+cvysv87rc+yxTLndslxHam0/rwN+kgp9ffrNuM4/7eooFFZLoj71KQuSXy2YB5MB8OAJyyAACAYSGwOXBR9WoiZw2gEX4+1M27UHgGknR7Io/Ooz++hEcPc1ivZjlgqnq11wyesmMe5tatZZZeb6i/SORAES4H1XzEyLr5wwz/hShz8JfO/3O/+rVdSe3xPy1S8d9Wjlj73dtXrrW8aDe0R4tA7jg8B4LzxMOCMOMWLfYUYxiDB3BnI7iNwkUoSqhQIARw8mkIiRBwKEhGBuW+CUKu5a3UVD4AlhYBYFxm8GSs4qhDwS3V6QzK10569HRU07OMkq0SBqujS+pb5hTOUFcpddyVxei6clBrW1E4flh0mPQXpm9J8MibhJWuEK88vUHx2r+bXysqtqm1bzvToPTCrY6uKiJ2LkZ3EXVPU2G//uyZNUABM9eUbMpZPCLLEpaaYheUsGNSy2xbUHErGt1gw45Y74cqaL1ELryiVN2tq/Q7ZMS27q2zeStqPyxE+0TVBQGGFUq9WHuqsG8aDa5oJy6/LzXZVS8bxSHOc6tiaovZqai38W9NJS/nvX95+ha9bP/lbOEARbRONNvZKJSf8yjmh+WvpS7RMjNPjdZTpWes8jPcr8P6pnkX6+6t4TTMvS5qioAPIewAA8P08gUcEqRGgK+IUuZM1HovWu4aKll30naYvWq5623gU8vgqYPIIjcJETiRiMZIVLdcSnmnjDqKJIiFnx7jrosSSFj25f/ETZAxHjSplBcTXCvWSBqW0DLyxIf4uIX0YuHohHb1OWHJdQcPW6Udliws9vrjHqh8qOgePbIGbo6dDQ21iU8ilGlOXitABQiUB+FAQ5c7JDnDgEzBU7AEuX8faLpWpDF5FN8Hbhou+ydpK6XqKIjxcJGYEg2A5ifhAJwPpFpU9a9fi45c77DkAlfSVc8wEXfbcIDd7bOPXmYOyra47N/Lqu1KeIptdrm69IrZWrMH88fVEcssVUjbg1fcSuOsaJ6GqcAcH/l84GQArIeh9D0i7ZoYAxIdgTEbKNHWYJKS9BL1z0bbKBq/gZ0VyNnuSe0jOJByRVABCypecIKNf3HVobpI2yVBezCvc2UXSzRTiY/1kHTTOqtrs+t6uR1m7DVpyqm2rvruL3MZpB+yiemik96nV6XytbY0dtpb4txPBjv0+Gihr1kLst9BeJa3FiGTXuOn8eyjjdGTW8tuOTucxtFTFNgUBJBGUAEwlM5SAy40BEB5+jOHBUc1nWy4LTU//uyZOYBBIta0ctMRCCByzpMZMiEU815QS3hg8IdLuhlphnYtmu08SgdS+6wNkM6L54SY4WXFa500Xb44S1ml6WzowihWZraVTvra9GmqDNjv3mquW32yPkjs/U/jW+BW73lvnptL0jmlazYapn5GHnVdcX3NjKOiey6/Ike9vXlSS2f/kTt/TZ7+49yoyumQhAIAe/oJtMOmEh4IxwYrCY4GwMgzwzRTKDDGC4RxIk2yu2SCMc2g3mcVGBPG3IpstKs6JsnhiGwIug1HsQXDk+NTehLhXI2yTE9JWLsXMn9vlpR/NxzCIjq+Wj9FmF5Yh6nf/YT8tZnMj5nvuUo6rS0O1qT5ZXfN4V7q5x3zsKEN2auQ3gufqW2Y+59VE+yRCbHp/BeWXXuXVZUYsO1VC5e//JPjoYsN+4fHL00cZ7XNh2Jn6Qt9xvdNtKkoqoFGhYq0UECcKd6IapV6v/A1Sp77vWnTOQBKWyCwuoSC4wP1IGoU8WNYKWzOU7pFrAvUdPM8q1yWwNRy1PcabSPNtbrUmDxl1Val7n5V/5qsy4sQv9VpMZ2Hx/1OcP6s808k/jHchZStKp1FacAEgCEV0qZ8Roc2XlQQCoKZOJGABckHQUG2Zmiy5IGkDjPKyF/gF1nCehOBwp6zWJBT1+Q0rSmtz77XZJRDExMb8z5tASDc1Kgu/4TEOdQ7JNA8SwTQNbCWv6g1cC48p7YnVL9n/7nTc37VWrfHPbm/kr3BmJrqq7vaie6C4+Ef4XftOP91uXlXeVL6in/l6sRD+ykgTryQ57Qnl1p5kAcOBhAEwHEMwNjVwMvUGEIWCgKDO8CBqA2//uwZPEABaZezauZYXB1Suq9YQOPU8l5P43hJ8HkrOeltIoxdMoSuhK8oGaUBAFUKnTNy+4NBsKC6GbNAyS6H03XFRuFy5d7i1V18998vXfDy9UGo5v3PW7Llm2bcKMVbTUPLShf3LvFnVXMZ73dnRWZypQxypT12zUetZrFKZBWt/d1ACAAFAHPHoQ0qZjHIAMjCIzAEjB4aRrFBOeIRglF423NC8DrsBDEx0oLFpmrSWurmAG9nC7byZLZsp8MfhbddP1ivMRKOvLI9rVKEo6GkBiihsqd7C4qI+oRGhgLztvtVd+pjyvHIfnM6wpzLuORyXu7qoUyc7/TOxTLRZ/MfvYnONz9ftDX3cbbycbrHiRFrKZ6lqW7SnfPho2r5Jd3+719wtBZVYqGyZTu1+ftWPr/My4br6FghAExkQPDejPy5EceHlogY40VBFMZJmCQABrRYopq0YHA64JOqJhl4gYiealgqvDNAeQufvWrdeYZdjstoz1V8eqLDaPLOdocFvLOi0IptU6gqWHVvMYz6W1RHTMgm0qUU09R6siJQ+Wr65ch/7pVo8jAVfTScCRSZLDQYQAYKgGYAgmZJg4UBIYEAmYHjerAPAuuIGEUYKgGlUmYBVjxfByKGxplgkJER931BB4NBhoum6wVBSKkSHCap6GI1CYmWWJQ4r/V8wJHehpNfRE5lRQhLjbUUOwBaWYPlCh+sAE06gTQAF06tPKy/oiYck+P7lcxQJHi70UxE5fvNH1uohYnLA+TeBxvNGLSLTpVSfo8u84Ina2tv9m9zr7ZDopg441Di145+5wRaUl5NN+6Zhxm+DlW/tD/+7Jk9wQFtGLNS5lh8nVq+cJthYgYNXsuDuWNQe8vZyW0FqARAIFQHEBkRnQWFwhrDAIKB5f8kBQcYtRXSz5DlaauzeAmTrdfFz2nyy9i9MYnnnibCiLEcJE9gieJUWPqljIEU5+lboy5JMOTM/m/KLPtCWk9HvbjDUQmiL3x56oKHnrUcjz8x71tT0ej9jl1IlUdQ0YKIYOFJZ9RR+UVUE4fMA7OggSmGQ0Z9C5jkShwFAoXL2AwHqbLQRSBIQuBYAtfGkEs2SoLJksUW/bL6P27qtL9veXnB3gcUeKBDbwpFpLUSRuPELJjpLvckiCqCi4IQqQ5tQxnKULNXQRvaQlcrMMZNZrPFHOCUF8+smv555vdihOTwtWf9XWcPEzvkYemnZ07l53Ppbml8nDrH1p/EWXML5FoOu3KZu0zjsr1KAQBkeckh1MvlYYAhhAJLCAoXJcEI0S6ULibWktKgI5QIQIgYKNHi7Zj6SjkuVYqiIVz1NNzdHZEarN2iWcmGDGeRgfO4wRiORi1jXrEARG3Z+ZuoINnjargUr0+oCeOCmp3cfcQs+Z7lV8Xyew/QfX38mkHAtAlckdWGJ0SOiC0gZCNBTMx0gQQPjUwkGjKj+IAgYIFZl8OiQ5SELiGJCk0UDAItgDRGYFCxhMEoC012tNPaIg2WWBQEyJBLiULV2rSNFBYMZKNrZqa0nE5e44MYayxsigjwoppOF6GAGIxdAtOuN+X7pHQf1APDzpIOOrI6RQ+PIOOy6KYbr4QG09313xJmS9HLde6xNWNpDC2KpfxpvEe1XKAKdt+/8YciijzuSm1ylcOL/K33n4bo6f/+7Jk6YwFEV3NC4xNEICpCaJx6GoceXM4TmDTwbUbaSmUjjByAwDEKLoICCaYhY9oTCWQySD6z5qOmsf48O2F1h2alPbuj1HI2WABcbWFHwfLhF4ZYvlwE4AJRrbCFsCbQ95zRJVOv5rjOFVW6AYB1GZUzmQw4lV2GWRWeXNo2pqFz75Xq/SynMk7aNdhRiM1GGKR/YWjb3qMekBYxiABDMnXCqmxsIN64QEkA3jyyEhegRwfB8mHwQOBNUmZtWg4c6//rQE2WYhJI0UuSQApFCQl0EMopAgYdJcRPiHUAEfVhR/ONEo8SRmDQdssjA8xfG6naa7hZOKZHqJ8XdDRunCdKiRWG5iWmfTC+lYTDZYuay6am6EMFh4sLOpWYowk1SkYpVMYSRG20SmjfOdTuhE7tXShW3tO1/636NJ0ITOcTFyCYDnHijojEFBBBnT9/5YQF/1Lukab4iUXLR6lhsCztMNBSH0+GhsSUi+qIA/UaOMnKHqKMiEo/kYGeNBlY32JEY1J4plMhRkjJKU0TyUzAulovJb6k9IUYJRBE7KjKUUMUoecW2q3QoY4ynX1nZonqpX0+KWF45kfFPa3cvQore7j3Wp+KSv+OErnLvl/q75LukPGGMFBg7HvEDCyxAFD4hZE8ZECSQ3FJgK8K1LuOmdTRG5WIveW3IgHuAIaWaeizU8INfaqwZ3II26szMWX6oJiUwdTiLAV1FTmtdlxjjvxCgCItD1qiuSb77JUsw4eguznKMSqouIfbmZiJm+X00T6dicDFqFVyykBV2eRXdkuRSnHqNxBmiiPvjiCN12Sq9TOEgwBN9gLOZ0dPAr/+7JE1wAEd15Xay8repZryvph6G0SAYFUbKDVgiWu6p2WIeDucSnRR0JjxAABJtuBV40hRhI2uSZGC1HEJoJNStjxdiH4ZaWgDg1xh3D2g5FZZQVCQfXhTnMXQqfKyx1DrT9sabI01vx+Ay8bpsrjI5uLrh2mBAJiFUj6k6kN/kbC6zUqPS6pdItTYEVmY7Z0x6KTo4tDSq2pFo/FVbeKsay1DWr25Q8Vnw+reqRCg2BnqKdaEASnGm4AY5mBAMUGLVmfBgwAn4uAGAVK5YWeJh0DLOVlclFiVw4zVpL1TunqAwDXMoSSfZHUiKbiTrpe4v24ofemYAlC0KmXcmKVYr+OPrDOTFgba8uksNH1CfwJDeZX4HP7N61UCGIV91XZrX3N/veNW/55rqmmpQ79oqXW5w28DXL1jUg3ZSChgACUaaohZNu0xLRL4IBHih4UuM4aZrQ0aJarGpiorKs4+mE1ujLnsNEYXSOYWY3dWONctmfKnLlmtlVL8otL+288lR/ZV9//nxSZ7aqQea5n6qjvR9G4n6FeV0pR0RdbMynojvLSqn3tW+h2kExEjAwOxgYgIQdj6AAYykx5abqGZGsY6WZ0oRLG6iqIz4MifJmGgLjxJHUMKDJFYAHBWCqCQchKWhdlcAJEMvp5TDITEZgqBjGV0JIuyBdHJcVdDL+WlXcce7LTPTNA6JaykDzMcwHdntPncxZrurqxxfHP8Qv3F8W3kiu8TDQLLqdeosc0yUvVd2efGPZelaTnlZsGr4wTxUTRESA6Ks6al2iXHQ4X3KAkAAlRpIwUhFFzBSCY1rpvhwjGEsEmXcLdr9UVV0j/+7Jk3wQEQ1rVO0lE0HqrOqplJYwTkXtKbTEVQhku6qmUohxKv5SuPK+sREj1C8xogYkZbXfEDhyJVmd5hK+UIsRqExIuDhaSOelkQRcT9w3UVGLTHFTOSzXNt98mMvCv7PMqW191SqUukTXbVmQ/Ba1BWnDz5rXzpa2K81PlB6psio6oV6yiUVnoigBUIxrwzEhdECOMZzYM5Zm4igUWiMXmYkaPTMiD4tAgdoYhhjuiL9VQTTRzLnDzZrCgE5FpSiHzEOQqQ/Zah1RaYJHFTjykEQKuV/V3yl44GrmgDSDVVAoBgmFQ0wNmI7txBuhwKg+uZpY0YV2JppY8dalifu74hBPqc1wLFeMD4uFvlBMTXTR8Tckszd3y53qvtbayTWp7138Yg0wlWKMCUQPVjioPcke1ABRtJmKHxjcsMHoclhYZMMBCAGEAiEA7BQ4BMQHFBQoDCwoBjWmplNAgRKxVv4chxxXketYZsTNH4L9kcCspA/HJVfU1m7Hzc1d3rnNaoUXz391bhQqZRVZn9vNqAFzBNw/dVzxJdN/S8buQq5Fv5/Myjy/DOvS7bxj6j+b/bdaRxadoUWu7HHr/2ACmmqY6KRl0qDI6MB0gysNjEgaCoLFQ+YLRwQ0iIHmZgAD+VfGaQFc4QBAkTh5MirJohgJ+oHYGIgFzJTtLT/W+3tURpqtlT1MngGK260KtSI5se4OGp0+ufG3h529pp4eVaiFl2ybGznECuetpYnUJms3HP1NUlEXMzXBSv3Hbhkw3pNrvekfbDr0ja6k7NQlfwyuJhsXS9OS/YlSQ9GbWL2zpVKazzlNWnkxAXd9tx2j/+7Jk84xFUVzPk5lC4IqLGkNtg6hVhXlCbmVrgeutah2UjjE01BAAJBJNEBCIqBpIO80Pioa31TJfkWUXo27IyyyWAsiD0jodD54kLwbObsDmkUrh4vY5UWy6pEkFyJj+qdcWAHa8lvfnD/QNDUlI4zs4WmTQGxTQ21T5a35tRPnUM4pL3Ll/jzzL9vy+qn57IYmKorxT+s0AEuSYEOwlRDhCdKBHCIxhosFAwusYSCg4yVAaCBFu0yw/Ig+gUNFS5SLTZFoMxhh9WYo7NeZCuNor/xbZUXK5uJtBlsQxgmRyLJF2hw7DtkHDwOHVlncmxYjD4uZT6aqDNL5BH0H5eMtraGNVEGXzRvRA6ccPskwg6Vq9+Tsnr6m9y6g+K+vGRHHL6v3ElpiUTmwgqu4oZbna6QAm3JxAdGaZ5vZiZ2qBcVAAaYsSjA0KAQQTjwkDSQaKhUhSoNSMm4qiLrG8Z4A+JIBvmHvNAJe8hKwV/K89PwZhSPFKblNqE2MIWOKd0uKhMSAgBCtDkR5wEdBMt6XW5UZFG3aal6pWVeztrs8xQLFpUVnRFYahiyqdGsj/dUehLbTNsZxcUdxocYRapImPsUAdaQAo5LzMLYYXy5J4NedkNmcjIgFgqJGNNwGcA4NMeEg5fWABxmQFagQGS0wy+IYABwGg+0CGlMEBSHtEzeAxxgXmpRhE8JxIJ8USst1tRyBewhvqI6h2iyFntx/aBsq5SzmPzh2v8cFFiBspn58yTWNWKWUI+yL4Zpm44JS+k7kPLubEePbqaPXQf888q1wxLdnjrixQbiIabBwwQbkq/IIyUIPVoACkrmHjcJT/+7Jk7QzE2FpRG3hC4JMLWiNvBXgUmXdEbbEVAfisKM20iqADRJkHIhjg0YsPiEVMPBUEJEVLwAhisEgALWAgpjbkLAlxgUUuwo830anYzGh0FYHGBATH2cRAmigGZTg5JBm2PuUualA8k7zn4+tAWdpHIV/O97MryUR1ZjMrmRWaqq7htynKhHzJ/a06dvT//q7a+adw7vDHJgAnJJzM48MlBgqg8zXEzPISMKhsDB5PUw+BBJONYMl8IiZ0ICgrCBSzvAWCFlSZUvgXNUJmyEgQgJWKrKcvsEtZLMYUIhUBuKpMTTK0hrYy1ckeh928xeG6gJ2v73f21H5qG9SizlKjMtm151qbEk8/qC7X8WN60eu9HLp/78vemb355+s3+v/X3zzOlJv5Z/a+TlbyU09ILmzDQuIn3o8aAXJdsF0sxCoMBlTGz9I0xgaY0DRNLRLMeCQSPCQoIQwSIzUR5Z5QCkoGYIGDwjTsikar2s0qQybqv6B0JiR2O3Q+eihkYh9RZKAvaUKGVxtAYvW5IMjINPpO4/59rR36TPfT9PLKGW1KGf/ypgwRpbPoOjav38sCnCeHzOFmRkRu55ZdGMQnOAAApKG1kmZ2bBUJR11YnW0mYxQhkEKmUCeADmAt6TC4AgkPyDIM2zUx2Uy8s6S4HEEkAdZMOXGJJQhT2EMAlMDgwgOMoVkBypp2QjXw/E1GiyrZ1qQHAjKpqRNIgWXVqVf7ZKSGgFzkdZNDWoRC7goE58qMesazsJAbS9CEMNXnHs76mg2D3ErE1d3XJ54zJ+hUXfhO3Bk1IND69Eb87yqnu1/bKhS6GnU82kIJhYT/+7Jk7AzFB1pRG5lKUIgK6jNtI7YXiXk4bmkLyg4tKQ22CqD6g2DjQmjOBS+1603rAGayfjCWaurgWlFA0ZCgCPGCCAqAAUIVmWyBAcuyIwkmDQEsPU0GYBwQTBcNPRAs+4dpWOEKx0B4WD4gRQGRtp9bO6Eu/3/PzwlXS2U6z89XEQHf9y1aZLbEODARm6ZVQpe9qJppomzYde179n3f47E1Y6WZWUo5FKcozZqiGMjCJGxlAKidlNTazJi0w8qMdvjBy4EjQwJgQOM1c0CXYAwAfTERa4quqiA6pesuk96Ohc+K1yqApQmCo9IX2UlGNjA6/5sbE4jJIlx9HyJjYxMIkCAYig3zSd002EiCDp09hiCM4wxs98HQzzmj2o/+f3+Xyqjn6pHOkc6wHBaVicMTudYYoUZCoKm5Rbbh7nKCqOekGV570EIrChBBKo/QHAuEUA4/rpt3pdv+s33O//8pSAJb1s5AqY/peFACRFFky+ijjwLgY8KlL/fl411w0+cMMnRLpdxWmv2nbbA+fauFqavZy6k3/7w+oa5FfEnMbLRd3Azv/vnTQwXTPJJRei8PREKmmR3iFErgfJT9E3dNOv9fzQt//c+UyffoGLP8OUiTAadzbNhhAxzp/l+OHgBCIABty1t4APRQHKDOxBARQ9L2lsktVXr8TuVK+xehjLLonG40874uzbwmoxFKacrPPIY43iLUlORb5nJV9VCPdaT267vRru1YurNno4gySmNmzyDZHgeih6nFzV3blzGi3erhAYgGLea8RMQtSt25taYJvuWS1Va/7cwFwf5TEab0UD9YzAQyvjJOk79uf3n/+7Jk3wDFeWdRm3lJ8H3LuoNkZsxX/Z1VrTH24nIxKo2VsmVY4kTVYLjh9WPZsw2te47c5uO51O4taFEsYtQhx6xO9VUTKLZPfuN/iurf7+t7lIRkReSoC9BZ0RGQlPdv2G8X7EFtqiX0xJaHxafUm061TxWlpHEoFmWQKR83Mmm6rKfbKyqrYtFXd8df18kkavYtasxLFsOIBXpehgqZv96psPn+y991jqw3v16vUxpqv7559nX3em1JhjjvNL/9ksfS3GsnUnzhmmjmAQS29EzbVq1dSkJPCiM/E9tNrRUrzR2mifPYJm7E0P7RaVUJgDIA5zVQw9Oa+OckM4FZcYk2F049iWHBJoWHrWQ7jglCJIJS1XK/kemFqjvuG1xer7tWiDu9rJvPdsgDcjciMYNcKruXtQDzSz7uNltfepuQKHxcizD+yYSA6r5Gr2Ze0XGw0/qxvEjX8hqma5PKriuoHSucnxceQ/r3xd11OzHfLfMwaNMDtKc4UdSWvJFTfW/oY9dYGNaNW1gmjCASR4AcyytovOmrbgV8mQNaa2sxW/OoVBcIDqY6QQpEHnTQonpuX1rPOeXAjjvddX4VJmGVFH4JDBfyj89/zsHhLX6I7swZ76Frv26+eipSsjqq8rXOu7tKq1Ym7vR21RkWAuogDK8uFBODkpRuS0NKJtQyBgFYhHJM/hDjJjBiHJYoUAESttizIcKdNTYRcdRiqooUgN09hVvTPbhwHzRdMtqpuP+ciOQx8wqtygJBC5lqHzNV1oP6OOgHxg7mr/DbTMV6d7FNeT+NoT5WvGcdy4royzIrZkKfVSLTVzLdQtFdVqn/+7JkwYwEtWLSE0lFoHarmtphIn8R8XtObT0NSe8u6/WGFfw93FLE1AwnyR81M7yUCS2wjW3czdnq6zpncBMpRCbvurbyBAYGX6FgrFZUhNTeS3fanZm6jssrYdnzigUPToqvQE9MLF5wuuxFCXlNVWqnO8x+jTbmdF8w1rOdaZ04CqKk7XJrvccnbdUMHksrP6ObTobkRsqlVGfvkM1U57xK9FTEDtNuk7XXKHylQRDGK64wbGOikVUgATlkTxB4CpUdomlngoIjsCAAiJBAov09hMqZ5YRZSNTWUDZ8rtXqumGJZWm4i4cQVoJ1LQhqR9SkmNEwSyu9yMmx2sewI4hjTcUSdJKZwOh6Ve5fDwlqK1wVfUil3HNJKRovdkz40h7tv3Xjj/iulX6rizY2b1hoaifsfs8rXY6mLDk0eYKA/WU5VsgzJiuC/5+QeGANPaJKqxBFpd0Fko4BRtiJEW/MLfNRRKBCYuZNjO3DUCPbYXiwsoXIxaYBCjzgQj27jO4eIxvTfPfrNqI2PuyhkXicd+btb6+zU9r1bIrP6P6J+QUmjvo9VtZloj6ruVKG1RN0NQztRcCHPDOJJAGbcnrBDjbVMGgJqAiggQUGwgKXWiX3ORhJjmi8SbEkTXSnT7JrvkxJWlbrIksqsZakpbBcLmH+1Ms4Y90wAwNxfEqiMoZW5Q8ZVjUCZX5bpHgJoJXOOnHHHKwo65p35QjVEX8qtPudTdah200h1yA5jN5J+3MlpMypRYD5KyU+bXmaqVNe6GVxB1YhOVY8WOXIGrUGndXmwVLJLgS/NBaACU7SUGizKCS5yDbvDQNrCbsla8j/+7Jk3IQEnV9TO0xEsnSrKrplIo0SgXlMbWEH4fetqU2kiqFApfC443JAcy+biMLk8gfSPJvxSuwSaHzyYld8ppjIos1V6yfkbyk1P/V7HSRm4p3/sfOIJ1mPXRUPwxbMK3W/Z0bYoxQVHRdZGu6OoXVjCt3r5hVCARfqcokxgYYyDbzKqgBAIOJs14SwwoZk17vYFBQZFjKYqlCZNEaaamQaVAUYTgqZ+iIZTBmOAqIRGMnXPTzMi8EY84EZ5gG3BPwHki+xYQBnc2iysBo3FzL0WIAOAkeoGiERSnQqtIB0un+jDUXKit2+wS1Al+am1K6szqnnOYWtLHQsOGOQOHsrlDaDKDXGzKYdUUiE0WehbVc9botvZ07vs8vgmmi+Uuv2JLZ2fq9knXVCza+6pX6mmu3vdxcvhUnnthxy+k788elpfzwAWt14Ism3EmhpnAIGZQGENDhYuQ9SSQkFAqIWmSJHliQoGUYS1ByiL8FSVOOlgl0GZEA790Jw8YBptB4JSLiU8J+LZfozZZq7jrkWah97W1nfq6dxfesy3z9UbEdcL9xLRdjBDy2e4HrY1tRyzcXz9RP9V7/M9RbX88So9aFRW4G1OpM9vpACkkfMb1TJhUxdnFfY4Y0M3XDAA0wFQMoVwNarXMsGgCIu0AiERCYCEyKAZQNYBSwVQEKjjpjoFniQU9GhvKv2EzCHz2QBD730Ecqxl/8EApx1ZYl0DUAFE6DKNGDXUaI4iXJUXeSH91IEeILl8o4isUH5yS6k2Vyxl6FCeqtuB/XMdSHiV2On5mqOr7RuP+/ne+ZGV5RAwPBYqzoEljT6j6O9p5f/+7Jk9ozGB17ME7pbcIarajNrCFgVAY1AbeEPAc2e6M2sFPjPqrAJltvJHpo/5UVHIKI3EwcSOIICqBhDbmio0ZMCOjTm5KaiEKzSZ0TyRbdqH2yMPTRUZpYDmq380CGKPGEJQcPsQzrGxql3vsHKaXqrzJZBibmFnt4gWrtsR3qdrH0GIaswkyElrc6zsRVLy4FQLhdeMd/XBKluvBEyYScjCaYs/myNZlIwHFBkIuBQxAKl4LDKVsWKJlVJbYHNb1aYcIuOX+RIjD4QGhYqhA2LBe2Hrs3KdwIlDtehp76i8H9KIL0fQKr6GVjR6OOMIiBn8UewwEkmBtcoMfcfFVYyqRm8u2+TOzCaGEB+H9Huq5JA5QfMqUuGZFfGxX/UT42fxo+b1WcsPDcSCIb0vcybxksgYgjT1124AEIeGiyMiBgVWiq3VIQiAzYvEyxPZYoYigeeooLJMqRj8A+NBWANRIxVw2OKAiSzisY9UHmOozv3S2nm1OnsrzcxElP9TaKZ7sn716p57zTI0pz8vMIZoHiMZGawX43NewGY/kh+rX/IYlJX/nRLOWNKAAWmnTQwlKLOZVoJpy5mIzkZSH5hgdGLBCYVdJk0HkgbMFh8xGEk9zBgOBAlMGhYmFSX5wlix5gHCpQfY5DC00TGBFSFaGMLtc5sDXFfyh0nrf99YLh2ApHm3XKe7en8I3ykq0tnfMb+EzYz+RxSzh38Pzm8MM6Gtd/6Cxl9bmX4W+/zCWz/4ZU/OY7vc7b/nL/P3M3L/75+9z+s/q2///x/eNjWruef46x/Llb6udfHObsXOf+s/sW+fyD6/NYX7uYePkf/+7Jk7IwE2V7RG3hCcHkrSophI5kY4XU6dcyACgoU6I61gABSr0BKy3cw3I1vA0FoMioJk1BQih3L5BgVFQyx0MCjIcdHEB1AGUFkHAqtFiBHgUZdh5G7ITEpFfzMcl119+SS9P95WwsYV4nIf7S4avape5Z9w/9a5rOte/dTW/5+HO51EI1Lw9NMQ2mhoM0OEyVklax4vUx8IngiNeVFxIxDyrko0eqlAAAQg4oFA4HA4FRNXGTqAwAMx5hEYsqmskoGLlNlSiMMM4GAw/ZKJCRckHDRkwmHL5acYBFiIma4keTBW01RlSdsBoeHUMKAKdLqkUmYSyhkbvwwGDs5QnN5efaF11juvLHftCgI0kDkyqAvyYjdLRc3x+9WGvzyXbsI1qYbUlKLmdFnzsUg9rECO5Y8DHipjsIUqds7fitb1dr2a9JawwwjFWfjeWEWomVtPa6zB22LcpZZXtb1Zy3n21GL0sx7qk+claw0feV65vKo19ejOYp+8ccuVN/z///n43b5L9YX6TlJzO37FnXZhbpH2kDAnsoYHksQsRf///////////////////7/////////////////0lTPmvvXe/eAAAAJAYEI6GQsGg1HoM3LMoLOFbB/Rox0TCQZhRYQvKgswUAWtqXgooxoaOqahBhSwgFQjbgMAkKSgqDsruh0DjiEVWBMFHpaUshD+pJsgYWMgLGfd2keJtsDX30FDwxYDQISFyKAI5KZwExB/JbUeR7Y02ZQ9CtrabqaSqEEShRtgbxNMhzOxF6noCQeCNRGwMtCu4iXywT/OrCWYwD2mlli7bt3NQKztY48Isf/+7JE5QAI4ofS1m8gAR3syo3NZAARDWdnvPQAAhAvK+ewgABQBBYHCQG/LvwuAo3AMitujJrUslm9crSyWbBIZIAw1JFrzJHoAASj48yk3MyGLxCLUVJBVNTRHUj/ORfai/27eHLHl2FNy48ARBHt8E3kkHcdqHV1vyzucjO8d0kao7tiU4dua//w8fTn/8JHmBMJMKq+ololNJwEIAYnyBkMoFoQgQoVZjCZBG1KLcQsOQfxMnCQAooHoQmKKCGYll2Kg0DkGwdQNEeRpVkMULRLKcqEjftRoy8aU6QxJLW4xNXxpknTVwdOabxLSx6ptFyNnq61vXhZprjRu1f6iudeEHK8cQg/sXtKVdBu/lnvS2OCQfLKOBhveVA7QAAACS0U5ITmESE5WhBdOZh6SSunKbNAcWd/UNCKCkGgPFiKWHoiiEXDsaMDEWWggjIoWFyaIKPYXJ2YVF6h1GHm7CpiDT0W2g5IYaPPmLnprf7y6snTTqX2RFa4W7GZCdvd1Ha076DKtOvQzp/2mcyKru6brsiTzIUydJSuDAiQ2IVh1vRRtpEgGMuLIPKCkI3rpWihQkV2eSceBibIl3v00OSYb6eBDZOL1ri1ctgjN5exiGlD+2KPQl9rutWaYshLPq/DFf5QEcHZDQbegwoSPUbQzFwxnY6xlu8TJzYnPeclvmfLDTjSXjEUj37HP/2P77q3SgAoFEiLOhmwrW+zfrAamxEjJACTuYCjuKKB3lMEBYjQvqEKhaSnQzhpryz0DT0/B1lV8So8qvbUSVkjKRnUWdyYjXcRNwYkt0MOwT2jfJEYni7/CF1LvqPWglCqSSr/+7JEaQAEBVhZawwb4oNLSwxhI44QcXdhh5h1QhqtK+2GGZicJrRK5rhNHPlA6+qIgiFuRudTrn0Hmaw66ktQrbfJmJPkN+/oZ7swTxAmpNIHumdr1FiNtJqFACBltD8GwD8SIFs7ANIsKMB3kOLayRjrTbZAQZ3E/ngIk65oLiyniVFFp5EvrMFGVOHtzao4JTJaEmSYHhnDbMyf8/Xe6cXG1spV5zM5uvI4Rjp9g4dJIIa0s9n3Eubc6p+soLIoXC2pF6dp5VMcGOJJwI2mUIag29byRvShCILcZBUFowKIrCRIJiLndVG4vUlxDrMEU3obiKQnBmwqNRUS5s6O66F9axVHNVwJpDdFF4qW6phRYSHkTIAdMiYQkl3vmt30PipSZWRukWku7j1DfHNOf48R3sZPSR8TLy+rxGbvIOMzV/PvRfcdJqzMRm6+Q3T+Q2wZKpZ+cfUky+LLFnVKQkl8imSJAJhUGstpTCSIKizbqLt2V41lNJeqqD5uG+7kbcdr1ALu4sDpoZFYCMGllip5dnHoqkjSDnY4qRRXbeZD3W6JUAzHQipUBDvSpEZmjWGpnt9lyP7+SklgxHEB6nwkDDtiUXvqSqTbJ3ZEa8Ir5QzARQYyCEDc4dxVyLELit3w+bqDRUbJ1AAxHwEg/QCEZgDupggbYNo8hvi+JmfiEJ9PPS+LhkO7hMMo4T1IX5RQQ3a0gRcklhOUTDRPfS9lyLnXlYlOkL192zbQ+Xzsuj7dWNu9Gvt5Ux/efc9rcxPUyizLR93hpsrZ7b3/ObrVr72jIz+tzX1r/1hlNhZRpTEPQtSiLKWdn/6glZhZOED/+7JEiYAEL13ZawgcUodrOvw9JoJQWWVfjBhzyf4sK/GDDmmWDJlvkZAs1ooOkwwvY+6/adOWOPcyWNTz2u3TxqfiNftjHE6gPB8M5H3bUdSds9XG9Z5AiUHxTEhBqHh4fMlZz5ENWYTSbGp7nWdlVoNC9QQmOhmTleWeVSOBT+nIRO3Md2rDhWiOD1IC2QkhVV56UR5iDHKbXnTb1fF3lAA0okzqgDous9e83FbGvpYJLlY7TZUrYq+WaeGXvZIpM/c/DsDWYAkwrRg8pM6Tv9nCEkmPx12fYoolJrX3k833aohV4stthUkMFDAME2uYPix1cNSDxTfLMiY+H09nU4RZOe832lV2x4Di5akznJycuabuYYMizw8dhLo8u2lVQFZYBMsAuMCAxi8jOSJ7M0MAuZDV+aZdzLXx03s9T5y2TSx656x3g5Z2nWr6q4v8KbCwzUlwnJ1ZWJFu2aJKJFHOW75p2NxcVW0fw5WFmGWx/s1GtGEHr+EaFnM8TKcCBRpMJeGgkjLjC1UmFFFM0HRsjL79dmVDlFT4ZqNSlA3o2opANisyAOVDoB4GF2jSm6RRRJH2JtMTHWYvpe7Z7Uhj1LD8Yje7V7cimLl5HF3lqOT5QHCFAIgbZ+uegqC0YVD4MZI+X8ZpN17YUbp2ygsdK5OmmN5g1GbFiBznmL5mTZZFFONgkMPC9/QtjDGZYzMpLAK5JO8/Nwaobgh52eYq4pjur7kt+yEU4W0kSSQ4SEYeW6Chi+6PsiT9L5t+3irGtNYS+ZfIoGkLyN7L4fo+SR6KCkYwgRR9lQn5Qk6DorMRSN0kueHWyBzMb4hMGCP/+7JEqQAEGV5XYwYc4oXrytlgw6pQbWFdrBhzCh8r7LWGGZwyJIDBCIgmSP7MDoNaSQSzMd2Wgs2X+Hlm8NobOWfamgsMDEVZWEOZXHYOq3XPvYJxrYaP/TlvPo++cDkucdbbIAUa4YwOSg4mmg6wElCoGmdQpgUjxr9FhKulEsqH7T8nSgn4iiCMTIo1I6a5cMJMIIKsmRTAtChUHWHcettbOovltWZKMwcqb/e3rvEvDP3fL7oPka53wx3Z6rN3al1tuSrcx6d2TCc23mdNbPsKYvWL1/nts6gwcipQXMCFSH0TNSpBtyFsJFAgukqENUjhxCeiNESRwe9Lt1Ua2Hu8xF/pHLHefqHW4WZHGLYkcZRZqLgc802rcw3d1fNueVNDCOPS0zyGXNuIDtmIyZwcyLFBzIMZoIhcQv21pZFDI3uxXnVE+LhHmvLvehCXJimS5eYU9j4HMEJBgAocM07aSkNofF2o5XWAloiKAOIGKFvGZpF3Feqoqauenmv9c74spi7kv1IkZtgFAcRG0LganFVBWF0MoR2VUhhSBHrTnQQkSbCeHFtQUiZLRpqvqqb01UEppjrUmFGNwogkB0/A5a6xUbW0ieIgI2+zGOiAxT1Jd9K6bZQzIrmaJDyROFRJhyME4InwZJtMWahdFbhNAAt5gMAtouoDRZsmawZWZXULXatZurS35c57UgNC8yJSy502UvVxaC/b2cKTLWrNTw9vVb1tU3GzUcRt0mofcHwUx1UEMxWblTaUUO/QZvvTDGx9OG71uMCh5HTYn2WmQ5qugzjTDOCOlFZRBBd71o0phoZFcQeKFo0VsJDqDyj/+7BExgAEIV/XawYcwoSrSrlhI34QYXNXLCRvggWt6ymGDWFIXWJAAIcHQKlL3MxU1WAkIJMoE81pogZBwSqBWFR6pHVsFtZKeDdOaXQwQCUlwbGoyHjYLChsKJFQEORAC5sMbBOGpBSBPDJKj32dkJjwrAUGrKQo0SpEKnnz4WySxMtWNpDUOpoYMSxMZ0jg1JarKjKkBe5Uh7MN6kkZKLorecxVAANYBDRIIJhC1/W6mX5chLddpCVOCLqDOU4q3eGBsH6lYMy8PUTqmG7TCMe0pcMnjsh3p1WU/NDJ0OAj77yXNKcpIrDtPeeXLRGUGZK51Jd0zknMW3xi8y6VlYyO7uFpN+2dzSkfTbTneHzM7tFUwzO+vv794/bcf+PpZT1+i6BemvuQ+/ktMFRoOvAC5BkEABSSCxAZgwdLuJ9LsQTrsljFHdzkqfDX23jec5SwE6Wda680q2aB5Q1jkTa7cvq6X8ULX1TaUVcosic1fpdO19qoKzn4tH3NyQj1OgmDHk4LEQQxGsmhnQ1BZ6ZsOJIq+YPI/3nsgMINglVzjkZjNlKVfg9Es2Cohhlvy+YEX1vf4irAGCAAEKfGRg7xh6FRskfAtwVBMkJqepwDmQlGkvL0liSs6lIF7KdhSzcjTllahSBVkTpY2xdEAAYSL6Ps5YHXOJpDcND0pEzIBjhRZMkDXIST1MeSmROKQTL5qcBaJRKUH5UC8wy1wlR+pAa5Rebs9NuGQ7MsljFvMU93rGfc8GbKee2KQeTGuNlbbG/WQJtAJHkSDneNACBiQEaAABYqCj4FJDMFL9hcNKoWJFQE4IZVO09GVB8CwP/7skTmAARcYFVrDDNAiEwaqmEjmlLJeU7MPMlKUq8qdZYZqTw+AULxHDkgRwp3SizU5H05VnThZWlk6QW3dsicAFItYkkVtOj2JnpQbTvir+1jG1FYjuGWd2eiGPcMhQd5PzKtoJbTJZR9V7Lamt4e9l8iHh63m33ydMxs2Yd7xCty4lbu+6guj1u+e5WBrI5Pez13tKpPUOOC0RkgGKQAVFbASYnSNAQyqkzmA37RGZOng7TPXUcpc1+X2Drb2RuJpkV91oiFGiiR3aSSTDkkXtGZD+0UHCYsUUbTTm2pib0z9jaqw8AOYY6xhx6JoGjNESmQTBRLn67xx+ROmVry6KUFbRzwa3TTUbSXakV1hlcpsteL1ksDzV+WllFTFa7on7TpQFQEGAIAAYZpUVMPQ3lFrq+RGJAkqSsR1nMTVZQwJer/zqxUTh2D6jiTD+q0r1H0/Jfv6HNJSU+aeaY6ZR38onqcCI82CGwhK3161TAcoiTMLOxI139GVrLcpAqmtcfM6mw+XS7ezdtqeXqc87jVW8vEsuGWXCk8T/s2A85Lw99FVJJW0ou3+lY5iRyViuy8AiACAQMGDBBxqJHrQqMv1FB0ERhIkvckqs6Iw6uxryzYde91HZblY7MCUeOsuaQmTLb9EqJJyB7D5oZuvXGE9GYeIB0XZqKIRRdzyztYyRKwmtGHOijviSHyhQkerPA1DYMzxJKcSw7Hy900rWt0rVPy56TFstw0k9X1HEqsTWKOKhQgTnKg6qqjVGK6Es9bRtEgAaCKAARhBIQLMLIMIuUGAoxU6BFMpLlIp0o4sMxxf7zqEz8thpnMqkNp9P/7skTuAASAWdMDKTTSjcvKiWWGdhJddU8spRLKW6zppaMnMYdhrW8d36OGbXdxTOrble7ixJu7z0ESk0DVAoEOdxaIwocmkh7wJj0fqlos2+tqdVZ8M9AnGnUuYMIqSMtHWrPKCesB5MyjMVe3LS3w8fLNd0/aG297Q7l30X83p0SGWDuAvEKb1Ls25OZzGhy8JRhFKOSWP8NMmVGQ5kABmYqRsVBpItW2NXb+Fllpr7lCmqJUdfKkW0hgmPAdO9iHDXB3buqXsSVRPWqimajtN6g47pePlbKG4huFNeoM4gvOjA9lCGlRapWN/oSkjqEJB5TmaZYBftdUfi4gRimUg9JiBo0JqqmvqIRbaord0iyNybapNajLP0sTSsmpF8NkOI5JN9QezSu2669dxDmRMrb0pKfH1EMR0nVOR5ICFAZQAJFwvSHnCXJpMNGhI0LSvNnTSdZWSHGm22LwS16vUBab4guJSP0TjTKrihIpsNfV75bkHhUoVMM2lLfgoGtWobL0U19Kn8GbjEv3UXcYppdU/0+PiNe4qG9acxaPn31Dc+h2ZiU0nJgV49w546cMNK2n06X///6AADQCBQAcRGGSGDEGrvtkL2p1gEEg4PF28LwrWXKKho0s5b8OxiMM1BMYHRmIAGk9LfsA9d5YgdUKJoDzWC5ff+UY2yUMWW95kcvsJ++yKOvKT8sJh4GwzE4+GoszMrdav43e9kf4v/PPez5cFt+y87mKxiLP2/5tGb7qden/7K4d9yQJO3aEe032dt9pSNLAAAYAAqADlyxLIdZAUkGSQGhpgJ9rNXYCEq0By0XhyFY9EYcC3pCXu//7smTxgAV4XtEDTE1AeyfaeWEmhFINi02NMNCCO60pcYYhsQA+HVV7jfEW0Ti+LIWIJiSna3Wk+MsuKMGIijFGm8DBVRVDGckN6RieswcP7idhce9YhnZau8PfEkG410lJqW6u5OlNLlBnXEddINqm1liaH0XcM81zx7jKGjrklH00Lvv3cm1Y5FUALACSAAnR04RGRkAanaaMCY4QrEIXgY4vJWMOkm6zpFF6lY2JZ00jWu5Lm3aFxGbUtHd6PAGgPpI1Qzuihg1NCgq0baPcoRQoq/IoJtMIeplYejcba2jSPbRMTjKqyUcr9Gn6IIf1L+02ffltC6bC3DO3FZL3s69RquQOmkaKQ+2vtv8JNUz7cvlWraRksxhSwbqlhmcUqnn7p39/iiltqWyACgNUALJJrCHxJmIXYAxlg7jVlaFImeEpFCxhSdOoQ1hvWh1iU+sOiSAGYi9DrVAlKcnbzKx9q6ui49fvrDT6KXWc1/IGdlOuR988/OLunqPlA7mDx+jD1cFpM3Uj8AXppe2sbIfqXxvZcv8vBOQpuqdjduCp/qhBqVBH7KWDQ454AJE/QCAAAHMGdFmphhBnUh5XAGGDAYFADHAiYcycOCNo77U2yKTaDDDnseRwQQwnjVXyYvhC4+iN4A6JpYnDbc+jU2sFbuSCv4hfM9QLRlWvVYUxrJJxYuwcXfqxMxjRNcZyzEyzEcXGRcEEcvR32beWO/HcDSW9yqmv5G38DozhWehiXDn+cMHctdbqkOGh0Qco6EupqvgbHs3in1O4ADEiAXESSVCEFvh3UWIUPEI6aZcMSTaQ18szmgw0deUFM5KAOP/7smT0AAUSZtLTWElyhWuqWWGDjBNpg0bNJRVJ7iSp9ZSN6PLk0GVhkH3I2iyMOUwJlmGcDRAjlSSycFSVOTRPSDjZgPhZejzGO1FYyoIDi+2GDXKcYM2dJDwebwv00tz5C+ZGT9+FByRh7jCKap0RgkSBpSth4Z9NqgIAAAQAN4KApgsaGs6cYXC5gYmgwFCQeMQjBIhMRPokz0H4I4BTXZioeXIAHg56wwXJhDzP58W+I5vi4k3VracKed+aWZ9AEDzpEwg2BCGAJwsXCf4UmYgmI4+Z9dvqAeOvk0KzxaB1vmJSwQNIVoiE99RmRzYa2xqbDUovZ9inZzxncn5X0L98pqeCT9v5L7jO+O+ntT6/3fBExjoRiipTNi2YOO5V13kPBQpUAaRLxEFDhZn44YBCFpgg4YelyH7E1vFymTLGjhEBkjF3ucd/OyggMh9EiXkcSPNRZHit4VX59WjaBC29U0eB2qGcQpB/T3KJprmhFKEOKQ2LDiRxL95JSVaQIv2zhD1NrPQFzlZHoIweQcs3EHs9EBM6GUijTBMUY5r03Hv0gBUAkSUEqOE48RgEYN/mDUiQRh7WwsNoaERApan8v5rS719CwG1qXPzSrQZbL8dsClUeuVHir3F8T9fA0CbCg0OgaxNATI5IGXcibHoHHnWtaJz3LsZ5NFJcU78CBQhPFwHswaLzQty+crb41v3ZDyjvoqNYcDhHgZbzedh649GP2K3um17GHdmpmyN75cM7TJQ4ZagKlzSn5aO9yjZ8RuevvTlgA1AaSKbmFClJgyEtK+yExRZJ6BHnaAkTRqJ0io599pbIJDinl6WSMv/7smT8AAVYXFAzj0rigCnaWWkjiBSNm0lNpNaB/a2p6ZMOOOgJEayQKfD6yTamzmqxRBmI0Uv0e898bzjb3d2/bNoSzQ69PnPqsYh6HSRmaIzkDLOCc9jLwYWvIBPdL5RSB4JSmRHWNSh9Z3KMWNp7PRYSDQAEwonu0QABUAAUQEUoJBShMChh+554A5iRygIADF2isgluWccKG11MKaEiJATu0SjbstTybA3STzU1jhVuMiiuBQgAMXofQudh9tRJomdm4zdIi22pf0vUqqYp3qW10hCTeS7aWgcbLYn5IPT64iIz6res+P/G/ZxzEq3mznlX8qzXMvlil/W3c+JdsW/Ln50nuTUPuDSecqjFmoD5V5UAlAAABcdgEgQ6l0xBkEBW4mYiTo1EFSTgRGYcXYQrGBV2OrRS4VDuL1tRuzCpRYkeAAMBk1l2xjpYetGbSmh1AevomoONlTZrQXLG6WxcgphxI90MrZMuZyVMbMe8eys2Jkreb301Xd9nCknbzCbu5mRXmkdLqkoa2zGzvmeodp+2iRLHBdP161kr1ZIAJiA1GLQYYCMZpfkmZgGZHCh1FlLR4YhKKYwhBYy1BOFNAssPArVgdOEKjQomKoU7BkR5IkySfLb9h3LJMQj8mGV8YL6BQVDv0BXT1lPIlI7tQ77axdUvoIlq6mKxjilCeuxhCoUob/uf6Mp8nJ+xsOynlJFlKpVxvvLa9QnruoVDlvlhMXTr7k3iNF+ckPKMr6fDjG/20osyc6PX8rCvjltuKGMcEXHZnHssLLysBFwCetqCBNnQGUirkpgcgBbHmAaQU+mCXRcqHm3SFoUdov/7smT8AETQXNJrSTXAjSraGWsGLlb5dz4uZYXCBi7pGYSN6Ay2mdsfIg1aGz5WQB1IyIZOr84anUacrIuhirC2WPwIDngIhUDixadHFV4g+gbGgVmu+FHsAaFJ83fJ1TCKYM9FIrSIXd/BFCnHpvec7+Xhz6HM679AxZwwAQ6OGSjC3MhAM0EXtsSlCgAAIAACADkJ0FgAxlTBNuc2PgkFT5ERabRrHigwYeA7wdNuSmyFbK3enl0vI51xTpmVLXlm5H914d4pvNLdVhiExJIzaaBFqGDtiugu2FUdqQY2TasYKo65wCH5bjd1TxLpGteUkWqqP06k0DXxCn6Zk6ahKTQWa/ukp+J59a92JwUy9Qz96f1aLpKEZqHmdQ5KBRNMUAbaw6FJ6koZQcPCtucmvvpL2uCaAmdLDciJAUa+gqmMX4p4ysCQCFBJ4QMplKUZ2oSSvIqRznXr3r5YVsVlqieUMdpssd61cmQXU3/HNVFCU2Yip1W6saKOvK7yijJql24iZuYr9eOffO4uk6mOK3iXv0H1kUm53yNOvUGo8cMNiGdp84K0NEOTRhk2PCoBleggAChsAl0xNtMAkCdjEhgGkGRQOThGbilUlX79piJGJ9iSUbjDOwgJ32+6+ywC/I/GKw+jkSCZtkKpK1RkPxLnBTvqPqmBrLJUDFKB4kUIWEvFislYiPQgFyGFIEKNJU46aGco9cFxfkWzZuxmvpQg/kSxiTjU/4O2zMmklov85R8GSTbdGPx7vK6ekue+3G526H5VqeL2/SxcsI0EaeoBHAIoFMVdStNRI/hhAMDTAwVEtszHXELksnQGojOTBP/7smTzCAVNY1HjeEnwfWs6zWDIhxPha0KN5SXCCq7pZZMiKL+TsXi2MhztsGdAopNR7qN+O7/scWileN0qcDJpp5IXNjqC99RUxGuRB0R1G6TrNVCMQTKHkxF07JjzZ9CYZeOKGPEVHMapv6V8TPDJ9d/pULHjxIQOJMEiDU41HJAse8lVTQIIAYLCpjIEmEjqZFuBjMSGFhgOgQMFRhtBqTJhVJuT/K2r6SHZk5rqvsji3KWWZtYkagmWwBNT+1tRSmLB1+aQkx/UJhiXk3vLFwD51RGtKycWgAxW/xnWfMP30iFC3T2G6KyyRzcYtM0a6baudJEzfPv8y621Et7ZffxFu2u074tXW1zXirXld9WEmqgGq5Ux33uR1US7cXK+7zz7q3zVgiPzBxQw4bOMEAsJkyMLIgqKlvSgFS5MJFKw6EZiR9weGX+U1j3vS98dhqfceUxLIa5hX6xU2i0tE7KRVWemmp5Fq56iVQvhblaNbRbZOn1rysRIASUSancu4IOMxm4ScYqAhUY4RKTfGBlmccFFzgod1z4MXgTrkbqYgUQI8sILI0GE/5YIHBzb5EAAGAASig4orrkBDGbHzBJigosKCD9P8oE2ziIVXgnQHByfjX0STGQ8vweh+ERdxajJSLStFFh6mCGRnyakt1ar12gwwRDZgQoxoNgWVA0ZMDkXZkSUKjUV8eeMHzAt5IsK1pNyprbq/6ryjUsRcEk1yVXFNck/ons83lQ3WXd4texlcr3MDxZzxIMsksRKolRaVOZSZLqJAAS5I1nOStPcVFnBhzIMBCAAknTLrMUdlSQ6PJmAi+GytyVyjTiGw//7smT2AMULXlCrmUnwiuuaAG0jqBLhe0WNvQ8CFCToCaSOMaGDI0CYjGK8Yw7IOIZMsFCMCEK4JssozBvM1hac2pbqG+ucP9C25fLu8xlDCRdpnVKD6kGNIIQYwvmvaFh22j9NuMZQPgyIzPf9RLtfKZgQ4Q2VZGgRwda/be/11QACQTDDhhIkuYLS5r90nFh0YCIJgUJmKCwOmBNRCEdCyQKpU4C6i4lBUVlnspBQUBVAlGFTkmA8MbG0MbjYKc8YCnOuI4URadh1owb8NyO29GYgDcWmqvIM07CBZJfioCT8CYRA3AuG3ILBJCpcrT1VqLSqJSpxcK31i76guYyljWaBpJei9yydIm8aIv0SLMuX35HdnqLq15TdOGxJb/TZbKhWcNIkDGaXv5zbs6V72SdywgAMAAHMA4MqlLZnacgkuYYoYEAn8Si0c01jEoo6IAacwWCvsTBn2f5gkBuTlalkaa1XpsSzYOSAidOnDJ2pz9ZryS4Jq74HqalpI6yNWdjrVmkykqZ1YqECzWpaRT9/yHPPumqHaRnL2azOHZIZ2n/l8+T//pUsKNhAQLO1UEwAAADDCwAzGUDzB4jSWTzIYV2iGF4FmJITDAImHQDIElV0cYEXeCSJRQwgY0xPgzhFVIk0Eypslw+jUqr/1drtiefI9QUu5urK+W4hG6aq/jgw9pCLw04NkEsQLy6Rtsk6pX0+xbCreppkImditIKTMsSiXEFdkNG9TkKH7GKfbIX4m698fD+Hf7iz0/W3bO0zcunqfTgr7ys/8c7VTuZA/I5j+hhDtpMJIjIjWKEAAAqBWMABhO9N8fL6gR4u8v/7smT5DIWjYk8bj0xAfms6BmjDqBW9eTpu4SvB1p8oDaSOGfqtAaHskMAftCgSoYsBDbhOyuZw6QBSQyToANMgkoIW7Jz1lbaa2EcI1YWkpwWGMaqNbIftyjTffLEuB/O6Ws0yq6ZFP5c/z+qDiM5w3Rre7c3Jv77YT7e/eolU5oFdzuyvd/8VAAAAMMOKoxuLjFSrOac85OTDF5YHiGIEqYMDwYjRYDpEJlt2YMKML5FEWjoQQ2ZFJ8NNtpuKXDSV8SdeE/RzTGJdDr/P6/EL5VcJ6MZe509F9QLDVi1K5iN267f28MrtBfwKCkcJcRBN0kYGUUYlx2qCiHxiOO6+b7OlU4FCPfPEKlyWU6qzXxQPbWQ/XQP26uv5VWJR/Ji8fT5fXz95UfGE87kJFIKqi8yJLf2HwiwTP9RZdAfnLGAAwAggJJwcYMRQQyCTAdkuUsAwyx9WJfoyobIFIW0hr1DShRB54uyWfrpP0s4ELqRIaCDSjYMGD8g6uS3NV9CuueY6FyewdGyZlIzdRW55vXLSWGp0FlYo4RDK3JcpIkWQjY7REDo0weijcmACAUoYWUwMFRkVVnDpMd/BZj8Lg0RGKjUZFGoKJMtDjMnjpMksALLCIacVCnOF4iwnPjgqRmTQFsReBM5fJFpbvBcOoCmlCYdcH3gzSQqBclxC2DixULASbssMmIHHryWD40xZd47tqm3UsLt3Mxngy27FzjFGqJtmHkJL4iVTzU3dOCMckuOhBtmae4Rn2+sivFkmj1mT2zbYjl/XLxY+xHIRpaorB4RxpMG63wo35Pu4/z7B+NUaBAFzExEyozNjuDHDwf/7smT1DIXEYM4bmEtya+dKKmXjWBcViThuYSmCBiQnibyguKBTFj00x1XAgZiSY4htdkkNshxUTV+xNgqF0WfxvINh1mUjfa1RA0PspzgXGOWQJJSVDkoQHNVFLEYtaQ/xsl6Htcmk3eWzqbwxq/cvfdxPfbNM11XPNS1emjz2ut8Ota1GMcccYdJmFpLv5cOEgpLFpI1QhQAAIAAByEzjIYOzFs5zRzMgaQxheUZgaChiuBhj0C4VAcyBjShSOQZEkyFQDPFNReEoCS+LCSDpQk0JJRASNSs+Vy5TkSObLnwnGMvLDjVuRa/AgtPXC4W0hNKgwd64ZGhfEsTk3KFSVgqD+wzc+JAbcXCCH10hytXwF01Y+IwNsvVVe1g9Q7MHUewxufaiSCX1tP45682MTTPP9nHF3fVdk1dXbKHLF2WadNneZ2Bj7O1n+hpJ3S1OJhQ+moopSRbNfrGkzbAKgAMeCSJKNHS4KCmAmAIQSBlSJdSpuzyQMgg0hMm0+JmNCAK/4+GJCORyLx06igv6zJT1o/P86ROZmHoLoRyoUVvLN/mxmchXwj7fSsOMZHDKg9+yqxym8Q4Hq2FDUc+oLzN/Ny/LIsiv/kf8+YMg1gXNM3pqngIAJJhiJmagHmUO5mHMcsIoKJXmILpmqlJ0rQTIibXgoYieJJNzn1PoJVgXzvW2WsE06vJrC8vmfsigAaBXRASnM0sxPVwq3tyJenNHSTkaCBS6fiq7utZncHTDU3kcd5DBy/lVYb3aTf8g1PrI0ftFnmcvbmY92lGHUuqxVuEOj25zncvXnl/MpHu2jnc62yMNpRFa0Jdcjf1Drf/7smTtCIZCYU1LuWJwder6WmmDeVR5ez5t5SfJxJ0oSaSOEeIwYHvwvAM4gCBEq8EojSTAUwLimNECEAypepEJZoDQ7+JzOEDgcyoxAjJ3UtiJk2bCxpRUzJCfjGQdhgl9MHwU3kTWFTLKx3c1PvTFvT6DFTFlwgicaf52ROtD9xftt854jqSr2lfl9T/QOLKmWAHfAzIbH2iENf1AAbMSlTCBYySLNW4z8DEKEQOLTDkAOPRpOR/UBGgxuymI6AFqygEttdZaBgZIeRVo+3rLYBqxJeaH56BpK0cFp6YCYi6BeYZpXXMPFI6ELtQIIPM0arjM9it5ALVdeXu8PBgjshniu2MNm1ZH5icXrWbfy6bpEUcuNrcqVa6XCoOhvooRqJ4sD2aVKhSNcsYmXcbs7/tqb3mRMMz9SyRKruVTJLUQ/V0lnjIrmapcCYtF1yP55M1J1ui5U5wTR+sw9/UCF/e9MywbACZRKA3R25BsG5ijRu2qPhINWMrYlyaNQMVWpimHDdhqKZzDkIag8bQhCgvmIg+V1p9VWnIFOPby+5Zav7oVze7R6YNmLjmkKUmhNRqOOvc0osfkArkamrj1IxlJLvGp5a7FKJErWWRNXzjzpSNbGvwfVaZarPemx5yU3V3Zo2rt5YLeUWLb6vLdZ9YvdlkQiw6+07jWmuwug4TbJkMxIl4DD+QlZSq+tg+bsTkxz0a1ODAoABABJEhsYLE5nKOgINgIegbEbGFUBYpTJ2mcsxT6WQ1MiBgyUsoQ1XrhdarMs1euzKCt8DjSYKoSDuXwkzoddYMD65huZLtjAr3W1SWCDpTtt/8SVmJEPP/7smTrAAZRZ88TbH1wsYyJ0WsMKtRRe0DOZSXB1a6qtPQWoIJ4gUl0JczkU6n3EyCS6BFlyNVeMlsvUMLRCL9KOZRIqzTTDFItalK3ta1rPm7JXqlqqkvyDPhWIWsOg1KZdC72nkumhZ5bzZItfLkmjqTeCgAKYA+BZjnGyJuEyAtsqrIWxBkBzl5ap2BDHW40ezxdML97BJLOaqs40XkwoWfLtda76GV/L+UGDU13lSbcaLmerfvX1V5qtqfv5jE6Vo61ere9Eb0oY+zNVnzM8ocFhRAKIMhnNEx0TnJyySUAoAJBAEBEplIyWCw8CNNpFzNB1EkwgzpSIkFglJSB34ZIo8yZu7YpHEy/S0YRMLJVveR67ceOXtMlhccHZaf8h8TrpB1XbMaHHVauamrL15jPmsC8ydtpgcOSmvV3CstvVrtUhdkFn1ZZcIeMp+mTJnyRI8yTe2KUDFW27Ioo5PULfzY7My014Sh1VZ9a4bZUi3GjC0f3S5UKfUKxF/01ZzPxdZwp2QAdhBAcKJILKkFAA9gduNoYJUiLgykImhEjRksp4mbUznD6Ogvq0+7LRw3DdxtGhdCU1lKN0OlujrPaxXIp3mqNEAMO3JtIrFrUisIu7pbxtisqq9D4duzKqqiv30dq2pNv5Hzjn7FVxjqOTExKWLB1o2sByB30fSADIAiqkYUXGIghiigeBcHKnxjQcQBBgCMYmPCx4lak+s5WZTdD5Y0UcSGm9SZXVAtqZA2aHJaXlm2F1S4UhafWoyYNy0r/5Ou/4Lp6QI00FMRxWdhy+tbk0OjXM4beJ3dgL+et/Ys2rZPOSL/oy8OZff/7smTIgAU5Xs/LbE1CeEs6TWGFeFNdez8tsNNB3ytoIaSOIcebFHR/TNjkCOeUW1iHf3P7a7zp3+Iecyu7E5k803miR+9k4+KZZWV6gAgB50RqAIqMgKPKCAysRDiJKDhaTK4kUIvCV5tBVxE5U0+LsXu5qjRKbCpdsojbEbB4w3pJWtKT5M3uOuWKyTImhkTAYmrvkx30MpLCOmBwUXT6Re9/2SUNCKSUibq5UhljMZZsfUPq37fKr1SOqxEFGMyXFXyxAEFzBh8C4gCpYNEV40iD1kARh2wm4uNoIjITmaLzUcW0isulh7gMSL9pqUViNAWJzAqbDDUmTbnhuGU2UNRRmx2FtmnZpv+D9jU2WslFDUFD8emjRuXbd5yQz8kZLuq/wVprUpTy7lvunZcd2xBkdnGO7K8trw+xzKajlub/ry2t19aihmx3xtLLJZx1ZpOfgu6S/X8QB3z2sv1sk5fxgiTBBmhOoAzRVCiFxYEqW0f5rw5l2h5Cnyrwwy6TtX+5R7EBAh7FRXAwigFaCV4OUpJBsbQSXpJwYpx8yOVbDIjMuZ2vRU87PfEqTdl1ta6ZHeaXb+rVlfrRmBsjiJpkxAFIEp0dRjJBkx1CNqbDpiwFV4gAzLlEeMgIAsXEAizVeqKKbiYwYBtnhC0y4j9UebIJl4Y9A1IcQLED4AuSD0+SiENH1V5dUMXLnhOGl5NFIKKDxvGCMirHZuEXwSRT8izrYCTryhV7wWGxNH25y/JEvOnTcFEEuC19+0py8t3XbdjVFnTHap0rTdajp5UVr7cYvWtE2m4NX7Ulv7f2X///6WAYAKTbRcxCZMgPEf/7smTXCASqXE6TmUjyams6zTxiqxRZnTrtpNTB2yzoaaSN6MwWzCgABDVoAgs05iTj0EsaJYLMSmXAFGQyQpGFCqAULNWiQj+YrTLTa2LNYIafHWEbM7jExUNqGffhQeEpbZFChlyv5X5xo0z8v/8vju8c4f5rC/Z2M/PzNvZOTzqkU2JckJKFQTBMrNW1qgAACCSUbvKgiZUAggUMilTTCsoMkB4IRDARNibVlEtNge54HXFgpXuMAMPZE8+MFKasibFHriN2g45yARjG1IyKzcEaTNMRHZHGo7zhDJYmsri7MY2wU3nEH6pwGYaIHRpJq+vNlibD+nRL86TzvRJ3dD9aM94z9B8e8V/nzCr2QVI3v/BX9FaZjMo3fAYiwkJQ5IkQU7P2ZGpuFj5akACAAAQQlAvDJYhqIALhhkELJF5GRJGEENokM1p1Eu0iBQXBsOPdGUsKcOAwbB8e0HLE81RdKCBM1qSSbc8m2Z2+w7ugF4zHCFIiQ+LP0mwr7ZOkNiMi0NzdehYOwgPiVRoqxsywkYYZfAyN08gm0wS0AAAhGgBpmRCgZCQRrz7mCSWCDoYxBJosemFg8Y9ADWAvdCNR8uwBUGHZdYhGvcMWIDB7Ugoaoy6qWSnUmcNfcqhiXK8wcZgT/Res7kgiyocyAsUQCU2+xCPw4PMYfL7mzy7arH6VqUkdmQmZuvLARIDJMHfKLmM9Kw9FK0oTZOsmegcpkdHZlzfpEW1Wn9K1kxc7i+WYrsfar5KWdNzvJrM/9cmDHbdAaWzI/VJgmhVolJLPthS7BuHtby7k69a0/sc6sO4AArmYNnxBGBVnRhiBUf/7smTxiIT0XtBTaTVQcaXp2mkjiBihmzBuYYnKDK0miaMK6LdcBBIE2iEKXpTMTRbcLAU4zYnHuKyCDTElmP405qGUipXUeC1Uhmbhd21dONHomHi7RwRq+rTfibK5Po+sfLbN7Kfta7dTr0utmfjP27PW/QLb95PaZ74hhD2Z22upiPZLStrt1Zrbu6W7MCUY1AFoYkVuxSoAmBSgYnHzIfEkwrocGJ+mmcMp8wJzTZHlw50SUQPw6SeJMRFCtsJVlvWm850YXNmimnNJGXSahc1GRmTkCW9RVgxBNG+FwL7RGiQLhtRKLYEIAwbVZI5M4xUUDMZzIMtyZG9RyNuhWG0vcfOROihBR0vcoYuF3fE5N+3klpGWfBBa+xWnPYQUypN1C45KoS+zzIQxHR0LFLIwaPzlBtHC5ZLp1nuvVtvknIDsgjZRRSRqRgyUtOWXa248ElmFdLcWioc4ixGmNm1diDpPXDYIRC7kHC8B+xio0EVlABXxM8AJzohz0J3gGaImsABcL5xIifkVJ3eWvAM0UOLiaEt9ggyeiET6Ff/3fiIiTifdPr/EL+eX4sXBgscZBAm4+sdxOAAiy1bjk5ppgAIcsOaIjKFCUoyEJZwVJDA0PDAAC4bIncZ+78vpHrbO/d6JzbpQVmyhChl7T3oe9zW2EI0xLA4AMmbFQEHNTNmzGFldCorKgcWm+naZqJtUCMlKBXEOxWRwQtxU1V43QYO3d4i5C3GvLclDAl+xaUqBsPQzmkwyIdRWFo7pBNxbSPzaLLoNTYQpqWge94FQLadWILEabO33qwau7dNFEpy39qbZwtOfeELBZLvcIf/7sGTsgAVOZNDTL0pyd+r6fWDDhyTxo0tM6y1kvDRoKazheGEGhG+qShN5UsNqoJapIS10kiGgtMXe5QICQBwREEBCYDS7c6xdQyQqDvxpwUE6V7zID30aCoOW3UHcJMRgi+HJLlmNcRUzAyCyJWFAxW9FcuerVWdRaCy2SPQXEf+dmG4o/s7nIw5EjpMU02nz2dCAEAAkclj4hfD20xMM1Do2ZMwE43RgcIJIzooDDH5acYSCJDPXVuh52obdJwEq2PlvJ9ujkvBSv+8TFpJGYCHQDAFMkcvuZDhuymgNIg4gLGAKEWHZ8JHC6AFVYmbbIJnmI3ArrQDKHqeZCxLqDoEMJ0HJ1ayD6six3rr0z0KwNUEaVoO/gkIuRXEzAbJUArvKkAgFYGaP7Bg8Zozzl7AQNdbjwsHHSEe66mIkhIn0bqcStFV20hRcumj3B7xslAU5C+q80r3jXOvd+WTLrpmcM7fda6eiVjc6JynVj8XkDYIpIIblZexzLaZCDi3NtHae48QR4MAC9EzPuyFgGxSHqAQytOq0V1HEVgFB+GkIZspAS1Y1ST0+7cOtwqRiHKJllHt61jrHgZ/J2zc0q/dVAwX4pFtOdQ0MGoobABh2EkU1rKdR+dWPG1bHiljxRqUxpgL8UkopqWXUtLMQzes8jtzFh2xPpH0dU6pm0bChiQtWv/i02s4iTSF3cU7FozMmqIakTyisImbza5inXH8dSmViAZOIWICeeQFwpUzHqwLM/hsMHHOZXuz2XQQ9qkJUeU1G8ry6sj8mZQvpJCrOnCcjnWj7jkbWfL090/FN14xxz5FzJ8sdXqEcR5MK//uyZFcABsNn11MPxfrWDRqXaS+YE4mNUKyxMMH1r6v085swfHe2lQeKRPc+WQ2EScTjYZcvaHb6iiObJ6sShmUfX5JYvjqZp7OUcmLTYBACE7JgqFC0AMsITVTiMUAQClrYXQM6Aau8LT3/cCZhbSXdGgctypmaTmHCBQfFbc0UIiN95Da6xlpMrEQarLKqG55xzpHwZVatz2l9OD+A1noLe1RoyPVMV/HtGRbczNPa0q6YcnAjmZSI8/4K6SB+uS4MBeSzo5IYvFWyGUdLY4wE4dcSUh6FMTc5qdHxnxCiwuVEmZUWdTlc32cCQQXHCYC1oQypJNKLEJTLuMwJMIUVZ4GCO9Pk0ckScaVmNwwjdYpjhgNO6I6K2QHDdpWpkruDHuAJATi8SQMNk67ws0YKiliM6FxeYaNFSE+B4cMAYYXqcmHpSoNKwmDZTGbqieQjQPWbS/ckK70pMi7pRp1C+/PcNgmY96bP2pPNqOfzRJ9ERbngQzp4rdklKvlxCJ4I4syqaJT2Hi0Kg1qYii/zqHiTIWYzb3tPYy5o5+GM9LVttZOXRkNavtMU9pmB0cmwN2dd8lLrSn6nnvpbOUACohtm2JEI0pQAQAEiLFwQ8LwOkdpRgvSIO82Xw61C5Koo0ZHhvjxl/izM7MtR4bJKpUvVTzRsQAuxJTigi0N03mk2lR4O3vpyc30R2vO+hs6nV+f55xBFpmHtPPZFTcwxLvoq8/dWSpjUXNIA2FnD0SD4/PRjse5BAudomAXAEWkATqzTcEzLqzVFEPCsGFRQXAAJCxIdEFnUzzBDVJKVIJnfoXLWnTxyDrNNB9LTwZKF//uyZBqABO5eVEtJXaJzq7q5YQKaE/l5SC2k14HqHSrphg5oqv18kpOHDdna7xxlfFF7GCF+0rDdiW3kcSFoKjqnUf+qRtZpV+khcQSVqhWq5SIam7uGmp3l5JqW1LTUsXzt1pGp1bWUb1HSJkvW97O3NXSerOqSmZJSUqLt8tBFubPJNiGq7DsmpYqEDhuFfEEQ8Hos0kKVIwEkirMsZYZ3F/uiqg11rTKZp+GGo+SyZmqsiUg4wLiA9k04kO6a+mbx2IzfLww/U06EwmPDWlNEDY5pW2bDFy36otcj5UqAnHuyzKQuzPRMiNVGaG6MlAY268h2VuDFIZBIzJvimUMBzFeYyYhAuZfDg55HS8wQogALkykDOwkFBQkAjhoARAwkIGi8Mn28ZSFACXKGPluTNvHmcr6XhOSzFw7GlUaLrY8exVqkuZSfqT3ZCb2pqq3ICZsbZRRr9C3kJ5Vss5VLoOt787NQycpfU79qol6plipj79jiy3UunUVWa1zEdskiOhLc2Is1wXschGnzW1IQjLEiW4Cktqnjys8p9XQAQhrk1jJYh6CmnQ5etIpMhEbih5aJJ1kjG0flB7chhG9Kh1L2yM3jDqfTw/HSlmImWkUoUD0m5xDPPXiznKM1K0PUXtM9AhA6azaDs3aSzoCcOK7jFi1EH0EZDkfhJ96SAQuop0LED1RAxIvqSofVWRSACwKj1PBiT3IAQIA5bXHTZVGihIE+2Cj5MRMdH0QithRRVpbZnaZqAZE9Sp64jHXQERiWvkqRIh6+Qz4UVMHKjYpgQUqnSMUImFGHw8pRTVigoLpZtkmz6sKnqjWxLFb9//uyZCwABFdb1VMpRHJ1C2qaYSKaFQGNQm3lCcHiLeq1lZZcMinLSS6sSvEJddfjW5uqJAgME9Os1yv1B+1RdF0OgWn1f4mK9h10j+g9MOTIztboYK6oAIBATkRbpBM2bOUVJw6MkLW2UbFzmVS94SXvYJSSGBcmqSGlnFtKvgWBCAqAmPHt11gq3k1NtjEO47D0Z3cZrRuq3Os8NZ9SqslsJabUrfv67Fb/3vswCgNkcpkq5FlVHmYy3Tn65jPBIXm3GHVQoZ1FlkA8AQySYadUgrqMibDpmU2RPMPEB4EAAMYwNGRAZ/IHuWaEopad5Zz1G7CJqorKsGoRUt/F6QO/bJoBZ0kNIx5aBrShlNcUeonUmcb1SHRUIpHh84NzAauxZNRA6HYdQ0R1gwSwKRNlh5uFe5FVaYLnxdfYYPYxE2Iu/laKROCRg6ZqakTn9KdH3C1EVDtG3PCdePi7OmukmBCqRxC5svzFjh1uWvySsQRKCKSC0CI3ElSSEEbgQIGgpqJTpKtHa1OiENtJ+sqm2rsTs+h8oO9TdIKW9bpwrNoJL8xrNF7bHuJpBRBelE69IkldNQRmMqNMlkWgjQykeJXqyZEqrbvozlsUwO6KUyoma7mrdm1Y81eR1tvfodFZkUoilBZB7yadNQnbLZ0tTYjjAtgnmYYQAQZgDKm5QHGQDwCAAgGRMXSFwi4x4bKX2uJyS+QW6We69EqcNzpzUSsaeQMqzhwKPp5JnhQnUNLGG4RXg6OObkAF6fuVu5UaPQod/7l9+xJvjOf7PqoI9+bjsdXaJ7rC1aqszAHOtQ/9i/dTmcrv+2/5+yEP76K///uyZEMEBMReU5tJNcB86vpnaSKpEul1Tu0xEonQrSpdlgosaRBhZS+SFAeMTf+A55Di4bjowYABjIBYwtMR1N00NagMqLBBFYN5FoqCmqHSsvIBRCEpcLJJ+QQ0RGofeqkavFtwa4bfRwBzVlboQQtSV0hdOHU0Jp7BRKY0h7OzXnumnxXlbE42o7vVVk6trbTryKmqsxmoxaW1olTbXu6PRyUsr7Fa91JopoyHQcGJrZ1iAuS2Xkq00oQlOHKWGFHozpBKVhYS2UMVF1S8oFBDgUgDI1sXhiIL/WOxmiysoyuODA5mjuitbaEsKYNzErUxB8UGbR0FeRBEavHikB8c/31mFjsJD6XEjvsWTnMJuOB2XYcj88xfYyKPNsYlGc/EcjpGBHfbGcsr4yru7SrSKgyaxB+J3JoMEuxAPi2zWMiEX0KhB/q+uIEt6NJ0dbEGpvIBnDLEdC26fTClqFq+NKUDVa01/J+feNq9kgHKNxlIdC9EP+fnSevnT3TYupN/mbxQfW30QnPo7szAUghjFBlepSyh1w69Epb9WNuT9L5AzXfOiHqL+9kHkvqWy6XewxNzUcjYkLJMEqOxCacbVY6PjkujPuTHzjDHjCABkMVTCt5AdCBQVCDJ9HswBJXwYof921N0wVU6ta/L5yApA4atM91utvMog1FGeltI14GLA0PvQ14bWKPrT84OQR/ue0sm+pjD/grl/J4rnVurtT+ZMvUiISa8c+4uDps7xwIpy5AfN1E8EXfdJr/NxU5iY02v4PGi8EIoNhapIHkiBMuiEOwEA7KOImkw47Ex4yEhCBgwUoMWLAwPC4GSAhAA//uyZFoARMBcUptJRcB2Sno2bYKkVTWdW6wld+J7syodpCa5qBAQOLkhgMv1NhcUYLACo87S+kJsaiuVpGRz5aA7ffcwKCMlTt1qWjoaMufeOp5dXVUGBkzNnEzoVtXRjubN9m22T+v0I3o7VT+r/+3yP9XviGc39If5nWZmgFUEAAZbY28QFJvlqyWQgWkoYcJ7l92+VBCVKVKIqqR/nFprsBQFBuf5dy7Zpny78ctejOA0rk5gQ8huU+EVHtvYT3J5O9JCBUfEgYYqEK4gAAgbIzRJkyNjOnpTVM2GRFZ/wqEM68/rCe4I2oIEBWrIiL0ujNtpQhDwYMQxadQKtsz6jfLvrqQwn9qBRiSjJ8ew9igmsYBoHDhxAwRtUdZ69C/ZL/lt5vYgEbjT4jXgwWN3zXBl8iECSBmCOSn6Y0ZEUqktGBPXIWz7dlNiI6ZThP5UjYMZSHT0JcYElJz8hGHZtB6MgpERY50SE7AUAUHF8JLwrsakHyNa/hGEUOxdXfSRhEls/oO7Dgm4Xdxp8B5MltBCU3LU7lj0zV/iSjvUH500bexnO1zhJdLCgUCsSAoBBPREzCJISNqLrrOxVHP46fq26VkBLhklS1xlKSgWW3UvqNJQnrhcU4AWJGn7Q+WGqrCOk67K8uisqq5Ysy2tMqLeGitCugH225LGwSWrYji3qv+7eNPsBUxakQTh24gCuIIEyfYR06oNpAjVOhj+TNbpflEftTmA3NkQS6yzGE7nhY3Qk2i1z4JZ7l29nyhwjpdtU0eLDyxgRi2MCWOxxqaCdPHVHLI0AGgEEIsuGSFV9H85QTGVCDkTUilwF+0B//uyZFYABJ5gV+sMQ8iYy+qtZQyeEal3Tk1hZcG+LKpJlIowYGNpnA4wR72s2r1A2axm5M5fsWCYPSQoliDZAw2Un3cQbh8TrjvhP7qtRcQ6kuNYFSpMDoAGIlIDVST+UDmw/bnm9k5uPh/eLqbiVeFc9Z7HWokKF5h2izY9cLVMQ43+WH95udntdbFR+60exayoW5Cw2RevnKv1qZ+zPfG+66BB0AIu4LdzOBRtmHS1EwF9EAAoTGLfFuCAKO4qACCZeUylkoToXRE2h4TF+OQDMu0E6s3W7TJ6kOqlh3IKzmiDVqmLyozqdJbL5rn/htPfd/CMzRSvTrn7Nzloyj7T7PVT9qzZLm3t41Tt3MXXd18tf3buHtpkTWxnbFuN7V1SBWiSiDWqlsyoClrxNTU0eoCKsJkjGvSYJywooAz1oD0rmRsfJxkhWDtPiMCT7wOTWD5kOHtKyBnBK7/aVzJx3WGij/UVI3tVWRy5p51iqDfvz5V+itpqoDOOZ7OyUir79+V+ikR67JSdqXpPQ7+uq7o77brohCKMMONQ05D6VQBSAAALJY04QKF1KEAOIRRMovAFzpKr5Z2raolBzEGeQG8SHQzEZ0o9B8JyvVlHJS/K588qxJkcOw/DabnPfNs+frFkLkDakIt/Xf+Uz9cUhvOTWy77Fh/jRUdfN3NybolXML6jo2Wumv6G33F9j3+Kvbirmaxhzdisjo0iSQhdqHlGr7h3vv1gEIcCAAF6aJENJ0GiAz04WzQMkWjAIpCxkV4u7qdDYpPehNFwu2Fg0rPF09gEmvT7VRZeG59qO2Ta7i3M/5zXNq29Tal0cUXb//uyZGiEBERaVesMQ/J7i5rfYYV/UVlzT0yxEsHElSs1hKKV9cp9fsuL6JDpiKVreHnLQbepEcBo95iqjlSjFzGodWyvm6olUFn0rYzq/CQizoYe+uMWAgKrbaUC1wDiBJASuBlkGhhNJ0RAN4AmQwJBtG4uMj0xtiM1AFIwlnjUr0qfPGyeVxnHyJXp2pUt5qc/WFkjrsZOEN+yVHKGm6mah0Fo4ur0GTcM8zREdire3yWMm6a76O/FUb54PP+7jlJ+bmaMm89ol7n6mksmuU7jpYxrO6dsMEa94OWCKCMrtASYVAbtjhJbGTPJBIV9U3HViKL1ydy1UIw48MJUtfYY2v7d/VDck2fYLUTlNA2b0b3B8SoUEGqJIiP0lhqeZP9LSxHMhCbHMczPGSXIOTplHGuGzJ/7/2hXtPQ7vXrHdczNtr3fT77QLdl01wKZ/+fIDYQFKWMpQRYBEUnMTI00RyUlAWCKw0JSqDFUJiDKEhQaPxSU7Y9DA1EauPr0ItlcMIcDSYSmvPLWpxi6QrNXlbePqnS+eSPRUZPFuC2BXo4yoGA3Q8YIlXlKscjakt+pF4ttL4r5GF/F2WIBJXVT1Qx8cPTemuzepUr142Wlm6rlf0a5EV4tDrvmL5N+J+oCJMANfJp5hvjRQYAgBmiPaTTiQkmJshaRXSmfHRWhdxdoy5UyN+IpRs8JHRu2z8B3NvMBA65RFhwGYnsulSkBnLV9TK0SdzOQ/EB4s6MpVu5syI3tejxW9ZTK1Sb6Jf12fvyzoj/lMNHNB6n+YCQAApJbJiH4mKWyYw4oIhrBae5dVTUiCYuj2tBy0AUAuZDU//uyZJAABHhe1NMsRFhtiwpzaeU/T/1rT0yYV0Her6ldp5W0zOv8zCevY36WAKfbyY/asfAUi3YUOWtBkOUZn7Xnav4Rtg+z2z/lKT0CDIY7n5vQncjZ+yzmGHa9H78hDai5ShHRk3Zh5/c7mVmor81W5m0a1QbXDJhBWAUg1b1gwJbRCNsHBuGWWAlTkQGDAFBYU9C5Ac1YUkW3iJo1U4fbs/RbT95zPXHuS5Meo/nnxGwxwpb43mzpER5X3jQa7eyjllRkLGMzGbldbp3+DaaUeX6+Z+hBcaOMY6pUyNfV0czWLTVc2l6e20yCioY+dVQyOOS6f5gEYAU5rG3RFc+4VHGwjaVQ6Lfd1Wafd5JBhl+0uqOJYNpy8QRqcn32i5rAwWXGnZocPw7l0UZdzu8r2ixppf+0Ov5MjaoTD6Od6+40V30ZQSn+Y6TqFrzv3FkosYlc1Xud+dUIH3vVZbY/Emv83qbXN1zNY2Pziq6pp3+RUK/qNXYndMowAaGh58IZSyGWNhkZSCi8lSC8aR6aARDFsTAisAhTJhoISsZM/EjASgsidQeW/BspgVWwmBm4gKDGp3vkqFNMFsOVJv1XNWUg+ta7S7Fc29kGLorbF5W6N+her6nfbpZk0lr6OrbvrfNsunr3b7blp0DsklGQR9+oBrJIpW7ayXkGlNWfgKpewoEgNaUWfQnlwXTUHglpICgcHODxFHAhETZVwnTqYR4LE1BZWwGX/1R7VcjW30hH6ibq74v0PGoDbMqSRUfBYPcDAJH8JP9HbPfqj5N1WNQ3if26txIIvv8jluRAav64Vbxtx6z7U0HjrphEPaVN//uyZL2AxB1aVNMsQ/h5K9nibYKmEclvV6wxDanioigNvBT45EIOz6GB5Xjc+KWU7E/bswAlCkgsUHDl5pgkRcAsdFQ5FCASGVg31HHjSnuMI6QoJOEQ4ZS0W3I2EKBJ5wuZZ8k40KAYTKfgvs2LHFyI92GrHu8jI1Ws9SUOi0OrzOVwiDjmQOsVodElIg1c2tNXbtlSdhLGlajKOkFqomDo0Vlt+CZOeuWK2V0YAbu0lw74GSoGHHKVspSv0xNQFZC8GDMkhxsbwOk1eZlUchdA9msZwRGUQn/OS6AGjanpQY1Tb2jy9+qa/ludNAi4gSvLne2gkzRfW9kjtPyxHO5ShQD1P5uR6FIzOw2iUOzUEFuiNd3s72bR0cEcUCUEhmyEhww8EBi2g2ipDjh5QcENByM6commHmhjwGYAGGNghkQRXVvMBNGOiAPYOQATqKUpnTKq1PGVtKmSzy5DaHaag5gtH2Uz9CQ9Jv8hQtiQ3aTbkZJGzHYEkrKaD8mpWzlWhj6FGoj8rW//2yJt0/2b1QlWqze8t866siAlz3ojtKOX+sGVnBDYRaAcQGhQwWNh4QRebVBAgHPoCJIQNFJpZeCVjQnaghMdQVw0oLV6pblru07n1cI9Y0UYJszrVraDcoTdqyNG3iSlRuAfJIvWYhbr/qSjoxua6O/12t1AQQ/gKCTz2TEI1PYyjvFe4K2RGukGDTP2KQ4oVJb8WydjF3wpRh05ZcijMrbbxHOmMmopWWK2gxMoXPzguXb0gFCDevL446f484TJlSRoihGzrmaZq7AQwVLIZoQwS9JggcOqLJjVqjcYctUiUUegiTvd//uyZOMERAZcU7spFOB3i9nybSKyFJ2DQk3hJ8qCLyjdoTLJZ5YeqcpGCyq3yfmyFV9A6Br61sONq152+5e9qD4Asf7wojv14lmZbbMHIvsw5Mzmwn69+3b132GO2Cu3pSaLDyVmzje1gvXGFnNvtvXmBzIrv/uTv0nvplflhzr0ml7r37zQqLDs3MB0WMmHMU1ZDCvPiegWYACCAIRApKMpQllGUMsqLYlm3qGBNEs6GFWr+agquxB/NuaysauP6GqXKPSPVx1CvZjrrvXs181jzQfveItP4Pv7STYm3hzKkehXMbK9YtTNScTyEHq2sUeS1B3HNWCxqot2vSW4fZy/fTrdLDX863AaxjmqWK2/bcPDtRY7Wx0iPFSktwNr1ySvt0Ys2fd7Q9r1a6CvnrRt7a06FgmoikwLf951UsjICAsXa0yMycQLilwCgBvue0tzygMEAHUJ1l9BCM3RvlorlibXGutZahImhkKiQPA6EHT+FVy8mtG4wkZihhareVKspDDMjs/5Oc/0sBwBkiLpNQYTEQiQjQdmztHWjt/+gOcYh63+vpW7UHbRm9uYYn3fWkpoE6RkGGjC84OkBsrkl68RMPlRqdXYWwOr2sYo0td+EqGZuwzST11187YKp0XWU9SJfIbqq1aNOdx60T2BwFQJM4m3LUiAEVQF6YsW+Dojo16tXTdW0mO5jKoCi8oquvqZhqbB8U7OMzrOCDbO7ZC3f3bDGYax2m2/Xq984RvYsYbq695G/dECEzt+FSrYS8N/6EG1MGVZp7g6uUYJH6duNRNIzY8zNHp+0MlkKs7pSP1exUBijFhAbQ0HRErs//uyROuABX5gUtNPY/KoDAppZSx+D+llWawkceIMrmophKHhAoiJ2FEgssJPBkrwTpCldSYipUOscXBWSreBmz5R95lqBoFxtB7cIrRzBhT3fbXL1CCY6JhIyLnui8TUDTIjUkoNb1C1/WXJt/FO9IPtoT5IG4yLrspPHv81UjKvn+TIju7rq+EtKqqmalXiah09Km1eUGiCFnQqmtlYpOFTU94v/83VTEFNRVVVVQHYpGo7EiAHRFGGFgsKlqVY6NcqMj00brsElatkhZG1hOtJpoNNfhPW2TuSJF8T0wNIMRjgipj08RBReZn+O7OOYFQUvi0+BGi8y/aGlimvavgOrttfU03yTLhp5Uy5hfVtdSq7f2qjd5jWbpWleTryie+d5EEBRkw9Fb2mXkizrvFOxAaSQ1pEAIqYAAUDVI3KbpyEIy/m4r5LIJ9z1M3zbYv1nPL9oFgVyFyOwiazU56SNCF6dWG+b0mLqvi45FTn2EEHj+Vb1dEGldaJ487rruOZMuOJnlfgqK6G7NLV3b/SfHXEtfH8w/JRNTzKzY64ufEERqWShGvWb0POE+p/SAnSwQVI60TBGKR4BU089xcVEJJuMCTYVGBIDSEa5fGovMrdK0QHCcFquUNSsqdrCa7JW3l1XVsGwjy7Zd2WP31mbb/29nts9/FsbdeSoeP4ngcvTHRIqZcuQ10/zA87RVuLv0PS5Ovlr5V59o8a0cz8WOjT9rmromoZLWG+LHCqlkyOHh8FKgpyJUVOhVkFqwCBAVdABl6JkE4MsMGCHjBIcik0lJBNhWlOQgAIqsKoE7LXIBAQF5mSUBz05XeWr1HV//uyZOIABB5e1esMQ7p966paZSiGEg15S6yxD8IFrGgltg34j5C9q03uknqy487ef2c7e9n686hgWegswzLuPVXWA2RoXWMhDBSOx92I5/rVwVbniEtL9xsJiqtGR3M9nXq+tCe17VU2ZTh6GFIOEZYrdWoAgQgBVhodCg3NyDI0qYDAhEAQjjGhGBSzUvAiZQaDBxCEERhUojhR9YEnOCAyU1LLjC2asnkDK2ACttkxQJHtGkpb4TasTGXuXjVX2VWfMDub+m/CRj2bF2X1U1LTtJlce/W6Eq6ep1cTRc3VfHtT35aWK/6i6NaENS31HKfdVZZZ1pvkrte8tQdAuU/0Dl9Z2jtncaquX9lmCd0J6rW867BFKRvpxU88rI3UAFQwZB1ytRUlyNgQ7wgKQ0YtmW1rAGQHYPslpjkIDPYmorTNAngI4zG16lLZG0gtuBh0MwnNg6BtLW+fM7/E6RrAlEwEfYYlDGNaVWdVpv40ub1+Ib2uf/rr6YsoOd8pXuSmnqbSsfzXH1/K/DXMrH8c2aSkjCaRpnxxO/YIAWUHJeUBuJpyoAW0z8XMcA1XloCoVOmVwBVlGRQiW4dsgMZ0s6d5ia8mEqjsxGdhFR93UX/PYSXeRIFI6hNpGi90mlRNJznn3p0xAdroVdDD6HpqnL0TY+4WLIryiq9ks7g2/qWzcPvp1+bKcvPWofc7PN7k6xbeejuX80VWobxfwzbccMSmmVNR1cG6R20x+3wbO4es2qZ/tr/9KxAAwAJkO4fZcG2gpyROAqwYP1qlBOSMq3n3oEpDBA8CMFmEIhMOkeriNHp1OW+iWNqecZxHetMV//uyZP+ABWFezauZYXB9C6pNZeg6E72dOM3haYJmLWZZvKT4p+R/6iQlGW6fQey22yJUUEJr+Y3jBF0MlUJFR9EnlJQ8+v/CXuH3N6S93F8a6qG8qF55y/rblTWpEyaVs3U9evTSO5V9i98rvJ+/Urpf/MqUYxy7jJK8UhSyK9VYVAwVdpoQAKs2OMczsBjIgwMRwgnOdLkVn7M8xGhCNElH1lymK91Bi4zuy9r0NxFq9ng+CYejcSgNHppWCCSNUZOG5SQ6p0nU4+OpzGtZVqHahd5rRIOJWq2q4J5tagbx60P5KDK3o158kLy10L9m63tRrXSlNx5nE9yyq4f+pLKPHLhSa/+HdQcSqEkj625zM1IXzsp3K9Xso7bC77QgAiAwAwD7vQxlbNRYQuGGIFBipgk6ZiAUVO5cpRL3pQVwUwqicYkGsrSqWBZ+ypOHCU3YhGn6fyjzeuf2cGQ6ahigWIgoUPExFBwe/Ltvc3oZAiiIszPVYuc1OtcfPZz1MfNjtee64/Vro/UaNVupvRTssWni+FWR7Xt1Q+BnqqEy0xNxJZ1CIXHUf3toPvr6gQAIwRyzPQIMJnY4kOTUR7CooJgwVRCLmGAOANAz8mWAIIFhLkqageNeSeqJSQqHBcUhjT8tJWA0XRUSpqS3q80rH52Ng82RyFJetkQuNTrizOtENpa48SDaBHJitS+uT5NXSHsTE/YUH4zhgO6pSW4KVDThxVwosWxuZ5MRo0iGZ1u+i1BsoAnn/af9x29Jh/fL7UmZzq0MMLWbdPmCUmTpIpQdOUyVNRdlZ7rs81UCBMfhD/OwyBLMkGzKSscMDDCA//uyZPaEhMZezrOYWPCRi9mWbyg+FfWLME5lZ8IOLOZVvCDwFBg1oCsA9DaFGkuSDgm4RgGEAawhJh1eFC7zeymrDUBTTLgBg+cgLDQ7JCpvuIRpQv2wuCht3W1WJ4Ne8d+vfu2NafJWu59Vi/rlLN9pr0jV04oqp1/XH63+11A2W05+IqueIfu2v8Zwo784RXQo/VUSAAIMYYhKkzHYYEq8ZOJRi0MDTgo40+Q1PKQIIuCXBTVCKqKqSStg0Iaw5KR8+RB3HKdB9FchoTc6UPpQrhiBIBMI5KiFoHZBvad0tq1UKGrciHb5V/RYsrRCHuB3sdwSDZrW1fsO6H1yhfmJ/79x4krbP8nxfBs7ub5pa5Xalxcc7tVqTqKC4+59qPemSre4QJY22Lq8CS9vYAIAAIADMfWT8JoJFQU1ojCMRFA4WEDYrXke5ooQFwUzTHACEC/geCw9tiZRna83S3N1XLfSke51opyDO+GRQtYxoiM1tTjZHGJtfI696IkgT/rPtD3Ii/tP5MbzVaP/O3LV9v9DvIevv5bvk71iO7WPj6f759q/Htfq9CAGtpsndR0yMRocdfmyQkaKBJgkiZOJozncNo0ImBi5igAikYILsdARKIgNVYhBFTgYNLujwUWp+BeJEjUKqeVibURfCJLy27V0Wh8JpcqFeRCICVvky2KlR4P84J5SNEoeQJRnCw1JA7SdjCfZ2RpxW7C+9Xd83sQQOT3EicfnIrjqk5u5ih8GEk/A6RzpRv+qm3VO9+kvCCD2nONWvHkbdQgyrGClrz8rhaMLk8oNPmUEAnbBD2KB1TQpCvkaSwwOAtCtwElG//uyZO8IBNZdTbOYWXKJq8mZbyg+FT1rOm29L0Izsij1lhoghKFpQauDtUyHxL+MBclhSgkYli94CZhFIdqujvN8pHd3m5ly6yO0Dp3fomrvkgVvr9xsuJ1/bOSKntDtCGHhd9uZGN4khh+5/GRD/tHb3/kP/v2YdPP2xve/xj3//GR4ffnjP/uxj60PvTYoQMTACCV9z0zASI2J2M7wnsmqAAgAAB7QWFNJsw6e5zbZlwyCVMNAsxip7BCCBxZlqAtDAvCqUWATsQWS/Ki0s1cNSo8CAQDq0tfRUKXJaQLxxEBSOL5djmy+8TipjrkNBpnGo8aIOsIVFsoHjhhQkyJoyn4SwvE78yIDzUFzOaKfxyy6xdOPqyNbVNqGo43xRXaymZep35ppfrTffVGBhS9pzodeK5rM9GNQQGs703HnfvVA/cVXGhNyhWkdSdXl4PuE5NDqELgPA6oiRCoYIjeilCu7kbQTTEalTfebtsb4mkrtriXXs+kACAAhBJRkmBekbZErEFi3DKBU9mBrmu5CHvcdabWkwIgBHoXCsvVMFe0MjYsltba7NvwyieWNYee/LFLv1e9L8LK62sFiPTsC6A5LJ7oYnF+HGLmW9dxgzD0q+ikwUsKs8PRPztiGPp9E1uDt7GvFh0iWZIlm9hjPrsaOisDWr1JvS4gRVxVkvem9RW5hR9obG71qFFn8Z4udfI9FJmtrd6YlyjMYVwjh+qpRnoaSEt7EpmiMqFuEjIiqZHOmFfiBife+4SWxqIAGjAYLIEAAQZkJG3c4cNoWGBgkYQEN3omkyu5GiUhKGI+ri8NRSDQIMph9CQECMgmA//uwZOiABrhnz2NMfMDIbQn9ZY9uEn17R6wxLIHRLqn1hBX4rmbWR12XiLrGmJ0hR3nn8+H9rvTogZnC0UY0iR5cwzP5Atf1gziUt/gTt2tjWViCH5xPfrtggOP6bX9GMauTGdNlipLsRvJu2Erqp37Qnr+zyrxFXTH/DELv1PXTdIYmUfqAHvjUf2bQAZVOiqwSvUrGTYL2gqsQQHDAQ64K2IU4q/BhgLi3FBPUFlqwNQbCwUD4hUsZVYu1wxbaFJ8xUoSt5gSCvLadRySHYBPdqiJqu4561lkr79vUqp+lDW0fd6q7UMuY+6d/JmGC1Q8R0lLcVaKGfooAUCCwAAUHPUMxGFAVzqoAAVL4MFeQNIPawDODGEXJoBQZLBXoe8IY+iwIZ8pCAGm4f70Czu5EXQKCeb6Nn0tzO7rSftmS0gdDdxtiHtM1bllH51rZ7ViXOXz9EAp+08TzonkvsPih+wTtYmEFSc5rU23NYhRr29hPFzOq90oYk1uIoJusqKm+gRrRVjsKKhpnEyRFter8lw6ppZFsUN736WgkAEYJChIeKMHtrJaRFNMqRoBmfw8k9DT5v4rDG5+H9mSOTgpy6zNFXpCUqrM6xcWTJ7C716Kc84oHmdvZSxj9FYVIrpO9Hc6ypVlx5Xshx0yveh7a81Ttn1tU8zOS2VqW6Dk2RJZ94n7LoYkgtUYYkcOkqiIQKXoQMLkbYQVdRrwqdoCGZeBTVs8TXI7sbcy/n203d9psCtms7GxKKY9yoMM2TRdrjxXdbQ5GblumhWLGA0nKK8JxKjpBXRS3kMMu3MZmx86ZYjdX/BF6XUd1lJS6CdT/+7Jku4EE7l5Pyy9KUG2LOkpkx4hS5Xk8TWElwaorabWFijCudf2n+qhhdS+cyPSp6scTYnFmR3LZMt0sTLbc0DVriljdOt+rgz5Ij7XTYAUtVgftsRLQ5ocVyuIzfJKaAhGOGS8qX0CoPu450OLfpJS7EQYjaUczpbvheSGY/s30W744qP2y+j73XJsGZ1Byt9Stb8IaUE6xqqgffmtob+J5vR/bd5rdNKVbVV/mfKuolgMihJKkL9sCCAHLE0jDSAAcxfY6iTgES1LSJjp3ylCY/b2IGN+udhjF0C5mQiCUL60ylEozVETU6zm0JCdv1zOUxxWHg5J1mKNdoYXFbUs6g2rcHHRjSFQlW5GCJEljQC7FPzyNpZG9XPkiCPu6Oygd1uUb3FXZJjUWbyWuCb+deIqu7vg/4gacNDR4dZoqHMqNFCuRFCHeoARHHekSCxFOOJll29ch1lFI4mY7DKGS0ytrX2hOy7SvEpGIBHJDCFrxE36+4jZeoniYwWbYQlRKRilsl0Mt2WwdgyJB8p0upaGJ6tfhXlRcyo3Zr9B5Otu+qrUrvKY7W9My1Uzb5bg0kDsYZ8wIBA5VGMLMDnQ40sMOBLyEUBBMYqPGCihihEoAYuFS5DkFSYwUFCoOGApFLOHZKBlBGn6oxuWR6mgBFZXavbGUlyzfd6F9xTOAYYn3YoUOmKjOqJZlP1efNUgdPYRBdfvBSl8bWItkb16TlL8rZhtY7d/YNGsamKfKa2/lEWU2TewNSJuohjlpI2uvG/KoQ7UHpEHh1ZZ6itHvLKxXjHaahfPj76eR5LlWc7zXBs8TC9Riaa8SYdQrxGf/+7Jk3IAEjF5QUyxD0G5rWgplInpVjXEyzbE4wfcspkWsILgasbhnFiZ4QsrPDRVkXlRqEgi3I87itDi3ID1qajVJActBXPupch5zLQ5NxNsIZ7XEVEsfMPRICIiOqwy1jY5LpIiK1JERliLjaVaeY+/7qqtRpBLsTc0txbOOSOrx79x9rScJ8/xd9b9s0KsCxgWm7yBNUPD7ygy0zNQK3cMDQjGjYGBIctg4DAw6GHBVAwuWixqOAphQ6OBzqqYBwUjQMg6vblxqmBUBkHigKKBFq91uMD1V3hhVGKVUuG/T+PlR68fLVA3KuXbjims5Sd5NyQtfqV7SK/G3C3IyKbGHsJYreaPq5m9s4rHbjF36wz66XwcRTyCu5EkQ/27/r45JVp9I5R8Nvrul+2lK6aRv8id/GWP2ZIGk4PBdR+G7aimRIlmzJyUMaw40MACU5SATIhAZKVCGuJiPopuIQOgRoLMv2w6FrKKp+ihKRVOCuHpyt/LaX1R5D7KY9cyGkdDjnumO1m5VYPA62drqJmUSlmdWucsghqjLabu2W9XSHR0qIhWIJCrnKak7TH6/rsnuicpUFStGL1GGprMZd/DacMD5izmTg5gZimeAhUyA1Ggk0azABTKBWpszmcmaSY8YnHGDCNWkobI+u9WZAQkSoIGVDA1A1h1pmnttCo8MZfEB8aikTWKALlKekUokTQ7bdkCqFHLUksn2Ay3EDxQr0khHPsKBm4mpR6jO9pCxv6FmpJ1+yn2yPZ1NhrxFKv4fWh5sMebZqXTX3yrdTvfT2LvDaVVF2ciMMyLm3+pVDphm6CnR7PrBUBzeGzohiOv/+7Jk7w3FcFpLC29NwHuK+ZJthYgVeXcsLeUpwiYvJcmmIiAY02ZtAYgYIU4FHGUZOOjkMhegwKWhJgg8AIr78QAmOmWtkoJ8wpF0IRYfecd3PntMz03IWd9k/RyQxK6LPnC0hKMuoHpeSp1Sm2Nr/ipj/K5ZC/VV+G9omSxb+r9YHamfvXApKc2/6L882fHlRF49hgdiQ+BgdojuP7QVBYrU7kUBADM5SPyLMSZP3EOE7MKtMWBcEyKIaDAoiGSkTwqaIQwCOjxktqGwEMA7BaxPge+SZPIEADihOAX2GmZxXqaZHldKgRQonyghZRMlwrImaylOmBeLacnlrHWfONXy8RhgxqRU2uXzydM4ifZNHcnyums1MGqMj+6NZeU6JSIqpRgvYi5meWRpE0bqRoubspF0K0GtVOJTesrLXd2UWSSNVmY4C260C0fY6io8A24Dcz8cIAMQBN6ZMuuK6JpDJphKHAaKmNGhCtPMOEhUBAiRgNBkQUKAUZh7oAjwVQYc0IxROGpkSIWAnBLTY8xUXklKUi6I7yQNJ1BI69S+l1IrPjwR1ntkGWgXUt1tWgndb9HX6ldSfR0DM9u9aXWvv9l/V/QR1vbZBSRpIsvSkksBAIGIeHQZhAUCAUgx8HLlIiOMY4KmdXSZLbtQBoSFgcECCCMoAGbwQABxHtnroRZiBlkeEUTS0zk1ErFABAlNZQdnb6SiHBYDAGCO2WzlStIQ2X0d2kzPGD1wHge9YMEaCOFQ4MIr2VXW628dKXqkhMvMYTCFGxINLFmEQBoce77rvuu5bD3XdyWWANYRJBoXiaO3ZSEozvYTdrk3Wz7/+7Jk5wAFj19MFWogAnuq+YatNAAjlhdJubwADGtD6P81kAD7uXs4cvdmZU7qc8Fwl7WcqZ9qY3899v8/T+P5Odw52UTjuQ5bYe+rrUGE8utR17Wv54VsbNuhvWdf+f/FMaf88+w5Y5b1h3CCYDgKmzkMThxtM45UjcQx///////////////////99///n/////////////hQ2v7ywGQtCICAAIkISAQoZjkICAQBAGAJMtMolLXmhhgHQiq4IYILVmlSmYFXmsoHvoDExdtzJW8CCQFPGcskQxNYV1GcLEDNT5Be6HYKjcEBBiVCGjD15gJNCeX9ludm7gaSRqJBijbszDgmQA4Ut8rbrcN2e+47XJDToPoS1lKjRFUMDE2Dd//5/tuxNh7T2uRiwMMF11aViMFeeE81/N/3P88/dyczdy91pb/OrHV+KQlChKt/8/uGt63/HIdyc7hzKGJxyH8SoZozlYB+J94GxIQrXfD/7/8//////nN2/zzzhyx9vXO4LdWO9UnjMFu27cUpIafTGRQ3///////////////////55//P5/////////////6na2/u4/YwtAAQWqCQUAAQBUVfxUMiIXacR6XgSQbx4CBEQzlkQScyCQFBPUuoO4BWhJzDCrOh24k5HWWEuIvDtFfBKFKK6fyYeF9gpM80YukEepknAObaE3iGOwp9HLyqQ0xzmcE+rlYp0gn5ozUum9RK1WKc7oKufqFbUqcOdSJ9xkcl5pb5WBWPUWxohdtbbHZFe1sr27fLHtBgohU1T7S1vJqyrqdXWfPmGmZaO12wPo/hx4dUIiv38OBVkeT/+7JEXAAG8GXV5mXgAt5sapDNPAAS+X1hvYWACkEs7DOwkAF6LGVfeduXpWp8/1DrM3OdokR77Xi+ufdOLq5/zxXl3+H9auhNmRkcZSCI1wIGiiYyJglRhCBLRroVIKfLmkwl/GaxleYD6D5CDCnC5hygEa2I4CzONANhcDAI2FymzST5yKAnx3J0eaADCIkOYeR4qghI72cyRqmafiLS5GS6lKYJ0FvLiji5spPkiX01VQqVXEGKPhDylZkLULcpNIQsI1xL0q23UC8RQQk0xKNQsKHF/TRxTq7bOxtqvTavjLp5GfYj3gKlvaXCG9zPM5a1HfRJH0/eOLpIvZc4bL725q9W6rdWXYbvovxfF8Z3E+8XrTGq3c/t5fPhDjB8WCjRKw7/uXlK942UCQQVH2Awknl4jgF+o/DI0gYPiK/4U3BSp2YYd88uJh+H4a2tJBNTo3SLl5TJ0U06raKZ/MTJp1y9pHM0a5ZCzN21zJtNzOK3uUSTljjzZiFyegbGVnGVUvg4z9x+3bHcNtN6zNlTEG9RNt9sOfLrQtNPiaNKTumm91Cb7tV7radWKC5QyXjSg6xGF9Rw+4QWi7Sy9RKTNiIELFBNIZUPaRSQga61pLm3aaM3aWNNbk8DD2lQYDSIGVTIwedbcjLRs6hltrLQVXBhgjJINsvtWUloZdJsMfEKVxYyH1p+vTYuDTlo3cXrrsT1q/nhULrxaqObO5+Nw1jLrcu20r95LbyWbWyg0vtrZPVNyCCUKU20qixuSJEDdorvGBwjG7vywhmA1Y5DpKAAIoJ1h0BENU7qMyQlsVjyw6+RQNtIZl7tvHOugw//+7JEEQEElVfXWwk0UpBsKv5hJoZR2WtbjCTOglwsq3D0mnl1QkteklT1FHFiK55RedRQjqcaaUpzLb1iE2iIuOLrunMDSLghItoqREFHAEpPJUxZzTjS6c8s8+U4kifL9JNAN0D+VCbF6S9WNPdZ5TFUqy5Ley4zkXyZs7d9ae/uff5BdJFwYsCdEp/XV3F38tpP1CIqujIAKgAQJkGdYGi0gWvVEMRAEirDPbBqS7xMjU4n3rnHTkMHD7fSMNZFZh7JyLDUjt3MhEBmoW+WgfhQGLNUHGQZN4dNlLonMyWZ7NBTle0aMYpDd3o0zpFHrIslajnYnC7ia/X26UP5akXKYuP2x+7RjHP0YwhdtV//xUP7QGrNZaVvsPF/S+3Tpyx1HdN7oyFAClD9IcBI7EwEO8hgjS2NRZLpNKI3m29pyeuC2MaZH1sm0RCnLRTL+6aFp84mRINLIgjk6PToCHnhUsSPOM0nkS+MJlGqKo5TOUkJKHGsxasLCj4POumFy2YJIc6Q+mgeqJhCTMjMEimTdfM+Scibm2dPqcvXyovl7cMvcQNS28bozD1HhebbKLamPeuIE4AAIqCahaxCxDAdCfCADdJLs+SQLsyjpRJxaq1rpijvGEjmurMcIdRoISxE+UJqrqIcQrFmD+pLLUkWI0jzaxM5RTD02XOkkVVNU1KMJVCyy8mXqSWb1MXUcvJhiGv2LKFNssUlhZZ5OUPaElLGotMNWbSKSVYuTX7wflnadDeM+euatx2IFDDEooES9rc13/iuaUhFUVQiDAACTcyVsVO8y+nuFRIPpITTYFUYDewDBGjwkAaUlzBsjdX/+7JEFAAUlV9WcwkzQo8r2t49hnRRiXdbx6Rziiir6y2GGZEyIdFJOaghY/VOTJiDHpkFnsTAzDcD5jogdX9DKtJEiPKXhqKKC1gAFYUc92inFkAPDAlNRqbdLmZD6clUktarI7j7Z6zGmdjZ6odkHLW2D9eTUdy/vz1XhsxjbRa5QK2K9JHyc7ScJ5wg0aLCGiqR6AARREQKeKgQYI0GQHUDSL4/JqGmpVcONXrKQSw8F+ooy0fupUMrBACVBAGNeziwCb77G/FsRKIlgX2nOOy7kWqrq16hToUWwsmFEjnKnSGFuQIJ9X1NO+hzt3duWlKjduoA9vkqb0ndPbqs6FK6uyB04Vc5v/7Z9fzmEnRFRDN/2Up0dGK43+yGFVEdFQiWQBwAEEBDvB1gIgajZCw6oI8SbAzH6cMU712/Y9JpHrD9iXMKIzMt2nsNub9kFxSCfgynbXe+rqbdzxEmhmhZj1e2t4SRRZQ5BjUPYTWQL/WEkDC5ixxJE5EEZo5jZcveBUhtBzXdjzzYHrsKWqscZyXs+l0NhhQPwSg3shiRohEV8FC+3/2uTWREEVvGkMrbMnYyR8l8ojJgvGm4mRfeMNxWHrbiFQlqqHhynca8oxvgjbsEuiLCMLVoScSRaoXFNzSB7FJETKSxI/NJAPFkZIi+ClpnoQQl1WecOXMurb5qj2rMyfrmWxTMYmb/iDI5kXKOU5B0f5eZq3QrX+S2u/9UageUA6ikpWc+opTuX/4qklc0ibCAWio3FTsCAJhkTIkjYpCuy9o6Ad0HeL8Zw6WIxrXxQl04MLlW6aeofCZAulQwMbZunufFOsGJIm//+7JEHwAEU2BWYwwzMIAq+uxgw55QiXdd7AzZig+sazGGDaCnJkZfIditcra+EcY0fdkl9Se5WnyjJTW7T4U/XOGdy97e8vb5raSbdTd2po2bWFGquY3DfGx1OrJP7/ZdqpLJVn8O//zOVsMredEdPtzm1S1US1cCRJeDgIS0radEhTipNsSaHMNJlzy16aLwRC7+eNCYaYaokgQQJKiNTo6llKl0PJCaRKTaxtNFz0ryj8LOLmjVOx95BiW1Mo+bnkmp+EkZ6U8uuZLSl75EpVLAUVSM6UhOrViOHkRvpDMZjymVrrimClq/y1p/RrsVNGOYVTOIABF1DJcsdSNnlA08CQiXMkWkzRORwGmOd7kQNZjNiH62NqNXs6sss2rspxvV96z/GXc0GspViMQpVUQM+Tw14DUGgYprATr/aZQzJVVw4G2YBINV1q4NZJYWxWiTpgOmTG/TvQSXWOubGeb58O/jA9E8k/03zqrBNutehiuvyH7SNagBY6cIw3QChaCnq57Gi2qQzYEjUmYy6oQlgOBHiEMwKJmv4rH9Gywku8d0ihseHAhBwBg5gLCx0GE8CkYV9BEdehxIRwXq0AkpdCAyQGtGRzMEiM7wkh9RlfctRT5tMKcQKZ9llrN6JCcNDLBk2pBfdaVMGO4gKkqiJIiPZ1i9pjkrjOgAWREQGvSz5YNFGuvJBV52fKpKTVO873xF1IxEmwUo0LFlkAlmUgRohpiFyi65uauC9t9TWF+2qaiqxuJOukndNPMfLZalSl7oUptA447MwYgmXch71o3up1QdoLNTle75OS7SBKnwwm2rKZsjW7sbLmtL+zz/+7JEPQAEFlzV4wkcYoKLGrxhI35P6StVjCTMyg4s63WEjelVTe53PMNNf/drXE4TogDo4A7CLjQxHEHWS7JVJjxGUPC0ON08CdcQEgFFCIelGBRBSBgWI2U2nM26Ch3p6iabtPWGIlEyelhZdDsYytHuLNY01iUqiYy8QQ8rEgnNSCE3yqzfpLoZbX/JfDSMTq8EoZe8UlsQr5xSjXvFNpMLjy0IqaGuZ9971UJ3aHrm4C4ALqHIU6TwBA40sIXeSvawmmsKzV+ImPjAKoQskQG81dA7UZ0XyTYXCaZxxpIrO1IUsk78uXNxNIj3Z3u/hZvh7JD5kqoiPbPTqrG5rP4vWeOq9Zy1Pu94dh2bVXRZB9+7rNuu7IZmd+Fw01r4DQas8bgK3w96v+y//nvcW1qjaIRSpUGswsEToXa+b1r4c60662mauQ8UOPJALKEBlCNntkiNMRFw88oaipOoN9/YtVx/cbRKYrnGGNwI6Hh7GZl3cxh6CuCQhBUWEDjEcfEoZs7JsRQgVUzqyAwgxqNsGD55FleKsnoR/JeKtLOdPo6OKow+RUT7d1XfG7vZve33YmBQAFhpRMJCA4vL5pyv+WrJrsFSvQzADcUQHgZkdgrhKjvhxfNcKwfW1cij8eTi+tLbft4Xd1RPIwg30I3oUbqUJ4yha8oghoD4yoYuMbPxpVDQ8H791sON6R7emvWB2hKe9xD/2pt5qWwPG060Zefc6wt2fFJZMTIuP3ZV4i9q+JH8PLOSMmiGjmRD6IFg1gYFpRMSMNhXC/NLL4woezp0lVTTDLygV22pNJLdEvoq97JtAl2GkmxnA4LTZ9j/+7JkYIAES2FU4wxC8HSrWr5hI2oR2XlRjKUPydot6vGGDaDMskCizyEghenqGFi8KBGchDfF9DfOewNT1PgcvpF1E5YfXv7F/97rbdwY+t/il1C/T65lTPoKo4UL0+ep6UskKCAAEYoxyES0yUljv85A4SzRdrJECJbx44Q1iEOCaiIxsCjVCekabCgqxN7NdI63c4OmmQp70j/6xKm/2D9WXOmOUghv6+PVerg6C6GFd0SKrTykyoTo4wwcOos1ri6uhz+IQutlW3JmOyDqxq1clPUDEj2u5X4gd8S03BkYilkLAuV9jpxrTdtoz6N73t9FqKLigl0BfBiC7rDFzQLFsH5IBIE7D+gOKAVIQfDiNzdhcRKrlvcsEeP8rwzCZho7haZre4NTOkJ5BxE4zYGd4IIdnpOhrKDEnuJmTN20uv90Ll4FeFtXpt/C8K/qlyEP4yy6nyfSL5H0sMlBnCwwGenl1QEQSlAEJHQvhHAsWTiciAnAWBOF6OmZQIxKSR1KYKVUEBRAbUuANIKiKE2Uk5VmGSR50iUemjZhcVDWlNAqXFIqE8FFkm5qqpSOhf8Hhl8JIycz8Qjuqax+m0xjeoctALSTmRls0yidgEhAiwfHj7s9FhiS9TBT1KaGsepBA6ELeimFyOpXljq3Orgq/kw8hiTCnyf9enpr1ZpFV2LqAJPAKaVoCO5KzWfHIOEXQgFZOiwwIRaOzm/0X8ME0DjutJAAoSKuSxA5ndi6c3Di+jquMcMLGKgOsLeP/skcMuuKS6J4My148y+MrXp1t//hEf1jIMfsxzL7ctjFLjH4osbT24q0o1AAILZDkuf/+7JkhgAEq1xSoelE8GuLGrxhgzoRMXlPjBkVQdMsqjGDDjAHXWBTPYAzdOGuoOxJNVwviDeNDpe0EFtYr6XysDX26dPGF2ihvH7hKiFFkhv8lhuoKTwqrakrMYfmpcoF/chX1e/kSefSyPu1bFBiqSm3K1mCj1XIiRURPNFb2GP8PfNTUKPuWt+d9tViDK7HPU/yNCl2UPFfh57LZesYo/IdOWYtqgAGAEDE58xJyz2VxYuaDiUcGJhrAuo8c7q9bqutZ6Z82dZtQTRPN25PMDrUdhX27esesx2zTzK6Cxk2hdWpu+IEauD2Yce61i6dxTltOkR2GhSI1kP5LoZGn+HY4a/KUxwluTfp0yLgA9w4zztbdXQqcLKRZCAhaRMEYCdIgEUfIrgrHA50qojKYEoy7V07Kp3DEF4pIkvbT5K3NxZLTUxiCTUYkimAUVEDDorDaYlCS6lSNAunpFGkaIUgns1bsiZZ6xhQoCOMRGzTGikbQFlISQh4dj/BR9LBqgrZZYDrqeD5DhFFL8yIycgSEROxInLdSKHvLUZ0qNgOo58i5heArxiBawvRQljIMN40kYQp1HhQF+GoNyxC6ICRoP0FJImggS/ST2EELlJCU8NVWtUttp2SwiiajC8WzK/U5eRuOS7WjiiMoOkOf28Uuk9yB6GhdN1Yj8MczEvMhWqsVNTwjvvByMGRc5HU1KAoIKttP236vb+aUKbchKoA29LmKkEZVlLXfRTJsL85NdXK4btew2JJMAbJQoxFuN0VYRx6QpL6kqhbtdbVSzeT1uLt2TE2klabxQOJz0QrFdjwHVHol2UBEnS19rX5wxD/+7JErYAEEFpS2eYdUIMLOow8w6pQQWVNjCRvigUvKbDzDqm7jKTFIAx4gilRDHM1MhVtN9RUI28wUKswbzOnGCugPIPADBLMIvxvJ/v92mldXEkoADg4ztRIEMNoxh9BJBSikMgcY9MdFmEP0WCedawlItpDCZ7MbMmSYxwjMLCMYn2Sy/y/FCjlvhIk0ksIGXL3vUddl09H4y9YxktmkTfzRFjUrx9jqM2ViglhiIdVtez2jZnDFJ5HS4fhmLfz5TcShBskW0oeM6beTV3+5WoxNodjZjaIJKdHCwt8S6QXEj8xEYIpeWZBzGBIyOAyKVOIsWMTbLGXSmrTvUzqR1r9wXqB4TifGi9+UM5xS8OLOh4G1Iq/qsIkLweSkWIg+8sRKqw5+7HenWgqvIcze8Lrp6fji2YOJF+Oxf85MybuAlmg3NPHVusc5UqQU1IMcQUyhZpCo82UrZt11jJRIILirLw0KsBlJAfoCcA5OzxBpBqC7iRCXfHI0PUGwnF4DkcBJGTMs3Jbr4QITmG6jRUT1o2ZicZKfsQP/zKHNEEEHMQs3PAgxshshVaZ1+P8z83z1RbOOkyL5l3Q68BnzMprn1V/XMJD2CiRx1Y07v9kmgWrDAmABcuauJbIKACpOorcGIQpeJZyHkFkIJKIQUIxxVhuGeU0rNn2FQqE6qZYnxsCo6K5RrY5hjZjx4+n31B7zK5qZs5eD1OvuR3IBhzzZGUMI5Nd6EpR94TNeHY0T9QNO8c1wj6g0J9EPutx2LRfoN0sVqUo7R5uGWs+U5qq1hZkN2o80bbZ78Z1jVQrOTRcb2UaUQB4pFGapmt0CDv/+7Jk0IAERlzUewgdYHfrKn08w5gSKX1HjDENwcsraXGEjfDwpozauqsiipmuxpLT8IFNDYbAPIgF2VFHNImG/TnI6xdddVBXVa3zUpy+aukbjGc9m6kpGf5m5iWjh9VSdozEnScikWPwrnGTyvP4+0MzXvn+asdyf423M///sBGp9J28wR99wSQAATIEIOg6YlAwaq6VoqBLJ60ooZLqMLaCS4pDiVzachoDBTVG0dJ0qqMtnrEgK9PJR63mm2Sp06y6Om1Ok1ZqKwxbZWUscc6+nTZZo6pH4qniloGqXEILI5ISNWIjAwD5rBmzKaxKGdgomrJCPzsQiheKVieOIhC3kci+mhoR4UFDFJsO/IIw666LVl/ib4Z9XW+xVh4N3tYjfb5M3JRObBlDl+svIz9W3FJKHo67q6pLSTABhPYPkCghkDwAKnPIrRD1huRUDbSonLDT7T9BBsaZi8+M7EyFht3RHjIYD5CozNqLfylxMfUaogxMxcknCceYfsmkxxyy3WiTJqNKT2cQ9phLtsJruWOOXStiBB2oUn1VNuKBi8XMkcch7gyzkhDTQjIoqPFoTgMiKt9n2CNAZmXMhowpcgQLAAAIGrk55ACejha2BEB4NCJj4Yn4sx9SlSl9mIM4nbjiPVAtmtH2TyS/BcgM9wnmHYjHquLUExihUOLceK/akdLOVJpYVyrafsvVGNaMh7Hp2vXclOCxMEFW9KRbLcye4xL6qXIp71ggZzDzM1lr9sSoxOMYjPY+6/Wfy3ruhdeDvj9DfEt9mNdDe+gus7tmt3/yc93/Of/P+XmL6daQAcwszEHfQoLjCPw4Mj//+7Jk9YIljmFPQw9LcImqqgtlI54TsZ1BjLDVQeYlKLGTDjC3KfglEBKNtU01aZeklSZy6PpuVAmM9jkEMJmJu97a16W0HwaB8D2QM/Fmsz3OVRhdG2aqkyuIF8FUjaaVwghHjklLdTIGRmj7oGcve8PKcmcz6+UFDoCgpHsn4aASgMsJrIvFSex1CkYoAAExESbNQcyaQAzI0LVYjDCTRTweARBhUhSthCuFY8oMVnh1OwKno7HjBkPFTzYXDdHb1YjFFjMdXuLCcZJG5uQ9npp5AOaPSiO91bdgq9K5WRI6TbHKzeZZyxVKV27vVc+jx3JV13Bs9Y7NFU2WQ5GVkJpmDJkU5pQa8UZAfXUGiHo9MbZG2j9bPUysstC3PZr1lrw1KS0fHPkW4sfm5f0/Y/Gem93kmG4JSNzsIomWQAABiFIUnLEyiczI2eIDwRFdTY5WkijNZWbKYYfi03rtgkImOL9DiYGi2oWldaQJphxSCwlMoq21pJo/eUVRXaS05pHEHMY4gHL4E7mrR2WVXOA1ZqGQGJJQwoEvK9jUWWbXKGZs+xH97huqr738+EXw/hYJwSFqqIRQGNbW9R52avUGKwogo2nuMpLRGNzbkBgSQiIjw0wZBLI7GGWpn0LwqFARGnD2WCRDQRGbRsjUIyC2YRGxnU5oW5xFStGxQCGpKGUdvOMsSWIo48HV5hcRi8ZuIvMULy7hGg1MPo1MbMZRIJEHgQlnrLMIPbAkznkvqYV3l2kEE4In+yM3OZRfKZXqou3ca2qnIjrFydtKCk6wja0ogYr+L1h+2QrreITnDQCAAZrM0XwA0Iaj4w4wkhr/+7Jk84YFfGBOwy9McIZLugxgw45TvXM+jDEuggUtqLDzDjglgLmrAw1MpaoFcsR4GeRy0hRAw3O+dWeXKrmgTUlu3TRiJxU5j6VOHpgNyoovbPSQ+nxWeG8RIlM4xy8qwNzcUSZgyIIIjooHtVH+nksJEggqhHveWn5AY8w+6u6BBFOkHAwTiCfFoWFz5RK/L4C8IAFootPyhjM1ns8SkVhZ4kuu5ZJf1sZYAKJm4A8UIyuVygOpLZuiWVpdH2FUiKZqPw77pDL2bLs+vhKXYqSOXWnJ2iTN2/0Ru1CwEhP5aTziKEml5RTYx9uV01nfbaSQFbU/N3bzYDJZOsqJeQgXthSOv9OsL20OCR+HhN+Nhx/4DBG51k0FmppiQ7KNJbWrlzb8ceG4QO+hEG3VeVVlgf47zH058DrVM6fKrZLJzIDFToIyICpzFtVNNM5QOdZpyuSaOIdCOTj9heOgXhC3qIljm4iViHMso54e+YB5metZ8TSOnTEzGrYhAiQZrZ5co20QYX61L2/7Q847tH2P3trzUse/ms5lxU5mS2OhL/M7e1bz6f2Y30+dbACvKVXpJcPAKSTKEdL8/OxRazFC00phoBAAIIlEwgQ4Koo1Bo6QorSpnsLS2g5+pQs2Hcq8TdP5FdgwZB9CcEtK7Ctu3iePNsiWR8vbcm0FJSCGE8eJ3Uh2eDgZLCza0Una9ArUSrwmQJGfQCSdooiSIEasOY7uSyMSXRecnM1KixbtSuPd5JTpOVDSE/iJlh64QOSSOGI6tFaNoiO6klcTsysUk2Hlmz0tI5ycnYpas4TqPECxJ/DZdb38qPrp3ISSVnv/+7Jk8IAFXmLQQwxjcIbrulxhhlgVgY0/DDEzwdytafTzFmAn0UaIBMYHroD6SEIk9xISjUbKpmJecUepzyiyMx4q94+O8SQTLQif91qJ0EJl2ggKSdNLcd20jnXF69EA6JtnkidbbKt2UqTPRnNuuTkdspyItKUWxHo71kzu8u12S18pGkdpAmNdA+Iug8GS4agzW8ZnUHWCqMgADNw9WvpBEYSAmCz4gQNEtOZNZNtYNe8YiDevi+dDQwxUwxh8CRNufCSQZqWDG0K88Z1pQScZXq1cMJavMYnDh7cjZlt9lcwZDZV8Kl5zGyGzEyXDmtC4SaulM+96rqv5Qg+I2y9T8mK2QKDq6wu2aiSiA/AhHpPZNIm6NJqW994VMHzPREUdxlrE2cfSgFLcQrJb4sJdYCshLVvUIp9RU3t8mvmYnKXgzEwAAEyYSgRG4viYLQ1NGSEE6NC7zGxkhuDtF1bsiyxVX0JGSmKrcS6tyq09rSx4e05AtCGHjaVXWVepjGmAqPsmVeZeFYVRKHKMgm1iG90mCbmEp+arxYheSJWFInRp0WYm6TmFXK0mJXkYdMRl1aOOgdPsJtXOEa5ivg7HHZ6PgSTZAATlABei4l9nBbNWhFJK9TEzCcNOBMB+myIauOuIw8FUWKJKnWsxtmET5Ctr0Fh3aiw65+HuWGfTbE3K5o2PtMq0mdGvUeO1oRiu4b1SvMp5KrvvVSeeSkLzjxRe+5NqyCO2ZJ6tcPGIVSXxEQmJ0yRVINr7SrmZUc75lB1mKcUpqmKhNDPNr3AtIifSyD0mhk9J52NMoSrkRwn30rXVNLQnFjqN1zMxmtL/+7Bk7QI1Ql5PoyxM8oTLui5liGYVJXs7bD0vwcoYqBGGGdFAA6zOl7BjyZoIGoe8sjQGsbLkvKmWii/QkkGcQ7l8ibaEkdqxqcajzt962QlSjvsJ0VKx6oVzH3d9BST/h6a2fcj7hKq7fGMrFsvsS4Tu9NgmNk4IYh8jq1u1Jk3wa3J6A7D9qgKNngLk85//7+oCAACBRNZBsynwY6Bw0RiAcGKKFMFL2Dg6ciwzCBIkOcjL6OEvEkxqwDcDNNZIIcPQj2fCSJJLd6hjg2NxUma1NqnLA6XZYAvC99RqI/mdfP4pZlLpWWjJw/W1D6nOdKFMaGG4gancUyKnXy+JN81qXlujt1Yjnw8U+oSCaHtm04hbQ/LifDQzdihCxCVc2zHST0+R0yp7aJTyPoZRYVlf29YzPeqXTFdj+iftahlNiUf7q23fmdMwuGYBKtosh4dFJrIJAKgBEwKFFkjJoHApmyK4vCMC76e3xE1+k6/u/S0n55L/Z3RPNkcScHACf1JM69I/Dizdebo8gc8aRVUm+lLj2RdVtUaxl21NUSnD1hjWk09Dp1skpkJQGRDulljnE2JVKUtfP2505dte7ejLkCD7FQ5H61CFBABClC4QyE71Gpl05UgNZWnc3FB9yAUdXEAIkL9hENYsYJ+2xW565JjRe2+eEhasZoCGKhbkckYdDpyOVQqjB9KNb85wN+4hWMGLrDWwXYlQm1VdqQcKCwPV6aUnivi0TCkxnapxqFefUxgBjUBgQSbs6GZ9gscgsN/2mMu8V7ySzWrTdVUn/iKVU03+qxXuMcryzdleVNeppssSp27436XgfFg1ZP/7smTvggXwXkyrL2RweWsqHWDDqFUdeTcsPTHBzR6nsYeYuHLaYyaTYAAMFGsib9BosjLWQqAKxYy3mohJrDyRJxhFKltXBuMrS8ZV3Pc5XJGdg1b4MiLo1pMtWIWk/LdrJXrHpztVN0dKDyh4LEG19fTO7/5ulbENOeZfdepr7r4yY4qRVMgA6lDgKm3hah5wm4uYFHnpmgIEAAAAjGFlnCJeY7AMoDFGkZx5cFBaXIYeaqvFWptmYEQweLuKzpIpwwwFFKISGABrGAJOVhgKhYFeloxm8nFZKfJQIWgU8WovjlXiKHKWLZKXI5lpTEJLNN9Hm9LQgiGppleCzmlFgHYlh+zRBmkEmaj9UKghyJTERcv1e69wmEWC41HDVRUPizsCWJAWRLfuPbBbwqGJGoQzqHp8Wbj6Jd7xdvHhNatjjjvMRu1u7aGYUSHHksMobBiWaMnK1xqlnZ5/unuvsrDANkCXi6GgcLTYBBnQV1EgwZPEAWUHSYde9UnlKJc+kNu3HozKX9eqFRrCT0tbCJ0O+VjVSYFjBppwznA17GHFY5KvM7eKhBZkPncjjUm2yzJooVPxG+baTorNIFVT9FQj6+6WsirmLtfpaiKymS72M3++LZ4L1/qAFDQAADDhB+0mRsCQMkVxIqFSRnQS22BDgRoYwESqepLBBqDpli6ia85BVWklU0uw6kPnyBCZA2Q3Dg8FnEkoJxbR4uwMKRcP3wnIV4cDgVIIWIjqkL5+1ahZImJRNEqVSNL6YfBKX7h4W+iQ137gRK4EL9+F9ROvrn+ov75UQuauMXt5b15Qx8r8G2mtReos+0hnSBrjy//7smTtAgZ5YsvLT2Rwcyr57GDCqhWFiTWNMRXBfhLoMPMNuB1fJRERknDRonRxgQQsRDeyTs95LUZdCAEQCwkZ8IYFSMYaKOL0SbRM7j8GGXEmsiSwaCjlTZises7EL7OQTqaP3aZoL3ZFoE6xMg2NmMx+8FNEoZNklClqkqQKNMuCb0KXScY6/5Q+YY54EaWuGIrIvP/TkAAABFBjXAEoYI4jkVjRpZULlQQDhG8eJEVdMBJqsBRZVpgwC5GrUggroBU4lsE6LioFk4EYoobCjFetnOT5cOCkLei3rkf5tVg5Vagh2P2IwNpcHBhucyvT6ogmaYJ0wlJHGLImSDFjWcMiAgSNx0qbbkpY1rv0Ma6R3jjSHhVRH8BRKe8kSNXSvTr2lIsG14dI2I0OBSmJbyZl1mFEg7vBkv40W2cxYWobhN74pilW7UaIr3+t2jwaQA7dndvt3iAQACCbC0AQ4vMkgjoHEMWB+cISBTIVgQ0c1H4ujLxayhDUDAMLT9CyMhGkYJgSrejpLofzOnk/APmo7zuTDiuS6skqcM8kidub50ICKkms0miOuDuY4ySZ0PYXidHaqdKhrJqwSkuPnvkchj570qeWLsLhE1GQxpnfKB7rUSDaJpyu7fLD21lyfuaKltrd87iRsvVXC3GfZpt/Cg7pI9xDrC9oWqPdbkpWub7xp14Eb78O9NyXzuTp0HFT+te0BwAQCAACAkbGaAeGKDRsd2aAdgoVFrIwQCMbCxGUGECBhAil4KAyiAICjAhUBADLy268x45jIQEXqaGJGJbgZ0WBLJBYdUrFErwMREXnTmDIDeOaUVSw4cqHBP/7skTtgAYOXcu1ZeACvivJdaw8AGL1lzj5vIAEYzMndzeQAJU2w9vgYBAAJNAQSA4WQeMHLBB5tOkwKSVEXjZfti2QKKSsepDJIyeZa0RL5YVvXpjC84GsMTiEONIhlrTQlbkxl4rNd9nzEnJiruz0ARXClyqRWkfaWuK/VZ6ZVJYROuLSTsYlF6Mw/DktgOUSCX3KKpRTNK4MZlcZ47dDUgWd1XkUWdTKIZzsolrrwLMtemZbAE5LpPG7esco1Ar8TepY5ET3TZSi9qxLYzSyt6H5kFJAX3qWZrH////+kAIAE1LIoiAIBAEBo2QvYjibM1BcXODKDLxQLjidalREhDRWYoDsgS3BgGZCEio2ECq6S7pf0dCAS6F4MADVEMVAxLkSjAVRdEiAftQeTy8yCC1SgsUTSMooxow5tk7mpfI9OsoGCQYsoVG04Utgwh5FH6SAaksYxBSI7c2lrrbR3FaUdnVZK1KDL78TbLYclNDDb2xLJdCmC9G8cKBmTNdb6CLm7NPnI/jkQaHblkH0EYh9rcvXnE5DLYhEX5j9DGpXuA6+Vt/L1NecyG43cf+3BmMXlkMSmR0NeYkctlViDbDqurWbFD0tdrty1lO37tyZfGpJphYkMVofpLU7UwybInW7DgtEaLHX5eR5XnlGFJK/////ecpVAlQAATHwMOkhwwKAVaAQFwUDVKkJq9FjNjZTYZsw2VTjEkqUOSwMboBTiIpZbFBaVnItVwH7Q/CNd0yAGWGYKgZTsOHJ8XVuOUXpRdC8qaZMArUpnVp+2uXkOLENOIfwnhX1HeErrrnp9ZfBdI0cXpWsPv0VvwPnNv/7skQ8gQXrY07HcYACs+xqHO2wAFIVdUNuJNHKZS1n7bwkKT5xYU7Nlt80apaIwLqDCsLb0ESEcvHiirccqOYrSjZ+5zJkix73KqjFY026Sy0XF8B0PvsocallouIFW8d3bdBL+F0SgBtTKRAABzMpw05JJhhIUsioARAyFa5lNWeOM5Su1+V29e8FgFPJBINj9BSLS/D1UXqEdzEsrg5EUGpZFI/YQyoDYSgLA2AkPq1c3+agzAuae9lpcuxv5cZ5esL4l88qij3bNl6Y0fSy/Fe+2gpnwdT4LWl6LVlk71UK3c3BDSmI6TKbXX6OLFq9yjNKOWW52FVe8hRR1Mj5/ztwqCOQD7YgwvZJc1XwvDBQuvFfNyDPZgAWwWTM0QwyZACqGggBpRBUBuAtOQJAytVzju2XfdWAmustk1E+XD1FWjh2R1DuQWLzJZNr+TIqqw9FrdWHn3U31U125uSSQRpnoWMh5SUCpBGVxVW84MwTTrPid0fze0qz4nOtEwcIFXhUvODJo7XerzJmJm0eWa3er7SRRUXGRt4iyNoEXJGJXlVh02FmPcs/9gBFQACADSfQyQMWkJJLZL6XFOpMv7aZAtJgTgiIAI+ODQZUFNPVH24k5dlrVpCzdzb5xh66pj3kCxvqnLy0kaxJpKKQ+Jm0sWFOM/mrO6Wjdqh9NGhQDrLm4S1R5TodXdUSq/s2NyqD15jCT+timFyRVDTl8ihdezUYYZZxpYtCcU5QfNczUcySi95HCxLjJSDf2CFdK76vrioI8uAgUAABwnEmfgOjcaYJhFZgUdFJPB10rFtINO6w94oQnhIYk1N3mkScqv/7smQWAQU4Xk9jmGBwecuqn2EoZRWpjTUOsTEB3itoMbWN+QRTX1QDZ2A7IUbSckPNnCM/xnIqaZHS62P7Gy44ugs0/Ukh/NID5l2WxIdeZKkM0LjT0MK897UKelocUCjC493Fy5VNVqF92WslKJH2uqd52N2nrnYZe1dPFo1Wzrl5f36Ubx6FKZR8dmHomWZh1MT56y12s7+zrTcSjAR3eaRnX1pogM26iosKGAsNbjxVX2j8DLqVI7Dd4teDWAuRCZxsWamYPizQE6ORh4mcWo5tRyDkrniL7551DgP6z3uVaIKPZZm5uyzrnuq68+p47nWJg5fm0u0u/p/a/SfmlqUu+OOWN4/WXK5/0EOozRa2qq5OMFekOJAIHHzJGCIGl+AUPoKBUdAlLVS0um6SN6VLDW4MjbkoIwOlo2LSUFb4WdJDK8401TGVVF0FaPjakVk7mj4IlqG0rPutEReYZQZ+BRigIDUo2KNPLlCQ0qnZq9FQ1cdHgY8V99jQVCNFk2XztFWQPsYwQ3FNt6SyJTYIkXMWCweE0+2j1UVppcaalqFqbK9lnxwcbZKiWLMWxyEqRLaiRCj9WmbZJWMu2f+665II7ORqTMoJnkGJExd5AO9zHFOwuAsUZA2Blj1PRUdVtnXNkyaHk+eShUv2Hzy2lZ+ZLtijz6GfctoHXo8PhU9r9Mk2F9fC0HGsVZu7FBXc1cgyzqUiOcZ+lTMBXNST/7TK3L6v5Fxy41K3LWr2l0r4EKPSyLncQ8oIFAAAOFynMQASYiTEEFQKYEgGZsJAQsxpaPZAAC53SZglCX7h160yodblAkAMmpmU1pniav/7smQaghWzXkxDr01waitZ7G0jahYJnTNNvRHBahLnYZYYuFXleulXEU5vOOF0c4/GluQ57u5KGhjqUJ/uTjBZGjTxWLLdAS0N5er9VsFYZ6zVXR3N2qLCF104KtSxnzLE+Zkvjcjaq7ZYmasj7SvxGy4+CUvYdw3svy5NsXUKjvUGM+tlZJp0dMXt8rHMfsJNViZh+LUJvAVZLEKF1deq2nnyvUAlXQARAAIy2UARtK1EW5WZE3O8vNlL9sap3dPNqP1FMkvFBDsuiTjGLEtXRPm0u0mHGbw50oilHrEUYMlsb1byIyQ9s7Vq5amRK1I75/fzY5aR59/q/SvMvLPz/q/S9yP/6eg9J1o7iS7hosRABh8SUDkEMBRptMOEQaGCwiKBg8owCWSLqIAggVc9VRXqH1A3Fra+h2Ia2LghQpTMr4J0fMBe3GVpOLXXZ1sK1AOR+5yMCvUWJnz396Q+FCX8LcV+ssEK6NSDjRsf2nXBww4kJXRaUkV1NUbMxKxNsYLC1qxd9g2FqSjcYFhYPsQSr5HPUJa7RH2RwKuOspq4yaiylpobx44bh6YeKCMH0m4qT2x1/Dfq1916jrRgYCAaX6IRWGkg6BfksqYvJLYrBEgOn5nPRnJE+lgER6oH0uPKCeyfnMnyzjqpVftl5tld4zZnGZi9OulTbHicAPJJIw0cSGsrFB73kUwkDWipGrv6mvFhUWpqBWQAAACONQDPgYdAAYLovgoZTZBgoLBldCkhAEcUPIgxpZqeM/DpeBRxcEqn3CLs05ThbFYsuJwpxgbD8K9Vt86Flwcl2S98l8KOVNXfp5WVlnjv5Hr1xv/7smQsAAVVWkxLbzTwYgeqPWEibRPFizetpRVBjazn9YSJ6OuZMbzDYHHKuLJndsRdz88F6y5wwQn/xM8mxCQ/VlO/pvMjBWWkVU639UWkfPLMV86n8L/2mXf+sk9eozt81uZnlGN7HFcQOXyMi1GZA4WpCtFwkrvlyyaBCTJVNyLfMAR7sr/XzAtpxpxUqdzWmw2VQ82QBYUIwd1fdaF5miAhH62UeiwzCA+q6FHbtR7KQrKV0WdNffuuitVhkRSVZt36/52qDcJWwghlgqsDM0kZvchYfJgACMkkEAAlU0K5YcOgAKGiYWVyr0RAiFl9ZAQBphqWuY6SZl2/EHdlLZqfB3V0yjKOT7TB8Cg4hWFYEGkwEQMv4HCD2A4vb1xQV6bAUaSTJxzZ0x8LuhOMmJKA1LNQm96fd7YTxdthWmi7e5MkfwPbQ0ecsvVSK17ExzX0s+pk4239GoZjpqR13Cya4OoYcHYolQ9mQVSP1+LD2TqWrBmdcSaJASUqAcwETzRqcJQ5tU72bvCnI16JuFUhTfwKg+mmWYEANhphYONznkLuLG07szpOsuTLU7dm2Lqnt1aVxNTGeeSZW3d5Vbs2Y1K83f07/3PoyaJanObVulWM2KbNT1ULFKIEEEApumxiBggwARhsVSSVOmkge9j4s1TVUdlblQXAwlSKmEZtI/YZ8wSWcwKV2umLI7RRY1Iw61yUpmyxBUIrvpZpLZu33CUusqzdmZZaiD+MF/S39WKX1NSX/n72bPl2vJEKU+lDMgjr6kEf/rX1O4Ynd+9l7v+UIblGXZ/7vFc8BKws+aFDKHV9ILNlJQIAJTcOSv/7skRMAARzWk7taSAAi2t53a0kABqdkzk5t4ADUbKo/zTwAeLuAgIDg5QCWS3NNJfK0GXrCrsX459BFV7EogOlAdDqhaZnWxpE5UrJFk0l7ejJNmlkZpkDHW1KsmntLPl4xb9xk10lYxvNy1BRvxNv7X96q1VlJ/O3/U47K98kZKveV8xfY+jN+q39f716v5H7d/1634zUf1qpRDngSw9pmS6XmKgK2trcUFcacPQWmK2m6DICBgKAwkKgCUAECmpDQJ6PVZdKlTVVooAqDTMQT1pP8xTtFsaDSMJjmF2V6HHaoUz0irlfg/mqEhi6q9eLswHNSIRELvCS7moZI1WKIqW+9lOf5bzyc3PLO6ZXqeibeZj78xOzxOijOhceDGearGs1x3ksTNsOormjkiP8lpbj3LYYp5QV1DdUgvbf5vAiOF85xnWCWNzCjXUZFIlC0ouq+r2P57a1/r7gxMywYjDnG9a/6wabY/bSdxqx8qxUE/////LqMViQNDMiqzsyMi+OVWuoVjsgbwwcFvSUIiq3dVYKADBCl/p7l8krlAVeqSRLTRFcSx1sQYZeybENFhVjqKZiuOw3FcgzRSMV4iTGXkKQTIn1A2GiSiAZLYqz2wuTdWJ7ODVe6cW01DYVXljLgr65Z5KPZJ6pgvSxvSjZzu7VBP2HfbVT4jz1s6Y46sVkd6o43lbIbYrFQrIl4VdWrrFs+MrIKaT+FW2OCggtEJ64w8RdMLA6YXG2WJ+z+aLv6ztnb2fN8Vq/3h5TWGxZ3ltTbm4PLwIuVA7hiCaOcdh3oxHIbatbOcWFfwHuNrm4IpgY9Zfdxy99n6/m2//7skQSAAScX1MvPYACjyvqqeYwAE/le1vnmHHB+CzrPPYNqHvyZyaT1f2lcpVyYkMegGL0JzFk3cXkg8MI2z/DhPPyxhg8oM9vONtUi1f1JnHMYOWqPOtk9o4PHCxDrDrfuMtnjlacvO31+7sEVV96ZRC7oBIdXusOMIj9Zel04ll95CSn+1WLN5vr85nxyzu02WC+7+V4CAcmXAdHUchKRmberXGrZh7ajR6xHluajdbnWm5+f2mzbs3N+ZyZp81y3XjpR8OQmMTh9trY149jxxVHsd1fNHt7c1xzp0l2m83t8q116U6/sXrL0VHWllboTc7dfBFlzzvt0ayW8nIIupuUm/dJ/q+++wzA/tPOFJTYhqT9+7Gw0SVivBuEQfc4qtPM3MS765EgFAXVOBUAosg4woB7hKDuJIhaYJm9XR4J9TnabyqQIFE0CVHGLOscmncE9RaBpptHat5Jqq333l7tmFp92d815pxYsY3rTp26XGV39PTD+azzTyWkhlz+lRmXIyY1K1DbWVici4wlJ89UBvigysok4ZGyQUqX16zeam3dlaxkAAEIbHDuBPA30+W83wzhoDFJ+ikXV0MBDPrE5Ms6yXGdeierV556rS+tv4qzFIZERmzuVDlEJxoFuXS/FMEAQhUiDHSMVgm/cAANicrb+ZcJUYEGTzzBnLSmsM4zovk9RlZ+EFVMymTs5wWBYkPsBQcOBkCa3a2GvI24mW8hJAKE9pxSka+HkHVI+kIUDYBUSIglxmUSx2IcU5BMTzAmmIwsTNXc8OhaioYmbvZS03odcnP0v/akUzz6k7ZA9RYUqpuq8zNdB3Ayzf/7smQpgARzXtX7DEPSbusqzz0CmhG5fVPsMLHBzyzqvZQKMZlBG4F4vU4Raml9Sr5JOr74Eq1zLWor1qfP3HZsjrumxlj7JfWSQ7bEO0dYu8SgQNoOcOfaJ8xWLPvfsK15ly8rLiQAEPWG52NBmWH4H8CJJcIyTEZhglhQBzKPSfgTqVzeQ3cb3pXFF9MNpxcqBxRzIcQd/c+5zZJIQV/X8cmI344+z/VUNROXg2bIYyq79akd+9ypUE+iNqLqyeZolWqHMrCBYx0a8RPkWd8upeGWOxoAIBdWMOLLtPoEENIDEYv3JlH1ZhQKnT5QQ12rDfwJBkTrBVMDzkyb+lCXTkt5O4cycpq5CwTqTS9Z+BtyS+atpRrBitnnYnM49pkKV3KNqZrZ5V9799TitUvXqPKxWfh0t3zOlDlS5dCj0sY1WWaZrFMoiKkfcVSERQWOKNuQcZ1GXujKqYS+iqaVfWVogFQVS/CKCgaKYHLNE9EijQ4qwwp9KS9lJ32Z3Bk8OuGDs9YlWPmRWHqVeRSRpsHCdXmpVhgyGFhcq1EEFFbTOzNdpzlFVEuiRbVWUSzMiL71FXQ1tdPa8y8rOWRcpqGSuXKzIq5BWjDra/ApJFeWkkQYkQAARGh0iqFAClcm+qoQsAQgqidZSDIg0Cv2jUPbphFJS73ziDe95Z0A4qc28G4y0WqfRbuVUqJz8/Ysvl6K5EU34OVdhj0gxeCDOYYPoZp4oYI2TN3FX/QquWMuARPisc21lNCz4wVq2LKmRCHVjVjJUabNkj7GmRlWEPh3lMMEIG1No3JzWndQk0VdRCm3CSAFAEorRJKZORlJCP/7smRRgAR9XlH7DENwdKu6X2DDjBKtnUOsJROBrKyovYSJqcnCQgVcycgGwZZr8w21qmd90rJS6ZE95ep3Pv3tm6fz57tJBAv/u3eX7QsF+09d9bzQCuDjnV9zIvReo/Kn/dCLMoB0XPtLwYm7kRsHjZZf/GPqWaKfycIgxYRejzqicxoMXusfTcTIAYrt0050jISkGGmIFIUOuhPctDBOWCHiZJK5dEn+g9qjrw68TZVRhVhikcsQlhAkky5iOkRiEFIFVJIBVkWrhTVJUsKUEUixti2DKOZRDKcH3HrJ2zbbt88dtNXML+HR2q1cAzIrRNLTnJUWNX3icYh0ytdN+0X7lXA1ajtpMD2EWSjcs25zb+b+Rk/P5LE6vDOiqtiIAATV0+U5hpDQE6LKHxch95VBC2oDanA+Stpk4wE4h8FQCLrqilOrLqtXlbSS8NRmnVqT1zO0xgJ7TXVubzW3VqGvmpN/VZzoqinZndWI6sM7ImxW76V1P7TW91ClLUEOdBtWKQFmUVSwAAiDjK2xCIQEXwaEYuJ6JeLSZ44biOPEnUVjees50ZVVc59nDgxvqmcKII6kFTFjAusk4ugYpd8uWDVeWEDq2HpBbDSJASerzfM2txEJ2/JskqoHEPwln6wyzaiqUvNSPi27yQsVsEmtu/EPzP+MX1+pJ+RJLkhi/7zGttfQrWdQD1qIqcOXEmJfS7uZlwfXA/n9ZlmXVIdWkYkQicgKK3FQ0YMzIDYdAsy2gVClzR9fDIZDkjEFGQEUmDmjswdEkEE3N3eoV5nf/lTZAY7SFEuIQDcKrJRHlzGS9qpZHehGuR2c+okFe//7smR2gQTAW05jCTVyZoh6L2HiShHleTuMMRFBoi0n8PMKcEqS4Nq1CUVW7fWz1EHtK+9+oEtapIxQACrMTIEpIbsEVXQnBwJwv5F0DC9bNICXrHL02waKEhHpISp+SkhrmA/S9iRJ8po5RelZb1DSQvtlslIrw8vt+8wlNmoXfGgXbuAZvKE/9iNCnXXO+US9cuPvJbw7fGoH3txkjGNgaI3wPdrFm8ZVcd8dTiMIvlmvGRb5iLzIrY0ik4HyqBYSxT96EUqSpbnAQ4iyZdiLlxel0FpmMNTxIETc6OcuxtpnPbq8DR/UG7bm94vlabEH4ssYBLbsXrfudZVsKQ/a4/035V3jpht61o6SK35S0Je683K2Y60O9mU8G3q9l9NN/R22M+VZr2Eu1skqAELYRSoAETqTzcBNkFEguEChEsXfflsKpl0sVl0CO7DkFujmEN4jgImzwYHDBG0S5cjvhAnHbkoG5TTkk+or50lZTRk7XOHmL+qS6BaFKIDO/Vb6F+YunH7DRC6Op+irEw+25yaYbh8Paq1aBYx+qHa5TS5Yf+KreyLd1aF3GqQh9875UPU1puG3TCQs/g4m8c6OZ2/NoiRLOjIdjSQBaWxbmCFLWXS+QGMxfZ2XRfhdzHIExe7RQVjgYPxHdo83ED4JjLdLvfeBKZXt1sm6SnPM7H7sjkVcH1PYohcY9Vb2yujsfi9b7tz6upihjix8xIkyr1h7oIfkcaujaRJRKsSGooCmKApyI4pnl3EouQ+8qa+LsQHBst1ehiQcxn1wL8/Sjao5DALEl2p4U73q2PZEl2LCRjViPyKzlUWEdy1dm8sPDv/7smSigASxXs7jCVxyYKV6L2GCbA/xa02sJFqCBJgpNaeiyD+Fyxny6e23Wdt771i97Md6MgV81Lldi3b/IjZ8qNJ0d303XS+t/qvUuXrShVRlGHqCSV1efiJIAaUBj1YLDGqGPymG76wkiT+MYRNqbZei8EFGvF+F8M2e3t901NDAg0eI5D07lWX2zBW+GFUAQgF4WxvF0EAJWlxuIeh87GdiMYGtjTIX1Psc0iU5T5EKqcXTh9O3SC3vciOiyJSCXP8CIeXYcvkP9bSHo0AwQAgsNbLVAqpVAQHBmFNBkil5ZaOH0TIFiSBC06W4YsczEW/UUzWoAhoY4Klyj13LVlFRB2KOGDihc2Mk1WKeqxo/7G6h+xHkrPAoZdDX4eK+mqEbnEBb4SrhK+C/IXhGMgyb5csftLzCGV0PuBp9cDURbi5s8zkgPFp5TLAY8ioK2u7IeGFGqTIVzgiIBC4Y9Ss04UactIR4S0gS1KUjmfLy+SgPhAdICdD/NedyFzpehzmuddqsJRl+HWfj1nmSSq9kKESVQosAGYE7lTLYDQkxY/xaHiv5Hgom5Nnz0FnTggncxf5km+XUpuZ9Iy896B+DA9I50wC8J3MZA5xwDRZxjsABvGrYlCSCCDeBkk0lNAh6dKPilTHy1MadqGUEUz8cmmCzjcZ0dxcuuUuaWGq/KxX7S+4QeSGqmJhVnWne4d7LZtUNcspnBVPylOfDR3Dlzm+CboL19yce3+eE8/Kj7M6WCANFjjtYv2kxgTXg1CaZLPO39jPVNkJjKzxm+JjpD27g2u+KzuG15ikAF9VUhXk0USaAN6cDrsvtTuYLBf/7smTOAAQpXlLLD0FQeKs6RWmDXlFJe02sLNHB4yxqvYYhUWwGSVXgtIIBsDGN8jiADyqzscSQQWLXPUDrmLbzmlDcZrLtcxb0PvyBBG1P/o00QGJ3HTLJbkMWdzPSSlDeddeWntIHzMx1w1QfExcVck1yQz6iyaCrzJYNWeduYOqNR3kac/hBAKQEhTIAAZz5m4igiBw5ULvoFq+USLdM+pHhiSHejbg1l4JyJPfGC5MJ7BNIDe3QntnJhJz9I1Lf1h6naivPR5FhKPkV+SmUAlv1rA5TpQjT1y1xFspEuS+KmbNQt16goCVobKupoSG/wfP4m8/Lh0Bbm2mvh0Wbb6plbPqHS5EFrlNv2dYe8oth5InEdZSFRhNBJiwPaS0hFaJ/Ti/xbby7vbky0vWAVGXU6gAE2H8wkoz7dd0Cocy5rfxVxC+tTKBqRd0tv0rC5RfF1pEUVH62mVEPTtcCpaVSz6xPK1jZD7yyQJTNd8e6BbN8z3sEXMJrTz+WCVF5LZBxFvwP9sJESvXM87rlE63nzvgspTgm61O3YpDu01DyQ9kiWNBeI0WFqPv7pb7HOfDz3WTIAjIgi1Q57YDtY5VVlDNplMnIRL9WfTuhK2QZHAcAbZk/w8VwnCuNh9IfOwFc+Meu32t0USzAxvrIYrtZ/XbWO8wrS8XAiv9nu7V21riVT/Ps12iFWbro+lpoja0/DbHGXtxEe1aX5+OFl6FxVbYEyO+NlyGY2rXZUHi72ol0rNvaGGBzCmWb8lH2XYfjaoyFMORtM5zfw5DBFmxnSBgPyAHLZhTsdcaCjcNAIKlGXqfhuRCCa9VazNspm//7smT1AQU5YtBjbExwh4vqLGkGjBOheT+N4YFCTS9noaQmcLNPD2d6zDM7OrbPNTWw6dlqyhZnHZozjXYbUTJjjWkHQLebgrcmmLJKmMXbZsaKu/TTwsqzHUtYzNRVKQrQVy7lZImjNTsllqJC/Ty8oyOmI7JhitPK9ILGnpzi11TgqmdheYXEvlptrE5XtKIm+kJxgNwN1AMH9hAADny4XAjEksQBgKGHWUipkjKpa4MLUsVjqOxIItAENxZgQQq2DIHpYYTotggOlc1LXMpWTZ7bu7V9g2nEL6bjz1TpG/4VYonThvZOHkOblsFjxLa9CJm91jFkm4TURHdtpLcXIVaV2olBGRG7ZcnaUBuVSyW9BeqiwZbiMt/rNQ04uq6lBmbuSV4aB0YEcF9UIwzmpzRekMnB2RAJQUiOIAAZ1umuzRioWNWynZaJAM19rKaaE9csPNy0taVwC+sZdbMaSTPEG46cQ1JL717R6nlHDUQIjacdXqktewuFLa4NmutpFzGGE8M2MMzarFKYpF8a3/Ghw+B+NEYhpSfNHSJFNWFpaF0ujSXrS2Kcda5nCihF6itXaj4a1spjiy/AA0FYxwJrngCrIx4/LUmEFSIzeNHS8BgA3aMzwQCPYzhti30fgl3HicGnrQ6H1a1zsYtRuXPGcZJDWKCknlSqvivOneQ/08ZYsS78vG6pIRT8hPXo1k7SKP33PNQeq4Y20+uSA/uCUx4Cw0UsQy+8TudYfjDsn9HUfDNHCpYxUeR1j6NJTh1uChPbZBnkt8D65HrA8tiQDDVM5fsM2PjWQRBUw8KScV40tBVXie0rgNVV1XLbOv/7sGTtABT8Xs5LbExghQtJ3GzIiFJZezltpROCGC1mpbSh4S0qwyOaUPn/JZVZe1WIIyHcq5rR3PA9qIlMkviz7FigyJoXraDrbJa02a4gYInLGs1OYx1rqSanWkkLVWYJA6HlHFWlxEnDli3OEqNDOS6T/tyt5xI5WjaTWckVYoRrg03KpeoCJpIQAE2fmMlEzHh8aWzCjIeFI+iYXWL5tvDUpQButLGmKton/e1PQZqmxCHxieEgwjaYXP48TW/XuXuhOrl8tODKjcv9lW0e2VuyV479V9TMlKa+0H7vydrq5zFfqUu6kyfdIqg/9uP8hRsZMQVCJWOXHyTeXy2FL+vVksUddE09++92FbeHZ9pzX+wfQ2FGtKRUCn+ACev8oABCAAGUB2cbkRphdGUwOLMIpApIw5VYqiC6mMvaw5sANB0BDZZcHB9vQ+M3kLPTidLw5MTLQQ6VzPca0Qm9lGWVBdWel2LJhSxK1rjuT9KQf1WIy1MsR13GLjBggiqrm1ko51VlPHNVEKxK5WtlY8cU2A6lty7cG4eEof+pSbuWTuN/fLFca1NrKqMH08AqLSUt0gJyiAB6oRt3oKaGVBioUi2NfSOBo0vavFvV7CQhz4pBkbkzvMEZ8Y8ajwut46so83jK5tIu1FG2u0PdYXDEyzXnV94toF63UjlarjH3pCY2aetaVhFjbXi+Pq1Jdx32ICSiTtrPfNiG0ViPEG2XLE+55/yR6kbE946K9HRQ3ih1m6pCzCSgtXTlmRUlErH0dgZlkBIQb3H8wwJYQhTcsfv9MH8VC8bQMxIzxYQ6iKAwsSCTG0zFLmSqZkIS//uyZPUAlNVaTUtsTHKTS1l4cwkYFKl5MQ09McH+LSYhtiGo026sK86lsbBkMHxoBJ7GWWERLH5ZHixF12z2KVUZ9NGVUsDh8cTXZVPkC6iLcJUJVEB2fDpP2ZfdHdyO+BGN5kv0h/QtZNHUzh3He+NIGGQZzydTQNmu2iuaiv5p6u8fOxrDUIryEsitAjaTRABNN/DARMUFnLHTUFALQ2Ls0QYUSRkbsXyZk7EQdoVJgLl8droRXhgvQyOXoV6kcoGyY5ByOCmHVOvCW479Y9joSENR75xBJ2bX2fnqM79WygppDAXvmJI196RzOX27MsTOMtT98nVr906QudMMc0oi2KR7Zjyc6Zei6dtf8tk1/fb6GkXIENJ13deLbvLifsaMU0f7vEAAglUAIDQmsP8zoAgDPirw4hmiQNg5WFnCaz+tEdx3F9QCH0D4AhobNgkEAPsFJrXZNYxsnbVTJZYxRU0e3NXUlq29h9tUdpMP5INWQasrThtmhGq5WOvtjyfOzngyP3NRe63XEM5cvGUMfMxdattz6181VSWwtEsn6f/NQ1lXDD8ee5WdBSyRb2kAOAwpOgZAOIdDAMCFNHNiouJBhuVMcVDGRGZmOyZmECwqZsCGDgIoQj0gZoVmFjxwIocg4FZEYKBlYWYIID5eZQAmYiAKGzHCAVAywHmlgxqAAOE5iAGXJEIApesQOBFRwAW0hmNpjCQ4YwOJCWUd4mqRTaL0CYEnYgnOGBREDBw4zVk8MoERYGWI8EOJh26Rk8whEkY3JzlFq7zyGZjMPUH0jT7csmn0sT74NyayqZ312v9Yp4bfe3abvebS7LnE//uyZPMABNVaTU1tgAKKCumLrawAJJGVP/m9gAQ4sed/ObAApJFDk5PtNXbIZfelMAwLAFlt4BnrVBLZqt3ryuRdkcrzlcrm6WVVZBGLNympKStjZeSjlnG4xOafWb3K893Mqj3wNHYjeltW59T+65Io9aps510rWV2mp6pnlP/Ubasl/zr1gASQOhKoQQGAViESBIFJpGgxKYiBZtg0Gkj4Mww20qB0SmtwaZQAQYTDSQDBQVLyioKMLj41EYjE4jMMAks8YcAHJpBqguUBoMBhGEphIZtTMZEWXgY0AAI1R+7b+SBckYdubSgbi1CH2kOi06JS9XbZXPV4+secCLSaXVoAYXIZBBtqKQ7ZkNWFwG1/KH7j9zVDbhqNWW6yB94w6zJpFUkb6QI7lmrP37VPbz+XZUd+DI3J4tnCa1SxVy5S38L12e5rms8MM9thl03UrTsGUkhiMelMEVIxRVpBjnWnqaB5vOkwocM8v7r/kbgRyrhM1b2N+1vv7zpJVdrX+ZZXBazhhH+osxwBJC/+L6mDlQgAAKRuiKoINZuBlQxULlBBKmTLbTCn8dly4u6j6uweHw+QRDmYiZqUGlyiXS1q72zRsbP0kpdoklGm1XM0xyNMg8vfVONT3MRmxsSiUCEAGOkmti1mrHTtMlVVvXUzTL437Pf3791udFS099c03qO/8HcdJ+Z/w0gfaSt5dboZcUJSAAAKVFBQ0oAMYCm0cXGBRZ7Whw+remkHDUclLHXkrOAJAmgcA2FXEYOQai5Fjq3oocs0cdexW0qKrK3W2iXao1JzS9PVRXVXMiOsXGvFV+8r/1/9venFJ/7V//uyRG6EA/dEVT9lYAJ/yzrt7SABUUl5Tkyk0oIMrytdhhmk3A6LH1Vy8fPcVz8d187p2iJVzTuME0ChAoPqIjy1///vgABVmi0Y+hEUGSnjMWNQdixFCSw4HDo1wpCS8SYNmQJjN3iDvqpqud28BwmB5x0ERNxCxA0u1QuznAiv5LSZf+t8FZPyJmt9/ALdZsszN7hV/6++r/fI5702RdZHMKr1DkNB2cyO+oUGwyszIotpzNibW7vF5vHIKe86MxhmnkAOW0P3vNxnW8zd3hGCJCJULlCpRwh3Cd1GozBn6Yi3GJJ6y1RWZMkg+CwfjpBFZFOpoTIawokDUOLUS0jwkn+b1fWX1+M/Y7PPa93//nf63YoZWlkD/+5Xif2iLb0322+5EP6frgnLHN6ejn1ju/jaucuanVd7Pn1gLQbcrzGwY+DhL9h+NOru4HkTd5DqKF9bTju2zl5YCW5dIIKstNth6ZkbQ3YkgIwUasMXmpU/EXv4QS62/OC0GbTMcr0rjSQzeVNBvaXdZrltrFNh18WkkzK/Ojeb40qiNZS8KlLJ5i0v6HNarZV3XueMZ6Ux1ks3dVUhnZqo5jHqyih5pYmRruHQY4sJonQqARY7ktrRDAEP6VyW0zhhAEDRgqmYKCoGhNhZsx1hU8hMwY5EJ1kssu3lZW1x1xKv01mYiGCbHeVAZe44WZ7DLSbXRetbxjYaWWTJNn/pHn7u1TUqiZX7PHVpXs5ltDc0NH+PavuFFlvvmxpkW9JPVNGNV+qWI/mOph9UqWeo5LDbjjLJRwoYsjSwsSi0ptLG8FpAkQXQCUJbKCKjgJNFFV+Fp5sD//uyRJAABARZWesJLOiDSzrJZSibEEVrYawkc2oErytphJZ1jLoSR+31nsc4i60/6UadbxaBeaUI6cEV5OyZ8SWaabXzaijUar4orBE69+Fbr75QWWDAIYYSFRcV/QFCbXJhTXVJrOqhpW9W1I1PP6ubZ2E03GmviScNc/0DhQDVhQYuVlJjf5K2A6hAUciJoIgh+3EB2HWBWLQGArLa04rw5J9vI/81H37kGF9fLyyD7JE+mKm6GdueamNr+lnfzy1WMQf6qlux1TbITE88kO4k/xkvn7NarJV0t3NqHRzqysrvyh2ytlY1nej3Sqardz9b6oZ7VFVRxVWXCxgmAhjGBjKhMpBG/b8aAMAQRy/W8wXTeBXOZcAMlFAmbPshxUqgNBBTghFocmpnPTOor8YQxGfMYxczL6qv1PH3qdakft8VS53vxsxobrs0bPiPo2N1k/l1n/pDX+6+Fr5bB+slvZ/A9vP6PRI/UZxob8odNFIx7H1+zN2aPypn7fx+v8r/zmd/OeT87M/fpEtB+dhiI7dOdX6R7WFawAKCAUJJvtc+hC6VQiLlDkCfkKE92SIwqEF/Jch5BiVtJVeOWVsrcehfY5KpqdoHINWPFNiIGM8xgXDBlE88UFn5zk3na2clqnWkzqd0lKRUdH0VmWgtNaJrd0TSJ9v+uCFebGhcbkcpiy+bOK6K7TqX7PsemhsyyxXXtlv//YHwJRpyyTpoCMjVTP02UBQpM7a7UIyYwhW7gig/VuVq+VgpaWH2wPZnu09tfFqrlKfiaqbB6XGavzGVDYpFI0WRPGhrZTuZLe05kxWpy+eqLyTlZu6zIH6t//uyZLQABIJeVVMvNHB+6Hq9ZaOqUdl7V0w1GOH8LOkNpAsZFSJKtdvVD7J3q7iuxUfzdUoQO1O7VyVw81qvybNQxt8v8uixe+z1W4rdIPWnHvdDJi5HLK/SAirG6FxhvrRiXxpywhIm3qlH0wQB5yAEjqZE/cDg66Cs/IlCUuhoi1uwkuqBQrJ8KkSsUDlSHlJSR3lnlZrmWOQstbBApNY38i6oilqzLj8q6q/Ph1EABsTA4k1ubp5BzHq9JN6HlsJQOyOt9DmoloNs038vL3f9YUilFY98NgUlZdwSNNdBC689cczqcLJUR29e0SNsKCxB2wx0VhqZbJQGQVb52n4SWKwGXby/JmkZ6HAkmOj6rBAjKJruql8qmEKUZGpXq8H78hv8/hz+1USG2wyEouu8rSW13zFu8/1+MTuKoZI1ZJ73PGdjJ+Jv3LWCYj37Ti4Ynxn1NjOBcWNhDdwpEr+c5IAwAASq5b0hDZ08wsYMELCgcMOoQURgIOUBdgePjBiR+QoKqVoTLquEMGQxCuVANGlqXRMMmCg0B4P7VWIa9uWxD6sOn0U9FH0WDOM6mxfmpOOn5WDZuXWn4Bc3Eynzf8N8Rf3Pzf+pQnlOYmrHvPSL2ypqnfqQfkwl1fQ6Mq2EwvqZM/n+///owBbu15jAJiYQ6zN0bLVGUKCypQ4twl0RERCBTrCkF05Y3WBEa4eeuNukq2j0PJNZUl0GP4pPnceXQOJ6w/fupj0D16W/1i9T+ym6VKu/Kr7fyiSDSyBDC2uhGp0VujQ3mGG6t7Dh+7e+rOP5Nu4mKtUoj1DlRs6lr60prj+OLi23xTq9G4NT//uyZM0ERFJaUptJRTCIaEpKbYiWUd1hSu0xcwH8q6gNvBWwrWEBgOyb+QAIBblFS49iOMfKjXW+jNWdikDMSN05xwTBIEZGm4GAEyXR2G/j6okEZ0LrIwcHJadXZ8pTQRXjbKFWpHSagbLGC1uy7DkplF7Kaldujk3RrYRQ8OVydbdd0Z0LX9qOrGtszs+ipdusnTG5F0dejdESzv6ulkW1iqOPipLiT2dtABRSeOGFNl/IapqaQfbAt4IECEyISBhgCGKAhOY1EIaRWbQ0sZsvxlDsPu4tekaKnhH7+mcyCgfdr3VyzqVTYY7LMXvWTNZsp9EVWj6hDudf8X/3Dcsy7wAja991+WW9nVJtTm2TPoOEGnS8cj4o2r0Z9G1tQmhj4xm3RjCQ0ePCQqPcpymg9foq3/oAwAAit5d05jWSFa48xKAGAxRfQgDlhy+5QQGGCTtA0AYIrXHIJXerqS1zoFZkgCpIfMxE0nmlSJ1grDYstRKO6Xupt36joz/NaXblEjzHtXqbOIcjaWGkUsbWsaVO69u79LXpBXZNWV8n6mTS7VX0ujZvVYkS1RNyJX/oAALSUNPDsAu4LJs0pUihcmS2KNGUwYIgEGig0CxSKgJAQ4MrnwIIEHtgIggBhoNBF7xUDqoiwPpshCw4TfNRIBpkRs4hGmNzRDekUMbdm9jaxqbEZ/a7yJbtfZcVhPoPUzh7eCud5lktZsj4gmcLPGxCo/YbQr+BUA3Ixki1bUb5Yvf3eLmjpGjouAb5zwK13M2znefSapfO1lRQ3Eg9qjLMxrD/BkRuYPDw1JNLR68eAQAjJZe00+iAVFggqNAz//uyZOQMRGBa0JtJLcJ8C0pKbWKOFh1xOm49E4HerSjppArhVhRbYEH0oTBiErTHh35GSruwBBjT3fUsgq0zx04R8EPzWitx/bG71LNQ9hkBs8wLcnHmyeatz2tdc+Qyj5habSdGnICnxxf9ZTq7qvQtKWnfBItm5l7dE8+nIvs6naju+jUGoxQVprR1AHWjYQ8E4ZhTCbEAgJpMSsw5XDBYwALCClKoBBQwDheDDAWVwANAKFrL1+oTnkJiOVxFu6vInNz5EDPlQvU37/PHKApX0zIj6Zi6i5VUNxf1mzqZ/beK1gRKwXdMxFJHqx21EnjYiPwlSr33kR4yKRlx/AgMfx35557ijnebPVSO0xWYv7JNuc9u9SQbc0cLXbnNZBWJt1Pd6mFMLo1163owTE8GHM/wUYpBAyozUAQIABJjahCKAcCFB02MWBICFMcQhJiAGDgYHCREXmLAlONAqcZL0sBaTAPE93oOJFmJhIFFSIvGSYlGFltFn9Tek+SxRFNhLH/zapDssjTxiJ1/1D2KOXISArWr7B8F59r+We5bDBR+ctoDgIItEBoNVLFLyBSnvHPxQ21f7StOr5P8hbQsfVwKClWhFEKLg3eRQyXeRd3MhxOiwmAwClO3KAAwtEOBmEGJYARpIIRAsDVO1ZiM+ow1fkGOyq9860ywILOoLlL5VVfVI9swvLn6zXOvPmJG1/q/22z/73DouaPs0fueLRElF2wH+bfPkkilniOayPfpgksNw8EcfSteaiD/cW2i1dVsLvtBWe1Cr84r27ezs0kc7XP/1JvEm9pJJyHcmOtYxJpUYCCWFgfnqaJmfDws//uyZPMEBXVeTxNvTcCcy/oabehqFD2NT0y9McKOsOo1lDH1xvdP+ksjJEADgMgBJOJOuGLwjoZbiBig0rNTaIQgIS/So8FUvdCC3GBQFxSAmUKwwqg4YaGqmpirQFdcT9yi/18R3S8qPBHiuzW2e7DDQsAub10+RJqZB5M0tK+gh7rncvQOWvZl6me30THCPVYvaOel5ZEwrZpL7kVcJcFaUT7V8S6TUuDr8pgKj/GcHiuTonGOw1IQbPKym+WuhM+91I4rvCxedaR3+CpUACsBiVvtibrzg076mp73iMA8BWQqBDJTJeK4odrlA3zpS6OwEDjVUVtPlThuiRGhthReqiWcNsXdxQFzcIT3oCeX1lBaLP6idzyblRYTZvSLSykZrZVP1I15ud9D7PQQIejaihcp8rNkPu5aslFVjGHo9WpK5Sg5GQPHlIUaVl3awAMgQWnSoiY/h6kDAJa9hhU+ZMjuYAARqiwNI+zuBG1iON15rfEQ4OaWMSZLEQ70bDNxkcFC1bMmhNJhHFzv/v/7f8ljGXX9bX9lmZ0mzc1UzyVRUlm8wmE3Kwreq5eUs/7zjQ/P+32MuSctPZj5T+Z6gF6AAe6kWGrCZmYvkawS9CQ2rq2UY10RAnlNWuiNo81OtAKPaUKRNxX3IX9CoYosqdESZSxwvaaPSdZ1lbmP2aO6JXY+//aWDOdBaR+x8qHof3xIz5O9Sx3joWKg68b+odXrzWq/jR36RFhxe49aVzY2St0uhl0nUJrU3adQMFaxkxcdNKguWxY8VvqL5GT21gAQAEEOFkApGc7B0YLltG9BTIoWtcQrByBmqB20jb6z//uyZNIABApZ1esJLHB/i6p9ZSOOEGV7V6wxDaHqrqk1pIn55LCQuQAy0D5IO9YSzJNFTdp5R9p4eCZi2UijEGGXoIbnrf6/n1SAD6ndbfn4xFK+IUoxUuxvVuq6G4a2iGdjvz5nei6qzw3kPQGBV5kIJdGR4cUUsKR5eDM7GgAKAAABAAGPgJo7+CRY6pyNhCDQF8OMzEgcxUiAWPWMBAGKmDEKl8ANzLWpDuLD7vIIygFsWHLjsftRxTi5Qsyscc8+kjWMoTBUllr3K+UbayyGfvCf8YJk8+7/bs3Ec+gPtrWP8fu3SD+6fGuc5ZX02c/MSZqjfuznJEkvVd2SG9rn8682GLxtTjSiVa8E5w8FVsFY6ITBXe72QAMAAAAwAKamvUIABeZ2Lo6AwrAzDgHMKhgy0PTHQyEhGYiBL6EAUXOQASlIgBEyIIuhtJVu0C19uxfeWC3KYvm+uUeeyyIHEnOp1bjNjlWLu4RvNiVrNJQKy08w0RPIss8+p4UJtRdOizt05KRHl0vjGQQKpvSGKPqFVyt0qhS4oD7jN0SRgsGdaNImx0ERBVLBOJWUbpnlv6ABwSk2kqYhCZ5oFzQyeNYZAmYIHCMcZEIASaUAUAw4Fgy/oFbmu8HCmL2H9SdaDhpGKjswOHTyoIEkkzMVG/ahU6vNdRUmJLY5LIduilmA/W2kVEx8Gwcr2PgSgJBVLRRaYh5VqrS1qa/kaPtmNrBbl+892StTD6HNeLVWo/42ZoqppasYf6yQsg0PKsuA6HZYo1wJz67YdpAgAABGBoZ9WiIzMgIhJPNwYR6+AhWKAJe8aDjMQxS0HCa6AMep//uyZPoEBNpaT2NpNbKaKznccWO4UyV7Qa0lEsJELObZsyLI6JAptF7WA0bAS7UPVpatS9IGqwhX2Tgz0NGEChACM5Z2qql6BL9JyjG65SHBEkNCK8PzRTdw3EVByX+dNnWbvDTfzXdTVsfY46LR5nJW7rnklamGmuq9hb4O4Icz+dkNDmGGi1hkJKBuGqaqAERjGXA8dlMGHDMqozp0NhlB6oMFPwwwCwItcdHi2RgaEJCjNiwHhYMFiRPp+rjDXtf2A31afBMndJ88qSlc2sUXKhQKikUEaxCquhTI4AT2tlhwPzq4tvmN4b8bt/nmadM7A6dVy206qS8ap2NgqRWohv0FNTDVgIrKxrfMPWV/CRUrFZHH03Ktc0S1rryrxnnnRBFzknb+h+sAFaMSAY1a4AsETbhAMBBwwJAjCYgMGAxH8uOCnDsPbCLEphA7tDlA6CgY+trawBb5f/KNrtK1B4VYZFcdO3NxWen+sBrat7KOWmI/i8/Z/QrY7kUW/wrG+/nwvWJ/G9JvyvWZM9J312x/92Xqck50opmX1tswvaDQX0RhQL7JiLRYqZIfCUIOEnbfb//QBACAEoprGCGpnh0IhQ3JzM6KzDZUDJBUBaSG6z0h8zPMeK+bsj6VZ2mQDGUGIpOVXddebv8AMH8AyFRGHB8dBglNB0xbIIODwgsPznqnCWchpHWErrUni7Y0+KUKG40FlR+3pe+ZUFKvxN9FDf5ZxQfO7TjYNWaPb3jk4dWTE88c1HPPsz/Q4RSg9iGLJFzhmdWQaZRaIg5F4nCZXJpu6xgUJJmrcM5n4DRQBCoHAQcABWCDG4QQOCuk//uyZPGA5NhbzRNpRcCNqJmicyZOU119O03hBcIjq+YFzBV6qwupRwt+OhGrJFtiJUJFJNV3DTxm21m0fW0zYfD8r+Y1daRG5rdLM3uS2xFaWmxMznCajqnMjOq1Gh9nUaY1LKDOlqLbRRclEN75TmRGqIly/GWIaqbKW6+upcpX70fMkcUPA+Oxc26hVQAk23TIijxrTDljbozHMjeFzchzHglMVOGUL1X6FFqKeKsxd0G8WGE3AkMuamO+7Gq0WuE23uSxWajLOsNsSFvdrv6SNTN4mP5m9utGhv3mI+Zc1yw3+nu9wl+J2wrbRsXncvZ3bW4cfGL1ifG7Y/zjWp5PVrvTVt11VlrEgNmr/NKW9Jv63/+dfO/eXz/wI/197nkfOEXDcyRRwUcI04iHdoBgigKJy3ABGbPIrcZgYHMSWaY4CqqmkIgDhg4DK2ByFGmkeYDYGDREDwJgSyLKZYgYmUq0jxKqrXMRksWewvQflazLOPN3OhjdWJ+q+f4n8hanlrea/0ftj+biPh25r/klRUObVLKNiF/jrhPXme69fv+KONqHR9Hag1UP70DaXzyNIASJYRaJkNIoHAoFAaICQDhoAgTnPjJATwrgiOkIZI4YogZKyPnQAQSqEI1oAFNl5EsnKib0h3oG+gGmZI4qZ7ZAcGD2i17axG4+iIjFS3YkGYI5EyrwdIg+FulhUSHLxtDSvf8xZQFWGRFsIfvSmGZygvxeKUNuILCFmC16rWdl5gYJLJ5YZblqk42igi6IEdyWWDCFL1F8CJlB9jSXFWrapcKS9T2c884ftWNSy9Rv+8SCjZHTc5Odc+68otZb//uyZPKABRFaTp1p4ACDSzn6rSwAJQIfR7msgASIwei3NZAB5+etQxDliHL345WL8obOsuAYdltmWp6NLb5m/NX//efP////gSkmJZbysRfDkvuWLHtxZ6qOS4PdSMKks9AFBAeEm/////////////////////////////////////7dai1cwvU+t10kCgqFk1CsYDkcCAYBEBRmcQ+ZGUTITB3zw9DenAbQROMECOwjGB5ehsBpjSDQFPmQISIvuiXSHswSoMHRVa/JEr0TIsC2oGbWAGUuuig1Yv+l2iGkitUFBRGyzrsqVvQfddOuHwEa1oDJAAZGegq085Yrv20yhl7gF/GYMHFjGBjQTN52anpybmcmSIoKaQI1yMWBG6AAFKUBLBYGczvNY6/WuZ55v/asajFhibT2eTK30H00G6q341ql/uu83zb+Q5x3LH42rFHDCICoFaXLgSEPG0ZMdaTGP/v///////8UwqWLeHIvhyX3LFj1us7ZU5kegx3GlR+mgiAJTTzn///////////////////h//h/P/////////////OT2YQbErWgNyyFvXttuJNtpuWXcQtmNGwlLGaBwBlJLJWkmcYQbSVLwwVdbQCYNiTkMCZY2rI3vC4h4YOa5ytLPTG0uglCtGalcYf2EtpRRSCofcp+mnuC/krfjb6T0+2sRdln85BVFNyWGohKJu1J945v1JoelDxyp9ZZel0RhiGKGPXL1qpIbm8b12bl8/RVK3L9+U2ccqmVFau0uNjsMUWWW6ucqr0shpaWXYUtLUi8M3pTOauWLctfikl1LqvWzvY2JDKq/8ux//uyRGIABy9mWO5nAADljKsNzDwAUHF5Xtz0AAIILOyrsIABG5NU2fOWa1BPWrWVNlerc/G//Iw7WMUhmmlc7cpJfepPvgCEypqNNpNKJtyJ1vXPcBoqpNo4YOsoQnKYRTkNJTEoCaSIiEougp0HKAjl4JyBWMYV0EEK4XU6lgbo1T8WAsVanVdldHuczYfrcLaTcJ0opFpCj0U2TGXClXb4jZQmIXQtCEIatItmXKkX0YxuczAKUTNWI14tqlruxQlSoWQeKcT2VdOwHQqcQ0IZ36UNNUNatg6pttlW54bbDZIr2rSrlSfDW5xD1FtUytdwWuA/vBe28SK4OLJjGW+Nax5kjVEaE8N8zELcU84K5vYe5OUCruFuWHBpbEJjVeZWdkhZ1HhTRJuwqAAAm8ADiYgAEdg0S7COjuKQvBLn4+1QlGdGhGI4QOPFD5AVUuDyB8GiovJslQe0CbIHs5I6KlDQ7tDGHt0PhXFRo93ikUaozG0Q2kjx5gsOswYtSNf5dpMUmJq0uruaiviC7ZLSIi5qJ3SIRIzOfl+ufdIviGc2T6+u6lR6qdoxAxtUVekEEAqKLhZShxhCl2X3XSvl4HseR24bVlbV+IbkAkBoHITgUNNFQqJibHzRVmkNsPmYIPxQ9yD0Z1yErqUSc0YbQxmvlaHDLSUdPeWd6u7nTj+9lmOo4j1auaulzyqu052m6mqemp06pL0MtIjlqo7yRHFzMVuyQ8glPdvdUgwqQRNCATACTgDEQzymOYXV2XgahOSoTinR8yvaY/YSA1ikRv5yKSwoiXLq3WYKMq5PfbiCidMUkjdqfZvGO828se7y//uyRCEAA99X2EHmHHB9y5ssPMOYT21fZYeYdsoBryyk8w6gONp2fFtze089VWGYVUhM2MEMXQ5qShkcxWzjB4xZGrFDkkV8dKdsM9jubxpIaqJGAyx4o03ScmN7WgLpNBGUAXIGIEDfFGLaVwnpooaGgVqsEaGoojneMzQyRqmFAswZRzlI8FBkCFOgzyUPPxOGur25T3mpK8S+MVMHVNmj6MKI+UkWL55NkeQNDXYLKEpbuh4Y0gpL2VTyhl1pZXcka0ohvDcvsuUothLUSJhlsJoh8zW6Bq3M2E+3GifiAc2ANMCVA0ANYFcBCAfSBDIPEgy4HcL5u2bqAWKr67raC+l1nbCqosrhi6JEzlSRLIJJ+mTIotj9mW6WerHVCNpNHLKpK90MzRnJrO/iq2ZXQ/NnPDkz1FdDmXDbUrTz6c/V+YmnSZDyPaXo4ZUCWfJt6lr/+hq7baIWxTQYQ9YQINUCmNoo18WgnYn6jJEtkqnmQGaLl66qzqNRMkGykYtDvhLlp9kDyWpTKZBJpn9k2VtLRZJGGOrXcCORqkzueaHFNOO8F4SOZmhZm2hOLJ1pqm6EGoyUjqnqwkYjjHq2Kjw2TsK3uCEoJMWDr3nCIZa15rU91SJmkqyyUCiorInkViVQS4VeowlukS/RFkpQ0oZmF0kSal5XaGLmSLCAxB2AIgejI2cgaOcu+2GMBcLyOJBs5uV2sLLjG4wRxUSN6nugMkABcAKLa7mfVI9VLqxc3pzInaS+ldoMQOTmF1PO+zXXjiEFVGfK581BC9ruG/iCZCk4W0gSXGMqxDS0TiYLZ04YEQbZW1eAFWrB0De4//uyRE2AA+Fe2WsPGkKASxstYMOKUC13a6ekb2n/Lyvxhg3pahmFS+GAGLJAost5KCI7jFzaS6oknHcrPFJwncLqrYrLsgvroSmUNYQJBkRiLEdqBHIIz0zXwZEXNTjOtJQZnsfmtuVPuKFwyQGM+QsSp5XxipHGAnYCCuXn/aY0Y7XzfkHNLddI6iAFT4QYK0xgBypy0MknoaYehAhsmgjVEzFSIjZAA4KFUSAFVITQzYTvFk1p0sahBcd2bUjJKqzu5GfdqocBKMTSk6gJs2z48KoT5k0m3BZmf7qtyfv5XipJp+aZa5KCL1GqmRGJcl6f3UgbYkIeFFBkk4oCKZFfBYi6/nCBgyWi0ADkgxIyFa00xZYmCsM+Kl6YSd7iPY2jN60ABuMh1B8NWtJjNr865p7WLbLHuQ0kDzBv7T+Rrde8xRT6IrAjJq8MjJQCEKKkQu+ICJcnsPxxYrLY0qme/MbSSI69rNDzLY1gdh9h2px8Qx3IvzPtg4Rd4d+Gwu77LQr5NTcooBZUIYwAuKc4sQaAsizMge0IDdMQcTKgKK1UJfUI/J4K7BQhywPUTjTIevpboSBQdBTEDdRUgVyIbHJkX1isWvdTmcpLXpCmRZmtm3T5maZ+kzv26NctvDN7qX/5rak3pNW1/8qJGnX/LSnGa3U6s763xt74iWDsmoRGFPVbuuAFBRaSIIBLiqI8MmsQjL0s4aGOjPAJ8pCqUQMo7TcuUAeCaMZpIlpeKpS2dXq8jNj2miRoiiFptH5WmIFEwmRHua7r4tGsOWR1XpEhdq4oE0qJtwwS9bYv4vlo8bEq6ZH3RlDKcWEod3KQ//uwRHYABAxX1rMPMWB+Svr9YeM+UBlpW0wkcUoIrKsZhhmgcxDPdjOMTYlsmbR2rWLXW3Ve/2gGUARJABUTuBzkcRwJZNijyM/R4Z0rQpswJ8WPuPyut21PxEDt1yMq1aFBI6IYM2m+1EmfrZqk5N9x1BFuuhYYLL7C9tNIhhdayhdSLYP2DmSkXHfrrtG2PJiKJjFsVok8WhHmDVICL4tPNTfNjf+PtpHNhKgBmCKV1C+mLf/b8oEAIANkgUgwVMKlFjroTjmUAiulethULbKuMKdDoISKcCC4g+PLpat8TiOEu9juuk0DVzJzxCWHGNpeHOrm27GU7VmV0D8ysLG6dv6nyLl1GXvacbttb89XlNnlrpf2qka/QIxe4XjlFTO1nz6V2zS5/nJvz2psKyE5Do8JuNlDYt9SAgkAQALaMb3HTJgMggepw0BLGEuHFZypkkhL2ZU1OwV7IRLqlHt6IjJvpKujjDe6XOYHFTCcNHA6PqzlmM4auYp6pD42VeyaiW7ZvNypxnM2Zh0DM2S4kuFSiJYfSOEZHCf1WKbdWh2rGF1WdambAm8yZNvaHvYIlTyu53Vys/UDECwACSSCVEnUHwfIQ8GyOChcqspQnRMswVRQCoZOflBT50cpnoI1VvJAZkcJWQA9xT1aBm/BKMMcgmeyAepKI2R15uXsy9KdGiyL1m0zeRZEXNSBIHUaIGtIt7M0WodUsl8NEXJq7OTembMxXfrJS2Xz06PmGMakrvMciUYz7pauzV+EGtstyRoIl7QOE6iJhMKVjx2QTSrIu58rnlmBtLR8pLZyveaVnq6F8hnZGPkuzaG0CJb/+7JEm4AEAVvVywYdQoRLmt1gw5pQbYNlrDBtaeosq6mDDnB05USLVBnNaJ1J2C9OlI2k+RRhQ69Y3ZKCcSxTCmMFyNyOjkVYE+VqqqiiNmswy+XblyYtyYQxcJycStecNicQGplRJYcU4PIj2USP/XT5QJAMBgKJKKdISp+lkxDRFZ92PM6jiiEKZ+9rtMdpPaMvZz4efma5ckjjrY9UHA+yjbIpfp+tQx4i810cOfdO17KSrzuFf+MD5s1ur+S62PVmtaQIl0c+mdem/ylDQY1K8Wnm6/7HXPLbP7xVUp5IboposHcGB730PreWgKoAOuFGKNkgupMCEMkLwJ1pGso0SNUphWApRyv0P6QAAJxh4zkyorNTguPkyq/WJwOUFSYqoIQVe3Wmmaj5KNXtI41XvbuqbtGVXurSx/mQzx2ltzK2vNlbtxnnI9lPnnLe9bo/s+ldqXngP8QLNaK/lTInOKoUcIGA3hEOHB56uOkgBCUiUW0klKSJWBeYskJVb4ryco8PKbKoMhCyQo/JULMBKremhrhmklka4ZEnr0iOginBNHplD21O2fANqdJkIqNkk7/TcXdl1at8sk1Vmb/8ktpp622ek8a/8ef7bLl2j7d1f7vuw9XkyPul2rC7YIjJyGp1hcEO/eBrU/9+/y/sEGEAANEEFKLJOaEvA5JlUpyx5nqD6mbnJXS14lxsu29S1YGichiPKlSnlePMXntam7dS9nZuyn950EGDJlPj1a4dVtKxEx7psUM0STy6S2/RiCsZn8joI9sHkjwMXUxltmOyo6OhZs8q0WXIzOlziejkMUXcTF3hA2CEFUo2psD/+7JEwYAEDFJY6ekzuIFJmu1h5ixP+WVZrAy5AgUvbHT2DfANeVSbtjak4a4wQqxMwLxrmoMgXMto8y+oU0DPFcmVx2gGygeUTBfwXnmwtGlEP/tBShCh15ZJ9MOwsTlH2c6FPaNtLyPAmSKZaTbj1bLqqHkR6mUIzyOv9LmpEBIaGa3roz2UyIrKf84cZSzyPPefA7jg3lDkMgRKRhAYfTVXASYDgAAQAIVimbCAVSYyiYT6aMGogqVwwqDbZCQgcypRwOA1IgLF2zLsaezmUw+zALD+6K0Q4MmRdll0nvpRHgeIVXSIGDyVI9yBGih0JMnRCmUpTHqQIVYZBcjww6epjlTOBhz9CopSFh1MIHA21Hk8g4w6B9nY3QfIwz7JWm3rho1x1VP2h9dS16zeaJGxppyzC1ECa76T8bqEMmADQQAISCSVCwY6sGpDRUoXLhT0EKEVJlhrKF1tdJGlwDqEUcOI2CU4XrTgDwIGSYkmZPcBJ3Q/hu7mZr1iuWjuRLNFxEizSpTXpYy0PfRzY9oScU7ZWu7P+K4ljh6ys+yRD+j9d98nRWj15R1cCyxHXvV5jGwk2bUxNwgwelC5areMAJgieRF5gI+aoQm60iSqFiUroIIRIgCGJWETyegtOBxgBaqBVG0hGuNTbxvmAqXP9K3hCzARFISjNJBSFNUjxIUj3yQgnQjkaZpppiTSMNKDKc2+uIG/Jtm+FWaobKb1C8cX7Eq1EextS8ghTaqK4o1drctpXLVK702FW+eg/4m73PwpnKpbv85q70Cl/1517nKhxmS8UvlNS9ve1tyk3WdYA8kZEVSKBNPYA6GQX07/+7Jk5wQE22NTy0lEwIHLur1hiGgUUXlKreElweetrDTxmzWI5tAskQRKXCqDOK1BHjU+Jk00Zk1lrb5omWqdxzeLndNxiNp2NU6Rc0ZRuqlw8bRgW4ret5GHMmJihjmeqwtT2uct9zLpXsBlWjEUO+Z7qfk/f59Io3P7O+v5hIgmw4lFJv6dJVLQOwdf/ZoBgAAAAILn4KOjCw8040N/wwwNHsKqlvWfFMAUFVFCQkqWUjKew8Fm6cy7xwDnOMnbLZ6QyZ0R8mD1BJWDyaZzcR5o636URby52WyXI5UKpFYAsLrbbMq6ZlFUzy7FFzO1JCgiqyObWkJ60OX/cn9aJ7I2i/pn3E1tylsqLterRV9azO+p5L1GGrz6TW9I1W+8UmsdzLc7+eK0nC/a3393LJhMMBIAEQBjYjDgpDIGwQFcd5WNy9dr9AQC0JEBpULqLadBxWny6aY5ZfmG3/odUEPQLTX7O9XLfWcX7/C9t0S4Xe43ysRQaekTA/kpleDXprLncVPyWaNpLGFugYfy1VXlVmjo1DM9ym62ObI7Sldd8LZqNMyU8EuxzJc/UvD/34cA4gcyYTTXM4eDYOAyQAJiSjUJAwkXxTXKCEtEPGRICx6VhgetZFFEAvtPLxkLBk633p6UIw+Wkotqa2ZTL8LEO0hPL5nr648mmSkdbRHyTOxu5xy8MEIw4CMxzCBGikkYkSrzLl808d+6KbwUTzsb2HsPZhj+UEsb+m2Y/YY/GM3nGzWpP0d/7jvKIzktPU4UD7cgd1yN47bvrx4PNjP4iAFjII65owaQxAEHCKGBViL7ZWvQs0MAxUG+ScdtF6L/+7Jk8YZFFmNSy3hJcIBq2nZowsZT+ZNITbDUyjsuqUmmGlgDQNckM063YslISwOq3SQExVP04+uI/vEP1I4ZLyWtqrYKqjmxx3w04vwLK183NFJ1Pml42Vy5SexKW46rey/53Gezt9VU197t8Z5xsrXeH+Rtem+s8xy2pu+vmpz83e2ByEO094nsco5SFz19zU0AQY2tIBRGaYOnd2YRUkx6gcMAhkIkDlMAABQOiMPROMdApGp0TEbJCYOSdYdCE3iwAJvP3D1+wut9n0dp35SrTjnyhNCd2YiJdPFadhlceQRVDlfkuu0iPMWPWMef3jZQ5JUM1beG9LTinrHmOWHgEYuShbkceM2UP+1H+l1Admn+PeoNbneepNuEEaeJXhk8et9nXfYyeRU1SmrkbxsP54/aJ9vkbVpA0QKACZIILj0C5jrxJQztC0IfUyp2hQcxFhrovW17NRw7HZDulqyqWl62QGQvvCtJUEzGKT+P/gn+rP8wzSl70no5umFrvqRmVJ3FvAhmMqiqGBHI7GgMmi5YMb/L9pCVOwwlCAiCeb7HK5OSsMwCnlDdU26iD0GMLvPFu+7/5/6/QIA2MsKNMFGjQZ8CQhoHALPwsGKMjx0XSSuYIUFhEYSBryeSoUmFpJl0q+5cyhg0gqXAjJDYXK7VcJ3rqxbdM6dKNWRdVCQ7qSBnNkLlmNWPiNAUj6gyx9Qvjfosp7yk9RZ78hfH1rcch6XGqPc2NqB93qWZ3QtcO6XNn6FLUH6atXKXcDBFpjDive4hJGGmsItSdRQEAAACVeeUYaMQaWATbWzTxIFT2AIB4TCjElgaWiwY8gT/+7Jk8AwFQmbRC2xFxIIpir1hg31SmXtITbEUgiIr6NmjDxglAMzQMXlRPq0N9iwDZjfnbTRq6n5dM0UkpbWuQZetW7okjHIGpmnETkwkPM3dTZ/hvOR8mMHKNwlFOpD3xtZECpYCbDDjG5yqF6RLWQ/R9pOKZeUujKUK/lOcz/P/QHRjuFDxiYT/UgQAAAgmAxdKxYwkSNwjz0ToGATjg4EFAoHHq0kgB4jSWXaCgeF213RtQdQVO172cKp0D3yO5TQ+7l6AotUwChYkUiA1lEhyLuPjllHZxoutRAG6gcTv8LVzophAOSVo4C3FizfEPNj5gZKoOeweJuegeMH2EA4yCLd+wotSaEP3JSrIjl5dYsaHxhBYGHzlKVBhbpFyzrxHekDgAEikS5ioGPpmr0AnkAjutPGhXAgpm6pUJT/s8W3ebs57QW1t0T50M4TgnWHBto6eJSWs8iOpXkJKzzYToIotiPg9AE3jwHDV0KYXvTJ6UhWf5W345fTM/MnancGXwECskrea9yY1PMsr9zz3iSmMCwEieacUFaaX6hACC8OZQFglIOuVT9sM1sMHgowMQeQ1gJDVDFLBQ5VVCXzBOesqho5kwYwAEDCo6tSsbUEJSRcslcmdZxJ5skSqkwqA0SQB5CRPgfba1ILM0qmDsYhUSt8nW8pNw/XC2UQKK9YjFeRTb3wCb8pD6yDe9et94TtVNSP6d++lKUG6yiWO8hdfSqHqo+l6jsYf/HbUMrZvW3tX65bPT4mgWIEDK3yFkiBgAADjgsJvDYs7qE0h8LAwCMGSCTCEKZwOHQMYQbDIRic9AgCiyYZQGuKoLOb/+7Jk84ZEymTSO2YtwHrK6oplI5QUrWlCzeUpgi4laKWmDmGQShAfPV9R6KYQLDllK7jUBIayrlr3ghVHUx5dvK6lgnd4ntEg0rCqIB0DQrBR4lKIpghCWBVEjHaxGEMiduVRX184dKFIS5KU49URIg0jlV9fpNXU1CtSIwsV/n/nBAEwsjxpGmEzwZ8RRsOpAIxDw3RtColMQAEiJoCCIaRNUKmPQYOGChp2BCAI8mQypUJVEpQ7Dg1KJ/pqbZ5SS+zlLJb2OSzLUqijr1eVKX+tjBPDg2pxUqMYFzExFF1gQhQOrOCg9mMedsOeUUuR8zlnFXBRMSPPO6VekMOtA4FezzKxDIrtkQYIU8MO/j5f427+uKS/EVbzJS4y6kpeCQ3CL0R4gACASXBkqD35g7x2xpkzTEXGCoVFFAC7BgBpgAaCRRMFFMmRKfJgyNF5uFx/3HXKoFPfAVlmvaHKqtL0T0ronrQDsebCKDgeIvnYrWK0sQ7GceqHEyiTYGqxCVqGFkdUfGY2omz+f2TzuUM7rDS/OYCaNoZydPRRHM+5PjOPwzD3uwmmWTFKwBAhpMfBELmoyAfjZV9MfgcSGxCCBAIwcblBUSx7QLpDcg9HRo6ruRZMMAWPSWTgWGZOX8Yc06tDFM6z9OBGLVPNvXd1qBJIylUoUXHGprMd61Kr22WZpJZM9LSBKiAYM1mM6UZflqzJNs6vXXUYxl13I4u6Kuo/aW7NOsmjIf13sMW9r/1kPst7e55p5qcth96++e5tbCMgozy6N7vNGly67x5GcphgDQEklI0kRG4wPeC5jbNf9fDIFlspU4CoheFS6JH/+7Jk+IxFJWBQk5hC8Ierujdow7QU8XlCLmUp0i0wqWmTDuB2YpE0f3wTDjjxQidWz2XyDdSURXk3qwkzaMmidyjmKj3ZOPeO+lZjpi9qth8g28wwubXf6LOB0VDvCTERQgOPkEM6Brk7hcWFY+n2iznWiOOXP+l5H/dy7wIILJAAKACx+BEQgMDFJiM8KbqUGOVRclNxY9IURUBr2AJByUbFg4BBSkk2hIZIqdLVLy2rLAj8pAq8TcU83FVF4r8U7cp2TQOz6Q0k9S2amUknbGUIE/0nrscI3kjMdFEvEpeXOdNkwGEfTr0qgjzjG8mZs89P9yM7kQ/ed/S24sdZzUUvTiFtAuqbKnU9zK02dsYtEdaCZfHLja2yqtloddSo3Vy1yeiZxeurTryjw8C6QM3ElJVUw7axDqRBM88CoIkw2XM1Xqy5c77NCxjrZ3yfT6GitSyfh/nNJ6NbiT7z0FFJi3QzfUrHBRBYYIBEcPIIQY8vjPCMKEJdDkLhUi+Tdok3JiU5IxFo1cnGo5ksouEEC8zH6I6eUjXMIs2pke2AFebC+8TrFii8LF2rXOMAAPH3LdyaKAOABmBjCDSoIjiYdjIkJXmJSQIUBqh6MOGDEy5JGcmTQDgcWWePHKDqrM1YU1xE5/ZLYvgHGgGFQ6xCLO5JYXZakk+8XfEQk5PUdYUmwDiKB6Xy4a1XIfSEUlqpspV2eNzK+4eIYZ8YJbS85eRRL9huuoM76jmrmIZ1Jw6sJ/xQQ+zalKE8U3Hrax/NqoU9oyoXBhdwPnSPOhcg8IxqNR9QQuzfrRAAIAEsjZSeKqxb4tc3iQ3qxWA3Xh7/+7Jk8IwE4mBSk2ZeQohraqpgZroU0YtGTmUlye0vqrWBGviXrGU2sTur8fh6WwblXxxgKK8e7OUQws+S08jlQzzjCQznOFKYQMbQiKJUUQ9ThAtnK+xzwltq7pUuj5J2Tq6YdH3Rr06FUqf59hmuiSqqI18uplfJAGcswkpWI70k3dzg1MqH8cpAAuimuA4rECJRPW+DMgNEUKBBm4B2j0g4o2YRMEZBL1ASlnVXCUC/mTJ2BkIhgSrG2nqFw4EdeXPLMRJyzC3KjzKlGGJUYlpwOATDYCW5rxfBcSI44RI53RRbVkybNibhaNJvcZb3pNH+tNLPHx6a4phNaNxiw1BU1Lc2Ua6r6uP6z3P7sf4xrzu31RprMNVlVs/EM+uV3eAZvb8XkUAiRWcEOZRuGmwcUWuxVHEeFK1KFAAiup7GkuvklOpJING6lWTfgpw4SoNScuR1WuMUtufNo7Oqw6x0myWXDauMVSXSYsaIACxo0caiQVEsa03b2vOqbe6cjm3qOo/1G3st3DpfsvqtxN3w93kzfNzyOFriOeYJqa/EhWpMRG403vNK1QKvClFIAmCjyaKDpiVhGLU4fHippwViwsTmC4MM3BsxwQy4tNgSXFNEIySglHhxEvgYcSQkRUGUHlBAuDBgRSxUEMMiacxzUTY7lLpuW2O23tZMp8+X1oTCvOtPhFE2oVPl8mJotLpzR6ArnR5q4yLEtq474XL/R09T/hxX8PFS6cM9tus9NTp/KJUXtnx9+XrW0DTEymtfLPXpi/dl+2zlu6kbUc2Wf2/nWWrK1atB7qGknLRupCk7S5QaQaIKhDSDtxMs9bz/+7Jk9IxE6FhQi3hJ8omrujJpBr4WyXM8LmmJweis6R2TDtE0NuTaLKSOXWrEXSCDXlaGhRByHWFr2U1mrlHBbCb8XndXG66ld6XzcUrADKRH7PbWmbWcRjLCMXSbML80rmjpm7IacbQkjZx5mz5fl/5/zT5l7lkezXzO+qQu+6L5Idy1VZ5kMzUKz/qyyo+V/QIAACTScmHAMBLowcGTtxzBwpaUEIwFo/hgiRDicKMKTrCVA55sbmuq3RlTgtCi7MQGFl5FETI9Y5zx1ViMUCK9RH9SbEa1pEpLapAhirFSGg4YsKKee52SOGxBIj13RVx9wQKVQsHqVVCWtC23ISyQYNI3celDmqMlNoav7kmqxlaDNmmuPj5GPCgpRsW66i41EWWQjOz4Aij6bWTmAdps7eYSPrtTYAJKAhh8X4DCUzQVROBoUFAt1iQhRBDAgSGuMgc9WxKhiQGA5fKoKdljkJoZFHbkfmAxLaLGhSWWZkushYHTj0tVZlautCCdZzk2vOM8UvM4T0ACGcF6sHRXFW1R0iIJN30MOgcaCnTlY3P7POw+l5F8/heped6aspgwXjlUZ0AAEFQREc0QFzBKKNXqA6WeAQBBIYGAAIAVY6GB10BFhYQYYYHnzCiom3dFR+wABMABUXaExURAkBQOAu1bf6VRuA2wtQtTOnkMIvHmiU4ib48KnckKo9gOFP3JqfoGn9EZ3zxPSghLTxAzfkSx6V7/UrjGDs8EWecb3wzeiI2fGd+S0t2H3xz/VWfz2R60HZsWcuNfp797sT/IG8ybH7W5k4NJENTGNSAUClMI5IKhiRMiHG9DIsziKqP/+7Jk8ITEvV5S02lEwI6rWeFtI7aVBXs+bmknwhGs6I2mDmHitKhIBJJ5ILqtKzr3Egd0ELUgKNDtI4usocFi6sBoEKF15R5B5fn7VpDL9r67mq/5lp/8uvrnld3OQ+wGxERyFD4RmCel5vtCWKZGU1xRl6GWdzjl5Znq2S8Lf83kO/tJY6CBRgwYgFG9SKat/Mvft24AkAJ0YEJnQLmAh0a5GZzg5g49FYSR+MIc3VgMGBiChNQYYIB0MVggXAVrFjggpvIouZCcwAHENmp4YlTzulEXyycDaOeAnHCMJRFEU4sPBcPUD5s4Jjw7uHEJdhFKiBQP7yxotsGy7gWH3tV8710YZmk140fflNev+Ho/gVOxrd4yF1aaWDExOK9vfqyrKtONur2OMh6FnFmJnPLlT+Ln3TQqAANmBPZoYyZb8mJohjxKBgxbgqTFBCEFA86aCZ/nK5Ch5rKNRHDwMQnWXLgVPaLN6j29hZbHPrKGmwznuALmUpwaR2/fwsjEZiJswM9Fl1cq5mqQz6qLd5f7tmWbnrJvH2ny5yfnb+v2e/3aOaDbVcy1B+18D0jlqAteQZF7p9xgxEZlg3r/e7/+gAEAp0wQRTSARGSQaZVp5eRBhOQfEQPAREFbhtOPNgE7HSpGsDlbT2sgQe1oeUDyFYZKBEEvuiAPBGL0sBSN12JtlnPMB9fIrIw8a0cORtsWMYwdWgUEDEF2HJYOnrb0+Tj9qDBXu6KHRsGulA38Tl7UJ1faFW8ZbyoKw2al4oSoDHWCrXgZreUMMebF+UkF3dJeSTf6PZL5kumbar4zFIsPRrATXlTc669uvyntspv/+7Jk7owFF1vQG5lB8IqnqeJvJk5WOYs8bmknwdKrqamUii2uahDlAEiwSXhmsHBoquABDFyL1QBpUpWXVXp1KqMmQppWytWau9WcsNAqsvn4BA2ICjZRDazg3D5mRu5yz+aFqqWMfMvHN1cqUM7CGehNZ9FfsqsoaZkRt2KrtUzGdCd8j6+ejvu/dt0Vde+EHUACfqMYnr6/9wCSUpi2hoYQlrDSpZMxVMyWBCisGRIUHmaExGEapulQWDQABoQBJ7LMBS5E+1xGBR5DFkyMLsWGxALMWBdyJGdsdSJBuesIKqIPA+b7y4hvXnKTJFFdJjDcomCRq26Aq9BkgjSU2MSTRVqsK7wehyvg/9Dfmehllc8jSF2Kqq7Jen9EKZ+417ypVG26lcH0lGBXpnIHYMxzFDTychZdoiILiq+eRR1uKXIF/Hf0/ggAgAATQtAmPhpt+WY4ummH6fiiY8KGFhKJQ8+akoHdYGBRA1tVxAGCmVHgoLICwbCGkqUJVIn3bVWQKM0+u25ygil9SMrqWqFIIYAuJoCOuQysQgBQqfW3R7YkohtxbslGds/PE6f5KZfP0Ooh8TlM+HE+QneXz5/r5nkffy6FMEBm7kIOksPFJ8MXDUF+gEAhKBUFmbASBAAaRNRv2OGCwUNDMAggKBG2WWcL9g4wvsNzIevwQiDUjBQAEJGN+q1paij9l+Xdvz0ZhMPPXnahANzkNFUGqiogxKJJVoeNMc0hSowyQUrKXoseh4tO/fBmUCb3to5l5Zn9z9K/fcsuk05+e/CpPG3oW/Kabdl7ye7/Bye9bIUnO9UYuGQxPp0ggpC4XayCKNj/+7Jk7AxFcWDPm5lJco8LSedvI05VUZ1AbmUnwjGu6AmmDmgW3wID1KKMbnzfVQ97D0pgiguQ1wSRNg/N1DNMyQuSbKhQHCxImRDjDkDRBSUGrCoFDD6oklAEuFTsBnGyKrCYARVEVyqER6mxDUWW0BKGO/f3T/W6zMTdq98Objb5x26xMc/iOF92Ok7f4AITZJMREvTzUzkKIkQyIxB5JPv0H27mlOnFMvL3YnQnKgb5OcotHd0LsosHzgzJVgcCwgEkkQXVqhClEE05gU/ygoBFQKIxi6ysA2Zpi+3SRGtuhK5O6bj42ZRKqV5KP8r0CwXKbebJTygiVZ2jOZyP37kddzqLFpPXYEMH5aez5TUFlAQZhB7DvKZB0zVT8zi37ae/3vxeG9BvTXAO1ZIl+mkQn6XI33ojY2Zt+pAIXb1cPiWS5JdlzouKsbGB8dXRhjLcgSZrN8jH1ZvXTfvB6LLhPtxh7ziTW/Sn3PLYBxQGaTil5BlW89xE+hVLzFIhCd1kI4s1Zt19LCtRkL0L0lrTeR3Ohj8siX/tJeAHiklNBp9mWA2WLmS7Taqyqra4qamgkD9ZodKYotjxAo+rDsgkvPgXYTGWXG6wul1pmVDNWmlGJx+BLMvLImH3aQb0WNJTeWDhSv9YWLUwzJ34lDosRHa9ZpzQfvlMIgN6JimSSoy8uUyhmC1Xq9ZfNXc3vZuxUsuICqYCHAQeiTEh8M7jKPoyIBGgILBQBEjGgYOKUEzF0+Sg4HgyJJPNec5RZISFt+/bR39e1/KtC/kOvpAbz1ZiJxltdk7SQA1sng2pDRY26Di7dSHRyZqM3cobfPX/+7Jk2YAFd2dT00l9+KdMymphDLpUXXlEzaTXAf+uaMmXlagMdRAFbdJGNkutgQZcVOwl4PT8ajvY5vwis81pSGXyp+OhO9Fd/NhmtetXrxu5bNZshnx23vSVUTAVWfyFyYnPOJWPaHuT6QAhmsULNTM9oDeCSjIhkMVzO2twtkERNye8dCrLsKEZ4jU5+NLAiUUwsvgosSh+sE2X2dWPTcLalDqK5BzFVzuRyKB6CwwE0/dRMPPvLRzqhy25axl5z8TdrqVUVdZGQyKiKW7vRmeZ1qyNKUdUzNU7KaHhyAWKvKWMHFTVDtQCEABACwQNABcwUgzWrRNR7czUFQCAhIrjoAM/CQRiloQc2IaDEDMEVyB0Yt6tQGAhclnBMm0FaKDaQLKb0MvhK4HjL3U9ao81qrdltmclm5xDIzbIfaL5pgSoqWOTsMCu4zK5vgCaJ0kZNlnS/tGijlqf/hV+LLrSTVJTPrSGOSdiwqQP8mo4yuzLMWUq4K5IlHmvJfcWahjM6asqJm+H0StVJuFFQY3cNTa9VLxQT1k3lQIQCSC3HGkoOTUpCJHhQ5EKhZsvqURRqyeqlz6taeus2CMwM3typlbmIajtvLdM5tJzlb1gG8xPKD3cbKcUvj+ZmSTAdaJR1aZUaYw6bogEat2bo5k0brVjNMCmNc2x91ea9jmedmqrYRWTtO7XXDABljiWLvUFneLBJJFKFsCh9MeYTP4c6z+DCkoABQTEI6PPpEZrPf8veLI5bKWqOKFt6yZDs7yzneZgvtfr3/VUE5DhrUJFtJLEiPYsjr6ZWY7B6E0mUF+BpBgwGtyKTMqXXM0y57H/+7JkxIQFmF7PQ5lKcHlrun1hArYT2YVCbaTVAc+uaaWHlTxXsmlDNfd70NjHRby0v7Q3S9ioIEmY6NiqnGJEsaojCiFP5Z8LQZtkxb4pPD5Nwpzhz5wPEUAfPqj8IkVY7o+CKMsBCAP9IGWFhYYUyPsG6sxihbuBH8ZTGEqoXQrXAqDxRiP6IiTNycOh98l+Rtn2WLeIMVGSxIh0HFH3s7IaNx9pUAUWuYYr3Q9CMdWVWlsMVKkv9U9iCyeXrq9TuilvreqLzVoyFUu9pmeUcSUWU5KGiplTKwCkSlAIMghMmBj+YnJ519dmEgiGCAwMDgSSwCHQglIohgAYE0mDKu8hyX1JUzBAVxKBlLAk3VQNM3VlsLbtYkW2iy55eLh/FTEcSLq3ILiU5OCDNUgZQQGy8oT0yvUA8+SaGO2jIpWm+6lef4jz2gz7kfcdS/r5QOrr/3f80N1GSfSl401GHLX8n7jGO7UvuKqRyqId4h6uoiImZ/YlvNPhOS3pqAFwBKTsjbb6BapR0AsVpzkoklwYZaVF4qyWtGQAWB3EqCpHkS5xbPQqNs3kj2msApD27CHZ3M1LS3mYpjCjdSqi72rtTL9maw5ZW+TazoKle9eqrZNSvvb9S6l1Q/NZnHGRwhoF8k7lP2Sk2nMOCIiLhhw3gUiHBiwAjGNBwmBZgoMmUwil8xJHBMoSICa+T0K7b5Mcu87yzICZ+p3GJvsyheFyAefYeWdFJyrrIexb0j3VM21NUXpZDc8XrdVIhXnpjMTCRycCBzrtbMgxGFBB1I5msRsOitUfAxzRpn0Pzp7WE6j0PLZiRFkdFnV9kzSHHDj/+7JkzIwFJl7Pm5hK0GmrOq1hImtSTXFCbiS1QZ8XaNmnoaTPEce6y6TWWAhtKDkBUxh0LoQWBChFipEEKgSTUq4gqGftkzbAWVEIMcyPYaQoraubKGvoawTy6u4r83FgpF8f9iLRo9UzHFqS05qnVVjsx42vjakmePHI8lXdeHZ4tcw88imZf65Vtu8s+ljhU6IaAEweJIy0AAxuWMwXTA6vTAxdDIwuAMwKJExKB417AsByCaaTH1gzgPzEHkITAFg8MtYwiY3RVR8awjIksqQlSyoYCijSTlFCQgmCWjRTOTTw+F4/Tzim4ZDpxuyIOHmpcGB3rTbLI1p1xnX2eaDK1n+6owlW4OpS/Hy5Qts+8PGrO8atXty5heaPabUrHvF3y1/uPrMW9/DpN831mtWffzn61/rxN0+N58ls/GZMeDWTX3Dj5fss3feR4Wcswmwhvc8DoA24025yU5iKZPHwBrNDg/FOeQqWwEoKhFQu8r+kbEyUS15fVoTBWAF/zoSwiS6pO44X6EKGqrvUPPtWXT4qfUIqpyh6ZFn+XmSFKfmiyVOoitQdPhl9/BPDq3W/yftf6XkV4fz28zL6XfyUEXeBXULAzrPWAlTAAWDFAFjFRFwKLZ1szpjuGQsDhgYGhgoQRiiGwPamJBBzsxAYJhpotSVSe8aAChE0oBDdC1IxOwVIuyyWUOnWWawZl1FO2gJJ2RHS/gRim4oELXKCxP6JCRpKZcUa2bhLxayG23E6EdfBdKfSge28vPJFLpIr/i7+cmP880zqilxNsxslj6UNt+Eq+rQ/WuslDfUJYl3X0/d3CFROE7bJBFDVVCP/+7Jk744GEFpMC7p6VHXq2mphg3sV6Yk2bukpgbytKamGCbRJPyfyXprxl4CEgtRxt3qKmBa7jo4vvDShK6XLcV7HvL9OwzUAY9GgP2CLRlBbgKQNJmgdnCiHqXZelPuvOVxu1O3uGKlCchTkAAK9SVYMPOM+ym6THaivcim53PKXXVQSf0bf+xGVnV9v0PsU+Z6DiUxkWD0smqoAAHMLCMMNAWMQkhMgDnNKY0HBiBoAhgnGCRQGVwxHUaYxoYckkbsQs8nYrsaSTFMVQTNWyzdt07iq6o0y+H2ntiYKzldj0uQaGaofTPh9occH8DFxzV8voXjSLSuT1x2H0FV6dZCvdN9WyhlxqM4tC+wpQ7UseH77Dh37C88f/rO3+/5Tuj6jM+sYL96c5eaTs6ut97UrfbXv8FL/XYm/6aWnvbuon9n6Y2ugqvIzd5xyl8m0eRNzk9X5HAAAKIhlp8ZBM4k6IDMAFTEhoOQIM7h9oCCVPGqwVjsHvVAzZnz+hk/Ldm1U5NSlT0P0NZ+xyDsCHn091dxEOhdXySM8gDnQjkLZbod0rItdlck7fOjESdCeSejXkz2//Tfo5P9K/JEhwmYUjv3JBI0pAWii5jYy0GAxhUSbkGmutyneRCsCC8wKFBqAhnY0UREjL4fIhQowrl1mPlvQMumUx9gCZIWBcm1SK9YNK2fMjcFuLwF9S0SlsjBRabxQQjQkWpoaYqts4IWwGEbBTN1XTav200rKjpPtzVQLvuyztd692MtDgOEM3nLsesqVyKLr7wc+AHreJp9Ao8sGmWpyjIxFLyajjcphgl1/43EIEjERgqN0063dIuT/+7Bk64yF3l/NE7liYnGLOkpkxbJmPa88bfMig9izqM2X4233mGK4znguOyZhk2IQR4F+sF4WFUVJtLWw0/KZaGgwGGSmAi4Bdt2rjMEwFmW4GUsX27QWEUQtNlQTpXw8YYcKboqoZQhbyBWn0CG6aCYhrSF0YISIACRnBMqiaAgACJMQ6YJZkkhx8rY0BhHbkEbfSVzFeH3HcCcbmg+zuR54//7ztqBDlDn2lIgICoWHNQehAALAooyUsOHBwWjkp9RQSJgFXbLI1EmyWXs+5LXYf+UOpMTlaG1wuJIpIgASvV28aqgBRScZqlolewhzYZT0RXcdnrblrx+PFKecNLzoluMW58CSBGFgnmjmWYMJcGQwLB5v3a4YT/PPDLAZXI/G9YcrLkcBSl3HkWwljyphExiuZ4C2Rz0FwRlV2g1YLgfjCo2E44UqnT62eigLYyqiYv8djUauRjHEdqBwhry/uOwWVLvJuEIRkNULaxDLeEfHG7zBzW2iU6Vhas0nR/hRf913bf+AH/WgsR0WSTjv3nwa5La0Ydfmq0sqP5SIqgACDCAQQm7uHEQksCBpnEhheTPFalFEtw4SgTd11WUKlgOSp6tXizztYEh9plGbZgX7aY5a0kQpzSEUvMxQoqWTLmdIfONB5zNrIEF9ks/DUum4ct29NFZ681laCt7Os3wcZdEo1NP2l5cghYuvuQ+vOlmXxaU2KDo3FGx0f08OPRWqthXRByZKO4hEFgY2SjLmoqRuhf9TUiHkAWEGBIdj7LwgJYraLEbOlemGz9tx4Vr7zPsgUrc879rVWvXQ7mKKJFI6PwxERhI2oiv00v/7smRngAgNZ9NrScxSvc0al2WPrhOVa1GtMS8Bw66sPYMWGJK5WIgAMg00QEWn8UyOMl+ISsA6wkC31IQHkQ1M27VHheC9Br7KKQxybhqGLc48sglwaNgABFu4GRGMmJQJatabk2zwzSkpXB12gi0i5lao5/nbN78qWv/2gtPtPfOazzFazi79qtj3t2dnq99hKE3mo7bnHKpheNA5o9ott9J6VWKkessMOHZ866Q5afYTIb0B0VujXrANqBPOCWTXaFQzVEKFOnhcxQ6lB4uvMDpBHRCL4S2BVnMETKNU7gH2ZCNVRdDrgoaaKYcEioBcAV6aM07zrXV5C+pac70NW0An0NVC1eAo5oeneq9lg5kzHuAIIYipGAAADPdEOSHpjihK3aiPGkK18rHLjI9RpaSr2XQMz8ZxEwG5SRutD2bI3mY1bq5ftpLO+8tApFbIR7Z1B6SnnRM7eoyOxeEvaLZVcE5ioEow+loYyQC2LKVHqgoZtBJd1rB5j8ifltRxYlKsatCFJD9vSaMQuMI/zRvmzFFqeK9eE4dGZ+bK52yStJSDlwuTuWAKAVUam+okCHNodE/yaKMLpL0HFMBgfgdZWRHRr1+Hk4ou+S4ovNwPPwJuEWKcg7McOa4DFM1D90BLdyHRol3WjC7ShYg9rTJw+bM9VWtkf1JLXqbjX5GOpqZFoa6ytYiUR90TMm6ts+qbFDzqJB8qObQWal1/IxEnUtAADgTEmLBEJM0mM9MXGx5BC9IsDHhimLNkO67nJky+41JptnmnxEQMiasQieKRA21Bd8JdGCeFMUhWBhP3088Vj/X3VwEBOHTSnd2Ebf/7smQogQUiXlLLekhwdyu63WCjrhN9d0ctsS/Jz6zqvYSJ+NA0e/D6bMUMz06TdVnADRei6H9klZtMPgZ7HNUsFgHYpCazohTi1nysqVYRSVHTampqt4yhbYZRRZ6oJSwYDZD08ctVAL7RGiL3GkoUjBVDFlKagxtd9ttmSSmImqtDCNyiVVKNRdEwoRLlKVdOCxFgkng112gwH83JrMvocJjOsgBXco0yGZEApgiLFEGqKiuztRnkEhMAX7foX3w6+W/qKOmq1KmiLUybs+xMz575H4FDlO9DAJXtV4Anj5bgDNAEYq0LcZ1HYvHgECL+B3gMGFRUAw5ZMlSVFX6RcTQLZEQTDWlhUmOVV9+2ShNAu8XV5fDda1ouJrbb3rtJK7GUoIRFYy297pYJ3Lbu2XayttULiNeLGW6bSFfySGF0019tYxqWx6aiMe2DMdra9xE0WltbuAYldSSWuCFfEyhChpFre8kh4FlrxaZfNZIXUsSbFI0q6LRHHChEi2DhPsVanTVDMv6AwU4VUFvrW0CixRXpq8Wiie22QS3B4KahMZJlkDV1IyCARMGVLv0mHxSyocLgU010mpZNLcJqp8XE23J/nTtzT60YLOFnx979vJR4zwYNqHdUUS9XPUzU9asEFI1a6P2zy99DZy69VTddWXRZAo2YomGpVSpgT134x0aBAibYOmbLwoB3Qg7LDIRTVG1SI4RFGYkaqa43mZyvJO+kjkAwjd6588tMCrFb0JG7lePZtaDJbVM7y6Kdq7u6zBy03vsD8d6fFWWz5/rFdCyZy7lIIO5qCnIcndrsszNoTaXDnfTBOSTiX6t16P/7smQ6CAUTXk+LeGFgass6emECflH9hUDtMQ8J7q2otZYNsZ1mrzKz4C1a1F7qKBOaTzTk6t2J22tHF1zzn2umr5fNGpfaXv4ng+bqTsOrbdMCdXHJXCCWKtKEjzBpZfCq7ihjGV6tAdVfs87y/68lFg/G296A+IY/QbAqzJH5UDVljrZLWav4moS6x5gjs6y9kqPlrM+701VPLuj5n+i+7io7JV0ZClaZFmDUo5u2pdDPcrfkcVUKKdLR7SCigSBB84WuS2PMAP/HSLagCAb7ssHg6DTAU9h4XL5hYEmUDcERxRFc8VBmecyuhOiW/V14/iqn3/c/iUH6CCEiYhCORJ2IqFMtwUs8OZQTiJ8tzsIwuueTUzZsnvd0h33C1YvNYNuZJuaQe9+bPxF8dQbN9f/Hwd6kxe40ZhxuYIAmkYhqxNHH27m9Mbwf6QAwqUEHUSSoIFBpw4EDPXT3ZCPEIVpStSVahkgHHTRo0Ejcgwi4+dYRwJjESHJmrmV2bsUyzbtVUxHzSHeqrTd+Z0yxmMj/PL+U7Hq+WNZ0m7VKSr5+e7LyiEEscs+OpEvOQ6Sgr0odgPpEXVXPsJsSVUBFUCUUMcJf/z0DDMiGYG8BRQ6MPEsOFSWcPBBQUsCJCx4kwuPBcaXil8hVlRZhLVl1ChAJg9GAjQ+vPjsq2vS68W7RxOWR8nN6h6figN2HSJDOxER8DHIvIbyw4NHKCE3iyVwNFOTbuS4HyTYt5TmzBV1vXmiBerdDDznkaZ8vVxNVtSf1xfwYM+x4tXobh+MH9sKDhgpHjWK+q4oZfk4EAAVOASPZ0CD2BuzhuF5jQRgqwf/7smRVCASvYs+zTEQyc4UZ+WcJGhRNeTgtpXVZoyzpKYQKOImZl7ipxRhxU8ZY2ENmDE5i6aOA9mUYJIpZJTfR1bE4YWJfBlBXueVVr75f6K0Knoi2roYM2easP1vJrnSZ2fhNxNZNBK0QqOwk8KPPPaOYgFBOXA8TAkLHQfmFqd1dQAikCYaOCqUbAMHnr4QIlBiYOHkQACkNBZP4DBxbEWIJmDywAtxvt+maVAKQyOC3oU3kclfweRhQA58ltg1HUkOwthSOqAQfqJAWdc1rl8EVLXf5BDPE+eiWHUGcrsKjNXJNMed6WogutqUn09bo1PUUyNh2Li4ceeeyDDSumI8mzZ5W6pj7Z3MHGx4/vmGybZMMXuMCFNpvOI6q0PRstHtemU6+EtuxJy0gAE6D0ihUYagqg8AsZQtvmvMaZs1+y9MonZfSGNA0O5bodCTXl+QbMdxdcnT/fHF/DECIG7TGOsaktRZXApF7wl0kz8kujdEqjZ20fV7UG9dkfZdHlXRD53P2xRGnEmI+1QACBADIAADkwYWDAkwNCMToDgOARIoUqIEPWiwVBvAMKQVRYaEwVhjzyRUSqW4ZZ6zxynktzpCSkZCLnstEymREA4ymdYyigzHzptilEMujJ7xM2tvrfyxdpRMRK5RjM6qpHdLu/moZ9UXyrUlUE7+IoehgLMTXnKrDC7HLocrFFsxTd5eb8lOFelsTwgShhM+E7d/L1mD5v+bmFzaUTYi23m2+2zROgBvECRnUX5jTesTLmOOpJYVULhuVGr9O1DOHKcVsF0AOiuOTWNG9Ib3pVsGUORr++s75bp7LP0mL0vV52v/7smRyAAT5XE7jeElwamu6rWEijRW1m0OtJZPKI6+qNYeY4YZ7SUdAnp6zNXkX7uvW/8nJ/Ru/9fXfq/V/moLc9jNMLRA5Tr6wBCBQkkiCAIY5uXeEJg0R0NvUngg5BBMUTYbo02IJxrLY4qkuDV5lkuo5c7gLIkdzNoUJtuUmCqOqEgXcde/9FuZBuTpyNN3pAWZAcVo98czoCSE1y89KBReeQIQ+9Sc/BJic5+v+236QMfii9bXrlHDgmnIX4HL7/5iRxzmvynN50t01umfSkS/KNkt+raNSXx7AQFaJeahI9pXHtc4SzdZjhIfr1FDkzB8Ta4QyPJXza3K2lV7F4EWS/yq1IXPGEk8DpMQyjaICWj2AvtaON9JdUFOcHQbaQmU/6+M/35E9t+k9faVkRnFhacRrp6YMFkzg1re9v/5zDSab3cvD34Rr5meyhmXXZm9S73vbGzfl7z1/7P7vvfkM5ZNO4u2w8n8sEAGjAIAKknHZMmYqiZ2I/j+noyMLEUUiTSFopMdwlUIjFlTgVryQgsOKscajSgqVQZGRNIp7jRPM+2xU9ym2dPA8aW7PGpryCk3QYvw2GVK7xdvWfaoKgw3BLFkHRljiEVDYF5zkmP9TRdsmjdUslc1ksyDpT+3LGvISo1CVJpuGI1EQtGJl822sQmnUm0w+B6oOKKx1MHsRrMPT+tQQLogZe1aAUz5fWowXYY4y1qP6pWAHK8VKoAQAhUCr0BQs0mA40hSrTpZZfVja6yNlxPXAUWuqz9eg1YFDqazFDFo4fUpLvFkGUUhB40UeUaOss9LuTyhCeZhkeLEjqCgBdUkcIp95Iv/7skR5gQT7X1P7DErSlYwabWGIaA+tZ1WsMK2J/i0qNYYhoAQgjfNlO0FDLhlerYZLnDcosSWpL1Y04o+BwesmdDDV7ohkuEobMsg0w+LUatKhlByKCMVWC0/Q857EEhaodxhjK+jW62bWpAJhB4KIwAJMm+UdWixJ/W7NTdpegxfKREcLAgF/eTyWz1jVTqXlzswuZdt9u+PP/3rsq8t2cp5hIgOiUVn6BYsHnVoxCOcczP1KeR7IrplK+7jBUa0bSJjkIQfP5znI7mqiMaJ1YiDHLymZDowZFQEQStk3hG/XWBZHU3ZEgAUFgoboIlBAhUvmUvWUribdrGMGtAf8LMuYHhXVWaQr7TlzaWi7rJq0xHOYYzs2Hw39aqikSzhRgRFO82o0lRaBa/kZvbjtrn5EE7aG+WHeSX/cSZ1rpcpF3K33bxUkvXtM0zVEVJhDMW83KNQ0kTIPOQxzgwZ0oF3kMNpidSAJ1pHWUDYkfjs7c+NEgVhC4eTfdK5/E1bvFsQifa+zMpo5KZ8SC3A+8+eEhdN/ezIXFP4g7HOmD077vYmopsnROYCxjScj3ZgR1yivxW62JEXxa/xYRqvWt1WKGC1pMTJx9Oy1oddy5Q7qmux7x2VOs9lD4HYw87EFLHzwS5oCs2OWOKWUznzb4WQDeiRVSgAh2BAGssrC66SBmYwOyoWOg7YTThh+8sQBhhFn0zSaX7sZOXT1TzzGL9PE2+v/vaZpnk1x3Zt/Z/pILf3uBFmRZZWOTe06qeBBL6tKzl5L60rJeXKBoWT3gUbtn0I6z/QfcJer+y9gDAIIBQGrG5sIABSwwcRMDlkfEv/7smSIABR8XlJjLERibMraXGDDflMNeT9t4SVBeBFpNYegqUwCkQEIjDxnikSWgkOXWVsSCeXYyKQmkQCptBrKKfiiu4KVt7Umnm5RVpfJIpf+d+JmPA0uR9NAjrxLN6lFXpSXvwXHPFr4nhOxHWY5aq2+xKpqzLHsgUy/JbxIq9xMVVW302yaVqxzZNFtVgqes6o/pxalHRU1alfZCJf+ps+TIbFn2VABQpsLJlPUrImSrMSKxaUgZb4r2ZUH6jTemofTthZkHqMkZHkGAvEMu9L+1Jn0s3HRX9R0rdu4YK8JPDTGeW76/fzaGGd/+b5/HNuvulL8vS7mz9/770eY6lld0I7SFBgIEPgcHGHoRjqWINcHDDHgoUQQDyuASFZa6ya0C7Ucd+UNzYi3aWUrPgADhiH1syCSPbIJsQVeZbzEX3EK1wTUy0ybL9M2FG622Hz8h+G8wttL1WZGLrXXnyzL8VmXjVR92RIZQnmKAKjPbmX4xROi8xPEjW+ZLbqIj+db3JLcje4lsZT/XMvgFZ09Jqt1KebTeyP0GwRDsyEtkiRJiiiRgoWF4lj1VEV1KWpgoHNNiiikrW7YqOOGGx44wtbtCc6RTY+b9DuvujOjLgLaNVWtMZ6P4M6PZS0au1PUiLVotAzvKabfbmV9HL2/KWtm/Ow4xEEw1IwhAAkBYTYZ81UeMlTBoXMW2hIYaeFBxowk6jxYk84ojCRYEa/ZQ6JNTr0KXK3McuOmodHmEn6wQMom1WmIMjA4TJlhQ6JG0h9dLOrW/knk5lKarWbyAhPykJb9SU2FJje9A/2sIn4umnurN1d4U/kxziQHrf/7smS2AQSxXs6reElgYYsqn2RieRNNaTmNpNPBgB7o9YMWGGVfeTJZW/vG+i8n1D+erSu3ckQfbp1+qWxQI3c48VLHnMXUFLIdLDDigdpUaYg6ZJwL9MJAWSB3vbHSxFxGHRt0mTPPamHEsPzIqW5ooPewnQ4XrUeVum0jr0TZ/VdGYHO72d2GovR2bucQVTN+a3fs6vqcQQNEVEAuhzmDnX//qeKg9WsVAEABADSgEY8AAojMJQjIzY4m7BxKHExgYSOAY0cjxCsC1dcCOLoSVWRj+oqsVpS3YDdmpo5hUf0xLil7G7nrpVHYuxr4G2JUpyxy1nIoEpxffeRyNS13J+DeOhDVx0GOzLzm5Ztr/XZPIvWj3eg4dXIvVobciUw7H1WNPGTi9tzK1qbU1bcQ/dX5wtFzSxoOOkaAWOTVrvnGgD5upjegQgjSSQAGmQFzCFopcP3B8DM4fGH0CS7SeD8CbkwQ8UT0zxJA8W3OmBWNYOmbKELg0BUtpJR7TueinUram6g85X68onRuT7ZW0XO0t9uh1fb/Np1/3b794J6icPJEb+e6QADAAAwkFTGIHMclI0umDmUWGhOnkCASKikBDoDAcdBhfIZGQQE1q3EBSJdMzdCOFP64C2B/GMiWo0ktpwVMGTWmPMCEo1I7X1QrIfapm/1t5pGVRYvItqHR+ska/ZsxOp16NhFFNu1ayfeEi4by/n10DZLwswiasnYO+vK8I92BQGB9NxPHYsJH+A6bfuS8YIUO2o3HLlLp1OVE45PCpYcjVN+agFtukKFP1gcWF3GFtch6ndIQIgKqCNw0YTC3PptOtICB35SSTP/7smTkgITzXc5jbETiYOrp6mGCWha1bzEOPTOBxCrm4ZQKcNS+26LZod48UD22aOXEZNK5UaBkOV2MUfSvdOKIbyN75Gm/z7t7pUq8elVsy2aEc9DB99WHl1c8wt6QrVBLg20WCFgI8OctCLhyvYTnMZ7PfbVeqUZGVhM1BYxdPTEYWHiUYVHRrcinP16pmLChhYIy55QA2HC6lUJixoYeb6aUrJj+0lCICkqLD3nWk7LHWVdUOEdw9CQse8RYfXwDkCdS/QS2sE4iUesrJNYFtr6djwN6ND6WZlRSLSaZIbxDBkWo4R8OjrOCc/2rT2S8TVWtHDVuWnR9kly9+oT/fEgOlXMJKYhF3T6VozPsi0+7H448KV4aPR2rCugRlxeR10RfMavX8nxMn6R+rBNh/0J755USfifiX/2AIBBABIiMaKMajAWg7aBElGAdDyAtc467U4RpfQ6OXQvj4b6Mqmk4vsiv3BdZ7Oyvs73UCHU1zTgU8mM8RCKiXqD54NS6FPDt+JBH4YbkP6szvnlnEBmgcfocEeFIuI81M8znSViylQz509VPgSXTKwX7+WpH0RcEyEQAVjerNCQzOAQaB9g0jegcAK0AwUhgkEqiFw7kO6nOgLi0oelg72s2lk6SoUhQKATSJEAs2pk5kDABDBhIBItzRvuRAqJ9XeUYsjIwoSEgMOJ6yGdc2oyXb2dIP/SBiGFMh1R83qorhtp43sUQYzF0eoCcHCQoSImM0gOtrlC2UwdH5RbNwq+tBWdeE+jRvZjZddHy6OEsTEAGJvFYTdqAoY81MyaOWGSB8QO/62EnN5do5UkaiYIVmlaQa//7smT5AAXbXkuDmmFwd2vZqGnjWhYJgz8s6SPCcK/qdYSh/JVLH5Ye6SP633/CBsvc4uACgMsAIOAoSHYKOWCgpA2iMhuZG8lFaNQUMvjKQoYz3Oc4LoyMVy/oVk75gHJoFGQQFCBAy29cKQZoNP/iHLFx9vF6Fg3tqt305yEdLoQExwfmoQKU7jFRFPahp/NpW9X+L3wg6yB1wQKJXZgwsTg0AUFEYwt2LPdD7YM5NaoDFSoEOIADhDF52RpnWhjhQ8oCxQwQIAgX4CHhfcwQRVFf4jFr3OJgGAB8QL9tG+j7wz2LgQwucSMxxD8bjIL2rHNjVKkjj/LDFezR3KJs1ZLQlM+eRF8sS2yBRCS9rPFhlZyo2Rw7jSmXsCqdk+XVocuU0vU5yz1sZJVM/dGItN7OMCr5qU6epyTbqc9+QQWnmwn6Ec25zhaKbsqQgQiNlKIY9ptMrwiPhBZzVn93XsBAQ+5RJD88SDI4NhccQBxgObQOAShaIHOCMYVDVKtdAAFS0g3eglMNTCzQxJoqNTX2kNeDCG1baMyuN9V8c+j+gdXulLUrzhcp2Wd85Lx9JDUVehKm6LRzHAuSKtUT2QVLCGEdZVkJ9C8MWjS5MtSzd7/QyI2tg5cYKlHn0jsNMogZUUIOUpVwr1vzNNPJDnxVy1tEWWHgdkjZDj0Y1rIPB0zcKbhcgdACzRhYGWUb4h3WmOOBAXGBpLeBDpa9eLKnAUeQZIhT0TACi84SE8QTtMeFIXEUfozB5KrUm7O3SzDVnsmYZ2GJmu26ulyWAQn07vCAIhUepbOKOz2zJNNoiZ22MpVBt1qILmZmR70Pcv/7skTgiQWCXlIzT0vipovKeWXotA+tX1EssE+J/avsNYSO3d95SdTottCSuQcEnEDqMGgpX/2AMiUnKnKwTIoQjTQvl3VlF9khGZwOvdrL0sAkDwRGDuRFpkD0k7JoNi9L96eZHLKWHLfRnT/hafWpN2ek86UEcMljVEmsnRRPPFrdu56dNsumSGHHMNE+MneHxC97+ZxQZd/qKsyTY5IjkRbcOHllDmX5GSthRRYNHZYsDdW9eoWVsEWEJ5gShwmgTiCpFPhHIywNWAukAQQXSmRJrtKoBfyPtNBT5p8z7mUzY4Hm7kwpo1OX4SSkzDkOwiNaRR6EggKvJe+CAt9MJ8BZrgB5Vc13qLRckfkqsR3w1ew0Ta7c6r6lW+nAsL/S1rJtbEv1a7dDrmn2ZN0zYxHPyw8ZfpTKRI5iJkxvUOYxZ0+9rCwABgZFS62jfUDHuDBjyEI1FXbBmhtEQ2JgDci/r+EwAhONzgIlbL4ydci0rKwIO+vbShMcwhfBBrxTQ1br1cTqIAZu3tV274wVSZvq5VrupdDUmTnI3XM+vreJX1bYWrVc5qsmcQNUSHqdEiSwIg2AFQfEzPBKbMUlAmDABFhIDDHqsMdg8WIZjgSmJgmHA8SNRCLioEQUr1wqJBZp3Il4VgfsdGRDlDYhwgLKDnKc4wO8tSGIZTMiFNqPRHUnoJFTfVpZ/vuLF728vpNujrdAEbHl0695m921iSfZtT+X+5SJH3XzKO/KJxkypjBlPzVv23McxGfilYUkNjnVvNQKopj1NTJ46Ncticy1aqyYJvNgvOOD4rjeRAGATAwczSQM1oDOxokFxAaGCP/7smTeDISHXtOTSF3wbMsqmWmFaBWFeUAuYM+CAyyoybSKoASTZYA0izCT0aK26hYqQzT3e1ESIMvIjOQYMzUk38meqQLuWs4lmxpchjNqL4wQB6eTfVY47JNf+3937RGz6ntb88tOeoXszzHZyn2bqustRJfPp52WxUMj3Vd10M+mtaz6ldmCjEcKQURLTp5u6gAQIQvw3wFjJ6jMTNA+YmDEhqAIkJhSZBWYkCDMAGKF+AhMazMRkoLCAnGBReZOGCVC1DvaM50LgEzMuR5HjmlMIGBgNeJLLUqko9WljbcEBtak4wt2J9sLRbkt7SPVRzpGWGWZsuJdWcnRvM2TTV+MlvB2502oVTkXvpeu9rYbjpdX+RS92UcWE6qX7GbqNXxajXlHM1qsoqx/e//5GmYvy2d8bYywrquQQsy6aA2JDl2oBYAEAAt2FGjLZnaHNUG0AooDJluk6JazcRoOJcctrURaxQ7aLHr+A+TtQXChEoI66VWMW9f75o2WZqbu5Mqgpd/xjt+LxUzgHkc9uasri1VdyqyQJjK8u6tt/bs8MgsbS8oNkvSUK7Lm382hnrfrMSLZQwCUotkoO6q4QmEWUc2Ehk6UnXimfp45g4ymHBqXxNiFAykRhUDmdiEZwXBq8qkBXAqAKBgbCHsAlQImKQyFSUQjB6VdP4PqR/xARB/iOAsGfRoSCjYocHCCPt1qVWQr/ddxKSEwrOGo5ekbYVITF7dzsj2mXyfJDw8wkUEIRTMQ7F7CYNDpyoSd6vFtfNSMao6bZvOFujFUmBBD2WXt0F66FZ1fSVKxhs18zzLXCNPAyL962MNeRHWslf/7smTwDAWWXE8TmUvQeuu6nWUijVbheTYuYRFBy56p6ZYhofzXFPyIEAAAF3WbjvZtTHQICATFDHA03mQXVBwIS3VN8YBQtGs8I9AfDExKgpoi6ILC5czim/aHY5Ea8kkm7n/sb42+FsVu3CF9R332/lNaz1fyI+NW6j27/5/+dbWpHSY/78WO8f96VIrhblNu+yxKTwpDL5xNagAVYVHhz5AGGG2fVnJv92CMqmJS2YGAxoF1AACmPRWYvIZlFlGMxaZRGxKbiUhGVA2mUCUREMYvo6ChTJExkc7BVDChhrNk4LJ4gQqbjjLFThEVatMr6j+nSYQ78sxlEfkEaoV+v3e+SUs1p7IvYcMiMKoMipih7DxACUWuziY4NBvsIM+ND4dEFja3OHTkivcPAwVFH0fsaq1LpXRo+pOS4KqOP54qDGbo00f1rjQ9v7JqK65ObdFQAa5JQZlMSKMNdN1CNkUEBQKkg4CvoZDGuDJHQwFgwY3aTISYFF3VEnDxNyXK2j60sPraaZB45N2mOqGKxaop8WpdOqfqT5rJ/s/lVxQ/pPPm8M0JN4SLo6+rSrtU1Ka25HoR3T2XQFRBNcadfpMHVtACClQQMxgpWsABpp1OkOpgyHTKwWAYdEYyBoVQOBqPHhQaE4DTxlqxjngCcjjIAGBqc01uYQYMMUFR8f+US+jSVbIPJg4bHNuc1CUNGYywSVaqy6GFlTcnG/KOZKn091nDKBSda5q9r4Sc7KB22esQT/Tb9pk6+K/K7u5bfTWxL/g8zfKDOZ+WUtpkyvt3wtfLK+Oqfv1qmMyc7fDswNz0lJDul102Gmz3P4Nt0P/7smTrjMXEXk4TmUPgeciaM2liqBSJe0BuaWnKCCvoTaMLGAFxtUV+mI5n06nEvmBAgkgIioQYEYxDsecel6SATIkDHCC+6ZLbNQLAoFCWQvAhqlg49Myl1kmVqwY2fOMU2cHQNTyvWX6BnmSOa3eW7riUu85IRkQheNTvTix805lX4xHtLd9cj6P00Z842db2BKpm7aLf/v8/t2oOMGUtImlu0JoAFNNQFAgSamWNBRXGaOpn5YYoBAYrNIPgoMmSApkAeZWhI7sWFTYgCkLH8Z8CimsIiWt+KwJBzR1ZXfEUGm0VCWC8uW5ETNmav1aaBQFIiRjCJkQTRC8Q0EXxFTkcbENF9kGywkEbcRBdeCxC1Wq4cznjhkO8l+Ce6IDod/XAhsOgkmtCybkcZeXvyi8fjVt+DR30vLjLuwoKRNjmMQ0hCoABaK4hhQounZMZF9CwkYCXmDE7F4YAQSrhNYvYCRsuqSk/UqaYLhCygMIUAiLxySQi48TDLZA2vfMtlrONXlHAXMO2zyveo1GSxZj/5WddNI1/l/r9V+qf6dv///7aNbQdwQVswhymHyjijv2jdAAwMBAAdaExmQ/GlZIfphBjlDgwrGAgMaVJBj8QGQAoGLoxoKzRBna8FtBlAh/R5gBIyWAQ0ayAk+RJ4YkYYERMYSWaLQixps9pPlLu/FR0Il7SzeVh9YRPrAQmU/MNgyi1dcEr1nduQvUkv8MCMmPPvIwxcraxC5i1xUnClJht8HJ33oDEPLzqtf7GFM1Hu6illy8PTVZ8P+sgSeDBJk5dSMFGv2PLHIWHZiULta7VAOG9qjM9mmjSQTbymP/7smTmjEUJXFAbeEPAbwvqI23iahhFgThOaS3KFq7p3ZeguDOln1tCBAE7pdyT0xV1BRolNItiHES9hHiC4WEccAzi7p1ZkN4GuzyoQfTRGhlWuXwUE29UHMxHUw4gQhnMokHeP83F1kRxY297rlNzxetXe5fYPDC3r/d4+uvv5fpKtLUu69KREqbe3uXmUM5tKtxgeDtM9+yMaLjE1coZVilC4oYkINPEB+GIky8Aq6y8RkxeCYUEcRWNnTIBQcKU0EDdBMaxhCBoYIlKyoxI0MNMQQgcgs0lT9LE3kk8ohRQYUWMGdbC9IWsb+9YrXO52+ZKUhstviHvfRbRuIhJ1NsbCfnrk9yoPBxYzfU2lyaz2HZ+hgrlzuPWWTwT+YcN66UrleqvxmEnGmLo0FdtSMLCyQUUn76gxj8zl4ZbnjZuMMbavVHrIq7zPI7HhM0eSQlaZavo6VpjJqC6Od0uCaDhQ50QEnTpmVh7ocvURQvIzgwK2+6SsGd5nhz4c4s4DV0kw7uAXzLmDQwMKIjFTS2A4FMoWKqqJ3P5DNJJuvSyaxQw5FN5yhsMNxQCso2g4XatEFRYrc6sjk+xXUkDnzD79qdHHDQqCgsN8JZ5tug02ZNTfo2Lwzr1WMtm2cp7NL7RhAtCrlFMpKONKHppvx7Qrq7a2v2eY6eXqunBEpStL2ZSH+5Rkd7K0J4026d6r6xi9oO+ch/ruDqNCGCWFUFgJhoqZqPGyDpgxYAQUtyY8UEoaCSgKaZV6y0Sx1AxgUAERjJdcKDxxPKimXNijVJXFGp0XHailSJRNxrWGdW50A2RO9o8ZK7LeH29oUoyXf/7sGTiBAaVZ9KbWHpQnIxKg2SsplPhe0at5SnBwC6raYQKcD8obWS30/8qHI/2VrwheJS3ekhjJPWN6boe0TO3bXmXENxuX6Z5R9bu+WR9TYZ6LZfY1k5xhaExe1m+pudJse+JkrGynl/q4o3LAY5rJHMm8WGltwsIvYwZlyYLSuQUg9AzzszXTN3r0seORWpuYxtWPFQ/sHxPmOUHB0y/FoJVtr57+Kv524KM4n+V6ksIqobVQyjnFcVvnpen+nkMladGlV6F/W+pU27po793RBwJlAgl2RLDsBjN9KoGgCCucJUmOTnKLHrlhiYwQVTxixxep7B1BnKI1gpBIZHEna7TZUEQyR4FxcfF7GlNgiCdsJx4z+zq3ZfKl13CbsQkEV9BDWxoNEZoUe12H0hAOixj3eNGZtkfztCCFdb/yJB/HHwdPJJXVpyjvqrckpeyRpt2bro881Wk9SSfeMMnjqWEEODaEEgu9ZjUelg4qxQ7IEIPz5FCFDalXKFX0NGvvSgPMtFZjJC5I0VGXgf2B2eixkMtVeqXzHZS4DJ3+AO2IWMTE/N9BUw44aP0H8cRcRJz7igNXrx/xCyYT6QEspHNSlmL9S87PdSlS798vpqpsj++QvSyIR5rwhHKww5VrgYQW9gcciSRYyjzgEBTUrzWsASZTRV0OI4QGES0oEMpLJbp/KELXlsyqVJdQxvsHxkEloJ1QsMZucv6hEwDvNfaJ8ljQc5+pYsZPbTt9tLOy6PSqCtoL/LJrTN/O1qP7Ykgnf7NUFHLl2H1iQzL6G4Z/nnxrrnxRTdL4czZy1IzJaWiw6AonB/28UXJYkmS//uyZMmMxJde0hNYQnB1CypSZQKoENFhTG0wdUnPq2nNlIqhJges6VQEUAAFLS+S/YZYWYhy61h0yE4ILhiRVIMdWOQXEnvnNWmeS+Qhr/crk6kE33JkFMYk1aUndvyfVN6ptkRILzjCvP/dpHkOMiCmsQ+/3qv9SGy3pei2ozSo+W9Gejtoau1HR5kwxrUnOf13agIAABc3uvEEEmCN8QHDgEkRVTCwIwA5RgWBDQZYYmPJfLaX6kRDVRYimCi0926oLmk0OBj+FS2rri97P1crKqd68/TajQ/61fgJBxagNFhWqNpdxSUUguMQxH4GAcH8DyvhRw7aIqYL9SX1hckAxJ9uY3ckHTcTlmM8DWvIv0a+mmpsaPtl+VDqmBq5VmFB8bweuMD1cRW0gNJtuhYae1ybMycwOIxIgVAkSthRQqACwbLaFyVnlv6ncPNSj2A0S7lCWIaybgGeCSWCVm9Xr+5A6YTTN40wBcRVD21KWsfcX9yLJJwnutPib/JXteu+Df619nT6bn51r+5MGSP5mamCtuGirJZumX7+VN+Bvoel6/dsemQTRWvDHGyxK6eAZBzA+FBhBMQKIShpsZmmCk8KFpEk0SLDE4YMSzOwENdHNy/N8TGFxtlB1hKbZYGFVCaUKFGjlSuna4XDIA6iDutcoKQRhGKYuWoaW+p5RfpI2PwoFY+KZqQRm8ikQfYiLIRg1DCnkMOpC5V3QwkHZJB85yolUyovUm/fEN206opn6h7vbWPqrNrW1u19kRt49zF5Uc/dN6jlL7dfSTq9r6cfcx8nn6hte42fyetIUaTnsk2R5CDiht09k1gxKa8S//uyZO+ERMFd09NMRLCGK6ozaehoFc15OE5pacHELOpphI41miIiIbW2ZvpJaV870FK+mIGwk1cAWHXijNYbSDSBW7f4tla1vfWbcvLb+87ukYk1yT988u6zp9XM/LXnOr39TOfazQpFYNKdIjydDe25H+0yz//v8q/zTyVYK4KX8tUFP7W8LOoQLmFAgKjgPFEQcFABagALwAAgQoteMyAZZOJJYECMBe5gTpKhHQnkvwzYkLR46hE0Oc28c7u67KvKXLlapRBDwZV6V+drh6h3D61riYXlzFde+S2jpsBtzVTyrZeSG1NPvZPCqk1HC3Libcnk/N6uNvq6i+7/c7ibuTV8c17vvvvdRyukIkrIXph5i+yPhZ8R1AANFKGBER95MZ2PmGRBm5yVW0ZQlhJUYgAnJjgBGA+IhkQriBANXSxx05/2g+okEHKLssnXLY+TpRZL8yDJu1Sab/jn1LlHvYbAUHwO2i0k9GtVrM6H2agk27GRLSdayqxtxd1G/xTX19RX1zpWhRYTzIOChBR9wNrO6jxVkjckCD2gEY/AL9TMqAIIkM0fDkxbCU6yV84ANwEImKj6GB6YKI0YJBkYLEqYIDYzExHCIiFEwAGIw8EA1HB8QAqgGMkQFMRxEEIWCxGJ1wy4pa4glMFs7EgfOrS/YWdY+3d/EngWy2CNTs2opKE75K78n9sklw4JAFxPSqIAE8MC9mDyuKo+Nwy6lgubGioce4kEfU6/KGerF+PLnaWuhiUgkSs81skPVHyUIr/NNZ4/4aeeq17geOuRg537GrISIbY0Pybunfg1BB5UKcsAnLb+AJh6RB84hh2Y//uyZPgMxL9e0ht5WnCJx7nTbwhcGDF5MC7lEtIrLyiNoZtoO6JAjSNVj9qUmqDl7UUgUOgJjKgK9IAZ6CQ0gUUUDadIbD8Jlrco2s0XLd6vPZ0367vOXRqlorvMcO3qOOCLMbFOY7PTP/VWgmQ8IflSzlPwZds96vw83fkEMXT6lTYzmynBAWKp7zcxk/YDImBiViiPw8J9jW3Gy2ZarEsQACckvMMGTlQU0cuMrODljMLkAJJ26mGjKvxwmVyFiYAhuKIQMCQCBESBoQLkBxDLwXOjODqJgzCTWLNGTJ+RArkefFmFM+pkWlE6W3bRnSseU6bltjEroukV003u04YaJLJqQPG2pRuqtd0EFukku6KRtujndzErNboGabywVH1Opc3ZAwSepNdaKCjB63KB1ku7nzJNZuQ4vmAMA2GGCsaX2WCAATul3AMq0sGE5hhKbUYjIiChtrphIGkki6IgcwEST0fJRoYAQUNJ4dhIgRkT8GJpIM5OSoMcPlLYwiHKzCklHPnVbuERFvpt41rd7Ot/N33fx/FgZj2pXfw3QLdxifFYk+Phub9wc4/pr/2+/ne/7//P15n+sa1r4reN5HVvT7+fP90vvNLZ1nNNyXvvGK4xj034bNnw2rP+Z2SQRtOABgAAAMCkcigYCgYCEGkgYKyjbDs6ZSITs3uTV8Bhcy4GMKGDPhoxs1UgmiChsQgxigMYCAhfUGzYewMqBtGCYRCgkgYSGXC65NAAkBsaEpg3ETog8fQsJCCxEEDL4FsBswhGFsCLl0iJmNYNUGIggXQgsFEgMYCEoe+ThDEC25w+SBm4yAr4X0DG4ZYD//uyROiABR1aUJ1uIACfy4o3rbwAI5ofS7m5gARnQqhfOYABL4XAhiEvmxYlN1ilwxORIgjmCAQMHQFhwXTFWL4RoXlPMz7HC5QYuIm5PqNB6MxW4qQskTwQcQeOti8keUs2OoOouFpM8ZvMyuOM4KCEojKCkRxkuQ4RiIWFbCzlmSabra7fKhcNJcW6abm6kEIyJdFbnjMipeHNGTLxACgXSZMv////////9iqV6kjx15oAANEKxsNRWEwDoKEmszAezLS2NnqszaqQ4LmACYCgcYSCokqzCoqARgZCBQOKipMoDBkFMNKR6Ro0FAmxTWwUKB0Sx0JFMyAMcyj7H4wqOuwGeVdis5ZZhCGDbyUUj7ytktFL4h08WODAiAG2yKkXo+kW5QVIHmsr9xDRB9FOFmUZad9a0GSy3PTd6tTUktv3y6Z2MlY/DQ2kOo7Uxa5Xt2rlSZocr9WevUuFJUliKap23ZxDljcu7y5S01Wv+W6v4Ved/ufS8aRbT1NHcnIu8DBC7ap967+fef3n///U5jnvlrP9///7bwiX5ww/ksYnF/p8+w/T//////////////////////////////////////beuYVAP4EAFpGr4ogkFEpxOQS+oSYGgR4EmY5InIAhGFuaIqVCgSP63XnjyEAZ4tLWbZOjyAekCGiQpMm6dJrmqSEhKRIWUheTYQC8rylRr0xF2okeXtDC4tTYhS6VzklEw6etq7XKgXaHOcsGRVOCralYwp58zUbaJ+SIzPbaS0GE/lY29aV76G9rmInWp9V/pyi+KuX2D/ZpJbQXN89WVp85PIb1xkQ9DF3E//uyRFMABq5mV1Zh4ADXLDq1zLwAEuWTYb2FgAosLmwzsLAAdyvIUjKyNkJ5iJBfR4jxlQ7GrSK59nF60pLh9iPmDB3JG1q37g01YGKtJ6Yf1xPkQoyQScFGn1kbhR2AHG0soAxGSeouYIgAJUiXjQCwE7KqylJRg0CDmmkx1FYCCIIhibVCdLQSQegdDQ0DuPV+Xw3mwkhpiLB0CBi8Mo8UC+VCFJVhMZiUhPzPVhsFzV5bUskWZUoen1QzLTAixST0XBelhyaFww1S8FWpxHN8S76M3OnFacFGmIB0ubIjW6S3eR2WHAiQGqP5arSqfVUGrG87amGdtlcXDEm9Y9WR5jF8Y1Jh22p6fN2yV9M+gPsyQ31/aK20l+cXtu770zCNEs4R0p/yqxqAafZYJJBBUTIHhOmpoEFZqzlShm1lg7zI/tFdDJ/GHpCNRwEEImRkPK6Vn0F5Jpqqjbi5xxhoXUVljWHpai+jE3nOOL3dPqpNGzW/e5zlYSlF0UrZUcKjtsdNdPPvhjae5Lt7E42Qm/Vi4cq7ZKHNrMt7NB6NvfT5hDuYbxO+yRazbK0zE2QNT7atjNCmHrmHv4+pUfGqALUajCIAGwlOJQ5FMSqslRxTFNaysR2VG5IzN6KR9y4UwHwgAFQTh+Jw21efg6eVWNLpiNXZiyzc0hNRWkpadZNsVOMbKy60H3vqjkPXlkulRW/ex91Nrt1HXJ+JtqDnxatavHSd7XVOfiu2VEM9jN/P1Ms3+yb+OXSx80obpzObt5thwuCb+TKNlwTUkyhgAAkAlJF8E1Sz7GFhgMQHC4qF/Giza1gZDiccSh/HIAFO//uyRBMAFLBeV2MMM0KR69r8YYZ4EmF3XYwwzco3L2uxhJnxoHhetzUxyeCEPy09eTImtAJ5GEjHw6ZNCiCMBRtk1fwmgsnQqKKshBhyiSLakWKfgeGPxcmsYUtCqWkajiwfIiiFWeEQtjnOtDxCBbnxe33c8ujrM3UloobUoLeNdu1s8jCrhFT7/mpuiN9JaJZnvCRG5GhCABKOjyyyyZCdr8rSZWWudQvWypi6gSvmCNZZYkMR9BsAWKMqRwWZTRPuGSRjawTZryyBEgx5ZSjjGAzgIkecqSE9VqQPVhkc1xk3I0m3yuabj5S+hT8stBAlMMacexOl1iEuerYKOh+gU+sb2+9p//iqv6nlZr+lw7O8/sYywJ8T/ydjUJIriM0KiuggAOk2yNRAJDoxJHxCMOtPKEq2ppzikmFs/eZoATDo4cwgSKqdUiVIVcZYKZaq65tP5x5YwdOPrVnLUqw/epXqZha0+dxdA/ohFl2vSico16cW/8wSw49qLqCg7XBu5NzmKBUEDTEMpiBuoVVolHWnaDQc+PBTz5x+30t/OeX3NfdzDjZQss9kEPm6hIL0N9azfX/KAKmYwIAdlC9HpLcO00Zu6yVF4NRsa6nq78tfJtYEMDS5Cq28iLR6qDoZqqQn7c7FJPUVxlqbFspqobVwe55tZuVrwPG7fYmakVR6JSmvUSRxbIUc/Y9zojXl0tlFqWJLZzHs7x3hE4TFWt8pmb0laje0M3b+LOlsjfnRySkxlGIUitprpsXD5r4zmWdNkiRARWjgABEineWCQsGoNzQZZ6tCZaTEuvPSq2K4YbPQ3A1Z0ZVbpIXUghaK//uyRBYABDNZ12MGHPKGrBsNYMOYUOFzX6wYcwotrOsthhmxY5AVUNsooKw9ni540xOi1fXRLq7Pt4mlwbXLRRhMXaHA5bGL+WQNZhFJFIZMdDMdqdFnwqzBAJm4WoSaurgjxZDKY+CGKG1JfzJGa37XmEFuM23dAo6Hcx+bRi7ijaaJAAMkiQSjoUIVgfdC2SIOODEFh3wZPGoGcBpuWoal1l5706RKNkMUl14TM1pFEkENyjbguQI8lRq614Ki7IBqkukI3JqdN1CwHkR3QJUBQhCJD0zM7BWqsuoUOx5veiVKSXTEovQZ2GrKXzzRuUyoAmGBEIIpaGFgvYhBqKkthZv9DnSibaKQBKiUzwjplJLRfl4kvFM3+WQ6kNJ9wBOUTN5bEX5lL8t9UloKHvDR1bvOykOwl7gdmI8klWKL1EqnvCRuB1jRlUj2DEJIwuQbfEV8yZsY8QIFGsmEZkI5nSRXgJUBQkGVjyhsZsrGfW2lgDRK6/d+EoUMHBGwi51RIXpk2nSZi++9AFCQARAt0ByhCMiAVkWDQnqZM7Z0hq2r0qXPqdMB+y8gmJg3z5JSs4nvV3qtvpnMk/3rmnQuQsL1ti5tpjNNIOSKLi0USwk6LOAbpqSAR2imQKGARjui+Miick14lHRPap9GU/vIKZkE5abHWk3NajcZyEq2cjdx4R6T4hn7N2b7l/mc7syLD6n2fNURCAAEKaVqQZM8j2lYJ6FdigXBXW5w4JLr6BpqdWtw6zyDJFqAo7Sb2+S0+gJum9h3tGlHCFdm1zToaIUHSMoP0MZbCCcecBmXaTErKxhOGkYlh4DDWrkZL5rV//uyZC2EBG9X1TMJHXJw6/sNPMKKEo15U4yk1cmirKuw8wnwVNCpb/43Vlmb6H/oJ7/rOyNd1TYzxj9XTFWpt0xysh+IbrN8koUUogOgKfJpr4vwnwP6UZW20ykiCVUwCdAlAGh4iigP0hJNAUp5naqFEzv0ZliSuwOl2fyaI/bu2jpte1si3ej61nJI5NFoPJNX6GuHbIjoqLlZs3XlErVC5h8MXobXy50Wm1wrVQrxTPQfRNVbZNLZSO7lVqO+ga6BqnArK7wAxAAAclgowECaSIBQWALKEBIJae9VZAIuZ36GOMRqSuUO4/7kZavRWWfTOqKNTZW/6PPpJvoUwaipaGlwma5yz0OjbUzWRVKY02vZRtFiYiBp1P9fYT25mGLZyWLxh8ihu8FLH7mvfaPfrJamLX7Gsj5FGumVSpy0+3o12ml/fPK3M/uMFpVPUhj7d9NIdKGbo7f+giAJElRALcgPoQ8graRkBPJwhVj0ZVwfyUcsLKQAMMLTHw/LmrrM7NXZrupVDtFNqSnbej8FfYKvV6CTMhiuCmfBLOQd5SNRO5q2oqPc7ZS7LejvdFsvXyM6mfQ3vq2m6AZViVopLu+tAFBJKKAAACibhb0BDKHBGXjYOhiifRq7glQx35FJ3dgSVSprb6RKTy+8BnmiDjyhSDemX2Py8t75SikMw4ZTDa0yPWtyitdSLHJFMuSEZ2ZGLzZjeGZ8jMfTnurcaIcIy4m2W86UOAlOlSB5HZYZgsm0WrIQUGWUID8YJ6uuxdOUO6ZoAVptI1pIIuhQCDCYBhhut4DwAykjL0LYiQJg/kQqDlPAeYYAIIHQb5la//uyRFcABB5c1msGHNKCy7r9PSN4UDmFWawwa4oArSqZgw5xCIIF1LbQw5qaekiLBChd3kYPABQQNwp1XGG2CiaMCUIBRcltzmqMS5qjQGvTqIZ6dKmeTVSyvtCXI0Iya++VJLWPsTLMjbrEQnUKQ7Mei2UG5jPtV2FumdAhJDSIQIILrPggrcy9CCqXz3NxTwd1LhlQFhYp0MCyUKHxbHRlUub1k+hS99epHVxnn3d+MnQaJAXMSLYKSuFJEzj2u4YWJEMr19CwjgMKErkrwiZYMfkrT8lUKKI2ZeCi/IJM9QdEFUpFxcjE3rt7kUChPgoVQyMRdnFEj/LyWrbEggADjjlMioQqOLarLaW0lbreLZkTbNMdmtFXt5cqyOAJizSaKOEDBCYEXTouqNVGS6g6zkwOV1CMik70VvcklSKsw/t09DXm5hr+35xSasswtY1QslNFLSDAiKGpMMMalbiL/sempQQW45f2yKq8mWW4KG1GFdYCwWsMfvzaf6ogYNElJkEkuRwiy6heMrytIu+kYsqHmPrNXZADjvh4MVZ2P6wgHt4bOtJIEb07X2TpDy8Tfq4ug5GKUgRdRTzKBtXwqkKhIBMLJaSWhhAgRHSmoqoCIjIEgciRzJu501qk+bsoiWoT+og6DEICJxaJPUTCYuq6MD0PexFmVAXdfe/P0UNI7G5GiQVUnKEgIj6PCjyb7gLARpuzTGUQC7VhxHlcUEYMFCTptXByAJK9EkzAPK5DJEDIIBiMwRZ0yjyCEOOg4ktSYSRAlRykEiNoQk/yKjq41IrCEHoRc0IzcwtBJsbsRckCvFQ5REUztedayVv///uyRHoABBVWVmsMG1KBjNsdYSN5EGFnVywwbYIML2u09I3oPnYMRGh1UQazTH/WefuMpAmOtaiq8rDmAoybhmUyNBVTZZOSqrL2JI4qWaIhLeOQoJSYSa+80mYXEod7q3cy7Dm5StE61m97rcnHhVwMStogKxBqpJqDDKICDhVoOXYvCvAYjEiiCvD2Rx84bN1gbCyCOzcp2062oN5kxFjxUd19cmy75Oph6IUMHYCJthka19HLgDRqJppgpp0HETkcAzgUh7C6CbEzJiM41jrKRUyoYk1UQ8CQqAhtlNZjCYOkkW2d8msqENbVQ7UJEMfWpdD52lD2h6Vtq5IJmuhzGGFUiFqM8Hc+BlDIzgoCMRKFbMM53Q+ORxJzlhUSoxroVTBIMRG1IsWgIKDSIpm6n0xFHCaqw/RVAHKRiPqQu9BQiqIOQB6K5XGRui1dRRpi9X0eeq0yJO9N3mekwR0FRgjSgKCKotsOtxtWekynTSS3pvb+rs5ZeH7JMn4q5nlTvaf5Yy/YuYP/UmczWPEY8sVnrL0+TIhKvmZ8qlVaeX9T1Jd7enCjX8255MOGvAK/R1XhyVqOUgAMDIAAkLIgAMmYsmhzWqrc/yelODhqRkaxWyvDKWznmgoUGLMMKFBEkaLCJpYqSwa+tI7m73HahuqZnixepvlfo7aTpbBDHJK0KjgnamcUxK+aRQ4KMowPRBGZOVmDhOF5GQVsnFNvpFFJ9UUnrFxj6Rchnw54ge5/GvnQxhmZTRI40QDIIH4rDh1jiW6NKGBInMHRlbiZRtNaZQr0YOZocBwThzrk61JCEozEhLXHUGbBZbEyIz9k//uyZJwAA/dc1eMpHHB8axqJZSN+UJlpYewlD2HXLGpxgwpwXNc4PUnfiDpOgl6XUeZY0TNw11JRF8N1b18H1vdeU1cNPFPMCzXkl/sv6VxF8KPvv+Ijq1qIMrGt3zzchRsoXHOBxgs6hAHoAFaBIFAIMWGkhDFIlIqkVADTkIA57WQYONRhukaltWNXX8YbVrWZBnGCpOOLU5ZjskeQFJu7br3z8p/+2seZXEadHDxhV/dxBDxpmmyQzZLLrOXiSOt22eG3qcqb6c12PLnI6KR9HWEV9jVVGS+QrrBhkQZDsQBYlElNABouoSGSgZpnU7QWC76YbdEbHKTRcehdFXtALiILFyMdMLnYpDiNdlaU45jP6myUrVHqL5LV043JsvCmoXQ+KMhRaI6wIOxm1SZiMGYiBxwEqeRQjJFQd64357Z5rJMKU+9JBRmhzjFsdKfS+N+GbycYotRMKly/zO9+EYGnC0bGkkpknAE0ZmITmdT6CMFMxJxkt36Q1tQ9igZXRD6HYTxHyGd73Kx9PnEh01BYsrMvdc4MUIIHcdSuyuLHorUIGHMjRVfhVTZSS/mRKpVMBUl5rutpHzh6H36RlDwpWo/DIVRCG02TCjiuwy46legJKSjGk994tuWsAZu6BdADiySVQgWVRVMEv0JYvQ1ltGfsb4XDaaguqmxiSu7R0kodOUSucoqsjw3ZopnH86KKGWySGUZBYFeepO3PlsZD1eFInai5+yajdtTjb1LNXFHWa746O4fZIXsi4dPvcVZGGuUMrSMnhrwc0Fg+rqRGtZooNaS3DHR1MPaM4ECkXkehIkEEQAVF9CT1QQRj//uyRMiABAVZVmMJG+qB6yrNYYNqUF1rV4yYdyIOLindow5hydwKAIaSFIBMvSOdhPtZTp7ZS328pBGHrp79ceG2ggJJYSGFU2p70qRJIntqNPYk0gViDeUpbKRChoOdasFpkrg8YNhFpdzmUvw9jrHqcphRamNDsF8dlcirMw8YDO57G1K0MaTfLop2r4YSoiTFhpe80qN1lfa2EABhR6a4APAzd8jY1wQVQIuIYZAqmjAiOYIGTF2dNhRFGhkxUR6YeqjR2IJFR4DxARkOUNsiWdg1kUx0oz1Bi8BYkQ6QWHvAPzrsoUJnJnOmgIs+hl7eEK0KgIr8Eo4kgxiDA0LYwOuoYx9ZMpBdNTUmBej+jxDrpo5WPQ7xcz6PfhjOXJvh1nT1o4fE0v8mpA9kc1kUeAMiAQAAKhYXAU5oIk4A0m6hc5kIyC6RIgikzthDW4fiE/Dsva1UIgAJCQk2kan0xaxTBue5UYB6rWyNRSh0/jYv2Kd++xrIaABIgN4+kcIC5DM5ioSfwV8T8kyzQ7DBLITGX9KyGnEOa5mds8p+0ii3Vgoz/eMGGK3fpX9G2nEAABxASyYmmEhkYEHJxsBJaluysBjxLLdMIRMMCgJdaNL4pAqaurNrDr1VRaHyQONDr00iSQNTWdOdlgkz0E1jCbRCb5Cv+gHxfJBgkz6kzEhUZyme3q4DM6mjVPJrr70aikS5ZucHhpMOIDVZp7eO9nHbCHfkw/sNrFb9rPmmJ5VJ7o6oEjVJ4qZydMbKKZ445RcVmpoxOlIhV4+a7ePFmpAQYABAHGCppSJzlJpSq6CQgq6kThYSHC2OpgI/KUP3//uyZOuEBLVc0ZNJROB+66pqZMOKVEGbRM4lFUHwK2klowqpLWhUb+xualT+WJfZxocZCEJ3qip2yihVZHLS3J2RxDYJAEKv3dZa9bczddq3UdOhDa10fpSNZCA8zqpxjSMsxr780pDzWYmlzbHKKdnMySo6Ud9OmClWLlwLrGsqQAAJUHEEMIDBhYzcjPOaDBAxhST5hhaiKIAFupbESCk2Wjp8L0X9Nvoy6opzi9QvVl1cQh3eWEgdnkJwGG42woUsnJqjnkK8vRGFMibp7okZkMTwUJjskmZLQRXpJOhzyaqpVjCZwmF6hBubVh6+MRKlCRPUClIs2ufb8WjQ4/Gl0mqCvxNTA83c9Kgw2lpCc0cmkS8bmcS44uG5GGLgGBESJSLlRdPqRAsAwYws8vjC0qoeKIPPD6+2YymidStfdTiMBBO/o7KtjB5CoOCjvajbPlmtPhs0bu+scnaWb5PTqCavyZJ4yhPuKGFXRzxIYEMF/d8j51GyyQkzUgTx8KVJmxxam9mSIEEGkc6GuVzuaRKLrsbAqRz0yDLIjCdf2gAA4ijwwIDCc7CgPi6zCwAughMMcgGnGWoBhjJgHihKBJ8xgBJRpkGwKIB7pEFSvU6EdgFzllr+vSSAni7LoYYbWygOHJ90CQkPJCEIv5d4nVSA8ALeifMaQTImlw8BuMyey2IYAJq8UkoA6GkoJIaSwofPtJEx7KwcM2ojNf0Yda12kptO6H/XKfpszy4oqTRGbhNDB/gKX3AxXT7W1OD/QmzOvUJykt7pz9m36/z4+W1rrwMFAIAAAMS9Pfk2bh08xDywytJK1D1gQclAiEhq//uyZPkMBPRhUZtsRMCCa5pqYSOMFoWdPk3lKcIPLSjpkw6oiAZzZp/5NDktgD6CB6W3XrwXSEgyJFigB4zJw6xcQXqkeZ6KETJpjd4YtF2xKGRxZTGPfRzcN7zemIGLrah4LauRmQk1Ooer5w7G+z+HfKM7te95Sy/+GZEYoh9VoxUSCwgxUUibtgMAAAJBJVBBTAoDQfMKicXDRhMKiwDIzbrDhiUFM0LFjR6FbRS3DA6eJLVaoyBT/ars0eNOq8fdIfQtpogbQ9dOLdi4EKLQRbU7IWpTC05unKiye7hyMIlZkOMAbHWaVi6GOFPnUU7nf1o3ebEin2WVfur/WE6koUV6baXqCCHimn7Tl04znmKT25z2pIk98qyUG34MofcBUqnltNeyBPZF1W6YNzMxMzBICQASoqgcMphdANIzTEwC8byKyREULqMSUqa6ILoRnYNiSZn7wuQ1670NAbZrjXJqqK0h2kQxYhwTeVohVykNk9ENX/SMhluSMTyatWcjVLWPpMn6ea6dK3L36NCNC73aHyZfa/CL+/dHNBf3zzwReeVT/nw4AIiWzFw0xg/AhKDLoMBUARAIn9GDoTIGL9iNyFImJLq0B5b+t2lqt7uLettUcmLx6ndSBc5t0bcjs6G36FSMRmi6p5exEG2MMCsVv8jrfbkh5xohhrmoplwfP3MmP4uJ1M5dIIbZVda05VFGP7USMcPpLIEGJEZPtk7ssjK+lzaDIPi71BidlJ/kCk/TedepVW0vt0gMJzurgXRaows3DKYxc2+e3W+4Z/DM7egYQiYUyjaSABjY6AUkoSSEAtSxKnwEYkiQCJfs//uyZPQEBURh0VOZSXJ2a5pHZYNqVZmdQC3lJ9IyMOmplJmpqmHyJEYBqC5sXnbqLzXvKUwVlrVg1oQUUlv9v+kaXru+lIwaPBSj9InEKTAkKWezRj/v9PYxnc7GcyM6F59PzHMuLaPOu29/9293+72M8H50zAJH05iHg/2MtVnk2INuEzrIIKc0n3azIeM/Nvxzy9UAQEhAqqBYoUjQ+Ih0aSTyicEBQFBRIAMDKl1IrqCIdRIabu3VhqgTfQA27sBwfZHeybxLG3YcK7ySNIumek8qNlq+1/BaL+RKZaFlWiOF5SMwes8JA3iCOZbRdu8UX66njc0c7K0lkp7Xp+enb8TRO8Ib12u7zR55rs+GTbspGe4VQ5m5RRGBaUFRE+KiAUTTDQEumoBlvVoju8D0mH41m1FexCHLISJocarhICisioiJbhrQa+pRA0tpVo2C/yYsA1/nLFuFfGobk+WpVcq4ZZ63vtS1PaqXaa9lscLUSFYEgRTNvBIBdK/RqahgZmQPSZ6qRex9MupnTYrVXsBoDlXJYVOTMz9lPptZ7J73FkMagFX5NKdxQnr2i5I9IpB/pjdTjJkHjq2LzAoJgAYGCY8dgIHNPMDjSkiCy1IyAmAkMNq0PGSAydcoZ+qVxXksv3B7xWcpLLIxclLNnl5dbFT0R5Aa/UaNHYmLVtqz2QEZ6gy4AqxDf/CD/g2uSCiLuBGLuiIfRMPHwQM8VWPGP8PN/F5BygNXKn65mKeV76TV/R9urFcqCXisWdpl46T60VZdAyliBAy+6rJNr4W9BztSREPAAZU0HCPaTU4xnRlLrJeRqABACVtYVUiU//uwZO8ABTBi0mNsTCCFK8rNYGnLEwWLSM2ZF8Hsr6lZgw5o/MPrZiMz+MN2pj3HCRDuWfAMRFYFnMjsiksu5W3dks9Rfeyhsv23+sznmbsPtIYRnWRj3YgvSnCvgl24j7fz1q0ty/ROGP7eZKH559U/dDxQsBKBxhw8NsEKfoIlM3yNagBCgiAnMKFRmxycOkBcbkyCc9QVpDBMGHRk22bqPsFbV+6rPIZmIOty1q0G5QC9gVlE+LOQ0DbXgWSfObbcdI49wyDuUgJZ2uhbZB0mVylzFezqHIyMPs6IpTRIG6iy3PyQoa115ZZ8vSgq9KfNaGf7JpbCcWeZSvwhvVPPd212PrTtamntJDz8OG4u8tjswDdSkJK1OayULF0+tqi8OwkABKKACvQBmOz04pTGSQSAkVEybk5vntkMUxroIBcl0EL3nhSJlq+yuWWWyJCFALLXjG0jZYktNgH2m1EUqOYg72imwVuF1SYeJjEVqfLq+otIleWMLlLMbUt7wxpDWey83fne2Q8Eyq61L8VP6OOyHnzHng1N9isYiVrHc+XYj3W35huS5JK3/zuq7akCgC6Ko0rGAFxj6GeIUAYwLbOALCytZaFgogDFrL0VnStYaVkNcGhMGOJyYXk6l4ds8FaV4/I0csiEtVVOWP8/K1JQlxemaPfCszuRc6+pOmkAp9gym5E1vM39M+sYyXYvX+Nv1GHc4/yQXrXOUxxnax1f5muh/zJ/+x52ltRnliTovlBVAZE/FgxHJLiWozM8//r8LAQACoirijALuhE1BYJH8KhgMNU7kT4gIhGWSoBWJcgtyqSKtJmTQLhwVHT/+7Jk9ogFAV9Qi3hJdIyruhhlJpoSpY1EzbDPggyuqKWkjijqEUFDJmliEudgYyn2cli3vIyfTiRv3zH3ZyZSnjDFk+SKFIKt7NI2LgeFjkbA+u/OifZcS0CatHOpnwE5okudXqqTS80a0r5GVDDjkFgEUqliTYHJaoyWAwSAMAopQugaGFGJgxi1MYdNjpEKBQqBGcSx0EiKfLNiaYkGrOvwHEO1EBJFYGC2g7emajcExNiTV8cJZR9FAPjr5rBJDS/MQTesLQUJRTDBQrFVNivyA4Sc4JzNICAl403SFQThRmiJkw2lqj5KFM4rGh7ZSEG1ODN1b9oQksPc3wwylW3p/z9yyeHkloV6blUtWl860fUJ2uSo+IjcbQm0TtX//IamnEN4gEAAIroIYRw0A8NDyJhz40FQiY3DAcSfot8YYAlSpjLEsHFVWRwj0zD6tEAOxH46zydlv8j9qZYo9BCirSkUBgaenKcwnJJ0rRrHWkBPVYsycio3X/hqPs7DF0Yn802oOtX7St7uuZsZQ51wyVx6mmeX7bTY1zh+eU+nKtUua7KwUiDBSEBG/qQoATBwwBz+Mkjg0MWz0KYMjhsaELyGLxAXWAohCwCMIFgoCwCDBUBZgoBAYYh4RSFEoVAPF4YKsZCpH2B4H/OvEAQMdds5iuGVImTtZXa5ULJBTRk0+gW1Eo4Y2Y4VOWI0RlDAQiRnShsPYXAYUpNg+R3BJVjpa+VWVQzGy/hjYh3sLSsqWf6OCKN3cc1bdtA1d99/rVlN1/JuOe3ZXrPd+Xqv7PGJJ4vqDygaiFyeKEDACjQ2SkOBKzXwAwwdMBEQEFr/+7Jk+4B1Xl7QU3lJ8IkLOeVow7yV5Ws4Lj0vUg+e50G2GlI6NaMsJ4dMACVZAqANfoFTu/FBYXlck9QmQD4XxzFARDzf0Nmq6oyvnOXiwKyHKBMbRW+BAdmJpx4domSpu0dMskMv8zl4VXhDbonbvW5V3VTU7kkWWehALAQcwWLA9Drk2ClbybHi6cuDIwOrCabvqhAAAARizcGbZixeeaqnDUxkiSCjMBGhjyiYUJmCFQjAzFQIzcMMJCyqHmBDDOwwPUCYiyct2kDOKBtffhwVRggDhjUoXssyLP7adGn1BDgPNLbDztniuoBWRP2yVxi4QhuI6rlZWWsyaHz1y4GFKJDIdYkotachcXL8Qj9zNuvcxQeLIXUq93CpSLsJMMV1zU9Za5PHL3Ib+/OP5MENPaQ98QKvu3YVpNTxQItaPpQHBqrNl2Dp3R5mtiAAAAAUHXBoAB9HRpmhiBoocBBpPN2nwNGe0wYRBy+Lo06NVM7zx7h2GGo4MxC4LFG9zwSGTpI9FebiSJeMYP7UAVa0nIbBfEPYV8aHrKwpT+5Xa75EYb/Uuye3lVTfy/9T+3P55vw4W/wmJy3eLwwpo1GBnxjVDEpR6gmPFQZnEhkxanLCEfIOplAhGEQqFwCYUUQQGgCEQYCjEB4C4jJAUMg8woGChHlwHqJhCTRwMC0SJrdHB0XPTyUskNdP98YMapCmLvfbtQ+3O7SZQzcyeB+pXhhYdyWSjCI3LtjGmvQmQTt2cooIq1pe6b1coIi/M3NyqHZR2YldNrGZpt5yiZitehufrKGqa/jlcr1d0trmt3J36kA5c1zv6iEX/m7eH7z/+7Jk7wZlz1nNs2wewnsrOfdpI5YZrXc0NcwAEdGV58ay8ALz7/N18+Xv3u3+W+Y//c6fv/lzdDPYZ7jGubx5Z3XKqBseN3XjAKA2gZ6R/RhYgKmCCQIESRdECM6GAV6DR0PsJfBZHKDmXnE2FSrmFsY1Myvr5bK1UNoNKXpGvu0aNNE3rEkfFMwHD69dbzX7iQdb94NI+963mUXC0oZafFyAeaF3knqeo6pw78Y1zTzhCSAz5cJDS42bZ6YAAJAQABhYyWcjy8NM7p411PjbjbNy2EykizDxgMDs0kLJg4sm0jcZhGJjwNGNQKYhDRiQCGNQqaT5EuoOYbhnHF70UAwZfhCAmeqwFTngAaQKrH4eZxW/Yev91zJDOYyAWRtcYqtpvmCYxFiMokSeAgCAQAsusM40IjlIsFGXza/LY7cjaRAkWpm0tdEGtZavdh9rcXn06l2yeHnEg223NvM9X2YMEl2u2noh23AVici9NHaN+ZFK7yz5RRSKXv+/GF2isdhVNY5cjl2vBEERCkqyulo6aUyiKYVqLGxL57G/jNxG1fxwr46w///u43fqYarbxxxz/W5+868zJuRWvy1b6CTP/+r/6NmPABdNMyyNHxRM0hNM2jIM+DqOmRpMcR/MQQTMwDFMLhOMSD7MiBFMJQFMOBqMUQYMPwQAg8mBozmWACvz5IKwz0JMI0cMME0OlBpAJXEkA4FGEntTEAw6gzY09UzVD1rLdVvlCtCjcHKGM8pH1aQiSsuLQbHk/m9VezZbTwP4gij7O5I/kofBrq+mxO+1Fk8tUFYm0twWXw/OqbNo97nL4md3WbwO0N17Mgf/+7JE2wAIYGTMtnMgARRsuXHO5AAcWY9PuawAC42zKjc08AD5+M8G4QHI25Q7EaP4xyMw+8L6u8vncth2zAU1Dr8S98IfsVc56gz3OwY3KUbsz0eo5yklOdM2aBJl/dd+WTk/Wxs5RGU2amff+9vt7/t5V71i/+X/SzFShzo5yVyjtSpZwCxLv//1/0X9QAJFhlVkYJAJSTjlk/4JdhUQYMeLJDWpAfXKAAoHSwa+DSBjGwFBl3R4uW7BRECECbqnpqmFpKnQnCwFjOqpqmA/4WEpRALgFU6P76uNE4hGadxpAwx/YnIIpIHlZlGLUo7UlV6HpmH5VBPZ7N+pFclV5sHbtqksxzUZh6XTNqckc5j8ZpbnZ3+XnSjlaX1aaQyCQPtb7W5j/aWYrYWb1js9nXpZbbl9PUpLXLMqjUavZZ3aW7fxt4W7GeVz7WWc1FaXGG8JdW12/rXdwzDN2mptWP5l+G95SyK5XKCO2Z672RCACAgIBEGC2mVXLHbPuDCwcuHZQCulIsxLVY5bAkOCIoLNwYTLrJQAZY7QclEAwHQZA+A5AzlUBoKwQ8tiFBBBbx6TgNAghBB0MRoGOSRcnWZSkQwXAfZ6xiDG0XQQIfpUEFE9MzJcz9OdbOd3O+P9TsEeKdDMzRoSILkhhfDSHoLAtMLJAZcKxzUzfEb55ZZILJdVtC+5J9DFZa27s0lYslaONnrDEY57Zu/xEhRGeE4xHT2Ay0gQIMGTvZ5o+4VILi3LLJlp3D3r73h26uzYiVtE1uJf+BGfvlcc+miPEc9Vh5oBjamUmyZgb9DkiqNfLeIIlCs0iVgkBbCyUDXFyQ3/+7JEDwAEml9W12FgCpMryv3sLAESFXtQbKUTCkSvammUoiC3SV0CWA+A8kbjsAh01UgQZIU+SEZHuTRV2/MjyrE9lL6p1KZfD8ltaoawq/OMp9xaaadzsj+EIa503uma4/ju+a57hr9jY7rZcSz7ZbGVKb1bebw+bSqVSUdPn1bUNSU9t28kEhdSx0RSDTzmwX0vBu+7u7qIPQLARSjiUxLNAMISIhows5QbQ1QCuopU/K5mx0rIG7OSuVA7MKg3MS5iCI7R2LNSnLTMmPbT6lr4dcNXs8TSREy5JhOaq1jnx0tTH2fUk3uJSiqjLJev8ylFOb37NnH0305upYzp9tXuaf0x03VMOpu2S97HrPgpNz7mPSRNWMhyJHJB6UR2RL6PMcg9Ro+5GYGAJOJKnsKcbZ0RDxhft5goOr4UOWyFyC8yEgqgKwzClrB4a4mw3eAdPLAaLNBYkBGfViuQvHGKxWxhcpFZ3KbhUcVjiqcphX0fFz2Po1VZiAagqYscMFhUZmKYHZPHEzkW1LrXun3uo0meF5moO1iKb64XeuontUrlTR03+l2smiKIY0WI6i5Yk4YLXAX736+8AwAAFFtN01hDfMOEI9IkAwiOISlThYRLcsiPFBQoEEL/htLFY7+QW8TPxkyLh8migD4BBapqxoHEQQXnhXSqsFXT6kszZq1lEDNJj3G6j6hqbLKD6G4GRTGRkz38n7cXy7+62t0kEk1AyoxsLc3HbdzMVVRayNuLeO3cyae5dKU5yCaEWDS6pWdRgsxNMeZWpVUAVHOdUh9PIFIws3OjMTESkFAAcBGUp5hQcNGAuE38DExQ2UX/+7JkEgwFJmLRk3lacmjrqv1gwodWnXM8LmkNgfudac2UinHAzhwMP+5KcwMAfl7KJTtUT/yh4hKxBWUe+MDfHnaceSZYRK6sOwdx58WVLNVEAcqGtWgiHmnyqpuTps6HExtzmV76qLKj3KH8sI/LV6inHvg2+n8Gz39urptXtdHVxtPFp3qGdRW315RLj+ifau6KtpgDbakjEpbdMbCy/j5zx/AFGQ0hGo2mqIqF7zAJA6EJGl73OYQ0lTNy5ZAL9uHTTc5MNAxOFDSWFnnJhA+ak9W4k3cooWzN4N5WMrTVUS+zaaPalME3t6XSq+lFvZjsh3NstDtnRpkK1H9ch2T87J4MWVowp09Bn1gCdaZpu0CGRhKZ+OhtpvGWCmYjJAFBBngLkIVMfB8y+CzDQbJsoTFUQEztOjlX1lJzHASmDOonkQShEQUaJLBr4HRCcF1wZhHhx4u3WAxYFFr1K4zLKNpUBz0o1lBEVoxDDINlKYQgu5QbMkBgjX1bHyKEHSpqRIqTWJSO4ltZEQ6SSnoY7ejm0U1xBAy6KMuinG8Flm9L40uYi1jakZlS+Bx8PatoLitPIyx4hlXlOcwL0VbAm7Y3TLUBCpYwDrGGkEAJAm2dl0TiKXI35KEotJmXttMqyKnj2DRJbIGSAFwSaBBjr2mWYJS6mJtilEbmijqsKK7EhvPG2flBx8HMvy0sRw6c20pM18zGMUurXFGbBsvVziLhpbpsx+1/t9ndtFl5amL41hrRPwmgcK7l7v18igAASTDSNyNggsw2hTdhHNbP0wIZjB4EBQUMcpoFEc6Yg0yY2KE4Eo3YshLmsWH9EEj/+7JkGIzFoV7Pm5pCcnjrOmNpY5pUHX1Gbb0UgeIYaQ2sJLkcLjiEgYYQWCKzJY6YsDlKdy8CoKIiyheQqAaBUa4wNOB8bspfGIicBMGoaJkBwgihBIOGvAw86AELeglq0tU5YupFhb9hN4hiAdDVXjiaqSkpJbhkXm2tgjk/3niV2Wx26r5p05N/G3KtxE301cylSE2VRoNQaj8h5iRY54r4rr307oALdk4EbG6UmtvOGqIAgh4Krcy0EAgCLXKXsTWAw1037tyx/kIo3JGeU8O0NyAExoOg123IrPPWdWicS+ufqZ1a3L6ldkN6UzDpi+oflLkmv/os4Djxl571XJyrNT8rlM7sc4xeUfy+/9X61/9kEiR6gdayspzhX/0Aht28xpwGncw9rA4ObmcGXgSA0tCYW2mJhAQFkgqYMrmECZhgUOgYOMQ5bepVBI9JtTu5bvw/cgJgA0EhFMVSRrEIqE8PGl9PYbt62M7l9Sx4o0KGXlsZBVTRQo8oeFWxp7WgmJxogtMjd1pJjYp5dSfmY84f83iCOUzJOH+QfDutzUzfYzxRYxtL9zUWVOWT8095cnoPHkplRfKm9kMcKgArSXGJKHMVkKA+SYxIYgVmJVOvZXyRIOMt8cmGmfBU6zJO4ImuMQ+wxqUD6hxRx1o0mis5PiUXRLSys1P9+3LZ3NZW6yXO5+zfvKht//xc2VeldJQYMbJVwnt4czE31/PWxY6XfYYKb//zxtNM3vem7z7lajhd/1UAJOzcERyvzDEM0QLAKcMD4gD39MqGhQTNTjCIxzAiR0pAEyBJSNxmCZSYKd8nv0VyW060Ej2XQLv/+7JkHIzEoVlSG3haYHzlmjNpg6QVyYtAbekpwaSU6U2mDhhmMbyKgwJZhWSCi3FxO9NlvRRi3IwjAvO3Z1Wa3MvUKH3BNNlu1/p0f1WkTT0kgom9kTLKMuaZUN55j5Pu+a9kffzpxPUuuLT4bFyrd1tpsIE5fOmnEJNyqlVVAkqSXpuEb0w2c8jU1wsxwkypISMEo1CectMHBSzgGCFAxbLKiIK7gqHQmO+6LOFOYPpmlJKTbwAmaXXOyHBPiX1itpbo+6x9GJsTYWIQ2pwgOWPe5tnmzLSHLBmCiFOMEHhnaAq2gvVW9cc09M3MkLb1CowwEAqlYTe57egAApycy90MUFgUqnBkZ9AWZ4Eg0bX+a2wGHhw4hNIBMx3MWyMSMFS5sCYNJqGLAqNGDFNqjHKuwQ0hsbSCIeohTxZgELvXpYRC6G9doIapcPkG+xM6SZ9/pjD9RXQUbb/mo+e1KEg8PoWLSYz+CH+F5bR+USzebUjW3CLfuo9dscQXF+WmZhvZRb5XO8vP7a3a/xKq6XhfVfHPu7SMw5ojPoo39b8Gpb4VlNOaRprCJkt3g80QE2u8KjAwmICQFEsRZYieaQ6+a40OzQ4CdZ9XncFoMJJZZDdS8nCwfTkd1uofTxGQFt/xDA2sX1y0K/Fz+hGJ4p8MGNUHYKhqKJJKE8KH5hwdWeh7chDvHvvF/P00QlS2ZX0KAKclvMijFqCEgMlXDaScGDwiBE+wovoSGmDxOShQYliwKSAYGCQsDNheGHhQHVxX2Z1AgztTAdgebUKJ5RIJMxoP1d7NRkize2olF9Wb9307N3c91UUHcHy0jJNUaOH/+7JkL4gEyVzRm29EUGdEWiNpg6IUoX9O7OGByhIvKqmEoaR6gPwjpatuGn8h5QbHq9djUxsLkih9VRlaS1SeEX1/Bc+tptz3aI3vlw1+OfMEEd4UhuDkUIlZd1y0gAopLpwnuhmlmmISiSIxoAygVp69kjgI6cAviSDXUZipsvZ/H/JlDtJ+uCzalt40bBWbi43lbfTQy1jb7YWDIjzDnYP03YfGOGDCx0m9jXi90zPUvVV+2zRf//Xz4s9hkaZWB3HlcgIFN2bYZma6OaJLoc0WkBEHmaiGqESxElVg4uttQgSDAWKoWMBIN7kNS6lLwZlnuO3cTGIwpMsZFiEjvNIXZwi9HM3csofcvBS3UpM/TMcWTfvbvPbp5Evs5M82r+Vlby3em2OFlITCq8zfbXpEQkRZJ8SDTbrOYUdlV98i9I6Z2rdZUcyfdu/JyY6ZvtwGFbTqYBAHFFGESyaXX4s32/6Hj8I4+ABBIABRRTsPA8q6SmSFCqayGtRiGguOWsnabTHBOasQEMTqbTWrl0MUn9LaEBrv+G7quffeK47oZL29/P9O7nz+QlbpRZ8c8PwncChnNpW4vbvAoZAoYh/MU7ln8lny8U6BwIhd0Ln7jAaGeWflnpRCnx6DQ7BeI4oOeXd3Fz4BAuIHT9cBGRuQccVuComiF4GQvm7KAKRqkf9VRkUjemISaCxMTHI/8te13ZsU1LnFtTf/WL4l/+tfePjO6fNbalPIbiyo8R2fwKoho5kPNk+xUFjEUt3ENIJ47s/NoXoYDhyO80c2jCGucM6vLU6ctxiXBJxXZPIrRbj/mBINGHtO0yLG34DteK3/+7JEQgQFSV9VGw9j8qyMCoJnDApREXlSrKTRwg0vK/T0oZD7yS1eoZwoOBEGs2ZP1hUEiyBEfrHWTg4dYcQjz18Zc9I5kMLKgEtQpcPBiSUTQAxIuEvkgCcZAS1kdBK36E0RFrdEg9iYhSldaIEYNld7F3dhdU/ndSW8/92Zm/TatJtaCJsmhGam0SxvHbLiyWyWVyer47ODjvrdWy4T9ptC+1R84Q36XpuYsfW+Zs3HAkmbSwSUlDtDLY8GjUBw5i14iEstny5g4SIDsESZWsLCt+EFED1aeNIPpOWxGfFc3XLbFVVW14HavXUR02N4iD/ZatCUiVQCMgzxkEsPqqMjg4gNaDA74SOROpBcsZPqga/OJL5HxXfhpj6+rqHl+v4/P8+ZdVnSyn7NQqX93UNyVqNIwuDCULgXUyCFSRHnudMJm7gjWhfr0Q8YhQUejtdHKcMaGowjj0RyjZ1S0mwlHpBdtwYOGK1/lutBDjRrEGCca491yJ4xPNd1AuholFypwhMEIpwDUIgGKaJNiCEZ0TgsSRSCNGSQ3CgySFoa3UjENC14w95ZrWpD9lOHPVKqykXjKozcwSCapiBlypJAsKAChIhaoLiKw80K2adPukb9Xxb+y/rzJM8V88TLLUdV+0paDViklPejRNNr6RZpsmCKzqIqapso0VIPw92KBMBAABVJAAQ7wPSWrDHHVieiOqfQINIGHq5Q4PG18aaChLYDyCNEWlPFEkgLHroPf1A/fUacujIhDsmiApdXXuOurUCOANm99fd6RmmZ47fNDVQLnt78/VEY749bfpLL2VRZ8uk0DT+tuaqQ/LZVzwz/+7JkOIAEtV7U6wxLImhLuv1hhT4R6XVRjL0Pwausq/2EifhXwXNXvhLyvOlVPqbTWl5pRqWOmBwbNaXQDPrdj1W5BsXk11Py0W+BLEvImgS0O5egxsVJAj1hQTVGuGLYeCSBkkk8dlhXQnLXinJ1+AkotheXIy0eJNaal17aoZ4iFhQp31uoKRt0uUdMe33dfo/VukqIzUd6k6ehXkf0yDuhqIjWLkEGNGh6zdBSslvWAYCAAf/AFJYXBWDQ0LvrRABo6KXqYup0t5h7NHQbLGGGvm8/1CxNHy/hyTKreKuWqzrKsxukVadtbz4zh/F3vVt01lxqp1mHBGSs6ns5Ro+mJpkhDSa8VjbU3la/GiL29Vx+9k0qNfYNmmqXgfHEkHatHAszas2rxa2l5Iqc5JscRJUwCo+7Nf3oiwUapsYBJBkaqqW/WRKJ/o8Q0LFRtUNBSnIq2GbUC8oAeaffHUAqRNpIx1+HFDXRv1Sqax+17VxZXojeSi1Urjd2pf9FUI7V1VZf2q6kfFNnI2fTqU3KkGKXVuntteqPm6dW/Sj0UrW7icgtlLm3jABAAAAUyBCAQj5ozNBCbQoCIxFJhSdVi22mJUPIp2wm4jVEY+wB2jgYzA+sssPSh0kGdL7QQ5sC+ETk0s6mTkw9Q9NjWPcUFWsaHos0DEEbohZ7VeSQ1rV8QVel9c15JpKxJ1DRYc/EpxlXBVPyVdYsbeMr/vi4vhx9ja+8OlxAqrHB0C6uVNIRPlAwEAtVGJOgzRcNUycTGC565akuaS/s5IYOjuTQMuLXUKymm2LkaoNebFymVGQxbPsiE6erIhwK1U/VCtL/+7JkY4QEVFzS4yxEMl8rOolhhXQQ8XlGTT0Jways63WEleWZPoxeQssui/szVxyE+XVubVLWM22pW1Nor5jPuWhxrJiUi28Bl2wOYQqMCeMylSeEYJW4xCh/gjBggC8OQV4e5Vgc0kyk5LqzFpjxncrgY6Eby9W7vVMXO+bWo2BhtZAqZqSK3xc4kZoFRMI3IgmToPPkQBVrwamxkslyMNby4+Lr7/KO128IYFrtm9qrmm6qfWWnn4v+p9bi4Gr6qtPox1sbiU1djncI9gR/ctDc10SVTbT+WBRIjD7DVFGgSFl6iz9MOXrC43HmGk4gB4iqs+YHo4i/T9Tc7KyUbmIatkfmqTmAYDTuYrlEHH2T93lcr0vuzy0a3Wt2Q93RlZnViOR1a5m3fqXpuXM7dtDGREFiUEsWKgBAEAAS3GkqAAISACpA1yUwJww4ZKowgMmVM3RrcoWEDgdE1sKqJcSC4YXA8A9hjiFRanWhchR+NU6wyEVttyFcuLm45aZ/JvVHWnKqNcslOXb9tX52A4UXB4P3qEHrLiUR4oQfiqrZHXiX5ZODW8fZvLeNkf7p+61I/tTIfj+amplL5oXfUYzA0FqOHC2PGu8cCjrBLq4HwnQgBGGiAi3ECGSbFTBoS9adCjaYixlPOyqrCRgqEEUdGAnWSIgftRTLrTjkxBdR3XidMcodGdw6urt7IrsYQOerD1QEQGek3TE1O7tV+39rOd8CDlauQwVWiWmSZqSqaRv9hs1uZZMdidAEIW4TcJARsQJwnBCFQ4oEjJSS9g8YSgMGJVwsZWdiBlgZIioCVkHE7KWCWTUoj3iISYzJRXP/+7JknIAE1GBR60xEYmboin1hIncSnXk+TT0PSasiJ8mmDhiDjKi3dM5p8RyjZHOrW4OFDkFxGYWmChFMHMCkVFbkXu8sBcw/Ak3Fiv8mdjP55xsXekR5P419GFfrqyTGqBKOrxyLp/HX9VP42JnLprm1HQLvcOLk3IyorNfsyJFBGABzWaMAeYeZc0CRpiB5bdYEGjlMgoOaG5arbThx+FRWQpDUAlAg+ugIbwemxEjxJ0N/VzPVbFRXHeLnnP4caWCkp0Fm0DiCZ38GBepPzv/71C0jfPhThJ//pRfiKSCw10oy8oeWcK1N6QIEADSSSUMSvAYAEDTWJh1CBhKsqRwjSKLr2V2CgCvoy3d9Gou7Kn7kzC+aj176HJvkZ6y8LFK4IB9dciEY4u4zvXWd15Q2/N1n0be1D40G8CCSsIQZuHdxlDk3Va6zsaUMvajfdqxJFsaCsd99oOh8JRD9IXtLriqhbul3yWIuxoeHzOluOQeqhh6QgTEttO9uczTugYABM2BkH50jnEIIlUVxQZCt4RGPiXLpiQlnL2uzKG8zjcB2+xSj5S6icVgQAKRYsKkrLV0NMHnYjW0lXUsT8Td9NYeBWI0vndVUPN3FlmeCaQ//1tdfbtrajdb1bvzM1/X/9ratcW0Oh8qPKGegTBgRq0sY2AhgVqsxlszBWNR0FDU0aKuxiSYS/H9cBJOIZtegca1fng5uwvldXvHbDCx0e1dSWZqzTj9W5cVgbh5xxZ0kiF6R7VRfzphWxw58/ZHdthS/tF3YVDEtRaYM2Uao6UXTroS22gnqTQWvYfshNH1UfQrU2RymcaVHRRcyizr/+7Jkw4AEqVzRU0lFMm6q+hllAqoRhXFJLDCxwc0c6WmEmfBYCi2g5gkZ3dYC0gAltoCJpjo1hRobMFgC8EtWY5LqzzuLwcpnEIa/bgwrNkNz5OrFOCqSaYYQMRKAAPW2gJI0dE68kAXDssXb66QKHn2CEEJCwHU258gSJGpTu4sxJApye2INU3sr/5n9/lGZQaT//+x92LA4WAYreo71VRiEAAkGGM4JKiKMNIOBVGdR1pKsyv2jJjuQm3VKIeiEfFUHQ7Lqo7XIEFXiecrlexnS5dLDRkZNyhL1LVlqUxemou7Z0YuRcP3c5Y+0RSxwg1RAiS2tjDFri86LH3ynVJjBR8XaT7qMXX54hNqjRKyL03aKIXupk94IqnFxdqQ8kPzAjFBojhyKi7i4yDc/xRvq/7ABewWiVIJZTVC1BxAqBZ5fVnCnVGlwwNaUrVUZDG2sRd7YLoYfgvKR2cKLv6laN5bAHKJWjJxw2j0NkFBYRNh8xaTaxdggITtVpM0wGwhZ/3w//pB4isR+qgznr197sUbUE2pCS1soTu5tj6eoeDM3RG+db57U5r7dQ7bG3N6C6YRjYbgEycQMRfnRuTKHmm7GnBcv2WHgWCKsKAg243cDLjavD6lLcYPdtn7kqUOEoA8zWYAh3+O5oPJPNnGnKq6D8wpaVGNWlxas9H32ixZv+rdXLmHDDnlF9HTxgiSCeDhd57OPexxS5cnVOYbcbQju6TT+zajUoJgT4UrWuhV3qWZaXLQO5DoVBb6tNGe41NAurnyq02PDBRIxwqGnadykwMi5uTAVBjYAAM8QAZm08XwFkC4yH1lDKNqpwKz/+7JE6QAEsGBRuyxDYpRr+npgya5R5XlJLKzRwkOs6SWUmrm5GyahpukLiUdahUiLzTtmxV1uDxQYsaSxXUFyukLkZ1R0fj9873Tuwy5Om1t/x3JJnHlw+IJUzjm817eMb/KCFTqJd8YtXL0g8IpU0uHpSLZKMTSx+K5NvxFskSTGuVT1lpRvaAYtClSbmVK7dIPp+jiIWvRG07+qAgABgAAEd2b+DGpJzwDrv6zYuCXFW0XIVXQmN1cWAmASIKEkO3hv+OdZOfEyKsS6eoEPYwdnUs13pZvebRbHNDqbuHp/g+ud+x7M0WzY5JLvS2mvlTxHRrb9J0Kizi6hW+UhijmS6V8mruwkxMim13+ZJDUe4ur/vL/uXmqZRp7EJ9TF2Wrj5XrUrnevwN6+2hj457qs/+USNteFpStIejO9AAJr4phMVOJRwYAEQIwY6KIEIm2ytqwbWncvupVRqAWZEZUnIfcdTLMRiwvGw77fOb5C3Zso2OV7x5CvzQYL7a/+N9YcrP/2KJhtxf3G+AcJla825Rf7Ir18NONudbvp8sZeTFfM0zHIZvdn7nn94moftjGo68FGPpovvG/nU35h62e6QMBFmA1ziNJAB4gCgIDJDJLs8bO6qlbMnfIoxCDH2L1y6PMpiAKB1KciPSOSjKwffBapypAsdeVIlp3xwm2+lvlLYnJ2kCxDnj5VyxqORIc/ZnJa5NRktv6bKH3mZVGvfhWzrc7yMz3S3Eknv6ArVwyXiYYrvWn9+Oa1SFKno2hIpvqOKXwrcptp/5682WqwyBgArwAAaRJmTrxgwMUJwcwioY8wUAS78SCgCilIWVz/+7Jk6wEE9VrQy3hgUIer6jlpJngSDXlDLeEhwjMu6CW2GeAG3Gszdh8XI0pn1/OGLrHHaN9hUOzx9jsaQWR0auG3+2+NKHmoFAIO2PPbZe5Z/GHtzkSteczezhqrllX62mYG6W4VZ04c+O6OtRz9OEWa0PpuRzaOwtAkz5mtKQSNKTK3iiOV1jmbt9PIwrZEtQAnAAAwAAnNhGrHmQBlIYjBigAaMrDtmBSgKiDTAVsiwV6UwFDABRqpAQofZGE3LhWvLJkeR898pndwXaXbglPZadYn0yaP6NX2q+VqIn6F4IvS8v4n0fwm2rSIthGhPdSzymSGuuyplSjlpoYSjTfXOHXeop2lJM1StxjDHu7KH4zedVyeRq8SSVjisFqtwV67R9OFlUGRzs3b1tSvpdqXoHBAGoABnTh9dx0HAdjMuHVTMYHjA8hYIVAinD4teqStSlD6lldHLaabsX7tXDUhpdfjb/sYajUprVJMoshpqLEMzImGxXamK4CD73ru933DiDoJtVK0lLwU151kTLlYVWzgh6f+MNHEAu+wPQ8SAhyql2AypBPr3ZhXCMIREiHaDV1IAFEAAAC3TLmJTQsPmHB67DPAwBAocqmIiAoHF3xoCSzR3FhFr0FOGla86EZYCz4ePlZ0Xx0F/1pK5nB+f/zk8VrDla1kSld6WYPxK1SQocWQIKoMdDd4fgXfxVkjk61cf1QNhTQk4dKnXyKCG/j9QWqT2dXn2PlXrGczi9j4Kuv75lbioes1h0oPosFoeTqYOcRGoJpfDnPCAZAyZTObnDkrASTzFz4kC0eC2Q6WJ1mHh5atR5PuA2evUXH/+7Bk8IAVC17PY09LQoNK+flow8QTGWlBzbEPQi4sptm2GflKwFQODlRepLqEc2Kh+TYdajaoeBvRpCTFKrhk9aa/WD3vn8pT7Yq8mqvzv7JtNJmvPt87sO3Ss18LZEi/d63/upqdJfBxMUY52mb0UPZzszlq1q2dfH9f60tZRpqt+Sqsr7BS+EHZTBAwCZb5GeIJVIzMTkzWDBx6PDioABJaGcQ4ZAVJQYYzOJR83BIcW2n2j+jZJsGsDmHA8DyAkKhfdspvEKMyQtICPFzTSyGfLEMdFTH8XznNsWz2Euo1s2cvmVNn8KQVua0cQ02z73YVP7PIanIYW4s5q+XeMPnp5otFxV8LcUsx7moUdZ7Gpqyovir4e3NrX9lqit/r5aKeh65eKtnmJQmjbIATruv/XxQMUJiaSKLERw8pI40AOED0RYQAhgoPC5GJrMRmUg8LE7Q9L3ghLpIqa4uvZYVj0NzqDkVoZZ9+p27zsY5GZRYtSu53EyMDs7Wd6noiKt0WjC1CDqWVnT77I93oHmdbGNFjMUSA9xVYo9y7LzNekNqSFRmjpia5PGGGJgIILAZyaKYWNAg5bJtVsqBMBKOF+xGCW4pgCoZj6sSq4GATYXwuC87whGRIEEog0PoTVxx6AKasl445Q0fM0/Tw6p5+5bDmBA2K7FR4PnI5+N/Lk5KaJwDP5AuSLduXTuW7fsun0edeOKWlL07z859e1SYQTVfenUhdlhik49NcKaKZ+zXUt+QZPeeKbchsO9Pv1u2PzVLrldmJF4OSQwFa5QAKgOBGFQ4cJOoJDYCoyslbKkelAGEBMAGFlxhQqz8eB//7smTzCQVGWk0reWFidAh5+mmFXBURbzIt5YWCEC1mobSKIAwbJQMKgQyBxB9H4Xwm4WZNMtiACDhMyTkGYSrPs84llaCHuYrhrMj1JUoQOUIc91PlDpdmeDH2FjMiNuHEshglVd+dmEIiEBUId2BiHLIdstsW0Ubf17Pc9fZEvYEIVY1bOuoDAAAhMzwQzULxkSGASKZKExg0GAAAAQCkIMaEQ3hDwp+Y5IqLsxyjfAUjL1NUE15cM3HbMPzLglArqfyNWrvKjN5urXh2MIHFJiKYOr06/OMq1ONsXdUFtRMxPqtDsxcW1GCmZVp3dXHau7a17rNdaVzUfZL6KctaeYemiN2PLObzEW/rBx0zK+dfpScjr19bn6W7XF9OQ4j2/S9n+TLbYz3vgj7dxj0GIbkQAsEWVVwaSNzXOofMUJHmzA2eraMOUUkYoygOVvBI0BAHxfpchGCwLiMUFDM19LlBWFj3EO7+pDs4ZtRqV0mz+gvoptZCiYOmMvMUthQlR4yq22fk3q1Gbt+c+ia1aoe6Zlt113p91JdNzHM7qOZ52bFfQdMzGo/J/sSa3YHsIwGVTEBw0JMFSoOazJQIwoMIk0ykpATEYgJGLjpt4qaYiojgU3pCxg0AJiHXQAFp9KorTLKIiMDdYDETuVYYXm8phGc+nlq33XWDSvcdw1N5HfRTXkaThA1jqZq7a20NShgjPE6EhEUDlDnFEIQcpiBDwT6DYDIinXIjzILgZD2G5F8QgMwFoykHONgNw+iViYM5vnG2SqdR7JQlX9O1tJ+OCkTkFXuSmYHBXqfL9umi3V68oINLqxRz0l08rAj21v/7smT1hAVcX0zDmWJwcyvZ2Wkleh9xgzIN4e+KjqQotaeN+GHEh3keeWGsQ7QWWse3eU8ea95WaJeWFal7zWj3kynMt82B+5+RnEfVVpWh2//HAAgACBqSNNRFg3tc0ssOPmUEGEBMpXGrakWs9mCVkrU3awzhrZby5ljjCyIaCnMbbUdDg5KzKIRl3B+3OMrPLEupzLRzoM8BPJvUt5kOlWrGQ30u1mmsJ9DkMGWAAxRnIpSWOo6cZWeaRTlcYDVw5gakQtGTlOCLgAAwMWES6Ut4DKCA+TuzgANkcIFPgBVE+QqTEiaiAXDghkoHFA2UFkMgOAIA5NxRy6RpujkDwZewoMJC5I4oA1TNFAP+j2JPFFBBIvOK/BFsBGWwR+AukLTKvb4yUEFWpDBIeLqQliLIlZcToDqDVFwF2OUqiMh0iEBfAGyEp1TvYDWwqW0r1WMr0MFxbo6eTyqtVrWXDOhJlSii5xH3uIosS7Mlvfdr/1U/2309jNJzXevkFy/x13/nd8/+PsP98vGPZNNozHs4ZpAgr+DJdK2d0mCcEyi7K42ll4AQ0UmFhRGSw84GT/rgxj0RL/ssC4revZM1D3XaWfMCIatZZE/TKJAtw1YrS8F0cFeuSnVcj1vT6rt1Ap4UaK5U+0ZmmZIV8OYnkadi+86j38J4/7v+9J3fR7oufQREtLQREeCJ+k3+nTfT8p+hffTDn2FvvoACPwgQGwMO5h3d0ghAxXp+bupwAASlDMwoTYTIxM04nEw9CpAMQBYQnB0JMLyAwQYiNpavIvcwsILLTLW1LEpFn1XDR5cyZtQy1mc22N5qgKkxKArS0f/7smS+AAU7XFbrDzP4kSvKzWXjf1WRjUptpZfCP6/rKYQmeCkBES3qxtbe3V2uBw9d9AZ5Nf/n/6ObpwMTxLUEPXQUkj++CylUrew6DfiiX6GGKlw8ZtAg3rkyZjS4zKoEN7JVi7I3faSrVo1i6ASK7NVE1czsUJgIa2yYJ86BpTkl8mKP56vzre2uFAgAECakt3ITGxIjSCmrIWELbJBN2l8pTAhLksRXDjOzy9Ytbghmsf0MHO9sFmiSgVmsDhl3eKCeIEERpmkrglf6mBIHddVHLK6C4o/o1/7Z9+tTo0DOaujOXureidhPG1f4ycm+VVO37JGY2iBWHUM19LopXMAx6cFYUsinqi4iEuYk9r0rurprRm1GqiLHFwQAIOIlgg+cUGYrEbRE4IOEI3l7l+k1XNOct4pYGAkv3DLyF4Ep11NCSWg6kuuy5t2jm4iRMPmpmUWCImgvdWalUzV31c8+1vnkvoUnUKjGMftIWiOnxbTQqsoB1k4+WbqHxZAjlDv7hXU1SAwac51FWkZxj9XSa7TK8LJRrDItKbKgMM4qsENNoqKp/WgIQAH6FwZGEikP5jFE0K8UqkbHYHmbSoEkFhWgPxMsgYq1p83vDQfnmySI6akKytS+g0HpNKxbjdbRvXIDtjgFnYAEk1o6DFGn/H8//v0pI43doiSs06G/s1eG/73Pb+z//j0jaOt31ysjNvzTxjn4nv9OX3m5bH5eZb+Y3cLEpWoEpDg3QUEvb1AMAG5Y5SpUcogmUbxAKCR2TCLmLnQtlqZTtIhK8fCgd1oLJ3shIqDiPhUHlD6ZwIYqatBKCaGrzFx/j5Vbuv/7skSrBMRuWtO7SR1SigtauWWGh1C1d1VMpRDCUi8qSaYiZdw4U5pqDRgKSkiH+sfB0F82NGmis46Yb9Rg/XZI7h9SoTnhi47i+pWuorrXXs76e1mSBqazJiZZkVF40eSIlqLD9uoY1x/iwdUmORAsNM0bWFAzZrzPQgUBRZEFgRSaBhIOUdcN8ErWAvkpy4i+pHZxEEuFY8bDgj3SlFh6JhMVsZisoLVuODyGsnc7AZuqo59qpINw+S9Ui0EbWyfo3oWUZ3bVPNiNUWUNm3NRhUVLZh9WcHdMrXxI6ZoYNlm6Hj3bqrpJhaiOZHLYrDXHdmkhRog4rd4g7OqpvfYAmTHdE0ImETSZc2mKAAKS3BMABzFlExsLS6MWDAg7MRQSYflKOxhoaAitfKGgYHq7vPFYEQKpetiMMLUcmbrAUm46D5ISg7pQlMPLG69CdV9g1SMJ87ySh1g0WHnud3J2b4KH1HA7nu7c8iJFiuVFfGD4u2fQPO4ao40rVm1Stcfwze2+31KzVysXGYsuhVQHAN+SUHww6unYsJAAAXv9roFDYAh0LiCQxYDEAK04XTTiHNmzutxWnvUOu80GoH13bQGVD/mEarFSaE8EVb+ezptSl+RumVFLqlWJwUBRzzGtF2NNSjI9MLspNqFFnc5lz/n/9NsWUwnlNIAVq/SmLH/3DufIVuy5a6K07xfyEowwJ4OIJUaDbLM/ERMfLQcNCMmLfHmham5moGaiPmiC4JFqQGhZlIUYCBCQCTGJhAQKlMja/MBQLTZeJjiTshY/NPIUCUBoScAI4jDwlPUMorcVWLP7/7KEZv5ZQ9YKyBySKf/7smS5jkTUXtETaUWQdKZKumUtilQteUBtpRaBvh6pzaWOoHGaMOZRf4Jemw66m/pkpIuPhvar67uA7oi2PbyZMx0Xuv4iv5NfpWvUxdrajr9LaQ9daJFj3gsUeoGv1P6ACrbJBUgY02YnUl8ZoGCABgwTorFXDEhEKYgVQCbJaK46qlaOjXY7RMfmt5xVmWXlRNo+ssVscVB/7uLW1Th2OkPVK4/qd4ABbaUIRDGz4ObMxN5LHppdCUvVUP/KFzYUWUtlTRsXcWI/MJEXjXJuABVkvMOzCVZBcPIWNqUQ8SjEYdrILtO8ZgnPmJdIJVwqKgIwDlkeRgHQpCTVHFKyVKw8PuYtF8WpTSfi3q4iVEoqSDzJnU5fHCxTLJY3kkKkPFh2Hwyr5d8pdIhc9KSFcpExKjRd13FntCut759RTa++XRVtfdSec3PnrnfFRaa2ZTP8ac2vGrHbonqH65QaskySdozHBsHFUlbFhoAqWzdwzfiN+UCtjCwyoICExEnHspyRsoAX2HCFHs7LF/A4hC9ylkKfg3tCoI1ScrJhfKd1JkeeEmfdSZHLKrOP5UQXex9ACy0dtQ/W5l1ddLLV5lztX3Z8q88okCJaMfHv3QZXl1BBCXsiqHjp6wU/3AYAE223iVE8zIw9g8Gw/Z0wJhKgxgsGXCyS0R5ORSTJqUJSw6ZAECl3S+S60ylUU4olphqEp44EbC3eeuLSg/StlAXsoXKLJOrixv3cerPIcDvTloqgTNWHYWIptCv/ZXfvrupvLmu9mLKezHeNynTRmOZfW5NaJDqFrxpm0H6M7HHO1OstnVEQurK85kiIYeUcSv/7smTRBETqXlGbSV2gcacqY2WHohNleUlNMLdBqZfqKZwseA4zXFDiJcWqAwBT++3T0PJkeEO8cCtTrAszAVBuQ6CmGQtdVqBw55pyYi+SgWKnUKlGSa4fCMkoF5mioiRCII9PvMriDI8rep6stv+bTIA61BRC9dqt63FczH12o0OhJsqsnOB0z00pWxGOdosrfVvMOXUAAkpU0OWDKDLMELQ183Dqg4MDlMDDUQj4xSqDUgsCBJ2hBzCRtoItJVMCQxtxpxwplRxE3ChEYIMGYbKQoFAysYEwAmWnW/FCzZZ1O0mCWjNlkkehmKigZCo1g6sHQ9OMubEAPwWGyMEYxQ0gxMevoK3Q0GI5FxWZGFOpbLNqZcTU+8J6x6XU2OnGNd46KkgP/+PW/lK67uHfSL7UdFcKuLFnWLBAS7zE8jgyI5JfaCCnZcBSA7sJACQdaAGMogVOUzyJEQAl83oAKSTTjgwkUdZUNy9A04QxY51lVmuQuxBpbWJJQwVTpxXeXqOAbErpFqUfb6ANjAOGu5RFY0IoWjK8Faqlx6tj2oqOq3ybHbMNQe1UqQyVdtRFUpqyPZ+2qIXIV6J5KiFiFZsWUVcUIQrf0CBJTa7i2g9bIAxjYJ22MsVLZhUiIgIupsmXIGJDFhog+8qT5gQRfxLlLJQYdEPlcmWsqTU7kThus9k2vh7vIBGKAwIzghw9HJWWwQt9t+492f9ozQrhTMVs/9fjS56pEi0Y2s2yrdLMdq+XBe/2i/5N7JZjCDu5//KLrfRL/2/paXYvdirZm77TKndCUX7Ndnpd2Cwv/VHCdOYvpABlinEQObocGdbRx//7smTuBMV9Xk8bmkJwhEq6I28lXBN9cUjtJNcB8q0ozbWW2JcFyEACRVAzFAJUZWH0AIMA4XVjMWAw5AexK0FC6t5fhoDS0YZzjdXyTnVDBD1w5jEbEfJrnpANNu5L/13RdpcSSnTXU3iCLLLLq1Y2vgBHLqtVRGSUerIamvZKL+qf3//3//79rarGNRij4dmjvZ0qAk31/AIAAJwDMFT5vCJKWR+L4rwQGywYMkQIZAsyYbGVEE2EKVCGsxZq1u6+skUfp7RuG3BxaFC2HzH9zh0V0ZP0FZHRLgkQ0Y9DR1WC2aVhe8dRhfAe+4nIrcYONhaqSJfSJFz5OqbIRFI5cqJiu0hovszStOXPfvIUtx1pXA1xh58VuPhfcOwb3Ut9zcliCGJDakAAqJQx8NOoXDMpM3KvNOYzCg0GAojBDBxg0gTXCZkZB0cW7BRYg8nKNVE+o9i5gwJDppkhdOHAUsqCWcy9DJ5/GHS6anojEazco9OVEASuIQIzB6DPY0ZVvmJIRnGcTG7yhmYnAyq9BQwUW3iHLYkpBlKykDUu4BoIiGOkDRcdbu0jyKrtYHcu6cJUK84d3l3Vxu7CgokpJYPnigNFEcypLP3GGWWV8z75jwE7pL0bTOpAYsBCc6rLYQESEQTvPLCEM11BV+GPQUofL2rJsQM3NqNi7KWbNJe+pfeXCAqLFqOaNJPuls92pW97fvo4XdLxAYGUSqTaCOTOnHGJFE5HQa27gbAcqIiqq2dVJSdKvh4TqlHq6jjhBGKBAQqZseQTUmSMbMgVbggnBmm6JJ4pxvwSEJowgSdEeDJptAuDgfCafLRCMbMuJ//7skTvDMSiXdObTEUgqsvqE28IalXNl05tJZfKu7BqTZexoWmmUMj8jYW39/G56f2OZIE3tbutwVhUqMgs6ZkGGHqHDI9DLDDBRHQSszQKIGCF2LGqkGdyy3SwDeKrW2Zb6Sdda3DCXYMdluKksrmH52+ZZvvm14SSBBpvapqRMIiFpPFAeQ1Li9J3wJyjAwWb1t6XX2V0O/Sttuwma1e5x+ywiXolk8vVrTd+SxtHSpdw/gXr2jhtef15Q+ijoyNRgWFsOLRKeZus0liATVkCwY39paucaWFv+fdvps3cRAVqGuRyEUCmA4qBhAxncEk21LrgKKJfDQ0DNGKEUsIaSbEnLOW6pFN+bjdWGGDtwv2AuF+QQiRD3LKBuIqhPV1I4owdvdMDp7d0VIRpV7mrsJyoDoLt7iDTqfWU1+pQzW1uWOv2G32vI0muK+ai50+6/R7244uffpmPj6+WObGhaKIFj6y6eIFjzHzvQI44hTbYAj+HBZnuYSs5SNTzVM9CXFlCWMB2ASIT6pMWld1r6bGTFkoycHs3jSQ51A7r+KHmVQwq3ZFQWe4vnCZHQq6coDDBaQWRhKPYWOKG9Toej6quT3XXqtk22NlLQ3euY+Yw/Z9bKYQBmUOB8e0WPAs0YZ0utrGFAmGGtm4MfjDZoU+hQBb4wQDMJGB4bixhogEJJjICCiCMp/jgARBCIDRw4DHA1FuK07kKIralkEO21K5IZDWERCFhhYYZQyJFpwUVG2XjdmQboLiJQgCI6+NRMJ8qmUTAUtBvGDQxkpVQ61REQd2PjBN7maURI8p/NR6UPmd2RbIYc1xS25IRCiuHhP/7smTIDARVXlMTWEFweOtqumGFXRKJe0ZNpLZB3yxq6ZQLFVm1ag57IiaoByRFXWyC3aBXQ5mGJonKAJjIjxlFny3CtbSUz57KDp9ZzU7j0QfJfoco9IvaQ8/09ughN+ltJeS+fzoOfzB/OdU0dEHRKkjQq8c196qKr50MBirmY3VTtmS83Mr2VWr9dW1t2zWqpKuM698JV1aYJLCyya4Lbv/aANjJKY2FicYFPBkMOGAYKBQw7Q4GBwOuGyUmCKIg4HRAAakhCAyXZFgApyjgmKUBOJZuQ27hOZBU9LqyynNuPQ7OpC87hSPb//JerWNy0ZXhQNWq7aDywrPTRi+rT1zKUnMOn5rK+vd88coniz2v1i4R+U+F8Onqq6mfihPqV13JWMvMslpTh0GAjHGCfA6Vv9BvAI4HiXYKup0JEYOPmAkBkAKWjSLaTGTJSsWJhEBBgABjB1GCl9VYCIWkpVDIGdyXNVQ8JAZ5tM8TZtwHJ7Q2RLQG2m7jxoNdKGROQQtZvVe6OoaHguUW3zR+t1ka4Nq3nMpmMj2b198Sujvq1b7u8yeXUj6aqtaGys+ryibQ1H62uAIhGEABGYBkmDiiGaKdm/U7GMovBgqGJoNmKxHGGIElvDZ3j51DJYjckkjRw8Y1WEdhUSGZjPoQQWDsTstYBgAz5SIlARE5ykmIiYUUNIIIcF0Vzyl/GMMubU+ANWa4qcHyehkx+j0yzCBL5gf/dInyq0kWLv+0mivOdM36nOMpP78W8la/tU/LVd2glF/ht+Xzdy4dOG71sy1J/3cfVXH5J312+VEL7JZpamhdL0jjiYifkugAJtpQlP/7smTnjMSNWtGbjB3CgwraIm1itlatdzhO6SnCPC1oDbyhOFTdS8x57PnVAYfGNpYqCkBgpmREcEHgo35dt6hAnRIlwk5E1bGvCpkbeasoeWnHDHkxfVM6VyFz27x+vy00HO32wHRlCPcVQjVjA/SbGTwwDxPmrfOfLyVcSp6840rvnGtbqV0TTx60bj9qVIL/qdYY6e59nNqY1//mvRvglv2ukstIGj9Ty67l6xACObfbpzHDFGBZGJvn37gAK3EEAxYux6MiIKChzRCYBPy5CJdSx6NkDPJjswKATIKk6YKDI9jDDBqIyPiAXVtyr8zWNM9LPb6xe500Tx+NBtT7Wt0/sUhlj3QpKghxzQXwkljHVAbUsTewwW0eLGhVTd2vtnvGz/X66yzX91xxc0saM3HHjz2iGmsY0Su7OgBKWS9QE4jYxD4FtgAFCgsaIIor1IgXDFjxYKIgqQQ1GfuHlDE0R4Q7sD017N8YivpqFlsso+UUclmTIAWV/DJsQe3WRt0mToAzozpKytQaOnVfKiqSZKGt/728VRKUe6TOzayt3SpVShO3YvK7oYhWKyqJCVAKp6gAY5JjAh0ezDCEY3cnPeVgMCkxkDD4yYADBR1B5SPJ6eDStcJSghD8phhgCBrPCiERepDgnmhzhl4MW9kowNmsyWQnER4HiCciAnqm0RSoIYfZFXbVkb1mKaNpMMw6qVOKkmftwv9Vvdht3OlLVqWebb/klfWMeB2EvOv0269bH/1W3LMtmeetv7H7f8arGL+rt8ZMw1NldkRadnn8Jc4AA226AhI0O/M1IDQU0MnSF+MPBTNi0LggkBU5nP/7smTihMSCXFM7TETQeItaQ2kFshPtaUBt4SmKRKunjbeW2BgClEAERjAqaAUeLArXiY+DlWnEYzDrNplN9XylxEMQSMAZECWKkH0qStNDDNu350Zu9QX7RrO76+JNZ1jeN8mOJJqPqZiUzvZjIRWN4KUhJaCYsepcyvl56oY+vmdqlTdFlSv9OUuqVtsyConSHaNHQyliagAXddwKQmbowwSGWlB9p4YwlBYMFhoAkhMGLsFQcwoTKoQFwAxQDsiQCF0wHwGxIZaCDhxguAjBrB8QWrFQLhLEFkFUTBPlonjEdRYOMojlVoGtnSaozWhrTdRHJnHvUyy7dAirMu1klqZzZ1JMszWaG7tMDhg2ZVsukZFRqCS2WeWyZ1L1vWeTqdeqtbO5mylUi10HUovGiaj5ySJjWQFKt5IAGS28CFxIqjB8dCzH1oBpAgYCJipGDRQmDWGGKBZiwCHCgkDGGgCwqeIOADwQ6QG8wiAKoJUI4DvBtpoF7yUSEDl8nRskeTpgRZEfJYLynK6WZqUi5fbW5o9ZfSUUWc+cVvMXcyLrVnUedQdM/UbmpmjpGa6CkLLaiYm9IyUy1PrRn1mZtzy7oItVe93TRrXN1VGiT2QrKCJqk5UMFLRd828b7gACAAAGB0KhmuBkuTGzGCUx43M3ITdUgy5RMgqzBgEOGAUMmACAsPCIKflDYLAgKExY3RUE2AMFBsfDLgGqwXRBEIEgh+whcL7E2AAIL4DdD0SeD2RSI2B9EqOAi4DRBC4xBrrHyWUxojDGYHMIoEnhYsACEMtkOL5TNiJG6ShYBzyfEpihgUABE4YsFIA4IAxjy//7skTtAAUYWdEdbiAApAvKE63IACOiD025uYAMeEHoXzmAATMvGpdWOAR4R5EyJqYCJwwaIIhtQoIZwWBy9OoIny4yCDIpE4VDdhYhZA8hiUNVCzQxSJUSKZ0lUVVG1aJgiXyfUgpCX0g9YOlFqF4RhLEVFvC4AYAnplN0f8nCKGJuT5kXCcWmbqbDfQ9QRyKWJwZoX4jsghABBQsClCQGb/////////5uaaGR5QABtBcPxeNg2DDbCNBnUBFA9irjBKkMPHkGBEHBgx6BTBgYMoB0qB8xUDSyJlAQmCgmGAdEEE/BDzMweihcIWBADaJuCui7ahhBIxtAqWBrCPKv9kkZcJ9l7Jdr6YIJFaGoC8PU9pU0CLyo3tNawxaGjgVGkx6HoZpG+cuCo5NULBC5adb94PpBlLclUVhyrL4IeChgR+qzLDu0zhQrXQ5ECYSrV3HG1KLMsmqWbm71yB4rb767F2QI1hrk592G91q/O47wxnpLP5cs3K2NpFNr99343fnWVtu77W8Pvf+ePP////5hjvfa39////deHIYij/w/bcS98vywl9T/////////////////////////////////////wsZvkfoRAyOHU1RVRWZyuSSyXa7dDMW0KBRrIQorGsL+sPa6spm5mSBsIHiISiqVzILKIWbwXqpDMDwOlFI8w0IF+rV4TFOH4JpoeY6kOME6ETETZvLuyEM6CcFYdKliF0ZEg6dLzQxMjWhUFeTzctMDG3u08hrXI0L8VOYY9S2epV9mGzseWaIztT59FdKVTRvAvFvJVSs71SPWvECG0x3BTRnsRf3aaE3pCP/7skRTgAa3Zlp+YeAA1uw6tc08ABK1e12dhgAKSi9rs7CQAMzTSP7wILxqixszwnC26Mqibr3b2VhYdXrSNTW4s2oULGra1/uKt6UbXj03u+rR6CISASDlQUZeAQHDDlS9i2lNklDKIVcGABLeTUamkYlszNjAGtIuAG4pzFBdALwkgYzAiEU8SRCDKOYlw2F2k1ezKpDjgICS8ziZsRxHGSGGrsTlY1KhCzvYk+dS0bp5KlSm8wKtkQpVTnoEqlNM0lCzJRdqZjYXNOpxUyL720Zua4StVTIfrAh7ZDVjnHgz7fMr2LR+2zRtzNKqZm1/6sqeisMaDSDesGFe15Xi8/g08mJLRnS1F1S7ayaboG5I8NirnMZizi1/n1h2+6QSZVd4KKYxH+q1gExIIAAAyGLTkGWlha8C0SPStqUTzLre94HtcSVrooSx2aFR2kOlZ8mRq4EdT11nY8ZQ+ZO3fSK7NxNfal1dq+40r+vN0zl0EU45zla1tXnn6y3vJIkzvsLttkFNnZtHTWfpTcretPvN7flmfrlL7u2t1LzDBaszD79lk3vletttu07TNpaBm7yy18mfnHLd2/8N3K0oCGNgkAACgpFpOwQxEE1VyI6BBd6WSQyplam9WAXe9bADJQygEKBoLAHNE2H5HmirCisVTyUIrMuQI04IZXBbS686cdYYVuCNJpeMa0+3BmpwZky+NQp2yjetutbV/cIekcYXi19Z2VHYdOWXSOTFQnUo/+a/h5Xu7f3f4LvypZbcWshKZIpVdBsqr36Y1/Gk3SFEWWSIyoA/CsSiqO5ASGkP2NMdSub5TFdDE1LVuuw4M//7skQQABSIXthjBkVSkGva/GGGTlIRd12sMMtKIq9r8YYZmDAcviTrS7WMn5UzqGkCROFa6XVJEQYdaJ9dFOywREiRJE9Jq8GFtZvv58TsuU8XkxsFvfK3l6wiYtcqsHXRFVmTd2bLbS0ppSLxY6q4YiDTUNuMWQdcKYPWLpzdXIHhYXIcWP44eyhgqRSjAuwnZS3noMeSiKgAErOtAlAGHEcG7KLF6E6k1gOh2bE4IQzcKoSmBPJRPM9XmyA8tWOVWK4Pdq/WO60Qi0VmM+48JBBhxMx3IT0C8QkqkpmOHqDh5iOl5p7yfNL5DX83Rx8Lcw2HIEe8K30RjCisfTGR0qe+Kx2/fzmVOJPT1/S4mvf92nihbag+XsWdPNa8Md1Za08bk4rrZKhAAACawh+XdLZGFL0wElQmFTSpE5oAoMhpwK7xD6QC9zJkcMwMrhrXVPWnSpIoHhZMSuCV0kKkRpenQ2hXJKKXCZbpQjL46tp7iqUgp0TpKTaj0mAjYm4T2ord0GraMTlAqD/lVaJ1ImuS3ZjWstv69Z59/znn6Z/b/S21cHFYeX/kI4CshuA7c0D7zcgmWIKQBYICSzsBCLJwE2ZfTEpBMqGo3MpccJgWEU2MTMHDpVZIJxMxlogR0TXzSPiDyKJ5X1R3W71fLkK6tOPwmfVuRVlahSLyZsfPJ7FHxFFTyo0+cyGKRytmXOKU6G8xv3xHUUr943d38ottZLtnavm1OYzdnbcdEfhaeVH3LS9qe1qGoj6FJHcZKEAAFKx5yi5IIGGY2Civct4eIbhIAUowDiPPtVEAoHZYSkECJpxBEataiTxkm2nVEP/7skQaAQRgWlbjDzIyiyua3GHmHlC1eVlsGHPKICjrOYYZKHa2tickoSVuuiWc9nj/ITRY84vmEki0AIIIyt8yCcZZBFtFNZPoMvpbrPJyUkiS8MJFCd25fzSzJ82pkNWlKHy3Z2tGc/3tW+tn5D4eggnzoBgwVwvz/9qAMxFMKAASBSI7ITSgBYNmUBnXQjCHiOCOnBDQLyzUhawj2BSK1kOReQQgH6blnQpWgEtPbk6JOojoZA/M5sFRdwpckoTWfEmLRpVuSSJonpY6c+BDwSaIRzY6fzMONVNyZuESz0tZdz5QMOd3i76V1HYgkzOVOftvdt/x2xO8NtJNf9YjpqRVzjL4kCpxoii8VBFUUyjGOYIhpaxVWmWpXLXWsqrNVlww1LsnIcOkvWzt2ESVL3FoF5+Q6lhO0k5H9J4h4h/0jatkrNubOxpBbSPQOM0MespE9PrQS1w3uUEUYecJzN3udMZKcCBUBRVEFk4pyVNTEqTCkYmeBcSuv8/kDA0cidtdKw7IYuVe+FLASFCQROAABXaDaCqQ7wVG0l2FNX9T5Uhw6BYKgLlQ/P0ZwVH17xsVzWE8LJ5MJcieevH5H5w9lOUaYSIt5U+TppB0mkkW0TQt2cAMgmRAJdjCsK5zW6JsSEqZEMN17ejC53Ff39z/GQTxspc38y5jXKtK8dGW840+nZB0Y8ClIfa9ASNMFqpZaFkrSkKRBLseDmlQbtjxHWGqI+JotJe4u63NNOG3NvR+jkUXuxPlygHkAYaicPJ2FVFvEs1FLJQdOIJccebRwZUkyL0x6jFQj64E8czdu6Q7XVVpJib42YWRWoM/Qv/7sEQvABQtWVfrBhzCf+k63GDDjlCxd12sJG9KECyq8YSN2Wi7A8xeMQg8jksQSMa1Y7BDedKpIjHnaZghJmGWBHV5NS2CUDrw29UBJtMuBAHZ+iKIggYY0xmT9qHJOxWypUwlU7hPfK61+GJNLwqC0AGMEklLpSCa9PN7Eqe3prpkJvCYZyk41C/U58ruVMaYujU7xitraOSp3ROHMuC7cUphLkcrfqZsZobDqzb7lKRMQpG5WpGBq4k0qpWsc2uxXwJtW/Uz6Wf9qIxuJtNEglS0AeMqnL+kz3sVVQ5KnZPPJfIuRB0o/7zAxo+CwXPsdW7iZgai5rVEmaqzWSba1WbPRKOcMFkgJzCFUaEHWyktYSM6seUJ1HMQJhcQQcTgaNijVaR1wyrgirpQRCjLJ+MCE/ABFqOjEwZn6TEQmutIEoMAY3FHJMeUM26qiiqgIg0IwAiYEaWDEZStbckUGVphqM326sKqzLpSt0DBnh4XHcNnQItE5JNclNP0ErXFIokFQgJ44dUDcAiwrubVHCmHEgqOMTQKASjGwsEzsJUYEDIgZnvW2ywKyvNjg04zKIwpgToVcTwMqxkJsgdLZ1Olgvb1zBPgapyVDZBZepf/+upAQmVstAgAKNZEhJtsLFi7Yc3JTdcXWctYeB9X+iTDGuw68VE6U5hNk7LQOAZIUCJPNHl6MHIdXjuvD2PQNoUROSMQ+ue1NWbBibWI+knCVzI2Yw5h791cuFZk5UpIeRl8Rue5I2VpjeGp69R4Ztoa5bBawYEuXLEgSbcq0nVady7I/rIAluInUODWkTELyqWrCqbrfnmwKBNEvPjA//uyRE6ABAVYVmsGHMKCy8q5YMOaEAmDWawwbQIKrOrxhg34EOQLVtchdHTVwcAlaSk0oxe6deQLsjz0UO8KiTwytYnpu9y0EMPzJpbWReoZyEnYTEFJxKC8Sw/VHcYt6xo8lLVcqanFK68ExYeERyUK8Ns0Sk7lxSD0MGgIMYy3meNcYkw/QoKzLYbfRISIBCViglgYOXIAUm4KwvQxJi11HpYiN6JhFqLTah4dKoqRXmF5eQ6Xd5h09KwIjol2FBvgIVA1OBfdSIgpuuiIFEDi0aESFYIcBhQu835ZW/MxqbMZkFDDGw4nBAeuZvddpPlNT+5a+WalnA6B50SMYyiI51MlEjumxDirASkaS5AG3jEgOmKCBToFQubIyJM55FV1Fpe1F34HeYyJa4ejPtOV5gXi4LylcvVXQ0711nty2RqHGeOoN6CPaP76b5l7tq139OzTkaGl8bM8FBY25rWD5m7Tdj3gtX9nUMJEmqKoUJrkVXes+OZRFUrbIqlz2fye6xxix5E4WM3kJlVISCZpxoklO1k5VHQcRB1yigbjqdOt7dUt2WxhcsXkgqeAoRFTrLxPdDAXRYNxxh6FqkUPEEQNVGyZ4ccQo5uTGoy8Zq5uJVJEJTwyIUpU4OrGpEd0M3y0M7KarSfZzWGVcifYWUDPXFghSc+iYhpLMyhmhFmoJmNzKlyipqiDSaAnE2QkQSComqh6lOXIEktaUgw9PStOqKLZe14aeOt0MCcaBENdZHCNJqCZD0cs5E67gqXriwQvUSioYYt0QYjZwgMQlQCBw2DsDCdYcTSTEz9CxcWLmVxy6bHG+bsDeJt2p+Sh//uyRHKABABg1usJG8CBrBq9YSN4EDlnUSwYc8IAr2plgw5gCrP4ZyUZHuhcrIWXbq1KKKjkFKGndNKPQBiEBUgIQAAABOARahgSQI/MPVxEVmzlIk827CoGldZtp1/pmTwfnvF1HXIom1/WlIqNqrEA1Kgxf9lAWu48iRctBzz16qtPSZFtPQO3mMnJ1Lot4LMYxOVZj824V2ucnaVGHS1mxU1VOUozZmUmjZH38ieloE5gsEHFmHYXE6AGbWdemrKAC+oqAByRVxKFSkdE/zO24rVZpDaqbgqJL3xdx1KWK2Mn6t1IqJAlWwUQ74fZabn/kUGJTdohTTaHVp4uKPNeJQPemIEqNNiZWFAnaM4kfVHgSsDMhBA8K/v3rHScyprTYzqauiF7V4zXqEjl+M80QPl6kBvKc65x4Q5tNKVKJJUQASNINC2QF091bEO6CUERfds7CmcMV9YFmKZ0UWWIzJ21YpG3VBtYsRhAhpsRFNiTMVeqs/GYvOJpu8jMLjCPTLmc7iZmcq5VNiWIgcrVdNGqUmicw3kPjGykoE0HxK9XGPEx/tMgvmeyKfdMh0oZ8yKgqHG7L2I+Gdp21ezsNY+Iq4UHJUXYEkIQFBAqC3meICEqlFnAZDGHSLEmS6MKsUSuA88lABKGOAl1I0EXkkgSDN1l5JZhj721T7dN9iNog5uw1SUls4RNRtBms5FD/eFi8iFJ7C/f8qJS62bJ5c5v6sdepmR+Fj8Ai4v6GW4ELszGUfWDrwNRXQBCxCgAEJAC0IUJNocw8lyLjSOIQ29nEGgYEm+48BtfiVNdp2vv/VeOPHCijxZBkUKl4v5W//uyZJgAA/NYVfMJLFJ9CzqsPMOOEolzTSyk00mlrOqphgz4itC0cVNfFYi1lFTz01VIdFx/iRA51KDM8SaZvTb3SAvHc6MfEN7g47VXVcSXTSClabMfmAzeQfc5RDbXqu+zt326meXxtvl/mCPzDPD/Oxw1GgMwK1ujmRna/n81SxmAmKywgAAlvi+RUEs9Yj/F5nKRZYGnLXWOGK4qk6uWazHZ2xSK55FizOEKMQ3S+c2H42ZWNhM4i8oieYe9w50k/tyy5Rss07csK8JKCutnyry5I2cVytvfh5Rs/uqe37hoKgocgveFF7PoAESKKBIAGFwAwN+x6QzYS/Cl46CVAygGKoeoImGP1QvS24sX+PvI1BbGlekUlVPMF/nDk1WQ1UnsbTq+foYxcQMW5LF2xaCUOHPwPa+zSokUq8gWpc8dkmiJy6D8q7/HXlKbwg38fOre3A+RQ33Mv2VZnrWJsnf4e9hWa4ybEgW0scbHTNLGzcjEsZRC6A37OgAQ7FCQYAXo8zQlJ8KZhcwDddj0JfZnHPpVnAntHnl0EQgYuUt4Se6GCQdHky3NUJ3Oq37xUhmf82PSSBrlk+zWbDzUPtX8rpZQdXUbTc6qelDGYtWDK92dNJ7UvUtW2o/o2zuvsKeSAIsRSCiPAIDVcKAA4oMIktA5OOFk6YYYAPCeOFIMJlOaohJa1C4r/v8w+WUkqnXZjFbKqA14BkGZyQK/LdfuLd9j2iR1hiD9OUs/KzXUV8KnGDxnTusk6sc1XZxZIIgnldWIF6VAFJMJWwI77Np4zQRMzo9SvMZKKtDC3kIUbAWwg0TxIbWdsjYCYmEk//uyZMMABGtgU+MsQ9Byytp5PMKOEDVxTSwYVUHxLqo1hI34kggU4scam8Ky1+xQaPA6B8NxQvQ8btQPWuvMYJTzhEaFGgsRpWZTZ1WhRjPbmnj11lY7PG7Mx+3CXuV9JAPXW5KUTTEdVh9JeTMw/lZ+C80+1jjHy6bEGZKScxIKPkamfJ09n9SYz1TCyqpe4JTWCY0BdUeDLr1NAGBDKARIBKiVAewdQdAHXYCSh4CVEoWLz4qFeaKsOjuJYCxfYKTowUusAi62ihX5hzRTahh7/GV3pkr55ZfVYCplDjAvW6KJqPe1dI2G4MqNJDcZxrzhW4xDIaQRLGNI7b3HqE95mfmom4TtP9Mu32e0R/7G/oEc7svzWY6zf2vL/moWARrksJZRTFvPnecRg7dQ4gGCJACAjaAhYz3MSFpQwDgL1TCb6woyu0VCr8dAVA5w/rmjZ1NWExTUjh60s72e6aOM9ojrnNL5Mqz/mVi/YNP2NOvKf5ZPUydKRWxSrVDtF2uil57m8sbn97/r99rrdtKRaYvWxmjWd8feXuP8b7bs9NWdtfGQYKkUGIUPGWvQvZQQAAAIAABjEjGDREIB0ENOPc5SgbTFa48WwCwtTCpKY3FW2kExBoTddOSTwpoC8nVaLiZtglAjnKlsKuCq5zDI6my9pNZMgGkzeBStdsezLlYuYFL3YeIUdsa+XmGqr0z94CcNajAax0cOG8HXcDn4E9Xkw/JztI7X0HQ2VxXdRSVjDuXNTh+4GjCaME4qcHAt23HI2hESRvHZIz0bxBMuAghBAAHTiKCKlPLmGqkCrZhlUslaRK52BQ04kwpG1GHr//uyZOuABJxgUusMM2CCqupcYYZqE/2dRU0xEcITK2ilgw55pZ+/EfFyDmEggLPuCRCbWmLIlaUKRxY4xjDSSJAFFJ+7pWhWrtqd28qkPBGxdyyb84CI1hTPsaXOI0X7WVOKqKNpu2qObUSNtXLpOaDiYcR8nI05uXC59wkQrJCNL8bFv/8XaQIBAAAAAMQsJ9hCQd055mCEIeUUCN0p3mamCKXFCAn5dl41mK8twE4UtkGo419k7oxx/iu4weKkFps6iePTMyVJicN0DqE35OCEGeHlHoNDIBHRORCFaVGl+WalRRCTrYKQ/kkJpHjLrj0BmHiDKs5U21sDUMvJbZKVRfCTIKtzj7zPNN/tQ9KSVXdRL7S255NM9K0oXqSqiJVKBM+4WaEyKtaJMpNc9Sva2lsztvlgAFQgEAEwEPayn4YSLETJLzLrj8HSRhzMoPdArkAA8QnnxLCednKMw+dImfJhxtpqz81nlsW84cYy197p1JxT5afxzVFCUesrlzCGmgw+itBgv5ucmDPdfQ3K5PEdLhelaFa+kPO2vrsWh/f+ziL4CIUHByBGFQyONCudu1YAAgQAACoCVRDhIjuXNoUHFq9KgL6hxFks4PgScZ7+QjJsqKISVQ1fG4WF+kXI4QmycXCW2KQZR9gTjvx7ZuYqJ8uSgW1InAXeTxhqAy18wGWqYWT8pL2ks5jh9Aggkh8qUp+oFft6alU4GfqTT+kmmolKnUO7uh6UP2r2EkPodPpeS+bCBDKsJN6kpusljcpEtbmw6VLi+CWx3F+TuF4yyQCANjlxEM7JbMaFVaBAX2YA/r+pougrax1b11UT//uyZPWABXpm0FMsTSJ9ayo6YYNuE+FxQ0y9KwnnpijllI3xA+TMgHZUbSR43NZ0WUFoPGO/bxRuZZyMj6HYHFLZVU/9RbRUpg4ZA6DMoOvndTwggITkZsUpWIZIwrOMMfeHB7NaDZoZr+d2yHVnsNzvIvTHAxpSXb36f9P/tQEDFIIABMQVKLIWMBkU4Z5VOEDA8ZICR2fQrJRjgTSqapkBzUrblvMtFq7xw8zNEt46aWiW4uKKd9jy2utBMZEwsB/rJnV3osiF2ow9c2d2ho8jnInKH1hEiC2owCDzcWq/QmE82EU7TpFI4hj/zrHabl/Bbax8FlhQh9ka35An/SSLUhqPrZfzn69T9ai3ZNb71M9pRrKVYi0rGSk+SG5yL438+ZU3/k2CAgsAgARfOHioQz5Yum8ULZEsOuqmSea4xCCV1QWuiZistd+NX4lO2Y5JPuXYjS9rdwNc2QsmmfwgBmbFkk+KMWiqCjq1B6pibI5GLkifJ/Askrrg5zamiK7DYsSSGoeFHe/KtE25fSWElP4cJaqrf+34RfL8+U58mhFCHA9433gCABABAAHERACkl4DKH5aABnBS0tWPJgRAADjORE3RgdlEu6/jaOnA1LBDW2+9/oYT4jCgXF1lCBSILFkBlaRquKTiqh1GjdcyOfbaZmlNxpXBnZUDhmER1Bq6TO02UJfZVdq+/eifXpALmbVej2OMOxEp7JzvqzeesIflozdeZU4hlp0V0LiaEsfu8Cg5KkY6IDgcoNIRHIBYtkFHPvF42Z/+DKRyhRYBB1iysEpJQiKC30mIOQ1YO+5VO3WapYcoFLWphFWDiqoC//uyZPoABU1l0FNMTSKAC6oJYMO4FKWbQYwlFcIYryilhJngnZLnk5wip5zi6tVHknRnHMaMIHl1tvpUxOhDGu11eHvkghHdcxqSukwQEMeTuz6+2ln+GbsZD+Ir10N779p3fshGbuO38W1f6QV2f6hkbYOnrtcdAmPTpcPpkIYdiV+sTiBnlUAgAHoPo5ITCzQClLEwxYZAqD0qgNMcGhJrKsvKL0sxSQ3h9yNJAIpZxVnGG2x17zFp5RhHH83uoiXxm/lUnD89MbdJUmYRuytTRTvfBOcIfNt5L6T2+R5uDq75j2SjM2WPk5K7rbtqGNJyqChhGamURl3ig67EgRE4betBoUsiqm5CgRipGnMGoRTlOS+jkGojOVv+Nk9gz1QlVISIqwfwhEDBKANspm126mO01S2IQ++64FTIfkIro8aIxmkOmrhxrVrLbPLFTbECif2CqBSk16XSUuMXIS4lShHUJppk+DQkJiM33IWX1Dwa1utjHJrpJItgnSc5RYuNsu5KuIPiUNlZqJiNodphl6ycoZLGoK+b08lfEUSdKMJIXR2WvEpNJSh6HUlcKXQBhJkqTrmwAjCkxwJfFXicwJAdBt+p0shWuD14p0DgV4WHdn1Yovkz2BHoiUqlB5UY3aiqsjMXA4oy1E0zrLDfUazVoIFukcUXw4vyS/5XNhOysShKOoo4ZX8kk2pjKnp+OKwpM23rabTD14dmSTdDWlttA1yyyrqsq77IoJbJs23PbKpZT5W4X0TWwkNcwnKu0lpFU61h/PZAQIDBdgIIEFAULCGWWoJVSAjzLdigDZJIUqtZh4x3528QPsRjogGm//uyRPcAFNZf0eMGTPKYy8olYYl0EllrRWwk04pmLuhhl6ThRMdqw8ihOkmzaiiL6cW94ltFhQQIYnIStgaSVDu4+La7ksCuLqsD0tcNp4iEdwO4m6FERJNq7YS1LL04ROtFk1kLTNJXGVomXQR+eU5qEOpBpqW1XzckrqVKfoPFpO0LSUA5KKGarrk99qgl6V4H4e3qICSAgAAgkIBalWYylzVaZ+kGFSiLsSaWMHFoJUIpDBttiTKI1DaAsFBZ6gcQ3L2BOC/jqTPJHTikhITykHKamRTxcGwbxIgOvtdldUBRcxWkOu8lEWygK2YFjE5HGU3RZbTyYEiXqwjqRCYj0w+JfAqtJZEC7vpNLYRQuuKzFybjkj7m8ULX5Io7Ka+pJD7eDSqu3Fy1JAL70mRR+QrrtB9bY2aaCkKcEJACICAc0BLU3knmkJgvScAAdZRCwrYmnzDzSVSx5nmfuhFQcwnktUJolYKvYzY+X6Bly5LcULaeZWSq8hdVY0IUCR8+uvqSasiUUpYgmwXGrH2SsrAvfW/AUfUMkrKK4anUhcJOOrYCXYqcDjHG70xjh/uEZoAiS5PYKhrbECAQAHCAFnC8QCgTqUSUAt5k5VFI5tNLKCEQCic+k5wkCnUL4mBehEXhbjeVmDaP44rbMmSDBhPraNwZKoVMjFDcauCE729iEkvCkV2W9QQqRUpEymHh06usAIxS4TH48VsQnq6+IiCnpHCCfsMIIVvY3BV5JYJuoOu9PVZlKoO5WOdXJZQrv8PzrVVW5ldt8pKPZSRJ5jRdDhRqtxCa39zXpx0C46APNJhkAiQFBH1GfihIAJed//uyZO6ABSJeUFssTBCCq6osZSOMFK15Oq09LcHgK6ixl40oM5tAcOTkIWByAmDBQmdgF6wOi9otW1zAL+xsTqMo0q0aizDUAA1YHgjHIERqKN8aGbzAVyrMeyZuOGwI3XY/bNgeRVM4c/vsxdJ/R7JeoRqplvbMmPjfN+cO2/GugUZQEJSpZ7XEOqpAQgAAAAAQqQGdkgNLBCFGewgIEE+xo4MIAFFHcDgcLjhex/24ukNCLLn3jjY13tBl0BrBQbJYYiAvu5ipqCBpBo0VUOtEg/vpB8BAd4GhMfgoBA2SoVWIdciXWVehExdtsNcQnFmjoOBCUDiotNJpTVsqMhkGo9cqA7poJmsZR3iw+jd+2/MMxd8LTrIw8o63cm91PUt3YVeRlkm45UVoSD9NdEom/KzfJHt7gaqrpXRIYCiC2ZpgcYmIApAJMWuQ4laprINGpe3C+K+FLIenpI87FXpcpyUMoLODx1Rr7h03lYZ6T02WeqtULiuto8VhOR+Mst5hhnzC1HemRa9tPbMU0PSqOGgzN0MUQiZRG5BnDSM6QypIXsS17KoX3Y7P2aqDWeU+YamFDGsYlHUgAQAJjASNTIwlGUioIvyUFMGEjGRwlKBoUaWLBIVEjAgpPNaaWyP7JZcsRVYFySdImyXaKO+KZR8zqZgOmVjZzzR0B2aBUPnR3FyZ25aK5pwh6HKCZqQa9i6wpYWl2xoFNXcDbfQW1KpHaQPpBPdWYoVKLeu2bj7SGwCmWmz59u0JSPbc6iwzPKcB23acc0m7MW31JZOVcQs7aly8Zt+Gsu91eQjf77r9g3iSsFBp7CCjvUsSgYGA//uyZPOGBXhezmNsTSCAyzoMaSOKFo1pNW29McIKImcllJnQgABGaWJbl5g6A26VYAMWulfwsfNFqnLhKZr4Q6gcaELJQdYIgcJgXEJcgBXSAZaqYWio90ETBcH4RTHFrGQ+DByTJhYjoo0YwiUIysPMUFtq8LPpiTxG3tp3LZBeY81Ooakn6cag7JZva/WXi5qAdb6xPeSW1hATDwUAUoMK/1VgQEIAJAAkqmBfDqFEIongiUhNLjiMapnCX2VO3FGWUQDFhYFIKSkd28x/k1Iodj9qK4XpRDzmT8JER7lThLKR4w1yYPtTZjHEh43D6szZep3aOs9potWF0H5CZzMN3/OcKypdERbVzrf0S3zM9nEdAWwbz6/mhlYSYNDyKZze0/BNlwgtcOBOBVUBFpsEJy+4d+LwIAAAADFOBryBdEKVHFosMhyZMHLjWVCgJFR00XDnKJMyaiLHIwWXIRIL1R+J+cQPLNTiItnFJhAqFVEltWSqzaeNWyvhjS0VW5R6MhzV1Z5q05mSBqovbzF+1GihzYxZO6ARuCCg30ekGMZ3zLktCt5Ga+L6RRT1WkWTDPt5oZkCB4FDalh5Si6fWmJpIwSkgAVgQeNZSsWiMflghEOFkwSABo4GAwAMdS5WFZjBaNMtpJOv+y92qEhGEy8yZm3ilJaBFuEJIIGG4nM5Csa3Cx7dXK5aWeLMFIdyF1uUO/ER+qQPZro63Iy+gNRE85tRBNNihttnxcj0XIB2ODL5sIz9KviDFi7tKlMnhi9a2smfHnyIARGoJA7Odsgbsk2gsXeQD+bubgASgkRyNClpwkdXw+nDDaNCMTZ1//uyZOeANJti0GtJHdCLStm5ZSOOE5GJR6ylE6nKq6dhgwqhKkP1tP1OWX5g6tJs3+k1ys19+41K7n9taOFCRyU0JiSM5pPNxyQybIDZzl48qyGMSn4STQGILZXKqbSFe7nzMM7MRGVHZKull0Z39Sae9NrNyF3MvR+1hR2if7r31+kATCwuMrBwhFhhkEG8KoYEABQEAQKwUKhYlDwNKCmCCGYzGAABAhSIzA4CBz7u+R4Brg4zpNLIWHg7xKMjgHzhDas+XbelrRlxIE76Cdcyi07LFUIlcki/yIspuxzeHEzNYVw0mZ6QhFHS9EHWCcMLGLmC5Hi3nc0gFUFJhEHmXl83nYzs3I8iYSePmFA8c89TGFWVwgti59l2cLThTFwZtxTINJ9lTrlOxpFyrr5SIuTyj53v7ifcJwmVvg4a4kF1SJBu/n1EVSqjbtb7htGpueTulY01LS0pilM41SmPjGv/OojU77VwAhAAAAAIGKQalEJUACRcipW9bcRASUykYoFa4EAoXC7yv3pbg2WGYk8vIUKxhESBSKh0CSJCW0ni0Wr62ZINRMJrQERjYSp60XEtVFiqQp1bS86hSE5GJgxCNyQ9bWtj01tnVZPryhdSzNeyHpIR0V3nKr2ax1QroWtrIm9tju7teJgc1ZI+fckdvAu1du6oIJKzPAMUFgFBnOvoYKr9HQ8DAA8NtnKwJDkYKJpMuDfDidCD/OIC0QQkjOYDUOY7jWL05LDe0HLmHdDGBtXKiQG12kkMi6UppLVD+dj0quCiFOvc4Eqkm9jb4u6xS11KmZGjNDIhYT4GYLNF4zC6TDvIKCSMxV2L//uyZPgHBztnSouYe2CQSwm6aSWeVr17NK29L8IWryh1hhmZXQRXkHxvbQMfUQYq+VP/fTShSE/AgIP8VbqmH2pUsUrYQhjoQ8113yvoCAkjbj0L1GftHTBsMNEB9BNf/rIFTbSbIZIKrBhrzAUjRY0IWCR0TUaA8iZQgEhPfMZnhyjxedoMMERYAnUxLRDETEKeTt7R+2Z3h3k4cUiTTWexbPGzVO8fyk9vs5TP59NEeo+vru3+fv9aI/d7irZDfka2PvYqPvvYe/dtms5O+9e476xCP7ejwuAGuSEdnxB2hB2iz/ENqgBAQAAAIQgGJgYjDDKxo5RAMrDw4cBAKKACmzdSzYyGMMU5jKqLxQiGZaj5ZSxqUEujsGcjEn3i0aDuIhzQWZOBGPo/H0xUQCSIaiscILH0JfHDExkWwdwCBaMX/PjdHJMsSNYKhZfwmj+jo4VA2sVR2gq26gnPeTEkVE45x64hkL7C405M6IAQYTRInkM3EBXGwIijFpkTUa82ezEhEpEsTG7hWqfynTjurn0YxVMQFdxakiQdG7XQ34c9F2yU7aY+92cb7zuHnWL53iEHlVIq6nhA5GSiASUqYQKAAgVanergQKxJFFxH0U9tgJUBIkOe6kkYhLtReEffr5WcPKIF1OFS/V93U+8a8b/Y3LmGTmlIBsC1hg8+FtS5HiQQJiBQ8ZGiixVGWNeyZLbGy9VBlQw2qeiMnhwnj/fjxHBqcIF5cY9aKd38SPMbljTbrIyT0bT2cIkGWfTdHWdQNGePOZsPlSq6jak3LtyTU8SZaZI+O501C+cYh1ZGgGAEBNYzYgveZsWG4oVM//uyZMWCBpBmzdtsffCqLModaQ+eV72LOQ09kcHYrqkxlJW4jggHEQgTSIBBGGScbZ/4CRYdewnS18YIrI7+UO47EaT2D6wUa8Yj9Ylui88VW+SuE47VT9bjvUeqItUNYbyRkIXHY4HacHq4OGGJte3Xw6W2kGIkFqjZDVWEi203x8epZP3DtE04SGNkQDPmjxmhTEMHVGF49gqU4khaZPjVRiGpRYw2qjocrD+J9SsuwsurKpiOiHPr3actWKWkZUtfzKOcfRR5iZ6tN/5916ov6331qZXXCBg0YMRM4U2HDLseejZ898Ct8uZty3EHOVmgG0QB0RpANgm15VsKlv9/LvLnAhkzNu/KmIQT3NJ/q40z1XmeomBtNFUdKw8tKSUr3fquVHRX6rZFVqo+q5WeUqZW1KOo/QlEFxJkAomx2MkaRowzpdTVA5ACAAYBDoBfU0aE7zEzYAOCEIwvVVh8MBqpoJZBHXiWjCoCpmFLbcyxKljNJmJyHXevVpu/imoDJ64WjepNu00BEaks5TC2hWCSygpmAwEJNKCoqhiyG1mZKBPIAcckkoBwm1NB/yEFheZVQhvWoM/SoM29VrVWBXcUS0ccFYP8Tq9td+LCkTGse6elWbbTqLSaonN6gFaU7VqXSED1pF5J9st1Guv/4PTPV9SYtjThlSRACUpDHpHGiCDMByhhQ4FdsLeFVdmcCZ2cELZIIRWTrYh3+RMrTCOm1TgyKShAb3Fn7cYz+7PPCc4xuJ0Izup1ebcVWCPV2Uo4VZi2+RV+rLUY7VGqVj02XVtuqo8a2l6KLNfbG7JiBTPHgtGtQRNi9LUIcAMA//uyZJSFBWdjTsNJXfB4i6o9YSV+FI15Nw2xMoGnqyh1hJWwEzABElFxo3OJboKFi0cGwcPtdpisAJBNgq1oZmEDnkljfLbVtf+mtE9grEwuK4pE91XEoRsyeF8XZTAQPqkg+TY2fV5wmUnaAfKKvFOPky9jisZHZSNPuWoHSsSI335fA+UCW0TRempP9dA1NyFOOzYuKR6UETab7CqGU/uxOKLXaBFLUm8klFlrwc3JYmWenphaSiJeLjjvcXqSaNH2ujiBq2GQoSSAC8RdLiEAMY9wC+DUIiNSlDYBENnumlMH1xKNo5ZsrneoskPI85cgJliyi9wzHylOeOo7FTmtIUBB9lKjLIeZCFQ1HaRhBUXu+iP9kVffUvf3Q0uW+5aWomlS5n1tEj0OKNzaAcMBAACMECAxCLwmRgBp1WWAGkBDCmoPffCFjoQaJwGvsvUwhEEtTdhmS4sWcwXKrcHNwihbFIyssoUBuREIyJ6ZLHKEr04khMVelp9thRhVkSoJzhQnUxCQH6IRxTqEgzlNigNUsnD1hnwoVt7axXLZRtVL5LASprKR3/GGz9rZFZFtEyGVNO+w1aXupQkq3tG4b+TdIR4rr0RFlTRs4mws8Sxd12pgXuRkMkgImCqILgVUSNBqskQFCIsqmhx+Cy2UmKQ4ZRB5efNCIicUe2m7ZYT1dgLb+VU5L0n1ggXxgZ/m1VthJH1/jdJ/Orw8+yX/wglmMS2PYb+iGTt0aP/3KM3utKhfzs//je6/sX69dgIaOCYh3BN1aGAAADLzDQEAIBMho4xfCBIQgYJBQYAEPpxtMB4C7gatnLYWAAKsysGg//uyZKIABThezUt4SXBza1n9ZYNqFY1nMQ5hKcGBleelhg2gstogEt+Cr67W0aK/DsOxyS0cTt0kvfWBq/JKz3SoXxig0MipIFgKRWkAcBiAsFUwfhIGlbOAiBwlgHhQ7ICdE5Yf1vlRK2zBAqlVE0YNuYnGoJ+gySRznvMCSUdybT/q0mrtydSqstlf8v88vu3turVr6dx/2N+CBi8QBVUqGrKnKlZNFBgSGwsYQLdowLORFXJAomLlpKWDFUFrW2NA9Wj5dJiJnS2oovZW7sDbnaVCBaRQYky90G9BpVRdjf3y+fi0YJD4EBlZI4VvrTrvCTmEc8MtyqBhFaLz5ulU6Khs1RTVAEIAAAAAAJgEFRo1MAFQM1GWX4NBjCQwwAQMJBkvLZWFmCCS2ZVBasiZ8oaKpY7SgDQpl414vq1W9HCoiUAdSrztPEj18nuKjgPFrtysnUzclneQGJNhgbZthU+O2Sw7jY5qIvDI0jhUqO1ujU51qy4QXtSXLcQ5R/FVcHjo5KrkXOqLDyPmOr4ypbmm+3qJhpznvyiho8Goi5xou0I941l9q4QllCGqLG5DADSICbiJ5F0SmHkCLht3AIhtyD6CC9Z4VFmw120eGKP6NJI9SUJQ1a6XUEuXRhH5EMHUHGpyaO5lbo1VKd9GfbYv2oyUR9WoqVhurl1XOykBPQp+azyvS7Klr+tW0fJdEdVO6D5WwBAFQFAIOAwCNgk3NInjDwYuwOBA8PpAM0KBRYILBUjkjblAUasULAkpfDohn+qoylTx5K+I7GW3QNLqDBhxG9ldwk+w5l2wP/d2rNSRGF22ZU688tHj/N3V//uwZLWCBUBizWtsRVBpSvntZSJ6VQ13NPW3gAHCK+e2sKABPdlvBXLIxT7o3+9ITH7xc/23/DZce+WWu77p/vftI4xd1cq+Wb+8OkT51i1sUr/Nn1vrVN/yXpn6c9YpnM2XTm5zNjhF3fN8eUO6hK23UgEkWIAQEUnmmkBhwAGACmqBykhGgHX/K3Ca0syYlD+MlGx4iheC4BCK4hiQWXYhI6spyEQ93KlmoeX9zjtHd5jKhEP000YoXqYa10Npzj2uaus3d3ea1GfQl/1bb+xjUp3vbQ/p+ePiEREX8X1x3/SqMEpE463wEfj6iuNHCA+SyTHRCMKD4xOBwwEgUgmLCaYIF7LDF4TQDGKzICAAVVzHjEcogMgpCQDGUxg7to4C3YM9YyOGWLCIKPsODpBoUKRXUAjHeedBMnQrEnwsuD3oljTWmKjQbXcvBw15qXF/nUVrZQ3NTZRuB1Y2bL7b9x4kxJ3W4syanDSv2RQBDqJKikFZtylEsjEceFtH3ZbIWnRGXxKIUTfM4fpgMM0c+9UPQ4rdNPA41TF4J+L14cxj71rdl2p6V1KCXTtM0WW1ZRFqeP3M4Qzl9ZfT2pmj3/Ifxbepqmhuxup3//tqCZFqtOyCzc7+td+zDcj7379W3sMLTIFDCF/ylRMvZ/Kx6ULLgAAQABSAAiKgGOS+aElpoYknGGsZpHJ3O4gw9GCi8RAAyAGDFYzMmA0xGEwAEzCIWKgoMEAILgw0iUz0Ew5kQljFmEwhwqhQLB2GBhtmiNaEQOOM0Vy9EGus8jNUxkTVILvWejLCV4POw1EdXrVlBV7wKs5uDT2Jw8pUpY3/+7JExwAIiWPJBnMgARPseTnOaAAYuY1IuaeAAw4xKvcw8AGeKQ24DSYhI2vMvksNydmk3Bb7Qfm27pSeWN5BmpJORXV2CG6kQhwpJMdlsNw9SSy+7FOsDbZtNPRDVZtrzWItFoZqW8qWco9O26tecsXYIrWoFtN3naeJT8D09Nned2AaXCSReXSr6kbqSegzpovS55b5+vv5xagp5NGKHK5dww78Myun+nnM6Hdhgv5Uh/4ooW/+2geVE0kkk2NAYB0AirjyM0cMxABK8ueslKZOxwoq6q8kfosyo4CrLQxE0c5Y1eTwXF2oSentksAtiEzncGACMj/SLmZ5kqtfJenWYTAlROBLoYwmuLK+Q1CFuBEUd0cX1XrlMNUWqhRWmx+qKMjnmO6YpFcyolhYXBTSP53B5TxPEj3u3Ynh0n1LEfv3rhAiqNiX9b+Ke/+vEasWe4ebiv54lm2Rwo5w4Mrl///j///+d5F+IEXECnzun8Wk0jK/zGAAc////+68gduxdzR5CQVrtVjsehhqqCQpfMKmDiLdImpprngN5H1a2v9QCFuQXsfc5dCcNihLYZ5VoE1TjbnM8zLYGhTGkciponIR4METF8Kkt5oHg30hKdoq4PNXrzrQ9WTKimJ476eFq0zpwgs7Y+YG9UsbyV5SCzsjjfe1ZBf1hMjlEe3tNEcWN/q37PGgZVkOO3xmROKCqvnaIDHBf7fyXkvNr5ziPPqBmZ481DY3PVN7//evXGPgyIjO1yTz7tmPdjngaiJ8qgBbZUiggAAoIiQGsl0sZPqcXLYemA51ubKYal+4NhmkDx/DPNsvfN69VZuTv9b/+7JEFwAE3WZVb2WAApqMCv/npABRSWdV7LDLikItKr2UojCawtLaz+ZDuZ+TWfrs09DMLb3Xn7xs3gpN+are87iiXrztr9abbk5du1/YtvdfzjFkN4qTTNgipdv55j1l/jyFPnMbC6+sj/AnbVvWcbSE5mqx5KDMvH9TIG7bSEerkitMRIkax/Mh/azmzHeKuBpTxDwqNNsmSgMg5wNEngMc6QMhPGIz1wXpFnm7ZsJ8FZkQjadNd0/T8l1pXkZbkvJD4rLalso1HP4b/KCiQqrqyXnkFyqSpRjfcZ/5TPgz/fjOVRvfc7rwryydD6AOGmQ9C1yhKkbbIxHC8ICYuSa2jousoribKBqPVJCcfSZkdM2lBAmIhCWRJKA7Po4tRxsSMSasjLp5MRWCC72coyXUAAAml1Eh0FWBH2WOIgmUwdJK9TFYI0pB2C95ojLS7hVOaXxczVdZk5qeoZ8ytcbFvrYMvdJmu7ZpV2n3RkLZ6af+6nFgIdl45tMuKwqvj4umSw79jIb6Xcu1l0dnKxoZOv0V7W5bV9OueXMbsw7wW6Bed8M9bSZw1yrSlJ5szSP23v+gxYzzDOtkBAAIz0qgQhmcUTEWwNyi/Dq3rqEkvCgifiXMDcajlLrUoVBk0KBQ+0EaZVgkSNdavSYIspRxmF6+XuttacnauuWCNXnj8rusojVFqNGvQoPtkisg4Uy6GPMCi+cfWtIofiE+VUWMLY56P1Wj/ct+7uBmzWuOg9L0XkiGUYUFaNFGIedDrQiHbCXZDPcdZMJAAAB/e4lFQlhYWXuZiqRosuXtkrclovuQ08gJgkWiMSj97v06163/+7JkFgEFKWLS60xM8ICrqs9gyIgVxXtDzmWDwfauaXmkDjBEquKIUN7NK/00MuYjYpOnzk57Xd1lUtnx8uBsEF5xnOmA92JgrxTJcgeufD0qjxuLtaBUbctm2QtPftSqaP5ZbcQqWdJcm3tKGnwccjbS6UkwZF1tcUvWkSnTQQZ8QafgqDhE9aT3URAP7Jm1WvK1Zrok/8r1J77lAyQ9TMQn1TQJYJg76lycC0Io01KZlyvGdICyEDMXevSpWuAZRJ3vJJAE6KzWQKspxhDNNdHi5A6kwZk03zXx+hQhhg+qS5kZ3Iw1v1Zg+bqab/7qef9Y8qK9ZWYluqj1q+NNoO4O5448wRuZmVlxl46LxIIrNAexZNv6HmCtFbOkACwREMygA4MUBIPsBKgPAja7wYacDD0SZt1BSEImEb71UFty+IuZAiqkjxrig3ucH59S0k+myu7LRDryY+rurSzMtatyzsTWs1XaZjGY9eYd1YrX4mU1609LtyQr9i7NZYIpNleu+KqE19YiMsVpXnM8Syy4uOlibWVLaOAtiUfQsn8dmiZTWFXtRnLBSs1ROpxceKz1jjpV7pkfWSHR1HhAL8WNNsfx7ENIxM7UCJKLDMZ7yAAAgkQIMDIIhZW0xURgSSiq3cmxCEACijzSxu7ToLdhp0sMRpGHL0OcfFT/z5Vm8ih8b1puMlg+haskDjmiElPYmhHwE3U9DXyDoYhT7b9KkCC/AztZn6iOGO1WjFWAjMGNONkYIjuH7QpN0Fv77BRlTXxRVTKlAEDIADAHDxQFwAIwCAgaYTEiiz+jIKLhMUe5S5tlOmgXpUojJ9M1lzz/+7JkFIAFeF7PW4l88HCLqp9hJXoWaZ03DbzVwcMtaf2DDbQWqDglExHYqzOelPEY4fyiATR3UqkkjU+mTc7VVu07aVDA5KjqolU6JCzzo+hrgIR3iaIDWUWSpZCRCbSkVGZTX9LUE9oaJu2kyZkru0eHWryFuE9fP9LmK26w5srhk/ba3Bjwfmz17aun00drj6g1NGPhadQvLIzRbQIetSTzvLPDU37f6wdcd7l0b3ttJUZQ6wdYNEUYZePUAhIGabx8RSadMItN1HgJwDRPJmNttOanWReq1/mfyZRs1iyJdakXm25xUC5rM5TUc2Yy16kft1LVv5bbFFVEH1dmRHeXoMc0yPu9ptkecpv4sJOoiDIMFHWo4z7QMwAQE74DQ9LASYoTGDl4kQIWFn3/HhVlRgAGXvQSuXI3jZ5QPU8mLSpy/HmuOtBczBuNURLPRiVqocu3KBgj5jq/42hT33XTa7z1VEzGyy0XEB9FgqV/rFHbho91dC7Y+takF5bVnNhrWqliSRNPZqteKezdCzBgPp5RwsKq2wuUumCC4b3GZoVu45cvEcbxhFFqrOW5yWHBRuFCJRtAG9jUk0DkMXpKn+Uvu+fsdv9R+ywQoilZlO+tEgxGWlIlIpuNbS7QkDpWLtfFGLbfWweECcPSCExpArXjupbEfJI/XRHHglbi0sPaX0ndmNNIYou3JV/zzLb/Wz8+Gx2z8/Nqbdjm8aXUtWM2nkx0iYualqZaF6kWXFcEalSIeBXAU2Q5RQBzAAAAJveBhgSd5pmxgE0wYgiYhAlcLDXuLlAweyhysaVEhzIKbPGx5IlCEsUMxn5x2Fb/+7JkGgUFIGDN20xMcmWE+g5gwogUZW03bbE1QYkr6r2DFdQlP4wH0FkOBa9XGtlDLlNXrIEcuM/KKimJGRV/S3/TcmciLoiV/Cm3fXWhbOmP3+NMwIokt12mbppX2sajAmIX4rLMDyRNnKG/6OeSSbLOF6a9a//dpJAWqlEBV94VNzJlH9NUpqc4/0ZhndjxJndbAQhlJSE3hAEqcX+qIueFiz5xQL6QEjxnzTLYS1q9VhoiPhdgXN8sHAECGlXjX+dG6CHH+BSPaCX9PPpZCkepZHQINfUxpFROsigOLNXB04oUW2daPPKHPCnY50lKEHkDoWlx9V7gAjMGOZJhgAjiJKhCBszWeMBiCdAmhc0tRgiBqWSx5ecMyJcUIbrIZqmdyBvl7FCdxSORKYsfE17oTthysTDt0M61nC+tR+0kftuHzpVUZONq76nJzrtwhp+IU3hxY11j5R910fOroN6CaP4vd6MK8tINhOmvLyNSbkCgF77QkcbRM/p6z9nWXPbScS1Q0KIVFElUyUj+rARGlQXPFSM6VdG/UDLMbMu7SSWJKy+WF+lYwqKNNxZ6xZv0LgQZfSEUPXXTZhnDC1ugaBD8iRVJWqTQejacgi3J26YSKy1NoiuQhqnVsquxF/OztIvRObIryG51TH97WR6/a/10p1qJJBxiHT3WABEAAGAmQ0gGDV4GEFI8WMIh5DsrKhel2whNpc7fV6VJoMi+RiWErqQgHgxlpw1UIQ9GVKQIcdDxgu7dDURStDZ6sLUfdiNroydl1TTyqSq0BGiSVJxL0yaW+TkDPXd7TbS84lPOXa3nZ3y+9MH1Bfr/emP/+7JkOgAFAl7OW2xL0GRq+gxgwpoUSX1HzKWRyb4v6v2CjfgKtWNKbba7WRUlvVen2YRuWVMvEo/Djcdh0aBI5c8YDa86ifT96kOA6xG7WkIZykQ9OAIAA4DpJHEJX9fYUUu6UUq5x0SM8U3ZhGv+q/EDxqzu/n1qZ6IxqNf2u9LMZ+cus/vOU2dkJcID1TobvYgVCClqy9n7f6tp51OzWg3m6V6bJ3v90f6vwVG7VHYt9yhoESnRqZJ3cjmdfIF9jpaJS1IuQjIdGLJlChRCMxDktWynI7T6xSZDmLLCZuU2motiul70tC6Ri+nU3713NakYi+kCz5yKNEhgTEe4inOhWF0c2xsn20LG+c0Li4JtZljBRlIHemaWnzhz5Kin6LGP+rtphhzoYIZ3m1d/OFdMm72Y4v/v61bxHec2Zq4KLH4CYKzahIKiFmz9pbbf3tqiH9fODIyO0qi+xuNPT9l5xkymEsaZflV6mch/Ict2l4MxKREKPnRA42ogVRHKzzURiNQuSllqRomHwO5G87si5/BGWdcXkr5cpnTLzvwR2V75P7/l5cItCu1PtPmHP67k5xE8yDgbOEV4LR+0WeIV5ORydQMnalIiSRFIAoT5nLiUpO4r4nQXcAvoaZckMWNTMsyYaO4ZR971QqQzOtqgxBXnT+u9YjuqmlUVCZjnZXthwwXEIHC41ZpUfCgzmmd2+5DO/3399f5sOU105Td/FKyI8ZP1Btuo3x2o9tjjSa2yppJe2yI5GCihb8uthpTvR2mg534opMiAgT1CADMJEWp3h+FjujD2NJgZfo8X9WhxAPDWFAAs5PKSzD34eCH/+7JEVgAD/F7Ueegz8nuLynw8ZogPuWlP55h1AgYtaj2DFpkZSb7zcz6afQ6qZ5vuzLNAAXkGyBIfnEdTJf+1x4n4+Xk84r70KswnlHV6Po66EGbeIviX1siod2gpvmg0h815/m6s6xknsC/xWu7JpN3sFFloZjdI2EAAiCposhPCRFoGKOAzjRYA5QXYGXN2wncaypYkQ+fRF6fOI6Ul5VdlvmIA29K9zT4r9s5eYnlUIFxeO25PHaDsKNeg1pBIYX/owfFEp2BC+qex0GGh7c8acNIZ/lu5nrbrpzg5d+I5K1gtBaBgA2RArBMEqSWgiSXeIZVthAICSFh1qimBMeKp5K+XG/crUNbGmrB994E55fGndgKOfrck3cqdZZcErcQOy3EAnZK6rnkH71vNVStoxQS+78fQwefU5CMIO874iKhrKURagofGidTOZh677jRRHdiLyTudmo9XVnW6K2d6lOVxgULsgUMFG40mZ5b2VURJl3RUaSJkAIO2ukggsQvRIRa5cMB2BQ3GXEDGo8P1eqqxMDUyEIcOJ0xCXF5gtRfUrWjp7s7YxhtpGXx62dOznW+aNfMLtVhsGMebFBOa0z2LfkL6iEP5q/gWE+s/pd8bWnfqJr1a7o677lO7WlS12ZdFapruMPoyRhV/QyCgXaNItwizoSpTfjUK01DuzpJYwiWnaV+UbZ+UCflYUgArQlheYez+tN3cXNKFRyHtAc3fc3dV7oq9oOosc0pU0set9DrSSUBUf3dT1dWxV/K+nspC1ZFWtsPCBdFVFJ65V3t2alqKWowfpVpDtZdwxSqLAxlM2wsAhWqktZSM06D/+7JkgAAEV15TewxD8m/rqp9hBX4SNXtBjCEzQa2UaX2EoZkAByGlGF+FzUP0+FqghSd8KkKzEQQMJ0+uinRFKjbxp1IFijskFaCoYhQInlMPLeaII7x/RI0zlZ4Y5tRxrBOGiKgshctT/LyvRFW2UR9OGZaj0vOUtrVJdZDDa+1onbfiUEtsmi+zirMY91poIQshj6WteEuRPk2glq7KjVadynKq4sUJ9uo14tS4tQTpCy7m6uuMkBTbrhaabyaM+y9Y78ZzSPEpQ2dRsKAW6Lp6LPRpNZro5VbdxyyK2I1rSWbldwy2rZ5TXJ4AYRuZK6hlHbHJeepL+d3v5/8y459ufZ9I7s3kPXvCOqd4F5nrPBTzZBR2QE637QnCQADgArELIDBAQp1XkAcGoATBxCrSg/jOBTzzqwLl+3m2wH7NO8QTjLEfs+TRGxgXJG5zEiJ+Mov9Ubpc4vOk1L8bdZMy3lI2amqTZNMwi+CQ/k5yEWxnP9YgJelRyVptyvlvuEJnA+AgOD0ZttVcl87Uj3OjrvgzSHkRPH6x8tZqU7pA2gZahKQqisTG1djl76Z9W6PaXKKhQqqJCvyoMAgAgQ4shUWumG3CgQwUOy9laSjE4/6NbOEWPkDo+pMlMmLVllHMOlPdEBP6Mic4K9lWaOkiRqsVe7FoylqxWo7/VkXeOjWSqOLSHbv2qytd06bmdTS93QhxikNwp3v0EISAAEBMzPQhFSDUioPRBaQk+NA4ajqRpKEY5eg6MI5yd03eiy0d3okyKzjz2PqIF3XVkLzzagy+7Rw5zJ/bb22PUql6bliJs0YX9aq+ZZINrHYtb+D/+7Jkq4AEzV7OW09JcmdK6h5hJWZTmXE1bTE1SY4ep/WEleCV7t9tbtWv0u5+RAWqNRaYvFDmRbjGwqUHbTW3rnoOm0zXWVUZUVUyzdO/ued/ukRzd0mpDStsSwUQltIWMtkGSmv1zflv0K83IBHCWAQlblImJqAIBFdCLCgGTyydZAlo5rrU0FupKrrMvQoOSSFp+0bcrJCsXckJmr3M9GvM7mY1AFMjRdmdw4VF/2YVqjTVbp7ddtA+IqxjmozTobaum032mWmwoPDv9yoQ90gExIA5ssu9LAE4HQKmCCjqkvUwIslMjsgkkGmwpXXoi2jSEqNCE8GUW2m/1XE2LGI10vpC1H5gc5JSSm32ayOi9S/v3X3M1MEzWfnDffiDyn4hvUmsBN2Tq0+kO+Skc8oRz2Vzp5lIi7tyvq8JOtCZv1expUzBNn77Ty0r/1JaU9grvnJDIaAV0CFwocWXvfNpaK3FAZ6lZ96iUoSgUikK3VHssqKIfmhMJWYJktyMJWdICJySQC9HkUqoDyzTVxLTJ5VDGEUQqSahT1bqruyrHFJlZoc7bPsnTp9Nb9tFd1w3SrQxc+G8pRDXljXLc9hHtTiLxv7f/9BEBAABkKi0AhAD0xYsoGQgEAVRByZQ/qj6DrFI84IOZFIqgSgJ0r9WotpzLNdtg1U0J7zkc9AquY6YkIFc1A6KVwkkNgsfmoTjiYIk950K1w0S1oPCsxHXl445YW2JHsKLNqaIZDLuHmyf1Rq6IWOsYFZJKL92KyVpHQYY+2p4zJXxSlDwcr5wvrpnvqFC+FqrS5UJNxaDCw4KCgsDadV9LazbgahQRBP/+7Jk0gAEzF9OYwxMcGIIOf1hAmpUHWkwjOElweSvJ3WGFbACrgqRfJZkKlglyxYDLlXxNYiVbG+Iw0Dfvs0bYuQiseZZIw/W5Oe7u/EO1r3b795l6dOTVEEwq7TmqQgdcgHPi5GuZaur3LnmejdUq+ocFmmNok0go2dp2M9jpo9686NFG+NIA5iCLjhyi9Kir70vtroA0IAAYAAJvww4AQwMuXBZAHJh6IMSQosmZDoyYRPWq7cQbIBoylsSuW6J7YXIMaVDuMbfBH+pMvtGpCclpd0nIkjtVLQ7XanLEbvRH32O2UdTsvE+o9h+ZZL9MsJ8n7Vhk9zI5LVu6wIlOq9MtiRHidsuznRI5vLd9K0X0HcUrd1ylsJ9UeNv117Vv5aXuSU2f+L6czkR37XHZiY32ppbFiJ+Fgvn9l8GwzvPxzQ9c+s/iZugaJSgAQCJQFz1gzQAKCeZDYRYjIcd4gaF64ZvtrNEypEgR4q2fqrQ/p0iXlVemSJpoZHT6BNYFCf1tL7VRLTGzieNFjVnaowe8z3YBh8RfnYXdEG2d8YrRNlycxdfKV6XopOvZ8c3R1ETKF7dkxaCEDBAPAHQuFBQqgLvj4a65GHEI8z59CCg4xvK567Ap0TCjeBMoTqwBwhsrgXYyJ8XyogWMnRBT1ZOiNTirCoq2vK921az9YJrzhyWz9yUnfCSyimiXmX0qzDPZU8UXJCzqXEtfLaE5LeIv+pSERygkEjl54Sbd5xFq9hKW9Ja+9/iNP2z9pL6s/u051zt/W40ak8cquMMWUjxhwQA8udqmJrc7fvdev7W7RBSwQO5ekaS7aOVwhNF0rv/+7Jk7oAFk1/MY1hh8nDq+c1hJWxWAYM3bL2IwgOu6PWEGfiEQDwRZal7O2rtioJhBxkqmWO5U2gwVl5dhwgBqabZxSxnD/M3ZAq712zpXonNdlnkGRVT6JU5CGdoy/cVh6e9tggQMeybN8M5oOFvaf0t2LJ52+Mq23332b19iP2y+7Z4jN+W55O/7vusgEZhNOIwwgCB+IJTD9UB9BdHEfomLIunI61uj+Io9V0hSnCwZJTl3k+N681P8+Hao22vtBv0tvU4niKw4kgB3zzMT+x1SpHForEeOqEtX/2PmbPG+Q29JixlpDf5tfBs+liud8wPjRIhXlJ+U8MaxXE2nf6I/UEt9Je7aeO5/SCNYc/2CGvP08MaRKsQX3JYOz9S0tOMosrZhtvH4gtPtdGCqQzsAB1AARSy2IwuQ5UqiziP9zV5eD3Q9zbQEhAdZ382x2smyIwpP5aLeofG3NabzKd/C/XWedJXrSkve0wWXRWBbWrskbeyXJqaRw2OECydoryl241i2/F0EUSgkNsIm8SXNkJ/SMvKbZslOLrXPF2oMUlJHWwiKGyd9WlNlm3Koh0TpppkUL1mWQOvHg3q+/i7ZMsvCqqrZACAEQrdppSJwKNKEqkvU+3uibCE2m5yJouh4clU/MTty5euWGmWKUcTJjsOJopJmAMp9UQmUCo/i+Zt3qB1ENdmntVLoQEis1HlEpm81H+Hg8H86iupQMrnkG3oxRwqP+7lwYSZFLbnMeTLq86OVkJPfi7O65bXvUjkgoIomgNUyV4fBZFYemzuKteZpCM5qy6MAABDBULW4F8kMnScFWtk92YZ2rI1KL3/+7JE64AEo19QAeZj4JMLyjw8yW5SOXlJ7DDMwlexqT2EmjDqV1IzMttERKd0LSLyQ0W1E3SSyxOhdEYE0+05nYKXfqO2cnKHYQKi+/PH5cn6dJALtsRuyTRw5o/KB0sM0TnhCfzyO5syWHBn7/wWlNlop3j9UMYebla/fJ5jthSRxeXW7CRJEQeCEzgGEmqk3Drk2alvuc3F7RQlJWhDNSrQAAAMwHOW2dWgSL81EGVBnFhCeI4BTSxuIL1g+A5Y5Si8H4z6/m4sabXKPJ+uc9TJTO2PuY6wjb27hses/VtVQgyG/6vb505WqrO+HFmrQiFnKRZnmGRfFthtoiZv1ANQ+NzUktOY7C7MRVRPdyZybubzT1XPigp7LLf27OzCW/JygsvZ70VtFtuWuHXT+1/19L3kT5U3CTZUY0sQAAARFDiIQIqRzTE4RSX/UvOgKFuCMvADEFDHJV8OPGtq/qU+h1xY0nzFzqFJZswYiP/HPCnS4qQClplL+9clx33XhKPiyr/pijzo2GRyK6wIZJ+olV5in7Ym2HreVI+SRo67DppmEP8OxS5WZpJFx0Ccb4wxmkWetvxg2VMi4AibJQoLDr3YWChyxA/8tYEpwmZGXWaunC8mEqUZTLxsyHZRq8SshdWnnvPvxyzfMY9/5E6XYUSEv5mD8xzmtTFqvg4DJPM+7FsKBW+BXL1Uzs8I1ci+OYmwYxAhUemoUfEYLpmCzm4rgbJXIpNFYFiMZxITk3pEtCKgmBmECdVbSyMqmy0TGVDVNrI+S0ciHhNIoCR8xMFTW5Ka0mkmtIjfO05+Qmio8KqrGoyACMkYK9CICl7/+7Jk64EE4F7Q+wlk8IVrui9hiFwUoX05bLEvyg4uaH2Ejfj4P6m3DM1KkzGhsEVzevtmA46yCoSeQ2RrsNr3LDnuMUp0xEhxVmLEaqpX+tBNg2fc9JYET+PSyMk3TRTBg6gYVMc48Fl7pj+fP6qmDT8tKQJiJjm47UKvoq+4wL1XlB963BRlBRG5lmFCCmpKuKNLD1EgQEORCMAMzKSRCi186VXkHjy1KepEwoILaBddTGKS1sJfJ7YwpxJwmPQGhocIWFFW2VA9C1TjNQsDOwYQy2QnRZAjIPQpNMxRKFWg2L7h0KhGoIeRbSSOHFDOx5cIvauHaSkFbK+sqmPP+lMQkDsS2RjyBB4iXutisuPySzAXV0MpC0dR+fPKJElXPwUj9qzLMC0klvHThJ2MEmOAlnjLqFUxjnF8VZPXXImOnb/U6E8U0EibLAwjSPIwqiVEwJaxVcoCHLkggk5y0QU0YHE1eQbNrrG1oHiuYsXeaVaa+OGgZEzw0Ta3ErGtTVmHBa2iE5q9VEJsplKiZGik83KTS0d6rH/KVe3h6NGcXG0wt31zyTVKjPX1tEfRV6iy/RX2PFnxhszTTyOQBJBTkrQIjkYjeM7JAU2JGRAAX5kCZwoeodA9uBChR72wbhlbHIndB4c6ISyNHcJz9/0JCmy47MfSPFF7Hzk7o1q+t/F6yYR+Iz48S95TQ23ZXmpPeLwMFlIN1flj9CySFrt6WBpeBEIj+o+xVo0UFkeNLBVI/sTknkYJI9ksGpeSK80Ao0zAxNj3dVtU0cLGE/Z0pGoEWyQCWM8bTlS2xvGqaGIiraVCdkkk0RIAAQheVgT/+7Jk7gMFb17M2ylkcHrruf5liGYU8XsvDLEzgcSe5zWHlTn+aSCSt1lJd5DeRLweCUxoDezEmZJWE0UdFgwSsNBdMK4/rMzR5Nt8Xt921pzu0zZRF7Gd1IPjmfX3aiUmfqRFLniRpdtPKkqOMBlqnsNA5R/PFfkpQN8zntBX/saLAkkYV3///1UEAAGiwQIMiEvEZ8ZuHgYDTYLzGHhasDzluV0A4eVFTjgMBhF9FKksoUKZMfqALeyM8KC+csn6ra3J0e75vOompoupIZe55TuHCrqv0ZFw2sqHRbI9vNC5c2NSOSRY3cnUqlUSbTgJ1LwYR2oQxvsHOWNxajdiXstEdYy6Vg6jrw4KdaMRJ+VKnUMFj9B493YyCyuvRIf36EQ2LwiOWErBXYO5xJWrjMGFwkD81wnrycoyx6b2JwyXywhOusxVtMLS602mcpG4q8I/T/3CjyUrEgEADi8KDBQoyqzSGop9ZL0w9K01ppgzy0LtrgYxg2DXpfjkILZkTacKkQXa8SDLe/Lu/5ln05Z7jBIeWskrEqIcFc/CVP0ItUN+oo+hsk9Pp8xNC9qmjVU+8DF1FpWK1WmHoZOiy5j0BHt/Z8I0Q+x0mwAHBF3MAlL2mbInUOmNG2xkCDk6lACBSMGEC/+chjwYnSwpyYE5pInWEOUyfU6kUqrnhsavtBPedxbT3OyFnbKureVUPd6amvWy7H9fw10xylEr42sq9mg2RCl2qj4FqeajMSuxCwvo29FZN7GkC+MnGpXhOJ6ubVRGzWCAVi4bx5PG6gu0sHgNv+wJJclZnoynDbr63FbVBKDCPg+uTszKThJlBCb/+7Jk9IcGcGNJq29kcHUJKYllKHpW8XkqjT0xwactJzGEilCYrRTmhfK7c0TGmC8dK9fo/rBSeZnnQombQFBVzLxH9skrPYwVvokhA3LdXdR7c7WTsqxM0pWGgKDKVmWfpRbbtl1xgq6g1YrC9UR9uVikFvs+oNoUXxZdwz3K3Mllbb/Rsjvc7VZBkOPvR573+//lr7qZmkDgIwMRG/tVBENABBzFnjA2M28zLyEYBbc5kzB4bEAhRRwRLDQD3dSNQBMhWSxNYdndLL2vqHqqVXabZzc5S2peRcK1xPq5BVaTtWUVCNgv2UuJkTp9nOnUFi270vC9VkMWUx4/wrYz7l2LggVytiTPYEExmRXUTqvQKqa6VtlgQsh87zMG+V0wqrcqy/ppRPkUYThIGV1547pSLI500TCoj65IMdfOUUeMrkC+H51d1K43CSQ/X3E08N6auH9ZiQiUjPx0es4lQWdlWn+/W6Zbpc4eP116btzdYMEoxASpUgSAGMzW1VvNiiQGWQsOMiUKAKkljiQs2EI1mzTbHZzrKWzOhpSbcC/t08y3NXNmfX3ClqzrMr7Jo+9CAZOQz2U84Z6pzhj3ZtyN0zerfoV69Xtv67t/PtTdtWveIUod+QiyHMgAhAiQAaSAOyL8r4OWwvliwYcyrHiP/LGiFA1SKQ7CUIFaoBcR94XFrDqluU6YccaEln7IzlDYwqn96SHlb0WXnTtbdD2sV6faYSe7qtbH2Kv+lDN9o5PWOoYsbvHpurt7My2tl9pLal3F/7cTCQ42TDxyhYHBhs/WOa0WmFCGrG07HGzNHCRjTkEeroz1CAkucDJlSKP/+7Jk6YEGk2NJoy9lYGrK+b9p4lxVaXsxzDE1yeqs532DDenVV1NdvZDYbm2yeY+pMTmlYAAO5/NEQwqIpEUcAIJR6AxNn4jEXymUiTmtDFyo0uGga5agRlZEJnTAMoH80aeedbTBUafD8SdGmETjJJgWb7mTvdqHMLYX9duiwZfT4jsOlcuOellDvlT9xccWaB4LYQWiFfQiyZK72E5u7IigbxNzd8TBFPKyeAPWPj0m/4gFVoBFwoogBlC08yACM4CICjGYrLhQCfPVN19ujKZuAHViETfh068t1Ko7Sv4/8bqzTJFHYvQ2SLSgswLRHoInFStSnq224etUR6sVVCLFmAlDnXCMbDoqzqw6yCHgThySZ1yH4n42LtmC4MyUNOr/eFPCgOoavmpjDxwowKVuiMzC3mWukghDgcDfdcPWPaoYX50Mj15RRoe5s8WHBXnXV8d5Z4mIlG4gjio3FgdNjQhagjvEPJGGrIyXowBZR11YS+HQvrB/siHzIRhX+R154k2JoMkFqljzd6Opv1ACNMgHWwCQSpbOcLJApG4Fqk+01Gc1WGppvi3vEIOaOFhatV4fRMLlp/ycVArY2269ZDiFLTPtx3sxL5IP7HLB0WVZGQB8H8FiBPEJJwh6vPZlWjnE/EcZSYmGTtpityNj41C0nbp5hlgSxDfesbE9YnCO8YHFn2wMbDZHNDxUn8bj1Xnon9tbGdaQSkBjMh1HZnFLIZpjZMNjAsRGCHEgSqNkiVMttOtvb51wfq6VcNSLRIDhKlgRLCFe2uTOiGtdthdGV0/gPb3jUhPdeJiaj6UO97ekkCaaUkeAAYUPTQD/+7BE34AG7WhN6wZ9kNcM6cxhj24VuYs7Z5mRQmYvaLz0mxFwNJCQ/CakugswdBMYDt8sFjTrw8JCKTEwkhVoLO0eTTeE8ItIw0vlfZKeNstegMMmnQOCEMtvwwa27ZKermRWD4UMcWnistjXriisWmX6y8YPVJGD3ZuMxWbVWYc4iMU5oVEFFVCyDkqlDIp0e6tjRGT5jE2erHlVEqZlVEnRLKpDImrDrmWMw9WF9vT4yZadLN6P0jeWJjZ2f+32mFDBcKs9IkTpbkzK/SQACCMDVVoBYDJQ0zwGwmSODODTF3gGNmKfb0+EIka0vIhqzNjasnrpznsrXajQ1VK54FSg0+o9kykuf2c8suwlDEZ4oQ3WddmFcmWGACBZeQK2cTCrKq9ayBD1CeS5s/rVrQaYcBEo/19LWVL4zSUkmx1oEYuLmKer8YaRM+y3y6tIweFMifjdGNizkpSbfmr/OgE2eRJELkAANIh4rpIuA8iXpfoGgYYDyuSPPUI/nCAbprDzM41j1cLTQckGDmkR1MAHR/q7Rdl2qiVyczh/7ORTD0PcYkmltKRs6IRg7WH4q5cmSpu4othSjPYW3BdOGeWk5NgxdQ6Mzx6IRvkIgj9FbldWhPKqnk6Gu85EGN2Vp+nzY02vD6ygf9LehPvxlVuinSSIdvHO6xetgu/QpgYPakl4k9NrQ5h5WmZPyyI525msWTK2kaW+pRALVUppQKhFUz4MgzNXqkG7hN25oxwLzKfopXYm6R7rGJJ5aPIeKo4h1ZiUUturZq0b+59zryRBAhXU1/zJiN6oPHkVnNTVZqJy8azaGMq361I798qVGP/7smSIgQWWYk7zD2KgecuqX2EFmhaljTVtPY/B1yzovYSOMO1EbUXqxrIgkyCqtGhMylBA+yDuwmDYJPh23oBDfQTWARbDm7GUV4WvjMVGg0klYz5kShiPb/006uAym4h0MmDp6wxHGI1M19yq5n1I251mrcp9NsLVpXjO5ekeb4hXcKrlxhsJVjFe4qyzRLPUJefSqpowdqOW0VGzzcPfzb5Nqtal6ic8exORlsRVWxwb4EVvKlTljp5qjR2VYLKj2dSHoyXSWTJdKdEd2XOnyJt2q5seR9SG1Hzc9acHE8eXqKTNnHLRpWO+YvmXMLKp7H9SOWMzpDNq20QCNaSBJAAEiU1OHDJHW33mW9bkvOa5dizqP3XixA+iYhEySWMyfUUKW1sbxBabqe/L+f7VVrU5eJCAjvJO7ktLdhvuoq0ScmLLtJRJEUl//cUbbZdX5fy22v6ka6X1bjQrxfVS1voK+EPWNUDVVRDwCgAzCeMFAhABkhOCh1fcOt1R+WyumZIQBpjQqZyHVU3GbZeRXLpVB/7K2o8R1dmzBpDdKSonOcnExj1pcz9q9uLZM14GGaSmRmMOmRgvo2Lp7ezAsU1ixNrbkh+SKxKLbDLV3aZ3r1iq2LRjfXsL183a26k1CiH9SBBh4o2J3W5FenocE/nVNtb2BtcwZXGWdEuU6+rKbbtnDNAU8rdZsP46tWoyW+WYPAq2Glf/2gpWTETG3awErD1OYU0AZyYPMKIbL7/N9HJRZ+68kgjcilNFb3MSVl+rF91qzolFMRbjrog8i8qVKshB4Cs6KaV00AXERhzqVyHcrZG2Pq19bM1yBC6Lk//7smSEAQWHXkvDbHvwceu57mCjrBRFeS2NYYNBiCzndYMV6bSXq3pZs+2Wh/7MfZZop/PhEKGwinR51RNdoAEFARMIHZkmUBwsxSM7iTDXCVTIswO1wcMsaIN5SRVNdaKwDAgCgw0ghyVF82O3m2zrqJHkCXCe7UvVrSWkjeUu1MtRUnNOmhyZ6UKCaacDxDcHDGD6I0+MJvad4/7+kqxXeuw+zi3twlG/urXH6BlATeKt3YvIyx3FaGtm9/m50wjQ18PSy1nt2gVe0+ZPWSszk26zE5kxPdN3ZnYj18I8JJlqJrNuIgBI5rryRJ4BQlHJJDEjm28lk13tA6qdp0GCiizx2y3+pzfyNesyrJoKeipbG1Ypjo4sYBjma+rLpff0PVN9KU/r31NZndaVs7J2K3OlHKSq5d0t1VVKVSoP8Y7iAERAAFIHSUiWIUFAkMYkigez8AkwwaNApY2NEMtTjp/WdQNHYFYTDUO1gtrU2sNoNtHA9g5uoY3c2xcObUyrV9NkFwtvFJqO0M34k0Cymmi7kguP7c8tkkRO8zQl2pITc1MbnmGsx7VAUQsgT3dko7PMk3UJJ+MYps1Y4dNir2Svr2gWfA6aemex/hKMGG+/vXfAriN/em7riV0Tj11n4nLKxyYztVbYhjJKMbkoPZ6KgoHxR0FDmbvJKE+lpog8dQhef6ajwtpDKGf/zOw46UTq+KCTmEREVe69S6M4CiTsMWxBgig0eiUGKxZBY0Y+p3ZiO+zbI1eUSgW0e8XtYEmt6osjTYldvSAE8AAZBAEyfJUY6QHTgAHF5IsgMC4EWls5KocQA2YY8om8h7b2XP/7smSYAAUZWkrbT0xwZkfJzWWFZhPJey2NPTHByq0mdaYVoCQucGFVMtsdZUc7md2p8P1Vp7pNNf387+Fh773fzXXNY/s45tR1q0KWk3fl3j1nHlbWHyjrjErNptjb111mbImUv+fR/VX7SNvV4t7e3XVMJdKImr01OWtn96UIeta6Xu6e6uXg6Hgttkmx3G2enWQ9PjcsVb//QEOpAy6SCQCzMXlnDAEhKjTGZRxZuqFittJlVddj342DYw2A6+LmFBldEbBhSACbq26vOVrEHOrGu1nq67nIEhXQ9rh0zDX4uOW7nd0fl0Rt05lozcTbV6kU8rdroRX2TTfzHLsZKKUaHhUXwxz5Ngsa4+oIAwkEwAKRZElDpELG5bsWBGoiMATOJgpYBE1JEFB0UpmUMNvQ1As6mi830wkEaUbvvuCTE16diKJ82cnY0cz52svZt5Rl6rtgJ82FAQLKyl6dODhiKImLb4ZHuytQ2XG4emYkTl4lM9jLK6ZvO4ov6JdSbq161dsWJHPcMr9fMON5YjP/AiV8PVvv122blpuClHec5g78dXfx0d9YpFPijea7P/9eoYUKJSRkIkBAONcJmmp8ga6UprqKwqiljZ3DUGj1mxgauOSmRXL6YzT6anvMHruVwLoMBvJJGiecP/80gBX5Z9e9EHSRKOk6XNPFUrRTEL9cu/vcmpuo5GOLBcMZ8q9aCBCASACajQEgISEaEFQEZYBVnaYPApkhAL4Ljsve+XjwJwgL1QbD+X0jziS4+RZYtrz2rBy9RafLnqJYXefWPXlW27MKem+YIrGwkrKXxqeTE7tXrKdUaXn217RJ6//7smSyAQU0XErbbHzwX8U5rWWDaBSZeSs1pgABtyvmNrSgAF3+3C+e3T3W9tLz2GD3S8/L5JWTRYtmUItYjhcerMcSuk1P7ytq99W+5v5je5E1613rV9JSy123aaoMzSvTBVpuKmbP//VqBDTaqUKAAAJuIoQLZWDBhkiaa6Z9ghB2balsgRvb2tDS7RAqHShAOUJxsVIBiSucFGQn3Q2aa08gKmq7rVk7e7DInfrzCZzaVQ3n2u+hjWe0496zs06p5TtoX7P3Xeb9VzOqH8lO75Qu4aeXv6ogYiMyl4+HkJhoNBoRkuej0HCSEkEJBxF5NkwO19S86RMGppY002K0aIhGYAkERSGmenbSY5VDMTpbsSHiB8RE/5pEQBTPw/tWWSt331h8CLG8Vcp3QntS+YsRSua1waCc65FIh5jd1b520/9SL09oFGIZF+GIBk5gESffL+sPqSik5Yp/a6cSwgNNkNpqICIlaxvO5z5ixK9z+f551qKKR5MAMLUcCAEki7Ed7ut387WWeOGu1pzO73W+ZgYxYFAe1V7oo4ZatCtStoVj6ud/dLey7///35fcvXt5W9aw1znpgKuYI7bWVN30VHRO+2jptPeTP/////////////////////////////////////wt4c5K5+d2oBgeRQOhyeBgMBgIB2DTBy5IjAmRGmNOnI6U7F0gwULNiiMmAcaOoB0+zEFww9FJYu9U5M03vlc1Bya7JKcHaDeoF6+aosG0aWwcAnJ+o+l6ZZT2qOkLaFyFYE66MZQEEL7ggkN0VXu737hyMTigigCdIQBPNR9SxQCLbqZ81xahcf/7skTNAAjChc/ubyADGZD6Xc1gABRBd2G9h4AKEq8sM7CAANQd15ZGJYXPRAV+XyZa6zVrlndute3c5nlhchiKO/L+xGOPWpVEGdxdYy5O/ru99/96sV7cOWOZPpFI3bbi1FvYadzdM1pgLhNUzt517Vm9zLWv//5I4xduxvKcp+y/LB+60PPA4M7p8JQ9L+XolMWqCe///////////////////ljn/n//////////////9XdnW/tby+0isEx1opAgoqS1dwjMCTxBMF7F9KCxZ432b5xnSXezlOg8WUjoZOmlUxUQft4r5nuqcpBQrEmmPEJ45MELb3MuGqNid2/tJmNChOVpH+M2tqSutQIUZ9SSPTVabtA3S0auqMsu4kasm6+asH+PJnvN+9dRc7r8Wxn0vfGLe+c4x84ixcy53amdVm1/i2MR8a9N+HFpM5b8sGC98lgp6nfTcfL2h8XVEICobNXnmCgBYMhuhxaCr2NI9NeibB2xwlr72gRDkFQhlCMDYgGgubnCw4482mQkTy9OTVCqUPQ4mj7rHNWbjSj1Ldhiq4sjLGP8cnRWO6HKWcaymxDNH33ZrQRfOREdf31dO933CR8JU9fxXvfX1MddDQ/PMlj2lKt8YjBPULsi9WFDeGVDGVIHBnbfARgCYVw9woAp4b6sDwOw0j7IauS6QWxbRL1ahMwOOuEDW0JQQOah1qlMZB6EWjWl3hAh6wsfe1ssye7/P/KSI0WyyNR0jzyB9knikvpTyM7Z9PJKvrnq5U4fW407hrmEVJM8Khqfm5DlhRhCwSuD2oaGbzv6/95qvRtpFECCeXwpBbw/kP/7skRIAAQNWFjx5hzifmtLDDzDqhBZaWHHmHjKAa1suPMOWPCNBGgiTiLGH8OTKDMaKpLSoFWqlKa20womFi0VBjXeH824OfwNTyyVHNBEH7KAiCG1EVhk291EuWLGsdyzfpWhZRJGkEQZGhEya4muhdYpMuERWnoeeTHbOQ/KKhFnmx6fEbJGgAquKdLS4NmfY+mEZFZWQSlAAgNqcEFP4XckBxgVCHFArjCDqLCIUahbDfnPhRKNUPPDVb28J/aC3O4ED4m9avVMY6F+bk94JrourLZfvB7PkoeqZOvhlxsxZVMdtb5Zso4YykLFKEEpH1Y13wvuk95axcX7CLSakyn3L4WthE4JUQKoTrKctX4d0Zb/YhGZoZ2IulUcDidZMgXxCoSyDCFCjBazDFjJaXkilM5sx2nAr01BxUL2GPY7SckX6N1hoYuaowpRqVAg7cFAYY78Es7mCtsA3MwjDFSgNiyRTNftUCY3YiEkEFviwnatmqaznyTL86PSXe09SZPJPTOMTqOJJ0xFtCIHpcWF3WkUqqV4OFQiOEkAAsuQNGQLYSREWTCEGmhzKDzapEzMUGbw+39MVSKrFBCGHG0CWEnKtiWr080tkcIsc5yRmTZbhRZ/lCk76/W73g5qe5MzMyp3FtTLvpMW8Y7392ksiS6eGMjdztlG4Z1az//Gqul3f1NR5+VLN27fCQSguEqaEmfO1wvOubci3ufqnanaVQzqQQADLJNiWwDjr5VGpWwBE+B5KregbJEfW9g17a1indntvkWGyxREIB0Alk8pJOSZOyR6JCtKRII7j9uczXhuBF8he1HPwmm877zM2//7skRtgARGXth7DDMSgutLH2DFnFB1YWHMJG8KIi7rvYYZoZrZruVaWOz7s1zHcrjmQiuR2rQzmQrP1kYrGdNLU5mLa9qBokZhxzCDlHXG51e339vD4qu7IXCCWjO9yAlA1mCQw0RTVqTqQ0rOkU09zXKe11MCgBx1ZswLKbKRG869+Nsz1pUhm97Lk0BhHdBzOiUBohsaoqDKZRnI64vdQ2YIrUQehXY1RqQxEnGVlViKsCUpbae5raVMhIzCIEEpaooSJ7wlY4C2HwcwYKhUoUuPUf3/+s1iUU1QxhBAALarhJ0W0rEfAxcDKvdV3W8anLrwSpB8fL447VhWeHH7ROcFKnrExJ02pZMpp3oaf1njbI59aUjWyF/EapTo6UzbYHoZ95u3GtaB84J2T9QmOj73ZeWlnVlSdj+HaMVbVDqh4U5dM6R3pjVZEY37/v9pivzsTwu9aGTdNsa1cyyahEhnZlJOUBsACfrBcLgNMdRFBPB23lVVTJfuWqcOhmiIwVJyAzM3gusuTOvZMo9Qb+e7IMQVJgFG4ZiiSuGBxQatVViIyozrBQEZiMwZ6Wk7wUaiRAnONdfzP95Qe7CYy1mS7UiIzADUmdgfugV9tzvEyVYLEVUGn+qCr9hfNQUtm8sbWQAOVT8O9PCmCkCbg5yBA5tkCLygm4x2KsCB1s4EewNqTc4ExKgk0wta0/ZbMWE+0yrGVz2bbqq6tyUlFpSgt4J5tnYeT0KmGV4RaUuWwSRh0xYQiWRqVeELz19KDYUChIWR5+e4oGpFyqxLAckKF8+L4CIMw4zp5UFVhX2ZhblnkkacJIBCa49L4L8rWP/7skSJABQCWlfzCRvCg0s63D0jnE/JNVusGG+J87ArLPMOOYiLrf1YtDD7IE9qDNvJmXyCGoDYoQAyROEyMuy05MKvTqs5RtoNyDksIJSdKrUd5L1Q4HjWCnYAKMG2FUGJVXWhiawLapQhYmKKMMJkmf5Mhi6SuWpSE9ahifHJQdYEkAxVrtSFBcyuv4V9Wwc395M5FK4VgPs+2sMgOI5YAmhDT/VSCDObE8g4rvCnUi8ZrCjgtSRKIPWdD1C86BI2zdPd1LN5hXwMpktZveybhR8zjUxZkoulro3eNtzigs6NWh5BGgVkT74pPJHUPkwGMbHEdXMVSOlCFpym7PdPy+1BKb00hV7csFuVG+bchUUS3kQAABGr14LtOgyzyLIVbEeTMTF+iEekzjVkzYxunkSdS0vp2WiajVu9U1jm3DcSo3pEjHNwpLMHGZJN0K7CErQTQR0icPwjm2cX4Ll1EDHOAs9RNCg0MU5NNDdhI3bVEWiAEniusCg2kiaZznmRfhi4fwglVlGOCgowkx9fYvSv26NEggAqAuojcElMAARFKDiFNLezickhdjvyqDTMRzfrlCGGE4yFwUOOqJOZ3Xb4kh4R8PLFGlIp9lZwk5C4dq9lHGabGIWkSyl/mxWHbeFrmHdORuz2bKS2gnPU4YSoLQZqR29e+m+amZHDmXoSlJR2CuApEN4EQFBNutejV+S6qJqyEXAAWhEgMUqNBgaV6Ymqgq+N9dNNC44TbtigyKxKI0MV3Wtg4DLsFIBAMQ1SBplFER5ukvbl7jyYHSko+ufrRUZpuUijVol2pLckubEgnOqEIMz9Coh8vDcj1v/7skSxAAQKWdVh5h1QgWsazTzDnFBlZVfMGHNKCC2q8PMOsQL4cucJYu5jSl5gimaUjJ0rZKyZVor7BoFPkCoGltY/+B1P6jaWliWACWEJWdAQC3j5cRPinTbEKEXJWMqMN7SGtqTjq1zgw36FQE+/wPIIle9oeFzBepsYtG9OsxmG0mg7PKfOK3ceTZxC9yHuKn1DrTqqKlWKjTqpLPFu0RXGk6ZT0pmqoDImZkCUZDJleHSMhBA1k5SUV4KMXMWSDTrvfuYjb5mEFjc3USaIJCUBSGss+Vw0nbS0GV/Uj8rpeuBbC/nHdqFUb0x8gl0F5IkAciFIoYjczC9Qc2F+aOpXNRk69pH+DUcNzCFf+DaVDIlLTUOgMi9oqmZuVhGfabFxjCwDMoCqwS5Z9ezVY/kTEdvHFGNOvJUDwYxUeBdz/T/+Sv+11pzQhQAGBBJ9gCsAkFChliZShVFaX0wVasEr9dllwNoSY2ON4wj2DhQIFiEl1iS+y7pJZ+sYk8tc7bZh2dca2UEpZD71v8zBZCHLxip0cGTEh2GGQeIyyjFRQJ2Ijm2JFfV8Mv53jmTwR7AvglZDqe9B0SQAqqQW+71f//1OgnmogMBXNSxAeevtNVcyZZexD+GEqGyQqUNTmliEzAEBoGZaj+6TIwJhaPs0hNYjInI35MqZnE94RgnKlzCFOzEzzaZiEkaFx8nkXFjgN2rEXNL2k4J4ibwhcEkTYcyi6o9OcJomTRemFMf/DnnH53dUW0w1Er0rvO1GM65v/Gdpp7T6ppQoOg9h/aihhR6pEoCqKmdJYdPdQEvSwlUUDLFGjIeM6aSgH4HICv/7skTUgAPzUVZ7BhxifolanGEjflGdZ09sJM/CPC1p7YYZkOExKUuVL4QBmJWMmD810AEehc1h6d3jo2/g8J5YRBWBiSRpEJLwiaWGE0OJ81CZQIsUambFXHMLCCVnoRPEFLlwMyKInlxWRZkHQxR6XVrRcl0fKHers/O7PEcChCs+RtvDGX1NgQU4bAYQKPB7omFfPwABD5YDDA0gC8IEYInoNWyGCFBwpBGD/YFExMEFAZdIdsQK5ohfI7huCxmaa9oU1QrGV0fuiA6N1MuG2ShERTJKtNtxSyMzCQECiRBgrnwajognOYFSDmHmwGjgyjieMLkocYUZ0SeVhFmo5eA0yaXFWjGKdBI4lGthl+CSV5vmNNs8tzDLQFLfX+aVFIxxWlv507tKgQZAAEAQgnOE0KWHgLQOUrZzpDZIT6lgSRvV6HKBZzBgTPLGqgOUnin08J0k23NB+126KCr2smuzYjRMzQLE50fNtbeYUqSGfkSppo1It6za51lqDZLgXTqCjM7kqmg6m4XNILTPROnceW8+iSKLTtba9vDqwjvaycw8Zcz5iN21wFGLWZl9qnuUUAjt7lsYg9XTGm4kCGDIXxQgF1FQzilAIrYUKlBYGMtx5yXoRg4HiUPtoQwf/ENkuC7EJMrGmkzJ40XUUNNyZgpja0i50SzpsSk0hCqvuSoUxSKImTggnNlVdEvHGvjbCdrv2EWqfLZSRQqDeSuuIV142zGU9yfZc5+1L4mtcqat2Rdqb0s3VL+Pm6OY3OR5aa2uUk4o7VhLqzv5o8soiUAAICMGScIKoKclIKgCIGDKDaYhhIJubjsLflrdIv/7skTvgwSvXtLB6TPik0vKWz0mnhJ5Z0qMPSNKWjFpcPSieJ8zUlDhmbQV7TRrsqukk5A4geqKsxldli1F12YCsSsWXEpAmYTowtsj8KKVJGIH0uqdYhDNfTbqhG0SaxE318ewrayGsfHGgtPiBTlauok40tO02JZlzmvpbVyOpInGWVMXECjgxDHDiKikdoSXvqsq4nZEqqQiIzQSAQACBcAFGEF6WAr/kqHYuzTUzOUc6J3+M3dI3ROHiF5cLCIk7m0aJVlZOJSaFRrqPOokMoKwMrHZPhO2IRTZMIhAigZnYejVG4xRpssIPkzXdK9QdpIMRQLKeSS0VSRIYdR+YSO+EjPrYjbI0v27xGrnx3zcXr/5h76zV8h+i2pOmgnmtaJQ0tjTopy6nv5k4ymEBAAIGYkUjJhoc1RsaZcpSway2Jfeo8eCsOI8QCorWQDQKm5YfbWsMsQbBj0O3RWodIq3dYRVdeeh1/9TwxIY0HoqUFxCH9HOdceSLPD259CUtWeA8k4ZMNYw6B5ppp0tNsc62UMf83oyztX5azrlttd4dmTV+RjR3vOjSOOFyI6C9HMDd8pB1fHyIIjKgkKAAcoABwGhe7qecFoTlb0+WXo7L0ZI44UNhXW5OKR/6xWHZbQz46OGThtHktRt3hdU3q8xMeHKKz9YMq2dtMlnVy7oXlGQ5K0BVIEySKIYKz9AOgCqGOjGxta0zRI20nlnParUu2bGKLyF0TXXtXrwlsn5n/2DdfNeuzP/vzcOnXc+svtQe63vq90SyzprjaAAELhfJXMgGDhBgyDW15uTJE0FbJQ15voYZfDsovzA71TE9f/7skTtAQShXNLzCTPyjUtaXGGIblI5Z0nMsM3Kay2orYYaOWHzBbK3vI9s7LzyvrOLD6D1Ea39hcZO193iWqRL/1ih7RBjhSXKh7rqFyM/Jz76YtNtwKEy9e+isAgZKTDOQ+yFFQnMSB6Kc0xOC0sw3lw2Gpl0arS3pbUR18uWdj68ppY+zXeUa1K/+e68rXvHy35K7/stkcEaRKAAOQBniqkTGITC82vABC48Ioociu/LwBjpIbdFnktUzVFElRE48h5DMGugOU3dCuaVJLzXo85pG1SIsIm0p5ZKLAsKbJDgYxHMw1A/ULs7EpIpImjWSyHumVueoRUU6L+4+Ft0R2TjW+Tuxa23wtqKaHUzztu5pvnY+5iO8jJUOq4qNINiDWJJoz+2dGSWBGM4BAQCEhY9QVx4hviYhlCT7bg4xZ3Re0ExRTpRSXRozu1EKaMJoOVS2tGEb1TxW8cuPs6f6+Zts81JS1cYIs9JQ7aNrOdeNGdXxjHBZYPqQlMwnyJoay4sjgAFGQQGobBzpczaZk5eJDFuFRTAyTbmGL7T36fdIh/W+otFv2+bu5/4qWzE9IiEIjmZ8G6krSCdSJAAAEFiPQOtOZE/BoVMvBm6c73lqVbY2zihiLnW7L3wxMX6S2w2WS6vKEE1BTECVS5HSumlN2ICLzCKMTEI8gwwwPyw72iITxi99sGrmqREiplCiKHEZ5VhrqkPMZBXTqFrTqe1WL32Nfq+vUEgyAIMyKDrFC4CJ8Qw0gVDbLQ/uCJZStsIwISNQFQvZUpluz/Ox+w2eApNlEQBnIIoQFYCSA/NYORDBEkqKceClFjclKZSrv/7skTtgBSTXlHjDDNykWs6Kz2GjBMZa0OMJHWKVC0obPSaODG+wg0SaKQCxFmCIkLaZQ5yMntZAIiKdokDWDDayKZgsrQK1yjTxDBOZYyqeQI4xFXUXISJCoeDLS6654i2EopEEzSPCTVHbAV2gLzDVxDDKsylPWgbRj3sM3d9WWY855n1Uu7GZTfPXY9qUj/JayAFMRM6pbqVYGmZIQAAGSGZolKTNFRWkngYYyzeJvlFlLvhix8pLTK0ks1wUpVsBLwu/cpLH23RCf9e7/wozlHhkdbrS0v9YfDWcOG0epmlszuWmgFTr1QsTPBSZll2EoPHsoYEbkQwa47W04PSibTgP48p0u2fgXu9UNtGmuturP4GNznPx1eU49qhYGutPW+VA+6lE1a+kbxYvqCQdkEQGDrtNldsRxTnT7DPPNYV4iUgmgR/HX+nqPKQGjR2cV2CVUiKIUDdKppFkk3oZkrbUJKTHoRNQCkUzbPfSey6rfl4Rmb2/YCmaNDc8wLBJPaNo6pOFDtk4hUFAWpn4huNtPRUb3pLNOb4kX7M9aXWNGlwABBlmm9QLaXe9azpoGRKkQARrWlzDIc0ZexqHkgystC6AyBhoJA1+JUL2ObUbWH2dQfb0Hw9OnJJOEdDU+eYSIa6GIlidzJyHq6iwswccmRKpAWEyih8IfRSpNeodFNRJeoxnH5q/EepXbsHih7LazKGrmrJQh6jLijsVOT8c48kxHsL3ZC196eGctLalLvvfvsdm794X6XGdV0dBKPSjvm136l+hvNcGeIZbjgTAAgAbvqpwtbg1IuaypGRbsnQwbqo0re0K97yTjztkP/7smTsAgSiZtDjDEPygwnaG2EmelPBeUGMMNPKHCRoLYYaOcTSoqeQntigh5UTTcxzW4VO0P/XHT7qkqQQqkTCPLnEr+327epabWtNexd9e3dMVV8L7ePNmSPVili6R24rTchplDaDZpvftT17JmvjmlSbOs3ZcZMKXx1rUv716yPFnp5b8frVgBCAIAAAEHhrKPKaIEUsLpVGRfT4abWcJ1q/X9YXS1mtwWY76CbgvD/eKgsU07UoU9eE5EuWKqxHql1K4OCtwolXNh41m7BkXyYwJURA8WA0Kq0fZLolE4wIfO1OaI3O3RHtz4jofu6tw8ZOpHokDMelAyjqJAS7EqZdFhxKquhOytjfQhTn5G1/etVY4ahPFK9sHap5u+psbg3TCyZjNo2x97N+7/qbfxZ2L9Ymo1QAAAA0NPM0lAYBQlAHlVykhA4k1S9ZENKZjMnFCWrLHDVYyXDuKE4BBCoCEUqOXiG2tBqBFnANERj0anyNrQ2JfkyLAn4Y9EgTIqJulk4RMuq9K2DLmYfn00IsfmG9izrz7f8s9Nr1ePevXnEkT2ONuEIg6VTvUPgQHetmT7Lb/eurwAKkh1MgwgIDqptfGBteaTYkpbdqzZ6sjgql6viH5dnqJwQ06tNxJCVeWkRbhPgIOuHDglmq0RwoaaEtO5KFheNozMuU9PZDVjWRRHP4ikdu4mbJRsHA9jE1WMOe+0W6XL90NfK5K/w8D6VX38OEHVR0Xu6qH8CxDRVEsO4P5/b2Q1jcvJFE7Qe3yI1wS6eLzUp904WPKIDGtnj7ZN8LL3SEIbz+8Tvpp6ZAbxyuNyABXZWEJgNFCv/7smT1AgVoYU9jD0xyhGl6DGGGZlVtgzqsMNXCHy2osZSZ0JPUmFAAKtLcnpQnohuoiG1CpH5hYMgQBa9BcPIRWQMlkjUyR5fLP8Jnsa21Hy9bPa5gm04QIAkebNOQgzacup+H9s3YwogbhDxjr2tqzLtsu/raTr5UV3e7aJb3n2seZUgbUtuYQl2n2YgZ3iLWxU9ZAhEIYKCgvsfepTNUSGIhGEAPSdn1Dl7hcqFS7kqVvx9naKqtDZnYhF7MrhYtS3BAcLiyZ1ydS8dN+d8x1zuqKn6hu/bfYwoUb42oK3D2Jkkn7lNQ90m+mTF1OefFl/PJ5vxuOSLeayTE9VQeOtqvnqD+MoqRl7RqmUBjeTQJz2rAiJxWjeYXPCofbXt4YOwScEJ69zUHnDzDUZwzL/bm3DOaKpoh9IC4VeuuARIDiI9P2kYklDsbae2kz1xs6Sv823d1afKPP1Gc6Gb5VpFhTk08xcEe9oW59Jvc5+Um2MhJqEvrwUzKdcgSkstyDNzyVvlznh6Y0umuG+pv8JWkeUMHTCG1g8TGQQW9kmNM2beLxt97KbOeyLEcslbLLproCEEiFVdMMbqs2o5Icc7tGmx/1hWhhKGJGIQkAAAEEF2PQgCVViCVzcljN9Lngb+XSy1ecle2Qj96mI2jjpZBm+vNTFd63FFMPzul0Myiv7tmdtb9avdH0bZ2mxrqvZsHqsK6QCUyKYs3VE/R+fvFjuDWdpzgsviisbDjy0zlTE01tO+sbUc8Nmklo4lU5iSfxJIOcXjP0E9OnDRzWQLmA2DqlN2OpckOHUzRJgAJKwuxdSgcEv3SDhC75WOLs//7sETqAAStX1JzBkvylIwKXmDJrlI1ZUXsMM/COa1pOYYhuRacpzVsciCuweAtGBwsMhGPHnTnc+0LvMvTtDZfXSuw91mWXrYhdVdsaK3roC6RefN8BaiqOFasa9EHi9KNnriRkPU34gvGatxbNRYknKmbo41Uar6qXmS5qpaZlZlp4gZeQu9Ww4aNAk7DzTrSpm6Jrd5u/82qggeKAItIH1eBO5JZdkmJYBIy84qxThEA6zJUynE8VfPZQWWcJkdJbapZQmauEzQTWzK/ZXOZGyvbilM5HqUXhWi1YKGFjYPxJx0EeZhHjDfTscU9tC8Gq/SgV1KwxL7OlVR7ksACmtUq9N98EZq3kgtY2YvOUdEpR7xeR/AVUTljI7Yy6IysyOj8DVVr/LOb+itmWkxPV1JRrAjx+zepSp+VPVs0/Yb3Sfab7+1ichYkqljVl3AAhGWwAViMxzgbh0LcSowAgaaCRBKLwZFtc4fvoxmLD7QcaLNVJG/ae/bJm7fbHXzhdEtXPO2kWZUNaY4C3na73mp1vK7pJUrx7dLTLYqu9FKqK+5czknvoZUFk1OXOK0NWp0dGXKDlWHh7oVXoLstFgViACCbiNKKbFSAoV+BkBHZeEqedeyrGHwmY9gbDKbh0u77LwHCSqRxFkJ47etNpnjGzMtnyyX2jC2tK3Lc0o24RNBizYPxFrqAyXVMQWCTJiDRVu1QQJvigoH1ER5PFQDoGpQN7SQuHJoxEtSpSOSTFLnYNQPFgXCpmRYMv5SphxcyQkuNHz8tEkHUFiI/B5KVs7pC0siSmzCBZpKQYj0aGLteJOstaV4yhnYqet7q//uyZOuDBXpizyMPYlB2i7peYYVeFhl7OIw9LcHQJCgRhI35pFWoSJ0flrKQAoVMh7khVqzcYTbVUuP252pcCpkDiARtSLjSH3C9Z8p/yls7HY2gaX0w2t+qp1k2ZQQxxhDWIVZFNuKe0VBCH2pUjciePi4WEs9iOQOj/HFHw+SHYV9ctgzriuhTQ9hJT34QlM/GFk/znaogRskgN/JlO1XAEQcNHwKiZigq8qZaRJMCU3ICYAcriVJ3jxjwDmRxDWxPoa0Ybyw4e2fuLJZECektvVfcLwW4nK3DZ8jWmy4MUimOVtiaU75XQ4B8nErNsxfm+dU8LKLDJNG0R09tECbVAKCqPWAECka6M1OaTq1sEcsLTHbKNIuviFlVZRiTKI1sSeLFEMPeICT49qqZVNZNvWOgP12G2f0/DpX7o/J4K2UESvVIgAS40VeIaGWFBhUCCNjZmsVkM0T20VjoJiGpBMXHog+/cmgHGpG+ynImzqjWcxajgZp6eQYWSndJBkZZCyg8sNTw27TQ6NoHscuVPPIEz8XfHZxKuJXv9LeRlGwTFNG7VJjj3BcrM3YmeFLZsgqt38nIK4Qz00AOGQQAod1+Jvl4RHWPTkQKU4KUXowcvgRDNblVSJJkx7bXXpYjIqFma0nN0/svdXGdgGarVYBpHslF5pLc6lLDbJJNdXQyRT8rXj6BmNgBgNzk6IC85iRDk0TGiQJxZktlcBTzJQ45oEwYrtKsL1ykicV1WFddhoETT7R0LDarlo5VjpP1H07Ry1+yyhZ3ccqcQmuflqjeSX0NHplGLCDJ4GKbB8SkibsaGz1kYdcZEcNS9L+3//uyZO2CBVtezaMPS/B6CunrYMOcFvWdM2yxGwHqrWg1hA6ZxA9tSa6moAgAql4ZBG0BSiq1XCEYkLo6utCQ2KNrRV637qvrYrtan+94qCWUiuYds5BULFecPq3NqxaSOFeTQ0Uapwj7ow3UpMCzuucd3+2nCixvh5Gvcrlpcn+dqIMXxT7L5SXcpfz5/Vhn6d5eqCD4IdcBSAtW1JNjXsXC5pgAAIoAwslOG6ISqZygUOnALFVEjcoK/9Ruy7lisTmGxympLK71tnfKIxhOkuKy8A0xQeWB4XbFcmAg4qJJNLCEaBuW9MBFLb48InI4DslJ/LYllAssLxtfB7NCG4nuHsFjc+g1lQ7KE891yAVmmC9Y+tj1mshW39lNWoEwGCPqzZY+h9itNFDUORovILTzBNVzXpfYxS/2WhU8flu9TmwQbDSVz6mlpE3EAADjJFp9S17wP8WzNu4eDh9gz6KortghZkwxG1jGX3adCIjD0ESzVBXO8BzdzDKcmsjhYg6TkQckjyZ8nnJZSCDaPlItISem7HZkJDSXbMN7sxcbbmkNxiu6VHZNU+JL05Dsfipnc/DTMv7T7b6/zz1YGg3Bj/YzXAJEBAAVBlERg84NgMaiY0AyyzJDgtZxKGpSuh+4eZc8cAXmvtnHeodDeHWH21kkDqPOGiowvEupUTBYm82U9doTyDJMnZCbB3vqS4XT4whrnFEmXCGrTO3qJpjRiQJOPDTJ7m46sdKqcIJulayQ29CFRiCuVe43kpnNEEVRu4cEtTPg29V77ncSh/Y9gSl/83b9Ozi8wuWvGf3jxaoplPzdTf9+ctKbHO3Yq5dM//uyZOkCBT5cTUsMRWB9CuncZMOqVxlvMWy9kcHfrOf1hg4Qx61qk7AULHVMnqqJX7t9GgAASoYUtAQ5pml21ig8KLRnApBoao0qWdK8a667EWL1W6KGk0oaeHQzd9rY6Iax3cKJFuycDB6awUejraSyrDXQ8MG2qukXljFnmVzmS1WNM1pSLN6X9n/akL1Ip3ik5mlzM1LT5fh/7IQV2bFB17ROy/1KQKFiQAIAARhal/nIDOgSwRtn5USq6jaYii+zvswh7BmLjeUbCGT0Tp2rjSuiNt5Z233hvFRV4wPXGBGlphttGnyrWZ1SjbWkSPaPD8TXh7c8wMMfpHaId3m4uawL/1javlmjarb+zdfN83xa81pu/eP52dif780+sPdxPSlv5t4xfX1G/+d4prOL/FvvN/741v2aMfzRoLkAJK+q3/2Ea+zANIAlOBB1hHQRRTeY8447cPUvpQBrK0kiVPxRwElSCt67CSN2rMKdZLWeK2I2QbQ4UdcskR6yUcbx3rykWFJrPkpJLDzrN4t4fpnWLO/irfmt3urtUavzAe7xfW/3dsQt414Vt/+n3E38VhR8yt0f21v6zjW8a366vrEPcb7te/3vWaz7/xn5+L+//zFpSN9wE9+oBCi2TAgAAAABoRoKhQwGHDKRQAARM0wkyQOwMGC1ohEBh8EmGwmDSALCMVAgOF4OBYgB48IA4JgJ3SECQ1yMiFQIOUThMAQ0yQcWRhDSwKZlij6dKWzOwwyWtPAjYBCMoMMyhDUGWuy8jdYGf5oTSAKuaJAs0AxAgBr2cF1Hqf6MOtDlOsSFjoYXAfkGBoc5ZHmnu/ai//uyROWABPBczu1h4AKWyzoNrDwAY02ZNVnMgARzsyb3N5AAkvo3BX4+9EiPWhxnwqLAKVTOEAyCHGgsxyC7stiFPLcY28l6X08juyprsE/EXcdFmEXhppUSd6etYzMMyOfm3UosKGZoOvplXf55oZfuSznYxUdmVbydJ4aB/YPnq1urqZ52NZSiBb87GZZN2s88tbvNki9iy7bu0O5iapPrWP////G1kAAMgkQgAAAAEAgJGQowmIhJsEOciXGi7hmQ0BAou2MBRlpEZMOmUC5IFGGDQwLAwbWkYmBo8Jeg4EKkoC0/kAQCFBIJpXMlEBgKQkBels6120a4gPNkozGgw0BABeAdAI4IizBjrJJMKAlZqElO9XAZiITzlBNUZd73O/AfZG55ZAFAMjTQSqaYvN3lNVN06VbHeYnqYZZL4cxUOaahLTHVUW7Ar8trTutEWGQivy/EZXUkltWiG4hAtHDkShmBm4Z0kXmHlf9wojNbwopdKezm7tWG2CP+8L7O7duzzaw/SwuVP9F5PLIzckku1GZA5cqiT91q1nnLvOtgeJmtC1h8ofi8/PPxc3KOUmNSkzWPU7hb1ZrXL3/+z/+NK0pAAACNU8DVBd0zERIxEKYaNAKbYwDF1XViiqqjzcVhXVXeX6CpEqoYsJPF+kfLzRCpDO6O3FuZiXJcvwQ4GMW5AqYzVIlj9DhJ6cL0/W4/sdRQoz1PqdcsK4gsTNVduO9uWVXPpXNM8RprLaK4K3sLFStaK+HqG3S328efe7qWtFI+s8bkMceuVZrys6412BbpnC/C8CLrPxHn+oHzJePuHKo4/03tkfd3m7n4//uyZFcGBiRiz89t4AKsbMot7bAAVwGLOo49M8IjL6ixtiGoaCqwuT0gYhvnGXKTWp9Ye5+cyvksnVAljKZAAAAKiaxwhkBloMAmJIAQEDqXBwA8rbpCw7FX5eF1XZXhSlhLNUa6lkJrLniPnR6AMIzy0rCUIxKKx0qOjskkkxLwisuftbLrnMTvLx99dHP/NmF2pUs8yy1tM6qy13dZ3ZrXK1+k/N5nrV2jCX7rOf+X3ae5ba/Ts8w6f9u9qHl/ucKfyETlFKxP48SWMlcHBQebE5os7Z6KyxXZRRU5fJXzTPn5ipRMAGoZ5thmoFAILFtS2IGGKUaloOAjgMtVnh9vamD2Msg7CQR+jkF/KOm6ph2/87EpHKeiUpZeWmxxlY4U+4p3xZ1YrmHymGjHkFjiOV0NvJfDhE+YqofWSQ4lZeyvX2bb1jLFZfa6Zw5lwUFkixK2NK+R8f4Rak1LMh2vDQmJJUzURk0HnwJiFm3G2mpqErtC0y2h7oWkGI2xkhCi8ll8gnQaaslDasFQyY3pdLquajD7v7DxTPdP0Cab+SmUACMvgzIi0mHxYGLZEwahOYcXZe5W132fPwwYflZOQyqFUb50LoKNtqX3be6dr0lnHn1+laLIqUNx/qMruoPmCwlEduo41+A4D2LQ7hlSByX/UWVn0Ma9arRo2yCknueZx2KjW+1rhvKf7mrh6uJNHTA+/eqmxQ/kPhTiRVezZqCDPZENAjLpJBlbQJjAAaHwceEg4PEIxgggGEZHD6qZKJZI8Lg7BwEcAfKwNOsHacPGOIC6XVJJ2KMirbmRqIV04OJbbGpVWP0A6mhgSVnL//uyZCWDBadiTiO6YFB6S7o+aQWKFy2LNI69McHXq2h5ow6hjN2AKhEq9h8nf9MPvqqh2kjlQwgypE4o+nQvakkip20F2PZOR9a/Tg3iifOKMiCXVFVyavIhBav64st5uHtkpKH00uwv3noX430kL0JyI6Px4q0pZmNiahk7yUwPrZOQzZu3zmzLRq2FHgzSbTLGaVAEcoyLSw4IECCBKAjgQ2FCk1RNroQh34ljqw8x6niDd2sCUcSKgvs24Srcm/2j5vKrUa6HHH2idFLMjAHATLH2aYYLn5TpEdll9RzFmTQyYi271U7NauVGpeiHaJPqqYmajy0QrqytcYrRQNjXvKLy74+KgFFQgA2olxMkIA0LgEIwSMEgBf8hAZC5jz/IqI3LhL9P6+7M4tVoWusKXXB1DiXdIxMkj2JwVTt9FL0qobBvNk6qLzQT+VC1MuY7HiRwXKzBfHXEijZJrS8qZgM3iJ9WXhREJjQjep7MDmm54dc5gXIj7VKQlBER3agzPE2oxXE5ChVxyKi1d6YoKBqRNFiR06hqi7KuEMy8UEQy+6ca04TNRqaTbJGKUEkYyT5ScHeSKe3F3/e+dV6QNJJ3dSRkZBOrMSQjRMVgMSAJ+L6lVDH1ro2u7KWhRxqNfKZbpO0vLDguLXysoaZBd9jUJQIHXzVRmW/3M+1rY300C7z1Rba+8HFZZWHwJKEyW6jZz1Lzr0MG9VS0i6RnzX75sZFSP2vNeevGM6V8KJclOdLzSguZAgE7HmSZcLHMEB0tKRBpGotyCgc9OKlRcyDsKaPAYjlpAl+J9hqURhH/hvVaddt0FUPpWcyFBKiE//uyZB2ABV9ezMOPYvB9S1qfYMOdFTVxLw49LcHTLOdxlI3wiqtQnZ9xWtrJu1UiZh8pT5tkZgzeA5MaanNFeLymhvULjn9c+dwekYhcsW0rh1dyxWayNqFr9aOouZYdochI2srRXDP3QrQlal8YhZmpiu6VivZrOZb4Mpdar9CX/7VCrHp5K6XKw16Fi06ioeJcixINH5c00PdNK28AGuKLOGprJEmggBCIPaXcfRISFtShtxnghrfMqaQVL/aCEyiBdMFi0tEEwmnKp7unpsZnwKw1EmagiaVJF3/t2do7nYss3xz8ODt56wy0zkhdnlwiyOKQsbnco0mUzwR2k18/Zm4azQdPOZJQp1AZMNJABIIVAAAbYjQGBK3DDIMLICQKnyoBhYWQp+00ysAJzl2WEzh9xrDDRxynHGF6dJVUuabdEjoTKz+dkGZVIHaYDtuP67lKcKAXcI70NUjPJEhuffqpfPmLRwXEoRJ6MBQEtXAyLuLA4B7kgU0n5EU8fETCVJwjFVoFyjXo+3s7O8sKSRXFkU9tuL7Ypuqt+paWnZxpvrS39nurVpeMoetWrttt/V4bSbNZ3v5EE1fZMwoLZ37CQYYmWyEQT0IoN1WJLnCTcBgjxRZpjdl7wkHwEC+FgDjV3y6i+pDxu5Gp3Xl1Cdh9UVqFeOTyFVumZDbwGnRNpG+R0/U3zdemFRo0Lyy9c0XQWyqhQ29DSG09j6TTpL/lc953TpnGlwQrFaaaCZMaAAAAAKh7YYs5TKCMoJOmAMQWMDgYRcZWsuaShGtSSIx4dAxn4EaqHZl7YDTFZXB/qnGZbRwwAeW6Xmh5H0hB//uyZCECBSlgTWtMTDBa6EnsZYVmFI13M42xMsGFnqp88wncyehgMqc65U1QjLKUFlCzxpE+MR4j2hoMMexQKYTH93FlkHU1mFccdRdTP5t14MsbHZ5Z8zmyq8t7WzjKH9p/pQyxTrN18y9uKVbK1kWTppduCEVNRYRFJ1Odeerx6jBQnNP2AyDZEEEFqMqFP9JMiFWMWpvvNB1pfq3k7m5t3RMCZHBhkbfepPZu9AMzrRKOcRVjMD7CliTVyJd3X0ObRmYYZmRWq4s87O1yO8l0/bpREf1caRZtIn7sr3WTCAgEogALZzFKZyDoJA4RRZKBWdGBAw8ISQakgICAZRh9XcaQuqnyemZVFLaSIjSeQH6M7osHwrm3EosL2y2O4iHycP0j3h0WIteCgoao8CO2Taowy5vI8PwpMVjj1BKGjyq4kylKlmmKgoUBtfh9KOyhcqZbb3sOyCDa8Nf7i1dzQ/7P3029tJG1D3m/zglmXMo2lvxjwJjB7Tonb9bsOmZcdkqNgNTx+WyvpMo7e5N4TyvB3Bfoef5YU4MMQ0WMXqHKQ6S7JMlE6zIgUQATILciuw7KhWYgu1QMac1ohRzSFkJ79dJ3dFSqs5mbs2YjTe/uiCGzkQnhQ+Ve1OpisvuvELFNvlYAZQAAAM4OoBUNF+CYTJRBwRfwYCQOD7SoUgCSeay8zwP+sCnoz5RF7cF05GkdavTJWLLyYd8iphqlkVVKMjDEgGxJCuczaloNllV6ssM8SVVro63ikXK3nphpzSq7fzuTOwuurG3O8VgU8DeqQWCJiHNn48KLi8mPpt1uzfAh3tF3qjhvfqod/Odf//uyZEWABXdczE1x4AJiBdm8rCQAHzGZQfmsAAK+Mqi/MMABEfPpArvWfbye3har7Yd1rnF9Ueq+Lt+pHPeburs1IMPATrP2EQKi0AAAdWEysJjoSm6vpA76ufZdNxIup6BqP7gQwEUAvJZGERTkyJ3ind3HXplZjv0ucVlO0Hi6shbW0nuZBP/3v/p+019qUo/r1NQNGuQiiiafrap3G1ekdj3RgEz0+lIgDGsM9IqIrKtsbUjkNh1Z7Bj+gPTETTC0mhDKEl4XA2BAjQxMYEdJL1HkhAChgQSUkl43USAh0Y2oyrlbSVy4pJ5MZkbkIHt89bY0Uo9Hmf0rlRBma5pY0xvHcU4mWGpuL1hDvynbgwFLIfjMDazkctg2VM7h+WYZulDEYi1uMWJQ5cf1JbM68ECvrIHEmcojXtfHN2YxTwZEYvD7xVIfi8Ny2SyqAoKqSN3N9efLtehpJurSclkOWYfns9xu3GLEbjeMLj1STUkv/kRmJdYkFPEZbO037z1nWwpJNhXhq1yz9jn6nH8f+XwQriYiEVl9iX2Llj////3AAURw0MREJGa2tRlvEwqtrggR0cFY4BRpQ+jUSibuJiJ7TrOR44gCdBBGuE5hx6bwRLFiG5tTFfFEXQQO2S0XR9EU6LA4pyY6sqQFp4I81y2/aBItYsvLhIYfW5MzOTVY5/R8Cak38/SNxL3UaSVPN36jm3oxFLydaodWGbfzM2nvmZvf3OnKdsnk2ZWqSskHQsQzL/TFvT0zMztb/NKTMzMzI/hPeyGP6I/THj7nz6B9dL1PZ7K1UaAwGBQA77rtScSV0T0ytS95H2lEg+F1//uyRBAABIBi1u5hAAKSrErtxiQAUWl7V/z0AAIaL2u/noAAaOCgoSouKkB0NFRgNHFxdh5bFmFKIgVk4cIHS0/jEjktnFRGMi1MFKoUeAHiZBhKilMONR4qzKsef42eSJqGHw+/BivKDb4dYUTrbzlxIwc0zMxb+iF25FXpKDCGSBDqxdO7uuiKk79L/xfFqRB8xSFLtt27r9fYyWQACAyABwPh+wEXFEuFMwk9NTcZkRMXhwUON3OJJ2A2Rl022kHXDqBdI8qompRgQHiSTBp8JtlahN0ZIGJDbXW2uvJLIKOUUYZQztZuK66e0rUMv1Cvc5761iKuR91uInb7rYSh7vMzr7Lfdsrqzg+qkzusLt0T4y3sP//pWVSdP1Xr9m2tadMkyrPD9ksq2UkgAgMKF5HSP2MRCCK1nPkuYi5jkNPhDWsKg2A0RA6iBKJR60axUlGGUS6G3YnFpFCskxsX53lLgfY2xxkQkjUkYcQcHYZEjZskPfiK4vXPJ9N2Xaq226L3amkFkrK1ZNDWlxa7S4KdbRnWFfoas8lDzIVZ06LxY8mBRR15vSUMPQw5N9bRdbd1Dr9kUAWBZK+IBBATQ6BjBwlyBrIAhAkpzK5hVBsgCg1AVQWPsOZboVg0YPDkVdRdDnkByjRJQ+GOGJzPkNRmNIsiI+e+RzECKDZot0H6QK0S13yPfTeuov7T7bgZdes829cs3HU1stLVNNy0vN4qZ3zzMOfQmD2CyUOqH1OKc0T5U0p6mYzLmX0xSACGnrGTcLzq7JnNwSOW7ArtISmIM4Va4rny+IOhbd6FxqknJBTDKZRhhSfdHvsES0FS//uyRB0ABAJZVnsGRLKAq1rPPShsD+FhVewwb8njq+q9hI35SY/Qtv7hrSLgkoCb/PXxMiLZNKqi1C9lG2sJfSnbffCt6l/1MPPp9ys9RE/bxvaX8893P3Fv83LXXjIC9yLoHCg9YDN+xRamoqrh48xRACDmNYaAJ8Nt4TsMUZheThZyaJGCAJY8XDZIDQamuUJEZVRXrtCLpXeOleHWi7SFOaqxq/n2KnkY44CM/j/mFg9y6+ipHDg6WrH18Ej7vn2G1yp1ekZMrx11T1bR9XapJ0/H13pz8velvU+7kBGzCtitILHAwxsBUslT3zcQvsjRAI0SvcVcXjSSdZVZnJCJ4FM2jQ1Hs5l4B6KRdOD+MuFO9/46hzTJ1c7Hs5vqrXPdebuizWZo9sNXKwqGGnhdelXa3rirIAYD7gvAWJVISXxgI9JyGS0zA01IyLbIjhmulTP4bHMqpz2Zs5V1YVTuYQfDOuxzd0sM8vMW6N42kQCJUUeokcoaYI2VRVkdzNnLYtbkrtSAsJyRt+9CPG/EatliTKst31VlOVxWMJsx/2OZdL9NhOgcE0o1kapY1/QtyArGREJ1WSFMk2OHxzVA2VLErSK7HMo4mfVJmhy0mKrWp6qzMKpeYVcMGBhkyfpKRmx6iXg9aiSEyyURaKypWRGBnYklCp42pIclNm1g+UN2TmLy4pCeW4ztVE//MM0Xn5RjnXcxC4JX65A57JSN+9vs1pxlsHx3xZv1tSHR/bcFEytT2Uebuvct+tDu0XgRXv7jiLqZuvHN5Q55PqarS1gYPyhDHsh8qlhWrDzWxQOjh/Bwteco4jEvSCtVbFwx//uyZEgABFVe0/sMQ9Bx61pvYSV6EsFxQewxb8GrLal9gxX5zwoABXLUnn2ZxlywrQBpbEj2GDbBII29TM35GCASox/JTUSlfhm+oXhDhQmRgIn71ZqE138q7q0giFOqKajLVC6Ly7MvGNQ5spvWZzWdBed9FarCybakVrKn0MrIpsjLlLNFhsSOIxF4iBV2gCRZhlRiiQIACGHvvH0DJoHHnhUhNdH1tFhmtoQJnUzhOURcJ4gkpAPCmctR1OSfxTDzUe0PEXQJno7QQzKXjjsXf2a/2zRdc9ap8Fm7ZZHtVCFm8lF32hZ6VFn1J0/1KC8Nd+Sn8OfwJpW0nObK7ak5beauM1z0lJb6q0cW+mtPmzrY64cvOTicxy/cZgbHhIauWargMqSrisZWucaALa22YwhRCfh8lM0PgsAWjddFKd7FdRJ02sIEgO5k0sdtHImtadzTsk1df85jQVU/l6zsQfJT0AoY/2NZd/myS9Ig5plX2m/qVW3UyGMzWJu7W9H59Zv5dEN3yzUQGqLJcaKqAziGhkUWqgMLsjTShciK6JSuBgCFaxH/T3Dio1hgGesicxrvtJdRuMIgLbKk9KN3hC3tNGvFwUm/JSnFOKcpMlnTvZYyQwiXlraRdS+ogJLA4CApZJdFQMcQOQd4iTh+a5F6zfLpWU/onpHjbGrw/5VDpOi8qK5/ipqZi9TiE2URIFRbOFBGPNSEnpR842vsbMlEQC8PDKil0kUQC5j5VLoEk2Jg4UQsI+qsUVCkyw9UkpihYbESWA6O2K7AhZUdB+muW6U3W+jbtPV82Pm+PoWcvnoVBiDKxtSgVaZ80pnD//uyZHCABJtjT/MJRNBrJ6oPYYNcEv15Pawxb8merOh5hhUgf3PNDBGn0SDIyJCjRExokDjQlWwtY920iQrOkrbS3Z5dnGUiAEbHoaDgqYFBQNVpEaFdFvfTVRWd9/JBRJrEgnGIbjULVoSAuFLag8dcOC0SECBpY1VaodtAzX/Qj6brhLKcVUKrH3bU6PB8fTh6opNjdQvKhndKmpEmJodPZRt2tZmCba7pnozWghvWPHNvVolVskw74lk0c75p39/Pqw32nuoYeVgufcPlaoTurUP32ZGJewBrkIhOiW3K0at1pOnMshCsSYy9Y6tI9CipsIPpDIiuq7lcCgDh96V3M8wgLam6pQ4h0M5zFcLBzUE3RiC4YxjriA3dTMTTR5EupaZi5jymXOjdNBf2WpW69kX7llcrUUqK7YqaVWzrEf7GRABB4ZbtwkL1B1u0RAEqyW319IFusyXV4bhWsMRun6SmWCtKYNxF06HUnKFxUmz5EKKqXblaSh+04vzZ2Y5onR6Rmo75ns42IWYHDSD0IFY1j9b8WfnbXgkhO/nFkP+v+k/7icDjNLb9UDDB6IHBj/yN+oTy141GTFbNOWFVqS64SYqunukMXxmBTG9d4cEBLh++9HmXlYeVUlkBMacPFYmnYFkIbN6OGCvSauUbhmC9U5YDyjRjAEJUSsOA+GbWZ6/l/9K/PME60y3VJPv14zC72pSLs53ctPO3fAMVmseV/XLv9ispxSiJSKj10g5tX1j3lgeNnQ60sMWLdSAaLMKplJKkSmBqlDrLL0EFLL1Zk1BQAYVwofXU67CWMRwxpkw8bPET7Uz52f61MwG+//uyZJkABLRcTkssS0Bppdo/YeY8ENVpTew8rcnwHSn9h434cx5zG4JocDHYkZ1uEqHnG8hsYt6Pin/OX+eAyj/jc3zzpFIPYTD+Rh51E0a6upQOIYoXZTUIz/QnXcpGnbRybjt06PsRqv9kcr22WIIqOkoYL9nvBMxZXlmRbbm2Q2BodjUJntp90w0u2+ewzxFhtyaQQILWRmmDgUM8lrEoaFwulS5QT8UqeWFYUBaI9gPcBvCvW0gqlZBfOJ1rhvNMJAaj9jj2eR1YTxAOc2ZayRGCber7zJEWo8R4oBcOL6CETRL8L934InBOy/o///W6T6YSX/2uAlMlKhbxgOP8SxTJY+87KEUVLqVrqy3WeF/oVBkdh2llQe4YO4ay5bWo0JR2+RRNCjrROSOJJTV/I9WzF/BqlI025EzKdLEXcV3pz/e89S9//6V14pRaqL/EwRWq3N3aUMviImbm8iuXduu0Sn2HGEhGQZoZoZOLi9hYMk18uJ/UAAkEByQDz7UWAulArYHFdGYkoCvHTKY0q00cT1qSb9jl3UuWJonWFxCGYCmKaBMlYCwaoznVtHe3m0ilTsR/cIvBN4l0673r6ZFZmn699s7/72VfzZvT709/fYhj/LZ7TvTN22ioh2+/tHTh97k2w/Cydh7MQx28brpsxivWExU3cw6y6NkmI7TEUHiNszeLs6c+w40kgl9YP5Sv6exgWFJYSL0587+jGcu0raC2cvs9XW7Vvz8zcSYUOpu1RjnFOIBWJJyVf5o+B50rok3Sjbh4heZjZ4dCTlquJuB1Sbb6NY4rRRnaQlEdeaeivTM16OcHpRRECOmM//uyRL8ABBVe0+sGRGCAS9pIZSZeEF13XewZD+H2LCm5hiEhRYgkCB1yFaQJVaIdkKkEBNqQOVMJ3UZmTvK1Re90FQRIYSgKF7wFStCSFap+M+fVyWizhjjBr3XQv2N62brjrLrrZBpfH3FxZA8aIILpmLOM6oWhDv4MeS5LqZS27idnkdAc3Aw3XHjJhBX3i9hkLbUk8VMzwLTE1DXrZGSYdlh0NRnYhSoHnbz7mY+rRALEL3yUinqzcWUl2sAPDdWGkqk1aJlrSZQ8M5QVHZADTJUuekjAGgUbtwj1FA3KptB/E69kpR2OJsKfULX748kV2vmZuX/47LO16vxt+tXHcUeMvjfmKpL3pafQZpVUvNXusVnk00tkPVXEBpJHDyaDawAGjLZv0grUt1bvH0UJJRgUrfQeWvBatSBiqTZ+snT0W45D+Oc9MwSjJQEUmzopkStCsfplerfZVh16iKYmnUY4+rvxy1Yah7lyoam1sWXV8VsxJP1zGg2KaX9yx11ZPNFx5Jf+rEwdxN1BSd6x9QrjI7qp57ueLhxtaRCrdUNUNUxFjc2HDK94GsJCuaI0AAG2RQYCpIixi3ajSKAXAtSyxNdbdWDtmdp7ncAw1ATlWrDxJNVVCtGiJY01ncmd6bMhyBlGu3G/4/FnyiossRHQhvlPLlA1eRMtRkWyIVRRlGCm3BUhU9SknbSKMsOAkonGK8MEU0E4TitjlU1yzpNpxpx5yttroJoZrFz1KQpMo5GHhdx5PwcbUL2THzSKM/UGoNpy1lZa2wZHS1UxIGAABN8gKLJrqGQN1GSpyK6n1C1XtxZ25NNUcRAZMEE///uwROSAA/9a1nsGRDiCy0qPZSh+FA19P83hIYpwLqf5tiX4+p0eV+F286ut9fZrn4/yVRlYm7bjl6utWeLdC44+lGli3atd3UItV6LpQmaUciYn+0ifHlRSO9aU2sp7KqdIkbEWUprAsi1mqg0ec1ROWXxlWMbMIC1RbQyh9IkTUNkyUQqBYnUbSqBdmAfi5lt/zdXiI2i2BQVDSVZFIkAANP2SZBGgIxATVETWtjJmlowpco4powa0Fobtsohus7kVnnkpOiGTaETJ/CSva4JQsnk4zGLEtJSNjEi2+p7Klmn8DOK4mk6XTab6A1OcUyHJ4QoryXy7SJcYRNvrFY2VJa1Zxi0AZKOpaKd0yIDacEpSkjSjTJLcCjpSWeW2bCLrUhj6Pp9LRdq0DSsNmKt/7XiOYX672wRmWodnI2AAP3yFhwiODEE1p5uSsEDtiUVbk0tiFSo6zcJVZf45AEQ/eqq7+qomUNkYcI3T0bEnd+MmGx8NCGC45fN/uakSlaurtbO+texhU76W95TMrCxcKH+MnRwfIeOiHjEFOMZ6iuomZga6qJ4wRUU6t6Q7QBrVZQNWumVNcfYuQiaPAYwFA4DQhnlkJ6KbPFBqu337Uxa6v+Q14qQ2PXLUewHaf9xEWdbH9Xsvv3q0f/X1sEWlUdFtiYemVg+QjLUNb6uq85b4hQp8bK0N5uUx1oydq6xIQXq5jOjxV913zCkOf60W1MOpvZ9NTFNfUNPOdWqJH+meW91HGc4Ejjf2pNv0g2apoS5xDYm13CfxI+k6lK6rCeW1nW/V7gDG4J1ygJ7sqhOFPFgIcQZuuZxoGToZO/b/+7Jk7AEU+F1O83hI8ndqqf5lA45VwXsyjbHzwfYtZtGkGmnDaVwJiEuxCmzX8p2MMXm5BGAycsCmvj6py3mGbUzmoNpd6iBg5N4PkMHpMmUqmon9mupt9CYS0rLI/Lol3aikv+5lW0qoVQKqJOuEcpNFiPmTcVrdjt+x85fZ6c7NJf6ds3CSUHX+sf1FBEbSQEAnCs5gAaqZSIjCKcWCkbAcNIZw+OgCJykmb7bC1iGqSStbheW6YwHuNMaungpyG5VXR8usOMNHbspY9/VTtFW+k+vBRryi6P9xqqNMWKq+28rlaacFFDT2pYbZDaorpWU6c3NuE6vWBIwT1gxZ8Zhnpa1p3qgwCq/7bvAeaPyEeNd6OEVSESNrTYY2C9avaeFlATnp1VXanZuwUAPJpQy7Zw8fWzzr5/2z7jgVn5GDiAAGZ1ERUHIVgi9qURfkZIFYlUieaer7wAsM5UkldI6H9o8hUkXvPlq6MtwUnilsYoKxnvNcrfF791dXb15Jdnz/H31TT97t8LCHYpDa9J7Jvn7Nfx51oosAntrSdrrPR4Hynavk+6OQantt6LM+vlbmt/T9i9UIiq6mdYYqcQAOaaxInEIcmuIgy0RCwOGkQ0ZGbIc4ZDAdfz1PqsBDFjrG0pmAbpxya2xrESCmUXeqvLduE1IQ0zPJGynXUGt/SPqAuWVZ3Na2TqdW1im94leQ4lhWstcp1vfSeHrUeFv8oTM3sTD9KJpXGJDk8SlTSNufbnCkVytdHP3S10NjlSWkns45kd29JBbc0Nvf423bYqlXaKrAAoWO3IDvWE+/G0PBMjfMADFijEQcDb9IFD7/+7Jk8oIFfmLMW29M8oBq+ZxphmgUMWkwjb0xwcwvZq2lifhNaH3mT0gR3YfvTkGrKFAFSYooISnVoO7ceWtYksYYnDWpfPTxevutXmb3tJSNk6o+/tOWZ3TCNqCaiNxIE6z7/WgpVnU9juwUwMsWR86Ni6OrW7vex0s6dV1fHTZ9BDoAzMMAHvvBkYg0gmBi/RbhlwoBgEUDC95EtWZvTWbJWaQdrq6ZJZEXmFqMmaGsJWmlY/ZeyjxZIUinZ4i4VyZeYUSURs72M4ahKVei9vbNTIYgMfDuC43fnS4TK9spiA4qhyo9bUbWVUu6bswZywsLyfeFcldYjQvAjsum94m32YUWs2nCm8saH235Y3hx9UxJXWKSY01bjZhuDfFpRRq7d5XHWdJSNlugxtSyxPjETBwAuGV1ACfSoA3UMQl3peZ4XkEgAqaZ6BoLPkQk9FWOhZjEeTeXAcCZzWJk22SpOrvS1lm4pa0P5DTjpW+e1ardl4T7oooEmN+yGefsksFWFIJRO36JIeEN/mTOx2Fp9i2f6l6ZqpHFqot5Qj1avCH/3WrJ47d2tqt8Lhv2obM3WR+/vqXuKvIG5/qAEBxBRQCAgAAAAAABJNfEYHAM6YYTGobO+Z072jDFgkMQAEwIHDEoBCEAbJPRhkEmCxCYQDwkMCAVGDiqtpuJumRAJOojFKL0QomAhxMyYNC82GoaPhd8v5HpSKmhehPJEBEw2K07bA6VY3A1J5dSCNMpMBSgvBRhARjZgipwTYdwMobBwR/ILXgkxFG6lr013ibVNeOmeaGAYAgaWARFKBQCXKWwZdYzLYHeRv8IcVxA9tP/+7Jk94AFqV7LpW3gAIYrWXStJAAnoZktuc0AAoGwaH81EAHcSHCwQAkTIFQwsZgZBd2jr8zgluMvW12Fu3nPyp6I2koXVTmX1LVvIlKWJz2ZmA4GhmhhNPKrtafaVJbkQzq0duvpuODULK72UTEP2H6gWKstbaGWkVWvak1NW3a++0SI7jrOIS0yA4Emrfcdev5x3wsy2Ns7jMvkFNdyrVQ70r/+UQv/F1qOxVgBpCaCsB3BGD4Zi0WhMNo5YodDvw9rmxBsbtAYW81BfZGo+1mr/h3TIBbgGxmEvE/ClhCUY48mqThuVieMBmx5GWrsWBsF1AcRmMiMsTRMaOSJKCEB8zUibFA+rq5cICUpXKBWHNKx8qkeXD+qhk65fdZ5ZPomM2cxRNiAlPbfW59atbKqWapprdBa0U+/9SZug1bVfRm9F1aLetE2mjU1CZ7QAAAJwQyDsViY3IBYCxdUq1UmU6W6s1aQ36gy7o23UuRbXE/VM/Q1lbnsmWVlhuMVicCdLUdUL4rpNVwXmR+nlK2EqURITqcoWXurwa7zBbYPnbXGC2xabjvZveL4OrWxmNa9dai4jemK6x9Yxn/4iV97/UCbe584/xBn3JbG90iX/1essff8e2ZZ/ulc7pqzA4V3bdbryo2wRKbxDY9948gfM6xf1vHgC0IkAEAAAOT5sYpnScE4AKARpet//2//////9CE/+3o31Od9WFiwRCgxQjIaWEoIU68mr8klXvJrovz6m1dagZ9oQKZQZAYg4IhyBz2/V0J+TAAA3k0MRJACzh0TvJSzXFboHWLJFRX4EYk3J/pTAsqfY0asAkeo0vT/+7JkkoAFU19SV2ngAlLruo/miABSJXlJzRkPwcgvqnzCpjhZkqnIAliDzBzESBiCRpbWzzVu1dki+6KGqatcyO0CN2xRak0Xn4N4P/svmSupQy+hkeMPtiDB8mmfJ5I/IGV2ebwplZYsZUjRVBg9FLMBoO5EI82IE7IEIBybEgAp/ZJy4YDRgTGaYpGACCtM7MbMTLcxzHa1Ot6q7QHr/7lX7tLNIae79H/t3SjfT1sdqB4Is6uWxFcgDiDb/k38zJ7G093y7Hu1fkJoNWVle+M8pud3D5+0e3qIZ5Na/kiX9MLGJpMPtVDDLcIBW5k4iNZIpmKLQfBESYeFMJ2qAklpd4c44SAAjPrsoVgcHM7UeW2lQHA5EDu2moWuVkidtpMgf5pbdow84DBkgEYeNRQGNujrLBQAdZYoBU+D9MWkjjXWcUnrytdhem+6uYH3JINb9O3ZB9lNE40QDciya3PjyyfWLkeIXx/LLcMldWOqS0bZp4ttJilUlLdu9RVkLFC4EAoq6JppY5rHln6gB5eniYftpkAM2IXyGmhxGQbKpT0M5MWn2pYLerHilQi72EpYEPcN+zQqRn1k5UqyUVlRDdWc1IuaOhcRKsux1CgtvKyoMI7sxbtqku61PyeeS1aVZDXys1iJI2VVqVdmZPqTKQPNBhNzsV5xVIJyjkVPQEXmXlVD3axtqCPE3IZCg4UYEYCRAJClzUz3Wb1hKlcMudDEvXxB7ju+uUdDxF4T7BYsqKswWR28xoVNOVusnm/DYzaZKR1WVH0Soq4KA7/abyQ+x7UP8qDpYQjr2r4Dru9eFNN4QOrvNmRUZXcXcEn/+7JkuYAEfF7Se2ZEUHMrum885bYSLXlR7TERCc0uqX2DFemx2NuFS9bttI+2+6jkaQnQ9amqbJAi1MNFW7mZkUX7vFQ7fL66dYlqKIKLzrgL9CUWi1gsUGTXApe8y4UUmc2GvPVAAEFBAwNJdCwUwcJ7U+UovUirczRGZbMZ91bRCshhMAX1bWWYSH0ZkQWMZna6VUUdKL3PvJSqqQ/tmfW9UZq9GShRbLJMQRa/ExjmsLOtdh7p6gQ7V4lkTXkCBEBFiyJBsmBKWo0BRoFF0iICteexjBbFf0OtPV+9YYjucFk9WjmvGqrDxnesOHRY67V17fnVtZc/Uh476s5pPxKMkxq8oAwNpoZCti6k7HXySOuVIP1/dLH+vduT4x0VdOxcmtl/meYVYaPJoTzlz2tEaQVyq19rU2WKqMKFqYJhWtjzJUk6Fag30AUZPb8zNctZJM53e27sHY4pjqGGxvA0VezpMvZGIj/R2YCwtSy1HI1zOoTtMAPpUurNjElUVvs4BS7GQwLjs0bsfNUlFs4U3T3w5Wrl17br4jn/k1nxpXt6N1oYUrQhwIdL/LxZrGfTgKdF+35AHJyIEgDH8YMPgIiB1dsZcQEAFNtWFTBnrap3OCzllTfKXSR+2YvVu3Gaajg7kzLt0mdS5Nv7OPzenZLM1I7VqTlDZgpddmhN2H+hOW/cu/Bo8tsfAnVQyYnjz2IfYyUll4tTD9MxuZqo+d2Gl3maQfNlmzaCnaKo1vsK13apOasvQuShLrfJZJ0WRD/XTeKh04SJDF4DZ2sGVYL3w3TlVCedhz9T+YDTq8hacgCbcruawwxX7fPLBCP/+7Jk3QAEl15Qc4xD4G2HWo9ga6dU5XkzbjDbAfos5vGEobma1prqh7h23ohMKCcCEBlsnkHROyshhDU5lXxdrEyzT1tiQOFIujPy29alPwMubMBeMny3Rhps5PU0rztFpY28mXRh8bWrez1MWtEhVSB/TxFZJqU0fcDuGomu71gr1Nqys3j+0x5sofUBtRkKXUAAMqxkHCExyBGrBcAhULF6yAAAQAIBGHNWdpXahjwxZddM57yVFWyl8MxGJ/K++Lwm5lQ1bXJ7CLlghnunT/VeZ5nBCFGjjzkfc5MwX6HIyA9ZY+mNReaz5k9mNSOdEQQ5zgStt4tHsZXWivoW1UyFChEc3vrGp3EaJrdCX4EsE1Un2ePI3YSiV2RqEUmi7kymV53Hy+yrpqaVK7VPuusQK0uo1vWl/bg0rb///ZWEoSsykQosg56E7xoEEsS9XTFZUkGwtmjO3Rm5mZgezKMfmorfkM+EmTzk1vFOjPTpAk5CJQO2ifj/48dKttihKCTFJpbVoO5MmhIbFHvXKVVsk+Efg3Kzsej4bpNzUkXyMizjlzpa/JNPzMrC4JmwZzCupKZgBRIkAJxhFGMRUGD8EgUGhBrRgEBl9kgQsAkkWaNyZcz2zG1O2/a81lyokyRxEQDZLtoVrMp1CX8yz+EWgHJ0OiPs4VEEeC5XLc9ZFqNH2qGdZhK5mibO9zzaEy7zpfnvdjI+eJo5Zc4VeFdCftqU2sKxBJgy3FrzG5S0jJfixq+KkDcZ7PzCeR5c9dROpT0y3lp0/12udy4JUxGMz6TNwYZtNl/Qs7qbV/qQdTrPYDzsgIM3MJB1EroGiy3/+7Jk8YIFiV5LQ49McHVLWb5gw5pV4Xktbj0xyfYk5dGmIXlKNAhDl+4skKqqKikIQVnYgOO6XFkSGfwUy6kn7ResZHxQnPWB3hLD6txdCsYAhdGdrEj4SWQXsH5SrmLWRt/UVQgRMtd2QN9YHjr32unvxIMvivgQonb7PKlCjY+uWaB2y6UibsqvsPcHEFHd7/+vCj0AAD4YzNLiRiQYZkyEx05i1Y0F1b0nn7LUKDVYmxxVVW56pRD5tooSNBlAP+qtLghsZjgkLTpDpQtl0dCYJsPIvEjOXFdpUd5hHIP08MvGLnMjE/BZlYx5ndp2vXDuk7IT2jgfJLJ6LysOZ5AYY5jVbWJownwSWmImiL00QDn55rILEskjArfEg5rexFiALgYz7rF9NrOq3DylmJ7PqSbq1Q6Xb8T+9InlswwzDPOukDV8O9P/+qhAGkPjqgABA9GLPAjLkg13KlEYCXokCKBHBCMKKcsTgto7THkbSks1v3w3fW1/sFvRBxIM9w3TZoOKjYTnmEY2narvQ3s1Rl1ZEovz2JRSbt/ZGQEKRER50M0wzTFI4cIRqumpXdLYJdT8RESIUoARFAAAT7CuM2hQqgkwgEBUCCoLR+Lnp1FUBJFoFixDNYk4NRGk0ViqeDcVh8mOf4cytbzvLk2K9WsJDjRMAnaGEmVBeCAm0kGduWEcf44TETxINTI/nBcbUEwdyJYJQzHNqM9VyxAeVrgc9Ti2XWPPuTHq2rjzVzSt2IVfTD9dxqGKxVrHCNdz+8b/+hD68pgKpzTOY7bHyOuKH1t2abMFWfagWLMKcC7pmj+p2M1pLXbcjb7GCDf/+7Jk74IFzV3Kw49McG3qyc5kwooXoXkrbj2LwbouZrWTFfAErp3//tDUTrYAAAQAh2ClExb0HACAF+JpPVbkuiMsely3Efaw3YHq0r4ElefshlXBaelJkhVaure0Tjicqef2XLu9xOp52qhXjAFYyCQx6iqUOK0Zy19bcuzaCP6KmxeddvL0/z6vfiyDA+6Fh/YdKAPp6wwzCSAcnKKxDDINMLAQFBkOAioQsAy4Evn1NENIliF1Ti8QG5OywH7g02UhLPvD9ybJorAcqnV5yHgXc/DrI7SuwypxvN2ZkVYc53WhAmf0YAwDZOIj4q2IwgzYENmHjis1AyvPzbpxAzFthdc/rSrzGzOXi4OAEhQJitt4oQKQMis3bzQeMdAE9rVS/LoyP0UQStJAf4wYtGjm0TvRyPEZHqK7iIydQUPF9qBQx+ns9QHIvU4PhCmcRBgYAgOY+FrBoxV21p7WVsPdm4uIu2rKq5bYjEsOpeYmYS9/iyBVKx3zTZzNbdb9pfXn1mf/dfJ0xASvPkf7CB6eXxL84TmX6fZ6H7zovQkQHmhHpP0I9zhfxzfeEbwvRTiE6mEEfXaBwN8EBu9dAgIDpyI8oCpZmiQBAIpsoB0cQCIhguqCgjnCRlDdxlgGdoDVgGwuc2GpQyVyn3wryopj1K4GkEKEX6OoyZY7hEH4FzUVIdfQGGUp5tqGRq/hkO56dgKHkkPsFVc66C4KVTgUAIUPaH07zlvjlI9EmGkC8JDqqEenSJxeS0e+VD92pFLc7ifxbHsI9UM+W86zMaKsA/58sypRzq6cf3kUiUiTQH8OjGyPNNjYXBgzHSRywon/+7Jk7YAFsWBLo49K8HiLue5gw34aeZ03jTHzwuuzJ7WEvfEh/rK8aoyU5EYgYjU4saQXLHco1U0xGxU33mHBffxMTXewG7DrX8NBrz7MsgBIlQcm/QZVtIFh0sgLGbO0iYaVEoGXJFFMJGsWHGEKLwUmMqTynP1nxmy+PfmU+vU5+srx8Ir/DhOxYHb5hdOequ3KCyEsX0vCwXxjYNbjzHOuYiXpGZNXa38WM31l08lgUu2vI88Chb9xlBMtX7+K8hrDn5o+tRm1dIyLInFi25VuJqZDzq1ddEbPN+5M7JBYC5ITqBIrQ525NsJCj/uvHos2dKpeRjxRMjnTCvtA89r5eWXAFQeImJiDWNkgAEOkwcFZL9EKXtbm2RXiAx01KWZtgZAAwPQvA0TQtW7RCWlCGrB8pzje6PKpF7l1hJThHHdSYUSyGtwdUfTB3CXb8xLfwolpID3+BW5SA3Cq3fBMm9QnnY5v1o99raOJRvxsL1u3fuy1vJidM8XlzUv4w6j/j1+0wqkwpoM7/xsctGhiZR+osivzLiV2iTBLUUU+ZgwJRiLYFFkAIaGBV3rUi38VbcHwiTELiVlE9QG/Xr2urdk7U1Cp5dMwt1ShlXQr5hfGiIO6omUrMokAwMoydxEyK5xU1e0lfXp9GXWqqylV9W2aiM8pU2tQw+rNkuiDw8yiDgwPaDLRB+gYe5mpZDagRACDsT5WIzQMZH9Eb3oZM375sDVA2NZTK1+OdKopt0tkbEMzl0TIJYSt6qsYn0JDrSISGik1JHzNet8U88rZSBtRBlZu0mSVaWv/SqNS0zlL/7Co/JyfYk3kkW6sdyH/+7JktgAEdl7R+wwzUHdLKn9lJWoR6XtF7CURwcEuqT2ECjjKmbR1Qq02w6OrS4O27r1qunjhhSsafV66sEoARbOEwhVDQ/YvDxWecspvGm+gzjhRAKGQo8DSAw65H0jqIr5U0OrmWxPqHrDI7s9dGBpbnc1fcTNMkIOa7lUg6iISkgum+P9qngXB6uYmOIlQ9W/vlRJU8bfo7/qnOz0RHWzddul6IWgttEPhAdSzVUdkZMIIMrBQzzXqPN7VA0U2hVNIcAAFnuELZsVTAYuyRMlqThqwl+o0wyDW8ux8KiKMVxHqojJgerT09YvzzyE/r21X2bRtHNvbl9cmO3PtrSsswwHTEkEss9v781W0tAquxqH7oBszc99Ez3T72391qiqbumCzMKr1ra5Ry22fvSGy6B1adplbyWd/OHziTsqtwirYcsoDwL/X7A1d6qXZYA4iAD8XykQwZhcXp8FhU5yE+PYlBOTITjDAW4LhPO1P2RxiS3tfF5HqXDTJ0He4S2hBCqqGByDwVJaBiLCs1kRzB3SVMoXFXfB11UQ37XjSGdM65t16FMVfpdVe38OvC6TJPcN+G67uaADgUcwIQAPktNewByJAwOVp7GMKBc65DDFfF6nkEhiXU3I1kODZp7ssyn3+Ok3PXadw/wqGxqerxeOY+QiMtSr2SPQPUSGvfyu1eidOqGmnFK/DVd2r1h1yGnc2TA5tfWibfGr7jNVvO3heptNnHYZqxMzaTR8wagTy4tRdWljUv4Sti4y3PZqq5wx4Fv4Nb5vRXOERtgU8HoV8KW8m4LCrZ895C33GldPR//+kFZ4WlMzAAAgv00r/+7Jk2oEEbljPcywz8m8HWh88KLJVoXsxzTHzwf4tZvmGIZkHgoKi92Rl0goou2X1Z80lRJ+ULBMJJo8y6tf4+KSYtpKu1F8mDlIoOZaL6ZrxBVrrqamfGwKhDXGtRLLPc6NV8bmzHWS2bBP2tp6yat67EkjzZSpumKqNGi4Y1ZZUv/lSeaFvcc/qtS4sJzBg0XWRz8ARdtUExpokHM4wkvIMEwWBgV4BoEAoOlwCg9Kl61zp8ug0iH2xvJjEou/0iUTcdOodSIRZR8Wjg6Wrg7JhdBmE8AjIyNGQEgCERMF0WEfoss5dNc7RAGSCkOQr/HWB4Gk7kn27KokPpHj/CjeSXMv97voRD3fr2TgnUK4RbuzmxtoFpXHZz6GZmyON/Wd8GqauLMceVjlvVvy2qk2zXTO38u7LBn7SWNBQCNyYSEJhCgpfEvLtghpFUuwjFSOlGc3zd54ofd1nE3h2mablKc52Q62nwS1aeHAPoNCm1y2Px4bvGHVcSUAkisk2td1dniIatz+SFZH1EQpTdC31VDEswbEVEGQebIpHftHJZXzGXPy2VjOt6Y4rMJMGxiQ6npBq6AAYCNopzIR0b4lQLXaaiysIPcYKRDhwkHEoUpe80ZgqxATRlaweHRxOKpEMsLWbHoiGZkHxibHKpcbTKQeoVe1jcqzaX7PnH2OpDo0MVnGyqs8YMIgtKx8ugLK9JxkfqcXoo+d1W/KZnLTdu2c+a/ryubmW03LTMJ+9b8tPTSfu072sdad60wXn4cpFLOv5vNNaVw9iw55x3W/rN8fsgE+tNn/SK4Eo4KwO/zM0HA0MtwtRhzo0tPPLmdT/+7Jk7QAFAVvLI2xMoHxrOZxkxaoUzXstLeGBwcyhJe2kjiCUQ5BLNGtQ25OEy6IIk4pQl7t7aPULMyVkP4wUiX67FoTyLkw7FvLjlvQ5gA8KoZxAbGGdTYEvwEFUIE34Ivobe/6S6HmQJpn5mDYKNaRKs6C0SvPuNi4fIk7G6AAzKuAAABHxuBYYYgiu5CBLItQ8Sx0tnhXdE1gVNV6tuoMPEpaLAFzTwlchxbVVWMXuLChoyVidpg0TXL44GUoUVCw5m6tHucrkUqUeVrdtZY3fsbnVCXGPWrdv32fvnbyS31AgRr5pzxzta3TVGHd6FL+Jgx/Fr0gPeJknb7CK8tbZ2kSz9Nt+nM36hnzMys9nftQD+xdk1WbEEVUid5NGCzGam7YbhJliv/R/SGHXXgAAAY+ik06pEGRQuD2KO68okEVqeVb7z2H0jDxAolK4FXX40cZYhFk3dzwiEtJsioaEYXbg5mKh4bfDxqG3TF1CEizF5SW7cjMPHNibbGNQj2USNcg10JbR0U5qED5dFqg15n1I+LoejE1cxbpKIO5WfUjwYcPw0wt45r8oBveABawOHIjBgAKBAhC0f1iIcBYOAQOlSmolq7SKjDUa1M0UaJCj/IWotxyeQmt8c8TLIxrk9oheH5lHqeKmF6eDFzGV5pGa3t6NSjYoI9+unCC6RTLs/kohN5F1AiVSUSJdxUqqe3WnmtK6SLGYX8t42EPPOG1vbRKtzFDz4dfl/S7EhaGLd57702Hhd3RMGrGpqHjwqsm7zxJbws38PUHbDChYqu1RGtjwt7jqbetITbfgRQ4LoCOZVt/00dFYQRLrACf/+7Jk+YIlbV7K409McIBLOWxpJYwX+XEnFbeAAd8r5W60gAAnYFCqmqUClsneVjLzty9zIFcuFrDQ6oGOCoOiGg0HXDAK3oOUuULcOYQcHhJzOcy9nhoPDhEp0VFWFp6DhZpVe+Bs3BcPcE98H3m31m3zEX21fBt8jtilbv9CRvwO+K/jHt9RS939Ur+6RPzWMXOFXpLKUwpExCdWsyhAxGY6GAoGIMcFUxTLQMwsGEY+F2ZOsCApmg0YaDmFS5txEBBAIH0egcEGIlRgQO5LWgEQVtMLPNsRKxZQGQ2ZOZIE7pcUBaSzLrydnK6IW/qGc1DZQFlyD0HVYlKckA5cta791gKbBx8KgFD17TNm1B03QPwzhdjyPuW7TpLYbZwX1UrsyN6+Xa9dNct4+rjp0O5LC1ANKqHp8K3tGWZMZ3svo8LFPn35yVz9eX26eXSBW143CkypJZ2X9wwwxvdz+clcvln/un678vVa1GedWry8rY3ZoTVJVdortfsrsY6/8//5fTy+kscjFjlvWGuSqHmaTGURibSHytxC5K4hZ///////////////////8//9///////////////UqX93d3xdaGFGFCDAFADgHAxFIoEAwBpwBI1VDGA8wBeMolRYcHh00EfMQBCFAMdC59VdpKOZCghB9OR1XcqOCwEFJNEwa6n4BxcWSmNV4EFPG0NuT6yyNNcsssOkMuGYAMLgqAJ6cLYFmFeQ5MgZZiBnBlDbHa829V6p2B2dtfl76IJC+wOXMYBVcmSQOpuf3XOoUA4d2mmIbuXFzDHLJByyiKPzZnOx1rnLe8c7GHIu+kCSh/L/+7Jk7gAJY4XSfm9AAyzQ+h/N5AAdBZVXmZeAAxEw63My8AFxcjNVYywBkXnRMZGw/uf8z3rmv7I30ikP9+5GOLofgUAfNlaaFiB3wuFYhf9n+t0m6n73+P///8slEsp7fxu32k3nvq3JtlTUIgvBwGrQ9VgF46aEwR///////////////////LG+/hz//v///////////Q3ZBhlfq6sVLQAaTkBRKJAIAAKlzYTUlUUOwEsDGcgemZ8Cg3RFcOaUWMwdYeHyF0acMYsl4L0u4aSlFwN8BhFUwHbMGYLWrhBopup0RRfNwnLSuiamkwjzDUnQcW0KJQkj+VbcdqvJYkGly2b6jZZGVQsB/od2txW20lqyryatKnZI5+R2RUvWxzhU1p811hKF9dqZJ4CMvXDUtqmFHaWuCzJBXuZ3RWRXw2RlvFfRYmdMM0Vth5WXkKPEj2iJKH1fdu7hijhdXLOodn2t51hhV6+2oxzgzMmJoV+iqH0pkQ1sTHJBf6igIWVGX/61//sQELcgABRAAABAAkHYDKbHSETkdB6I9XQI0/TokiC/wYO6CpRIFp6S56BaG9gLrDH0XlhOonLYLGTZFj8LcoFa4K9RqdwbGSGXGEoJoDmxK6I5oJejvGZmOJvX1E3MUU7prRlfHULZAU5ysk80RmbYuIFJoMGi1Ld9hSKyLEYvJtyZYDvMKjjmSjO7xek9ppcRoz7xpINe15jv9Wn8t5YeLQrZZN1jZnVKmb7634TbFhVtuH7vXdpY3xnP/063advyxPRtuoA0FWQSBEEHAXgEY/g7THFQDRJOL2ZDh9I8hJDSmbEWxZIkEhH/+7JEEoAEKl7YdzzAAobryw7sIAAQnWlhzBhzSi6u7HmGGamkgpLWUa1jTDPjWbdGD9IJ3Cam2ZR9/LXtbsJUXL5kdtLUuacq8d0iZ5C7SLbPDZ4b1iNf/9ofNnPOb5tvdO7Xly/Z1U+TcRtbzUNna73U+yhyaUpI9i/P/XIK7ftQ7bZgjJFUzMEEQJMcVEoskS+C3YGWBTwiLmsLXPefJvco+QEwXDoGgQkCMDZKgxxUTCIorN5wzYgzIHxajtXxKerSQHhktAy4Oio3loGCQ8bUFWpFjxOQHRuYlDuZQiZ2s6Ee6tHRCo+qqe6hSohpVImp0aNH9O5zr0/iqhrcXhqHJMXVcDzNPbRCKxsbERKgAS81oPWJGQ7s1TtbknDInVbiyGNODA7htE5HasAS2lziZYGacP004mVUyCM2HA5+Jw2tbWakcSuEy2XtlJ7hTHRM9CdMOEXZYELhseMxkkUWFjvxWDjviBDxqr0H7hJWN7H+zsU3yjmoKzuhzTkfhB47hoDycrov4/0hz+t6pIVdZiM5RUMTAFBp/J5l00wGRII0SWlMlToR9Z0pcLTkqcdeJx2q4hvH1Gl9GtQ6Rfqyb2aLRlPJ7r1COlEykPO1/Z4bZN64ZnGQrC8X4RxM5y8iduXyXg90ZndSsDZmMRbdd88x5pmiNd53t4+N7em9V5bP47v/PfqKIpUYfh7TjQq907MhAu7SpdWleVZUIS1AA2ulu0dUq10JwLvFiJmvIz160qpVCwxcGVMdEpdH6gm9DkLAlo1j1KBdwUQslpI0imMZzTXLNJFn+TDt2nd5fss18orXX80y0pSairvpxF3/+7JEK4AETV7X8wwzMpALuu1hJnpRmWtbzLDMSikta3mEmdnkeK+ZlXbIbhUPvRzc0i1OVt5/9eZ3Kr9nZvPyvWZ8+YJJLRtFHKV9eUZVUeu8tr5tmy6/zWIqEgAAILogsgAruLgIdK2ZOGAWHKGJFTbvNCep84zGBUlqZwBbUSQiQbYMNdT1yxhhVVA0jjKbw/hk5GFlFGJyRcAe0oRfdKoxCkooCz2w4ukjaovJtKznqd1934RQQcRcoYedFI7enU67DRPvtt6ds82/leI7tWS6md/hyjUdW2W9O/Ssk2XMX/8HCu07OzKpkEgAEZlJqhoTXnL7Nnb0hCQibkpWWsUrkzfEkZDOqUako0CRora0H0DWm5Zje+AiTw1nfYcdI6jV/yigXEaFNwqE6OR08jFqP5xxWlI6Z5cgQvoammmm6HS3byelJcoJUkcYigxcv3Rc1m62fUk/fdOd0srz37fN/+PMoO5VVSWntORjFdXfQpCqkIioQ6AAwgiTFdooEmkkdPsKe8u46Scy/YZ9uVC86AFh4dZIVjCjvARkA0xcCLSHSOEGE7bOnhXMOLotW63SNbImJRYupS55ZcscEH0Ib3aOtZADxAamhie0nyXhWfM66Sj0Wdj+J+fvvbruLWcUjNoQ1HWrIiCs2chqktk383HO5i5XisrTrYL2aoxpIAAQBFOthHgPi8ixVzoLKW5N2bJzrHn3uWZqs7FFG7cPRKfuSusp61G7FMzg1JGD9O3pSRSmbacezi2Ilws1oLInRbDkEjUQCBsJLWWQMIPaN2ckt3ttlzW9f9jPfS7v7SRKrLD2S+7mpbmBwUcFQzL/+7BEOoAEPlnWYwYdcoorysw9Jn5RMWVZh5h1Siwv6vGHmWHge7bn9ykhjC42PegaFmvqfTumy6aRFKoARXlxKEQIwABjAc4JYvpqidjSWYpSK1mTVKkA2iibEUfEmQwlrD3EzHonqlxz20tEzbmF9QqILpMwt1FtVV1lXH9IYXkio7FgbKLKIHtqB0HbTJj0ci5RbWjLM7e3aHPOSpkcDTWwjnVkSzfcRr13a2b5WN2+9pek8wzf+1VKMiMf4K3VnI7LU5AAsl4hScBqAowXiGigC4TBtEnGnmKL9TKhmPlXl8T08FlTzt3Fc5e9LTP5SEkUUS1nQn2PrFmmSUvHw7z92EuwyzfYTGE05UgOvzKOTZHgUbokBVh7jCqZKFf+tlrEMDXZ0JDcGaMAhgo8BpuLUkOiEDlJ0ipHaxQUMhjzyrhdowaybf+au2ytqAALGDIPLRQcl6JLjKZIBF2O2jyKbVhFQqkp1MwqyFiRWL0dlnfRB4c6sTMfS/IqCUGMYfLKIqplKhJbZLupWcMdS7lyha1rKSZRP5uk0UTSmd0pnFPp5F6ndl/D198xclupshty7UdCgk7Yp8c6La7To812x7127HpX4bHy97NmcpJh8+qh9YNENlczEkgEFQuygJaIhLYGWpQvHRJI0zup6sMijxtRiD8tqmxUIUTAQtfkcWiarbeXjoEbznarCTGELHp4xL4lGY7tM7rutSdYSREQlPcgXkHouohe9sjbuuU24jDy9enh57y8mYW4jM7SxZRUzfL19rHz+syt9Z67u/PQqUkz5ZwhjpU9pPt2LzOUTdMKABZCQWLHUTX2LZo+RP/7skROABRSWtZ7DDOChqsavGEmclBpYVWHmHUKDawq+YMOaRitBFmjJlPakZAzltME5goC2GwoiOJ/pHVEHVH3HKCV+x3LrcI2gmlpRX0jSB9Yc0ZZdkaJ0niKCZsP7L+FLTUbmO5PW8S0X+jjbO694uu+tpzlODe/s5HbGZnuvRrbnbWr6bGS9uZhpUJMjyndFwTbjv/fetNOuNGAAGGkayHDuEjAQivFmJ6cJjGIHWxqVAJFJqrSHH4/W4T+GtVowoEAZD/st7EdsN8MVh6dOcQlgsqj0+YvcPjDYOmCRWNnEJTigoIASHUgiD0oUHcuzUieR1BMcHQH2YmIxUU5H6U2MFQexGlbIjRSJ1QboWjH5lC25LH33ub9miwRqxoXAIz4yURCQ5oysIEBEzbt9uysrlu837KXjh7Xvo80o+nBgZgGXg8sC3aOSOwKIxcYhy4TKcxIYxRvTQdpw/69PiNHVqZEe6LKO0cxYpmYgWkWiXU8y3d5V4ZY5TVCZizQc+rQ8MzBlTU3IyECAtMiNX1TB034nlYV3rdq1X+1ycVtaTJAIKg2SOSQdBBQ9N4nBFuzqGEOAcSqMVQLJlA0MEuSIeqqXAjko8SqK5PM7u+lpmMmeZT1sSsF7CfgVbhiML+4ZWDxzDQhiVwgciPuMkc9kpkVkGmVgZ1HMoyrRGWZl92YGZ9cr28cUZ06TOSBwSVoJVgzA4fv3GW/pxJ61s2u0RTKBJdCUpg5AOJcTXH8DCAcSZSjZTA9S8aymSpImISx1zkMqpkkEEiFnVH52Vau9rxbjBnZWlBRa+yTbJQM1cKZvaZ47mjIkz6BUSxTCv/7skRpgQQLYFXp6RvSg8wazT0jfFApg1eHpG8J+yvqsPGbMMVKnq1QzxgbIchmzCRX1dB8sv8iOYsfCLCJK1Qm5TLWEYUQDrxTGoWmSPTUh+UCG79J5bP+JG0AFAdxABDwCUR4JUSsHmgTTG+GuPSf6VqaZmhsQGmJInbNZ4lh09dyhHLCOSESaAh0xbmZZRxluIVNYlExhkIIKUMiuOLlcqOlIlqLBcM/VFKIXD9A+Td7Oshe7MlDCyBgJ3M3rpfZaxeBulkQOObjqFXjuysco/kVIlkS7jscUJoAByDOxXh6RBTPEZRAgZCXw9xP19udvEPVuCcrqNXE7LmjNGcK4g7rVuc3WJrXZEKHi21UMXREmIcwYkQvDx4MJLDbBILLXIQZpwKENRLZHSEtAVHJ2vLmaMknqm+WC4wvlHKEbwonMhZe4IjZ2gWOSLCgwBiyy3VDtKqG14xAwAAJjmweYDjBD0WnsIFoVPZDyElo28r0Tju7lLFoXnqW4GPooAoFAvT9gimw9KAIGZXLIdsHOpzySLGHJafZ/9lO1g35oW2FFC6wtEJktGHc0DK5URnNV/2MoqE/IBS3I5agTtXC3wLfC3eXM87cXPKPHJtVCSkEiIO5FkUKuBZxVM5UyK1GSoQ0gAQXYt2G1LoAW+v1npfRSqJtFJt7gMXIWlYR0kDtG+gu7KVH8+zIQIADu0cM7nGzuH4TkEb56029mLMXNacdYsRroK91U3MvVPky4Pwy+yyzPOXULnvn886R+xf/uXwhVFCUMqFaaHobhdkhSIAEalMgdlKQUHANIvlLlXjywQnOr2HXSmEhaoZBURrQKv/7smSOABQ/WlRjBkTwbmr6vmGDWhGdaU+MMQ3JwCzqeYMOMAtMLsCna2I9M2nf/vL4ikcwxQHD1c9etihQx96U5Z9yDj7uRxjSHJrjBe6geUbFJVrmToLLVkmjlVL4Er01NUArcfpT0jdbpXu/bC9crF40n2rlCvfmYg6oEjqxMh/0YdYx7uH/H+IKI0qjoZKgtvFPdUFxmTWi65QRVF+GtwNyWRB0H9tR+el1JlMCEml3RxOEly89DSshJ0VS8OvJZLMdm+6Nj33clX+SHux/DIof9e1Rwx0nzwtMLDWAq3bdWvf+fk/7l7V/l88vKfUPVaZCxZZe13X11XLXVGQAABB8lcugIxpuIRt0EJxoiwsuYMryXWZ5nDSX4svm2MOsrpA8S64nR+DK08SYj1U18WITX8ih+myWpp2pNW8PTXS8O5GxtEsPqJvaITdV9XpdN24wMLWOesaIvZwtNQv9JewcXsoie6LpMXKVUKamVTU+9dltrF3O94wIopyi6kY5fB9r5pQdlLeqOVuRoAAASdE2zkiQuRvX0HjrElE2whotx0MH9imo/DkkJyaZqDP+SNbz2ekr1+V4lNozpZufMiHcQcQzUpssqsbUqzwZeOgrJJFNknuo0l3ImHkzpTqpkf7cXJUb4HX5vnpTjauX1CKWFhwLtU0nCyFRbdEIkMMyoZDCABgwN7tJnq2JRomDUIaIkZBrPVXsXZrKZKxCmsw5DcPY0sPQ0/W56aMskWPZvPbp2rok8bAEvnlvrnrQLU52hKiP45T+CRflANrFxdMqJLwZsYGmqv5APjZmzCfCz4X0gh0KTaCv4MW2fxdTIv/7smS7gAR2XlNjCURwdOuqfGDDjhE5i03MmHVB0ycqOPMKoK4qdG+8VBIgSRCQAqSyWr0Nn40jLkkgowrsxCXqgXCnTID7UiaBXgjYFBHHwOwwls3hnpyHqZUxM6rFRc+YmSBEhZMp6Ng2GFFFTloOu8x2bweSlH2WXKLpy6j5uZF0M47UW5GZlGardX0RadrvdOi6utU6toBBHWyMQGcJmCjBEF1pArSwehSQR/QqTTdjiBBAAJhUk1y+JCHVO9D6bzBYrFlK1QwM+7zfE5zFy5emMWoMeWiSQLws4f9gO1Qa6ItvXQTRNoquiiWahWUUTI6CUHb9rILZAjMasqiYZdh07xTFHWNuEyYiEK6TU2NLEWqVJVCy78zttv0ifsrhmDvBxBLSC7HXqTRuXDfEK2l2VuPkAbAKowu5HZIx32aPc1FVnuYvyLNMFqU/e1MJo2icQDktJDhNxtJ2sA428BIOQnKYh8My1vKrgYjWmMfR/b+5NVr+4yJQpCbqnRt4fMM7lnvv14nu2Zlb6abwlFMS3H1kp12qnV9DW2Z/3tTfWpqe8/65ov6pWGAKFjGXLb3UC3WAAABGELQVVxfQ6pb0dRUXYixK2QJ3SpnbsRJplHxwZJNbkANfPrnCy7B64UGYXJULIV/88OcEAjwojs4iLlPHa3IcvD0f663Cyum1cKatcOSGkQdIjRUUWCsMyJwJMHSa1ZekG6fnKUVuFzhkKqMLvVVWdP51qW7pPuW/nX84VmfPOR2QNSWUSo7fCgpMxZ7X8x9TSM8AACMBYu2UreI2MOfEtEzddMALrfp0mIWZVAuFmCoy5k7EKwKk5f/7skThgAQPXFNrBhxSg0tKbGGGaBLJa0MsMM/Key0oIYYaeS4SljVzxCLMGRIj+MulWCBaZqWxTU9UHVS8+YHbFi48+cru07NMPjJQ1YeebWPE2x4+Pbjav1KazFonjAxMVpfOUN9fWxju3MKZG4W5WVYIUNc5M1eeJtN37UpApElXa089O7sZGs3/i4s0dXxjmhL6exncl7b9VRECCRAgAAABA0F2Ei05C/TNJwFAQJUyqigDTcq+eNBCLk5RxufqOWPKOz6wp+2mOG8FQuRc7Z26EpOlFURZmpgWyPKYilmcKkKOx8fs/RFd/HwWKdbMlRGmQjjtW+h6Uys+9xWt9i+8bvc9V/IYt1rnagBQ+itj0OuuCvrzZWWorW21a7JZyiXfpPvVna5Q8lGhtZvsNZwwK/T4pAh5hUdCaRJJcMHYjbrjTQxSEQsZQYOekUmgp3T12abpLUjsN9CorTQ2fZ6BE0kYEpEU8e00ynOgkgroAdIEdoEp1w/uZG1NkNtinwRePTDkLCLebNgjNfCvnQskJYuzfM/P7ewpo5rsI9EsAFCNuXOvWuoIptx03+73ftgKuREAEEhIpr5KxECLJ4CSUSpRBc5jYgERRbxnrRmttD954y4su07I8DxJdJLCOUDUFCKg6PyVjwQ1TR0LlOryN0vnhMcKSQhIqHw5x9CenlLSOiqS7L+xnBba986rr1Vv0zWbLT//bOr3z31fwqX/YWMch64QbB/9Hj6w/70MJqSjeKe48VuBkTEoP9Z8ZSkqr3RZNFwZXC/EuaTRJQ+YnMAAlRzvDBQj7dlY4CIhudJ1Oy/bLHBXYqGfxed23//7smTrggTcVlBzDDTye8l6b2DDllP9hUGMsRPCMyRn4YSaOUvBpjmVxQtrklWBWBIJnlkmSFpJ5J0IhQIh4q0VBSaEmg8k5O62lzSGArpZ68V6MIEDkJ8USYgYRCuQ8mgMqH6gmLty4OTfTk4MDnS6C89Od7JkXIfkr3Zf5qr0GjpCuK2O3qh3mvTPdB49t9ZAgRAgAAAQWSdwXwcALFV9TCqCY0igqTMJU1fTB2mxQ9VjTZYEs+5AijuwpA9z0BFH68sDmcaZGplGwrVmULhA6iVWT4UyCGqyEeEKVJ2WG+qVBp1s7uInFMkLeY5tfJUG5GmxjjFeVO6dmMcer1x5rx2RstBR+RIqNPNE64QluhMPylFWxUuUDoF+SMLaD8pYX+0o4xGk3ID98lEHxsfPsdrT+OumOBiNyIzgRAAAGW+uBPUkAuEeku9G9Wqbbkw1OeHUhLyaqo8qtjITI8eg7NkBAcYwkSfuznLFXN3ZHCI00rOVF9pXXsbUKgrdvy2lFkaBFakT0Y5cW6l5MzSLnpAm9ahDMC7VO3dDWbQ95I1i7GMwLxS0InDbMpqWZFmFqtRcmfaQFARAABGCI+qkfMAFZXXJQGEDKYqsArQnE3uFE9NNxkMsajjx1mBQxcjckgVWRrb0Lbwk6xAss0OgVpWSRFf7aYxvmZ5np/ZXhawrvY+PFlS6eGJqKxyQVcLTz91xuSbt8hr9VMp+OUS63Mr0DFNGfsZq+9puFk7EOnuPvv+sSLPmbfibOxys5RhdGIbNpSh7cmndn5mIHsgEIJfT8bBAz89NO4m59bbdiQgA2BBQ2Rj1FN2js1QEqZvO4v/7smTxAhU+YU9jDDTyfwraHmEjjlS1gT1sMNXCAq3osYMOcToPo86MihdPBWdLFo3D0WypgQD2OekRvSe7nvEIc58m+8HVbn/IJ1OEAgEj4io+7PVPKzcPXZnX0MMITgR5zRI5OSU0LRd/KI3afIvFFHqcjG5oaxGV6hZ6NEABBFg+DAYGbhxfmnufzfq9AhjjBEAl16O9DKkz6iHyoJXqqlI0QtdAUvB1ccbJkPQkuaOIfIdU521+nxTQchINbMqEzkmD8K0SrTOLk77XE/1gkKSEhIHmlUl0KZyAkiB4jFD8D2QtgRjD2QgvVqlEqZDhb6yJ41gYLTSEorw4MHRNEUiTfQbIR/DhMe1YZZe9hJShjV+klB8zO9SZG3dIVjWMhichGDjUFgN1iSrC/D0dRleAX8+FHpbkY1EAcMMkQKgcEQFBZ3lBwUSmU0Be5dzjuW20/SXf5NunY68tO217KXM+VTMzbb5f8x2vpwZNTLyanjkkgV2fWySlOcR4ammajYdOIVNX5ww7NQbcbd/fO9hrYtj287znm5jfTHmPNGpPcR+9TJv0gqbpNG6pUh2aQhE2Jro0Xkg2kCTL4Iryu1l6zFAohrBEQlAAAARCHFimgANIkz1QQGB5FlHNAcOk4Wd6rh6qVJionTLVeNAxKwT9FetwEv5wflBYdJIUMEN/D99mSkkyxG3CRtuYbhuUhc5NgGZsREiLOoHoZFGLQLx3LkdF6XSWxVYHIfT6d+CHxJhpHaV7XP5qykc7T4Z1mGc23VcbxuFyWaLL5Az4JLS2RwS5DyQb7yrpFq7y1JKknMsbJiABITY2VCib5W1AEf/7smTyAAU/XlBbDEtSjwxKPGDJrhNpe0PMvSsCKq6o+ZYhoIBqfZQPAygqH4maLFoI0AcR3XZUkgsf1H4vhQ7ZOquyiqfTUQ5IyJqxw9GfPuJ7WKE9YqGRblJfS4OUJDSZR0tS0t2aO52GycOdPtk6q5ux7JFKvFPTFQy60ryvI2rtob2StnHz3XlTclFqeWMD/trbHknAAamLLKpPQ5MlQAcI5Eg3IxBjMkGlpwwXitx0FJF1y7THGnQDACabqcsu3NSPUGJIph07vOSJavV5aNPYbZYZPkaJpZBHLJn8oZwJiLVA4UWXFdnxoQ274bLHZSDkhVoNRacsJ6xFQqnKnS657mVFscsT9JoSd3iui/D9ZsJ6KO15I9OFXrfGlVy60trYtuVi8jh45rmZJ4sWFZvoxIWxathIsF8tEa8p3d/oJPPjw07WT0rMys7SIEAlsIrF1wNUZaoHBeVyhJ995xqrYpM2rqRmfhyTO6+kEy2bbx34pqMwNrw5aVSgNGpHI+T53UWv+Xltasz0eE67zUZPnz+ql+21D9rapmRsqqpD923d5a6lRRX0PUxWQ0+cSqyYwFMkOtKa1RYiz3WXnUgCKrQguAXGDEC+X/ESizsDQpI1bKroAXKpN8lMA2BvHI+YmEg5hWdDANxyql1c9gUR8j5cp9XRW5udOELDRrvC+lS6gJxC26A8duPJiZBUhCGEkiwFob1kPnrIi8IDaMWelTc0uFyDohMziU6lFIVbNNlTzE51jUgy/IMB+Fxr13Ho4K5ymSoc5ZtVyPCtUilvsylu2aRSUaluICPx82SQXedlXr/RZ6pKkgAAIOODyv/7smTrAQVfXs/bLE1wd0u6b2TFqBUZczsMPS3B2q0ocYSN4P6CkGJIOtVep9qK+7im+DuJw13ZSshGw66YTQK5OF6z27n9al+KmjiQSB0LxxrBaxBNJBAqkIDukZunFFupEprTLsdDYqZAyin2hAqXzT+/M81WNDPVS871fWwoZT3+rO+ZBqJowBGhxpjO3qoDpQAAMTAjjbhwYaBKosWSSMCMQVpmeK3IjRK5+lWonx3EgN1xgG8S8vLxNuLR0mfT5xuzs7vBvnILE0WXTPEakYccSqKUQ5qt1G6Aui+rnGoSKZmwCCM+ohAUo4iIj6sQkSL1ghCL0iBN6QlK3NE0SmPhIehAhb2QOD0IiTENkFIrXchjh8n2zizOU6TfFX/qJDZDcs7Kpv2hvY6GZ98Gvqz41bf22qhOyoNJ20sgC8jNBCw0vUPcl+lqIDGPSxWxMx3mSNLetW3OrfeuC5DSwKHvSjfZ0o59IIayaKRoK+8qZVQATbkkZeiB7C+WQwoZjYP1KDztImNnPlRM/F3goYUqptw/nUNZQFUDcyhVVMlMvBlYtLpXO0tm0WH+X5hnWeIQBpLLmbRIDBSpFEmUJIERQ3akxm5t8HuIoICgMVftWbfkQkjcem2kP3RV4fCEfEhJuWedLqNqulel0pAKULSQf34CeAs8usLIguIRobrWkK62kBsdvVPhL7HGiT0BswubRFf27usShVo/JUYXaVBBLMUMJs7l8ptDO+Masdzn/ypx4Is58shy4SfWjCtFctlT8KvTqzuizuYr/hor+v3RiIqg7NQ008pszEEAcy4Y3BgGCRNHgC/wAMSBpHyVEf/7smTxAgVSXs3DT0twe0r562DDnBRteTmMMNPB9x/nsZSOmHLa2X2FglqMmf7Kmhnl6pWTRhykYa/OtQcJ0qlNlbMRdxDRecX0tRUoqh0JduGxiwlBBwkZoYwOEhWZDoWJBCvBHAgWGWcNt28EmxvpBLpwNYdCTh74o6VS9SnrIg4syk5emjitAmRAAQFiVrLlgsGMBh6cX6M8LWqMgExRGHL/Sp+3RYiv5nl55qzuPa3VGdfOBOIQHCmGldCAnup1Oc7siVycpDiHpZGkiJchcMZ5PDEshBO1qGuDHpHbE+aTDGsYZ4oCxCWJU2UgliYXSB0DOVriLoXTT+EcKEzHorlqlzYUTnM1F8gytZ+qlrzIqs6lfI6KwbHDV9pFy4nM2mSMK2qxJlGISXOVUM8iXIbOPzbqctgejv1G1xo+x6Mqb6Tz4kfNhpelbqQBEyoQAJqREIoXfbu/akwFoiY16G1KWQLDNLVH1iVuaddli9JbXgoiHSyyMtaATzXYofFaAgsPWWG0JMhP2GV5BoiYLmEsaJCSCwr3SVMEBAwkjOy1GeFYZ9o2U5zpJdA+YcOgMgsDRlA0dFA4wVe6WOKjG4KsCBj6piZQdHcrXAKyeLnAVVMusw3zv2Ae4kkQAIbFqTQ9BLgAoECMigD5OBFhzlBW4KFOpOuq0aDae8/K9pXKVcQAnXZhLBkd2kpER1KqV/0xXQEa1AIpk2aHxNw6qczAERKpzB6j9cRktYVY6OUgYO3qGR5+eh5K5FFkwr4vopRYtyK2+oemp7vbBPwES5Asf1P7pXR1dGVWLTO7tfF3On46I5gfJosNwbBUSpVCdf/7smT1AgYmXkvDT0zwjKkpq2EjnFRJizmsMRWJoavpfYYJacZfUXL50GJrZqKaVMs8OrYJbk5lDAc27zZ5aCQBlkA4KVdTRDqMtrjwnD5YORcaP8WSsWq3g38ZylRIIgZT6paVstmtqybm5+mU0phk3U1bmyrHXZNVMrzcxiKamkl2dHZKvRiem1n1/1wyTagiKPY9+wAIQAAx9+ayzM4wHBrIZIMrgEdQ3WKhtXGBkEZIIsDHYJC4iJ1WImICsLA8QS/IE0cI6gmToDhb5F2JqukOH2PsbbeN4rhPBAl2qSiXaLPsLEVMReYQbGo5MxI1yyH0XNQObOG+bx0aGoIQNRsNM6ggF1GkiPblwTkSYscFkL4X+dsU7NuG2CrMt8kkS6u2lCjHCa0BteuiDsDnc61aee3Y+jjsxGQ7iQlInYGm+Ey98tuF2teiMF2ym47XGbqQYM7+uHqpr7w3mtMs3eI9/5JY07QA4G4beS9n7/6kBzMGQCALBwb76w4yh7R4A0Jv5DATWkOAgGj+ZguIbXJAulO0SSsJ7NM2rCOtMU0rB66uQctFSAIDglQC8kH/I8q0dVq4dvLO1uqOZV4kzwJXXwOwak6rKmDvvj01VZV5/HGe52Uw//f7v/QQaAGhtiwUZDAgKBWxhCEMChQDKmPtyVjXaXEaBImSoCV+zsnWCXFlm6acqt8frO2aL2g3KvQomx0oCAOmaDcakKDRQBNUwOBiCaO4VHCo4iiN/Ki8pHrYRjd2hBEgBOAiHg2JWg0LJKnAyTPbG0kE6GmdpAe3FCHORPnJgiI2+OpVTBsmnZtJib1UdKsmPdRf5rt7s//7smTugwbkXMrDeXlwa2YZ7GEjbFZNgTMNMTUBzCyoOYMNoEOl16YhCDGQ7SkLhcEAUJIZF8Mmo7wX30w5bZ+H1VRJoEiCAEfGtJNqoFQ5r4k/K3rXVCqNVQGhVVa8jgJBpNKkCyUXt3LGhiWa9OkeYyHbCjotUzyU0KslOFsqU8Ag0Ony00If/Ll0L7lEnyED9Kem3op9520Ejo0DjkIFxN2J3NIoGcMrQ45gYED64QM1epUbXAAAAITNS7JAjzCAJJhsr8C6BWmpXRkoJZFMVrUujKzLtNArpuprsULyx81ClTg4nAI9gnCCcpCEWSojHElA0cokGET5XEUDitKND+yDMXkleBoRUKtQEmTsCwegaIB2OLigVjUdMwnFQXwUipZFUwC+F5aJZEeZhf6jhwCVIQVK7m2nMwM9irL58safPZKQZi5rWHMvjHRjZp4GVPbEdjYWS7xnc9t7eTtjwyKUymWG9hNL0TcTM4dkyJzHezoYhbPku6saXBsVsPfh1jbzE1ErEjTK2/LP6fK9+oigQES6dIQJRkfQUmAQJDsypbLJ3qeVcTQE14OtU8an4Lpo1L942Zbq5WvNJTigRe4yh5x1d2SSdLI1GpR2rXhiRGKN3wvKbbV1YFDKbLYsPpxhMSLNntiv0lEC/OY+rkxnXQvaqwbyTFmp9GzS8EcIfduIrhmu3PNRmveIysP3OGsjCMeOlY/fL6wbd4bCPtDmVWGbk85IhyPdMKmRDhAV0SfGGPdMxsZzaPnOJ03SkgAb4RrgJkB6ptHngEXPAKqsaV15rqqLv/FnmXWR7D+L1B3QrDkugaEtvoz403TLV//7smTfAgbQZ81LLHzwsQ0KDWkvrhftiziMse/B/q6ouZeY0HvqESrFNUUiWYXaWkgjKkMrgwOGXy8O1xh7UWJu7DItmK0wSlU+6xF9xfynOdUZfbaVwnzARGFYh5+R7KVAxM1SCT3lbeO247B9SWl1JVtS7c4yPVqfL6BDi0lZt1UOVTuZyXcKBKxzrlhXG40Ka+7Pj9vmEjIW2pRM8TOp5stqhtWm97x4DxeRO8p9Cy8I7kQlwCBHGRDoGHN3QgrDIS2yMoTrOylvCFk5Tt4a0qZo5QMW4lNT6NPz2ZiGUJbl3nrJ17h3/pP0WaTZ27fP+4sKlj1ZJX0rISzW7XbF+sntX7569PE9qfu7qdHrZpz5M/m4/Y5/iV6zyp23f3v+SxvYaT3GXfKNgwmbQ+0kHgAAC+RZpYQGfEdRojjrbCOWEaHwKYStDHI4TBOCU0FSPBNt5cx6yIbnZ7K7vYLjFbl2jDI67bj5hNg526LtxRaocDCYYHqhClZMsyfZW4caudT5SKgeaXKWhOMcqGXynuiZIa+hKbnY2DcaidfkTRXPbQJF4yn+sJNDHeYUXe0y6UGW5eg6cDpjRY7EiHnZJ09ldH6cSPpBbGzriM+iK5ga8SsJO3e0khD9wkYqx6txNXKc/m+I63CpG92eTfxneLRaTsJnddZsnwlMqJ6oBg4V+2tpAkhsAAW0z5SYweGt2W8STdMpYkpcsFSYxzoiajTDENbu6yM6ks7EXahGzDHvM2MFwCZbF0qpCNrYwm6OsvqzJVdSriV6DEMtmtLs/TlZ4j9s5N60Qj3XGgOQWi4IYSTjRYFDbBG1LukDHADN0f/7smShgwZHY01DGHgwdSuqPmUlahaVhTMMPY/BvSzouaYJqS28IaYv2J8TnZ+Bosnb9k04zxMGGoYWCOGEwGmVK6UqvRUCkckST1GUCF0jqhje1U7p1DP4+40exkl3iwWt5GiLp8p1DBXSH0mE9UO42lweX8dQHXESoZbiZYHdl1kPx/fhincxUe4oYdU+2eZjY5OWK3HS6vkmtXYl2JoILaJx9eiWseoS4+vqZvubWHa1E8SY9glc+47Cpg4tnuJBKX1WHRh9F1E9eYv+1ilQ+KSTobjToxnaUhGlnIyOQBlihsna21m7eYkigh2a1gaQn6RKbuK62WjSvvNXPYWQ9NHX2fsyihh3c9MqvRyM9wo4lahnGUoJkRTkiUqcznEbVKzcqdrMJteyt932aVHys9HarPVVptTenQUeVxLPN0K6wbSZIAAAGFdwQhzTQ9Kf5aGNoJC3bCHfSVUFaBChkJYEyKuD8RVK/CQCA90TvnMepao3GVSDh+ODcbKgYvQKUJb7qlbyR7lWPmBzYyZij8zNq64Xjp28Kut0Ze/qH6F7kNO06ZasvWuRQtbTGTm//P9oxjino4ZvVrOft07Fn4ZO/ifPmGteatmUutjfar8zqxEwRqHPr0pZVfAeLvYLKjFnVHoTmJI3h2ZBJAkFFQGV5gAywhCe7pMANAGANBIX6h9Zy1Fwug2sBxVKZ4Dj/+lzDcECe0jTvBDTpDMQ1YuKR4K0S9QlajLOg89z4rpMrbcV/mGWnsSlk/nqzJ8ewb+5eXzn0pPbqT+HDVtHT9makC4HBGFP3LtebAIQACZ45hdVIinlwFvv8FwaXxeh8v/7smSYAgUwX01jeGBQdItKD20jdlVRaS0NMNlBrp7ncaSNoWIsGYgsaGndQISXNmSQjvVJU5LOGUU22H0FiVxSI6l0NNxhzcAsoTXRFURZdaCs8K0ALFgbG6aMlr/xGYoIkDpCr5aXqe+H461KghCRJyhk5yXB3NrGTnV3RHNLqURLifQl6mdNGPlU9yQKjj9K0F/mFRu2eivWDZhiAyijZQ89u0spqSJagcdrjbbqGIfnGnD0Re/o5c20AMAg0YacYMLEw48rchSyxGUvm5LT1DU64Bh0TAqb/kdHt8zzvNeFLLCdqBKSLAZuIFjZhl+vuSczG28qEYkHaGXaVmru+b/aoaa0iz/p/n0criJTgyIlr8VxK5Lyoy72sf/sWM2bG/LdIEBRAAAAGDO1nVA40Lhg4pBGmgG8NJhkkARnV6/8kj7GmnXHhi0pW7EGjBKI9ErZ+6XxeIbzpCXhDVoqMkVOObhYTqxKD2Fsmnf4JYCKUA8kGp8yqeyhEEYKtDUG5nY4IwaPSA5mFrE24pqFiHDDtPAVsVUmL8xUR+rg7S046lV5z6Kk4ry8YVvT16RqF/Nz3Lxqp71sYz2yZkIirMkZKu6c9jcqR/FP/7X9duyRECqiiRAITShiNCFQZn6SDoqtqthu7gh2WYvJMI0oOkxkViSx2wrl94IIe7lzPfPLG88veHUqSPv9/n9zcLm9i9KdcjKAbOBUadkjYbPmutb07Ef/RYTpTyABIgAAILpXMQIyEpQNh9RUxShc0LCDpWxyikcNrl2zkmEFDIetp5ibsUJafqWJy6N63HczlTTArEaY7K2FgdNFXFXOVFAgF//7sGSnAwVlY8vjLEzSWkZqD22DZhXxeS6Vh4ABf57nMp6AAONIoUNkuqt50lXCHGalMkGmHEOA86xziNRzhoxU3xJIqvtZhTYhJODbSji/L61cxqwNZmr6xY1sRLb95I1dYrf/735Ka8HFPje97zukn/7VF38+NH2rVt3qMyQPXxNblmeuVCllbv/9AUBrgARAJgGRHmIOkNsPFj3ViPUotyVNZrmUVDehpdKgcjKMFUyxc0uUGtY2BZBoUOP7DovYxPW3i0q4hP/5iLloqKPq3U3hU/Wu3n5v+v5SIkfBgqWARY1PKu/t6IrFlQAQAgAAAADKsDEszswASONY2PSUNHZA1QwyUzQcCWgNbGkoMFGiXroNGEQiL3lMVCiFKZ4hVIS3qSKBEUKjMFwA64vAILVQJociGSKwZYWEI3qwI1lgLXyhEAukkVDagqwBfdSoaCkE6rSVoV2kMEKAOtEE0BEJ0EzFkzKM6V6ApNWVN9DCNkOolMpk7qrmbqzFZz4Zy4vQ+Dd2pqdRGTPFP7j1RpL9rfgJ+YtDrtYvG9y7W2SKhyrQ0D3yx9mX14ObAv6JU9PS2vj0Ve5jUgoYcnoxQUkrnmgNKltFKtvNAU1bh96IOr1evDRc1h/95adCFVKlK9F+vTfz/5OQFLsabVFKtfeBUgxbWGLv4bRhv/rnIYWwBAAQAA15oxEMYYD4wxiYS5mHnkzkOWCEqKRAeHInIoGBS9C4oVKIhdJMVcaS6/k0hZA6MmSFWK1IqQEkElAqFYNsSgYhkozFFYyULeUMDs/FgzrSl1CgYcVQUDYkn/AK5YZfBCSsA7EuYnBCRiRE//uyRMKACK5kSKZrAAEI7IklzWAAGPWRT7mHgAsasep/MPAAbdxzLKtqNS3mS34uzZGZvoPisn40iHHpTzgrB1l6PpAbFpiCppo0NONDMpjNqRwFGYanYhH4jB7+QpgUsitDllTRqF1G4R6TyqbsU8r1Kp154CimEo1SXKkRpmsPtLYjHJFD1ymrQHBU7QzlyS1Ps8///KUV6liQwZTc/HeeuS2pNVrk5GaDXbwaIDJofBY9/uY06Cf/rEIreAKRiK0kUgwGQgGxmfUAgI+GeKCUu+QCL8NOYQsKwVSxnDBKBdyP7bCli2K0lwt8I6DHNAlx1JkxlwtmQP9uUCmOcLUGgkh4vB2o9SKhgcJ1E0ppvTxlnShKOnhq9ncI51JFD2Jc2drlTNNoT9k1tQTXz9RZW2uYksuawEZmPN/6aUszp28X9sTLBmvWkSJRzhWpvVH9sx7s7uWI54YIM9MxuwVh4f5hN+pY0e29xqZ+P/1vT7EBgaILHu+d33I413I9y4RJ7NcYAMgZAgAghggqGR6FQyGhdRAOBiNFNdAI1y8mLucASO3G3HctcjT1AGQhh5sYOuZD3M3Xx9umVWF7cjgaFgyzTQ9C4YsZoFzw8reJOi1talOBXKBnT8jqNEh2c0PtpnjwZ5XsRuhw4kRqdbbI96KuXOYlfAdQXUDXzd4yRH+38Kzzbm/iueqyZe5a3lMMCseQIFN+sJ5imJcxGuPqJTwaRodsx9XZ59Q4/z/TXzMyxqSHBSZqiee9fH7A4SQ4tnkQ89n////QAEFl4G+CloFSThbTPX8sMzVy1mOK47R2mNgTSbK+joWSGO8gnahU//uyZBOEBNNeVZdl4ACRy+q27CwAE817UW0k2QHRL6tlhJYwj+CkolYjuLutlzB8J/jMslp7Wkxqr6B8wZ9Z0+t3N7FtmSmvGbaabGSvrCpj/UPyQfXPkx82zrV96/gW/fU9dofG715/AcHzh6KzX29fb889/597xieut01K/Z9/dHKu9w5srakjYhK2+8vq37ZdwjrJ8eBAAQbFbn/hEUuksQkUiHJmHLJVuUHYDMI9NllMaIUtAUNlCWPxKZL7RN3tpOlXxq9dr7W7W1xPF9b0JVHaQW555vLkNMlUf7N664zk2v93Msps3NS5/Mo9bB30w+gncKb1XHnvp9usyJ+w0NX9kuuSQSalwI61KpnM1JqTEJHsoenRsZ6pvWqaIrsPBuGxSsIUgCAEAZSQLVwCGFCSCQAknuMACFCwsOVOvYkTpUJxqllwCJQM+PpPce2o8b/xuIVmav7efaMwTqIUz538u4XXYb6XyTMKNFd7BvbESF1C11P7njEzGcjsr6Q14UjHnllvDpDYn7DyH1EzlcnK7KD+cAMTwqSuBGpI4OGRzlrqtTSolqLH4hUWynTEH5LbpcnIuIAMwISX+V85xKppxR6zeAAqYBwYNHcBXLgxhAOMgRdbdzVCGGTUPMteTcsk3GzS2iM33Ri96rTtY0y9g5HfAon+/+dethtXmP3pFDueN/4r/Y2HjeqqyJb6FrR9CcnkRUWvupV7d3ojaIajq6xpVmZomjJOBR5w8H3UrNGD0xjabqIAdMgIKRttqHe6ZyqRMg8Bh0EBMQQS/iWTTW0RqfAXQAEQWTEH+ZVkFtztHiOxmOMkQyFi2vIi//uyZBuABI1eV2sMSyJ9i7rtYMWYFT1zSK2s2JILrmnZpg5oDpF0mb6NL81Dbq34RokVCNFDxaz9K7xYrv66bMIYf9Nuzpsi/W9b5EzX6pbZxlXaJG+9bfMs+O2vvhrP0y+XrYeMb2WVn7c+dSvLvp2RAXHokyH/KlmMLyWo6AKWGkQq0ylGJFmRKhWd5l8moQWdSNkQNTTikTcduPGZQK9C4ZjcNyqugceuEG/KYRs3+9om06CGI25WFVfbebjiAGHat7xg56MilFBVEMxq0RzJREypm8yGMx0sU1WRqotHFnR7aHxMY6lVWnHsrq0UCZUgUPD0Lxogi9z0iAAAJqTNSALiJk6MdCtmbBoFARGOjSgYIErBJZGKkpj5SCh0eLCAMDi0eB4kTCgWBqVm8YYSpzmxKA0jGhxZnDCG7ZwXNrcq3vl8E7iALHUwg0+igncUdQya7SDE1psLMvULr6K3uRz0ZY/xc5BZkZBGNeG14HkMkjnkxKvSjuWgVrjQCi0qhjiDPwMjmHHzaqJKYlCbHhJqMWMiuxW0DDM2YLAIOyNJ6y8QQNoCIIp2nAAJAJY0gZHFCMAhWOpzDSdN4VFJ8RVp0rQFPak8ifAM23NEluuF9KbOlTF+tu44+yhz3LcpMNZgmYKwpPvx9lOq8A81hW1b+sH2h4J/RPMm2C/1Mf+Rv+9AV7SIur6kWhXaHmbH1G6ucoPpXueVQH4EKfYKRMbHiTMZLRAAAAR8t0c0MmHKpzw6bvLG+FilwEEDKVgiGihMIgg0IeM9HAhbMHGQaMG0i4esZIFhHe6wr9M9aKhEvFEBnACaHCly42tRGNSZ//uyZCUOBb9fULN4S8J5i6sdYYhlFlV5QE5pDcHLrepNko6wRpXMZtT8AzC50sQoesLNWoRu9ezNo5G6Hsh6Wa/WjHUyNj2RsVtdTyWryVKocX/fkp/rJL03Ml9ABKE9U+cYwRStZljyJY5R9CxaA3+lBaS1XGooT+MoI6ssPQ4DYioQuLMddA1K0TWmjeWxd64axbSlRu1cnERneZwom0FUyVoMHRR9LpuK83YXKpWhZVoXpoUNEVCBQGgMg2amxtjVuP80etEX7SMOyILVMbZMg0W024unhn7klOOGar54rWm4lf/x1/2wjwad6utS0Vtxa0PbbX6ruG+ovkp+PtXzLlRHqh6xwcHtaDmWqWBvqYxIZmtSnWBgZqAxg4KDwyMPpcRBgwgA0SjHKCMtjIIFhgyQJMnvGERYUBA4uLVHrRgbskIXSbFOskMqFQWolARkKqrGGfOQJA4C3hDEBQNEIjA0/25R386B79d/Oe3QwDvkhCbwMKS/askCT0WHMT8kRJ4qvEHTbFe46vKFrSloYAYqPHzSGpWqr7zF0NNkpo5W+eGyrJph7HJaEqHJx5ByQTIcrHZphblEq5YFOuS80TCTcZUJBkv0BazUnnUaSHGRJMlo6zlfyZHiD5KX6jd2lX5Lr1pslqMAco8YIGAQXFDHxMxXrmWRohGkHRBzFAVWMYZqVP/56dditt+rsV8rbbFdSqHkV+sPcnTaMfQnIXdm/pxVNbAzwSKYBV8sAAKRNMW9hZ0MMTTOcIz1bMFO0SUdzChZIEPLcQ7OjLjMpEDUiJ0INIl4FHlyKZ3EWWKIhS522psFbRoEgXMuV/qW//uyZCEMRQVjURt5QnBvquq6ZWJ9FMV5Rm3hLQGgIiqdhJYYJtbX9aqZVptg/BaQZ4gToHR37nYOY7B+15nrYU6EMRlokOBT2EAQ8sV+Ee5Na/Vl4db1N3kuu48YYqZdfEdRK1rc/1zXwjRypFdsMUMIdiCHJ48ZsuQWK+bVzjbij1gwAAEo226gMDpxBCCpVRKApRKDwK8CNMRYXF10RKMOARwXsmSaDpF8tFhzH+VrSQJRIOqnT+1ciRbvT9x1FDVi4NqlgzslCLkq7o6r/S9KPuz6Nkmu1QoVd9lKbKiF7ImW1VqvUjNltq6jit9rSftAAbalM9qTOwExIQMQYzv2IysdRiRsM3IC34OCmVGNugsoByMH7HCnKokZN1EsyPbs6sbRDq0jAW0DApm0r1qKNanxCIQAFZyXYtCUPX0yeHhBfelPKRZOJA35QhddcRXEuZnO+6VVJa4NMf+mOlRH+q23+nv6OHVjGHr7/tZZdj+W7lydnp8tysudx1RkzvOodnqG0Nh9HeyChLSSKEaSaRMiVcLTAgSmmt4Zc3yHmj71uF1GDF/dN2RHgxYixqaWww3Zz3hVgy5QgJTaw0LEzewTXojdPH/wD4nIXIazsMYacfLwKKI50YyoY6kJayev7PkOR0KfmzMtHMlk0PfHbECvTZXMbxIeLh14fkk1AFAAAAASaSpuPxtxIqQEyx1ChiTBa5h4jUwyNCGujpMxAwOEIqMRL2zTYWKIToIkdhrsrtMbtJROL2GHSlNyYvN7e1vlNCp0qV4wXbMLjkIdqkI5z8p0QRGo8RFz0Eg4zHbZT0RdFfL20MES/UeR4iLt//uyZDkAxFVcU2tFHlJ4CvpDaSKoEt2dXawxDaHOLuqNh4z5ZS5P00259zt33Ewrx4Et0ARFdhrQBG7+wAU2iobLOTKzL2zKIhISIRgGKhQU7CiYROU3AphL8EikkoASGJg0AApCy2fYUwVJyXRGB1aXUEBolQqtRE5MsVnHTcD/b/6/bhJKCbcLkx8NM2rs82vCEEUtDJWrOlnunZM31fe6O1Om/7d70rZf1f2XqtRyFs+geAIoQAE7ZE1zOtpySwZAtqmsiS4aHDBOmNQAvGVl1YA16SYGvW0pO1buVF7y8VqeXFYltf9t6xJMls6232DIvVIzyLlC7AMEQyoqvFxd3ZS9x4/5KIHFh3dd3G8t/UeQKeLtTiGIcSHYq2NUioGi3CGCjsHB/wk8um9/N098ChkuWjMAmLIDhwXPMQwdQuDdn3v7iv6qS3ACcidL7HzZ4IYxqIjJ2EsTQJghWKBgMU2h0bZjHTBSq7K6QTNEeJNosrMeSTAbLn6Ty+e5VrTVL0Du7kfnCSm6IR303gQlf68JEEC/N+uExFiRTu2/ubmeR04TkxfIXeFyu6ZLXyQ8PuEEIai/mEIiHx/mBEBAAALcrcokEIYjcPCGlrzaGylxoed2Oqrva809NPTakkvlH1Pid7Uz3Bu1t0H72k7Dfp6S8n1SQwfk/KbIlkzuPS5rF73gW5Eh33S312bGvc/1382xZdZeR3unxrv/bmsrboz2nnlkWxkU06ZynRVBmnnGwUUR1o+XJ4YNHlL0CEAYGyDoWEwnlQzCHsHkL0KZOeuKkYW7MkAooFRxMSiBQ7QqdAgkShu1GlOrCfTmZG2O//uyRFoABAld12sDNTCAi7rpYShnED1nWUwlD0oJrWt09KIZbsdFw0/FfNSWINLLXG6Y8kQFjhhr9Ufu38jdXiO5al741tULKWhibSdA6S3qN1Vt7WFtEWVZlsOlD+Joq2OQUkgRhFUvCtzajmgkQXy4WSAJ1xJKAWSNCeBR1BQQCUqUWWXUSDcJIllTNXEuLrmRA2G3MCcQ7Z0+TBJyJAj1M6paTXSQkJMhh8LK21bVY7HodZQanaFr7FrEMWO4uBjRbj7n/xhmtzX0vqnM1AxV+OOTFWaefuqiLu/jjuZvth6TT+6ezqJ0cUYbtAVBafw1sIRJAABuVtuAAME6ACwUBOhJQEMoQpyYj4OshAgxtGqwJdZkSpzw44Nu4egBYm9KS6hCgTlWZYgNP4y+NaizWNg4oQQidag2r3EaRJAtS1CO+SP1f9BIbozcwr+SNvVVsya25uSESc+u7qXt+qpeKZiPuMi740tI9hPsVAy+sqCr2/QAdIsQAqNkmBQ6Iqq6II+FCQy5OhShrK/H5THZe8676jrsUDY4ciJhLDC02GsmRK4MsKJez2U59/dcCPVcteNcVoBoffD941J4Orzymk5hPUrfMQOtrXmDjuIFr4n2LTVrtLpeonqI1HXW7pu1W0zcQPuhh61xa9gq0oRSWl2hMR5UL2PUBAAATEMPPHS+baw1EhGi0XULxvA1sSeYGnZDKE1jjxsLak3VNaG8Iyy5RLVNGWpTQTzCxwx0NzJopeT8ka7tclsKDwZRjapcSL9ZqTP2nI6POz0V0Owo9US7Py7NsmqcSpchqCIx0SdlQO1dMYIlKoeBnK9pxx3N//uyZH6ARCde12sJQ7h467p5ZQWkEaVrTG1hBcHRK2nNlgoxqAbjRLHNzwBY+bV8Yc6NEEDSABtYsMmC2xoOhPhhGaYXyv2A4sjFGKOw+z+TzSIwsKBFRQHwpQuAgDUirck8D5BscmPK8pplijscONYFo/aRinbki/jUuVDmaYVC9Sn5CD7RZ+KvY2JkfPkX8VFwPS4dm6T5RPT+YGe8XDpddzU485ixq1YhE0NCqQx00pN1EFjRp1nmNaB1GLFRNnRcFl6j5dBokHsgT7Um+60YeZ68sCWKYjj+gVBwNxKEs/WoRe86PXGy7OWcjcjf6WW5cd+nQPTjW40E5ZtTKx7LFYpIaqtP83WrP1X9y/bT+S+nRN1bYvPSQyq3Z2VB1iQwy+N+VQRRECgVNdW+CRpNwIWZCZIgshLtJ3xgWW6iayAZlLe3WToCGVgR158rxTbkEfd8urr1WC/czYI4VUWz6XZYJsH0lS/Sx7RhdDfIvyRlWJTnrEcTMiTV043Ya5GNcb3Z0clGTkC1jBBDlO7b7VrXvb+husNV/f3tHq0si3yKj8GwbJsVHMOYadzZqVHbqxAAuWWTBgzTJRYLraAtRd6PEDygeK4LavmIh04ms7CHhy6+eRUyyFRGcBg8URZzjozU4WV2qlGaxUNQ7CQ8Bjs7pQyujmtonGEVkaRIsYfXU+61JRjD3M2qGHql6+ZtHNsvfc25W9mK4pjJoC/tDgBklbeNooenSUOck7qlCVRUoAEVVTWcdCSNDtnSzWWtZoEZb1pVOwLU71iyEhF9aeH/sFsnbtrWsVD9XBNInJYO3b/KnMTou1drn7NpmFD7//uyZKYABGheVusMQ+huKxqXYeVYUe17UuyxEeHFK+rph418xWovsLrn9riFl1r8yoc1JY3tRo4d/fNW2DYp/i8tL+b+jk0mKgu2+IuY/Fhl6ky0tryEA5ncy4q2VDn5SpqgNRAS7lkmC1V0EuQSCKp3IEUB8PNkUvcoWdr6+nhg4XCNi9hdKye56RIZyWy2wc1hXxH/q0i6saw5eC/Ysfkkz1OUR+fPZPe6Hn/H+EZ/2RT8i/X/3BKrMVKSk0Pvcu9SkfOVO3Y6VzzJ0pigMwVCf6kCSyS84oFSgCljVODhJTEmHiQQCRJm48AdwdUJhqtL+IviRxqMOLcSdPFMIkHZyDpoRTr0hCS97gwpmTKgtLDbp+mWh+frY9i9TDeMkn1/gynZVU7JIQJckS82gvUlX+R6y3/+ory13JoherdjclMo6PtuBoixla8Q8Vf7O258V0p8BIDeqFZEAfJm5THrrkgWpJbgQ4fyIUiMIVeKCdLlD9f8FjTTWUUUrkBStbKkt3lYU+MNVHB6sEWEwCwWJwaHG6kmB0zs1jYXB8NGx/MWas700rUpmqd20Vbr0FVRedWou7tuR7ZVXeWYZl4qlQdUbY8b3LD42EyNI/U4WAKt1u5uHYGEI6DAkbhhztOhL4GDY4lbXV2mVD7CXwFlLyQVAbcJinlTCkRgOfgaF1IWjzoTws7M8w6U4HJnXqzVSj/PWbq5GxYdQnDG30K1jAFR3mEc2JBH1Lb32ykK9B4/4H9kXyeIA6O7uLkdJB9/Ccube1Xu7U1dONHRvb3EGLAhh8+LihPK8+oy0+6kJzW2YyRRvlFcjiIkgoWsAlI7//uyZM+AxH5cUxtMRGJtCDpjZWKWEgF9Tu0xEwHFq6mNkwrYyyUrHGJQFCkwFOJcsPCYKSamZiAV6NzkFanatIHtvT1StvTzuK30sOpK+1K6aFOg/zvTaFGGzO/fMG1V9lfi6uuoSpJcl6FfbQORYI3o9xfQt2M9G9v66n/USfQBroqqBKVzWMyNCAssBUeF4gPBh0shAHLsCAiKDDRbY0YILDhmCQgdoQBsMMsSlQBDyRkksQSbVhLvp4PSra1sOARLpMCwDAV+wwZ15vG1STQ4VBcELyJQ/iyiRNXNCfJD4s8HEEGUpbxeA/gQjh1DAycVsEhDIo/kacbMQ1bE/MflpWDQSGW9VwLxPBjdEV8d70nVP/NUW96lFV245jQheYCFen4+Rj1blUACcZuGsZGVG/KxuQUaATGSERjZAiMWvTUBUSNAo4VJvkQUFjv+KjJuLTCbsIgqRgpIWTAzYSV6MK/0VZbD8PPjm+uT20kB8s5UA0GpjeibU78yskRFrNXa/7/nXxafS3f38C5sDKv2u7TJ3QdzQzV+caw+CwXAqxpnivQ0nmCoYLg+oKz/sAfARCNIFMwVEs6IyYOenYElrEk1VE51fl2pSCQrquarRDQsKKC8GRF82fEldyU+HlvUZyI/5KDa0zC4wejPJcOVVmI4Is3beJxo+eccZcS940eVViyU9t8jzrcUT4HGcT1xP8JwLl6Oeri4eVvYzRDPyh27PcrA6JPfhJmx5gpQwkXcvI4GAoCB3FiHvFEhFfku99qQHkQadZLEHtgOWETFt0kUCokiq8abiP8NJ7MkhUsuw+1FsLwW+aMDiNoL6nQO//uyZPeABTVezxOZQ1CGKCnibwhqEpmDT00xD6IwrunplhoVn5wlOdIEEYR1mwh0Z78uT0XTRQ5NV2BGSfdeu0IIO0a+/63bmIfd7a6dnthiH/juTC/GUgKpAm6858Rlk1cEIH1/r3/2fc7RnyMu9nwQz7Fu6QQQNuM29dPN1MngfyUAYAAEUgDDQ0Ev0PTHKOcFkS7WiNc240NqayqPhiRQWCA8li+oRhVB9MzeteSNuaqW6dmeYu/ivjnubpr7YThsuWtRrJxednHLS+T1/HaZZ31ldV1XNb58LeVaivn02brWudfuW9K6vzyZbbXpIrYsc/UjK/mPln0dnH4XGz9zuBuvXraL15wrNKL3R7A2Riy0JJaWtPpIU6EXDWq1uhAHjPuOhiQKVkCilJUFaFiPWTDIA09Hicdgs6pxi1CRO889NEN3YGnuTChFUdodXwx+4KEVN48gZVY9IP6/xy9er0sxB5cndZQmHFhJLhmWgUOx/iLAjAgeUUPhJJOCti3UeljHYM7bVynssy6vsexiW1VNH0Er0j+sHHTyTVi9q69ph9tHsKmA9ylSZGdp33G1K5V5nxULpGT6+R+6Fdvw2NIngZmmd1dEoBbcQOb2CZEMzAzFNNCUbOW2TJiqeDXEH2HxuFWVcPLVW5KSA4Fw+CuKBs0FjIHRGSLhSSao6xLHC0V3qWyGnni7CgnGnfc3VezCQUANA3QaKsPMD3J+OBxm1OvNJHMVNs9VD1HMjbiZZai61VHFsqymWxqPxU2cMu5qEVBx4wKMHZIiijiplkDYGmuamwyYpWASAAQACZXSZMSFBYqKNGEhtABDsBpa//uyRPgEBSZgVFMrY3qjq+q6ZMyLUiF9TS1hAcJNrWklpiGhLJpAcHb5gAgEJOfl9UBVslmoWLF5cUhQMZjecncGKK8o8kOjauIIrW6zDzhSjCiC+Y7r2OYSg2CKm7tVxQTUQ3w4ijbF6FqgkmfGikzMMUKGj++kxHKFoOMSVHfBBY1mupi7VbTGHC0xzVOpppAsFC2DujLaS0gtNsMH//VYABOwWCKCMAJDHTE3geMKJ1LhwhiFdHlu2fGk0muhwW6DQmOyRS2CGEcBLBqPReSUERwkkNx5gThzt8tl9UtJ7sW2PIexpP0ta9jzJNqNRY+dtSZhPM9k7imU62LXvU9i7pxKKkH2aM9mCUj3EIt9S0U2Mjh+WW3ZoY2fmqG3ttPtgVVgmjfc01BEw3B+QEOfLiVqsLPQ4dCC9xiwqeyYLdDZ3kpERiajQFaw4n7I4UoFIl8ETVjCxVtLDK3wBNrNmWKM2RB4RRoV4ww4VX4y8b+KFCuBlokCMTLGlZe0u6IhxZTsJhh9W04iJ3RkoAxlVHavb168voiJO+5crNW1bPN1toK5VWhCvZMg1DQ8IsTSsODPFQSgPxYzTAAw04BLQYEekg4JaJAC54iYzIhHuwPkr8vmws+qV6thhqN9lvoZWS1uAWVUqVwfqCkHJnG06GS6t8gRtIH05gGyyc6k0nXJqj5KORohdh4xsMQ+1vK2vbz3dejnb8zSGMtfdrd+tf1Cq3T3stQwaesu9mYGdj1StzXY77RUWZxDqz0Ln9ex12PPZHAfLph92loCVHFrq/s2jNau0ial9qwAFCABM0AjmA7h8xZAoYg5OAgxdRKY//uyZOkEBUpfUJN4YVBsyzq9YYVaFLl7Pq3hhdIcLOixrCD5mOsoZOFREomMMFd92FKntgJidSOO827oS6UtgtOS2aWUMTvYDCBWne7qlJg1aT6upjOurYkBARtZfrq2dVmJFVkdroPHfNVd9fH61eLN1fp96tbRHMNdRSr8pfMNyrc1LcRd6vWLCM9jSB9uhaQ7f/EAECOoNM1EHgYSDNwpNAhYyOUCIEFUDnlKJMiXhc02pQ18aBUMBipnNRJfAQ8lRJWnOsFhmXscbxtRIRCvjxsylew+Caiak6NH0wcYjUw/9mOHcpeaGyJR2kub0iLa9yRb5ZLiuWedBWT4wuXMQxjbxWTWdJExGKT3FgPSR71Y7LpNacZrnZLP2WsWUb3E5xjGN3SpDPZN3/oadQSBhVksk9nOga1QXTASIpTUE5/XG7t/W31zpWs7SvcJYN6GjJ81x6zEWlrCuUWoguq2DJ7DY+OqNJKPiLxktaksoIzhW4SLcfXqsTNRUTUy4pYlOUnHyynKapTW6ws/Br1PlVxa+3X/3Xz4ngwf8Q1ZTe8+01Uxr/9SvrF6Wn6+9jD5KMyjH8ZY9QgTifWNlA8Lg8DMsOLRiEgmHgSIgcYAPhgsEGAA4jAjBYoMcyUJBACGDJqA5L2ejxGWfdmYYYDRJgDgMfcQKgqQcjcCOOhUpM1GK+dNbm1iAiEJNs5QuBIINgNpQiRojVCZasSShtLEpvUZJLE2chGMq+HLy5CpWE1SHEos5VnV8umo8Nai1laWzE0GrVQx95seQrMxUaf/V5/fSWYlO8Tr7kbZVueKx2aeBQWeUdDXJAbpA1I2k6Zy//uyZO8MBV9ezhOZSfB5a6rNYYhpVhVxNC5tKcHYLWippgnxcacIAkAGGCxlFEOLhwlJZ01FFvNlagopcfxaA3C8rk26ozIdGzpSUgRXiWXD+zOlbILS3yVK0/0p/nUkcUGzH8NITASFzbKn+2qERS61LNr+pZksrUR6TPZ1ZvK2zpVStS6JulfoUoOzqhgcLxoFRWMoTcwmSQucQFWAzSmRh6CgOj+YNIpgECD/4iQlDbF0h7wEIGgJhJLlUCoaWWP+ISrANJgp3VXxyD3bd+UVg/EwtJTCwlrGQ9GoglmpmjaSlKniOlcE44VQQpMXp3XKrVFzoQbUoL1TaKKhWvQo9DkUb2oTupblzuCS9jJvuXHo0Y+VKfJucbJqvXM9z1qMPu4PI356s2H5+obIeu5vrKZaonWACxA8uF7szk7HSkKhYgNhUHBAgYSQrsGupAkmS5zYFSK2Aqyo2jhDEyrLojQn1deMYtQW7PReBI9S3BCEEEVLSjd4x00TcsaKp1O27sKjq0j71pppp3v7sfHPxkCLxBUXH/LLo7PIlWZnxceNS7FY4fmRzXI6ap5M4lWfFgitpcrD/WCC0LmOMUarAZgEfmdwAYtBplAjIPCMOmRBKGCUBA5wjDCCCAsLBBMQGBIhAyWa8xYArrlsXiylqVzvK2vkNAVKyjikOzOpuYYvvVBclUTcC7dZY6vKbTDEuV4+9XAzcr9VjseMHdDYaD9C+lTm+xUEXqLIs2ITYanvY/+/FFsQ0FX2teG3kSilc0t6m/V38zjNLgVMngWq6GsTBIURyRDH+UOCRcG1PK42FQBgm241Ts1P0dGYyxiI//uyZPCERSlfTZOYWmCDSVmybwhMFVVxNs4xGMHPLWgplIooJPpK1MYOIZwsOr5PR33CpLCAZqcob16aB0wQH2xlwNhrVl3Y0iFpQfNrcaXvpKPurvMlG9kyyQU1DKXUK1jpjJbFTF87zkPgyO+eUcUqHpR2rBksN93Oj9ft+26dKhGyBRELvnuiBAUi20qazmppsPAgNmFSMaZEgXFgKEC7BCUGejQoTtMWg4SBKcU4IAIUFdJNsQQJS8L7tT8gBT/OWse4r8ORYLcrl3VSpcNVLRTVY0onY7BEz36P7xk3/hzd46UgXQi8bcNjm/O54syrZHo3bUnWeLmMfiZjR6aj0ry2rdP6cIcH6SKUq+3HxwKZ28VZgJlUclMt9v4q6zMUeJPymuVnb9fVpLm0A/dearDdMPCnD4SwbA3fweEBrmXl6OYrRbjkcqjWKhwAgAAABkAznozcJASUNkhDBBYTkQ0WDgEov4iFPwIQDOWGqURNdibLRHZVUoAs3CxtSE7JcEJwklVd7aTct0LY9w6GkoFNGhxTYtPYTlDdlXVTu4to/lH09frp9O2p2r6qXb/6en+mo8zdZRd90ZSu9BzdIEIKXVLZ1yAZqEGDGRhaaaIoAU1QMC46BQdFYSDS3BjBITCqszIllhy00NHSAGJN3kUiYc2s8/srZ88MJbrDsWsxx/UzJdJIlONdMg8YJI0l51C1sxdtreI4tFiJfYsxnUD7ayFWWcibqprkE56nvZNC/itmbbfuZaHzV9sVkb7XQQuTe6kwL/5pP4QIQ1TPMID9fXtlGVp11BbFlHQsBpkwC0TB6eOrOyEOFK5cABCg//uwZPSABidjzbuPZVJzi9nMaYWGFa2DOy2k2UI0Lun9hhl1wJD11kinBjw4C9WTMVkCYTECAMtQcR/AoEAhxWdKMBuZrTMdDpbAzhNcUEAgH7+LRvzNnOZEjGY68ctGIzd+bL41Tv/73rk5/5md9g1Pu8O24rs7EEKy9h9xykMsqeYq/H13u/sfM92Xf0wyHuz07aMvbs8k5Ns6UK2+IPIE14YhBAPRjzHu8yBuADHIAJUjZCp1iBopZoqnGQXBSri+qrJawMvuPHBgEZLgrJRswDNE3x6NZzQeUdh75hq3LrmnUXOJqq6HrUtQ29osLnVZg4cmjKR8cZ3IQn3O7HmA6bjIdH4havV95DIr8NbOkU8oS56Z38isjt7uAnIsWzAyOFIipW+u30h0MM7nAZZcyPX6fc4EivjxoLG7z37jBVlmR8nIiveYQhy6YFsWVGjI9k+niwIewRI5dxcxI0KOwgoN+MyI9nUirXBMzbYXs6v9FZAb4zvM8k0dwfjgCC2AR/+4NFAAUadMdBKDT5csGTMP7CiKpxqwkBzFSJOlnD6HYf5d0+yMxhoawNso6ELukHsa9D8VN9x4kmGO8se88K0zGqLYinZFclpgZC/kIAW04XtQKRKyOCXJ2SxPn6k1Gr+p2KJn6fnO2sTfnE2HFXMEGNNPiRWRY93iliXRMd+0sKHo+50MfbZ1ezuEdgOuPNMf7c4OaviXjQYl1fSHBfqangoXBT7LSOxpBvWMVcHhfyZsilhDfftsqvYGptPc19O4EHO4+IeNe/j1gRyOr9wAioARKhBILOjEFes8GmRtdFJDqw1PaTquUoBgbDb/+7JE4gAGjGdR6yx7etRs6dZrDygUfYNFrL0sQmKvKLWUmnAmwJkN0+2s4lUyDLABTbIuPUG32i/mszbUZjMRDNrLczUowgxyztfJNZVWHukrhqqVnQVEUqQuKtQqIqpNF/a7S/R2k6Sy8NijSjj1km0zi0lsq1dXpNbJQnGaFm2TlJxUnTMyJKqUREq0jzK8eitE2KRwQFWlThuiWLnFxkom975UG2sMrADEIKJUJAAJ/BgAIYGBTgO7LVIlRtXDstGcRB1yW+kNhGGfuNSitPZl7Ry6a6IVh25lN3EQu+MZEcC5pI/6qLPYUuax6DGHSAsGMveW2MVSJEMODVXvKw2adTUa3sWkm02ZT0Tf8mQbrg800y8K77Y89HpP9l/R1qI8jiLXNIxDSJRObdPzYk5qHATIpkk8q1Fs5w4ybht1NQDDACFGwAAAYvsXwhwHF0Pl3oDW3QmzseWWvdImRT0HsxeZ8ZG7NTdFJJrFrkKyZtI6kRsWsoG2peRxnSr2pTdKPv5dp9FJYrodbltf3dMWxpHP7xMhAlvtt/glLcd52zE/ahf+ZpoEVGbdc1R7Iwg3+Q5kmmffL3EuczTRovHPTujn+lsGlRtmOaDUo+gcJJgDrrgOBQJmDGgKMARiRCR5gRTU3NiaKQsBfJzoaVj3DbN4tjK4s3GTzlJPxYK1E4jHJhS/1qssLl7vIarK7zKCPJJrCCf/0uZOYaZC2nityetn3yq5ai+ZlgaVNE12sqy4fZrqD16O0sSila7beWYo/FHZxiX+W/Gp09tdhjGaUcTzBdlaV8xY/ZTrOMOXFk3cVxRFRICxnHlpasAU4ED/+7JEmAAEd1pQ60k1sJ1rWfVozKYSKWdBrTB3CkAvZ+WmGfgSNpAAGDrgZ+WCIY4DrLPU+C16wEUZujwKEyqCh12nXceRUKnq2oVyN0lSSX7qi1+leOfsvQj09Bjj0pTxhc3BFv3cu7Sr6yEpxdCGrDVbLs7HmZo2c9eyl6y6sPxr3e3jw29H1PcUwGMmF91ClpsKNTKLjXojF0kqwjoCJWJkyjMKpZIDGhpB0MpbBCnAAgMaZADdXTGB1FTLACboIg7QE3RGhcR91yEANaC+VcR9ANGJ4sB0/MxII59ZC8WnFGivvSWQMZmsq3u2vOetntpfLT7vIdIUx4O32bfm+UWuaxGWLhN5sSWz3jNRY3Gl5ny34d0DmamQW1Vss0U0wdrt49SOayn8lazNJTuyTUcO1EvoJU15smIb52tpJ6KVAEAAADgmMJ0HMIKiEHEswcQTEQLHisCgQBB8nWnEscUIcRrmXy85Tlk0Oq4bnDcWmSqF2plGaUQyyycpp2XY7uM17hlK5auYpPbCZI5fXcKrL6yTXDdV6LD0ZVB9ijmcm59+8gTT4nckfVpJSTkIpfsO0eOPpgnac2NjcaG53SZ9GbeDc2a03Z0o5GjzeZskxFG86NEtfIdqjlDZE9ybt5LLAITiW2gAQYAAHAgJ7PgMcLlCzYJGARwEAEYZgkvsEGo0MISjeRyJ9TfkeqPHSw9g9JrBMooIVEDJ2DkGw16kR1g5WaI072htZ0SRNX68wnwJbQ0kbo+JLwXqaey/92P1MGCqDFvfqtOW8Mm0Wf+uG6jyEM/2kuoIsEJN/JoCsZVCOF4wcxCgKYqhEY2IiJX/+7JkmIQFOF7N25hacHgLGexlA5pTLXk3LaR3Acee53GUjmgYjCzawESAgwETgBpOVA1ahMHhcKMSCXHhpLlxIDimDkvnAywjUH+YLRSuDMsVxE82oX6hogNzl40ZimZz+Ufe0TcKmH9NXI2gON2MAzu2hQXOKZ64o4aVQUioDLMKXAKugELJwCD4cUpYchtQjbHbhoeDE+1+kTbO25TrcYSNMhFmrfhXdHJACqABCb0GDajMCWCLKAaEMPMIJJ49jxolUakqdN9pzYXbf+ioGnsofV0oblskzCASxPajdnVDmfJq5PJV4r/5FLKqKU4XqxGYuVulGu3lyfrf6ZWfeXvbPL6VX5iaLsaxJ5c4SWNaa+PBJVIVJixsnURVCWQj4lY2EEMKQDKFkYVBCADwaKBZiB+ECqIrvmHEABKkA40EGAiBpYfQppM6XXE2KcR0ft/2JqtYwyG/RNKnbHKq/p/Ll6IYViSod2pyxU5PV8eF5Yq1Z2yndXTq61JLyZqRqGMVpKh3XVquz2nr+NdYwO2f03/PEdsTxwWr13zHDupklf8195aW86n+/eXv/13+JRny75IJVJT6iKS4MTkrtWAgxQACYGyWpFgC6AxWBdqY7ho1xwdg/aCZJkHBOYPpJvafKz08PrUpfn2e6GZQyUFOY3ix7kpkFvBmyhqckcAAyNz9YqV9mMORmKBlKCP+3OlM/9Dhw9DGbvrmj4Y4OYBWfOrZ3LGj619IoAnCweZ2AxgkiGew0Pe0wcPSyIIDxhlCF62TiIMakGGMwYUFS4VGjaJFlnAKLpwvMyV8CqAVtcRE9QhVRPuFPsou4t4lD3X/+7JkqoQFG1rMk2w2MGpIej9hg10UMXcurmlpgaifJuW2FeBbx15yTBi+3forGC8LsL5PFtaM3XEP3h7uSoG7qFh8jpEmQYuutEisgkub9JH+2p/VVC7rtibNqTllZH2eYvs+Z3y2+aq+5mD9RTS918nXZ1ebNGIcXb9UM80BAAAQgyAJgyYDDhsWBmOFlERxQREJS+zHKMusxJyRoFehVcskMZBAeFB8lmt6rQ4LLz0/PMEe859RYLFgR5rlndq/zpqhMw2ynXZ/6ej1U+iP1zPqJLD6wpZW8QE65IWzx0FgVW8SE4R6FQBAwCAI0kCYdHJjDw8cBwjRgVHNXaacaqtHVaQAvGqNudGajyHgNig+fJY+tDE5A1F5iaulQbTA6SmGg+1K5+NxNX0Vm82iyaN3JmJp+5aIWO1Vj0ZcJm3T6LKlWf5vdf70Y/j3M5LCnlO2bCxCmnRxfvrfn/VaymTXETSF7NMuNYj6bBKvcQ5xOmpuP3r9ggAacacPURVUIBRkDQGpiMagPXWZsmTA2dPGpq2VaLpMZSxRWA0QZeZloLDSfFGRBDVapSlzRG44oyIpcfuYNbjWq5fMdKy8lrn43REHKiFCVVWSScxp57Dibahlune6P2s47vNo80O3z1wcYdmS3+q5pe3v2bHN4ibh6seeWrg9OeMPsh2XKoMFb21gCIEAApDMyiYOBoNhoHajBj5EamcGZC5tAgGWwWEzGhoECQsGGJgJj4uYWDA4hMTBTCgZFwaCAUFTRhinCIRiFSp0lrmMCACPoOYUpLRkgi7ZfxYR27atEXpFtorx5pduFMDnk/ZO+7DbCDwYxQf/+7JExQAEeVpP7WVgCoxLedetLAAhLZU3ubwABHVD6Dc3kAGlR7lMUWW+VDNOlEhEFLjtZa4OfPTpEcAIbaMzFrCTWpukj08/96nEiAvAFKt8vXAEUkGVrGY1VkVPLvysUF/sRtyhwIEX5A8OMEfFk8ggfU7zGvYqdwlsASuimKt+W4W6iOa8GaJqQHL68Nxd5nklcRn9zuNBbt4a/+f3f36XcTsc5/8/4fm4fygeAIEZpE5+H6lgb////6TgDAAAAEQADYiDAgDIgCYAQuSEgC3i3I4xHHYSAsoFHbIgA4g6MNA0Oyarjr9MbKTJQNK10nkZQdDhiCw3DsogRtIqdKIWNHk38jU7OSJ3pa661DZLQDGoVSz9qN2mXyjj2XzEsNoU7VSqGvfeET/dyknN2NXSyYgHBS6xyZ0iLi9nDn2NRd+5jk5vA3mAGEGSGSGVhIyJcWLncdZXr/dZ9zqcsY24jB7iAQBapdtLkvG3C9X+zdu2+Y6wz1yxr/xzz0RDFoHjVoi8Yct11SDRZdTuPf+9rfe///9S5Vp69FXs/Y5/OexR5Wnv5BkZn0h23l7aROLxN3/////////////////////////////////////+fdyc/VJyksYW5AEUyoUQSiABQRC3l0Gma7Jrrhdc2ZAQoJPmniu4KKlkUlrSlqHFAMiCEMF6EgAYiEhklGwNAMkkRezJQh8SoSxkKskJjRzLPVgNpCBXiSi2NSruUqRM5V5imK/yezK0srEnjLRza1EaZkkzH+4TmeXEdsxrqqdUwqq9meMLCuGyG5K27LXbO26jzMDEzyOdWyuWtXKaFFn/+7JkS4AG2l/WZmXgAMEMKx3NPABS3ZVbnZWACi4x6/OwsAFhPY2Xzk/zp/7sLHGfsTYr1S5wp4W21+xpaqwrX8VwcoOZHrhnFmNhxuTUXW4a5jXo2sj2DNLFpbtcUPgkFEmM8tNH+lJT8uRhKQoFAlElFJtwVEgUOQiUqBkSFADN1mHvKFD8Lrw5LJFuN42Z3G+GaAvDAJeuIhJA0T2MlUsRCQ9DmLqPSplGfrE1ywWFdKVWYmewcvFLaCeakq+c7ucdsfaYVUvSUYMxHGlGxkVs8OjBAXWLYiw5KWh+9sxokWWNDxNEV0se0fEKE+xPvG9bxuI5RWvU8kBacmvdsZ1bcCtawaNcPVsyRN0kamzeIeod6RLUze0Gtq11mD95xav9Ym2nnZbwMFjJAAAEBIgaGkqhyQFRhoC9EYovIVK0tXbX/KnwayTTUjDcakJI7QIB9OvNktEsSXUYkrVUVbh3kyElSq+SaQlUxO3Z23MVNWSjHJq1z10E2QO+L4etsVXP25WdM3psmxrvSbXpLbHVGubXWZK3LzQ7qrvhhp3mE3tecqe7fJy/0Kg6z3JxTETa4Yxm03OVP8ffKEvR0Mq5NFQAHEAWGwSUJd1OlijM32iLuJVQVDij7sU1MajwBKWkkdSTyp1xTywvammkeyaUMYgP551uYv6ETCC1UQbGQ43P3l59/b2ts6ae5F3KfaCCL9E0n3dSyOEn1x/ClMj421Ew+4fUXUm9+qfq7id9v9hpzLWb4Y/hpxiajX91+o/ScytlfKEhm9rz7e2RdoBaLcNSkOCk2ii2heMeM7C1V4rEm3GXD10qrxdfQuEKEDD/+7JEE4AUHV9ZYwkcUpFL2vw9hnJRBWNdh5hzyiGs6/GEmZm/08yjLDa82tQfZuCa6xkvF8mZoF5TTUVNprR+hI5qTFtFJqESlYRIbER4JZnkjx80eU0pJnRVtTrtmVvcvPRHHWB6YMRRaMDR+WkrG7nRANnbc071hBKB75JmNLUzP2MlEACAJyLIy0CbKYGMBADePELovwDwW8lgv5TYkUmIgFtfKQIJFFjHMTBaTmSDZMgIx0E/KzSZ5o447Ro9i0Mg9rKXS8maRlEs6UterWcxizt5tU+7RiU5hI1SzQ6fQR2ZJVDRdGjnxKXdtVjIv7iZiN3XZOI514+PG491iIxaMJayLdb6SnaMJqiLfTPJFtcmSdAAECVVBgIASozBchziBH+RlkIVtYPlwVe6w0korXZwffQiCJ5gOlsFqQg9AyL5Rakw8liUeVYI6C6Gg0lSly0Y7hU31GLh8oeQNN0hm4gx65MaFRU+5KJTJJggVl9qKejBRQwJxRJfPY82UR7RchLyFDWxi0IIZgCNbpSLbV1xcv++29Z380ViACwTDKgUeUkX7hhOZa0+oonY09nS6RoDg7VEIDEWwOm9Ss4Fh1FJu9eLTPNE0RgjBx4hJjTXcsh0lHAZpAzA3RnPyXx1TVKjoJEXUuKZdlxqcZe7mYzfborClmn1F6z8tVVcbs/z61tr7Hp6aLyoxy7+O3LWSlYujwv+ryo4sysnwHS10m0tsMgAGWSdVkTCQgj30SjYclrjvqAMReV+F/P9DxZKgSqyyqPETwzEDA9bpA37NAupwzG3RlETyqM3zKiiuxIK7hsWsvZLUlD1iWmtCOr/+7JEKAAEYGZXYwwzkI7LOu9hJnxQaWdh7DBtihUu63GDDjlvfzocT7UqLjTc+vDqksjqPJHHJa1zX13zu9ZHUcz/lb+zpfv/3Nx2d2FBfSFYb516lJ/DIurW34+fdRZ3aGRUQxhCAADPJ13J0jwUIR0y7CWKgriv4tZSENQS3l91rLgoiVME5sjZ+EiMkrEYhSrdVttuc5J/FpI4D6IhfFlRMutk1I5V1azkds1WyIgi5c1tlZNmILsDNiEIZPl5md92aOfLw09LXjL8y7vL5e4pVIeHn68a2fe+z/PfCJCCWD+tUSCQ06wHFP3ONd3llhnRI2QQExQ76qyFnlyrhTFdphrE/bkrGuBuJQL4HjghiglOJanqRE0wbK1sT8Cxg4tbDmzSRbLL3H6w6PQamP3OhI6ssUgctyF2hlAQrgtK4V3ISJSijxUXu1s/LP/tpI8OZG3lSPgWoKKiUc5DA6djH86ecd5oJNONpVIB16/qeudlpaqAEl7SDhBIiGSkF0KwKhfqH07W56eKeglrVmCoahwHDlDIDFgjkqSvMJim7gBlHkMNVRGNSk0nD5468CinRKqp2suBUIEmJFOIK5acxOqTfFMQwikmwoI2WhfmaJoFBBvMd2N2qkvoeTDtWKY5ErIX04fMY0MDIu1SUTu9R3WOfpV2SDdWQDhJABcEXGpvsChlClWIWoAlr3pahmmLSwa8kId7OYiEapssr8Qq26DgEJEhxIkkYoBMtFPYTCLWUUQNvEA4Ze6HhCZcSppOMJUZQvLSa36zefum/DPmhEhtNg8NTIjLvFWNNtyvtn+t31bGw01uvLlbmMRk60D/+7JEPYAED1nX+wM1cHxJqv9gw4pQKWNZh5hVwgEsq/TzDikiZK8y5K8aqrKvDMZlFAAuJVOan8u1KpK1GIIWpe3NPpUqGr9pvNDhUuiz0wqsSuScKUcX9u509jMdoelEXyoVtaiZLDnxNFq/NyqVc1SxDc1jPVWuti/DaZTBe5an2xc4znQtNhaa8ytFOCfU1cXh2LUXDbMzxXE+hilHXq2LFePtfbyc+bRgAFwj6XBdgWiSEJLGA/hHiyaQcoljHSB4vaNkW6IfPICtYp7wIZxYkhcd3mbX4SLY3F0TPtZfeNw+9s/plVtolIH6uTSwzF5+ot3KlHKyO0vPeqs39F29s1468qDqk5isGqzHPx7NNoRnwSO9yypXI9kkEQAk8RLLtav1tXrZNvY4kgUnQFE8T0D0MQUtdFmE02oQNA2zbL+MY3zju5wzuDiyYKKfDjSJKCj7eXhnT7wayVOxIC0evHJL0y72R/rrmrtNwF1P2vAdyEMOeb2IuLJaJlV91QGx6eYEQNwhXIOsChWkiZbLS+G6lqZ0qoM6AAg/QvK0hAt313/o4s0bq0jqgjguiz2ihgS1q0m2Y2wBV+CyFhXQZE4HwRPvFjg+20gURKtkTc0TF/Ivjy7eYSbNJaEYcjSWw6opN+Vg71KJCs7UFic2aEyAidXcg4kUuOAiKDEiw/NMjjzI6zP18HYcQ+DHKXacqvSvC6R1qR0yYV0GovQ2rgSz7Po3qn5HrJq4m0CAAogQsOsCByVTGWl9RYzjMFUyRYiUsXDSSQzWkIqG3suCcRLLz4/XNtLZtj18iVoves/sOVhpypZsKDSNYx8I1NH/+7JEZQAEFFlV4wkbcoIrqs1hg25P7UVXjCRvyfarqrGEjfiOsKUjjYpu1rRzVBOeqUEx09VhU/yP49pUjmt1bauUpecObEDNuK8N6p1otZeg1hEr64zyyWHc41ZUrKe440dABtOtpijotNAPLk9hCEaDKMGVK3OXFHenG0NIyALJorIoKxQmyhOTDrS05xrX7tSxtubC0vVmaTZhI5tUrH9nNzf709YT6r5ZGKGnQ0EwihmyCKVejrSakOgPNUSR3PVaUKEGcX5mhH8kCoFzLa1cOqqhETd3gv/r3/tuLyNkMABZVG/bK0cke2twtfMBKhd9VFMZe7deVluh1AIhgjZ5EpClBcjoq7rwXmhh3/YufUYHPkoM3FrHJ5DltpKW6rD1qxsaK0VbJg0CkXhkoN4Wpy51AQlT6RRhrsaLU/PvZqJg5xXhd5caKhc39wykiJIFQw4IoQa+Al10RjZpUhjQJBcJyBxEpS5yJTiK/SoV4/8bUPTBgZ4iAFQFzBkrDoRqXW/8aN0PlrK26qYl9+WclGKBQyEJlYqdISRRzRwT+JDAx3ChFZZWoiG+KRdZIVMqX1s7lmhpnCQc5+kjlwiZJUwow5BQfeN6StswFCNfjytgEYp0v86m/VU1Euq0yFAAYwKbZfKrlL1FWjP2rh13qZ6+EqgukiDxya1DcVi1nGkH7BYSFJeUssgPi1zu5y0deXi0bV2V18mdzSSduyVKRlAl0V1CIx5Ntdt4l6DJYZOZs6uc6CtqrvCcKZcyJi7XqeqGwYXWN7ci6JKA7QOtaQhlGeg3/N/l9vl5ckvjUaJBLplYhrSqRQti0gW0tuj/+7JEi4AED0vWewwbUoBqGpxgw55PvXlbrBhzAgas6nGGGZHrtZZdAEQZu16JWY/Z1CrOcqSm6cBBBnSIYkZD450MCx26Xl1l7nOxpxOEYKcNCYFYm3D0tI7LYRvkdIiIwXrSqcLckvlnlte1aUi+YpgeFjVnlMrV3BCUIPQyiKGEfQ5gyBmCYVYfc7TDcymyJQQIenDTY01QoEvYhuwhYGFxR6FvVKp5IvZIQdvm7/I+WUnJIHKdJ/pgzD76JaOpeQbWlb5UCHN865UIO+b0tEbJ1lNCNSxr0ct4RS9wnetnbTd8nfEP02X7yW1rbW19Yt69t47VpTSztXeMj//ZpuzhbqZyBKkKxW+fB//tHSFARBf3EcoCihWK/HlHAK+l7xq3Mxi1p66Uf5HkJRcjhIgGw93iCvITtt0ZtDcTKbi5AWekUEqn0Rx6RAAGGEAdHNIjTDFIyFq4Mu5GCDs1C434lSbq6xDrkrqicH8xofdOkB3bcaxwUGIcHI+VGJb0IqW8a92qpHFjTeNxQ1TCnSmSz35V+CLxcxvgnD0ua5CW2FDs8mqGfIok/9UcgJKLRuhDCuEHpGyV+zd6wFisdx0EVZHC3nHHxYNB017FSHk00uiFGLC1Xc1UWlrrMtaXMVwWvCOHXBR16xMTR/1H7zqrxsPuDawmaJGQyLBJAERlWrUhtJ5MpgqgMvxWkpdWOtAEjtdronET3LTMTAJjr+TyZeKEbjLkMNwM1DpU4OdLOnjOT1hhKRQRmGH9zIbaLNwDMDb3wN6G7nyOxJidksd/Am84BbyNVuiALfprdnU/LBPl23YFjXpcaa+uUtHPpPP/+7JksgIEn1vSowxLIGunCr5hiFgRXXNPjDzMybgsqvDzDeDp5XbGnu+axabtnvw2/crtyt9KffnbAIjXSGr32psg/tbhnpXU37pNJc27lYsB8BvHMKsFU4jIO8TdWxyyJwp1elz/LksoiYT/0UbqluYXU1jYSNQiyyzFtkFQq2xQ/EmIVRLvBZcMGV8ERzIoshR6qhGKEfApJwnPImuTftP9e/P1QzhEtcG32SzEcOFuWZYYfiah6q519XE0ArioUgrpQAMgLDSOZUv+MqgUVgtSxp47DIGZ68LxNspIT48GV49h9jN2WoWMhUxYU2IMcoXUWqDizMFRUDBxKtDONKKU0tZUflJzMYRi6aiS/aggag4ssEw4voREHqkgfV9JtiozFONVg0L1h2feKJDAXUF3pMFUEkqxKdRJQZWrsZmUKIBKZqizmyEBbqpenKWpQzbK7yi62YEYk+tM44ZVCoyctEJRALFrTKsn1jpN93LzFcyTEWkps5qcZXijK25kcSmTIt48HNSwRpwjRSQxIwEGHOF7gpFbpKtKF0yV/WsHPJ054qq6Lw4WMAcGEvVQk2jGwY8LDL7yKut/Y1/6q2EoU2QBWYoyg2DiloFRP2hPTqkSkE31gIhSNpE2lvlSxKQkZIhFRsRlQUA9tuKYnYgsQEdxVLpuFCuLU055WkSsBWIVWSdkRzJ8Q1HHNiyCCU0xqoabbXWSVRY2VM2j5lphF8LIYUHwmjnZnHwhiJFlzqFSXUHunmMcu3RZvXlH/zp2++2TLX5Z93OlJ0OvFIZuYUfTajlAgAAAIkgo4XPfUSImO7DHXRUmp5vBGCQsSg//+7JE3QAEGV1UYwwbYISK+o9hI3xSqWtHbCTRwk2taPGGGfmSuORDkqj2UL+8E3pjqFP0wtE/46K+xa7A9reVlmkTJyXGG0qn1y9lXAeuw1jfRF5G1sFjQY5FAsmTxISgPNNiQrkNLgwjHNVt8sdVOVfPMPPs1+2ovRdPH3P61uCRuv/r5m+taNyPXPemv3Wp5SFABDrDcr8G6sCzGUQAABGJkhg+KmWCGRBA4800suylf6atGXvTRg51a6kHNnFYWvuLe3LQHFG6leZ0oiaH6HXJ2haT/TC47gmqzbzzrKbj1B3qXYXrQFyNk6Q52g1++ycH92LidNvQ2sYUVyYy2p+A+W/vNqurHHN2ETYyVPIdPGwRrYl2Zp+KX2MTz4fPeb73iPfH/b7RsJVKddmlTVObymeYeyLp7HciZAAAElcT1eRC1m79lyx4o6FdLhqYMShKcDqzUKn6Jw4/D9uYtoipM2a74R5vxWefnNa1LxhQfjMozBW3Du0efg0J189XjEduTZfIui82jWkxVkUryaKCE43HPsP0MfLtbnOkikR5UQfIZn5aSytYXPbKeWt7l+OKrSWOzbY/2uQgGZAgEAAMIZWJACJppo0NQVAWRGaUhG0k1NQSqmp+NBZJMPE/xmfyHCGWmU6UlVX3uxCcBuomN1bfaHt5QitNnDcru1M1v1XvrMMonu6KsVcCRmOK642XXbn1q/fjKS9Dxwb2DgaJkU4SGc0TUGLsKl+Nt+B4y4LuYs0zlluDnvvPuRrXLil/U1vA2CBVqENouxxiRDF1M9+UN7dvNW3QovHUAHUBCQSiPy9rzzBiUtLCAhhhfmX/+7Jk7AAk8GDRY0w08IMq6jxhI54T4ZtDjDERyforaPGDDnEww1Cegdl06y9yZPMT1JKZelagYpOEDfZGJumNudgyzenMEV0XTetfyNtr2UKqVz2Efyt2KPMMzNdnUGwoTMM1MMGqQSlyb+S1SakTKhH1UzJ+JUylr8+nngov0oaUj1cE2Ov23u/dgHIAAACAKBsifwaMNij3NoKoJXrXch3WmwqhddnjktNlT8VXVkW4uzV3JXYh4huVLAkuxF4SFuGJLCtUyIIGCPfyraxaPCV0JOFR54ksD7Qvph32BseGbtxR3hKJOgqWVserlBW0xUTBqNdew9F9buwIoqNliKdohTwYGR0DQxpS1KyVX7k+IPXzCtfJgh+x3eqzMic/K7Pp/9X3pN/MJ57Pxo3Pypt30gTEgQABa8zVRp3CZKkk9oyMjVa3dIddzCmTMHn4y0SEIXJmKNssNFYHX4RlgwukooIvTRhlYLORNiCZEAEwRPWGPo6ZsLQTEWSLVusiitI9NU+iJK1jZIKHGFPs6xaKV0aE6YUGlTqNrWfdw42niSlnUc6qCrAacJTU889zk2skv/afv92okgBIiLAjoCQwXpZA2yHcDWPINAREKBs2dtyWyNiuQZKpQcDx6LuNdXVPRhhxYSMScBiURpu4TgebI54dOCklSRrzZb35gzSoo02TnOcqxFfuTyNDoTVmwyOKc0wMZvxWqSA+56N73Dc22j0dMnqRDztTkTo7qxPupSy10CJNctJ1h5/whU/wmU8mWukuarNdX+k8LgQT9IVn0hjmsnN+GL9S2WQ7WbOf+//HyiPzF/NQIsggmI8qdqr/+7Jk9AMFRWTPyww1YoWIqgthJnpVvZU9DL0xwfYt6TWEijhFFAuumvtKWrALSFaUvU+kH1JYuzPWuzYFBlQkThlrkaVJxRsS3K+pmIwtowkDZlHJqSnhNeb8YqtqOt1LIyXtVKCp50mmoS2PWjZ7sZ3p2ky3UmtzVGuUquapTkLspjJJ9u3ZLNdRSmMm7CbDL0KIVJUDOQAAAIGDT71FlglOAloDgYULZUJCwEFAhgFg0+7iTMhvpn0TQatZrsYaBZ7Hyr0nbyhtd6BZcuo0X0EPHUvGMUw6UjevD7WNRGvuPJusmiouI/00HHB4H0tK1q9a7JkbDtK5h1bijVvPFtb3JliDLqRd/MKu0FD6sIBuOxfhw8I4KGVJI+oO/oY/ESsWNbzUq2JpjjfGOMZZOusXK6LQfNrlkpiMSuSCJIALiyEYngDBpdMZb4wwSOoK0GDLkeS+8DMuUvbkLHyI3FiR31EsIpqktK/1Uth3wbIb6HUJAyBMxB3EMaRVWjKcDKQXrdqZs/Eix9DZXZqkfc2+rDvUB0ssrheov07QLCrY6KJQ1WmR5mkalWVy19zmFCpwqJHWqoUgAKCAQ4UjTcTUE8LQlpedQWDlnp6JHteooPdhTImnbg8DmjwngYRHBkRmZq06asl8abeVmh4YOko6zgyKFYHkczXVfU2w2lqqR09ZkZkseGVpnBczq70EbYRg3ljMzWqMwiuPy6wwXaSkenUYs5Z1aVLD/o5NHO2l3ZbbcMILlaNOHSR1ql5mtdT+cmE7le3imrt3nhBiYWFvcUdeorEAAuMxdG8SksLA9kkMqjP1GtSlUkPyy3J41bj/+7Jk7oIFJGDPSyxFYH6rmj1hI3oTmXM+jDEvAjOu5+GGGjjLcTlqp8KjqXVq343l96uNOTBGgxwwf+3w8bXcuXUY1O50BAMFrrcwRtHVNtZ183csmOJufZFFRhjroWf9Vj4zlay9dZ568MTqeg7H6tij6fIpBW7kPDQe+fWLtzFX/mtmX8gyJWYCEIuPdl6LP6ZNuaEQICAAMdkhpw6RreZV6gL1lQNHqFpBQ+rAn1QSmcSudSk4UN5gpMVrDRKY5Vhx0rTZVOG0XQl9dlpZ/IDovfJzDDrp4YPpNvVhDjexsUlvioYf6GiJb+yvTdQ8+krFjFS6meirSDpsU4c1Kp6lhDe0uqJmAt1VzQn9jhgq7pjf0rvU7WTW1qP2SPEtu76InXgyO0iIHbul0JKV549vJwW33IXqfsEFIvC9tUsiiaEZAiADGSwmVKAlZwUMDXMiaiosykrtxUwjzeQmU2x4ksDQ4PybNXQdymaVSXTLL3R8Z3ZF33vSl+4hiK3CurycMU6rWZVK47hk7mZlJxtv3X0iduUN0dG6V4GVVLdXcih9wYT051+HYtajAdEeJLTUVHVKhgVhBg43Uu7lBoQFuy7v+MIAEiRGAAGtwCc9aAIrKxzRIEDLm1iN3Qza3AkjclkW5SwV9SUftHIbi9o7QnRZaMG/Fn3JIecmqVzwW3UbDe1BEkmyTIWiOvVTTYpYDn3MFQ9XJEjUyFIdYGzCe9oqK+w0Vykbc7g4pWIjDEiCJvMn5SH+aphudSYNyktN82tTxJJuOsTpZEIk/cNqmRTKB0Vedsr5stzpIpLQtLmsErMrBGyQQGSuZZLXNU7/+7Bk74IFYWNQ4xlg0IbLuk5rCAxTiXtDzDEwQdYuaf2DCmhesugBRO5TXHhWHaSy6IvrFaLB+p2Z5p+3rt5RnEEfuIHZycQZaK0EouJanyKS+QJD7mvv9d9AxRvMjOuYmaQS4Nivy3d9lRKa0Q7IZOY3NRLSrrTd33bOTKEAmQGASTYI0ozuM1pIIuEACCq1RlacABQoTBBLMCKdQiJIQwqWjG3af1LwipAOrCk9DCAoSGDkAcaZknmyrY1a6skmBxfVUzBpAvJ6EoMf1WG58yXzU9eDoMDOuDzV3WMMaMEtWp6wXLoS+V1DqUsn63mQbBFZ5SzMBzHSWhyK9KFW06yHCuSskXRoRZobUZY3bL5tJFRppUFK/xxsctgbrAUiGv8aUl0UNXbSXR0/Fpq07nQWowpaOreLtl+TIUM7GZksKAmHWHCOs3GA5GpwY4goC466lDC/seRSb7KdivItmfcsGCvjBrfGW16fOO8anSA+eou3P/UqusqNVSZIb6sG15+luky2m+bE8GTWd0vfKzObP8bbCs/bDhDwvLj04mW0FPiu2FPCOWe+VHK88OG7gTk3PBpuNUIUUQDAFOY5E0MZMIRB9vzGHiS31IvggOJh5U0x/U+nLehpMQL/Ncvp+puQ7UqzWXasW3KRyfv9JwkJzOoKdbHKEqDlvhIHUPKJqM4TMags+872I55TipYbvjB+dUj1seqtxjyMmnzBJvhc7DqMydczr6XEpukoBOKpE1qqVx3ly+8mExq1ZNwkg8aJ9rckxBEhIcSaafJMltlWSNDFeM8mXU3xgrltj6d+z9RILESQwgAAAgxFgGSCmf/7smT0AwWNXs8jGGBifAuqPmUjjlWJeTqMvTHJvSyouPMOAXzVBPi3nGqMKQCaQWTqTpfRtJcxAZISopYR99+EGO6QqSmoaMzLvACnSeDWmQIUCc5JaPvCJkOmz5oEU+LnYZya5yKGheQj6Rw57v/S82PpTh0rEPaH5/SuikmsFQ9+aczVEAAIwZJoDClCjFnzkgwwOQjCqzLiMTbOGFAUfdRtk9TBhisDEC0SKya85pmCHF5o+7jhldDcVQabDdDS/peRDk6ilyzr5iSJBmRAtbxsJ6FawxxbyvQ1Sn6yvZpj9MxCFyhzaSbpeOQWZXhyq1RNppDgZZUmxHO6eJZsf5P9Mx6mWLMcd29kUKqop3qc1FUcP5Hiejn6rULTKyJ2uKw1vEWbDqC5rTCEkr/+h+h1WxKYrOiSf0os9+UMrLIQpaPdSF0xerrn/ChAgtgLndn499ZQptrB0AEy9UVcEeq6q1GlgQbOpbHUk0zHVUVG4QPGbJFHF3rsk+eRPXURGByt320Tfwpu5Nt97d5gbI1ArnA4wCYJoDVVkOIUhFwn1MKEaMrFGqe9IvMjSbAcEwo8jsr2rcpB5t0v//419n//RaUYTqeUgo/716AgCw+FlgHoZ0j7l7kIl9KRRiXiOoYQ+7dGGp4pZTLNs7EmkjRL1aO2G5SW1afiHpZUs24xqefx/p+w9Lk8yb5k0iw8Ry3Kc2Q/lQamdBOKiC3UxFz1HwqIVEoJnTPENDhq2eP8xG//4DH1QdKvfpABUPAjKyLDLedEI4fxZxNNnKYW2pO/mlrNuves27+W+vW+t2Xen8Ww9vNU4JQdco7xRZsKNP/7smT2hwaHXkwrT2VydwuqDGGDbBRJaTcMMTqB7a1n/YMOYBiQiCCACYak2gSU2CZ3AruFqRLSylnosiMTLZx9NS6/yKUkCWeYi3boTrLJReLPs9ZByyFoynZKqCi5KEoZd3kMcnMAUlZ9cWKAeIZ99kaJEVU0M4liRT7ys7Eiuh/SRzzpQ81MvOnd+3nn87MqQtGNcEssVuZrVuWgEIAABRE2nRzQ/q1BjLiaQLGGGUv4uM5oJIU4a82qtgONRjYSo82ixn1iTHw0AKZgiGAqSwRTcEhMY8FOMkuK/goV8LlBnSXoOtANZyBQzqZzChOnIjI1CiUERjQSgkVilPZXKc0049upzOIK4rkykzPchKwz7fnAz7cn6nhVSyjeyoTMo7Sneh7D4J4Tu4ESF2BkWFfD4hUggRyM8Hp12xhfFBH1ePmXx7d4lFo3eNqYmLKe2WGaomT9tPIJg9jAQ/9v+4AsQgIACCNHGpRCQDIFKA7IkxDwOkM060AXEvKss1TwWIJyC2FPdupLDbdTMonIZ5qoeO1BtA2rEluDSTLrJGnosWjvmVZqKjEYpEBhAeTawxhQ/OsDDI3vTo4KoVPCoTmbtSl5BTgkxyDA1DBhWUWtF5Sw4rpQxQAAgQULDpHD+RpKAYMDECoICpbklAtpgCNr2Ns3IHDqiglliabu0dOpQqs9MRceXk4syQVLKJOei/xxHwOB+ZolP4S+TEG6hew4lLonntUyI5eFyCX26j6DVQ20fBJXRgIzWEg5Qq3PHbNpXnaIZKN7oaZ7anrz1/QqW9e1saNaBUJzKFhbrBwX9DHm3c6Z71S+E6mq9c6/e//7smTrAiYqWcujL0zwdgipyz0jfhVFizUssRWBepEn8YSZCIHkQ40R1uFU3i2jZ7x8MWgqggAAHEZZfHG4gIjxruh5XEPtETAGCw4qpqxIOljEBj1k46Zl7g9UoWqsqt+5blJ3ldNntyqBo0aBsYJRQBsCY5rSrwEcETnk3FamMNrSvS+hhElNaq4B0HnlNK2qFAALhFZYVHN9wdIGo030AR3AiRCZKK5UHbg19WyCUV3YiSEKpEs48/jSEdSI9iG20Z3GZDFq17BpNPHLrvvPTRaH2vyWHpXJF01bENXlixmNupNSqrLLM5jLKORw9I3zZjJqVw4EWLPQQ0eMNBrQTGoOxydSL7qUM/V3RQ52/Kd3961OU25h95yimoxawuQ9DNXt+hjPd4V8PiUCWfraub33HX4Y0vcK1T+7y5Z3rHuctltjmHy7dLS1r9WWYa729rVTPeGX5W0C5hkXtFAAABAZ8iCWmVQDDDEoFICMUPATwTpSrYG5aV7dHpHAywKQCicAtUZdncIqFkynW4t+DcNNgaIz1XmlY72mK587VIyvTeLywwFQu0S/XJ9I2eVwjpyAnGad3lnHuhLPmYnMqYUqqy3tqrl8NCGfrpviRqTK2PpxV8s2Z40Ht0N5aRki3fuadveM/ZcVdXx2pA3+42sVg21JB1WWLus+L/N6w733B1XH8W7XqtsuH9cuFtN1JkBboyyH60BQGBWCAgAAgEAiGlYxCMgUqGuA2mHOpqDpoEmOQuOmciJnQwcO5GFApegKAhjgoquayamFFRaBNMEThRQFFBn8aZQs8suJKhQR+kzC6CgCsDOWlhcEvaIRUf/7skTwgAZmYUutZwAEukvJhqy8AGMlmTu5vIAEY7MnvzegAGwYCSPlyjZR5Xg9XdGXqSdFAAIYssmZSABqJQgsiCGvv5HnkpTAAMAhNOgVxClh0JygDeqXL4n2JOTXtU92ka3LFLGnLkR8ibkvoxBs2TcJdLNRTOz76xtpjRn9ZLcgdtlO3Si8ouw9Vhnk3KcpJHZuYvW5FLdxpQZ4VSPxPyaQyOhf2B5XGZdUpJqR2btPYlMuiroUGD7yy7b197unIlL9UtFahudp43Lc+370CWodtzbtxiYq56vU+N/////0IAGAGAUAEAIAMhANCANK5CwqYawmGpYqvGSbp0gMIhMwkHOUWjJwY44iNyWCIUYeYcDGNCBhyoaMvEBAWCnFLqvOunCR7C2gPOpgYAIkwKASgCNEW6QEnbQ0BfMBA3+Igih5QHIA8doHQYur4u4XwhMsSMXC/6toGDQ7Godvvs4GbFItAEtmpAVAIqMWS/DIoBc6G3Rf6tMxmKPDMzjUH0hGDsy9pq1WZKA34alUCQZXnZZVcSUYWK24bi9dgMucGXVYCoIq16EVMZRSXrlBLsNtLd+fs5178ipZu691d6HdlEOQmKWnxlEQuz7sXcIJllm/Ws8wxa1G84XKqkugRyMpZDl6rt/pTJpPVa/WlducsY9r5f///+sAIZCAa45wY8BsQMcDhTVjCgYNAZOsRi4KtAwBfdMNXDdHKFjTMN4P0PKidLKsPuIusLcaExqWHChRFh7G1JtvgNcTFrR7PWtljzXpFttFwerVU8hzxsV3ReszX8ms6rfW/4+M4+odKb1Ex66rqu75mnpH1n13u//7skQ7gEVcYFTXZeAAsuwKh+y8AFG5Z07MpRFKfS9oxbYa0M9Pf3vrOdffvSn186k176zrMufmBFj1gapDkzq8RgcGRaaly5VvBhxtvGpYtAgZicI5oOGhAEANJzJzBaRH04BjxrSjMI0v6UGpnCzZQGYI6EsZDQ9b0WZK52FYSwuRiNJdB5MK07K80FlPonsyTmNWGcqGvHyxtveP4tGZixCewtaxExp+yxbXfXivcxa5hTueGyBnz2v627/Nd1rTwcbtrH+/jGcxdefVIeYc9IMT03eFNSHq/1Hi3iTavCgTaiZlr4kfeF2/Y5YeKTvaUhxY6GNDFLBPusJsgvpL3WPXEWsBhe3Ql2IACubMMo6Ogz1EJHoyjgcCjIYIyAJa5ecuKXCIgiIKCkAU4yJPtZzCYMKg2RgSLAQCLhDMhWB9RyibBznpsdr9WuMhEl7S02GwyajS9042ruaYYIARyQNgo23sqx4rEbs8kW9NFz8svSytFRE+s3I5lbh62aFK7iafuHeXJNiPi0a0Rh4nm1NcF4nknP2GJktKYW5majpt56YWIGjFoKRjBxMgKgMfmHhw0SGPDLxkxeAhZhhEZkQs8Q8GFA24DNVY2EJrtab2Nl/GrSZUtpZb8iCIQ+lXlQnTdDJrKy9qra2NSTFFZw9ZBXF2oJv2FqVLoYBgxN3eBGTO/RMt+9FevWdq3+TO2TBUFX/27JtPyq85Hlpn9t7+ph3a9K+5G205OER/UfMb3745uK1KEAAAkSYCeUBOoVTzRjg9IbNOJlhASCgFXLYixhdox5jvSAWAtQn6QqIRNIQeMIGNtu5DGFrwKruCGf/7smQdBEVMYtI7eUpweYsqh2UlmFUpeT4NpNiCKKyoibwhOGuDgqk3RnFFSRpWuPfeoa8uNGmfFG1NUIEGXs7gC2uoqJ18VSTZ6Ss2kiN7qWgzcw/mpsf+i57LxPLmhz0iXzbfdNIK9QvIZueLW/cvprMsfb35Xyqv3Ej/1i5e/FYZDRlwhOHX+MUuq2xXh9rWWKEAAU2koYpB+JHucCE1YyyYVJDg3+bkJVpoCABVEu83KJL4e1paLbz0L1K9glEcGh1sw23YiQDOO1BlWgT+Q/hfKrz1+a6DXlDWnkWVURTmvrDxkMcpeqvNzUNyo1VmkI3Lkd6/dprURdBTe1EEKOmICDliguhNckUyO6SjxgIzBnE3I/2jNsNRZEBgcaQzGNCos+gItMkMzX2MYBTMQ0EAhzQoNJysplogYaPLZR+ZiShw8HQJSv+ZKAID4WWra0m5LllMBQWf+AdtJZG2UAseJoRFgbTGQdTPJpTHlHkMkhtFtpduFUKjXVuTppHHY9/93sxMbhZ192l+z7aMv2je8zWfG7LPRfK/PNn/KrTsbJov9tZ5Rnv1VpYTFXN48bvlW4AZCAAyY3pmhn5kZENB44cvUYgXsTEIafVCF4/MXoGgF+teMslGBx5gFFHjJAL/WElzvu6xVpi7LsFWXjpH0l0ZgmXyytgHJIjuIdRaYlOkgfbPBv0EY6FVY6e+ZMHGlNyOdnmn1rmqriOOG+D5iIafj/u/qONf2+Unj+Vn76+a4uPb9qOKJkmtZZUABSMJV42cQDBQENag45bGjQxtCAMMi4zOTjGIoKgNMJgYwpFDBoYMihQcZBS4aqeTev/7smQZBkXUWs8TmkNwceeql2XoZhYBcT7uZM+B6ZipTaSaiTAjzClzJVVAy6DSiqWLlKGgwKmOZIMJJm/QgFRqO8WZWVAJEMbjuUN2dp/5dHXsgXDFyq2MdoIY/f17FAyDGrh04wx2PqIE47PG1aECLygNx1DFTx4tyTc8qYPhiBTZYsoD8dwfPwLcDbM5KupD05cqvjn7r8Vu5M+c7w9ttBCD4cKH1EpKIn6VAAp3a3jDBrrMME5USUGFAhQCkbiJMPgODtiUHUajCBSrkORuhnYqGKaZFupBRVGKwNij0WtxBS4T9sbWQdFnS1ahQyCrGaxXCi0tbUN1mzqp9miaR2+bj42hLvzhIdpWJW5J6iSn0QLFeTBtYIqqNm0iIpQ16OTDxtMaHA3MdzzCWMdDAeC5gYJgRcgoCA5LqhMaj4wSVjIQAMeBELio0uDStMRij0BLo1oaYTVFVFUmxJ5JFAhEFJXUukVU53VdFW4OJiEbm4GmpFBLpS+X9v6pso61CIZbwfiz2X2daRRvmAZBHnn/iTjvQOdNnJNvML39FneUdx2b+53vnkBJL517v1WN3/ps7U3e/nf5nxsb7Ww2/7L4SJ33mn51Qaf28yATLZcZEsfmYQ8TlkR0COjmTFl38GARlALAUnwEDjqmjAxwYx5+AchYjivBMNKe7DyssbaUjYHHiCQLnkS1QgXSC55v0sv3dwsq0HA8+j4b+/mvcRKWMxT7lunLWrA0KYa6DTVfPzVa3Hu1030z4vsL/g/Ldnf9vrhcVQAU3LzfHI10HMTVjr14Rt5o48LAIMGjFEAGCICBljGRQBhxCYWHhh8CQP/7smQVDMUxW1EbbEWgbmRqY2XmdlYJiUBuaQnBmRSpDaSWiEOZxoXihMOGBkLRGgvOnvXc9HhqYcJuFFWckgAwqdE4BA7nTuJ09i4Ti0xORnvLTHvm7qPQtjexOy1bUO1NH2JQFBBHkirJZA1eNK1E6SKDO95uYyuJTzXSo/saXyTN/PXXWZN89zK9RvfBsJ0LNISkHSIA9h+GJAPqrZSAU5d+Y3oKmLFQNcKySoanSMGuuosGdsqYqt8CBrxjZbgh4IQxTCq2B1I1HrkZKDNBD6dtfU0nh5cPiQBXJL94/XJlHVPy35B0jKl7NCJ5D6zOutWoJtbfOdY6wwdxvCe1r76bTTJ3rBDTN/P/v6AAKbfNgr80CHDDouNeDg6CXDSpBHgiFxQGKooCZNcLenpEnyHgokawYIyZVQixZDgUFDKCEAyz30Lqpn0qiUBhhBC2KJ2KrOxIoefcrDwb9JSRg0FYTgsmKAFGWWIx4+XB06BQePoKpEU69WIVNAQlD3FDay3O2QmokRR2IR6RJqRKDl9mxpZzxt+LXWp18xFLNXxXxvzK8TxsOf3k3EIRBNah+Ks8jz8YbKVX5oU4SAATbGFgR2C5zRxgWIOMGKMtVJBENJPgZswcRLhCABRcoNw8IgBQPR2AxNrd6ecssALUcrq1SIE2l4gvYWaZw5G0g0KK4q292ZHGX9BpJ3Vq7RAuwHa2i51EsKzf1nrt///8iydokQAUnJjpg80kwBAgSRJ1QoYWPjxUyowpbRsS1fszxHMYMjEAEdFwqCgUhhtHQOAgcPwElE/ZYDH7jhe5lBeFA3jA0Oa+bgOhcEDJ1qwScf/7smQnBMT1XFCbaUWQb4RaI28pLhOtgVDsmT0iD7DqDZGa6A0SqQsQG5AeDlnIagiDDmJoXNLziWtCTpom0sawjrrVeV/AlbQbfOizodjIelKBrN9fBkziwNub/y59knaPX8ZM1obDRxGWebuHx68j2LDUwACUm8FF87ZcNoXDRTQrFDBDIyQg6NeogHOwJEQMCRRASinngUaJmpoHVNUuuWPJL+aBXQ4KFtKQDwaDx5GCY4fOCuEMbEJnG/uq3JuKVlItdjfixhqXYGMXLNLPLKuGb+mK9CZ6/p/Ypz6gY3pcpQhKZaLpuhEUpKuDIDUfIUFvIMCh0NqFVUK1F1/o5PGlbTcV2prayrOXZpYxRLqhm1GGs2quFEt2pqrXu3vgKfq/b1b5t8sOfdnbOUQoZ/vdfPv+xEFBEaYNR7bSbfZvsYq6BCEcwgp9EI21GYeDrbmBe/Tydnk0M//72YQk9iGXCdAhBm+ZazCCmjH2MxgAB5GXabns0dRqLE25R0HwSjZbwRcMKA7oipRbLxKUIyyKDBIGXx9ktRidJfXHAasVvcdnGq/xslqQQ5nbzqeDDjuNxCDmSc00PkhFsiEX///XEKfWhmuAIie6OaE/XI4iOwAlfYMkmDhZCPHaIQ3xDREd72JJp3rngNbnnp/Yy2z/+9LAYcghEEMv7E7sdiGRJOUKAAbckChoWfECojDDQ0f1aEpEamDLjoBAa8KnTmQwgBgZssUf7UZl7g0eolJoYqfcmKbMEKXOmSJfvJziE+9NAh6E5Pjcj323oiWfiQT1Zh0DbHT2DwYiWrq+vrY8w4ODBS5LbbdKCQnuPB6uNP/7skQ2jAXLZ1QbI2WirswKkmHsflNxe1AtPSkCJa9rZYWaODkyLB6Si8wSDkzfLZLhHxk6duJb/khGyYFNWclc/XTQCkXFMCY/rx0My2kUgLGaxxffBoIp4NYN1y6rDKEcFctuLKwfZZSm9PZN4KSgHt50efjStFE4lKgs4fZE19gkvU1U7WqpHJSJaMSOMqSR0fNYh65Ohb27XDdj4rvP3mu8ff8mPvWM4h7xjGqocOBjXorxwzbR+ItC2NDVFjy4Phx0sMCIuMQrZgprS28bDlvluOksLWqITtUjp+vuT0mJ/bK5u4+THKuQlv3Gl0voZvhhRcdrzdF1gEKSeenCJYQyUesVoVBEFEL8QhvRQHDMTaGW3atvLnqv6sMHAmKRhYsTE17KaAQG1+VCgN+U8pxkCFKAz0gHG5tZeDNwpWwzCZOYtqKKFKO6lLzzqeeVUau8urrU3wfsT4eEU1bktHWUUEQ2AoNXMVIhWow2iO2jM+6xNRXxSdOak2rX2n4zImTEXVKzzVWljajJDkJopER+LZBJDpGopb0TGRXB4TkmuksibxtEjWCRdYgtTbSlq81VomHPVkRoEiADljYXQPEVyhG1ppLNLqisOM1nHKep33npqedzno7pHylfTcUl3LmRJ5d7PY8x2Pt0zcxFc31y4xL3zGk1jnLJFBICVw1AvLLTNiOwxiX+Hj3zP3jv7j/Jc2RVUX3/D3XgjOylcozRF1XTlTSNu+sRIHeitgpxVRIHR54UnDxqUclIPmFlK48AIQIEDgAAFjEj0xBYkpAHiVPoEBAJxfapkC2Lv8sqfXETGgwLqbcDy0UMwkaxQv/7smQXgARzWlTjK0uAbysq/T0CmhHZe1NMMM/BzCzqXYQOaOhyKEmjtxXNIUCGXi2z/GOUst61ZDokJM9MZn7fjMv/1iH9sgP5GWb1gcniG7zwRse3F/9f7GlHeFZsVN3pr15+WYjPu/nfljsTu6pcj+FEELSnnhY/LVZqQ64g4XlNwUjdaSckiJLJuBeAUSRqsHcuRXUORZNEMHEiS9s9S3u5FDLiCyvzYGiYwVqoqRsvjKyVWo+eOsnWpFCLkQAmB1/i/iYkNO3zgGWVvia1bU3Z+isqutKqiu9Os9U6SavvMyqz2Z51OSUWZNRA4jvW8HdGComgCjZoXWg0DjKLhYjlJbIRNOKDQ6gwytijBbzFT1IeBf0b5XYehfQK9ClpqEnHzNrKiNs0s9SFJafna/9P4vuQNCoRXf+PHNwdrWeF9gOP3JDpciqvyl9rfP9zulW7f34XLbj+m3+4W+S+akk3pFtN2JZj+0z4oiYtsQLY8gTpZiHf4U5SyorSdVvHYQ4QACANsuLAC4z5wOpao07dAnzBsRmJ5xIi1vsAX5rW8HhdwPHDxrfF1d9+yCFNHG3ExnKYM1Dw3UoQg6E8SzfrURS5W4xeSfl4ki9r+ugat7qdXPzh7LIuXwcqpFsp9CqW8fVBR5TyAsoLFVpouGq6agAxyESVI004bJqgzIi/AaMpNJBR8QDvaKiJxqruM1NocENjvQE6b+bkCrZeTSY74lCbdWBmdXST7JWfvq+NZ7JxotOUKZM9zB66ki2MHtxBv4wT617uHJWKMtRD+qCjKenIXZO7Thhtc08oWlyUOlRLbXeNoaneUIPRUM0jg//7smQ/AARpXtTrKURCZWsKmmGFbFJleUTNJRcBpizqaYYVcbOgVOmyHBrfRorUmTwb9QSUABRFEhsKBcU00NZxDrFl3XJIn28Tpuew0xORJmAbt9QimH8Qb2/77s0rmsz9fY5+CP3O537TKTIDP261RjK5HoZZfmNdi7k9ZjPspFObRWxJV9zMdrF/33Tk6G6HiSV6nQawsEAzQEeiqDAihxDBOJIMKjd8voBGjRSYI9pgCiFzWAgRERJ+rTEk+mD6kNKzCG5RDj9rqfLKs8VXIqgAu3+paqKHVsz++KFTcVqdDUn6IkcOmy1lPNX8BhDGBcll0rbrVHN1jF7gbU6fnCvamchSRXGU3v3B+2w+IzcfG3w/7Mq07atNTAy4DoPoaaU7c2tTQ528mBvGmdeaToqEXYMCRjcR/E5mUv3dGhOiAkA4Jlp0Dp4QwiY5iR6pZLGtBA2Lxw3DWXcapvnMhDSI5nvLRspQFDB7pDjmO7qr6zX0QyUl83/VqbSsVlaydd+yP1XcvXl1I/ZqlagwGetrUtUAMAEXG0lTb4B7SKJTArjjMVSI1s+ARtIZAK0ovFPMtWBR1TyfJ9VnNdmqeadKQ08NZsEIDyUriTjBLLTU3rNFi5/ZZL1uppxHjadYw2tvySBzparOcsc3Bg5OXtWeTHnahz/b+wyfWb5LbVzOSXO0jmTjfWJ5RqzoHwPmOO+H6mbnGEu8qLzIZEJjhAPurJuNzwysxxGBEyBTcZAZhQN0W2CgFcracQvpfgFWB/kXGvRl3IwskWLjE4JGAfz0aIwWScVGotOWt9iCWOSVt5m0qPaJtiRflRsLxJiEqv/7smRuhASxXlHTTEVQbgeqemUodRLljUbtMQ/BmCuqtYQKNErVzd3QnmXvb06mG/v07qq4HgkBrVERLQgONSlSCVj28NHGCrk3zYILdiSpktJoAYwFHjoLdhcc3qjZiicJTy6j4/LB0UlgSZKHgKhQuTIJ6KxioISxGWusQelo7inGrJoi8Q4LZ8S2cYajnpRe70S0djEk7x/H+JB6PD8MAWbdB0CmHYoP84OL+O8bEe819TVPOQ8Xv1dB9j4G3XJ12pkXk6/FcfjYN8hV96EaRCk6IMElSYt0Sy9MlZ4xo+ORDzQZSV1rKgPEcysQTTULht4XKLVMoVDFU/KCdo/p4RQurVyiw5PgQBPQUU3jSB/XxZD7w9NOeWq0p0NZkiJU8wk1nDqemHDaGIze61ODXOVN2qUbv+uSpP8v/v6O1FR98WiGWNoVAAEAAAMqGFMIeF6Y1ctMHKEZygAcoElzIy3CfBh4GxFsxEEKYGKAa3a6LLAeLSMCpYVHhqHQ/uxniq8I6ixnaXgi1br885azcaF+XXM1LcOuOVKxkNi4cmsUJx/vESNa3hTeLzMlorHFT8P4rPYoOH8X8GLGIYf/ctxH82/NzxKY1uKGDbn7qhKTajwJmXkDlNBO6hqKgCwABmAwFNEwYdWQRAQsFhLM02xGPWEAQNYZIZOl2mRTTVmOzDaUjhWHYgHycLlxNJsTCWH0KjGIQ8YYGeghsPZ97q2PH+3sw0GSooLoE1/c0oeqkVhN7ZIqvyDtfsUOozryAqPLgTpAGDIIBCSaKgJzGnyAhCgP1EAZKAh3L3yNlKmYIRYk/7X3+UmGxCAysvbiAf/7smSVAASyXNBjbERQaAV6GWmFhBLheUmssQ/BsKwq9YSKPYRRxFW9WEhbbufkt9g4OFMtmZbYkgAEMHoncckrn9pKY/vbG8i32FnTFFHcaE7pQilGIDcSBQ9A8HWhAwu5Leu2+CJbKfphl9/wTVdCN6S/xPxacJfP1FmvRV9xqrGXFEhwTwVTTntQxgGlExrTIkFI4QINTLbJwhxVexCUIMKkbKklAszJo48kep3ymn/r5AjRRQLYfy55SNu8ogJIKI5zkKGFIqAbapRiH7BAYn123rtl24eftRi06YjsLejfFG/LWEOp3T/170IyN//v/////bG4Z/e1ShX5lHEt8jjBCKqaAiGYTw+3MzFQtaUi0vptmP9Wk/6XzUY9XzBg0VIC1RZIzO0sq1iJFtIiqF6hGYvBEKlZHbQ5qAxukWbaqyKkzrNy6acl0tilie06M2srfGZdwyVPL/IpVkDr0ECpLv9KrKuvd3yLnmlvhITj7H3UGInskUIYXsgRBkbnmIQKPu7whm4CSU22yqsQKLbcIEk2zILADJQFGYjDLCYg7VNfgYIUOpTBO63ry08KUcTQqDVCg6FrUHhGLQFRpmyVc3F8Cgcc3UcLMbkq4M+VJFDqtasU+z8mcjKinW8n3dfbRv0Rur+i8538QQoAMcaIVDGB/5/v8wi5SVo3GmUoHTJ0IBlKAcpkUga4nylwwZdaRrB83LBAULBmyiKJ0PZ7dKh1PPgP6f6xivZCfveVXYunOtW+T0FN2qNdmrW+yb1EF8ihM11Elj/omHZOb9no4cpUWc/Vf8nN0k8yeanfh6JzcTq2GvsKtmm19ymft//7smS7gARcXFVjCUR4c4s6rWECflJpfVOsMW3By6zplaYhWXWw3SbLpOtikTig6SAS1Cl+q9z9MsWpDCAg40OhYgSIYoeCmbHUnlzpCvCwWMsFkSgVrCIXxUPrJOTQM2Q5WxxMO7xabqn9RHfUPX8X6ne48v+V8etqGAbmeZcJ3Y/dPiKhXmaqoifmavky1i5vabkfCVSVcCy8ssdHz6tfhzawqcrVxIw+mIx/R2kXNv5VCUeak9vkhbghnCHFJpelAknTDWUx1t3YYkOgQ9W7JG8e2V5T9qX08RksxDdLeAEaW7F98zcI64Z8WcRemz5BaFEohQGSv69V3dfTLCdeWKKK9o5jvvSfnS65+Sf9oQH838UFXKJt6ICpEu3nGlni1hp10jCUDCUoAYjKqHxNrAALDIkaBAAJntI1HSFS5UlAwqU4QUgMUWguxNpDbPZPuENVQr4iJM5bOVyGBQw6xzyIAeozUEuNJU3herSL5UesINKC+tbR8vJj9/xL2PHW0z6ip21N8np6k33bKcTXE3UD6SaietJsZCXzUR1Lz3Dja4qWtLSECtWVmEGDD7Y0AVMgBqIEgAm6+HYBAUyZEYWvTDSuUqRn6kystW9TKIzTWlYiKnEA10/aFBmVwC8taUxni+N0SkS5ptuD7MZ1/X9M7/T327KNJxJVTtbfua9tJBF+z/RLDVeI3/kh+fJ+eJ/OXEemd0UpXj+pRVDG69bMfMNd52KaTjcZu50Okja2+gZxQW5JJKskDxZGkAEAoQAA2PIUEmgCgYoPFAIXE7KEJs+ytJiLaE0exlKIUSyp0OP1vVjOZBb6sjUZYNqAKP/7sETgAAP2WtXrJh1QgAs6bWnoLhG5aUetMM/CdC6oJaekuNEb4JGpRuMmlzkrh0eXeLbnm31mJSWF47TU/3E0cgW3wQz1C9lz5NPyaRMTarGLp3jNpohVOU5JwQhmS154TJT0ZICqlN7ieGEC0GFUpzpVnKudYImWiEGV3J9tZCoT9l0kV1nS0BMFsWUBNQAg1aoxhfebIQjg6LDAJCQICIE2ZGDhCZhgYCShgIEmLQ42ZywcBRWMp8u1jzBVZxJx/6dpQA2QWkIYERQu3Ehcq+zrGSOWf2w2hxIidnUNRwHNU2mUfpep8y850Hb6sI+V8eCce0Xx5vHNRefq/Y6l/Xd3RMU1PPfx2cj2JM8moEe2HazI4tlRhbgiMEORigYfu/UfSMyLxZqGKBIQBxqUbnQmOEjWy2yDxMGs2EgBpKyFfNBVLDbt0ZaLOAGutblsvlsTpKCntS01QdIRikNiVlkIRTTsQ3niuezobWgW03V8fNSFFFLos5OkW7ghRJx97eLQGEbGhRHMqUoSzwYyggkPSBDqkscIeiMbbHGHLbIYFAqLyP9AQDAAQCMsoeMBRUKgBA4fwcWQUCphBgGAp3w04m8rOe0Fq2hsjCpySjnloCeJgS9kmkoyNoM5rJdLJ7cF1pidI7DT9ZDyN6ZWbdznvg0c/WMZZTD+CHWaKSNrWqKZ84Y2VF0oXSgpy5o7poWvciR5W5vtYk+J5hCDBEc6imXjMT0l2867qlyeTdkLH8ZvuFTpJ0mWqNpZcIwSJwZjjibX+Gsa0aW8tlvpxpVAACcRSfamfUqE92wHoqToQJBAl88z6tqBWqRYLHnf//uyZPIABO5e0ONpNUB8iqn1bQOoVW2LOS7hJ8HtrGehrCB4EAlXLwZsXwfmZrOSLh+QeCQcyAIcm1hFxqTWVd8Nf3Nf/eNoTibiD41Nqtnprv+pNi4q1uKUnjqm/xbWe1FRg+pqJo2mzpbueP6Rq6fv67aWGNf0vd0LHIULLqePBAAJ6N6mnyqYALQsIDLxWMWCcuQQDM+dzDBEAEWPKZkjE2pKNnkARBKGI3kgEOR++PCrmjagrXkN1/Qe0h0WqVVJXA4mknnqSkCNqL6nJGxw/g6S5ZRVor0gPlEM+4a10hwKrCoPEGc8zxnqOfhMtTeGpVZfqed1389OZdsMUTRLfLNGo4pYPrV1ZNZrVbrJyefY956b5elp11qAl09jEKdohdigGdo8PTkBHHB53XcM/nygpoBGKLGntR18MNFwOSAaHmDAJgAUokWBGACILLpDwKzJfzM4ARIc+maG8yJaNky/onxIQ1RbTv3juuphLAqoaAxfTTjRr5mICl8P+cMy7z7BPxM/TOf9/6X9BCgRSKxk9Ywi1xqzbq3NEdKsZDyhQFgpp6D1SCOMgkDAIzCGDCAUMWC0oBmEJmAMmWAjx2mNLiMUULihAUhGGwAFAZuwcDCoGLqjlgqSjT9LOaevIARUAGzGjHoaAErapyGZS0WizadLbjmn6zYVx4tmj18E9zf3aUlksQuIQD4q6ZITu0Lxx1mv6bE1i1Wl8zytZMyezvr67ydbP7vYqgjpAopMu5HQvqLZNYpp/7DDu+sWXshHmdOMd0ZSyCKFAi9W3u643+1imMM5z46mmMJCIQsYaApjEJjweMDApPVLACBh//uyZPkHBZtaTKuZYfJ0aHnpbYOEFoWFMg5phdnuIibFxJZQlqFUZLZO4wxkyymBKudNobBb9+laouiEw0DIqNCkbXzRCNPTJkZO7s1CCjxxBmwjVQMOMJ+RM5SRN7RN9BR5DNsED02RGJymONZHYbY6uxQZhZBA7BMXafKjEosjYYbLLJw/DkRqFAAIBHw0yZlERg0PGKh0aLBRhMNCw+MGhswCREUCgQtoZhpvGvsYY4zMFBUz2tgZ5DgnWzaOopsNlxeSeV6tTTi0MpuVqy48cfh6n6yFKyiU5f6ZX/unD9DtUtwS125LDVcSGKJbGRns1pfFe7CmLT1VSWbxSuaXzsoR7OWtPsvfAhmiLaO16vZOeTKzMsTu9071p+HvrfJvEldlMkb7ILwsuC1dpkYLvY9H22bvEsKmSeV/oQGJIR7FOBrMqExgwEGAAQZsVCFZUaFk8vFOVlgYAxReyWTVXgQelsWdSGocd1sGCr3+wh56JdV0nEkLTsTtsmqySQ/DEie/OSm/HdZIkd+ihlsIUOFc9RgDI4+j6hzXOF1cvM6hnUoUpYIuSQdBQbqzoDiL3apJd9EkEj7KRpca2dfkAECqLHyL5mCA5YENTCwAebnYIR0ykFVQRsUAHQoOEV2OAwoBG5dhqsvlj8MskCL6gagkCbbkwRiFIw9Xb8Uqt6Yap1N3iaZHXMaWsdr6c6dcFL0jrOGuTsvoH8a4xCWOgqRiFFJVSgTA+WCQJDk8iEvx7OzMnxoqwCQB8P17Cg4JANCYZ1X3YWOdejFJ+kK9f107TB7J6mfdor8GS93SEQi+Yf4e/rM96eWVnZb3/qbl//uyZPSEBaNfTLOZYnKDimmRbSK2V6lzPS2w3IHUryjplA44LW5RNbNCUKeALltLgI8AETE3KWDQHKGluGv11VbXzRBZo4LhpxpMN2h905qFRiEUJiOWpj0ZCVDyH4kNDseKW+7Ik5FRu5BkvDxyUYFbkafUIMVhR6ot50Iuz3e4Qk/03N2SnpXr6I3nxJp5lwv8y4TJXhofshv4b2/evE7ZkRfiKgADkLhAjG4jnIB0caEAaYEXHTJMqHHQxe8YACQxASOAC6CuTBBJouepeWQcx/mCR63qNxCc26Lj5TEsa1cdWWQGoMW+TFXqoDAjnLDPqyhoSCVViYro0S+HPlNx3s6aZdmcKHSYsKJbLEjVKPg9FZ4KEnBMJAoKijF8sT0nxjkAp5Ylk4gU0Bu+MLWs5dd6RQaTi1mL0Tibxdzm8QvqBBGE4jgCPytMCigmqbVwdbwaiablkJwBImSkAxSXmEASHxUkDlM608FCwoKToMGBbVJJ1YJdeBnfl1ldboVHVkftglrMo2uB+GDukX+XSwVlrWIYcpyVvtfTRToUjKbLxRSNXn6sRm7DNWjdrkchVat2rajU3S1z2LjZIz5jqlFGF6eLiD4HjBg6UsJBBAiQEEw4Gs8imnDDJNTUf5u6DPfrROfSMXbil37osXPmUFFAYGrYG4jjTxQOKILTMU8q9B4HHbAARKlMl9sBhpnPKlYieg4YYqn0xGmhk6g681fhyN5LtpbAnFeOAn1f2IwFBXzM8GjlCSlDrkQHNhcYfJaG15GHVNOrzUFpazE3dSMYX6rlk/5nH8xf8LHH3XzXaIW4vaDa6dxnWXdURIwy//uyROaIBTdZ00tGHyq7rAozaMj0Ugl5UGyhNcJCr6r1liHhYKMU3NHVNMFYYqRGFElMtgmTtBJgLn1Ulhb2utc8VHwYC17H3kgCzCACAG03cDaTcVZAcNpnEJ1LLBR6xxphSCWjX5Y5STceYuIAHYB7KQyTD2JQ2vBQx6S9Pp91n4c3KWYPMrxaAXjqm+nQgYd9Wt3FEDxhd1wyf7+/y6vevbpN3XP2mZYujk16TQ+3L/GasqKwo7kbHC9NUBK4gIqSHqpQpIsEIjOWoIOyFLFkB+eqJzFH9Ui1AmCTBSdtjToWqgDUXApTr0BLaSh+xhWmAUQEm31aArK+qNUSg1OKI7F8nKGcuivzVcKqa5cmyy0r1T0roZyi3Q5vtH/3tbgV1ri2ZhGH0HIQ3XxUZZ1xcVocRl5VTBSeNS+H4Rb//Phtb+a+XThuuapptJJUVjia4a2Zg0+RB9CgFUHV5fqB0hhSRc1qS0wo6agpWB6CzJKdpk7F6RXLeuykUzejnYm6FXExEp0AuSOlR/3EjenH/cpuJQS38fIDRHSzLV4Gg70tc0iDilo9RpxyGh2/vNVtX6eRFRa0rSnfkTZtESjn2Ztn0XMc2DM6sxZB6qM9NYBKJRgQ2M+kVYbW6bMIpaXOEBwzqEeeLWKp8eNKHF3xkKskSAGMXBGCRoIVbWkRYiWpHDOYC3lJXvAmamuK2yTyBonQY5zTnYGD9ieY4gWCn63WNGRcEX42R0VN8N+xIm6+tTTeBh300bCg+WQ62Ja6oZXe2vd+8dLPExcjRlZSxcRaNAAVqYPRVfgpCDSp95M9cDoAgDUabhgug+k57UwU//uyZMwABDJa2GsMQ+hw67sdYMWLElF7TG09DwHcrqpplIoh8iqQDQV8CBBMCMjx6TCUyTIoBapWurUTilRwwThtARtiluRiF5Eq3ZD6zMbM8q9BeaAMJUXmK1A4EdjG9FQUn1kKjm/uy1X+qvmQxldqWopXovJaFZqouLGe0k6CHRuCEGNIKdC84hfJEAADGiUcJOm6oxgoSZvSG7tJkBAMhjdTSicy4XX0YySISC7YJChgnY6DiV6kAyG5KCNRHgZsTyopEQS3FmztuRGKo4EPJHgbAe0c3n8eosjU208+lh1w7pluzav20Rz06Vw21FK0mpdWlT5AcN0nH4bms5iiPtJ8bb/KLxTTfkw7v5/73radT/d74Ofmznqy3nTteVZMVVblJcwkSykgj98v6k/jRAEh5sljFo40ZK4OtTARKdQtG27NG/DDGasvYOm/Lrb4uoRatfMzrbYnkm9c1fJpc7fGRCneRo9deXX7uufRvo+hR/7ar+qRPJ3zLEbLWgzakwLmDBqsIjrGWQGZor+DC5roYcQtIp3Tbb2mizaoci+L9J+tdNfV0VqLYaNxy7/6AFUzJ++NElMwgBjAfsMTEQwYIzBgjMGD80GLwU5wgof66D6BgBZvBIzPawTQzIDwMOIp5hh6eokGaOuwBBhJpFEUkOpQJSZfgdQDRyOMzRQYazyRMBlkiaNwfDfY4Dqw7DYvESEnm1VJfFjhj+XMmFS09ZgtzBLetcDy61ZiLametR01ctf2gdq1Z8PNH+nO5OQu6Yfti/NX3pX/Ucd32kc3P+c1PwVslhqUmkTnL1ThxVblABWSSmGBhqI7GIWY//uyZPMERSpeUTtsNbCAx1qXZeN/VoV5PE5pacIxrakNrCy4hDcwqcxsS9QtG0q6CfkTws2CDbp86iexvWmk50ZXtLnlehpyZMrhYIZAHB5M1TYkmwet1UohWoR77apBogXbrpZkmQFS+DY98yu3k69lTFXtc6rRvbzcrTMXNfb9t1FuM3I3NTHURb7by1JJnD2neqrjr2tqbNY5n/cbNmE6leqVAATbdIG45AlMfJzu7I5ABNISwoPuYZJIgbnQfNbWgoCQFAdsGauiHOA4dACNJGqADQH0chGZowOUQYWctlA2H/dsoRgiYZe4sklEPyGRuBYNThqB+IZ5JNgrvkwdkpMAkfTE04/YUOgBg9bq1TLPGnLba8QxFLU5V6sXMQbUBYuqKG9Q6nYsc23zDDeTm+KvRp47rSKmU4sUDwmHFi1ya/JOq02Q6AnLduYVxt4mg6eXxKKlUZoQICS6QpJjDMIFmhQpGkn1dyNuSHBpIOa9bFpLQvUwNnq/p9HJRI+oMtUjibh+ROhSySXPr9EgP5f9+tET4rxzPKsu3HIrvkZHg6/JJHt6m2a0iuixwVCFUyisws5Kn5wGxnJ5pzYpVLzleHZsKqHqKk0aAA6m5xg2OKYgpTmLvJ6QoAmRMkwcUEaoDtoaCxJhDk9IMwQIEJWOgAsgpKAgBUADA0uAnhRu+3peFHSAoBYbLp0cAWKx4hDUaD3ImnqvonYoYkBiNWZMBQRoGStutOUiAAV+zWO0darH37K7zMGTNHetbel5hnMytOdsGyyl2D9VoLfI/dnlOyll7TNZECNDId87qKUeAw9AqYMcOwkoU94GAAFj//uyZOcMRS1eUBt5QuCDqzpTZSOoFBV7RG2wVwHyq6jptKqQc4o/BCIZWhAM0BQgVDBZBUEwYQrYZyYeTl0kajDwA1MRY8rGvMMBAhBkcBqia8+bdoZyUunjgqcKntCx6AsjLU5NOe0SRWhAkUXo+1s4C0icWCabofRFVVI19bH7Iv9H6IrP1N/7WO03R7ftru930vsacXIBwZtalQAXHJzIajKB4YFUIBkoknzAQyMQwOfWiAxmjA88PKS3MAkhdC5RojpWJzjSpEEnMUCS0kJWqVkJbNBZiM3mA6BwoOsE0QgTy5M0H5roOytkpySx4bnWx5+VKlxe+D3rcZA1RJJUyrZTT7KTC5ioa5NtKtb7FlvY/z7uXKM2U6907ihP/55v4u+Z+a+OfSllds5WH91lajKSsjoKcvx9u/wAFu24zsQykY+rY/CE0DUKAzFGTAFYbBxsmZmMSIkCA6AjIrER7YkqgZ4ENKGuQK1dIt0G7JPEgBGqOCohKV8awVK4zzz/61Sff0D615fqxr5/rZP0H7+uz3zk17Qvbkd8vb513Oxz2UnRf+6uClkP2ojq+m6xDsz/e6TYX5TvfGuynzWcb//sAFbNfKkyfDTB+lMjScHkIyyVTFhKBBhMSLADJAHD0xUKTJgiX0ZfCBgw7gYjh1yEijlGI8Qkwz4iuxB4h/JAzSYSeRIHTwMM0OKAlQWkki8yYNtFkR5u7oSu3Bsbn5mJu9DU5AoJnlwSosG1EAPyLApTJS6rapk8IbmRFKWKVJJW7udILZLvFr9qSk+Cja4efDyakQiP0jhj6yKGYx41ycrIhCBGm+ZSnMqWCoeV//uyZOsMxQBb0RuZWXKHyFojaYOoVpFzOE5lD0IIq+kNtIqpOORV2lqawC7rdwoAmDApuAidISlrjFCsVASQATrHh9kQJC0gS1CIZmALH20cBR4MA4nEKd2nYbBChwAeKUBoUKqj5YuSTNRS3Ems8WYpx0PLERzbWzq/xBh9Ztb4wXf0SGVZatVU7nU42aUlDLT9t3dCG0d6N3TZLW9Oq7bzut0bMSovlRvv6uoEAAdkcxr+oG1GEmm+yHHYAlGWaARgx5YO4OqjQLVH2DjBCTBIMlBNoopG0f2SJYzaLrW1MYBaizF9sLK51u0CgsKTKm0nyjW1MlXjMKOnmRXa+FlzBiCajjXcogXqEs/sc0fHTTiffsxDMaNi43uUQy2KjDz3aCe//49q7/b72fv933vOZ3u3u/DptHh4UbcEErT3BZNjLT7IRE7KRAAFW5KY8JrMgVU9lSZsWUV0kMxBQtWgKHK1JVIJgx6LL9cceGIh5U0aZi088D0qzPJKAshIIH55916jEB2d14V1CLSRpI73V0nMQOOpE/yMrt90yNz5zpqczEn+r+RulFfIr0UDf14iNSfq6cMRiOMn7AOXzXAUN5poKHMxn7jOyLMWjgxKETCRASvGp6UEzRmDcBWDmJQkjky4kPUgIaAnACVmMGAESREXiCwcwYMaIjo1wUjYZZq2MsMVQ1C/CFnCmed5SoVsuzhE75nX8M08df/UjDvvobBQI2hh5uEqqhpeCXMtjm2qw4FBZfQ5OQdx1ATidFJmHC+Vcw2lcorvyp9y92xc+iKZJo7aTtH4OdWZzdXuaxpjMibzF/aotFYo/ZMqzbtj//uyZOMERPNg0jtJNaBxacpjZMKiXXGfPE5p6YLqsimdpj75TjFFN5k1VSKQeg5u7J+TBjZ2Fic4B3izqiIuxXHkKZPsDZQ+Ck24Nj2+/lsrvx/HtDiX7foEASusvKtdIA2JE0SQQDAuQEQoRhU3GBPCW3KBxCBIgpdCORlfLziwaSswh2QxeIQI5TQLEfuWI5lMNLqUpSk2UR3ujxj+e+GCZnb5NgdAlEhwR0yqxCsoERJPsn5EXzzCctQkVBo+kvDkqoklI6RXWUhiKzrsMkiJZCvOvlfX0NGz0dJrSMqKKwMHDFbMxzc4Jj8wAubtryujyMRS1eF6SMx3i1EOplhzp99lzZIDnZs1Piku/Wb8BCgBBAAgTSGikYMDTOJYzg0MtMjBBkwUXEByBmVuhghkPKekxkLGRJygLF0HQwwNCjvEZe4iQ7WUn6O+2PGUoYvPXicYvRanwdyTng+Ho5GMHC4q1tcsOM2IPxTnxtNqUdjwWz+INWkTRBzvjDTIVxS4UUTxcU4HPSqQPxvFSI7m6t68ckHnYrRtoy3SRlMStWNr2JeBGB6DEBqIjs44vgQR2RNsDnSBoACCThShfUs0YViAylLThgAcarc3jZ1LGTPkrtIO1PvqpbOU0GTtSzMQBH3twDkWHFUxw74j8SR01x9atHsP9SBWu5+5qs4FV5ZtUUtWK4revSejc/T6qiVqqsqItU6aW0MtFJoYer865TkZQhFbio4s6nqCHtmzDXAMlQ/M1XNYrJQZckkBsTLfuYKhRo86A8BTtVqZFHFM4svAcAyOkbI+LLINh+YAt6QCPtkHUilrpPmQnOligHP2//uyZK+ERSFfURN4QuB1KxqaZQKqEYVrTM0lFQHqLunNlJagOb4p27pJwaGSdv/cyueq4GX8zfRV8P/IYOypbgoeb6j69uBYZ8J+l1rc90vR23MJs92N4uGEDyHatt8aBD3MOsqLFTWorUTE0UoFABs87rC0xMaIz2ZoTKNIGPAoNkiqEkAgFPfeJUqFkVeqzGZbJKqjstqCQmYvaJ3zfIxnVFbNJrM39l6lfuWfrLB2v7r/K9oWf0cRLYjm+zarq3Gt1XIzVllR3quiFoJt7Zx7SzajXWuoTMdg6BnET8wpGBTeLAX1IzVGNqOBhZOOkQcUGYCZbIhJDAz0oU1lmAhym2QkHjASX6DBxPVAeUAKToXD1GadN5TF3pMpzQNCp7DtyDAqEbT3YjF6MUNv7yVrr0+nZuOzz0tQFqlp7unHetAJrUFngggrrk3YPwsvb8elbfENMiP+FHBlzLrDXn976z6XsKym4zJSMwb+TtqJlFASAAEKJEBBbAxSQTkaB6fAwsWAVvwIxVqAOAT5dNcCAHvW6MeYrfucmJXNPqp3nSBQswB31tK6qq9FX+Dpz9K42o6upDMkYB2S+6PyJRy77EPz63dVTmWcWd6Oumsz2mmVsytu1W0N2vmerdBaI1WLAKbSVGaM1AKMPZz4Dc7c9NGLjDyIeOjOjYWrwgo7PQ1BHUQDBdMySkJKD6nQs4DQBw9GKBWfFrUJqnUjlyptygdRkdPxtae7jHX5nigVCong8RmQg+gfvVKRLocHx7TEmzLGC0EjepPGcYhCeOH2VfaOpb+EVaurGA3pfh/i6hbToetTC1l18q3K98C1VB/3//uyZMcMBG9e0ZNsHbBwKtqKZSWnFEl7Qm3lCcHHrOu1hg2soaMB9SB4qbJtOLiuMPNriK1yQBGWCC7P/9ejMsQysXy6LMkBpedldBdb99WUqiBlHdkD0LjctzZQUz/GHIh6chEqGJz1mZAjYIShGrawJ+lWqEG7t/O4dfs9+WwvAbQJwU0OEetIhOC1FGAXItpQq3dbkGVc1b/4zeTe8L9jnsUw5BzN1QA7JXjA4EQp4JPTbLoxdQFRAgAjEC8neA1UYOOgM9dAsqOAhyw2myguwu0IBChKhVM2MuSnYmVF5iUTtpMlV8fBqAHJCLHBwc4TmVwaIK0KOApZKI+ptKCmA/pjxsSZmSwJGQ5tePGD1z6vhDbUY9REX4s/0bY0SMH1iEr3jaNz1mL58VmuVr2+fuVRan/r4MMSGF4vS/g599PIlOauTPmbGHSwdwa0kusRpT4t+zcQEZuwiETUbyhtgCz598e8pKZ2LDn8PGIpDXJnEHdjPwZX6Ltuo8us741b5LGvVVNXkzCtZVI/blT26Wvf8/vnk2IVzIobFaM6C3nfTfEl97K93zXijeDIJXQAAMYxPaZ4jOZVAscVUYZ/GcZCouYHiOY+GwZjG0ZDAMYlAeELKYIBSAg6DDOCgwmK4imTIfAwgDAhoSZ1SgKXkU5L0LrTLMysqOJggYXOLQoGw6OoitHL0WE0IKgaBEP2Gv5Ps5X/Dlao3zwxunmayq0gwuakVTDVMeCtYPY2J4FIHKCY/kQknJKQc1X1U9ktNfMRjTPleg9uaivg++Vm/leYNqBYYvEVrfc6JodT+OHdhCZqxFwRKBs0yoACtx0y//uyZOUMxNleURt5QfBtyHqDYMOpV41vMk7pD4IOq6gNvIl4GdMgWTWhIwMKMHETKCkxkqCoovEMK0ERhZmPXBxRhGmAQ+4YAg4EkjXUoHDZW20QlT8iAhPOhbD2My2QwXQ0XJ+h7WyuwXe33uWWshcJLRkPsAAKyAaoxD3OpalTZB7fsjq3XohdmZSyJq7s7FOlEVzF0f7q269f0Mo4+hP/3AAZJJzRDMeZzUwMHUZ0AE0ky8PMPBzDy4MJEmDCyowMGGAkRBBjQaBgcmJBAIBMgF8FrItgyY8CFwyUMAg1Qio5QtJfNQ/I2KIxhHl4qrJ8uugYOtZ9FA+5kxZPIIrqU7pl1kXmKOcKKE3Lla0Kqzi1pJOpnqUi69FE1epOq7umpSDHF3NlLrP/stl1//Wz7H0nq0zA6X0jcrqWlR+C0BPoAC2t3M94PHAN8gOZBB+Uz70gSk0M0ZYWmFvg4OPHy+Rb0OVoC06A0oCLDjDSAHYLGMkLlERDlg74hgtBBzpXFbEkYORUmi6oxJ1pkcqZFSTltiGrdE69TprIoii7rR1maaZmTjomabWTMCitZedVI4ZWSRTWmvtz5eZJ0aqrUnNM2VWlZkEVOdWpbp6C61oUUEDc2d1GzoFo+dczSTW63so13oAAAQAgQDglDYkBJOa/Q3UzjdXqM1FU24yj7ZqNEFE0QkzHpoNfHdDM1wmTFA8MLkUwyBTJpJMGBI2yDgKMB0Y7C44Y8+5mGAoLDE6wAVHmyBpNAoSZpsSCwoBS5a07ifCAZVyk3PgZCQlYNBogqtBcwulzozUsiQBSYKABAhhcIbtdiFNYg59mQtdk//uyROgABQhZ0J1uQACji8ojrUgAInWXN1nNAARewelrN0ABUEL3Lfvo6iOCW9NV5PRKA60PXGu0l6ORcOBjQNbiP6G8kllLNWYa3c5Dssh/OxN0tSdarefyZftv6KH2/nYfzhx05Hd3Wne1pu3Cm7udr6TC5TUi/2sWaemjExHXHV/Dljtv+dqb/+f//jnPf+FfX////xty41DjqR+XyO9Tz+HZ85////0GTAAAAAlLg2Pi3WqchrZac4RCFINsJRJ1MaXAqDgZkBgAGMBkQFAhj4WTDoYDkxiXkAQoAAADIwNxgLgQEgRMhQIhUkwQhQwEJQDG4GZFiAZIkOIERAawxw5RBx9hgMLPhgsfyXLzlYQEHPFxjnlwAEKF5g20C3sUmVBzD5SPOVC4SpPjnj6BsfD0QbvIsFgAupLiRdY2KpwnCILdjKBlxYB0QAUWA0PIGHQCDDFCZTI1ROG6kVl02SG6RMghgQQGwWMIWQGrxH5AHQMT63Wy0lm7nT9bLPnzAPEDdQQYISEIRMZQLXAsoE5BihV92X/a9mTTVbw9wZ0GwMN/FbkOE6C8FEFzi2CkxOYjwin////////+xfN8HCIEOF1glpRppMtlQqN2VW4BamHgUSgAYiaFlh4AwLzaHL2QOpnDCITiPG1NJkWjkYK8sF1DfdEDGEXskLJOdZaqYnI0U+xuJIVSvHkBqiBC6iumXMSYmU6PclcdaIcTsWEG1PC2ubNljZ1acjMe7tEnIToM4uqcUTkjYMrK4Om16r2tte571kbkITj9ZWkJO7TVjEuY0duVUOFAq+01yOS7bHBku8aT0fLbUusPJ4em//uyZFeABvdh2G5l4ADRzGs9zDwAUv2VWz2FgAH9rKz3sIABGDBlhubdtixt/iWq8nUlNK9XDSgeuIrxqxlhhxMyN9a1zXG6NbhPH1FMFjADf//QCHNJW23lKXC23HJJtutdWpKES9fURQ5KXFkwcBCUKMRDFtDA2nJeiTRvj0DlCqO5nLeK6fBvq9aPkB9CRRTVjbITdQG8sG0XtMK/Dm55WH6OWmMpD/dwVV3OHKz6VpxK5Wu13WIjXkNfZ3JxYoisgIltiwav/BevnrPhrc5pGyK1Qo71VJpliTPaMyikpbM09MuTItuFXKaVTsj5f3aWRm1S96vU7AWWWM9gSOcjg8UVHG6klUzU8dRnniyHKy5xGny2zRoNYzd39n0ObEzaEoxEEbgAAAwNMEsbgBHA6SxVKBUQiS0OJL3XZcb1OVl8GD8gsYgWWcYAMrEl5UVaI7CGfLUR9RVg1XodhPmTY66FHkmao33Sdc44a0eYaL242PTCyaUqqHfeujLFT73wa/TflEo2Inn3Bo/pid55JfkmNX7mtB/LzfZopHHPVZSvdvk4f3vcyYX9VCbTXO1XfBWXnan/4vk+yQdnDkcKRRKTgoBN8sqXQWmKDAoGJSKdlzA4Baq8C5YjZoHAvFgoDoTjDVHVYiHrNFUSh45RKYq1Tp2t2YKL0E8JDTPBa/Q6Goe/pY7/0IG3qR8PL9reqXzHNZ+lImtRIyXuWtbgUSOEfaG67rQU5Wo5eB3MXoNYhn4haAZx3t83gcazpNQAOrWEUTGLUCo0aUqGIL+VfxYRZ6YCwK34eZa9EJh+Cw1czkiM7zLK5aK6j2ZxihWA//uyRBsABD9e2OMJHFKTi9sMYYZ4UN1nX4wkzsoxMevw9hmQlSzRyTnNr+SBbYLvTWj9BTdGcztY1lduo9WAsh8EszsZXKK4imj47mzgjtTrtnNfNjZSdyQyikOVMmBo/FtQiJFQcIsEwk3HgMISiMfcjr5GuAJrRpOkAHRfrrVAhkb0NWJpINwTOVGmStGgV+rDATsqR+NEo7QOChYWkx+RdSPon17Lq6jUB0QT+nDbCzNLIGNRFbFoZAHuaW5d601VMitXlWlMyGnb5rX1qSLiqNOWo4ND2nDnmVni6lb1phvZ0tevpVpLcu+km6eRzrx+XzbiS6OHKSsb+uLqyzj5wMJ4ivYdJOgSi4AcAAIla2iqCNxZhkDXGFL/c71dwC9DfPwup+4CYmIS1aRPedaOLobBZeV2R+3CV3HLOP6C3c2StCHQXoyhlYn1NvYjWdI9r3OtCzajNlD9Obnd168UaRrwdBaBr3tpW+YmpbX7z/PPfM0t+zPOTbNlX/3raYnOE9MA8nJRNqhrM+r/NooNyNEQgAYDyBXGMJ4AwFwDjCEGmImS4WwuIip+ALVnIpYLIgtoHHwEkBWUmuBV33Rycg4wslpIsTqKJb/64ZklUJLOaW8NGsR+tVox4xRV+UopluWkxbtEze65ro4U5OafmRes9Fsu3S7/9vKp86VjY8dtzYzHt/95mAsKEImKb7kz4XNly+NZUA5iVQGeAwEsHUzS4CoRYrRx4kDFOJNOPglRP1CTtRkftzQbVQxwkAkpSIcft0UiViAkESGWXZ0YXJMwNBq9nFFHdkk5NObvD0csbdZAQyagXd2d3HQ1AlKk//uwRCsBBDJY1sMPMVCMa6rZYYZkEME/WQyYc8orLOtxh5lZXI3yqfGs7dJLg1yjjjtY/K7omUbjX760X7NFN2Tre//w1vuZp4byXocmlPSdMkbakIqUgAApQhsKiJAq0KrKql11HJiKK3qIxCyLUYfxkgxJUJZ2FEeVgQFkPmkSRWSUDRiBjnfUZBjzoPVOFWfUfAlGQnVSWU0Cg+JAZMPSUipszJswgvSL0m/rOZv3eirSjkyLkS7S10I35kYx0LzLSTxP2u211JVkb31qfKjRQfkdV1NktCsh8AHwHRCcViokBAosWycw40FEOLIVuLwVpsJls1qxtnEbil6BaGIw3S9lYTogcOWXF1NHZ+CVYsr0NsReGt7Si/ppAw/A6j0GEDgSqSGFURJDpgMVGqBS7kiNhgrTixpDY5phRsZ13N7e1BAGCNrHclaChJUNHGMM9hy0XW5X8BG1RF8irGKqvA69f5AJt0ElUAKQQISgRQLVSsQDuqjqmETEYKiQJYOopjnZ3JgiralP9GQFKNOoIWOOS3YL1DuOZIwespchRZGnx1W/jrhJiOVNnJF7CwO7R1j9GustoMfVXbDlyipHrjzaP+Sf2/aM8GlU9N5r74pdOwPhLcZA5pM0dGInRHdt2bedy8IM0UslFn1HdyhKQNQABACHEFnkHjWUNGvDa5i/gsSTL4gCCnqdGfeXB3ZBR153VpQOKJcqZaJN5u7KJUDYbLlPdUDkETzLcYJKttaSncLKusCjs32RILqZIotZakiM02hy5qfkJsY8wh7EqicNMUDiiT8L2dYh2TIz3ze7HFmX/pSHPAg7rOT9TxT/+7JEQAAEB1lWSwYc8IOKSu1hg1pQMWNbTDzFShOsa/WGGZEkACk2TESQAHEnmYkCFSlC3hXcnYsQmBG1GR6B8BoqDsfKIKpBE9F/sASLKE/tn1zPOLqKFUgosCgumBxRw4xqKfFiYxFuvRyhkzwqkBCjaqJtddiOxVqnSDlhDjT9KbRnNVzb9jtNIJBBZKM7BkSg6tDA1PGrRWHlMqT+FfVsHJfBcDNIr4ISQACoSKe9EwAgV8k8jBZwry0cx6SYqdGlMtXc3NYVokbIGBWdFiDTQLMLVMthH6iY51xylz7x1bh973a6nS2L0zMqjk3r0zvPMdHNhv/f1neK/2Hb5tUmk9QdskmrBEs2ZTc6f5vYmM+/7Pmubvb+ny08JhYkVLOOL907+cl4QknS0kkgUnWFI0hUiaC62HI/P2mmpw4ycKOLyRsGPmhs2TgOkGNg5FCyynRJMKmGhHHgJvHOdWHOpFPUuWy9MvbZnZsdomonuUOyc/KL8Fz8jV6VEbb5ivTJOzVPf3DeP9SZ0wbcdspyjpl/e34L77kVc/5vn9m1kyzNCKKKZpW7W/nfrkq5VZJAAUJEFxVcGWzExY7AlYEk12weXih6C2VhQRhGdEYxLZnRC5MPUGnT7K6JE6xZ/IEn29/uZrduFbqAsrdZS8fWoOLMySOMoR9si/TgnUxyDjGUDk3hiQ/u5aFLLs/b268Wu2aGUiMb9Z1QrSdTsqvKDUgjAEM67YhZ9iz6JcFtlomtGJAAAURPNyBlw6xwi50jRxQlsLjCfcuZEuYEwSDDiVCJyM+joRDiNGRasvJ1Sk3aaUWsjFikov2S8GNVax//+7JEYgAEIF1WUwwbcn7KysphI25P0WlbR5hxigykqmWWGWEFNsQRgs4djdXErckubEgnOqhMZyq0M4WfktRlUqRzWv/oQq5+lYzj5pxThvSOHozgVqJwoAaBspLDp8h7eqkKuUTIKKVPMCwD+AEQH05w0gzhbzHVAkpOyeNR0nmyJ1IKtxB34ESB8Ir56yL1MUuK13m0IMTnZlp9qiitZpqjSss7/+Q7K6MKKOqq4EJnQxk6maWmcOJo/5gLEHM1iQETrfRn6aoI8iX+SRY3ZxzsCSLFDKCXYD40F+umkvxACUAQAGJYUqwcgETGQSShqzjBRa9QpppeAC5BCBUHxutJoQGtyO6QCsuxgtCzBOKeyvWoYb6pU1JEtbEK4KyCj0YYl2gTXMt3kDGXNzkKyMknAGrP9ZHKXttnMbGfA5/qvOHI36uO52f/Wpnekr+PFK0XYJcxE4VSzHD+fnrS36t/95UwQjmEND1rTUvJTsAjaRbDBwD9rbZq2dXjNkqmhrphiBnlNmBcE2Renopo7Qi4zFDaO1I3pvlH7NJDNo1uIZyoqjM7ysUoKpUjsoq6stjEKJfjZLSUzOUi/UrnxEIUaeRYZD7WDvQjxg5GxRz7ebO3168Ui62rBuGhEj5GPLsZBk2kAKQKAAsRFLzr/P+1hC3o+wryOCzJspimN0m6FoJROc7Ah7Kg7UT1qXZQolSucWIBah6zL0xKGXvqzkXaevnpOpKXZKTaplosvMqi9d3u/8x3QsxLHbGxW71rac19Z9es7fGeP//f9X5Etpdtfx+zopMbOQv8Ts1OSdrvMub/XzfoBNOIItpIAqkgVMz/+7JEhwAEDmDY+wkb0IEKOqlh5i5QbYFZrDBtyfss6rGEjfAIMlOIgw00tEmmSCYm667VttnJ4fBWmbPnJDN4wajTuLzroEKzUSNdeFOz7bJWvb/WbWYE7nYUnbVx4gm1eqYFQYRXqmsmeJjpll05fPYr7Th8esnfLNVz9aZtditXMqyMj8ySkcJMiHDjvA45RJyzEGCWy7H2mfKQAFCQPkAdkBhAX6PL1ToBMVFXKVc37zpWofMgdSBqdMeXBDQkqsUbgatY2iU1AiJ3wU6uLKE0UNtjt6up2aUGLV3NM4ChdikDI16kkcnURByIhVDtVqocJvDU37SUMTusOf9+I9vtYFBkR1K7HaqLDO56B0EDmYBJvELjJRHWABwAAECQkDZgAMH2OLEp0wArYSZKocRQL2N+JBpl/rOnH7hphbuOdqZbFWm+SgI9LyeGIq7EiuIJmw8pKc2QnDBALmAg8zkDSOVBx/s5eg4Dpx8Hh8VqKvkipiTLl3nG8IKnxjyNR464HHCazFjGWNqXEb7W7SD2haihjrVV8oK3rB3vLMIwQjuxGHY1TH7MpyD1XVn8AGlBQACJSpCgn4dlm6brA5VBsjWsqgtCg7AsvHYwHNZ3o7821DX8KsV/dCLxqbmDasb0oSqymuq03J6/4g+5gzwp+f6kfkRnHWxJUUb3n8Jy3ucfzZOt/RPmd8Z0xPLH3RCDYMYcKiykgJUGoADgyZtk5z58JgyEteBasRgJmN4W3S/hbJ3QLjs+ys1W6PxIq8ricNRGAocAEsmRYsnDc/BWHHr/oq3IGmOVUbzmI6FvOdgTdwr2SAW40g+PE7vzM8b/+7JkrAAEsF7TywZFQmkpeqlhg1oR8ZNRLJkVQZ6s67TwipEZ1Z3lMkKKl9tF4hF1lC/wPepSh3VXU33I/jnFuIasgq94it6vKDcsaIwrVUanN33M1wtY3i1RAUlTuSSSSULqCyAby8sJwHWiRcS9yAsyuDGK0iaJpXraag7PNuc3ATNIu1skYrREYG16AqEzuSaR8ADm0ajGnYYyc+fIqJSVRxS6JhnetNXn3rdFWzP6Ez9U6q907euxy4sPIu5L8aoAEHAFlIkEmBdSLDBz+w/CV8/xeljJMiSpUF+kfgYDCFsdpoTIH1fDLkGsycW6/UPq5MZz5ASw+vRdJDPbsEn4pubKCUOiotsD7/Se10k0vNtUZ1cUP5NM9BKJsq3/G1tTc59Tk/Ztdqo7NNnz11hV035isZ9cCvwI3UdFJIC1oPs5Y2Oosp0g/v1qRBiEltaeUiIIEFkCfFxPAOIGwLAohXiKQIcE45y/KtuZYbxx3K5y2TiXft23qTwoyC3UxdBCyUWYrhn5GYZT2BgPVNo75HD7GfK+5uLVTtdUfIiTE3v/Z372voXs2/KT/LVucZQmDzDkSvT/qACgBlI8YFDTv7WqYpDJSQgtUNEsmRDV+7zDYaYM8qpw0CYChE+oEjXGkNP+kkf9TF9oxm6xCQ48Ru/D4WRCNcLEuwXJPWpD10i/dH4UCvr0+sZf2zUfXg3ldD6y8fJQ31HLO6fkt9a0Mbcz6/74r8/f22v2fPt/+5xvKmsMihyJ1fTM2Z0CbAvaFZ6AJwAAACHJBik5nwzBiZAiAjH2SvSudMVRh4BCsGWtAyJbBWSTdXF87NLXcK7/+7Jk2AMEZ13U6wlFQmrq6w08YqkRcXNPDLDPCiUsaSWUjrDlToxHijYoc+kDoTcofR74ruWrsNc9JWKF+MwbfWa/Yj2z9Q3oZe05uuSFrWdPdOFs7sJeerunJufazEYgFlDJshDECLKsS8YUkdPV/tnQd7YeDS6hXtILF7U3KtowdFFmAUlTDe0zELMpCTHBcwkjEbOWVbkFSLAOWlksgIcGTusGU3GksCKA2cQqZiDYJc0WC+VmAQO968+JjzyQ5OHY3SGq0QlJwsLp+XnYQ4SVsWXHi0xZM7AS0S/nwUo4uJZ08hsh7DSidY8wedkLxDSfg8qI6YsNf9QomYvxkdUJq6hBV1gUpHMi2f1ufvdT2vn07vr5tW+6vrF2yzsy1WYI3TIBijQ6xRGI7rKGf3gRIAAQQUYMyOTgHo/EERBRKeifyiksVEQKkyBTc2+fdtrcXalT8o/m7EDyimtWDw1PGeL9W1/UwMhtI3j4gR+K3BSZPlpzNMXEoFGxupQnLMM2TisgISY8JyIM3b54Q1CAUvkoivDd4ZvbYuJ4flzIvKl/z0ISjEBVBp4KLncl/X/30QECIAAJhBBZWZWiaAOJ4jEBRkOnAxQSLniHSdzAcCIFEQ4wVUoxLEGNqEfg+kauJV2nH7m5PXzWnFza0r6SOeSbgoTjJpL5o8/XPtqWgRz01a4DrLsSqGO3lvO0BWXogP+xFe7lr7du+r5QPed7ftrSxH55dfaax5eO2V+W2vZl9/986lZ5KaMRzGXTeNT7v9/qf4v85KAFIAAAAAUMKDAiAAxhNAhJBpJHkKAUgkLYAIQbxF34FCADdUuGvJ//+7Jk+QQFhVhQA3hiYIOLKmpgw6hS1ZtJTTzJwi2n6OmjDqlt9Zg7dFG6BrdSpYJGwZdWizAVHYXZ0VywNx21cHpMWc3pKnmP0ZpbzSG9yJcuydQmQMzNYaxBwcyC1lCqfKMOys3zW2bSe+uCDBVJxU8WMZBKy/4Fg16lApdUsf4k4Zf2trOS1QAAcwkEQwvjJ7FIAYPD5iIPA0AGDwsYVBYsWo2Xa7TPuvhCOdX/DrQh4CMlXDbTufZM12ozSRXK22WQyYgDpxiYeMCxlQEgLFoaJodAFRJAPyDzHFLx2CpEr5kIJsQsu7LHBZmSM7lNKqTIXda3n5+w5XtN+6oTz+t2dQEDw5egrPFoWSDZoNgwdPhAPVnscKuhUWBirFCdLr4EKkUD+hzKTITtW2AgnBJKKbg46WHzeUJ4EJBnECip08ai5q2HHSNdhlMw3rFGlt2lYgkUDFadGULxyRgKd6tH/bkjqLH1gvcS2EfuvlHsbZVwlLulWYxjb9trpF4xcHZpjV6NhzksfpdZTJz4fflEUruVr8u74c8Y+tRMqFd594Z3VcRP0Mzbd3YBmABYGHcxgmzH9EMuD4QDgQAoLk0znA9JPNHxC5urIk0hINl6gjIYPIj0Q29sQ0vgvhEmWQbMWM2QxvERDgGUcyhIPOk22dgFRQzayROyqQBNBwuCJlx82RbiYeZtG8V8uwIJQWZYkgBtfUk+3178kCrW1EcYq9h8Taf5FFl0zknWRfOgY/Wj8tZn20xk6mltzfCsUvpzll50oyL1spv8Yp5D7hPJSDS5xQAyAAoAkqDpktqYMCdoOOgzBgS9IyEhhxGdoFr/+7Jk9Q4FK2DQk4kd0n6JCmpnBhxVSXNATmUnwgQsKSmkjiDqFADziQJ/nXwaCzWlIGip5oBoHovj6mmlNXIsRS3G6YmqCjzkk+Du5kkampudgahIGAQ4Y3I2pncMtdLG+IUVieMKKRTL+dGzXodrnXnnBJbVmTl2yyOGpF2BSBqkFRHGkdhyhCoAMAEUAADDClgxEGCz6EV53RCIxlYIILDERKwRAjPFdvQpalogPRqYI7a1C8CX9i+xtiqWF2HY3G4RJ3cUlETsQx/MpMFi1fCoBmfHRxe9aurY5oTd9yd2p/u2KbcVaozq5fNyy58FuxpGm9qleaC0aORamfQ3SNI/+N6Ga+jH+KfsYj/rz2KnXRz7v+53luXXmG7uZvkK/lfVU8r2mQzCcPHNSfkEAEoAmSASqpSZOA+mciaNqOKxkRzAFXGq5mUNrWexGjb/OFCGrWBhwrTh+QGXEyEwAgopkEECTIPBJveWbc0kk59xWFbSJoqhYbcIzO3mUKKzlN5HVHo2hK/5G8yr/NPJacPnIuxyN+UpUyPtpXMMrBDNtAU4YgxrTEU9SdzugQJACxETAUODApPKk9M0BoUCYOEYBChg4PBg0UIQBqIXko2EI/lAAVinoQhmjq8mMFvaog9NmVy/9ramqIkjsYNLB7HUTVVT4jI/Ho5VWO15Xjzms98/e/SBalYJUpgReFyTyAid5YsPnA7D11RyS+7g5B36Ueyozp7jQH7Gff9Bf+gh9WSxgQrGwk+kB6ntLmZboBEFb+VYOxAIV85DOTLRx7ZvDf99107ACIABABw+UTgEB3Il2Y1RggEBbMVL4gQBykn/+7Jk9IAFMWDQ02w1wH4L2kpkw4pVRZ1CzjDWgfus6JmUjpgDkDK5pekmZc+dJbvQ/DTMI7MzkmD52a8Uy5jMhWIcWjmX+v6X61Q6+ejhA4rOFcPoqmQB4yyhCVZITyqb5uf0siyh5lOwrHM0lOua55Hz79z3PQvveh3u71iDh3EjgIhRuiS0VSAAYAAyiCC4mGLIIgEzRKk00XGQItGMjI8Hkw5TlpIYWWioz6BkWZRLLzcF5zunrlb8x3G0vQ8Ggw5Rg/PEhS55Qoh8dRTl3U+jp1PxUKXL/9jbuA0x107tJV+3U0GKMbXzPcGr2rvf0q/a+WqK4dN36TaU/NXb7TP8KOSwpybp4aLpjsw8dw+vLx+p99PFpHCRVRMJrdm2lbUpR/fi21P20Dtb0ZxAR3ty66JlTg7gJkdCsgry8JImEERIUBDwUgaQgOLjJMK5IfdCBUjVYQkdwSQo17VSXqWK6SK2Zksh4m9qUX8sSmXERxULMK9NAxpmu42jv97V+6+/5nqqEelsxuldoHJESlLnmVJ4tFoIkano0jAGiPCktJKiyEOAmDSSxojBFucOkXFSzEg+vH1X/C95gAIAgEZNxpQEByd8RHlkwCPmHmJDSToGOWbgIPWJLmFrAISmlrVbSBlFZTRexls7HINdfU7jdUfltOsiLV23iV5Yoc3px/GhQchVySTZbMyJa3frR/qh91KACFM0jo3c1xQeYRmE5+YshtZfN7DsqbZ3dJHzSZBV+W35UJ1mrKop2Q4euNwrCMpedqTJuDiQCfTzvZbnIuCAHwYSO3ISLZq3vGb9PcpihYTgIQ6UaTxp2CqCHIT/+7Jk9QAFMGLS62llco5MSu09KG1VAYtDDaTXgeis6VmUjfhGorwO/DtR8dBk6lTqMTvsfGx0DTZVlpxAC1/Fk8gggUzKXj2J6RoHkiNhNLz+3kJNfIRN77h/v9YWE5/pEHdSDTNuCHGFAtikhEE+oW8zvI/ObTvkvXP73ql7GdhkXTLNwE6CAzDwKoCqg30qAhIAADplpjD4/NMWIWcxgcYoCDDowP44JcgxOU5dpNZPZPoWerHTuMmkyWiuUWKzLMrcOAaOmf1e8nIQI90jKNN9zpWszXXDYHutsTLROmXIhMSK1NQ3vtNFtsIHyLGdmjkl1ULcfAChfqwrbIp77IS2zapqRNB/WQS2TKzeIUUPbpfmnK+as/SJ3uGupY7ekJ+/cavrCfOibQ7CCha16XrAMgGcYCamOFDF3E7kBqDIOBlgKYQIqxqYwGlQqFRlSObK+1Rwe2EzLK5Q2hL0IlYvxeUbd70jqkZgnXFRhKPqG+HqNf2NRyCmKV7j03sU6k5Ih5qMGZVdldDaae65bLPaNKxfp6leU+4ksvlcvQfz3NNyzvoHVMBj1c9hjeei8ACAARh4UmPQeOkEzhbhKqEAfGQIFSqYaFoQK4wAVq2r1JgF5Er0No8ydty2KP0X+agmAYg5b6w1lbT8k9uy68unuQ2yCPn6Jk2e8fvqpCLE7MuXQeUiqEiu3pKUqNb/F29FVdCwp1lEttHNr2SQ3wWzpGneyqD8kRbcLzU09fU5563Niv66lf3GqSxXKk/ZTq8rWEpU0xqQeQ5UsfTRo2KphiNAgQCAAaeghfM8hi9YEFgCNFAsk8l0hbFBCOv+niv/+7Jk8QgFClrQs5hJ8H8ruklpI44UfXlBLmEpwfEraGG0jlAYaOX9KAB4mdrcpodc2ISIFAF4bppDIqiVO7s/0cNgdJRNKRR3xIuCbXoZgQhRQsfgk4tBibPjlECU+ZvMs/lK0xIPf1nkcP4ZtVL8lLjr7N8I9s8mMtlzYd4VcyssugQAAgFGGIJQ89mfKZiyCE6IUKgYDGbDBtwD/yAcyDnZexg6ykV0sEKadlosUMBNDvR5jLHXSrQ2807gsqTVCgeaNxIRjrKLH7TNgOtqJGBnEw2Jk1SG7yTGqYdJENOUFWqCbXaSM75wN5Bqum9K8Lj47kJHGbUxfXsMuoZMtZmyxDBJ8onF/UpvpDKdW7OnNbPkcuKGexS+SUfOAJQJqOyFTupU+qJGenURfydwREbKv4lSOyGZOIFSissgAQGQkxKhAIcoB0BeARG6SuXoXs6lIXRslUkImNHK4s3Mqw1Iewr0XcksRFtaoG0NiSp7guhz82Oe275c64Z5qLodY0g6L77umrirv0+e2EaJSkeKloHytf9jp1yr79dvg6Uo6Z49b0P1OUyBgBMPDIMFxYMMCDMyLpNThvEQYAopTEMgjEIHzEEBC9w8CQmVM5eQNwHTSJf9cCRA30uAUXjT7BYaWifj2Q0zvttw3UjkWZTCqPkddt4ZZPPs43zLetpLchWJkVqmBmWnhYj5QYIR3QeVnJACIK6iAQGWsA4RaxxaXg+bWnAST7aLcqYIz8yBbEMT2UcE7PpVmNocf6arxhH0dYapH4+K6uTprff3zn/U6V2JCfhZ5sWNPedFDtmoBxAQSySnRELM7MB24xp2NBX/+7Jk+AQFZl7Pu3lJ8nuLKhJliIIW0Wk2LuEr0eCe6KmkjihKW4VVQvciGwSPdFL9haH005/t0cG2aFiRlACgwRpFfUpc403CdbP1PN3O6FklXAuY7be1COKo7jyptoIFTsa1SiGkMlsKFucr0+z6MzACSRDtjkFQYaYz5UWe8veSNCVIMgYoCtHRAEwLPwxeBIxtI43m3E19Cgx0G0xIGEwPPMsFAgiLeCQhYFTXDnTKeAV6wQyk/qd4vGZqhRtES04MPcxWxHxVF65d0REufAgd5XLpohyTFiaFcqB+M8hQncbTIlU6ZOG8ZpgPIkNzbIx+IFCo71TkPd0bGM/t6HjP4CnOGsBuVG++jsdpWaKqJVMczZPCTisbvCUb2bbC9t8obH8rXAw8nv86c9+C/iXhxJrdgf0+pn3rLufNb48uKa9sQvhnk8NxtfE/gYlh7xrOtYpE1cMZ0gAYCikW1MDEDjPSMFpwVGiLLlup7tu3wUEfsQAxYAtky4PC1iTvaYPWKvAxTR5jAnNnuwUE7wKhkH1Zu0IOcmR6pPc++4RGIklzJnuRGNQCVGKGj2xK03oWeTpAz3mADO2GRdOFgKtSz9z6OsgAAkxDQz8MRG5jmx+I3cZgB46ATIwGPMMfkAyIhET6fgODEIiWZuAF8F/PCZgCgiopoUDbCyGZfiNutLcWGO1K0A4RH2VASB9DTKyCgcFIMZMiFDoxLs4WchaaYMQpEbCdLhUB5LCcdilE0Y1IgV802owXA0vPmp9YRahhk5s9TH6bqHIRGYxEiuPIBPPz8P4Yz8hVfP1v/frPHUe/IusUqRgkBGUk1BXpxjD/+7Jk9AyGf2NMi7l6ZGxmmkplg2YWKXc4bmUnyfGrZ82njagtoeZj/7IAABcFZhjM4Hen1JFnDFMgUVZYugSHuAZEm+hVDSUCsxJVGFxC3foqRhTycJKzOn0C0NXwo6RvDvXGd+AqppYYMUglnHjvQL/PDZHUa5hC2IpY/qfmiR9C/Oc/77w+5l/5TvfvUBG1jubJ7ES5FXvsCEhJ4WNidE6I51neAEw9LUSUQxWYI2E2o0DSowjIwwIDIxtH4w2Hwx+AJIIZDkuEXMMIYsLGi8AySy6wwGKNl1ASziHxQMwSUI0/XZe1p1PBAqE4ml3QO8zz5O4z99eTLsWrOVErHK79oxWvkGJi8tPGSQwNRwmfbHkDgfQGBbAGqPIjRIJSEowvGmQCPVCTzvRGDXlKi37VXdiGhH92Srb+IBy7LUJjaqLZ14lMSy7M2pu7/x5uLfx+0wzeH24rW/J+UKu1gO678HNB7hL497W8zgAEJEkllzjpwzjQIDHTJKBQKCjLv3kzm9BwSClY2yL1qNPbGxOLZ0Fq1hKHEo7EuDI8cECYXJdcISCUPWoSrM55W+bnTpkf4IWLVhCzr64tdGr9109H+vNbV7r5UoU1iMR37SNbclQs5igjEPZasFfC4fpCgoyzBYEMMq4yFnDXgNDGcYEAgNP5gkchBNQOGAMnRAzIUngKAgMG2ntBXeCAQnGsypdSPg5osoeoKli1BAwwvHg8PKCpaR+8kOdKETaVafBCYEM+pxYNDunWtNBM3KPIj2rJqVn7LCTA/HA9z7lenPP3OrgYszY4SePvxDeehe+YepzJ7LLu5NHyaeiCiD6LkYj/+7Jk5o4GOVvMi7li9nLrujpoYqpVNXM6TjEVSewsqamUDnSIQRIug4ubeOAUB4hjCd9Dz+ZsAHz20AjFoaJhJjbkgRknCaScKOqcLrNYh6JoXzqesZVqlcWcuH4xVjEnp7xAeEodCfcCQPSLhT0oiqdRsVxf9V1NxYzm/ubdLyTRgs5QRlHiENeylH0dhJfrktyPPJNwWjvOEfvksyTuSEWc82RM4W566LkaKDehx0WAYfTVTQgAAAxmiCamOmIuxh0OT/hnYSLBRmBIGZMKVaE20YWAprEok4wfJ9WWssJQsUTxvxBQ9voB7AkKosVF6LMpifkOFY86JYtMaauOG2bVNugLildAjSmEY5rF+yqR1lDgSSdiWfUYQ1cfWbH/kqFMVMMF1ZWM9uWptGEfSSMmyUc0cmaKZlszcy5Mc2UqrrvLmIU5b/qed4Xb0xuESzGalQqtY8efCP5GLPlYGEHNvlhjCAUOiYW78zBWc/J9kgr/SBAgBAJSKpUYgS2aCUAz4yGAAgQglrrSdRqQ8MgYuYpmAgjYWIPlCFw7JhxQDCQkFjRYhOIcne5v1CXJ3rGPnfy9Y5p7YsxNna+3NO+7ONFI8bgQzbN/bO+jUfRuJ5bdjWY4L3ac6Uqy+9h51G17Uy3vwx1m+dFkLyjtvHXuONmI7N4phDhQwwkRawjNKTGuAYtMBpOh306VLPXHvG7xxyPKM33YunIrNiQVQMHCoDIsxEWDBV/MAGUGAYDjmzkIYRb5JB+i+LKE4EdC7a5n5fdgQqQnOpxZWRHVM5t1sU/cIL1yQI5YI90N4fK2Ee8WmtWHlojxIrEovWgXlQ3/+7Jk3oQF/WbPM3hh8KksyhpozIpWmXs8rmWFwd4saSWDDqj9C1tHiAbI5YVsyCoOIWrk5wqcXmhrGVxJYyy1Wvq/EXY4bnMUwrlv66j5kpon5Q/ysm6dTekUUuKn6uwrq1gu1PutVu3DiVadNfWD+ZiPnqqChb2HtmZiflpt1RsclyqgJYamzARDUaIjCbxkgRDQkEu1/lIv4kFXYkvBmODNb0Yk2ExPyuvSuTNxK0BlLNqp/yt1msvW8NGOM1JkFlB8saVOd/2fPnAwcN5HOYJptJaDG3Xdamh+k/SfZef9t7IVrX1X1Ms1nkf1Rrl/EK5CTgwfcGlhS6kCCAgEYUzGElBhygaB8mxkZlCAYeGiJRIkCd8eDYZPNeUzSOTHFgYZc9L0CArGb2SJvL5VNGotHea08GN8sEAyYtUhhBVVuNCchcothdyeGzKkhSOYBIbaaOC55FJGsKDKZgc2yhFvRh8zqZj/rAr7KqMbjBE/rhUaljSn4LLNbBBeJKNsYhRp+fY04VEyP43fTdmKdN1xBeHI9xtOM1EIPDImaCxKC1dWedWnVUPtJsvTrUA9ALZKRKiQpjxGaiGLpFJZ6QSNXKBWaqwytP2BV3Sqlf6XRvNHVInAC6awajCjyratfVXR83Q6vLRixIYB/HtRFUiCrOqqUQZDOxfj3WiLl573VWROttP6RzxXqpsQFc0qUEmQvD52FofEB7j+MHIET1kVv5mEUAMCZkSDKbIRSRPhGfCrTjFj4ysQDDJa5d9WNR9ZSUzN4ZbdpS6DBQBLmbm2tM5aE3SF3ETkQTJjVDLZad2wkIugeHR/0Z4eKdXnuwv/+7Jku4gFm2LPM3lJ8HWrqlpkxYYUVXk6TbDVQZwRaFmsGHCw/LCG3AQANP288Wx7wklmX26WgJSFFKVfF15/qEAaE4nGs51c85GD7mfANWzNY+VjCy62p/MJEq6aM8pMyno/OUlDmjYSe2vDgEnMJ72fleUWXTFYQmFQAYKGrPmPhmrCGtpK0HLWGTVcSRQNk7jQ2mxJznAfpi209KI2SIBWChSRkQFGILksuM/bbnMb8r9eRjbzgcgLBkcIVF3jFBEuUeYnvrBK4+KPmypsRNlZFiTt6SsNDBeGqXNpSgEAIRjAzAQTB8kNL+YqCgyobQKDjKYkMqBwOCAOIYCKCMoVySiSbFiJ/MsRHATVN1XUkZaa3zCJU4Ex2rK6TkmgikgftVnlFRMhQrJtkKrzwqEDZ1nW8QIlZDy7f6ya80zJqsFTfvkcdTFYljBfM7RtnNI37UXs3FdfxlGkgLiruNT/puNRnKCU2fRMzLUL79S35WQhNDupoM2qIdiFsV64hDOxXTQwkfisSxToqIISiRUDjSRpIAQLBE0UnIZQwdR905e91VxFgoSB6zxyekarnVs+hsZE0keXOaVm9mBEO+ja0RxpRmUpqKg/FOpipsd7uqfczFldll62VaIqORfeoPvmQzaov1Uu5eX+xRFA73Wn0gAwACQkm6FTsSUDEoY2GMNaNi4JcoEJoCJiIYZyFQ9VqtyMTRGRFAQyS9DKrnCe/bY6Rt49JpotURHXKEZUe2UhFq6d/mZGKWfu9Q9lK3BtNAjjyQTynAtmFB1C9Qi877UN8IzmR19wVtLv5B3aTjQrh9YhLfzQ6Sxw2JWbk17/+7JkyYAFbl7Nk5hKcGYrKo1hgmkTGX0/TaUVQY4XKnWHjLzyIfauohli3a9etioxUPDNh5rar+x1KfTw4Ak/DNk7HU71UhAAcGn03FMh2K4vmWbScZTDaCkpc4y4qmM0OEA9mtkU1pcIdlg/1wXsgglWjLebGc7Jav9p+n4l198lEgUXOR4C112Q4k0p7pLW5jB6muCoLJXvHJDpIAtgF1UATHklMZlIwjEjx+fPKAkzuHDBwkNCPIw+ATNABAoHMIBhMslHByhfYA2BdEMjUkBjjeOM4VA6TDhaijKmlP65TbN5FYkv6HJG7UVw3TN7F8qJij+4XGxx63ZfEtt5DMj55ChXFrQ7T41qUVzclDsUHByDsXOPE0iObS62yFl4pcEeCWlrlZYSRQQ+TZ3346HL8PUtszVnasnlpv2x3tn83lJvv/Nc7NveYevM2bviErrjaB23kX8d4wAD7BoULojQuRsuDtIMLgQAZlYXwQHKEs8qstTqAzd31nwy8KYFhwsKGCD6hYcEipQ3TSyBhh6qqV7IzufrR6rcxzeraZrfjH73zOlL9UYivyLaIDAJk5Qq7XBKkgNCFdh5kxaPBszn/jx+rW/benfbLsASqYkLJlEUmMx4aJsY4BjK4fBQ5MmkIwgEului36Ta4FDxkSAIp/PU7DyZZfu5brrjWtHWmxaN2JSpg89cRQ16y4Rh1UPQ6zV0KInreZm2qfHfSiEjrmj9VmNTNDbLWCCJK0ZLZwihTqRqajamTb9Ivly7z307cfNHQ4q/J18Kwt9zxHXn6qbrlrdSeNOm1FQ6CDXM2WgbUpb+jB4wxJHksioIIAD/+7Bk6IpFyllLi5li8nHnudJpI5ZUWXk27mFnwc0tJ12klhiToyvMdtUsEZFVAyx9SoGvVAWRKTRvh9KRdo4UY24zKXGVzsBJFkbKKyVMuNNFoJppLwTVpsecPOeViTC2peiJUS9uzsro6o7VbnbRKqUc8rO1HyuacQ7F6OQrLtRGZq1+VF7F7o6OkEEyLHscHoT1qgAAClQMspvpsCOrNTQTFRdWUzZlMDH0hZGrTAasTPAUKln1TApSQHgPQfzhOujzIyYaaIQqW52W5uYqIdGZ/BVy1m8aNHy+zrb+LDxRx1E7FWt5XCmr0g68kW27TS69IWtami/Ntel3se/rHzvWcfW5t+uNVcG+Lm9f7PIG9t7PX7z/uTGsatv4v/mv8LOYny4W/x37+Vr3qIhMB/HFgkXJMWfNdpcAQbMkYjUxMwRaOFfzm1k0M3MIHQC4mDHrFUmBQHlzclYjBRRvgUZAIISEgAuDkPAxFYI0W1XuDjFYVQUTFO1JeqW71i8WG2xX+49ZcwnsHVJca6uvratiS3vS8W8Jxtu2oefAbNfwYPxj/7lj59L/53b/evrP1K8lr7Vt/TVfDj6+fv5p/TU98wLZ1XWPJWDTeZr7/j68CLb0Zd7zKA7pwv/AFJCAQAAwERUAUdjKZaNBFk4MLjVbyMRLsdHRQAxgUmBhEOkBB4toXbFiOJFYwMHTDoAEQiZKEhBdQ0MOb4u4gIVIRAF9wxRSJd9M2MPiv8lDDkmiprJuBVAzSgzt+05F0MPgbYsGougeyc0wiBEhqaW4EPylncoe+qm4rl9mVsGiqerhJdKwNZkEvbTCzT09PNrxp//7skTugAUwW02dbeAAoot5oq28AGKFlTz5zIAEazKoNzeAAG3TqZmwCB3FYY5UxKIdVw8eEqmc3kr+1B+pHGqkgjN6H5G+LRJLAEejUDwFasTm5+MS7dvG5Rxukf+OUkERiWyCyxaZkcP09x945EXohMAvLKmCPxm7+tVb2XKlV75PG6akjEUqSizuk1rUejFqxcgOcvxuk7R2w5//u//h9D9YABAAaSIpGQjEQaDQsBg4uJhRkC4AT4zENNxQgQIFnwgTHhIBRJpQ8n2qwwkDTkM6SAcagIIWGRHQ2MYUD3qWcqd9EvocEpLxKJNlYM7keQrCGW2mQzITbdy0xHXh5kqZ6ebAU+2KvQXIR2YYmvGn7hUek7iV3SNJwg8dSQpWWsweRsDxu5TrvnodmqSWM8RHr0alDdXHhuDn+fZajFV6v5K4vD/aj/uXD6/GoPA+z/SKXq4iDoRWG5C6CrG5e0WMSy9G6fKNw/bjFIxN38YtBUFPrXZfL7ED0sAyiLO44zuSl8ZnHeGMbm375e5hqxqkUsVJF5GxhCiafx0XXkEDyyasSN1H3eemYnegWLyeMavhD//dd/9APuA9dQCFwAAAKeToOuzmaCAh7fAaCTSrgMIXCx5hKJ7qShOaGRaiWgL4VzWrFh5NFmbW57NaFAqwafWvFs4x39bYs26+5N7zi/vf+VsU/n1rO/Rsh+E2MkS1I9/6XZ4OH/1Do/gw4VYU0PGNR74bZrt8uUQ9orHineWanjIu3csBRx5ple8XarcnzxWNWYCgh1ZH6jcIlR636jbYLPCSp1Ms090PDgEkK9IE6EYYlaoEW1IhFjvNtf/7skRaAAYcaFTXYeAAwMwKmezgAFKJb1MssM/KTS4qmZSaMaXGkvvSgq2ee2pJYjc/knAATAAAXBjBvTGRAVSAxMqtLJQcXMikDr2JtlbdlrV2lXnFRCCMKSpq7zU1FNymbd6WWey69WprUqtUtXkhrY7pq9WPxmM01NnrXM+3+d1fry21W3lj3uda7SUudJZ+mq933KvParVf3hhbxw1S3Nc+pzD7nfxq/hG6WITtuUzmd34xXnMOw/rO/G52VXr9+3alGOdPjjRZS3LDGQT8bt5Y5RmluYVqaUvc5EqzpWmfu5Gbl6pMvfP0tzORaE5wUNUAgQCkABETBmlnPAZ5AVcJAxCCCg0y4iCoyIhxHISLV81d/BiC4ElJ4dC1Q4dJW3Aa29ykhMgahy7pGpf5e0tb37t+mH7P87A0YTuZS37K2pfWC6Ztmnd39oV/9QIesTR7zlc8g26jYk8Tmv2gpRbHTu3Pjd9Ugl0nzSyk/GGucy3+GNpF0RpOTjErhK0ZFERW/L/50IUQAEBShGkBqAeuFQEd0XVsl5wgddqYjSAsGt6nWuzTUwzeiJBWBR8xAeEZMDZLEZZXO+qj7No0E4oLFCbH8ZZSu47WXJj1fLrd+MxOEQDr44HNqtHDm+e0Defh3Ysu/yZuzqMYLLQ8Y34x0eim+fYhtte/tyvczscpI4vN3nthEkeYBwEgkk8wvAsxsSp411pr8QMAAIEy2rMlEjDgI3QJFAmIJiKDTCxFF1qm06Acl87AQIuELQjUNtHlxeGTnixKuBcvATLXJe1KpZZ2ulh4uWxTUioq9P363s06T72TUz/Ziv8wL95pyP/7smQrhAUnY1PDeGDggCu6vGUoiBNReU7NMNbB9K6qXaYKMeccgehhHlT2PuzjIdR+zjPZJ0qmeJ2TS+4hEudXQWmFdWKbOUnaM9Y9VKu+G/LrWcYbg+cK9/cM8jtnR1gDN3nnaO7O19qFr86enYqW1kFsgKC8kCNc0JFgNjgYCVDAMUuRAm+rLkingVe77yRWFxtpLQPFYBFBXqhPgsDDWooTHx3oHsVMmV8amQbmfP+1eSHAStrE8TPIhJf3MMWd223PyYs/PUceWt+srT9dU3td8d6y15dfMpzBvrM8Y3iovEM82s0PrKTrGE2bPRSaEK5AjsNgdiMUlOGvM4ABBZSsONFrg4EZAsSAlQGBGmAAlwjBgiyMPtzSc5XbPuVSagkDc7rUsOQRSesdMEje4O+LrM3gLRk9VpuLa/Corpk3wOBFe2vt2yxtuadWsS3vz5zLn91pbdP+//MT+HNvZ2ecxu7NnJEq9fOVDO8s/NjcfTuyW7VJNTwTI4eRMWkmCa8JlUSJB9T4TrAEgpUQGYKagiHqbeDQJH8oMu4kamSj8jjMI7sEeyMv1TTSMNVacBGbNxlO54YNXrsLf5ae278EzC6ez371jluZTUZ6pKATGsOrQc/Z+iHQJqpqu86B+1lf09YMiMiO+rZWZVtKXreqLmsq6suhno6WLWGASEPUsU9idvfiugZVc1Ys8Jo1804SI0JsAjzAlFtpUt2NSWcoLJcGcpeRK4ntg2BL3OgcpodJZruK4b2uNZ+mxxEBDXWhoeByIdaZ0K11cn9+rSwbH/M66TWSsbbzPI62v2qosdy0xfsxtXTch8p9dvK8kv/7skQ0hERAXlMTWEHwlcvac2WIehJ9a0zNJRUiMK3pnaMPGLLTo2rHLajP5lVX1iVc6r9VGUopbUJRUVHxupuaq+8FyRJQx0jJFMaEgwN0UAmAQhIckDaaPbAp0GghYFINTIDBFG5eAuQR7HARwgZiIQdLU5kfyriw7l2DvqykKt9dhxChfGUTCFHNMnC5oAUL2kn8qxIqphIx5FA/WIGgtZioUllNpvVYj2GL0rWwMiCRpbJfjGm3xg8pkHrVi1dTrt3cqKnq1x8pVhNZTDho5ph6tzaMFqRArkMBLDesgDDEd0ygZZLIA4YKhC0xWHW8gACo5KgvAgukk4rMHsdys4zHr17Caa2+oWPzGcsRmFlU78ECF+nU20KzFSUnK2JZXaLihJpxVCnk7RR0oLzNh813DlHQxMLsbB0kvUG17HMVJ1yFUNUrnUdesHNEM9Ws0NtnnjhL24mLlVW6Juj7cgWmRgSApJDkVvyogCibboEwAmG00CKwwgY0irAMAAsUVAYMuJHk1V4GABl9AwWNDndXinwuxuVVzZdSzbWoS8LuU2Lw5/ANr8+d+8aBLdJxqjGo8gkq1G5fihyTP2nM9Z9HzsEv8bVf7OTDFlQu2X7NTM4DGoOGeTDGTMkuZJkDWGx7Glbvt1VXK2hsKzEDaAMDPmJKS64AKJlUwF2NDIzFkE81mMANDAAoBMRMCG14MWy4e4EeDHEFTpgBfSUakqhK0L09JqRulCLDGnFZKkw8nYckWYILiGq9cZUlujMit52Fru0zd0sOnHDQmeZChsvqGS62Ofg3meETPlH4zq8GypzmUH8K1e92zQ+/9Y77P//7smQ9DATiYFGbeFnyemUabW8MHlPFjUZtZQfB2Czr9YSKNJnre2tks/n6rhi971zf6OGWTGuzU6b1nJjVPPvOqxwP6/ZAGAAAACvjbqbZncAZGYmGlQNiK6XuGZYJTHPa9iAhAkmTCWrObTxoo3ZpHvaFK2iWOQfpSfHNooUOuwbPOrGGueZSd934ItQdgydmdBmY/dqkbbvLLtj+0avMxPzzeP4Z9E0/Bu9+6zBX+qUOc+3Dt31n78qbXo/nOKAFJpPGUeHDGjxQ/hcxBkYRGONmCGj0g0iezgGrDGSW8KhG0oaIIEFguWBgZa1Dkvy/BEOR93G8aAhbFaisl6sKAyDcOovCWZSDcIhBFxeHIu1L4pRBwXPXEXHiFKg/A2tZ9T96FjPXbkaMrLu/m/p9rIM675WqxI/1BHcVWMjqJu4irg0c+oneu5H4LxHWxcWRZDlzpGpKdrcocVBGVBNxbTTu/+u8yBVDzmHtUcdJl/Auhiyb3I0qBJJ+4ckFJE3mpoAWaP9kFtRpwyOWZYUbjGrIc9nsDJzyqdd9p/1sbYPzjHNz0inwQQqQStOjspC9c5D2BubdUUyVjak0otB+ybIWS2RlbpK1TOlhsS73FH1Ot6oBtNpQwdyBQ2DTYFlRppIQiIBmKoOLEBRbI0INpjFpCQcHBkwdZ0J9awXQ8CtNyxFJmA3kWgCCXUTxAw9cjn2QgbPKFTpRIHA6k45MVChctuPqWaruri/RfEHSku4JDvV7tr2/Bw7zV10nXsdybVzRKW4v5J8VlRZfsbyz+Kftiudtvl83Js+46fLZmWEKaRqrtLkk4j7B6pWSInwAb//7smRPAAS0XFIbeFlwcOu6p2WFiROti1NMpNOB/C1rKZSiFZRnNCYS/CAUqotCdFKlDjCVkJGMogd1LNdosqkqQQ+cquBxQdjpspKQwIDcM/p8SRxzT+AnrHFGWPGvuRECZKOM6ERiB0mVXq5aWer6/+1rapp/p69/9P/q6eL1DyMdBx0MKLEwM/CN0oBggAckrcxjMJxgAA+IDKZGCTIAFohQeKgEVIVA1EpO5PRY6LEtfVry+6Bze+yUEaAUCd9gf6QjJZX4gBg+2ZXZoPlueg52XNmHmTF2wuuT75xzzI5zoghBQ86rgwIuXFbf7k0/mm728flEM+PsAWKcHdu8P/CPdZSHYETb+UOyH/797V72SY8pCkDx4WZhgWDyx6a9BDCG8/eznmu4CRQSa00TZsyQD0MImXlaww5Pt6F2FAsXcNlL8t/GKfKhahULCNiPxYceGG5Fs4g9JHMmgZqIDnj6tO+/lKpEFEirr4IRM/5e4rmIFBRJuL6e3y4+35Fz7uJfZMht3+0mt+76erSvnnyK4V5Sq//yFU8UBoKSKEBBGP34/2+AIgC6iSgnJa08VRJ1I0I3uEo8pVA6szvJxNtGmGw87U1B1rr80i46Th+tNkE75nNT8ccpufVcpXV22/qGvpZQbgxVUuzjNpW0nmwgpvCBtTNkmJ6Qknyc0C1rX9z1GsXVjJbZrQMJ6hY8Zvi+eIP8lFTJbc9dB29rG8uRKbRz1y7kTc7ZNhgPmEoAxKb3NKPDx5hqN4zL2C99gMIoXJIEYBuLQDTToQRWknTo3DnK1BmkpyeLyuNV83v2QjJG7xOL8Hr2L+NI89+80v/7skRkhATBX1hrC0xqj6vK+j0ojw/NZ1tMJHHKBivq6YYh0Lv2ta+JxrKUr5bDiEWnCVqZOSFM0hBQGGpvQiBjNVJrXW9+jskzxcc7z7SxYoGjlQy2kRyTKFA8eXFoJIZ3V6m5a3XlxCoXioc1akaYKg2EEkbILLgmx60wiGE2ifYtJ1zSRtQRcGlrJABEV1JIyPokWluzVzV8q2P4xJ9n3szD8RpUGR3MwqlYNGOUykGs7UZsNilq2tBnIVnuGpbr/NdNb+Ny2UutpcVPzctNX4vOl88tBbbFDlt9QmxM4MW3yzeKeKSVSKSbGucuTH5sPL/o+ykFFRwmOFJ3HW/+ASIADUykmMCA2DakaWhelMgYwxRFpy6GWLcicYYE0pyV6cThKFMSNbxwkVHIteJLzqiJ5zAcE42FdjR/tVFPa9nIEaNed/JWUnXy9JZdUs/jBcjdVvxo/1q4hmQXKvGTN5yrFmX1u8271UtM6ysTxjL0XerahshYTAU2aAw8c1lXVQXu4nJd/o28rNCXLLchQDcy/sjMBUGGQO+sNBTQmvQ01LVaSwC9dn7rmnIiEkhQqYrcEt3EslBZaTfREMsqp50++Kaao0AADaow+oYtDtspUYRZlK+oCjmLNuZ6GFr9GEmujugiOa7psao50qx7T0daIJvMKo/VRoQMQoYHaIqnOMd93zO6AFgEAGogIceOWs5kzULTAQQggYMAVuMEUKGO8lS35eVdCKsAR9uSLcomnYbNFL1lfNNacel5/PQD1jI2em3aVj2vpVKmRiEMcBTdumYcJPOdJBVlvZaO7LolDcRV9FKqHflzO099DZr1cv/7smR4AAQvXtnrCSzKfIu6fGTFslE9e1LspRLB45dpjaY+mO4rpWpxjpXKDlKoeHuhVeQXJWIAS2Rp0YoDMWcgMos+WdS6Xag05wOLTESNTtaAg8/7rRmUQE9CndvCu5k4KiEI3ZfPACpqrxIxOeIzKKVHkjcZSr6MOyXiQODa8EunBJ/rawwtFoIabp8Sabu0V0N+x11qnjar1jh+pHKu136J5TdNM8ytw7XUQx0YpUi5ZNOPDymKkZ0KqWxU8gtysgoYYGVihSeaVM1sREgUOS5X24xhDakS86ZKNTJWstBlURZPRzDgNRsbl7MXWzF6vYIqHJabWNOSYPFTsf+Dp+d6lmbLoPqxEJLSuYMek8sTbjh5auvb017TgKs4Q9Q8bv2WgG2IniWlizwiEQu2aeHYSPEZYrcqGAC5JHKO3BsKYh9UICxEECB2ABUdLVSlP1GZCYIwS6z/tXi3VY5cDpRrdSuExMwDGtyr8pk3NbraJSVavVmOB6bJIfCht8s1mDJEu16/kzNLHF+pHZbOC+Xd6NsP4Zs7V/NoZuzjgJaOttdtjvWZ8S38vFMah/uV2lvbkUlWmdnZbPCRumotnKn+EqlZtCONpQYdGLpm3TmOPiAQkMFBaZsBLSBIpKJQVTJSKzHsezrppfTM27ECz3xHJtqEVD2riweU9f55NEbrdaE/k7z1t769S4u75d+PfKtcKyGOvudkaGoqjMhS/V1etWo+qIerNRFwV5r/y5jaze6nYS/BW+9ZPKBFKaVp5bRNyCYA2cDNGGU4T3pcMoLOBgS2Yfrtkg2LxWUxh6RsXymTowgOOqQONWiMH5f0af/7smScgARsXtO7LDRAdIr6Y2kiqFChaVVMpLHh76vqtZQW3JUReuoc/uSDaWuHthiB+N5svvTL5wfRJYk0jhtXD2hvyDHQQMXUc2onQhMCiJqdTO8japci2RlXVduLJaQhbIcqgo51ExIHzwSU9VbbaQIChSlXdo28SrFikMKA4YEVGMSoPD0FSsIPZpF3Wh4vSyRPmpAK6akGvpdy+mbJA02sSYvPDIIKB5xeenKHAa+L8L1pAzVmhHZxZW2cfcDCL1qm2hgbTWj3nZ1Zu0uUgddUMysZ5i29rn0ZLLoWqzOtvdFmFgMHBCHXp9cD1a3Ntpb3wHuSFDgNRa2HAYCitA8IbMFhiBUEBWJy5KuEDSj1FMEBYXAya4rOT69BhmbIsKyg5rU/bPJKKI9C/gVqAEDx3O3iDm4gnPWLxEQWEVSIUfI+ttb5u/Uy+KqDhFH1LXauafiCq7pFwNEXg645mOY/sbdUh99s1EBfpXPsF8FZKSIBKKeKkEYwymCIhhRACQUAAMKBxm6qYpkAQquTAJgYGiZHFSTkrf4BCkDr7epocstR8kAItmrBCdVLNYHMQilUcODj0s+umvbK3bzNmbkpVKkL/+ndN8wkar92sxa6pmeiK9ro+zO1yJcyKaZFtrcpn7uy+N9JPrCU0smGB54BRgA5xK5IQTFCBaQhKDYAJGmTjIVsTTy4jsiyWVy1Llqb4NSxtWIvG5Bm0LuMrs+gqedbniG1U5HkZNupSm1AtvUekkQ5YX2iofY44CCtqhq10yq2Ik/Up36tI2QKZqvlK57hS3Z87rGOP9VulW7c+I89++o73z+InY7TZeN6aP/7smTCgEQ0WtZTDEL4eAvKE2ypvhKtaUhtLNdBtCIo2aeNrMfpzA8ReA6yJCwRmE++LA0NIQzaM0OM6wSbDmQqeVuHg8ebMj2yBBM4TMkekFCzG4LKoSzUxFb2kCBNDcRKhs3JqqjdY8OJ3xMWpNVP+ffp4IG7ZplqimEETwyF9Mqd8hWb4ouufFeN/QSnp/V16NRQHUspRrs4hJFDb9IIpttwwMc/QYyas76M3YkwxRmLtoGKJkBNrAgDNOhgICKVKtdp0nCTFVkea1clvHTkEdhdnbw555NNpq2Fy5BiZeutgu/8i/4++w6NQNIb8+dJ06MUrXBJn5YXrSvvBOuW8b2Ln9oZlJ7xZId9nO06ruHn36bGi8t77uO7ulLecY43nackPebChlCAfAjhShmskxuJQQwRrDocmgAlUARQEERhRYBgprTODHA9wS6BZqwLATKEo5lLZwmlM9Z0nlA1+Tuk0GGnTl3yuDuAuGmurSaODurOpRuzLMO1zKmGIuyiysqPQYDWip2VBMdLfcBUjXYsY6Z2oprHV6dX6L36sdVpQqe2QtBb1pFHbPiqcZAYSSbSjBFUfOBhM9RIwZRHhLVGchBOqBijI0b1UWIJgNGf91Zpga+kpqbPCzTQDSR15Z3KGJFdOh8SIc04QmkCTVcDiy9z29pyuzokbb0Sz9tZlIXLOWbdsEEf4Qe29Ao7gUfkZvG6dO7uhG7CBci4eV48ox7P42P3Zx8hwOIUYKJQcGVTHiiS6EEEON8oOAge2+cXubQyxO+a4fAISZaaVJXhuKgtiGmJeggKhYs3Bha2DIgHuAPiZp4rmsVrjoMtjf/7smTphESGWtEbRkZQf8r6A20FtFOBfUdNJRcCLK/o6aeZaX0ugpNvZTxfFzYtLmLkPTb/y5Gn/M1kPGZlv7z8wYDrMyM730C6ZP977/3CGbv91nMesue8O9Qz/3LXSC/777Ebz7bPH93e22b8vf2yz9Mpyex2g884Iy0yCGQq7PtDkZFonzgFAQCSkioF6oCmhQsLbgujIBa2G7I9qVLjVuUoYQuqAFbnShU87ThsYsdwrXYjW3CbXx7fELSbP6c62G+01pdVFW0jqf2aCYqFKDaO1nEZIjbAQMK6cGQu3c0AEeINwv8H80qaIT80BAz8IyV9AsSYcZKDnMVD0XRDkeCb/IwfyZSc0hAZdiixuCJjxTPpkuoEIdM24o5L4/y3L96i5y7gN7x5hSObg7hyU+NSfecfWZhgAKYJC6RzjJxtTCMdLVhK3UFlQ8gtkb+SCTOjD0RjWM3DVEUPjysYLFXBlcrVRTNQ03/ea0tGrEVWz0XQf4Xi0zJ1ZWvFZkVRGFaYarxZxWnlKYlYoTK8vRj02NTBuK2Yhbf2f3oumaaLmAlI0OM8bdba4e2ud/Sl/vcF8qKyMDjfdX03ix1xP6kLrCbFxFswvE3eHBJ2PhUoycnKk01neqsq5Onu5yr8Jx3RZvmD95zGj5zAsAlm607u00VCC7BVSEFgUR34XRpIggLbMFbm/60GnMaWHdQyiUBMRfZ5iFdAPi6uoqLFkNJq2DRsr+6xU6T1z08SvHkH5q/xd+zYPBtvlDuIul+uSCOnS9xv6lfT1JY2uK/PuoW74u+Ue++6uoniPOOj+/Ym5ICtuW0XD0+MFpTPAE4xMv/7smT1AAWFZtI7SX3ytQ0KemSviBAReVesMQ9B+S7qNYQWeCSEpANmRuoOlL7uMgQJAqcJrKDoOP6IUMoTXiURVpnnhoNZTes4GiDLg8ewwxSKSGqIex13UWlf1N7n3jSRfmI+VWsSIdkHXEqOtULXbgafBeVSshDcC8rqhkr9ateits1EY1SplJsvZ9T4iUCjxgWwqdkSIiUqDlNNagkIQ+AAQtTUFFChnnYkgMGQLzK2p3SxurZ0tHldti0KIhVSZZq5RWG14FT+LikI0XDW4wUwUnUoLwSPU3DkgzmY4yaiCRzB/FfV/iJ3Qv+QLXCB0d51fQuGqaSvUYdwIQh1y3Jgdzu64xB9bEJ08XB23cvjVW1eLxgg1jxSYhu1EIO2zR4g3NTXBj3yTEFIZAAOHCRGeC2xUKJAwINX8w1bBKJWs6LerFZhLHT5WY7M3HrnbcIDJPMgg/utKBPJa9LtWzd665S/+V82X0sjBJ13Cf8KvkJe/6/kJRdFHc7+TXQbv55VtljaQqwM0jF3WelPJiVemdqgbrD5hm6+yAXDSa9dhD8c+88nlaSI5kxnKVs7GPUEAhEAHacDDaqhrYuZcPJ1FvW1BIu5wcWrUTTnmvJNKLsScmKMQYDbVblBD32ZiJQ8Eztkm6MTzzVN7TJZqE1lxTXKVc29aUjeMVj7PLz97G91H8Ep2oMOo/Zlmsj4lsZzfJSGpmmzPTp8bDfiB28kSdnm9kcNfqObSkzEqkzWSHQ8jTcbCZHKAS1SQaSB4Oh6JpVtlwAMDKADjjABEYETCCZQONMqKoVAQu8KDEHk6m8R2UgX/Wpgp8hCg64YKv/7smTqAARtXtJLTEQgh4u6JmkmmhKhZ0DNrNUCAyxo9aSN+GY5PW7Mw6+c6ypvyzk1WVeeJ14wvLva6LYa8hJwinJKFWlr1piEgcBAmg5OiihPC8Ys7S/Ujg9PXMzBlrM8iKqjfr9l4a8DT1repHsmRHcGCC4ZekDK0xAAAYEmYGi5godnXGGaLGphYdhcIpzCVhQid8xhgltBwoKHqFhU8IcFgm4DoKIDGyZms2Jqaum4PE09Sd243KnwCjiBRN1AUZ2DswIEiGWHX5EmUu1lBRiAyhw6Qor7Sy2xuF0xe1A4P/bhk1hEa1uCjM6Lf00pH6Z0qAIhP5SbO0gC0onUUdkSsy9TYiFmM6VSlGMnpMoXT3K/ieyyI9GOpCp3teOTWex033AMBAqgBiFbN6DTlggyFYCoC7A3JEQHTIFlqkeyoFgsHI4PWpg7yUyl77SqWuZKVEUHhHIAFJUHTIDlSqsVUlipzZbib55q1lHKNEU2I64eNVKa1h4jiC7qfFuXUrmmnnjH47i5ESBdq4hqmTY0aMYcOrZR19+8X6jLhCWuKaGo0THqUHDQPN6G8yG3TflAwDCpkHMWrQzjMnEznx8yspBQqARhQAEgSAIwELQUXOqdqryt4PHqeD1JdFq1FVQ4Ro2JKQpAPF6PikeMEoxLVuhYOuWPKo8Vrso2T5Ip+6wEpPY2VbEgcn2HdvcC296TNCBP5JnTNXS/kk9VXIeqbzDXB6Vw18rzksbN1Pzf88MjXBUX0NiSQ/dxwikLpr5rSjlgLmhgAAAQX+TuJM3Q8MWNzShYRohgTqEYADkxk5REQkHzXAvoMOF5AdVl7//7smT8AAVdXk2rmUnwjaup6W8IHlKxeT0tsRLCSC2mmb0guIlYVVOGGuKMZ0zpNwlb6AJvAgGoKhcJ1sxgbXrYvhCY/ql901zAewH5bVJPyscStb9/wfys64qLWutrH+9PLocMLEIqiuNldBVD3niJHRSFtdQVcKXw212q1H1k09I4q0DjzoBDT+fdpQBAMALk4GFQE2zQVmMdgcwSMAcIFdChDIQaCgIFgWJAAUApIBQwYo7N+/Tjl6odKoBTNorU0yp0pQoOxST4Z86K1g7s4dqhP5qY6VbQVN7uW+BO7HL1lWJLxfVc9svNuechRFbD+L/+h59IaTsQvTdR5/cDPldTjK3vsYdPlTPBE3J442U2+PvmxiDbxhpHzQ5SAFj8oTscUZLcFjlzpuXMexbugAAgAEAe51HmKDgKYxENgIPMiEwENjLAqUfIBqFjDL6oIEVCqUBs3cUvMUQYC0qoq2T5ReCJa5DfSfDOc0IJQBD9DgNotj4QRhCipzqt62lz7ES5qdn5VGevmqmKzo56aXK3lfhv+4uB2jNV37OeNuoKnn7umuU75X6fbxnR1yaDEt0sky6mMhKs6aOwAqDa4xCKwYzCI6AzAIZMLE5MERVnWMUPLyGCjmDACwOBaCjuiOo4OGx+QPCzZYFuDuoEy/Enq1YrsxcWMWjHN95WtXbJqvRPbsMckmUGXzdTAON8nHn85kziVJApndlc1j6ErpAsiyYYfmtmey7T07t5l+DkKuLJgtWbfkXIR3HOevnlrsyhZWbzndnWgPWJ9CW518df5sWuXiPSrjSH71fVJH9y8wxNHQ38HA1CRie6aFUmGv/7smTzDYUiYs0TjEXChso5mG8oPlY9izAOZYmKAK9mybSKMDptR2ASERlKBwsBCMHYSAhMiIpDQFqlGnsGip9Vks5csFQEBlAHihMYDgJE3BdmFSQu9aKmYp3HGkGeclsvUflNiUjrsjaXr9V3ALtAgqSAJJgrcrIypvf8qochWkdquouYd0qtzoe3rN6WzMvlk1QSZ2TZRvVrBFBjKhAj8zUEY4euMwXDCi8MEECQmUYJxnWBGCSAhMeADGhYQHRIxO+LOKZpKqv4+9NDE6w1OpxKXOgqbkVQsWNaJBOSwJTEFg0xGa+Plb3+yRqQWHM9FNjyjSG2wD5aZRjepQnc1/OpuJPV/+K7vykLpmGTmTHv45+gU9JGNrJy9WxvSxu8nuSle2hEcKSFOQ+5dJTlJGErjZfY7rknuGqOolAgEoogiADDKjSZ+UssAxE8QyHIHDw6piYYFEQYnexIvAmE6KCSJRBJCBVAMTYSH2HCUHjHIZSLH3s/2xsYbDxKu0rWqjVUacBALZUsgmIndA1sd0Gkozd3/b6aPWIftvvyff9fvpjGL4uQ4O7kUXMgeZki4t29JhxMHMSIYgRBujdmfBmY8HBiEMmDRQZMCo8HTIYfMGicMWAsoU6JVTSGOFEmMXIiYuReJQlLGEpfSpIdCaW+dOrJ5TJ60fkT+ymhuSpIc2HqzjuDIQFWpWWVVL9T0o039aYnnQWpXUISl66qNu+pTzauEo0ibjZfxY0PvNHKu9F8ubc2Q28M0Jyg4OrWFo4OXsVX0d14xnJUrqzQ8pyHeCq98scV1936RJn7UWO7Bp1XGkI7fXum15uw5lGwOP/7sGTsDAUeXs0TeUnwdqvJx20liBhZeS4OZYuKFq9pdYYhZAI8l7ftgRVoaBT2NF0cWIwhx1KEmRGolBKRCJYyTrvngCxuTjwDIKnA4gWIJMQXs3eiQ3KnKhb4LEMPBCGi2QHgGyRDj5eqnZBQwQqKTnipskXSPLu42Gq/KbxV3Polu9xwZVei2iU+nfCJ73vzI0XH0r4wjIDxITuYQY9GTfUKWfsqIiO7uVgMP6EBwEAU2SFAQwOyCCoI9I0objAovsFQIhbKElwSwAaAqCVJDsRDiThtiLgulCWhakp8gDmGo7CO80SN5nG7bi8eH3oontUM/6IR08byA23Aej0yqiBl6LxeGt2moexWKdkY2Jw3pD58eHFQuaZD/Pi56PbwIqvj/bJN81TU+S+WmljK3EjDn5x2Nby1qCJ49lRW7O4wbJlH5mfqRngJ1Vv6NzKn0ZJ3Alb582oeoEWLGCNqB6bhVqKBAZDTZYTESxzc2xT51e7g/vuJB3thd07foAmWSclRVN/Wp1tv2s92k3JSrMiIAY1kU1Mzd3G6Rao98gWQl8c+qYLwYv58/du7Ww6mZnWUbiX1RtRdg6OtyA4QcH+0KZUPFBqAr1BIqEk7zJFP99TObdcrpftTL+kOkCDPqNPrwJtZbm28uYartd/Hc/7RdwKz0362zZ44UvEVnmeq+ngq9D9deLhAkfMbntkOtQXxANwhDgtJI0UvBcl2z0Uj1cTPW9/P6vKYrNrff0bHGgEYIABAioBRnBGxBly5fsiAKaoI4FZ8iDLmtMCXWrmHeRxypWXDbuXNEkT7m899O51+tV/m7xdomyVcrrfe//uyZOGABoZnz1NMfMCzbMqvZS99U9GNQu0xMcIrr6ixh6FY/4XNpkrV2HWZSqVq8skBVqgMvy1y8z9HUD6rv/4R5qiSb6UPz2I2tU+jxJ4Cp0WZ98e00oVajciVieJsw7M2sxqEZbLzJSb4sk+MWjLCZgMRzQNPuXfLpiVr7svfS/EIAbgCIvBAhSJtIoi77IWGiOKJBZReJb5A1gJ8fJxHKV01B5KiSjvMONii2UtNM6zWYQbWpMWkd/ieez73EAcsxP0U2SGQGmSXUyY6uLMH9QnNERVkXVKRfl3dqWORGaeFJoYerypaPaitWLJOWOfYcf5AdSo3+M2mKHBDJIjmjkkYPosoppPPoMNxVQF0E+AABWYHLJfg+IFFF3w4pIwvZEQUQBRpAWAV0sHUBl1/2d2Xwnu2FEIhC6oBgvq0NvVMtGwh51Hk50+fuvvk06uiIaJXZ+3v6h75M7eeDTtYeZlrdb1iAX69Jb9Mte0Bf3slwauP2eNBCu4s+dKJxgqSZ7rjD+xgwp5NEptCAKUerJTjA1KoLlfELqfe8VrBYdqlL7SIAUAgEQsJZaFjXGjwSnVdFqiw3uEI2ev07KxI5YjdZRHCKWHbb1RLyKn5Yeiexaorj44+OLG4tegdBG/U189yQ7ZVVAOpj09Csabofkd9jOiSdWQ/TpZ7s+nI2xqKrOhS5ARByiAsPmCjhrtxMDAggAFyY5QHNyyYjqAJAYA8jO1kWFOuXqFgLnlmEk2HpmkQB3KFRp0mea7xqlxDdMHprMwqm67fSZFCeYuocnh51G4PqzMXF1jmguI293X+Tp+m46/FqqIU3da+BgWt//uyZLIBBIpe0MspRPBzSzpdYQKMEl1hP40xE0nCq2iphA4xeL4G/IjHWU6pJ4THOZFRcXM2NGRLRkSI85xvb1ByyRckB8ahS0dG5UjA+Q4Z2QSCX8T7YM0cVtMkAIzmdBa4rAhvTBQbTk3XYXssJDjTVF60UVzNwDBErGC7F8bOEhTjNjZS68b2OGMvHX9zMkTqMB4Pw2NYlYkn3qrx5b93y8tqRFVnmT4YHPbSRi5se1TPP2I1B6cNuQzyi9go5b7ifgPvrg05QBAFcDisKCgFTzMCgcFAuMkoKBAeMCg+rG/BZ52VUQwIIh1p8dVTUfVSg63alaDgEwYBAeWQrWaXrCxj8ZB5bzNbCXGt+0qoZGhRhEAvONxg1IxAOE6DHaNE4TCsqk8nKZZMxy5HwMMZcdZYLJfRY7QQeSX9xj0wji1UII/5UrGXFy4qOoYl7WDy4fKMYoQQW+hF8EsK4dA02CeRtNyBQMpwJxkVC3It8qpNzcllSSzoxSKNXhgWiaX/qGsSfEUh4ikCguLg89VtbrN/PPrPpQNh/98dfCNst6vZqXt7Z+R/92Y+cWJfetME9OxlVibimUP9RvJ5KiHxjM6i4IE0p4IvIkAFlDQBs0woPFPDGEcxQVMgAzDRQURA4rNxYMWX2IMR40yjTcmETa0FOTYEL4EoCiFPA/HFKgzPwwRMGTWY1ZyTXDIWYfDA3cXXZehdbaemf6a32cgVQnpGUSmtr2QEo/rAMIeklH80X9WOr9P6Trftc6s1t+mBGpmzKmNwg6de+ZOxYc3elo7d1b1d1MhbBRqZZa3oKsve03esRleZWrf1aipNXHfl//uyZNWMBMReThNsRLBrKypKYQN+VcF5Li3liYHJKOeplBX5qZnHjvN80GEhAqjJSTVzvaElQIUnimQIhFzo/0hfQvFmkettXjXVfEigBAOGg+OMyBhR61z5QhBQsgtRv2iUqsuxp0M5DwaKyAraTD1MHD0tEZvytpYuzkpqza2TWDGM4xVoyIctK3OK1ZVsZdk34iz38JQqqfr+sAkQI0rWMuDQ5pOSXTDAUxY/LngpLMHOQoAGBhSLBbkwYCMJAzEgEwoKNVAmYqdFry5STjUdwzEIFHQRpoOCCRmPMzumpdO136xbPWVdTOTjWVurEnwy6urJWnE2Y9YrlX4e7/alc+1EEpJPKr2S1Y7JEt2WPvcXuRSb/d/Gi3J1WwLhVeXpRgnFfFR8eeTyWdcCM6dddp/Y1colY7IHwBwlEysIpFXVehiCjWDdwTaEZAwdUoNWR4KUGS3QXGKEAAK8iMo8BuI+sQIhiOIQQpm7NfYXR0tFrUpmKj5gEN7zlGHbtlZpaqnsKXv2K7VP7VySLds3b7w4G7uaQ3IVYTlmX2iJlKXmfgnbIocDqX69iGDMklIskim0jBxWlhskLqSRsIIaExPoA4AGBZlbicaaiRIYObAUDD0JMMUFUNAcYswUoMxMDUiV7FGYA5UsBwy1GmgGyxBW5CwaIHi2+j6i9XAdxWKSbT41iNlLygnqCBHJDpvkp6II8Z9FlPKidVuRN3S4N7kiCPNqyP871CNlaV+xAzkqo9XoGfbEapBzlVi2s4mzgfldiQ/R2dptnzO9WW8PukfmD8clCyK259MMS59mhMNuVqZwsetkRiLrDgONstwR//uyZOsMhWteS5NvRVB26ImiaMOqFXl9LC3lZ8H9rOcppJYgVCJ8JSEoygmrt8C4AySgt2FY5tWaFLhTERVZ3LmTq2EY6OEWs0wJmZeO8iOBtacURF1egqhdBtMYQe4peoq4dB9FfGBMjMdXh4VLZiUGO+7UQmyP21Kdhg585pR6CkT7j2ZCKL3fo7to5mZ0GobFDQQa8owAFZYPcpUFIEg0RBGceaxZpMH8UEBJPuCZ4Kw5imgQZaIyOXoTtHgAwYcZbAVQzg6zRBIvoDnilCIDJG8tFdE3MS4zKLpGqOHzZJJMjGdSjfQMT04Xy2tyv2fRMWUbDuMEGNC7mBhTTMepS6LLakdNOkpZ1Oo3NmvbNGZRkW21I3pvW5+nejTZB1KQMDMyWtdkjhKH0DIZ9BNUxM0pBu9WZo/U4IoMb4cLxDdsSp0MkoMemFCzOjEpB0SQj1ZlOyASBBZe9HkOQCbrIP4Xoj86qV7nCQ8yAnTSdbTsfUjOs613Ft7XeN8NLZLPXT/fpmJ8Qfhwf5v4v+ILDjEJm+MyMucUhN14cXX9o2/rX/+Ynxjf8tfiGz/73/emqYkctemM+WLP83j3zeu9a98SXg61JeNv5p/hg3iExw96kj9Y2fyQAADQGqwRgkEgkAA4lTMcBDEU4DgIHuTBzUxg5NWHQEfBUxC6Yb8OmSJAGKDISYORgCImBjpm5IoTCoQw4Ieel/8U9S5C1QQGQSrrL+IXqGJDuSwJbby22nF4EOgiJmhGqDPy2J+X4VngZRSAo+NL0+QEXEib2sTZQ3coPS6hiEAQ4UB6WIpXhBdDBgjLUjmnPL2xJOVrtihk//uyROqABOtdTR1mIAKea3mCrTwAYjGXLVm9AAR2Q+crNUABMEYUYKMJARZKyHa0OQZVpIzMSatIJmCb1nkFVeSeGZBG7DqRZxJRANDOPTLJ7GrXn6GxhZdqMZUlensdpKRobevOpN9Ibd+YikikGcYtd7u/cw5///2q09S29ymz3uv1/LbN6lDD9BJJHUwt408/p3p//R/lz4WjQAAEAHIggCAAAAADFFTBDD+rTOBTjOCrfEAFYMxAWDDksz4CRgYwsMBJ3m7qmzEh2w1WI1DLQAywDADi2TYe4TYoYXCBrCgH5hgsaJgtlQyHLMydLwNiAHAAtIBu8hhF3LhcIu5OMaAcqUBvDQskDKCgSFpoE0NpJTFQyLbmIGdDgFBQMeHFzAa0yCE4SZ51GDMSZXWs2ZwN8eA8LcAYkBmAwAzsBYEA0ESXWq6CzNBqlKTTDAAsIYnAyQYL6FwTcDdgggxig7rd+6Vzy1qoQuMAQEAOGAKExlhSgYjAFCgKDwMcGAKAJILqPJK/qdTJHmZ2+J8GTJsc8UoR4pcA4ALAQckRZ4pcSgOD/////////REFBcB40WmaLTIoIWFpY9SWTImjCYUQW3XBAGNYnL7CMIQBAFKNLFB3QgjIhmHTAJUAiCt1h4wQAdgAZAMCEi2lxJcfgNdQncXIx2eTYF9SGWMoB5FJdG4crCbaJAeguQXxc06tCwltGCrXSdPTvR6CwEPNIoRdozNZjP1PIRGgu2xzGCBhHUCIOhRGqxJJimcWuKoG5egs2mGJWrnAfaa2yJmLmSSlmxne3vuaLBeUUry+IkdEIhxVTApmCdZeR31rvYav//uyZFyAByliV+5p4ADTDKsNzLwAEn2TYf2VgAoxKCw7svAAbnNrzNAiyvVw4mNCwzMJfGN0uIrUzxdOoOrSrp9Gl9fnMqsfTR40rwiAR/e05c3W0U24CgSiikk5au80XIPOMoqNnCCLHNseB4AGCkgc+h8RGN2dxuyBwfQd6KDcN/QsZf0gPWQ+MjjAM4nAaB+qgxCCpIwTIIITF+yNbi3WS0x0K2c21YyMLBRbgt7qd6hTS27k1Ms1fLpWKhVNUyskP5i3LO5yvrOEsfS+/3Hb7PXrtvZ3BshzuUumKrLN59Zg2ZHOAvRd+AsvG/zwcQfDrC8F7hWQM2htd4GoiPX4kzG3OLBhxjzWgMB0zVfvYjcrtPoMGWHh+5Xebl8tIuJUUKQTspmAAIAKgYQeCdCLFA0cMBBgKEseFfRpyhiIaXrfQM9S/B0kklC0hR/gdQfWzoKbVD8otRUc59rZuc86m23E4nv6Pud062Mc/ttaJ2JfDbg4/5cnNTb51vYzuIN63Uz07+jd+k5fk0ZcMNz3Zzphpvg+19RB/lvdycfveb3rz5ITZSBMXt73v00ka6/+eExmeqFjNGJCCBBGBBJ1ao6qqJDoS08kjGsw1FWINawYm7lasrUJF4xwmGDCo4xde6oZ4mWTc3jSz2aoftu9M11etqxL/S7tTFouviaJj7jbruanxDxf4p9UgQ7+sLfxLneJd6rGj0/rnGc7/+qevx8azvG64+b5z9ZxrWcemsf4eQUlwtB0uQC6qyAgZOT61c3ZJWSgADDJluodRaJeV/ZQWsKCxFtpera1tqiveNKuTw9XFhHrZayuKXW1x62x//uyRBeCBJBe1+MMM8KSK9r+YYZ4Ual9XWek0Yo+sGv5hJnRtV80abKxcIl5exFmYYSwnoGcj9FNEkrRaYYuCRtGK059PLgRWLY5Go+pHmTV0gTaC8zL6FIa7wznptdFGa3eTa2DKLM2KwkXZijizLplPdTDbGon06T81+V3QtRU9HATXPJ9gTY1VDEVgAIAvBzOJ5J2uahigLQNftiLWUuWDqhW/ZeC6gtCUMDydVuR+pvA2pbbmTPbvJSYCLGEy0DSGEDg0mlCWKLQzibQPVKDb2NlFw5C8p4QllaUvqq/sSepZblFqTRD42tlWGaXi6xN0paKeJwr/HZUbuY1OvM5z49PebrQ7jVowv219XNUTHo37Eq+rPJnbqUgQgYQapsjFGkYROR2CwjePtSndGcUW8T8d69N8UxxAIk1UjksstuXNR88sUsQb60UmLgkRNxqQsmw+ZJYkmsr1n/ZkUZ2EoItGyq1uVGWaY7Wx/vZjIuRSRHRJp9Kcs/bSt+YTg8pHel531yl3CX6tPlptis19Z8vC3hekIfW3HlviTdhLV7/6ntwrsamomUoAGdhoAE0VN0nkDIDYKpxLF4vmuqPULcFtOHLVBsUsIwsMQUWKD1wc+w+JmIcsmYbhE44YFy5xJm41klURsPfD9Ldxwb48mLP3fZBdTUUVbuP6G32aMxjjqY0ujUGgxr1ulJ1mxeGV6/pe5czfnq7LzWzI37U5UCk1iyTpzLPEzK3suZisKcm3l2Fd1ZmRC5QA2MJQP+Dor3LWyMhAuJu6WheVCe5ECq1uU07G0+FKRIUZCh+LIFj7Xk9TuRKCYlbQpCXtsQk//uyRB6ABFpaV/MJRDKQ60rMYYZkUT1HW8wwzEorLqtw8w8gLUQ9uDRhVRZK51jktFUccil2NoYo07qr8bWIByW1lRlr3NLEILVcjkGRcSjcpFw2nWOOhORtfnw3P9U28RI4LWcJFNOYEjMEEuml3rMDnboYmjgAArTnG9U1RmRPZSOiX831O3BdLoO+UHhcypEY1YVng+qSowYFgBSCQQvMigUigm7G7h/DLDIpBpwpMXUNyMmoEYQgnLiQyw1IAkCEmVwjm2QBE2BEkyYdMjHT/yYJaxEic8G2klrkIpmSKbuyvUDULh+ZXxiKVeN76clznpyxvSxdJ6nVxtkgey27VDM0KSKogqADJbp8EIm6pQrrLfMrL/MoqPEhOfiPjEexKXB6mUIFUHNxtHLNa0i7JzLhZFEon5HGCeCgI6piN+lmGFlE4ek6I3nRHviREwGYWzsgab5Io4UvOE9LEnayzn2Yh2bcjvkJlbr1hrs+TVMaW1/EtMjlmrmppZ+9sQTzMeecDT8Dr+tT+5v1bYUqADAhVaQkB0F8A2iLgPstVSSohQkSVP5NvS5MC0brcrIuX6ljYbGl9a2Z4EzXX4X4MU8YotC0UjiNVE7dR1wtyJVyjaJndQEYYtEFmCZe2QMMfVXZyVvqdajb1CT7q2/khWkFBHWgxKRL4lZQCgOokLC0cChE0nwqWQZWQw7/7CmB0isirF35+SyFyIDYCwAwAoh4AjZ9gpgJESjfDKANtlRZqqx3BnslVbFgxEnFkbL1L2ZMnzrm6naVvrbEQ9DZ1C5QNZ2yRyRQaXAVe1Gopj6JK0ZhKNJRMvc0rtFXvXon//uyRC2AA/FZ12HmHTCAqIreYMOaUAljX6ewbQoOrGsw8w5xDQx1YSmZoZUkUcYn3Iki9CrHhNZSKMaGMWAqwIAY0SL5GgdBmqKqqZYIA6Mq23tEkJTssbVOhTB2FusjRBiMGNDhV/F8o+9ljKmjwsw0UmitMnIxrfapaRWGvHkyXUkakbRPj0W2YaY0o2tmjYUWdEiWpERdcTAKN0YiY8wh0OVxPIRm0jmo0MxD7QWLlRmWUCiL2NFje1Qc5XFWWulwu0bTLp9LN9pHUCSS6BfEMWwI5xgwB+A4AJUno3w2xMIbAAUmktYelVGpbXnyw95w/QkpidOMrIxkEyliyqSQZvEmQczybdSCCo4vNVCiCIcsWykjiSdG6zNMicL5PFlsM4+TGQryDGfIt1NY3r4W5Ea1W1Pcu5hBBgBIc2xUODexWP/8aZLFda1IAFg+UPL4BJjsAwmOD6DdwJKdIjzIEfOpFk7LAqm5aSjAwXBSFnA5EkUSlAo6LlMVG0Wy7I8s/FRpcr0y9veqsYxZ5ht01FjNJfugXkHz1GOexJM2NpaRqaaGbDJl5jyGLPznKrN8z1eOaozrDBHoaHliAQfZ5PWY4S3a1vtXQvs/96lUkCk6HFXI3dICUIVvKwhSa1LrD0c3kblOrZoYrMwZOhkM2hj84Po5GEe2a7qN6t07eZVGOp2IZq8owzN4bE0qZZ1afbUUxyBkYiBQw8gOORcWezk5USxm91yE1yysJyy3CkyQ2UraRkeykRkIZnUPSmSMtB8ot/07qUR2quWVogEABQzy5kqAKDtIUS4DWBooAvRGBb2RCWwuqLUqSVywhOn1//uyRFOAA/teV+sGHFKCy6rNPMOoT+0pWceYdQoAJirxkw6p12rcs7knRdx98xz4zTqTctZCH40ugMyUiBlFwhmzPRVpvamHaRrxZBAnNSCI6lEBO5dfLfPWa9zmtNqa8VDX3glSCsCyNKaG4ObWtqFXegtbu2LSrRh8fPtXIbMkEyqhFoKNghxMBYAdAKgDmDtAgDWYRzDEHoGccDMlSaMzXHYWB7iI7nlXMYQPCwx/VlPKKoasXpcXO8oc9IQxWsyBLZS1A+X/oMo6LY270GDDDTzsczuiEVK2VodgNKHM1kaJlszLPJjH+8+qKCR20UtJeqcWG8Ov9L/45zsvafpYkqCNmVeW3ZESgo+EQ/GwXk60qmDOgxaDXUnFQUcqeurGLX3pXhWnYsLYFbM2Gr3BWSiHXCyceelRqEIn5DbnlHMvtDFLijPqSTYjKZgtWP3GCS+c3zrUQCIodUEAvs8hjwtSbNIo0QrBF8rXIbomEeBzQzSB75/0t/v/+dpyOCMjIgoABx7rsNFF9pZFkmKK+Kxv4EBTGuGUhMHU8wglwGN2i21TUYkk6Pjy8cqix8uwt/ILZyIxVYOKxzL/o9PDCYyGPRrnlkN0Y3eB/w5H3PyOWgj0zl/nsH+Xjb0f47tS4/nO8b+2Idi4/BlQ3jc9/+V32x9b7m7bdl47y2/Jvta5dgkiZyspa9kAWUAAoEtDwboxg+BDwPIr4sSHNg2D+mGkS9PpJdj0VPjPLx9RefNGUQ5+g734HRnuj5shWORG0xFnzuK3Q7AFrJkVJMMV6zRYsmV5RVzFNN/0Wc72t/nxM+rDdjlreYI/HM5WPaqU//uyZHoABE5g1PMMMnB2Sxq9PMN8UWVnUWwkz4HAqCs48w4YE1ICv931vvhVrzaUqrcuJEAmF6g6DZiULCBz7qL6ApfihpAEKGYI4y+GIAUQtJciBmFCWKNXVyLElHy6qNuSUGckQ18UI8o4YSd0gcu4pG+BSnjXDuYIT5UDsc179BKtrzHLEr6GbvE3jcjeFFZmOCfT8bWxHHNIZzkG1jJZ22e9ZlxvfSDdqv+9bmIfnBBwgfUgYEqq9LAqyyuZjSqNwRYXrQagOUxkyLwMcYCOHDBTBCziZaK1R+RyAnl2raIeunj6gVWyEgcltLaTIzhBlY4mFXLIKM9giUJFlaObpa437Kfn7f1srRbG3D1zy8+Q9T92LoKTQMWo48CxGIo2Dh8DyKRRl/qqSjMmjEQAMDNQ9UBMgOgomIR8pKCvj5H2YB1BxGRiLHVhbgUgBBzH/IOCmHpjbZktKfLOGCiOMcTM1jY5R8TCZTmFrvMNgojD1exksoyupEpsxArB7tB8IRsItjrmpcZIp9V0kZjgUgR+rHSquFa0zZ9SqwcfeC5QRmxQcwr+xTkkVGJSqEFwVIP85xTgzkRY7RcJC3FEQNDJFSWFEXUhEPEK5sBG7mJCgaru8S7Ye+LFghyWn4m+GM5hSfYrUGNIu2RQbWycE/M7Ui36ql879s2pzPkSjzD+zT6LPxoeHiGqJy8yPk41et/jd3e7FaX87bj668kfdGF/62/WSl5yKevyxSxNKAC6uAXzIBPQx0D3UIdEQlB6CVMOx/HAcLcUBxk+uUGwlJAlAhAXVBmrEwM6gx0KDFRxSbBjm2IB1NuuSwGwMSJL//uyRKOAA/ReVOHmHFCCi9quPSZ0D3lxU4ekboH+rSoxgxZ4rg1fMZyQotDEOUV1q0oLCQieOQo6GqwUb08c2kpv3iHGbhkZnxD4nbm2HHRgSDnkOL3PQLZuSSWJooAAT4smSpCDF+H9qOepwma4SYSKEMwRMOxDt+++col9/OgHkpMQKLKMLM73slUR0sxTQibrq3E4qrZKDyk/KtPSxmLwrVP4LfIipb/J3ilKzJinlrpaFlfZY90R2Yqu857boznqR11xioyIIbkv6FDWKPFBaIhwkc16c3XY9a1ldiC4MOnWODCp1gHshtS1T09FUeE6mqxNrUUd7Fgyce9XkI5JE0dmoogdqqC+W5KsXJEucgJT9NK3IEUVsFiBVJAowhwJWQkdXG7KZsQ0cgdM+ZaPV12rfbzEqgO3qK3F6xNu8by5D/Ms98+mEFRaMM9pAOgWSZ99S+mjI+AaxbALRGxHQJiCBzDLBSGcfReS3maS6RlJMKW1BUT7E2H49+pxI1KZplza0GYtqyYcvqsNwXWQQrHxn3zSuL2fF4zMHGdiqEoyURAql57EIkKJ5hkztUhOH4D6EEiTgl0fOjBeG6V2lgIl9At+mFI1lZ+E3ehTAsyAVPr8j+tcMaBKLpCEOOISpplziIjqqqLtbtHWprcdKHAkHUK+XFEyeLby1d2uNvn61YdmEwtnEHvvixIAF8aqspMRg6rksC7bbhMimFbMhiikYkG9E6Fsu4qeIwg6AySrYId5Xz3hFFs5Lwd6It12ON0mnWfaUjFqLd0JUkWCapd24XM/1vSGJyykxk0QQC4XUG8YYLMbB2GWXoCSCQkD//uyRMyAA91ZVOMJG9CAq8qMPSN6EHV3U6wwbUn+Leo88w5pCpGJtXKpWqt42ocojyjTPSKigIiBx8B0ax0Px5upPbOezLqjb1O6q3PPQiPkLN2NitiI0RJBSsq5GWrWt+pv5/2YQGPVe8BpD1S824LQwxF/6AnjHEh/5k6CRzcXrXCOTndQeFfvaoNZgQFEkomShAjEJRelAcKKa8poruGkyneZS4TqpUSulWAdl2pPcpwCEVCoXzukpCWf0Qr1onEi6qmCcpkdDox0/skRsixivqWDo+YhTomlJksaoE8vsl4fVEsD3WrHqI2FFbQwE06mFSfOWbfPu5Ur/l8b88h7IB18oMynSIy7oVkYHzoDd/MXyum7k4R+bn73TLUvcpLu1Lf7X5RGKr0f+8geuyECgAbVYBht1HdhKXQmcUAlk863UnlUFcKw0ior0AQK6QUw7RlGYbRa3kEQpQ0myOMRMWgfFAWO0yRy3YKFbxl+CKmn+6kvNKcm08j1EmIKqzuZaVwm5xguONVmOYaWhGbZHQPGPsqKqszMzMlFMQyLr7NtS++c6HKoKKhliw0lYFks9NITpAAABCIgiSoiuYBNtNQwggOAZiqsrMylVHbZG1X640zL4rSRjJ02xTuVPH49ybj8fpuSJqM/8s3Qo5WE2tAbEbGdIgnWKZaLf1OztMuO3Cz/v/DKQKEr0VCFVLVieX1W2OhOXs3DSPqnaE/XrLFEw2v7WuZI+GmnflTA1xmVyjpazp1ph/nQxj832ZevrbyjVZgmsPr9/dvlr3v9+PGfJ/NQ7ASjuRAAAFOyn2eouOks1K5Ht0VLX2C5WPrG//uyZPQABRJgUMMMNPCHaypMYSWOFIWbQSyw2QoMo+ixhJnxUDVvbxskNCJIVni60VWWGmMQRP6l4PTTkokvNnFlkCDGJcXlBdZbJHJXQVDnQ6LVN5PH1uqS2UgQxUdTOo4pEgvLOqaSuHdI+qtq/K876NrbzY07oMdAcHT8v/89ivfRtA6TulbP/l/3yLmQAAGCjAwyRwwYs7KVfIZIj3HIc9fCkFK24Mkh18om+knACGOKAZkN89OC/SFg4UMJS2uofrykfSJINDf3R8hkxOx9oUz0uOSST89s7c0yFMiR+mOo70RltHJkudyqc8ucosXWeF3kHQwLMMhkQsPDKRSYcPTRfG3OjDpieODzuix8DBiRsLiHySnxbeXUaUKw1l5R3oKmRsW/yXHCt5Mu44iiCQAADGHLK0xwsshIwVDm+jzQM1RL5/MWzs3vvK4sOBM1/SouTuIfNv8yTvDWWeRSdHJKASCQK6IknAslajX1csdlKPwjRpRTIytahZ/x0kUxRHDEE2SjtDlW2w4TrWi2ZtTmXvykUrvD8NzGrS2giHoyk4V2jrOz9J8g1bZ8HaDu+f///IAwAAqkiuOqEQCJguZigwAbWmPNuwo6rY86xFcRORTD2pkt/FaZyBwGxOXwt7W9a0IQDLk0R+LOi7qkvMaA4ukldCkS0yLzATqG2ngWJQaL+W1ZePo7k9gNw6/hkcUM0mIUu12wt72yJK9Ru25vs/vdyZp2FKw9YZj7VecRIPs9Zf0kSyM6DyJyYaVfIHjd4VZm9ZVFGhxdf4+nzXRMTccT92mzpNs6TU/xzGj63CeSoch/05pK1TEBAElU//uyZPMCBRJk0EsMRHKHyQocYYZ2Vn1nOww9M8ILrek1hI4hBRLtNbFoNke6BFhYHiCmJZVYNsiw753JLTx+y9QlBYjAt600151WvQ783z67U4WjgiAWmVIgb4pzMkjV2IAKODBB6ooFjnRJB+Phi6ixVR3atdFUYygvKenRoa8B3mncipu6iyYp3mRkbOpnk4IwgFFjUCe82FmMHfjtILFhICIAOBFLecQDPIgrOIVtYCDQ0BnsQL0AVLEF2MdRp3Hlo0hai0ngVO/VD+VXLkklXxuVdU7LxYO1QsPTkzPkfwYVaTQk19Z7OlJevnTiHGjpQVcSA0LV8datPNnHtMOuNRcaaEJPeGr6JwV2s35J9Flhj/iE7yCd98S3l/GSTf8uPLyjll1/Rf+V+Yjvoflwdc7+G+Hxe5GTDsk0rMSYKcsaMWQmAEuNI4wKo3WVCi5ogMcHHhVDbsxpBmY2jD+HGpqKwH9FexMwztB0GYpHAbhjAhwTuOBAw4sAxiucjvnLqnSJDyTKFCZ1Mq0IjLHdzOcZ1OQTuWnEYMUpjR5XCtRytkawhnA9RUvgkVQljWiY+m6nbdRJkAARmjhMpMjQaJBPAhcxqasTOjgNJJpwvgcjNlPE6T5eK5TiLU0N+q5cTO17Ei8e2enXcAdOiUSnqFIugmaYXikoNQm2GyKAeNID6TRMhkoqpNRMQelyeUiM6lnOzPysklVC1yxAG4JaeRzSXP7BEvlIAa9FINVCmD+0ufrCRnen5+0F+2svWsrOxGddPYXQotHsNvW29mvZwLLIbyG/+kg2QAAibSkbDnGQUW8uoVFLVU7G0bEwnVia//uwZOoABOBg0GMMNHB8iVptPGa8VDl7Pww9KcJHreehlJqorHTpo1LbEqhqlyk0OtRpPpRTbb3IaNlW+diHtOqSaSyKJRDNDj8mVyKSIqXRINVQITGmzSJzQrnZGjzB2K9yWOQXFSpL1sOWk1MlsOiQyhZBWmGzB9ag+W1X9zLmD9tkGr/hd8gq3P1rvY/x2lcGerXwwIBhuUo0qtaYmAQoADGgUGGOSdl5UAQAvqhyV6sVlT1ImpyOlUhxj/2Dse3FcJOQVfeZNYq5rtMjVFidMbxaX3pmYu2E5Lv4dpW55iCsbmW1cpcsrE1fRJiEEiYUMX8CFKEm1CM1+NKsbOWZ5EO7Bg1s1VmJF2f0ly0fMUbcxlF/PzSSNz2pH3LfaSRLp6uRCmFxFDaQlAGZsqCUMplFXG222YHW/5bI/ut60TYSIIBcS9ArExwiysA9NN5CWtebWJLgwCZEY1LL9ojgIzNod9B3sVBdSYfRav0e0Wqv/xFK/jQdKmJZLZ4GSPI/nv5uNvuuN4iKh4qviPgaVltTfT3mRbI+zGntAeB6WkDU6IEVpEgDQ/ijRPODYR7dg8BehEB6IswKdMWxkGGoeuusQQDiaEgAAMUbS+IWAkCun+Q+AaHhLSUgUhwCAHcKhRLlvJ8nF3AoYYIBTCcYgzBsGY2ottMhkicmhK5cPkUGkGUXnSbhWZkZnt2wwz6IG4lQJF8mbsl5oMeDZInPpgYBi3skWxlu3AgIo8bfPC4OutV/kkTkUk12IWsTypZLtUTU6SaaDVLnAsiFX2bUZ0ialSM5sy5l0NPBVpJ0NdsirGiG5DUABG2Rr1QuisL/+7Jk6oAFEV7RYyxL8oXr6m1hiFQTvWlDjD0nQecuaXmDDjCzpDZPlm+M+1OCJK40v7G5e+zcW5Z3IRVRtozhTedTlI9OIMtRMp9y6f7mUl8KMTzZbPOe9EijKGy08yUNMzMwVBZkvb5h/bDgzIzfkdtavqXmfEL2Zi1U6xj2P+j9bAigUAKMZ4MIjCfXVUoS0SQyIrU4Jr0DCoCGWlgxYDLWsp3qqrFl7hL9eB1I/ML+D6pwlDYEbFUSxN6BeXXscQHfSRiSou69WzJPik6EIXxXbMjpkpqTw6HM6PLaZHkEsJltGvJfacjWtxcJx0+yeq6ywRlt3VVuoVVEU2PhJ1xIz0BKIf8hHjXtUMr6ibzKPLesaqj6YH3JdpW79JdgTEHvcJ9VUDUdMZGD2LVh1P/DX/fDC0qA87XvvZQ0TgAEhjGhhEOciIkMOgvCYRKEqFP4tVPdhsaVxlpSdF9aljqfvWta3z39fbusLoODzoGFZ4wouz/Q22IZhWOoBUOxjp17YxHrW0sOqVFaPiZTe1/RttGqoiah0r9K1qpeOdzn3r5ieCRbm92hBvF/sKNeLLUt+MGupltTSIAIDFWsBNaC1I1Bzi1SmzkKbw2xpUVA0pjr3HLIQgvpYHchPj2QpPG+Tl9ZvOZjh7xh5u5YzETUFOr0aWY6KZSZkjoy1sKEumNWeNCO1UvnWF2ts8rEb8SqYaH8iCgqnEhHUtLIC010zQ97PpzSsr6Ljhp8yIzJIdFTcVJx1VWb6ISUlrSVLFimq8ZVjklXvKaVZpo1TSxNFpZlE/IQbdZCf+VNYKCmrvy/iGTksEZAgABFmF/oqiT/+7Jk8gMFYV5PowlkAH6LujxliGwVeXM7DD0vyc6uaLmEjZF1b3KfdMFpsbRzXWhoxZRUTguKCQjNIgKPqoAeRkLsId/enoOihoZjs5UDb6Lgm7u61CUSvW6cDGZQilBQJT40VqpX/ORB5zN28jhlyZ5w/Nj6h9WHJT2h8Y+HOhRswoIfUluKf2aoAADgg865JmVmkA7SfA6GIxlnorLkSFZ25i2i+IsNDz+Pupgyyj3DYtzSujROdBXeqxwxs/l00ZUxP0JZZ21KWbC0HwYkrWcxtyL6jRTauT9gvcYORTua8yHHEX2ddltiHufTc/bEWXt9IxOBxTTI5qyvqY2NWUBIWDcdvMO1GOCrtOGGb2gzJMHUgty1c09b2jzbsxV16rEJ0jnpcTWasy7OmN48tTt8m3sl53ULobz+zOntZpgarajkZCiiAmNOelLUsSWsmc3ghAhYnEvlBp5+txlNRza9flBA09U6oZN3mu3OgiQGVXIDykKQzAKSd5EJSciaZYi204/AFBrQwJqpbEMoOt1iImcIKhw2eyn5kXvk9LDYtNHiUwTSNJqoqba+X+37chl/PjCkjCTyM+jM6dAUAClwcwpAGZqJksGKJBQ4GFj0B8fRKR2Yo968hIVEky0g2j7RDSvpGy3CShKFzGbygOZpju2ZPyn4ykgjuJnktlXTOmaVmNBURYpDTl11QhDfGV5Fp5YthgoZE8QhVR0Txm48hJoIGBJnqK33myERj1cKjpFEt0clksHZzzY9W+VBKW5lXehOafuszOH+e2cL1LLC6OYXX5vR78vS31hpeYsatJ8iviObbbZ3Gg+KHbIvDVP/+7Jk9IIFxl7NKy9k8HtLqgxgw6YWnXk1DL2PggwiZzGUmfFQUJSAAAAjyTApIMRa4mC6MyCRC8NMthYrAJG3jBVpMjFyMQAePGteyPLETCHVM2UJGaYYJHRXJG3ILUXTslS3k4tTb9U5B1oICyoLMT5sHgNCyz4KnVSUhUNrqonh7tiNtBSFnT35GIrmvHb9K0FVHb2DvfqDrUZp/eXGzyzC0CX3TJAACY4MVnJg+DAGmGlwAChwKCLZIhqbqtjLoCS+EhAcBe6PKuVhMNcKUXQf4CQyDoJmXiLchJXSuJ6FyU2DCHYu2Y/TqEzUFxYiQHHoz2FcuCmGKNxUTN6jU1jhMRPq1cFsKWJdJnQbsWELEpHUElSbeQEgx70xXY4yZ8OBSQFFzDKETroeVAwInxFR/6Khn0uuggIJXljOr8pE1BgRvQ0Hzl7ZhbVV5v8UdZaLYVNdH+UX8JRxO9Y5NVBQMTa21QuJYAAQAHEKk51yolsAL/Jothbu69O18QgsKUu7KnPfRCMmd7k3bKWVSS8dYExmS6BL2cTpTRVlUSaarccglXIeP6CrxyCHZtjCbf5j5WJW/yHibz0lePAyESx1127/clf7oDebvN3+ee/nZpjjCfPk3ZkgABxIe9APhpMlph+khJEjBMJ+npRsaGXbdVgSdBb+XzLX00FpSGkYWsI1WZfqoZFmJSExyuTHwsofIhqWNomT+pJA0Z0fSOcww+tqdOnrRyoOGPLQ5GkJ4PQFKsjgP76cll5DsXLJ+bSvOzYZmvMHLtNE9Ta96UtWrcwroEUpTs05cq2snb1p1+OfhWk239rY9P5fmf0t877/+7Jk5gIl/11MK09McHHG6exhJnpVkYs1LLDVwV6VaDDzDeBTgwBpM0LpzTaX3RjOS3WLL8wSktUQAbOdHuYH2EQSU6B1QIQKxQCMFuXbtdQ2AQRO8W9lZOPaVfVLJC2eVmMn0SiAlJx5bRW6kZOraGs4HNTLobtht/broe/eYykSlTTzdLjvnzzhWh2mgABAAAAAEaIOYgCY8McsCW3FrqXSRAKltfTnfNHtmDQmBJIsAQ4mZ7GuQ1vUZ5gPQpxoqkdI9aJXkdKlm8wny7jthMBdoqFmXBOK5lkoP7ad2P6dIFtULEwsj1skTzAyIa4GgXJUr7SXggs68QUvakYVYwptyUh/pZ7Rdub2uGp5M3Yp3sRWvrth76eXSzL4LqNFpiGod5iPZ8n6lo3gT5j5v4WPNJe8FtntGk3W/m3K+jR957hvWZLwYUa2otr5b57wsl22G35H4gQAECrEiJ7G3xmKpaxcEGDVsuVc0JtVsuOkoiTWJYZ5MEuHK9XooQo9jdXxituz4L6noz1ieFxlYi+Iq8Q+VI6kMs0FI/Z15DmyEoUTHb5l2uoSeiKxw22EGYcTMhbYKmaFHNqAsQrphTqrLYp4m6SJCedmVjVnMbDXpua2CmlVCpEZHJ12y7LaC8rvtZxY/tWJWWF7TWxi1LzUtjO+3/eYV7Z+YfzGms/hXtjU9d1f39ab3jw1tfPgBAfNAkBAIAAEBANqRCABMPBTcm4MjDlwEBBQADAqCEQUZGJiMfBA8Y8UjRuZQQGDhhigEaKSIev8HQT3OwCsUAJIqfo0IwAg4JHhMpZg8z3OCu0DcYYzRTYBUMv0vINjTpr/+7JE8oAGT17L5WngAriMWYWsPACiTZU5ubwABEIypmc3kADEYgjmCSoVpJtcSdEYjsAaknjEIZpK7vzbWy1jOFqMHd8t8nOzBlysHZezuknp+X00jXO19f6KCxGWMThKw7byViUYgu7OTV+BMY1LVdtbjcb7G34hiDrbp2XapamcquxivHKaUfPQXTX30beIypq9PD8GVqj9761mM0las/caj1iDrb/5ZztuCZNUnL/1t/QSOdqVJFDVmMYzdfeGTyxeVcp43KqfOl1SbAH////orAAwCkAQAQAIVMSBAwVJQsrRznHs90IMBIh4iloCCCobmgipkgmJAykTCwhGEzQ0QmuQj23gqIYayNRd1g5d0SEVKZ9KeBkGvhCm7OKu8FBsQh0QSA04EHRWMvG0VtU4IJXQuBwG1HAwzsaQDDVzw07sOvWxuWum80niCwkrLbAZZmhhgrNTDa87a5ojDErlsmnX6hcDyiiWgvxpaXYcWIgkDMI7jRUEg5K8fhmrD8WllJDkNl6Gjvm7TgrXf9fy6KLmpv/1yzvF933yh5/s3neOXRKUsmj8ak7gWYYn5zOKTEu3K6WzLavan8yz7WkdHqvlKs6f8MMNahWMLhyJsHppRDEvllLsg7//11/4P3HK6ghjWSQAAAAoZdNGzH4cSIOoASzSVA0HuksVlCHWHV2s2hiAn3YVCqUcl8uEyJYmJXXZmOKu2EtxpOb5XmiN0lpuj+Vz9IGkhyHH8dULD59fMRh1GfsOYqTeuNdfEm2yNG+KRYN5Jr1tef3ieaDiFW8+8WznOffMC+Zd4pmW97a9/eHPTGf7SavHrrvMRLb/+7JERwAF12dQ723gAtGs6fntvABR8XtDbaTRwkQvaLGkmdinkf3c5qdSOn7habCsU8KH7tafZUsvH6ZeasDBBiN8B/pkxD+Ne2tY1mmYGRwBKAAAC4MbDgKAIJ0PS/CMaYKmLVGWpCw0zJ+Gl0LeP6SlSMy0mYBzI5IvoamTyiTj4v8UT0rBxCFHMDeJ2DdLCLaqTnMIwVAGcXoM0kzm7cGV6ynTZxRJyoYooj+ZPPm6F4rJGd2RCkmUT2HNq1H6q09jV0prqRXUizy3xdrtjLa4yZbY8NgetbBET824ElVfSO8jRLbREFiZHGr+PBcNOWGpyeNuKYN9+xvcx4SpV0PMjkiCkQ1ibbDja47G2MLe1Ho4uN4D2W9qQq43qmqSXlFRMzSLAGb0gQaDAipckGmuz6BUoayXMAozLwctxHJYlG7zuVQnjJ9CK5jAm3PEuuNKzzxTJz7IoUnTQijGdOhA4iWauWLJVDaLXlSyRYaOxe61Xwg505IfTSe/JyIfMq+2J/rpkrBXk3fLjjznKI8tu1EmklBcoJR2NfvzRqVKn5csa+pJPs5bXG7BSU316wVVakRggAnP1nmSgIEkOHAi6pMEVKrA7DPFZFzPO0OCnkb42CwcbEznoiBtbZIX4jQgwp8Xs9NkgnGujlMeSQdwYkao8weWFeNsrvPVgnQC7amW1aoJwuY74eT5fzWwxuyJ2OtrNPBfpfZil2i6RGWrMyWl9Nw2SvlPbw+km1/kbRuxY7qJ1vmNKcpKQImXdUsBQzEAQAYkRaLBfDAWAwAgCrEBilyBoMEFryAwYZBhtVgGGqBSKSN/AMos14aZtWr/+7JkGAEFpV5O27hhcHpL6u89BW8VqX03Dr0vwcws6r2DDm1pc+5Uihwwv8mi61i02/Zcs/S4ZdFKVhxuJUesWMThkdHEz1ySZXqsMz9VA8P86XYz5Cl8syyab1TomkaPn01sPjlAlgSiTPuO4yWC2jtEeb0BeX0rEe9MXquQykPqyX1jGvQzHFsKKGIa3JL5mxWq6b4XTBTVajMem1mZxYChBJUvbO9YJNzus1NvrIk+B/IkmqVLwCXAslwZzCAURkAkhMgxnLEX1INBsBkkUq1doxo8kmzDam5WR1vUR7PXPCecIBb6LZVoNUerNRRw7di+jy1Vs3I+iSola23ZqdZmj21UlCDamlTdlFStKNMHWAgWOGCjvFBpjkEnsDqD/AomMAAMmpsKgFAQADAIJS/qbDvlwUJ9dQ540NXjkLIHFHgFZoo8l46oUJub2B5CvdwhuO4FFRDVkBbRa12GMZcSCyR5bWZodcqGDvcilY8EAQVJ5Y7yvc0OUWEBEajEoKtWGWBx17PyDxKTURCHHaknHqOJnnFlp22Imlk4osVMa7BSQD1X54uQoVeQT+EL6RPWI3WWJmMXkk9Lk56SoASSS6BB/rmJTVU73RiVSwJOZdM9NtLGiGGddl1U40NxIRfJDqjilerCoI7rDaKXz16zbnICeWanpcKLzuynCemgLZFKVp1XfCqy+8oz0syGvAaw+S1T3mvfpNbGJX0PJNhRn3nxuwKX1TjMfYZ2m/SP+ff6XyN/l6qWX4IV8Ie2vwbVBhQAADI2aQUhoGWOuQSCasJKpzDgDiLtZmsMpwu1mCGj6G4XgBDoB1aQAIkEc4D/+7JkF4cFWF5Mw7lgYHarGf5ow6hWLWcurj2PgYaYZ7GmDZikQqunbCEdrnAkNZSkMmeSS9BWgkDxA0D+r1cKlZejBlNj+V8bJyYJMiPj3U5ixR8zHatB78xhcSuTd4l1o0xztTpa9j0CFl8j5aIUJ3eXm+yBOts1ErluJdtSaqi59yevLXrcrSmnuSy9T2vPIsS3amA6XT/UmZVNF3XKAlKDVCI1FQI9uiBiACpgDQZWIjLM0mSQEuaD2RsRadbe9z5zKfnY/jS14ep7OMhLljlLYiM2MPHaXaE/vbf1T1HmWNgBJ+MI1TEZaRQnj6MG6nLGNizReHP5NmJejQj/zPVj+fqfss8v9fNeZP8nOGVCCRfxXKCGNsMJB9wjHQrBwhAoLGgeKAIx0AmUIitAEYBRkZ4n8rABgvMYIjo5YAjbApx0F0hOB3JyPplNxXNqrJZeZXpMV3dD8hagHM/Q/sJzH9bnQSWZqLq/OR8zEo7eKYTE1WwrJNvIYMn3EpQJNeILUCrEyV/Yyk2swdi3TbIVJkTyLXPRzYKTU6uUlszLdehlimu9nYug7ENnJYt8wY1sHtrrPrXbS7eZafvPOGlnVgKmiusBIKMgIAoxwF4CIs0EhKyVGmnPjZpJXDKwLGoJWjJztTlQ3j6qeKtlYcNsg7hVQ3DwlcXYopzQiNnFzpS1b4SXPnjwyWFkJTtEQTaHo9k8AUqUDTiKE06VrJfZT2gqo2p0kioAAA5tPOYsKiQEZWHsTMBAEqBEEAodTGSaTSL4iMBxTKWFkkxGUqFG0unelbZWcO7bn7brSas80QrU8fV1L6B4YjLEGMIhy7z/+7JkJIYFblvMM2xGMmKIig1gwmwVNYszrbEXQYOrqjz0idyNYdsjLZzkI5AeagYOl8nKdqNDREpBkuhKbvkkvCzWCVrNYcX4kzuyAfEZA/F3TYsfMDAtvzWI6EqRztRrwUZUJEUizVi0DcZDMMxlRJc4gw77jjHCcEYkJHDvkt2JZ8nUxnXanEkKwhCKIKjhrkvkeoDlDqWIrgWDg6vAthiCEtrFpEl4PSM2TDjfKu7smvZhTGLQUalK2o1fO71e6lVnk6eyZC6nJsMzK1LaHTV767OqBg4kpkzHQtBLVoI9RMtGK2MYkXt6QABACId0Smgg4WBzDQYxMBUaURGAwWDHmLxo1Jby552ZKgX7KIYTldVqdvUELOlm4BlTzUktWJdisI8BifNCetCXxxBgXqaJ5bUuoaIPJQ9Ed1COFAj3Pj9/8SGz32HrLLwYnWa+qnU0rJaoc98o7clY3ZhU0rFFFO3qpDBQimEC6w+76D2tljkvvlI5mq6XGTxjbTmGksHDRM4pjtYHJjBOsdfJDnUBlNAM0vEUsL3E5LeQFfCsBZE6L+TEKlC0kf5ftDD2hYaY4r+qhp/NkiVTR60kiqdBG7jMULIQEAH/L6cdO/MzoMVkY3Jzl3vVTJu2rVfRxBtm3Bdt31u+3u7EP2XR+Wo4ZuamCpaaJAIAKbx4TTCgUFSNh4UCtwHACQ7dFVmGrseqXtEjMTBIQBBBIWtAWiGIdGAROo4RjjmDA4XYQA/NZHFTIBqUiwK3VEjqgW5eWSptGxrTqeMogaOvcwl5Kr5Dw/PZfaL9B+7DmsVE5u8/ZBHIggtvmL8bN7qms3yvlen/+7JEPoAEflrO7WkAAI0Lic2tIABZEYswGceAAw0yqP8ywAGWRaz07uHXBwEhFRA0UBm9yXZQBpKlIAAEFqHzJAJkm+RCyYUuZ4iEcgBjVZcs65CvIAZY2UoDAPADgTFBQMllsOBqHw4oWKPhBAdkD8UHoJCUoOWHWYTNKNMqA6+x0ClyLUVBYtNU8QiiLe5b3Ed7INuxiXIzn0vdu2Ewfk5yt2ho7Eor6RM5/70kL/NfCynMc+sWWLLdhZKiB16D+29Y0kOlCTmwRRjNPD8iEhgAEKjJQAhUJAtJIu+sMxpp7UUcSTGiXMkwfqKSJfiXkrgKAkJHIk8YpOi3kmakCnzUZz6HwWXRKdOhGLyTNAjlOyE+EPUpY1tRyvdIJWJtHPozcaaOg3ktARCramrWX7xabn0RYNCaSJEewMzWbNV1FkbbV73bfM3w4ykcKoQlHCd7B3W+sa+OxQ8XhxYuabjwGEuajft7/DgxwW2mJ8wI+r4//tmtLd/j//OO5ahx4XgvAwUGfT//o/pUBuWiGNERVQ0cdstdr1VzNJCFj8NID7UiRZE2SRww3bhYt0FhRGYFxhKoKCixA5DqESkfYxSVA/HeAfgdGISHKcnAqfTRWHqGVxw6pJW4WDofGEAUNHw5mYvVPJddjdNyttHCGLnYTCzBAIxg9xp5wqTb5MFx3Y7M8OvdeznPrzdK6pqndVEEPxiP56cjwlst78hr2Xaceu8zfZrsk/oC0htEw7fia6Glm5p9NmZmWo41m0XsbHNPmVAN1VccX45S7fiKiWb12y2u11eQxMAYFYFrcgV4uaOOJPxT7hKLMdsOheUK6BL/+7JEEYAEZ2DW7jzAApXMSt3HpABStXtV/PSAAi6vKz+ekADCglaPQJlCx+gC09Vh5A8BqgLECDbNHGM4pFD6TLozUnx+vct+CT+WEgdoJmNsdmwesznD8yU6NdAnjZ++vynfX1V7WlQnuz7NvY/qKjvtRlp7XzdoLz2TjD7y83M0xBwKbe4b/rwCmJckyZHYrbbbZbIBSEAgIAzD4FyLeLUqzwdk1P2O4rb5kSGsOmTiBMMwXeMCiUXHvsHCuROjJmi1HJIkGKZFEQluoQtVMeuc5UQMeFQmh3k+IFC7bE0CnVacfYXu1/PYe6QKrQ3fjthLWX7kWkczctlnnO1Nn7qFbD18g9ttidyShXudg3I214SzMhhfb8PCf//PYxNBFm8pO8xEsypJSiCCViqBzAWxBB+AVQc4jCFmG9RQRyOnECWg0CoWtJaRlFCdnfplDF8l24sWoOMNKLRYPxYb86zr+D5Y2TE8UklVXwOqYKgXPA3GCbJJPYYbjZ7+UGJ1sqfLXTl0518lEd0yiem19VNFmW1iLV+zcCaOpYxKDd1CDUrTKNpJ1vyFwhiFEbkpFFXnmQU113LVquclnZZaSQAQIhDlWAjAgyuEWC9BjCbkrH2hwdB/RkolBITA2Aq85ijp5ZeGUyo1RV7rdAKxmcUe+bkLqn96+3DItxTz78lGpRWOB4njcbc3DbJqXht+mK8Ovt66r6+xr15TQ309vyfT7aWlCcd8YyjNKV1OWTzPWoarM+XcshJ6Op6a9x+ZabjfNXeLbsmXPyhEAMJMLaS3CFImJnlAxCNbtRnAIaDjsSiwoAEPyYVSyHg5fCjymav/+7JkFwAEpWLV+wxDQG/LSs89AowSWXlT7DEPwc2u6nz0FjDXO2JaWkZrQMYG0SaKnSQhVTDXKpcWcYWLHnNj7vkL2bZw+MaHWyA6cqwjbjxNlQMuVOHeQTcVXAqx2qVoVFyiT1ScljzOtubu75qCxKtPMxMQZQZBI6xUXD4fkqP1PPqZW5Y1petME9TdzDvrSQAEDjR2J0GrB/BIi8tQ4mUOgoDKZTqNRTotgpYwhBIPEGTMxFQiOnHHyIY+JalVrr4r4Qy8okEE+f/iTHzPoHZDszdFM6TLqnCP1R0z0q0h2+7HqjdT5Am6OTIyinbBqNEh2B3hOWzVypE5Us7rG2kCEYiN+2MrAXNYOxWMFu4GS+SMQdR7daApC2x6aoBdVI4SYZqGG3Y+45c/cjmZotq2a5HnK6zXYPyBpHxfcgbB00t05aZZXZ8A8P8UPgYsj9Q9HXjSRF5SOZ65OFrlLXOBtcD6m2HSdBjmQt+5Te4y6amtVeoVlyR0jvm0GgRLYecTCTcspTBZsJVUojw0RUKVabAAKGLO2UUwTItibIZCG8TlTv0kfZhISbp7sDKHdRNX3rJsOaPjmOSMY8ZlzV9XKehrLKg0CroSbCFSqIrZC+lidJUd9n2LZBR8jtKI9zOlDqZHqV2URpVGopc6HqayuuFjtB4syoryCx1NrpVs2+twrAAAmJRWUgpr7scqioGbM/02VwFN5REndblM0kCREwThkuURRSKkPlvkcu5ALtUNjcGq8X1mOm+ZESmaxJVKXTKousjbuMzW5EhRe3fplUDfRxrwyf+LFpfG60CD0PNFDZU5pIitipn2dTLMRgz/+7JkOQAEfFzRYwhMUnHLSn9hA6hSaXtBrBkTga6taTzzHeneZkS2rWVd1iFmKbKsUnhaOHWr1IZHXfdRZAzpflZWmItnh5IEUAmBOPMMCZc66i5IMOCydybj2LbQ2p8ovKZTlLKGep68bjcppsERnq7raFgbEeVbw0fxHtPzAOjpTH83dTCH1vq++34sfAXDeEt/tFmp5y5F85xylsMpXLJb0v7POfeeq9xJ4ZkMMi4svwWS7JQxIIgBAgL9L0B1BQCxUwEtkIIuup4UPhEJkMGQc3tmgfqWymjwkpQHFJFICSAIiUiKqdUh8OMrTpCHYovvqn+4XAcITooLGS9pTBojMcICp8kyKqEIL8+KNkruKvgXCHGsfSA+UI2KGt6s+OxXWkjFUHjBCEat0+UZVo91oQUuBoepYkD6GJHUvQteUPrkOXKHVZZkVbIWQCg/1IASMgAJAYW04FiETk5C3Nig2q1NJEs8ASREJgGdCyLUdK4fvhqZT5KvqYKp2t0azGlgHaoTmlSPejzbdTkpbdjen6I93ko6y5qZpj2t329jtrWNx00jS7zprIULuhZndSoE5tJIICaMiRS8SEBNQOSQADrTikw5clShHXJ/GxLsex1KZ54CKPPLFCSqksZ3VQ3MbF11r5+kj299xIgu/ai/++9KMOv2fZVxyy/aauKKl0bdOMVeq/WGdTz98lZqJ3c++vZdvZGW4rAlNmknStQ0QbiJmv1ZP1EWfJft+/nT2vOZvMmpUJPOPsjUlpxWDWre/6dvvP+lUWiUDKSMwRBFJAmzOo3Jp9pUpxKW2DKRGEyGRLvwL2cGWUKQbGK9UXv/+7JkYAAEzmNOWyxMcGkLWf5hIzwSoXk7jD1tAaQrqLWEifiWZQ9+zBuSllyf+xeeo5nKZFRBBVyNlikVArXPbd4cpf/wnzNaIDs2euR5ApCnNips+Xc5fQzn8y4/nJKxhh6EAJ+oExuhoqoAR0LHk3zaRK9NlaBAoMBDTpJXFzE1UpVIlEEuV8QOVM0lUZvLmrY2s3unJay9R9EldjMrQdp5ZSpPEW3KtY5tVBFOqezfqEEcegGq3BiSn1uH63Gn8RwYKp3G1arZPzGmcJM68VaBDrToGV8sPnmnIvhdnz13UKwtG84beg00kmZ6DhoedRnFbzKWMCoFjKit9s5LJrGiFG4Zn6IGJVwj8jImpSsCzkE3DfcoiSamNOPzZJiP8VM7EpPfGG9XXLrpkFrGQsZ+yKeuVSSbRoOIlIf5PdsidjkTIDysWXrKzEBEo5epLEe0nTLXRfd7r///p7GjkFhiyI4Q01pEzSAQa9sZIkgACAKcIcTApC1/EDlg3nS0ZO+DXW6U8la7MhOFiRhRNYLNsMCwpyRwfhq4uORxQTn8K6hZxBr7aIE4tSd0mEb+VVrkQhZRFHn3azWw5dFN/MOyje8lj+CPoSNoHYC6ad38ieRAAJ9KZjInxjJxTUjGYluaokFnHSTQuINqLAJvWNs6m71OUGbvgiI0PAiY16ASAM0GgJJUuspY4IVgy5YZbw0EwnjDJ925dv62Tz0dTISl2OXszu9ytaCYVuOl3Xma2E1OeVDJwRQcCpoPfZmUX49PTf3zUyp1ftR7V6orUJu/QrSen8iaMvUhSkLUVYUigr1khw0mhGcKZQAYCQ05gRH/+7JkhwAEpVzO4wlEYmrLOf5gxZgQVW9J7DC1QeGY6T2GGsgwSTKQUsssJFgJWGA12OranG7uhA++ReF8jF1dcJ/GGhwNROHQJwYSYExYhmdsXrzNBgoYAcU1fxt/WiY5CTw/Rz9WOm9/msWbC+9OrtnVkR3/Mt/RWoydOl7NkE3p4rfFf6d7//ZatZZzoXqAwI8RWsVjKwE2QzhELRIpANyQSs/1Ghq3sHT3DFz4MMAiJ0QLBDEBIppKOCV3Wmbz/xZORvOxO1zJrDxtvLHfUrGYkKBzADD/yXCZv2JB5J44dheg6d7EkEbza8cyH2IeI29Qk/Ywgh4IY5hA+Hxc+W1iAgJxdvvd//u4hiBysZUCfSSttV05VUihFBoQ/ZDVAOXMOB1M5yDXWVSqCj1QQPg6OY/amXGM+2YrZyDZgPlXwxCMuHqNDTocCkIVI2vJFfsyFdxswMa+zxtuML5VKljj72bjIT5e9O/Gp5bV3TePrrLHwTX6DvIv5ePmef/393f0cYghic0ZeCEEDBT9idlW8LBRiJDMEuNpTNarL7O6gol4mrF2DpjOc4imagykB5GpQ8sCT07XZjFEbjvldxLDzNaIg1aQ6s+xE8qkXAp/j98vKW2kTUNNtbeNvYWmxqkIsxahzqV+6Nql7Yd5KCEbJkvkvur25+vv/fITed0UIIIPB80ERz+gEJllFaUkqbJUSvCCl9HULdwYWMfRMkCTETRWkDkhH8r0cxKVSqFmZ2kWjstNhcvxdWsa4cHYc9IpKbRPkc9Hj8OGa8bdZBAj6gB05JOT7ETsWr3L+Vm+F/mfp9bEDyV+FJvkV/eqorT/+7JksQAD+1hUYwxDUHprOn1pIowQqXdV7D0Fgfas6XGkoWGBrVwQnDfBZycqzS58DBDBYRoHr8NMYwTgIZG9bQCumTlMCCkERGQ0Y9L+GFnJUzjrQ+sC4pCDI2Dyk4zVZDAAhEteIbZ5a7dqhn+0OhLqIT+Pnof8iUV44vuCdRICtrc6pd0opVThvcoiBnPETwi/MC6SrXe0j4e7a3vxCfk9T6QTR2Lm8ICkepQ46IFh8KhojSyIP4L2OSOfkgE63frGwSACMSi0hhkFYKVTvqhsqbQO8DfxJaE6AKclc6LAyQSaqhXJboVVLs4qPbKSJu4kViSSYuTIWfvambQigjTXWVlzsXYq15GkljiEk2e+hg7G5V9j49Cq5qIJatd9D8fPb/aJAyVq7uOlWr7sfUTrCPK+UqKKYxMdNk3b9ACK6qsu1sTJJYdkFvbRUCvl5MSX0mc1902ky5klh6ozRSJ3mpvnK6e7Epg0ijHKTRg4WMfDDROubKLbj7jv2o3TfCJwTla/f+x7mGEn6oSMuY65AgWWjoczZCPZiuOM1Lsh1o67u2MQl3Mq6JuilzrVjlcYFB1h4kwg+S6eW1+6AEqjmnwAAYpWGQFxk4kGAS31D2jMORxbgrcy140139BYyorORncnE5DXpDBpStYrerB6sS1pU4YgsYOkxKVriEvlmVKgkDi4i19RsSiiFwhGpqwrIl3lMJjqviFEUVjOEpLMrwLB2YWyzRxOLWpRkDotGpRXQZLkjTjBGnbkWggJSIHTNHChQWkWbVvxj0OYjWAZUrm6USAADL7wycVAxSkwiWgCUFUUR5Uda68Vhg1pu7X/+7BE2gAEB1pS6yxDQoArWp9gxZpSLXlDjbENQlWsqHW2JfiGrDsJysvnSrruTRw5XU1Ganv1hnLS5Zeox3IqvUyWe2dv7B40XhUe50MVpslTVdSRXupQxFGvPyfXSWni0kp+zOXaImUnU6miJ2aezmJxtlOayd0lKbnMblKTyFrTQuXuoCqC6FFT0viT0h7xcGFxYPMbpgAkXXVSgACCDGs0BCwOSAsh7K7ME1VkQuJLCIoyRuzKJqUzbWm7s3nKB/RKJYTERnzIUD+XEEUnoRXO4sw0iOIfS2XaTLNorZwGlifLRwjUzzfUQ1Selcpks6oy/xTDXgiqVzltlYTZVlG0AkK/YzTtcyXYtCtLcYi9aZLmr7lLNvhCaT0tMVqbEtSoQxrGUNLERX3na+PnI001AZQPSS0AAO2hORsMu2LXjgIwRwSFNIS9dNRWDMGiZMzo4AHNSlQBnJisSiLZcYW9l3o7Ys2x+wafns0egi7olo6sWRtXCQRhtPXWijs0+GGM7L0jPXl0y2XkxHzXUmvdG1L6qyzR02Zd4y7Mhr0Fiq7ZpQniEbxRqeTLg00s9BY6hF84OL/xABkQRSI4kQAAgDTE0KNB4QOiIAEhkgA0bk7mxxGSpkpJNScJ1lg1yGkSoK3EIBRL0xfQxmiIDU4CU9rY6PbEPm24p0inON7yKd25RHEyr7tVzviG/SCHtic6tI17nPysahm6U+VH+9QfafqwrZd8Yy8chdcM31CVduU7i/PKs/8oU6ob2U/XacsGkN5A23m/JxxbuDrx3WAGy4moANi1zdJ4KwABEEewoCIHjgIpYgyKAyl+1D6Zmf/7smTtABTZXs9jeEjwhus57GmIelLtez3tsS6COC1msbYh0Sxou6YlpeTqqD8JHmpMWFSDDYnEv+XDlT7Dz5Sfka9d4eoA0PrkaOUpiTUsOi9aNq5sOpqCE434EK1JUlPqBOSM2ooEhBEIeWowaSJoJMFWFZhihCfxWhBrsjrKfOFnHi0CtzZUsjwUhS+OgUs1AERNRLAmdrJOUGKipEKhQJNUvU00eGv1ukujKXL+MSZoh9K5l1WZwm9p6wXq+bamra0pkArjxirdzZN9kBxVNOCe9QVQtJVqmz9eE2/12H9EBCc6QIPKRpvaJH1FUjMxhcMlJP/SpG7wltnBhqlpZ1PFnG9l/CfVIUErY1P1edKXxJIvDZSTytThRUJpJEhA9AAkqNoKBYYAABoMCZhpGcKxpgMYIKmAgA0Cr3eZNxGpLGXQQ8TeyJSYxCfA7Ux+YHV/sdGZ8bNNurGiK4/cnouzsQ129/DMKfmL0cgvZL29ortts7JW3YCC/ByGvsl5Jut8uP4Nb0uhIbLjllXJExKSaRWab2Ty0y3nPrbiX2/++b81rzvanscE1Jb1ACCJAKADihY3wiMBJTAAsEIrDWBDoIh3Rcb+DlzF1oEi0RSZjdSTNxeW9WzWM39eba0Tv3C+1sBUe/Y3LtmUS6dbPr9Bsdy5a+rF18NEbHY1+7UiQ0LgStUgZQ3ufYXe01HWBdzeUqw7rtGPUjHh2K6pBWVnxZuozQm5+pxlgjMStXJecMqUfeoDkdVxXf5uqjFU5CU4AWxX67YoBTgAENNMPGoofgsnEsAwNl/G4MzQfBgJV85qC7otiZnOQewhh7HjSP/7smTwgBSnV83beEjwiEr5iW2GdhN1aTNtsTVKLi8l4cYh6Gk9wwtfG1v84td5AsbOz3TAsFFNZsfsXY1ROKSFbvgs/qxxlFvPkVHQuI1oLUniOFaeE9KTpRS1DwfKQIREn1qgbEjSNGT5jj5xe5EUp5Wb1S+kW6fIubhHGjb8a863eNHme1UDIkIAAA9c2OSOCgQjRhBOTAaH6qQqBI7uqvpwkMXNa9PPWhKuIzKcNZFhvfQ4KMPOd5ATq09iLO36RVMLel1vGm1Dp6ahtlKqxWNNH7lM+she/77nw2ZdRVcXpn1JDcHOm25VZ0rXf1FljdhYaa+VZL8bzjLZnTWusw81e1rm29S0Udt+Sb3rWmoNs61Jfy1mvDdKmm29lVG7yxrUiK2N4zyu94m/zPmAa5WsCFbSAMMqTOyA5Y9EnQrBC/aaaIEoZaOATPYdpMO7cwRQhE4mAUAmD4Rg6CkgMCMq4NhhjQNuHJMxULh4OcgPeBjpwKG3qOexcRzvMt82Sak53xOH85Z98b/Rs9QLVu0/3812dPQ42kSxiyKjb6adC9KWl47u4m/i6kgiq/lK9Wb3v5HCQPBNBSZwwMQaCwNiINGRhliVRQKA5kYmeFbG0CphgUYyVAUIMaRiZnNlPzBhYDA5jxiKm5o42ZwYEEwleY4pEMDqz3JBpagjoDwIcw0Zg66UJkDK2LnYpIGIRiQowgZRqMMOAzktxImWS5TBilNFlxIIwcmoe16WPDHko6jlOg+cXSip7TqsQbg5CSb9xR0I5WbhS5uo7s1TadyXP/E4vfYgxB+JqrdiXak2yijemmt7/5Y9Umft24fvf//7smT1gAVeXsxNbeAAg6vJiK2gACWSEz35vIAECLLnvzeQACUXJNbkE7B9BKZNUra5J43zKrepL1inn4van5ZRWaaUzcPzz+St5KTTzPvSSGW2OYfm3Z14jMTU/R0E5X5l8/115iGI5KpfFY7VysYZ71///////////////////9////1z+c//////////3vd7SVLQQA7JFlbFbhCh6LJaWjGc2Y06hyiZgSqDmorxkA2ZOcgprUpBA4bqCGelgKCgCEnQNhgDqYKBmgHgwM1w+eQMcaEhKgcgANLfgzDi3CmivSgVncebAyJAC7iXifEGPY3WVSxwGmt8qtdVWUsY7O15jC1Ox+N118vPTR6wyto8DaoHjceEP2+rOoIZxhGnyiUvdu9BkZXwziprkqmLWOUuyvau3/ktbPlvl3tI+mFDCJTZ7RWJ6vflfa3NWb/2rFuVY6lEsmJRYp5/DnbfJbu9IYYynqGW1JfUhi/2X933XztDQ77c7hnc7/Jf2V0lFa7Zm8e3cNVKY7//vvRd/lWsAagXABAABIiRAAIJSUbbm9MQbDHVA2E3MSlTV0gzwfMnCSQaNfFUzDfzFZoKAFAw4cQHqokwSIhiQR7pkFEpyh6ocAAhS1suSjYSrAWlbkgMKoMHthac6apaKrGInFG5KaKvxgOGpLCpS6cbn6C83z2v5erWndgmMzt2WXX7+00WWSV2JU9T4wW7LwvsMkU1FVf3O25TeVsdP9C79Baf6ZlspmoezlNerWypqlyn5XztWpRGIxGHXi9HLOb/VWthW7vVN+PJHfilFS3LPJTHMbO+XLvIaxxt2O6y+alF6//7skRuAAeQZFJubyAC7UyKWs3gAFAtZ1R9lYAKCa8rD7CwADLYfqS7VFqnxx1ZlNjtZ5L1+X8qgAoADTDiBEkBgNOtWwzsvM9MjBR81dDMpsDcTgMUFhjUA0dFDCjEzY4CwkZ6AAYwWBMEKzARFcIBGHUeMwGKxCRLDAA4aXjYk61h5YrcpYSnbO9cWcNYV3G/nJW1heSDiWUOOm4z108beGpI3enXGeHKu7FaQQuBL07PQRXnK0lnozJIW4ziwC1mgrP5NyCns960a5c78NU26nzUzDMZoLVezVz7Saxl1z7ssh6phOYXKaa3lJ5nlLdo5RIpzGiv51rEusVN0t/VJj2w/uN/LKtLvs3ed/L6e7vHGk7qb7+W8+WIvHL1R/aeW09PZukBIKSkMd87IQaebBMbAhACOZ4yVVVIBq9cRiRR43VgQBkEcMCorGwjMRJE1kkhnKFpRMsURdMm7D8sliVdz82txttrp7nNbue3y+Ng6Z+JfNL/fHzc389ctja/U2M7/uXVeyu6tnLNBSmHPp69clS0OuqXNYc+kz7mxkzTJAPVZt3oRSSdoFmenAxhdMHKZ2X1iizVkOKm+5JIBs8ERuKBWNg70BQH0/BFJku2kbULZc9ipKZUqKT008l8NrYfLdGWw5Vrfta+e4TPxaRTP+7t//Ee6f39/M7fe1Brle7Y1T4Z9U6YljHsOvfVHVEWTBFe5Sro2PPtOlFUpVaSOYbE0rd36wlUwA485IkqWZGruUdHgxbTEWksF3RiSl4MVY7GW3le/WecfXBjk8b+0N+heEIUHFEQKjgwRMKsfX+dspN8tO/RV3/Os0KPFf/7smQkAAQZXthrCUU4gUvqumWFlBAReWNMMM0iAK7qaaYiGMgZEZ10Kik4wTy0rI7i/4LP01vghPUZzdclja5v4dvavbv3T5puLunjuVN66+djbGBWbRXq5psaK0vKgeKCm1Gm8z8FfCGkxxVghDsZhDAI0yUmAd2ZUBYmuKHI2+rfSXBosNb4hDFlRgnnWTG05/JgUenRwHw6HGiqs92eY7TBS1Y7kfZA4HRW7CqIzs7l+hZaUu/fzqZXrRFdSqy2vRElZ6qWqIyFZqpzkaYPiruGhxyOLGiY48w01el1AhtfO22STBUiqlYRiBTmZTEGp2wA97L7iqsvWeOgqNUhdFYbbKdiH4UyndQKYD8r4o9iksh3oO8U/PYbkufTC0sxrPV3QbeV+yTb3NzPX/dEP67a9TPYUnmM/7A/7ZW0y/3ffF/Xzb9vfrfmX6c0VvPIdTuz84D3JUdn7z9TdSoeAaAAbUhTq8TgCTBLUN0vQEvJljDlDiqETFSDp0PHEQhjE2seUX8gdKxvMFUqBicYZPwqYO0NbeyQFVxYdELn35VW1VFkAuM9YKlkmB51cjFjEp03F1f8dx8fNfr/zK06V/Hr1z1xF1k/7pyQTx8LLlVNzWQTBVkCNDR1oXqZF5kA0ARFHG1DArHA26mgYEmopua2ynClL/F2HqHSpd8QfhjlmvgQZ3xFNVWGI7Hy8jaxJgoNEC0m1XzLFT2SnszVx2ejHhrZryTO1s9z7xlN8PqpryqpkJh6Cvi3Zj5Y9W+u3RKrqvKJFdSevM+HSLKicvEMwICbMOCOBIi6QGAADRfjcbIccqXZAT9GoU0lgK+Lzv/7smRJAEPiWtZTKxx4fEraimmixhEleU9MvW1B8K7p3aWWcOkTAy3kfVPEUM84GlS4Y12MP49/bj2XZ3c89v/2bxvWa6dE92gN15okaqP0Od1J7ubnl6zrdUvmykRZBDl5jesmnCmauidkf/2qBGoZ3f0kolZk5jaOuay0plqrVZcMO8kePkiyPsAIAAMpyyYxUgq8IjTprBOwUZXe2yAZ1h4QBJp6GiOiQhwkAfowyumRSGFfjBMXKHO1lI76LSvwft2yaSI1PtlOg61ktd5gyNur6Vf0RHdtdsZ6oDETHJb/G46dmpZFxKPyhW2D3BO3VURyolfE121vtu91f23bNu7dVSt8QeuD0dUiar8n6867WEEXNZPEzZDjBEDhph0KHTCasoNKUX0xgMjesva/TDoba8nQ1l/dqONAav1IhSulRuOzFonjzRHDsPlF3rrr6+b/nHuzlROaNn9ttiuafah8Nn8vRZOrdkRCkHpK1u7t2KRDst/Mm/Qz6lT9S6lqdn+U7hR1EBrDVSUo4i0BgAAi7rtxRURRkkJiymh+DEmdpYhQFWRYUFIL6MJlTdQFQB7CyOJHQwxBtz0NnUN3krWnB8us9jVcFYaqQ+K1Y9RNiw9MsY6wg35EWFaQsO4S0CYRUcQAdMmIzWnuq2tX2/j+Z7u7kTIblE1SGmXkitTXdww293/65ua+F2ZuL56HT49XEZZ6v0gDEAAAEGy3ZaBtJmOLBgwcYANCGgAIQGAzsMRGjgyYCko4EPCHBsFx1XAi0lQNoRkeXodCZcG1FR6wp4DvGj1OG160Z9D7m9Pyte67Vqa9mQclTLXONAj3Mf/7smRxhARNWlPTL0NQfEe6XW3oeFBxX0jtIFdB/qvpaaWKODHzdcRenFc7elbVzakMummu8RXobvF4Lfn5Wp/jLXtZHZX6IASpbMGHDgwBAZNx7NPWMuEGlAYcUwZ0RKwxOSkAs+QlUNUMNK4Yow1spKEUKp+tLY9Q0cw/sirRGW+uUNogcSOMHK7iwwPUNbpSxbnG/FVEUHP6fEpYkCU/nteyR25AlaRVxn7GdkjO+MPYyKsEc27ZAS0En0X3pslNWboaGHeZQU3AAQACnPdvEziUh18bEWAgotjGtioL5AACCIKhrAiwdLYeBytoKk1fO/gNwAoSrA6RSMiSBPuzC1pIEAqnKFEnoMZOldadVJFhlHNT0K7qHxEdayNLpjuQVtrUVmKw9nIrV9GWZ29DPoTsDRzMhl0Q1tO8hsxqvZrIquo9wAqzCQIAAATTtvMqFOMdcQ6LQ3NEqQ3aC4dW9h4kCRoKoAmLiwWfZis5IFTh0pYyKLdzfGnu7oANqUrlMM6ddTlG2mcZjBAvctzlmRXvpDPxz56S/9/xJt+ic1Xl3e6zkaswZm9VXwVPS/rmpMbCjOh0L97ufwi+fMua/RnPJSxI8MGLY6ry0StckQFJNuwIyl5BpoCqAvSOWoGAUmYsQggYbhCo2MUB1bUZJSpY+qQD207Y1b7fcWuR+dwd1KKtQZxJD6JAu2txg+7NHY5U/FD/OiL8dsU5DcKurmxYVTO90a3oqaW1XdKQio2z2FlPirc+HCjsl9pVsrj3dFKuZxqCzQdGBhayvF/UECZPbsZgYRsiAcZa4ZSABig8KSaZYyNCBg6bRhkqtctaLP/7smSUhEQ1XtLTSR1QgEsKM20FthFdaUrtPLHB+61oHbwVcBafc3Db0G+6tc3TbvO3mu0ZTNKYju4LnTe55Na3ndneHkS9YcJizmza+89M09J9e3+Y7yNQzwvnOkGWE9ne1mnx7yT8YP0Jmao4PEiB9RBR8LF+fYw9ldnqTXYYgg9AKzaUQc1wQkm0XCAASbWAQIaTlGEkxszOZuBmqF4tjGKgcXRvMpBCiWUxCykIgU1lCTBEUSyrdVQIhA2mdla7Wx7gheMBUEGcu0VzUEKrZ9qqGPERQOkZxrpMVJaaDjyqa873I84HRV13a7oPb1pTTTnI++Yi6qu23//69l6qo0XfcUQY5KlavGIIAAKbThlUJziAihHHNFhKI7CWCmyGThIKqYDoAxSSGo6wtSxCpf7oSNF2E16wik95DBWCcQqo8pupjpN3UV6nUShnoqvpNOumTSLa5sxfEXdNn2gzU9xJ/nn+me/5H2LdKZgp8Fn604h+XO1z7lzfr9tpFwq/ZEReY3BATsggEABevC4Q1zsZCgwsIwAU2IHDxKXt3TMDEsTXdGFXwZDccd9ydQC0+BOYuxQ2KCPwd9zl3mPLkbx7pXFifzJRIWSP/Nkik4lA5ap30k8do7xUxLvUbxN13cIOuiz0/n+73uX0xnadkU8vH422SiFlDJr1cXHiiA5E5BuyX1gFTSTA4A8TxGg0E6AgFGLIuqmSpYs9bbGFpRW1ikgqC1nALG53HrgGzgNBpOS00t5wziorXHH9UYmxj8XIyh7GpjxwkU95SrrxXLVSAAsQ8w4fHWMpDmy9rBXprES/r8/ab4Y/JXh9ZKg81P/7smSzjMP3WtG7SxzgfMs6VmgoxJStm0xsoZMKhTMpTaKy0RpM2oV0dkhb/IWkD6Hl81Or+aNxXWP31iixVPOE9yllnwg3AWaUIJOrGweGcN1h/F2M7+U/umm9zwsAByOd3Tirh1CTXb5mTAs5bBSL6UtAw6AVU39cSYe+FLehq5hC3t5uOzN65I5D+HNueFBx3mM8nf6arnLAlzkMV99xizhgXFDOIa9ZN9wqNHr3N29hphTHDGx++s7UiOmZ5Xebfucfzev0fYv1/jq0YduY13ccdMHJfnAnN4Yef9aJRrSXxDLiI+OB+FknKhuh4SyG/GWG0eURXu1M7r9SCCokUB5mly1jJaQEjMFBWujTAipV1JLRACE34pGiFvVivxDuAmolmoRL6OEYRyd7XI8tHj66xg7iB+YmiViSK7YbncfF1qMbEMGF2gQn5PEbQWudyI4gv5HJ5Yz7q2cQVxtxwPnll+zUuYu+njeriPxlmzwl/R1zApCSHqfVxwcs3X1hC93Sa365ueSIGocUoqqH6FJM16GRNDXbQvpAzKcHuOpEfOUO86SF84aHYpMKXaDDtpoy97PW3/SO4H+YIQeekRLN1nguWFOuyWPRUGxVTEvKdXP2vvNcZUc18zNwdMRCx7NwTS7kxyU99Mc0D78iOSxUKySJCN0Frx5guVfPJdJxUAoDW60kU0eBDkZGpqJVMBkSpUmmxFOAkDmg5L8oKctj9mVUCZEmwscfNPpBiqxKRtuklNLDULrCB89uwwjJj7KTscU4eGV9E/A7nGV7MsvR3D/q4i1PV9C0+gvV1PJr30nwVP9R/PtA/p55SqaIuP/7smS5gAQLXtILTEQwgiurDWEodxAZaU9MMRLB/azolbWOMLGXjDJuV4WA141Brwo0QHdawgdC7xOZCAlHgBYpkx2HKQYI5KGhg0YWCSku8zRb0NtCf1RB3OikBIELMWkU8mLkaKi0qYddYarrsm1+n1Vdc18wdncaDaf5ht1Pck1P96QodMjb/WmfGvRP4DlkCizO65FuMXIWTOUBkfc+mE5drIIOG3hw6DkJFYalQ+UI1V0IHOuROb2JGQ+CBICUqUIirRxl/pqhYLeLViLGWvvxXYk3aO0PFHmaTur230oP1jcsZlSkOo4RR1UkZxiBqoxXQxcossmkBxrc+1VSnUiPigRYkzFb5d6J7wys2zMWqNkYJmPP++UsVuPCzMs51V59Uz/O+FKCkD51ZAEgqzqAd+Vu6tExxw2yh5wEROUHTxsqJtylaaVcvZAD9vg1qHnzq9eCvn9TSbSBMSdgJldYkpGEUCuiVpaV0bUmpspOpddKFFREZWjeHHypv+7/oxCtyc9yfos13OG1h6C6URs3l15qXkkak2qsJpOqk3JMj1EuqiaWcFYIUDjiQ5RkCuEjkUAAQAAABRCMgFDMasrFDpYY0AHFs4DUo8hKTSqLsg4KTdFk1TBuLZXEHhkrCcXjfpESV0JmZIbxeRh9AhRr3C2yyIqZ5CGFI60rDv2T7QtevvdgtI2HYH/M+sbP8BL99dL//lYycGu1tD72aPWbjkPe6z/aLyjs+2zw8TrF7+1TNa2163Wz+eb5JYVppwC8ACJlf/XR1MuED1DIGOJo54bYLgi9GgYiYUewcEPjGJyQEnEOirTKdLjB1LoQU//7skTfAAPyWFXrCRzYg2uammEjnRJ9azuNsNKKZC1nBbyg+GUhIZDSV2wO82Rvo0UDKtxfBqfBh4egYAMJMJjCzZIs8PxPJR9rjC1yhCGKC0xeBY9paCtJSCghJjgaVF3e7M11MNMfsMNW5bJB4k+uH1xsraOo0ooaoxU1H9RE98D1gW6uvZibY/q0KFhygSHh3o6VABcIRiclbSxhAB9OyBOGIQU2kGxBI1AesoYEvseA6/aFZ7c4hNzsTvc94HXmNTLQsfklH81kbAgRMHcTEuLNLkJJcJXqSp+55jrRjxh0Um8uFXMYeZkA8fUJOufFu42NnGXXV+cTdWdwDVUxi96/job6/WahGv1/WeVhem/ZosPREIaxpy7V8mnuCPMgMA5Zg3LOCkYHXKJphvCaUTmIBSe67FFTGClSg74RRAyoZHqpJiUkvqpIdhTQ/brA7Y42+CmsayxgWO4WJ6DWeav5sMkYUAhTRdmmESigQdXEQ67ONYOlopbPdUdtDtJXQ0yIim+yluxBcxjFo7tc267mfk1mXJmLocrLe7qpowDIJEFjYlMdAQQAUSlTOhE5oLHEo1mXMYRzQogzEGGQ0tC8pMMJhjg2ZABryjIyDo/IVEQC6rYlttTgCmAoLxUMxNEKHhMud3UsF10rIjx1e61eJ2I0ccjs/GsNrLPgfo06zEYwRMYQiMF1oYCt0+rq6vjHVjJb0qvGlcLFWJx3CVeMRVhk/taxhtQLvXNXzE86RsqJsXMA8CkTZhznSNquS0GCe7t9sDKJ9M/aswa8DYKsMOk80pETOYSNNAgwMFhUDgZ0cmkKgjH5QwYAnBbQSv/7smTvAMRjXlLrCUW4iAtZsm8FXBP1ezjtsRMKYaIlgc0hOQOODjggExELAwEGIjUYXjGkn1PpPJ3wmrKWaS+eiN1mKg8ATVwWA4wkGw8Ow8BvdVWHclMc5dbpFSJAmp4OpzifgGPnkY0R8yLj1oZd/VRjOLe4sp1WIbtSPKM4YWKiArfyY3bbs3PFUnf4q3/vagCAAAJKSVAQY66whEAogZpIDbBAIZqg02dXhZ1ZIsMdOA3TZIFIFxH4fhMBXFuZpEJMpJGjyosPPMyLniSRQPImjksTi6ijqNUjeqo3c2PqZSRma1F9pmOJ1uKSaa1Tdc2eyZidWbHlZ86YvmK3o2LhYpToLYyISTUCj2ZFFZo1brf751nzhqiymSSWUS+Zqk86fOsghWfZTVioa9QBKTcpmVA7hdY/JUxIABYxrSOjkeE2l9lliwPASCVwgRgUBkIZ6vYkSQ9Gypg8UU0vyWNOEgtQYmnrHGbHr6DDx9U1ZhrE38ezn7ekPs0LHpi+s5n+csX90Kjbr5Hfrb41fefuDPrFvn/V/msvrTGqf79o0PHzF/82vSaL/W+8ax8Z/8uNV8CJnWsxN4a3KHuWeD801r4j17HdIAAAAADAdGgcHwcEgKBtRKBw04FYBWyb0DnL9oGdBEJAadEIgbedmWDwjClKwYMthMeRBoofhGQWFTLbQBENeU2aa/7QnuYId6atT7tKklC8jAHeZmsQwgjCEBUCkmnpDv04FV11haKJHjScr4CnNgJnMPSiXw/M14rGKeVQ7Fi+aeDvw+jeY68PPwnwmc5rc70ckA6RC5VAkvN8c+qDaQDDA49ShWDC7v/7skTwAATnXtBVaaAImovZ0608ACVqIT25vIAEIrIlmzmQAKY3nfprFytPV8cLUBWHYlksRTVO08tAnQ6m6CkkH4bqfjbv7iEJq/YwvTnyJ9H4VOy+LuJBK6wcQ4nNYf/dd/////dzH+8u8////+KPMpgwSTyiWILuv2vK7b/w//////////////////////////////////////23fl/a9P3mfbeYAgsjGlCgBo1qGXKmcsXJ5pnmUdMZkwYlHDD4XMUjEycDzRIaLQgZ0mABeYHFphgJGezAlUahxqRGsqZqAd0YsbTAiJSBkBBE4ZkhIJlghkvcrYQBt9drq9V2pFkL/F6U50xm3ZdTqPMHSH5SDRi03MVjZpADRHHibtzb7uRD01M5v2oU0xr6jLuu5I3Jb5Tz6xCjjKjVPaiGKG8NqZL0TMh+HJyJyyCMJW60ahimuRfc5ap32gSGLlTtTKTR+Kdr0kg/LDK5hT35mUQLNzNixVvVJFlG5vDUgpnEZZK5RNWMtX5jW+///9XK9dwsUOHN///8nfPCV7vTEOX7HEpfm6P/0/8IXmhyqmA3NIlXQmM2VbZW6nVLJ9S1R8kCqSjgqABI0RLDImQaKKBQWIszNCJAA0KA0TghGhPBLjIBB5LuHmODpFY2sqKWGPuFJ+Fu08IdSLcFJiNNLbyiYGwwkKlEHMYc5ryo5Nfk6zZE7zgvjMr8Yg97/tyWnNRaVUjoQXCLUYkdqq1RSawjrtAhp8ozAOEnzob0P2cr9NyrO0sDN7E6Wy/b6TlW/qvd3YlEfqXqTCXz2qSTP7SyKnt2HhguKw1LI1el9+nvTP/7smRhgAeaYll+awAA08xqycy8ABBZk2e9hAAKEKwr57CwAVN2luzdD2xrvM/pYMghr9v4zPzbZ52Ocl0rysQ5ct4zD62KantWbutYyz8OY1o0woAhkQDEABAABtIswhQAGEkBcAa8LrJXm6eGAJBwlHYrCQTPkg1Ag4h6CrAmBd36HBkHeeReOaZL12BfGWY44CDlyVi7Q9tQteVCTYTzYSbPTQcmtHLLJlVtZ4KpjQtpjFhQhErXhuTlNldHIjNq6yjgl+VWYri0Lhyy8rt2uokz5d7dQLsDY4sjbtywrocKNbUfGLbV7I4vH+8trQ7bPE23P9Swc1boWpZo9M3vfE6shTVb8QLTRqW1Rzc3uZ3uNttIMK0a0XNIzyR7NBB4SFWM//8WyRjjCTBRKTpVecyNOSUMoXfl68y3z0W2aroS8e+Uu684eQMcBEesAvD5rFCjxUOhdatjo6gfkPweMuSYOv7i1RuCmqZ74OfSR9QW38P1NzOQ331Nilwpz3sZ3N+Mi+SCPpr5HvcvpJF3pD3a1d6P+9wqeLo9jQbpx17Cg36/+uDD8J8EGgQAA5CdnCYkTVoMdTygOBmlQc39A1pnrUIVEAaBcCZAwJhKM0i992UG+byO89aKCbbMDVsXKB1um7NIOVlDX8pew3Os82Pz1HCq9e/s/Zy88d5Y73vupPH2TCL/pzI7q3Q25vdxPzbfY+P46plcMr3/Cq9bEiyFc2XuNevrv7K727ciyxuN1SBeCdC5FDgiqYjtKVsMCBDKD0PZNs2EGso1JrtQKR/VjJD2bJYWLMeimWaJgLFjh8QNYa8oIY0kULMILMqZeP/7skQiAAQNXlnjD0JCgwvbLD0jfBBpbWOHpG9KD69sJYYNuaGQ1KvF6I7fdLOvF9XNc0tzSTF1dX0nULE9XdP67c3X/dqPmjPNZYpJSYXi2h3ihMyM46K9KSDT9D3VX/jBCQhZMlQCw7yPCFgEADAX8/ypNU7hdQzx7F2UK7ZThQlB5ghNUKx0sUBQUq3RiTEYZLdojW1pbahH4qjVWRo8OpM49lIn5xqh0cRXbMjcoZHGLyZ1NHSmleeQxcC/U83hnt5F671xVQWCgA7IR0MtORjzcOY4pLkfSIS9EjzJMuOTYKAOFokHUEXPQpBhBlmIFcVI1x3H6J0WB4LazIlHujYyOkQLb0ItKmlicmkt6WxFqNucGF5a1HG1GpGkgmQsYx6z9IpAuKjByMnNhIoEHDbBrYDVIpnbnqA1zBCGIMCEG7HiiAlGgzauRGqocrt3B2H8KThQtRVGQCfgvyT47b7wms/XspcSHIABLlGyuSIwgk7XUykNVFmdvDJIeSNtrlYtNlRbKRCj4xAwYVYLyZAdOmnWZOtWU9d8uTW9X46zA9M4phn7rKdYRupUgrCUZhSZkoGxhEIws0jBGIoeORhUYmvKdD5j5sEDtSSy/6gn5pNefdp1JH14osYTQpkXTidFKVHWvv2r6UAjQQwqgBp7Hso5NscCqPrmdJlqXEGIozTKKrtwqFXKOBMLbyWYkQkCQwHIbmmAb2dMrTyrOhymFmFlgT9jln1DXmclF7SG85cLhjcln+K13gy4AqmGZr6v9qnqXVGjmGboKTY3NVp7mO8ullVKzf+rHMqQLJXEiRlncx2GAUzS2bKmeKRfsv/7sERDgAQMXdfjBhzwges7HGGDbg/xd2GnmHTJ+quscYMOcIWtoMSuZIo2MEBE9CwZdIkFU1PgxRoYgjIfw8MX0wWXjPjRDSoThW2lcba27a4qrsqztuylnW0d7uZZpmBqmUBMEDpnXZhQzigRM4g9iQmPBlguGZOWh5HWVQpVtUkOVPVqp2n+ONb8WxzRjtLZD93k8TWFDGSJcwPu2MKlLNKBpFIAkwzQBEGqQgBRmAHZiLsvQ0VeNMw08I6zliQKsmgDJV8dnmcl1VysgvEmQm/ZBvA/Tta1V2prK2olMw+iWsi7lsDeowFMVpBAKXK8LYUKHKRlqzyTecwtKw62NFu12Pjs2xmqy2RSZv/+YMIoMKIJCKqxCoj6mpG5ugrplKL5VbiQ0NCaUXC53DliCeFKPJ6L2Z/BDLHDbO97qxOUTUebzFzQkwsakSkhSepAb0QLMSLQ7IylhLHbFP/3hsK2oty4ffSDahomdSe2h5+IqoZRlgq6w0iwv2nOMZE7d3IvK9KhkVsGNKVVWrKz373zBaRSbaBwjIhyyMUBMlKMstEEyxQVoi4ANC1BQi9D0krDjMM4TZFtHCnVScJ7mUhcaKgoKIfLAnUEDqg0yGvGyT7OMJ0cislJidFoX00Wcpk3gFVsE8RDNyJUn2rBU5WDNlMOWEvT/NuHH1ESqXr9yMSGGH1HIhjNwva1JmBkVpqo+9NkHTLRWvS2yaJUDCCbSSBLrdRGBMoaSXEiaMsmfdnbcGKvC9cfbu/byvPhJuyWzq1SzdWL4wTVRR26c1EvCCMNDt7lZj6cq3QNbpZ2duQheSFVJOGWbMq9IxkP//uyRGmABARX2GnmHMJ+q+sdYMOoUAljX0w8yQoKrKy09g2lxgRkcyOQsz/pnSkMyMmL2LzsQW5cX0+hVjmR0yz1uQo4BHZl8XGY/8t1y33DKRCSAJTsBAoZiMtIGnlA8GC20VNURpIlkYz2IXEp25L2PZ38kasZZAGJJ4++sSwn0YOtCEqJHRmfzux9u3h53Za2yfNHvm5zfmXOZD/93yGnu/+5svvp2Rhs+UnRWCd1sLl2OmfkeGum3zlPLbX9fy+umWYKAm65zhLcvLd5C6Cq20cmkgQDHgP0vQEADGpCbB6DQOMmx6i7shZEOAiBF6BIOuHZQdWM21knqX3LKzOAmBmzhFFUMCA61CGEBtQN20YlhYmIhkwoMDYOS2AiRHEk8PrIpUUZBj3QjfItEfIMZD4PA297JWJqREZmdIli1T0++sIG6i29orYxGbWK//rpAiAEAgABSmJqxGka5ppRNlUimGjYY4DeoBGWoVJqxF+lBn2vvPgE9sLIQFD4rWaE0zso2mxUIm65cy6MGF8gkbR7RiMqUWhroL7ZVZuJxq7o0O4vuAGlIONhIutpUhRzO6O2YmF0z8vldt0fhlKKDeiKWQe5uNwcb1DNhRAYpFPWj0GImRi/fXpP5iBAgAAyZJUMC5mmiYyi4YOLrxnlAN+Ue4+GI82FLFChXTDk+930OTt1r29gvwTO4VOGVdUIypXETVJuSeGLKqRqufIJ4Qk5UPDifhiC/TPLSXjX2TOsOwFz4hNFBHfbBh4WdPoFEH3bEkmdCkwACAA5IiASDBBFTDvPVlLAEtSABBcsQXlQqGx6bUmrcjDKX6fDffdF//uyZJAABF5nVdMpHGBqqGrGYeM+EHWDVSykcsHQq2slhIn4CHi66JdEdINYWhPye0nsZmGKYGlsYOBHBEKYKSUzuJPNwpuMDPCn18WRiZ4MG3Bi6L0hsm4nKwcsOL82Y+T1C/07c/xR8k4MzccvL4CDPoORaX6XxR9hZqGrEoAQgEXaQLxGoAZJdVwG6IS6dVqWzSI22sE1oVOjwrDFgoYXfa5cSWm1s9OU+ZGNPnGUp/FWY3kbyk8yy+fFzORSzby79nlZSGTO0ECA0a5bGZLNkdqgiv3RQhWmLoB93cs9DX2bpqv3o7pHMBU8s6gjudWqTHMSbTjZQKrwCRSqgyKL4NKdVKiYZYz5rs0xiVF8XICUkj4XBUixCryGfrWzKNClphLA6X13O1uDyKcBso+gtjOmrBUlVnGSGJDC3YhMjBiEnaRFTVyMiy1bLM4ZGVcExlxeE5duyVnKqLrTT3+kboWVpKGIvIiMEPOhgJDkxWmPoIMVjbScSQTpfQGgHCEUB4T49jAM4apKxbiNMKnek3QKtZzKXjkuAoPEKNJDVCMkmfliMU0HpsE9i4tyQpHpQ7AgNnyAlFkCAwJXawKmqKlsrHeQzL+iCNMuGmWYeMI1WuDL5kLtCOxgIslaxTM8FR4c6wCmaHpK3I27+v/Xz+BgdeS2minM8Qs8UOZmi237T0awmHD7soORtM5pi+3afdc8OuFEbNEHrJS1UupI8dmFiuJLww01deu69M4zA/sZw+lpA/egyND7Q5GTk1unNSYtHIn2P8FGu0Okc4If+NFXVfIGVXdgp7GGwStlnkST8PS8gYofCOPj9VCciV2P//uyRMAABA5a2WsMG1h/qhstPMOJUDlnXUwwb4oAq+x09I4o7/szgCqt1mSyNS9JAxVwA0gekQBJiQjfLoHAWNRDuVB2jORKkLrHbgGHLEN0cnpEETzbLWxYxH00S6FLolpopfJre6OYsqckUcHo5oCYOlflZ7yOQ6a1KWaeXO/Jb9zRjt1i03E+9Je4pEJhS7aoJP7ErEgS5gzcECzjC4MAiMTLakoqQxAAhlElRJ8QiLzIbAuqh6aKuaFYNPdL+6onJb066zmQxLbrc53c1CAh1OCaJs37WrzNUQHiVMcoqGpLcKX6MflmwtNj3Jb+yYIAahRBXzdqqejS0naG8Fbz1aG8fIs08/GpncyZ3hM6LDVu0MhU0YKvJQYYKMCYW7ZZINYw33X6/gAoSIILiRKUoxe6mIEQcgtOSpX7eVvWA5pTNr7Y22b98pmTTLvwn4ly2CFQCqE9qSJUNdGkCAtFKFEe6VbG0H1ExOmOw5peS8uE4CCONqX8XLKxpIpr70be9I6JcIxhVympliYRKRZO1kI3xTK/AuJ+Qoclg4CNFYZPjEpdWmwRCKgOvwDTTFqQ0kcN4HCAcXa2xIt0rOio3JGRPp0oBirOZpq9Ch/F7M3Kqdo0n0CgcJkm9RXOySWW4aTbu1iAyiPO1IoGTWUlBErCuZiAHjuVotkmY84ytxN2rIyqXdbs/GqclW5Mzns6Gbf82696uvef9l1vl9+enqPm+orl/OkTNHaOgmEXXY9TB287Hsa82SEBB0MRSIAcHnOc/Re1hqYzlK+UyVWjzDUVGQ0cfcODGrQCMh3ppyY1Lom0HWpPOSimuzNoBaCz//uyROWABBFZ1lMGHNJ+6vrdYMOaElF3UM0k1II/rWoJkyb5lWTXFJdUpnX6JPclMMwAxSe66bSZziRKdYCMnNPy0EZyeTo35mVDRToidu3fQk7XOfMp7ul/Xd4zd2ZeL7Wjr60+N+M3OvMTyhddxA27NhQfLlXS+1lOP5UTAAAkSCDFpGiCrdTmNx5AwRR4xJFL0sk2YlCqqITkVYIedA0iNxpp+CqbU9N2ich+ST1Se98MMUcBNOZk7A8rc9xYjFuXdvpZSsNatILOQ5aJbfBGl88upQVt7LTs0zjD0fBJqbWelsgfdIOuMfXBtc9tJR0cjK1ReG64l7q0rw98oVm5hhziGEzEDzr5pRz5qVIoM5kz4i76KQARhifOT8DNGwhCYEYGDUAjFhEFThEr1gtmCkCUg8CdtWlx0IpcopTSyE4QAk9O8Z8yR14zQ0z58t13Gq48IJqNoUhdFUdzwaRQs410AsF00JWAzUVMiYSCE8InJMwNPY0FpR4JtCw2b+bsGm2x7mUbSTzB7Rzzp9N7MhWvKnUM6F+KZnoxiHDPfggpRqR4pMu9AEAIAAKiPBqYCX4MOSgD1GABBgItUQSAGWugmAqZG0MVARNdLYuM6a4m7SkmHVVRjrzQG0GH2gaZRCUkuJCTM8U66D0vSWsWyiI/iJH6FfQ7na8bPSx/XxY9scunXFpD9Ks5KOw69X/csuMUv7l0mU5UqR3tFZZbOzuMc9xPVRmpbHFdks917P+pNbGja2rkrJjwCe5Ej2aqe+cJfrXnztblbMAAHHCIJUB4Y1RQEigqJAQFuaDqTJKIKwUbL2ln4IIob6nEhPSp//uyZPsExNZnVFNJRbCSqupBaMLKFF2XS03hJco5LelJp6GgzH0+W15TkCVr9cJBLNkrYLpigAstODod1KEtBghTQ2BuLFLY0Qw6lsfcBgeezdGLI4dkwlqIBtVRb1zUwnxQpdrDQqzMINXev2rdEjRa5/jetlSai18evDP7CPdEyZKoVAjWVCtEGKaVYFBAABRQAJqaZtTjEjOKTC30ZRk8YgcytCiNJC1moNr6413KsiOVuke74K3FaG/bj9BjBNeyBFE4+g2Ydp+8HLXZiBa+E+ejB25Jfcp/PBNzyHtmJM/ZH5n7wMX3FX3jJ/UrO2dhxFFkF72QLU+x//O+x1QLH1xUcXMy8Vxcfq8igWNp83i1KzTmrGNc/XA9eK/pgAAFtUg2ZMQkEvYIIiAmBhwKBuCXeIRiBz8HADIRLMuRrrsLBwfur4hrhmIZS5lLcK77HzGbqa2oAOLh74MOtEqRRpAEWp5KxNJcOMUQSnsMbBykJBgQIH6EeCDlxC5zO5KyODgLAU6yyO4CyHZb1joFt31YqPHunAp2vX//+36AgAAIAMCgeLYAhDhg8Ny8Cz4YsQJNRTCBuBdoRjSsIrqPiVliC2WkrMX2m40Kwwukcpsb5UIHgsJBqC8/CcHBKII+McNxa8PSLcwRRS3KC/JY1jhLYzk2R2WCYw1z5OYaTWyLlCR1cQh3UnDq5Hj+Fqul5IS8qZ4VR0x/qnUtWdd9tXuOuXGPw8Vuk24gSdBseaszKtdzL9Ex7x5DWgJEICCRSkC4RKyYvxkhjAQMKQmBcJlYOPbEJE4s3QAwCtyBGhQ4njcAmNnxKfStgN4ph8jv//uyZPMEBJVk1etGReqAqEpmaeNcU7mbSU3hBcoeq6nplg4oWpw5MQdsxL5ag6ZpSXsdZULV9Gq57wMxw5e5cMTa4Ogzas/VFwjwpJQjkopNpEMPEPUvf0eiQVGMmaqRnggopTjDLuIw6p8kI7O0HFJeIZGZd0oAAHEA6MBEcGDM2uITmcLMACowmESoBS8xy/uGCiRn0gLYwVQy0RiEtNmB5lHUZYmrSqkiRBeFE+TNxaZOqpSTQpEIjxYlGSNCVIgTMaiJ30RhYV7EMoPxSG3aSFSDqNCBnlSEzi7BRSJg5tIUbtVdSLYz+UE1bvXR6iOfnBLKKqm8nP9T5HunvnGP2DrjW3l6f/VhvlbXqe/sKSmzinVd/5IXel47drynF9VAGpYBBSJILr0g8IwlwQMsOvpEcyigwh/2ZqYSJHViUNNAmMoCs4L7xuSHVgfa1MLD1oyEvfWJHbWNrsQvUqZfN3HD+bkFADhsmLhGaijxjbOn1uEnS0is1K65XfKO3N/IUxmDUtfPv8QgpA3gQ8zhhrE3c7iTYEPiZSgsOMgvt9QIIAIJiQZoECCA2mPhgcsMgKPxhQEhUOGAAiOB6LoUjAhLjOI4NOYHALZmFNNnUEycE2tt9WRW0fobfSQS3J1LwkoNDESB4mmkakrBAJneKEQbYlBJTkZCzSzKubQla7do+VIU2UrWbsH0Tb0l9Xektezp18GqbrS/K6vB72aBUpx070k/4JFY5JH8fTQ8F/udHw5+1T2fIvCcbWPtUVv+o/vf8/96r87ABCgc8UY4rQ9UUIqEK1OgzQcdBBQgQqx0ezAtQXTJAzBUVkYE0Awn//uyZP4EBVphUJOZSfKAqsqtZSOXFRWdRO4k1wJIJShFpJrLD5VKkweae6VMJJBbNJ/FMR7oakb1sakjBNlGxrJ9NfVheiCj0CnoUyoi8F4xGV7x8EwMshW0PR2iTvGQUq6Kk5J6a2jDazyhKdSnjvvyFtbS7TP18d/taqAHN+kv/0xVMRA4JN3dnD3//6oAUAAAAEAEugAXMCHHTMucj8TgwYhFRcwEeAhAS5OkaUrkbsprASQ6NbX2xKIwBGVu4ouQO4bcK9d9Kayz3DNJCSClJItA2gMD62wQnqlrbt536pNnnGJVFZJ9qzWnYXZ2K8f1WWdSrIU10VqvjWSLZ2lWf6n+3KVq5PMYd7tqvS0f0s26dnyMsTVyNcQ71jU9qk0HLrfce1Stan+QDvijUUgwVdYgDABASQSnSEI8pTT5G5Qi4tiZKKYrhIqiIFNKaVSbxfSXcSc1+0opezFLKIzPH2Z6zfcwzSeywxIScIWhkElEEkkit2kCQp4aEbo6Z8Jc+VUFThQGbS7soPzzasuaDvlf8q5Vp5Hn45m/95hIVYf2r9U8Xb/Ag0hDPjiZ6oq79c2CQSSoIgQ0gFCxsYpKnwU7IRCGJlpBm68NixS5hnG0qACZ6EJFeVrflTBLNRZcbrMyhVuVRa9Qz188EC4SBtUlaQ5NyYycMIQpqMb2TqDLFTqImvLXmpF7abQ1yQ7H9fLbWI5+1DNfpRjy+8yJ6AV+Yg2fCX/8/rrPr/6j8Pp32v88OnbtOueA2IZamxPSgPnAtIblBAJRRBdGQBuQpuBgeWKBoyMakTEn2BxVyAMLg1bag84lk6sHMpYNmxpj//uyZPIEBS5g0et4SfCAaTpaZQO0UoFzSG3gx8InMKldpg5Y2MubLpgB7S8HiDrhxV3HzJ6C6k+WuvPRZSRcjGUiLsymICAzZYEGUuKdtw1NXWbLzfKmX6ZVyzd5mTlkeXknCKEnTTIwywjhmmRCzI4ACJSECwwgW4gYEVUOgiT5QWovEAUmile/4kiVjFnxxcgwCWo3JQ0tgspUyi0sbSDUuoFdZudSq1Sp12NRp6Oa0KDmJGDSYZgWti5KR1mu5w8DRKot2zOiOxn5/SeRBii8fbzP/CFFR2zLxtU8/Hp9qc135DmIdJ8ivubrZXMdkPVteh0bfcQnlhzvtFNVLtPfPC0pcvc/CQGhu4Sh19Khvmjj7ZpdS2xTG7w/3fufDFdQIAOWBQdLzGGIRCRutMY4IFlkhEgVeIzhAyxBDkkrBg0dQBIKAFJV3UbNtRLCfg1mkuC/MFJ20jMpFrbMPpb+4xUrcuFzTu8pKitZKE5TpwxjaWS1DUar4hi52+p3PbZWhka8MlXirnfRBGScd1TFsyCWfCmxfDFIrwgx0qXSnVh5SKesTM7KtWQjwYW8AjPqRPJ4Xh9jLLhad3gEkBgEiBJEmBByX5n4kZtbmAhKmAGCLxEHCgEqFVAdBk+2it8k1CISmw9LZGo3W3sQy3aT1BsDTS3UQefOalN4oepPcRTkm9WUZp+NroKM+vk41XniSw8guKBa8UYfB6C7ipI6A73SO6JsXTqdP8c1rKUNMi6rrqrcPexmFQzcpNVEiQ9BQULJmJlolZpz3aAIAECZE2HBkEYKBmgiZjkGlIl6PBbWEVlKVcJPL6UGlaLbImCN//uyRPeEBPVn1DtGZXCdDGpCbwkuEcV5Sy2kdUI7LymlthoQlc98bDHTM1iL5JYQyyos5gfPJfp2FAVMzalZZPJo/4+A5Es68febj6TY85aFaYIpqdd9T67mIeW+M7v/Zu+siT9U76+lOczVjfxeu+Zn+t/Ph2xmrt/3+TR5R7EQRk/9yFlkQk3Ovalg9UxBACAEVUSHAcy4CFSMFXBhfcSiIwUAFTBIDw4le0pKVCxssbWGRZlK4X1rtQ0qpQwBJaSuA0PDBcVY/XJokOnvS0YOHQgGgPdkjBijTTGEojkXAlVeRrcjSKoadUEDDrGrfwSbxM/A+/HHeTqtCHWhkXcHLsS/y1ydS6x8rdtxUQTWMmL+nmAZXKJWvudz6dd42/ADAAJKFhkcMIzB0DMGxQMqBAE6gkDKo1nSLMEnQ7mIFqyB2shW0MJ1m9mJJFJ8lydwoMN5qS5/17s4o8xkP57mb+2WOBABIhjTB7960Ho2LsxJhFWs2+vnqZ/7X8bN+NlZdK+0rpq/r6JSUu+EvgsY8/tCLeOi8aetYqVbV10fjGVgCYMHBk4iiwsNoMY0L/QwUmFwOkgCgD2wLpp3BUU1JwGPGE+BrkiQWghSrYo6UMX0w3aVveNCldLwNpDr73ZkPikcyiQEQkfKio7i2iHYkR0AOpoRKeXUXuStFakSIWaTEDfolM3IZVu9ZlqSSWzYIm/RPPL1LekbzKUJ/RGz/Dfqca9sMStWU9VX8uilLalO3NW6pPrUmqfcFyXF7Y1ZESb493xhi8DVARIAUkDqnA5o2AoDOTAkRAWTILLt3EYARlUeHgWHLQqzNNTUX8j0//uyZPGABI5e0st4QXKBq7pZaehcFRl5Pi5lJ8HaLKklpgpYxOZlzQK1xtKhEmWxOfnXyXuuBJfFNsZzFsTqEww4RVjpdlMDL2R7LVCjDit0SxWd3RJWfStfbpf3yZNDI3tRW5aV6P+qMxeGBkIm55yW6kIAADMBh4z6AR4eGNV+co5RiksGAgIYtAQc2YwjihDLXTAgGQklEqjERTNXM0tGYhLHjfBgDdE+Hrduqz6cooxQVQeIlyS5DQqkSIjWWLmhPrJwDUk6D01UKt/EVo7LSNJYoKtOI1ZWalnUxF8NVSaS2aUQH9tQp/Cmfs93k04f+vjSL+k6/+/xlfQ5/UM2W3Hxj9qf27qFlsRUVVhLpxzyQnSairobpAQAAAAYCGZ1Lh55R8YxkFyG5glJaovIBoYiYmIIofLpHjRUFFC5WZLgmAEyNu4yLQtvsFomlR91LWKOEnr0keH+i0JtpotCpdEhbgrO8HF4dc81XWxhCm+Hmw0VvO2vLNEHNiMMv3TrTm8rxOs3vLiIcN7RnNhve9qfNxtx+qtz9/rU3auxWx38/dIkU6kLRlPNdSjj2MJDW3VgEAEuGABaMjADFY1KFjlMpHAGYEAgBBYITM7Vh4924BcYeNKoA9WBoy9bDgwJygs23uBcukavBsMRh0pdSt2y2aISUUwmsXwNCAmguiEyLEBnPASq/wdPZpwNYhNbSyavm9BdnSHNgvn+7s1jrEsjuySXn7U3UlX+1SkfUY5bNb7Zvyy8pdAakqnXWURaliJ9qzW2Pz3V3HnT8JqfOzueln6UO9UOiAIKg4CHBIJqNuYEdmSjJgSSTC4QEF7C//uyZP+MJTZeT5OZSfCaq6n3aSa0FLl9QG5lJ8ItH+fdvKD5Q8cVOtZbQMEZPFiLIIaKCQEeEPR0RCyu8taNLRWWnThkgMg+x74ABsUwRPcpgkPo3cs7oXqbOHIls+9MXotbjqkmyEa2jOKLiIbqZ6m+ahripeoeLh0WaG6w9Dh9UyG4rh3v1RfHRS14PJWktIdzdv/+fnUAAHT5BTajJGmuosHMyeBUfTAsFjDYEkAxgVyaxxhyCIyTcBESoKOSLARYazCgMSdoNmIWiQvzKApEPEWeqXrribQoy7s3bKY0Fa8acLUCFDWiRDwxAW1CZDsWnSElJluuSzrU9DHvuorkD6FKUIUOO6g+t9D+02vf91RkCGY3n4vycO1s5SCs2fcyb0ljJ+Zc6bwV/6RW1dX+/3Zbv371/mB6/y7zuUfpKG585EtLjhr5EAkpKYVKHRQm8EnKfGWFF3EgS4KQgWGJ6FQW+8DrEZi476MdVhlmmUUlSU++ys8D/AAjRzEDeLpCrNvAgHyo0FYQydTLCCqYxnNgarHeKFWDMJVTr7MPGUjMgm/V+JCJP4cmeXb8XyPP3OZSHTtN1pxOSdzWjE4I+FDQZCmkv1gGYVB0Yui6Y7BAbjJOdsmSZMDEHEMYZBoAF53SwMCHJPllzTBAM2ggFejUGAaIEJFMwRkQgYRW4ZASddpbrAs046y1RSZrrfU5YLQOn26PhybiIP3HnPB4+jddJcaEUmr8dN9YPYo49JoiuerFI52gLpUglYaq8xUf9dDerrRXNKeoani4WoaUts2X26ac7KGvUdZ+fk7PKTRzprTotrn7PzM3rXZyZt7n//uyZO2OxZRbzhO6YfB/KxojaSOiF82LNk7ph8Hlq6kNkw7YTMd7IZ5XPPO+XbtTLsXTb/lay3UbATbkuGTzjaFNSGFCIEnAo5US0nlIBDBCbKoq3OC1QKw0TG1QWGZQdnMbjrwzl7UPdr/VN0yROPHAzZgbEfsNeXTSLyYWySvflKPaNkGdFoPk6etORaUXBmG37WKokNTVW0//2/aZ57lPI/4nma5c+EVgkzPWMS123SohItu98zNQoKlxsiUekQmAjigKgZcgKAbnoqDoGn8s3Bc1EgSh1QSMMiUK4ywuB6sH1kTVzmRq2KRRT8bNisYXd04KtZ5EjFFiDamjWgXVa2Eo7VxbJBMPDZFRf4CM6UL52OWi+6iW8aV8Ck+SLekitylXkkztxxysvJswNH1tFjfroRrmvuyHtcIQ88vnLlogNlq8oAAES8WtP8OBJo35sxw0yY01wYFCk0zJCQuQMQLbqvhJRpAkQUPjaWw8BvQ+1C67MtdKonX20rFbt1Y+UnDBiF/nLro79YDFmnKzWTVs1ttlMMcqD7nJRxTJVKTdE7Pne81b06o3b0IzHtfX1Rt3kw+RCjOV4Iq4gj496hAAQYwEVzQAcMQpY0WnT88UEArMUDkBFYSmPihOYEFlXM1yR+MlCL0meGHKzACFFAhwgovoBIe+7TCl7wVYZpCY1PSdLcjMtohzRVK5xXteHpHhTOgnfwtpO40NE8nKGt6EgoM4dKVteOFyhtOVoWGm75Asr084o7nf6efvvrGuvSkyhLNmV8zsw/kv5PZs//frVP28ucxFTJyB7/v+TNpmxwsowuvf/o5HU5A+i+34//uyZOAExKVeUZtsRLB7a3oTaSKyFgVzOs5lh8o8rugNsw8ZAAJEqBUsBiyZa4HDoBj4QFCUykrDAlBsCAiqxgQdEkARgQGVABYUmAlXroZbMs9U4qMuvPqp0mtLqy7r+GcrpqSn+A+a5wLM523kPEPuZ+99MUrzUoQtYQfeKJPSIRV7sber5JXJuc6cNzeGcitQ5pqd/zoL73JEd3PJDfKpke7bnK8ChXN44hJTg0953XzqA0AIEkpF0wAQMkFRoTM5LjyMMEl5eMwMgSpjrFVfvCl2kQVABgMDy9ozLV9F9FXV1LJ+blDYIrJJNYktvyFMq11LQ9DND7I0MIXBA1dryptCRQMn0H7Gt9GklyMnbyZAYduWcw6QdimyJWujWzrHMuBQvlG3eKyAxb4/1hdvYE86iRwy5IqiUvMnBTGzCCl7Ixb6KxAnFxG4Q10byhtGE0gPnj1Hw71ONxzI253ikfWs6zvEOBYACSQpB5z4Ea4BGFD5hh+YENCMiGjBAOJnGJhZ7cEly+RVADhpCKiQDEw7NaK1pNbcpsTay+Nrwtyq5XO6MaYX7YoW9v2Vn0nPMrr31f2LzAe8s645D7jjOLmnOw4rfZ6U616K9Kcn7H8j7fvkVNdXRd8Zna8d1ky3sdL59Jt9PYUdLZ/f4TPOvQufe4SKLNP0o+akfYIAUBgyeF0Sm216Gr5afl+fUXjmjk7a8zL6LAAIIAijSoy0gxjMIRTO0I1m2MACjBwItqqsXPbuAAJEAv0ytDsxZS185IrVMJkT2LJ4nE1tQJRlHQWfigeexixRDiwb+RZOm7kSV+cWqpokfP1DLRurxavo//uyZN+ABbFnUVNpffCwLLoDbww+Utl7SY2k1UIqrqiZphoQQ1uRUnmwZJcmh/+Fu2bWej87rjsgj6oTPL39lvX373n+XqeSa/lTr/wXgVWc/Na4QcMEtsGobVrjsSd5uusKAqIMQmTTODCqDyNhlIMnDKF1CkiTBixCNLcKLFuFc6QiSgpG9Tzrh3dOXG1JeeVIYDNhpQj0qC3io4HqClT99zjvzE85A4hvZv++ZIkSrlNR5Ty9WIf735TH8v18jf2zO1xEvn7u+suaaorv57ynHlr7GoY+yNktBX56e0cYXrDFr71uHIi7n2dNCAsAAhQOmDxMCR2aiR5nSnmGRICHCgYEBNHnAqSpwRnYAQiGtJgpNv2kHE5qcrLhCySggIxFbkR76uGpw21GLJV3JEKhptWkvKK0amhWsgJP7gm76ow61TGVNDCoLRy2P/Iof6018tWn+0LX9z9kK9+MLyi175MV9yPSTNT8L3pbuxu3XhXPFvXV6znBO1rTD99ffTFuvBaioAwBCiUiTEEh5DiXZhEihIqSBhi6aAgRmGeAhzp5HJ8nx5pov6HXKlHzLmLGkZPKeHziAAhhNwKiLRDpVXsQ13ZCshiAU86EOjI6iDjuiGERVbsvozZdDFXGs1kM7O61tQ7Ne1EK8UdqIXi+kqKp6veIBApkD4ScRVmiIfcHCKi0I1UAQNDBKZUBI4NDOAgGOMYXEpiIBmDQoYGEQkDFQkjgjmNYRNVNomqDgiJpbcKbK2OKX0k86tZTi7NvdZjuNqJzkO3/s4zb3gRZya0qxW+CJv7ET3AgXJxNOOgAQl7NR+gpus6CGf7+yA7e//uyZMMFBMxe0LOYSWCC67paZeVMEx1pPw5kycHirOhJpA5ohffw3dc5ObXTzs+1zVX3MKl8puxKq7nVt4/r3nKSVlJbnhST0Ak5Y8mtjQ6cuqpFKAjCnjtsyhIFzoiYAAqETU1FXM6BwAvYwsgDwO+qiCJTVndaZg/iWccZ0wehgvEAHIHTBhJ5gNoQiOhjvMaeu8dfblCgj7WXozEur3cFetrTUXJ+efIeX8dv25GjeR98quvtfmfrONCp5dKlUnuAkSixo40UqVTSAQAIBNpp0kCAjBoEJxocwmcY6YCEpmmsDLRCar+DAr9F1HNbs66Wz7PS4kQhqdoV+w3Rt3f+mLBJZOZT7TiBPRUktYfmrRxou2YJlpGFrDkZUcnzTCotECebRBS6dJmprmRv4pXioypqV425Boz+0/A32RfaeBY28ie5WLWpqJNqs/5oPtwkgnJNY1BhQtjSh1ZvRX9AIwUlskgwsCmykAMzZOMEMgGJr0iHIBA6diXa8VSOhHFevJIJS0HaiTfV5bUps4IxjzjayxpwC6XBd5bJMmtWJ41NTF+WbGRYdr94eab/WMa6FRUiZuHchjmZ3r1VWZz0Kh393oZKeZmzN8xl5aRC96vEugc5QynMdO0BgAKLRQSjGwUfITzGzY3LUIRYEiZEUpOkRpJEqh0DCgG0JojeKYJwUraNEdKQYNXP+DVc1xlEKGjYpHNlM1XMRMQt32q9q6VA7rUW1gW3alcjpbF6yLatdxAUIuxBlEEETbRCvwUvUivXN+JB98pkC4qImIAr+NdtB5W38is3JUeS3dWU8W7bzV9Lq6JsfE5TfJtWc7AA//uwZNOABKpeUVOZQXJ660paZMK3UrV5R02xE2H8nucJvA1xAYwgRP0OjD7MxFtNYMDRyw2pOCg66RhAoYWVCzI6RrgjyMQIinZKYZCIeLERlD5thdjFiKqZETjdi6VFy9Dcsp8bbxWLFM6BgBgsVUQwubnKFkqN7npansiySfCCfSpRfXuyUvX/yx5a8q3pEv71xNZXDt62uwua+gKpEQf3EAAACk6YUFJhwVGFwuBIIeVs4NIxhICMnBkZrkzgEHGIzGAiJIosQvCHOsYLirKlqMDpFAC93dYTANiJNAsOFFLZspNX2RiZy5ln2ebMyhD5zgqlVom6zfGpQd1CJ2LDorfaR+fmpfSqfkky+rW+9OEaimY2osZqLL9f+UHelpx/u/Pa3CW98JZ0tS9ed+LX/is+BADUaO9R/7onCCnR0DRRwEAAAU3SFQKYzb9jcOjfiTIuwLHMKDL3go9HEnEPAqTLQIvDwotuPF13MfxqyKIN3kMNMZZvID8AaJu64cqPUL9+j9JX6VxvqQUeOSnkpUPJVVf3P5Cul5FO0u6JmrEsJ/54dIPDuGkY7Oyckp1OUm8s7+UjWlMvczGIPCRu3JlwSWsGBgyAHVLjlCXP/KAyKSTEQWMRhcwYMQM0060vWKnEw+8Z0EDMYWHrKdZc6DKhL7pnL+i2DJ7ESY5FdSGdD5OQT1Ad7NB1nZKTbxIwS+46ylBRHqJ+/0zmYVyyAO9vwJJ/yMbWX6pFfSNZ/BF/s5/7e4gQoO0QblH821mW+nDxhXzrXfr/1n2vte31v23KG6fAnbblNn/U2mf8/tYFZOE7wACHLi5Q2PGpMhr/+7Jk6AaFE1xOu5lJ8IAq6edpg6RUWYk67mEpgfytJ828FTgIKDmEADJkYoYCJIIBgTJYmhK+kuVtvENXBQmJPQPDrSyWSpuVh/Za5Vl62sXu345F94fLO7ycWMjj1vUqpZmoiQoT6ayut31v+dqnVKGOmRnmehNBgdRrFVIxpl/qxFZ0bcis+jdG1YxBUXFLi6QAZJe3pQogEEACBNJSXjgOMQgswsEBokHAQ4YkDY0Go6CAQEFpgZaJKQdBKVhVACB7nPnTKudFR98plqK34NoHnV7IWiI14rJNkkWqNYQIYE8Cc4liUkts6edyZhZ0EaNBrTkExdotyeXdsz/f2WHCxZZHubUIekjIexhYdTxN9xVYoFB/9fFpkROWrdr4yZMosRlrqLzQ5iVBAP5oR1E/mbLfoAAkoQCK5u08ZBKGImJsYwY8/GoIIcQMjM0FiHECyOUYVAKeQIojmYQRACIUoHfZu7er7WjWYc0Zr7eKJlrJbKsXAeOvFcoH3uwoDRIc4oeio10Mgbjtc2AVnnp2dSjHioirhjF2MnL9WmP2mL7mYnq29rGWXNQSWIJGDSL7PtygNj5Zwen3DqgAVYwpG0xfFgwXHU2jPs4+WEqjcDgqMGgKHRIMBhGCAFBQiiF49hhGCSOBx6BgPDYChWsQLvv66wVIAIamcBIRlt3CeNo6HBPVXsLQBgAgWAfowhAAIClGrqqMcLvtyeMLjmeKgu8pmSHihcJGgn04b4swSguZ/kvRZC8HeXocEzeTtnG+haBVyhKdIqonBc2MkICOnGdGD1iyITAEIFnF/A3EiqNWMom6kgOieCwPV4TcTdX/+7Jk7QCE7FpQ64lFMohHybNvKE4jAZ82TuXrxA+0aN2sPXhnWHAgFAfgKQCXfZT5+HacbAi0Be0UzA6LwC2HWhbw/FazNbEQhTRBuF4vs/1twNBZhK1NlsLYqIcCCW8AXgFbFEU66QuzUPgvDAdB7kLcGxQS2gPHk3y/f3Y0PjTHMQRP5D58wNlt25QCOosYYCURjgo6EMCCEAFga7EGy57M4fbCpeXYW5AUMtgvLLiCi7rX4nhFsYc+QT9dW9qblxxsaEuLUlK5Ksi4WDoaFq4cZMlYZXi1IYrSFnG8Ux0jxCvmJ2aaDP8lQ1StEzXUQgh7mmolSYJ5J1C1IhjiljUAyMBOGBUHPonY+EdEHwYiQVp3HKXvcq2qNpkg4KtJIhgDgBOEzVZUFKONKHWXQcDCXQ4BZxa4UQVwvC+XtrL+S8vhcRY4eyfmEbR1q9kH2edT/M4eEYI+ayELxYB3gY0HEZ046D8EYMsOAvDATtD1eb604uacOQuafOuhf1XeGnzom8OEoHlbP90BCAACDHLzPXA7AIEICTHp0MCXa8hEFBUBoCmTMQYAT4dJLH4tM00NMDtTEAtroCFEpV0P3F0JZZdjqY/ZfcdrrTkvnq05gajxdFeHY25A4uJPQvrfkcC2TImBw6wC+3NakUjlmli6fm25JzxGTTXWez3XhcZ0ZHPv4yid+7GmQ7pGIPnCntUqSscOaR7gSX4QCzBcqo5c0sHEkE07qdymsictezbTEklCQDySGISNXb+OMzSxHVE1JpfqU320SfLhPXA7W0iG3cMwUAXAcKWKKm7TKIEaWkotNd9OzsWY/beO4qOXXr7/+7Jkc4AHsmjTU0zE0MssymJpL4pTmY1TrWUhgeUuq/WEFjjoOk/OqWTyWpOuQ/Ug+poAJf1HzwiwNNNIFWGEQcgCl+nzSHjzgQam+ydVZ2YW6Kc8ZzIQmGD5UngHNLKGPFGiaWmJQywHgyqw4VCYVTEJp+Jd36pvwIBXhbZ3j9VQLQnF7HT6FG4qLsq4ZcVnvpXtqpZvRhiQG5ObitlpLw9M95Ximrl4rA446uLwpyDO6GchjQZjidE62yO1thYBH0tEgMBfGzanL24acTrM6PhtA/rLUoC+Mb5jFxOaFHhDkMV2r0ghytu3Jhx71dIjNmRjxm7ZWHmb68eHXKEIIEQEaAAASryEnoCALUG5qn6qZRcGgpgp4F3VU0ZYdeB33zBMSqCoRk6orabSFmIvQkCU4rLrbDCzZlGwY7S5uoShvLsZfPJWTyzemznoqhsQgzfioNXmoBLikvlJllO6bD70jnWl0Hu0WyOCKtT2vY5jVyYhU3O9drerBfF4pXcKnFomraj+nI01aETxhAlj7hsLTIY/7mfr5bQCGZrG9K0wTC5hjUXVHiS2WF+1g79CgIV2sxWxcTrcc5hsEQLkglCOFNKF7EAAYVNLE6xj1rdJph6VNL8GvEsPqzyyuJm9ma8Sj17NlyW3mxX71PWnt38iMqIvShraG1XKzysmUmwi1L57K4cF40DEMjlWJCLAZfMdqgAgGaAATc4QUvCgBzKmn5DcBIJkJ4QSpy5Sh6HlPJHcdpqteQR1AfLtHoFkaP4oNvelKDvWje6fyPigYr9Tfars7SsQ8Ofe3DPzd5pBv8rjTUjOU27+AjCOLWt+rBr/+7JkLwAEpF5US1lIcHmLqr1gx5YTVXlITeElicEraqmECmn0kbzNYqxCox0lGurN0sQtzuWNZJCafk4bquZqs6f0g/9LGNdHdh4g0zibBF6lW+23EECU3ZFwAEXGipASAEBrCFBc9T7dl9KAt69QXEkcv2HFxrEbAxtiNxWuEU1NJH/kPS1L0DBtN8VRRyLIU6EnrW7b25xuaVBE/XquPIvMWJmVUdOqnsnWjpjrc5HWY2z0PbW1VR5VtEPoYTZFVUQwx1q1yhpGRFzqc7ypIwIqqxhAA66MNnIAsUGIlQhay6zPhKRkyYIPs3NOEjPB6s0oVhX620zHXYh6YZuSKTJhDzypYffHLPx1ka3CIhdTwr/df35s/oonSIIrXJTHU2ivE5V+KXfLYMZc45qx0lyDNZBOPsouvk3se2xS62YrfXq5RUhdbLU4pJLTsoiW0tNRpqJR9IjUJqebKVrNxOilA08u/a2CcccdQt6gHQquKNkAmToUEZgA767WvgkZchPYuWlQrJWhmBJuFRlc1JF/zicCyiEQRWGg2MHEwMSSS6Y/muR3+szbJIgItISAgIzr8xPUoZpA3GZVILahHs2ql9agRqqzade7vNbKz7lp0RNl+6srwon4NpnaQwAQCmlAzZTYFnDrh2sYItL3YIh1OczFFaqTAoRVBf68l720kGXPvBcqm5lVWQ3Giw42l+BZ2MQHWJEtiJOgq1WzSWPi5D/1oqJxCpxMZFwYb6jRXo26mA8bG4g7N8lFHb6LdR5RQ6qKWpBA4z2v5JVoWMazXBytnmfENqrXCis20vtAcnyHgji0GiCCk9cUFrIk1wj/+7JkSgAEul7SS3hB8H7rakZsw7YTvXlCbaTSwdKs6emRlmiiWSoEhPQDBSKMvEzeDgxkaGQYlBUrASJoYEQyvcBBK9kPHYsrGc5EJxmp36WES+j7PV4OvvTDkVzwsbnpWXkPmOaxlF9u153buQSF75KSkuJ7UFLhl86T98/qt5T/6xFqbA6wn7VOYq53IwvILUEf/e+FQ2CB0PYMelC9QORjHIpLBxAohmC3JzDOYwhmWDxj8aYEHrXLrAUJDKhd5eILjRh4iJCz7JjA0HTKvrGjy/ohK11OLBUIkDKqwNoTBIQERDOjLJgiQitCqqCyGUmi95wZ3SBiTCqfs9z+VnAiedgXM8nX8SI9rA0LkolEmPn3u1mPJgWXfOmc8J7pZZv6DZqJecuc/n/+f2mtwrdZjiqHJLhabpctVNyQ9blkapIBGEA9I23THAN+MPpQCkgKhgjHXPDCS0fSMftShp8Vas7T+F6X++5BUrwwoCpqMIaUKtGuviBYtaQQnWw18FpuGFDkcYuGXUZdFZsj92zOWtdtSzJaDKIqzK7Uczs3laiFehjLnzcylpucxjHUYHmE4CLB30IBskkQ4qEO5BRAomrFBtUsYIFDoKEJZzemkhwuCYawe4mI5AcqrYa4C4GPvtBDnwBI28xsunDtifiLwwicEgwJYyyc0aJB53gBDjIPLOg4YLKYNKsQhMN5G/pI+hCAmP4MhNRDGciD+8GySUX7IP4GxyU+5xI/auhpqPD3/p7r5Xf/xfwj/FGT2NF2D0lqNGIaSLwuwoc2bV9lCeDOg4wuFZGSYDJoBWFFCUOC5mdDEoUhzYatFrrZ2p3/+7JkXQwE6WLQG3lB8m5K+opgwqkUAXk8TbEVAbqiKvWGFawEVkDSYehGF94Yz/aGNtSyiPlahvpHGn6IIXzRHad1m5UP83ScPtFyzv9da+95aHelUutdOksjVYEaj1JM1SpTYqI03XpmPTyMlmiLQQGpXv1ECgR1LaaAVEombBxmy3IoJGBE4VHzRUkzRPU+6C+w4eGhVJQvatUMNgcGrcjCpHrsAoXVDK6qQbsl4onBFBoiP3BoUxtwOfJ7amUKlZ9ND+1S2ytVMaU8j2Fv/yAuPuiGAauA6ipZQa9CxnC5eQMW+6j9vGJZtDxH12yTVOxK3yOMaxlfNV8VXHEGp4kSB+jFQIzLZYfiy4zqJNakyW2x4LjbYM1ltjdGHGi6Hy7gaFAiaKoiqWLQddgkArAv2Vh+EUaSapls8hYaZZHiw1GpJLT5+xMsZH70hldDiZGVKJelWhApNUXDwvnJjWfZNPahDjKuY2ctVPRDrOTQkdUdmUEKrT2hwddPiFKgdc2RAAEAIScjbSpksJxkowWAT8zkBfbKWIPwYARDxCBCwEIGvLBD6JtKqtAdynSFxsVuUTnZcjYfHo89PZJL1HmKNPGsWNAifWf5THzCyKf5de68kpGIcRCGCPUh2tdipY+Sx33YyIyLyZN8huht3AuKHcf4u6SNC9dxfKfvzxP3E7q6ZDmVO5kiCSs0BAeyCAObmy495N2UmmBzRTcyu3M2CzBRExIIL0hiuYwEpmGShC2VhoaLzObAVpY5CAgYSiOdE05uNmnj1M2bkBQNEp2bxcLkDfEk4jGLPZa2r5m/El9DfozBKdUojWMPo7f/NXz/+7Jkd4CEsF7Sa0xEUHFK+hJsZ7QTxZ1HLaTTQdcuqemGIRnPuiv/tX37pr6/3TR16GXHGAYgVHKGdHvAxAA6lXM+jjVStOozcINdNUVRgFIREMMXWe1YhUATBwJ+49Sr3LM7iLPYvTyVUwt1ArDuQihXaRg+lI5ablyrf5ZE1ab5v3ULGvPsoxWJiTOpt7A6unAEQx3X/ZbrPJ294gMzYrP7j+n+GEMPNK19Jt4OPt6Jf5qcQCE9cs9fdN/GXJdqM+7SD6geWmkAJsHRVZkK55mez97Z2//7GYaJdSLLhsuDWmOaaSLaHiBJDRxkGwvBEchzKA5ATLUA5kawgANBuJrhBPViE7zzwfFj9VuklC6R/0qHSqIDzub/hEhN+eE/+ESv7iEpJYz9/cXmZhJjhL3fSp/TSvtHRKmIjgbeQr/VtVP3SIKnkB4lWkvZZeHVAIEmUTddiTx3mEGUmW4OxGdS9mKnxYLjphMvFAqjfaQIaLlga3SzEVj8bIlAQssvDiZ+VEP2OK7oCFeJ22JZslrd+ECIZQK53FgMb/fRaJTdEQcDbqWIn4/o/UmG1Weno3U1LC+vR5/2+DjMsTVNqO3bYm/3+o+Ns/+nkbWo0e+W+1Na06xat/A2x33aZmzjE8aChBP1TdckgpmI+WY/YDjc5pX2vnDZT++dbvKCUHKClJGgDBlAPiD7thRxbOj2rA4DPFlsqVkTEnLbeuo+EPWvKAYgi7qdqJDLSG6IE1zFtrEtzszAxuROq4tVjmDH2aO26MzPoIR2YP+uqdYp3Srax3oNnW4OrDe9frnZBB/3gSyw+xf5qv9CidpX5+anB/n/+7JkkQAFaWdVawZ8wKDMSq1hDIlRGXtNLLzMgeCuqimDFmBFjM1bXbbzs6+YA5N2mU7E6YmnVdGgxw4QnD2zJfe9lYU7LGrxTL3F3+FWGgApC6QAnp2A1FXmU4Njv9GVMBEAaBEVT1ZkW+caE2FGlhRo58nFY9ghCZQOlUvi1H6aFbJgP+u97JRv8bzA+v0y+JouGQ3GcEc/SLb2Mp8gbhcvv0FC+jpeM5NP9Ar+kcoR78P94fpdFN/uLaqvd+vhXudy2OSBn/+50SO8DCvtkT8qszscktlIAXnyNAABglIhGA1KhQBEAUqEDZAt9VVMN5H1W9fbSItkgGx8fd+KwJXMKREihkFMSZuhSIlmb5s5e/1LTlDs6hobv/hYsarURnXMnRBWsrrrz+gyi1pOyIjtMbQ1EtKrOsm7utyZyYqHA8KkEQAkc2MHyD6DD5KtASIFsABC/wzAljQWHneFrDod02ghSY4q6gyCZYIgbHIg8izUHoP5DB0MyAibC4Ve5eBGRRiqkxXErNjaBZuohQU+ZS9lupuDgbBS/WPk2Ygm+SimmZE3Jt+SUG8q1mJr4KLqu9ZEQ/OS7KFduKmWfuRMPKzBn3YylaVgYGXxKJLHTVNIghA0Cpgw3mGpBMz2vaxVQiYs03czaIDdUu0BpKbKqvLD6Fk9HYm5T1vZGog1xvokziTfMsNh6b+Xw06lklEnveBjPjhhLI70Yv5i5gmHBfI6qiPEmN6xosdSv9Jkpshlw7Prez+26vJaiGzdKZD/1dl8TEuHj5c+JuMEMJG1XdYyCwKORNK7CpIKGcxK8yo2ppQMmX25JKNCJhnLnoT/+7JkkQAEm17SS0lEQGrLKu1gZaVRGXtXrLERIeSuaamUijir07fGmLDowVsh6fwPy0mux6Ernt/znnnrQsnkwPX1E15MlSLggVEnIOyCz9oenFRWd4ES7M+C7jRe9S63MuhkP7XfrHCzWcza38JE98WsXV5PFj5iTVWWLNV7mholIuSYnx7q0AAWkpI4QWFRDq6L5IbEJhAMCTH4ZQXmghJpMtp8CMwp443NuNnBIHsvu1CxRV0J+afZau0PVcpaKam+OT3E+slcaQgcaqvDw+azRReKyV/X7HVVNyTUf0T0qZGlZtWp539tzPVjUqyoTMhqPynaFGJCghzHmxJYq2gCICy4myCz1UE0TvM5TN1hj5CwBgCdzaLAP2mnOoRyAgeBt0JZLSQe056+STKk6cy9lD8871jNJSn3d0S/6l/h75JyRQ0QaGya3YeG2SFzLUQBFunktF5nhBXeYuYStRtVkxcBUQD+Lbi83W3xtflqOxV66taqaq5FT6pRvyUOkPYJtZNvGsH6yAJCTtSRLMO08jGHCRQo2j8BuFE2gmCCnorKnvGFQyhl7LEpVhJHXlbM6XW5dTtnvHF3pvKth1fnMLHzUlFyV6ssom8lGFFogH//951m0GJPVI3QdMoUFLRiFHij8vI8ynLqd7Is3nb7Qz26X3/+N9Z/PKQqewnEdaXWwXVck/glkRJCGw1ueVRbAQjR/IHh7Lg4MKiAhoiLepZSZ5oCqEutKVyPHTsqcaVSVt4PzxyeeCb5ohGCXdB1lBgwdvnRFl3IwT1zeQEISDx6hyL+WHZhwlC0eaj+eNnJtoKFocaotsMr+Sbz54H/+7JkuIAEQlvT0wxDaHsLKjpkw6hSbXs+TeUHwaae6rWGFPUYozGLfInVce3wa7Y3rFKruG4/zpmmOeN5ibFR1zJ9UTV9mp0vUEWAsbE7Lkni8APkLBL4l7EtwUJ0hceDUEw6BEUy8JQNRxCu2haFAzOOcOWHbERmWgozkXKhIwSdPqyJ0B9lZrEI+hjkcyuURGXGM5ataj/0/FkO1qWX3/438hP28+KiaTf1QtkNGRnu9lUAACQm2ylDX4ky0ZMIFDEkIRtoVE3YBgKZeMGhEimxb0RAwQFvpQbVtBAfK695w2GWlPtqgesDa9xHA/BnlCnXoQ4ohKr9CVNUnFfUmTee2WMJjzXq83nRwzaonVZBofmWpkS2kE79X27q+7+lPm+WEtbuO6epeUOjjl0JneFe+P3R/aP1S1fC0ojV0xcrpRyyxNbp6oAAtpums0qAgsA7SZomZc+CAYgPFokJgCHDgYcDrkd1V+bktDDAiHZ9JU5CAaWurKrccdWTWFrLMQt7H4uOzbGYxdwj7O5DSJcy6s1AzLcnXqNUjdPvo+tvKFbaFmlqLz0xfWhyrliwodYYdrEEBtE4emjFROAp2M+R4BDoFDYBJkLJwyIASbkzZjSQF8EIXohw21zNVGokkCwE0lf0dZO70FRVqLjRuzKGDyuEFrGQMrCFdFqwoKQ05A9Jdq3pEAhy1sPxCs89Lqf4Vdw+DD50scleHXZa+/waS5xR7uXdXqo/FZRyZHDyhslrp8ilz+9vzmz/e19X3q+o2nXyKre1GEuiJPhcfoJXCYlQlV1AQgACOE+RPGv0xUVMSLAsrApY94zMJAPIjcP/+7Jk34iEqltQ02lc0GxHuhlowqQUZWk2LmUpgfOiJwm8oLhq4wxkUkLlYlIrnFFhbtyYAUcKg7iqWXH9mJuiJFw5KAoaY2CgeDfUgOiSqqRKLfCds9avOInPu3uYTbGL42b7szmP4LrrS+Xv6nm+CpHp1Xys1wPreQPLHSC1SrkOxGhS+SUgTofWPEDYOJBlEFGQbGYxMAgGxhApGjiMbKSYYeZVZormaqhqX0VUDfTzUHsmrNyESSXqTrxNiaqviBl7y6nhtozPn5sxuWt9WpYxAbVyA9ugcID8NRlNogJmInQLBjCMfE+fWKsaTNyUBlLcBtZrJjZf9C++cMN2pRd3VXMxulMiRGHTIgFVySeSoknLrBxa9XlCNVvht+OR/8nRXXjbZKUz2Zfa4VztihSk9xL3CLihBYj58IGGNa4Dn6kHUhmJUDosLhQVOBZHEksGkCE4qiKORggCmozxfshCogHDDz3IWiY5TQLu5U/eXIiiApe4wGS1c9INaVRF0uzE/obkNoZIQpaiiOihhmW+oQeCL2twVkXBK0F1P/p1Y/XM3RtGdBLdHQw0tLPR6woRowTHTIRFMNA4yMQDZRqMfiksAkxSEQqfhpJBAeMCBpgB+UFAC1jEEAQhI8zwvIZQSXiYEslEcU3cJfDoImMkqujCocpJxldHYtyuB53GqruNu219Odp8sBAmJ6IY/rESdWSK3BcB5Pf2cnKRW5pbV/Yc6WFK1+3XmdV3m52vm9X5mV6/+pswIjmOlVnTr6+dO0V9lOrmcveV1D/21+3bvTsP4H34XvbvR6YXkxYv7LLnesigQTk42QcKv/+glwr/+7Jk9gwFrF9Mi5lKcHWK+dJswqQX2XM+TmWLwiUuqimGDjRSawiTBJ4acugOEY4jyxBDxN8tfBbCWJtbtJCXnXbZmEhh9KTz9tsSDyklct5TWHJoVyfHlIHU5XAHAOB83EsWL37nZmvX/9zs7Oz+970mb3vMzHhaf3vTN3LrgZ0DM+pcIIu5o90Q+udDueW8pke7+V+V/eFf7oT5w6wztA7xzCHAAGInTicEMAE2NJNlzoWCEaYwWEgq7BhOjCvpUW3enlzxRWOVP/IG8jlCgneVr0wyuSMSpc33YpTx+WRMowYIZVZ+IBl2gydhY64HEGrsyByFCh6nFNaMZjiBRODErhkKU7pdLlKdVYZ3yMnLlsntHDjCdZyHbiu/E2YOS4dvHB4cZRZRF69+rCw0f9kG8dFkdDhQbmlnLQA0CxKdoAN2lpweL0qMrn1j+XKYsEqSjCsAEAbyuFjDrAEEZqkkyC0WYLGCoDQqq54CTXZSvSCHTwg2xQp48IMB+zsNbp7NWNYbl3Gozy/2lYzwdvj5d99FxbeWNqi21qFIcwkL5DmaZm3PDY3FzcxABDtLpIIVKiNXDdWtrC0JOWg9JS8xfFrL3R5EgR6ypBZRhGxKYoz6R0depc52xlXjkaLzokky7G0kNPnmFx8PI6RHdnNKexOnwIFo4rvFgMEIAbTTlQ2NcQAM1HDoQwFQR8QEeiUTElRShpoh+V8kBNtwi6UZGwHbVbY3louB5yk/v+z9RDfdQX2B6zp7REpf/7/vLUcDE/5i819SY+f++27cv+r7fL/+XBhzU0v6We3yZqd/dqSgvFHPUpR2c2l9Ux2zElr/+7JE5AAFXmHW6whl2qWLyrZl6X8QmXlZTDzJAgSs67WGIZAjSNC7STjc0qTYPGNrqAPRAAgHHK26FzkimlhWozFG0CJRBFBOZGkJzNlyw0vsGZubFlcfAxeYPCN2cePyR2Yeocimeuaaufy1DLl4cdplSWD1z8/qzDbDnq4ZZHC4jObcV0Pvfept3+m+1hhhXxXxystWvfyj3a8ylzxXcMPi/5faHMD2Wznho0eERl1btSoDEACqnGnAA6RqAl01MxIZJRegAFBQwc5RCEF0iURPiilbJA/MjMGoaoGwFsStnz9BwhqfYvp1SU+bBc3JFR99ndkITUXRlg1F7vv+DYuHH+4qOmVOvKWsoHb115JHNwUK91Pjaru62KetXnnrztu0jGXe8d4w2safFyukjAjvg81zTwt+/xbAjZSCMWkibpc8DfGfQHGqClp0oS37QEAbWGEG4I+SYmLAu+XM1p1yY8bwX8XWCYMtZLwGPeoao3jZxd4kLU3oYHPNqJDAZ9e14dV60mFx6Sq3o76Jo/I/Qxls25M39ELQ7e2c1K0VXaXuhUcWFaN1F6zsYGJmHYcg2mpP5vQIaybmXjosKGBihjSsdIUqhMWCDPAMxlFMKHWTJeCzwzFahENmJgAWDXRYZERoHMVBW4vdIVnkwFXSPdWoHQnkUS1qEPcXDxTZbOll5HhHbGykjimziJCfBll8o7TII7/hWe+5VnmctH95r2nYh7rNzS8lhhybQlX4BRnFF80hSmEka2pinSGy5m1haB85KC4SClYfJi3sxNGxS1IgRDtUGvRIvjT0IStAAoAIAYbuibAip4GBekyEURX/+7Jk34QEOlpV0yxDwnNrut1l5U4WYX1ALbDXAd0rarWTjtgBJqIg5N8WbTaBtE11WlfFFF3XVHLpyYrUucy7texpRpv/pPggRDo6LvFp+TIWjXQKaUPjwE6Mqzkd0cABRA1JxIuQPF5M2Mikv6lgga+eX0v/tM9qXz5TXqt9Xlv1VKW+FExbahEAVWNLBDnSMzcKNGxjQ6IwAdJhsGiwQ+G6vmY6JvEmwGD4ocReBU5Raiaq4eVQGJB00dUmi08cngR53WoSwHlUA0HQmB2BgL0oSiMkoEJUbnUwlj9kHKAMPZokRVyimsbMVPVSxYtXMcsLk1UyPhTP3Zmk6mAiPFKh1tTHNiDYyHFa0eqF68avtZVwtGUqfDCCPGgoNGmvDHNBBz0IpQ4lEtIAUjTg4kHWE5nC4YYbg5WMMHhQLZQuYMJk6TJxooCyoGOODh13W4POGAIsGO+k8tyCPbq9TA52tBi4so5qVIoWQAFn95/+zU/+a/KDOVl9fWQK3X7L9p2XE1GKUoJpxnZ+mL23bEwLyk/8zHaOUAwZleQ5Qvd1uQYix1BeXyBvoQ0xLlYtWEA6wIyjtuQxulzap02F+MIPTSvw573MzPAcFAEzMHgQdlpJGQKjPzF24BEkDuCaOHCwCFwVQQSSwoZCQU/MBpBhw3TN8rhEpXkEjAeoVsiB2VgkNvCs0yE2e1ortouSfbylQ2+fua8BGY65N+mkL/h2Ec+K0ZUHDVJIetRwjY8mR42H+RUVdHbQRmJ72uBs1ytbXXRNm5ZqfFfzUMjRjVrZmlw270YHElkGpCW6hAFLbLxIce0WEfgMkQBjgIQAEUn/+7Jk9I5FD17RE3lB9I6rakNtI7hUmWc+TbEWwgwtaZ2mDqEtG4vGZAik219Q4WV08CMERhJiL+Pst2N2IBZw0WL2hPH6UlE5zNWh63v1uKYcR7Pns6XjON2m+31QhRVZy3fHNNwSs+F8odWXYqCMm4Xb3wVE5rQ1Wwp5ZwySfsX6vzWU8ttuk3fM2ZlKiXUMDeNVAACJMMQN45UGDDzANmL05NhjK5oL8iICmIEMbrGMMm9anzMHNvhc+FQgiGnUKHLABisogmoGDNJtWhrLL9GfKBYIgOSoTzKBtVGkoFQSvBusN1orTyOEOFA2NpeDoH+iuJ1YUXzxOLZASNUq2/uecxtHpC4LS9ZjDqJ5hLj3vr0XL7k1/g2+o3MXX7d2oeb7XfzfvOrXFT8/xOpRT86fxJ+SaYP7KyvVmG8nkWlqyEXmwBHJHjMJTk5D+ZjQ3DAsjBnTRGUO6JpmASfRszS6UJoEIio5ynDdItQLFW6pblAx9KpQgYwZoe24SFkgaeJNYd1XY081n6zXedRMfSO1peF2gSa3ltvkm2fJ/rO8emwHQqmM7q6kdVs6nF2Ij6I+hzFO6OUhk6ToeNXkdzMbe3eXNp9+yqKIeet5VQcwygsAS5bOYyGmdloYBG5W5pdmIRlnCMyCIzMCsgohnUbtoJnslQ1RBxhyzV1sOeyZ2w5FdfE1ATzPLUpXuulkhOIcKI46BDNvJsm5hvJEMbe7jpCEm/Wq5ersCM+xK6DxaIiq1m+JGehjcyvMvjR5z9Ivd6QNGV92tCtf1H83PMQa0Y2n/sqbFUcwwdjUqrUw4o+WEvSAE5Y+KhQDLTC5Iyn/+7Jk74zFil9Om5pacI7r2iNp5ZoSYXlIbeEJgbstKU28KLkKMICywBje2urrL8skOlSsSTxMof7KGpIXBikz6BRuZld2CWWyhj3hJDRiZjRFGGKEhWdB9xxuWygqslZrqDS7qmvaQNSqb21vohroul/ohlLra26PVv7p//7f86a9ZAXubvoQAJLrtxkxicOYBcKOYRzJIQDHIYBgIDADRE6NGHRmSBGEgDRWSukDm4CelpImXkFQbQICwbkoUyJ7G5T9PcVXZvdGRtGRrlQuzzrEeuaU3qw/SvN9uZoRvl7Tysjt9gZNQ4rmx016ZRe7+6/+r/vu/qH8t2Fig16u/dQdaY/n+O9ThvXxj7CGwrfbJ2GHUD5+nujp+UpidBlKeV+ajnRP6AE3XJyyR3Z4i2GlSmaMBVYZAEggEY0tbFTRqkSEKwQQMSLoVKGWgIURM4NXylG/F9o7WiwCc6q4i3b0ekMQK/QMAP3p1e78Cc1/vR2xMpfc/ZhvYtUmmbMxfu+FA0MoruGEUs3/r9+1EV6dKGn/96v023umdjeRHFPZgbwpYuDfR6QBUYQiQajEYYQgCaYJ0cPnqZCC8BhqGgtMKTEMDgHU8YgDEfp+ZteBk4GNISQjUbUiTJCh0CRoy5UpTLd0dBJrNXGgo6GYwTD6MgEjSeA4Yl7Mm7Rybi9zrMLN7UzKHi/weSqLYVrLBqZIPCqWN4+w6s4oPv1F05QbUv3sKpc3UJmVMg3Gw5hN40ZEUMrzaqYH83in5nrb2lH6Vz0LPjXbnHTJQcFj3KP5DLh1pBHf930gEFJKGBgGcpLRg17GKTGYlF5h0aAUYp3/+7Bk9gTFCF7Ru3pJ8IHLejNpgrYWNWk6TukLykkr6A3MlXngQVgIVCwKMaC8oyCg4WTO9RW1RA1gweiHXL2hBMUubqqaHYcYfyIocGC40zmt0kvf9ZlPj33Fn9XJVeq88doEmuqKaKiiaUbnEjVazzmHUkexus4v+zI7zjxA5znkulT0Izvqp3ZZ1Xk7lIRh17SxMaeOSRwABU7Xv90EBqKUQhkzYSwMNDMjsOBDYwOAAgIF3goASYQM1IhGQiswULUHFBIfDCQYBBCK6LSSxIB2LPxKF8IpMJdVaFhj1OthPK+dIY7VTpR2Ncv3TJrkU9Sedb+ZmNzBYV0eUUVfweDE7cgODDoCZSswOFyJkzn4EMG5p52rKil5Pt5uUxAs4H5N+xwVixhLzpgODiaJjt/WCQpvc/UrV8B/1qFckcObK/kynUmKSoASF1cJC3dqH2jIpmD8hT3hHRGybipfW6v+s3kmp57Uo3yAgSV3g0nOOODPIIRUxxHOBFlaUE4K3XwbcQZMmQUBEzrOG5qxAgthjiiQB7Lqzm+CbF2Hg3jIQvtbi+OSPBiEmevd2bsaxPfP+/nEXHvX+xYCBu5b5f263WE6YmNXx4CkY77tW6HxEPgUpDrFWmtucE/M3d4yOolXJA3ZGaAdEXO4bNvNnrnIyNt5vuaG2IYsRNsCkYbvoE/fPEU4UPghEkZbcX8rkPw06Q2QRwWBZPI7h4jja1yaCgjotHnql9mmr43gxtStUbdJYT2EHiyixjBIBxMKIxjhcbexAAtUzR7GJHK2ZCQLDGbEb68FLFIuEN4ISpir3TU0whZa2dORLKbFN5+si//7smTpjAZjZtEbjH3yzYzaM28vDlSFeUZN5SfCQS6rdYelPMBWVw6CYk0bxLpWvHrQjCTh9ik2Ten27n2mZVpQ1xABtX9QPy85EPmi39Q9DF0/nii3edb9MsaqQCZ3oly0mjjczhLLsIoaymzVnGl9109TT+zMjytXmSk4jno6EI4kJmNuDo8sThg2eh7rBDAdAL1iqasYBTWIgozJmgkAXAlsiiBUq5+EQfqmH8nmdNbXsY8tY7ReMa+XsV/EZYtw4Ybpz6ztiTG47me9yf1vfaxb+///L2VBFFnJpUjg3bnk7oVL6jV+J+/cN9XLfJJtdNVlXaVVfRlZ1alfpZXPrs8GofE2cpQVXltS/7W9gVI9VRxl6fmqMlg61B3k1QOAATqiJcQXC4oUTDss8FNMNHJXKETE8y5aCw0DZdLp1CthuTmNaWx+OwOeNySCoQTEU4svEbDSZcycEAfoqnAaujrUFC1cjxxYNBT8dVZBvVtf2tq4hP7x9lG8c/BMeMX/8eSvFxwUl9VH3fCkpVbY1PrYfI4lctYHXTvYYV1ECR49YmSAOaampACB7xchLHNAjwY3Y4vSIBQKRP++jSqMGhkzWQuO0CC3QolfKhikSahX2QY6hTGKYhjVDaMTGaUD91yPPaJ2FI5uf5Y70oDXdx+7uULjdEQqULtYfaz9bl/fp7lRbtdmyPreUzPO3XuHpReRlMbICiiiAGFa845kiWNAQMAKuWJQACybKKNDCQzf6BGKdlQ5E17aikUyEtWovo8bdlvNMb1oKS0CZ6B5JM/IlPYefZaDSKMUTDFBA2hcCfaF6m/GmxY0IZvmuShG5//7smSpgIRRWtRTSUSgeSu6dmlinBENeVFNJRKCBa5pjaeV+BIdUBydY3EkU5NXk0u2/FH148WsuG+hX6qvWrjie/4t53i9Oe2q+DlyR3U9o4wF0XA9/ferFWzkYA7W0YFSpgUQULk7YwwhexExd1l7EZGABaIq0Eig4HVhI7QlzG5mGVsCZrNIgLLKfL7w4mffGV3mu8N3+YM0mvTfpNd6yS6ztTEytJW1s3zFzeZW2Okrqqs0pHUV3QzNsegcFnlrMJPSalHsrZr16sXMam2bVuEnlIQejVeIhJbOBgBkAAAnbam8OEgKBHTw0dMfXYuHNAgeisRB6EvDQHwdcJ8NRJLEpxHMga2XoUzvapetQ5EtBc2pqh4yrnVgDh71NiTxQf26nNwS1B5IwfJSr0eP7JH/c28BMWqp8yjcRPtXw0XV3QwO2viY50uCkjQc1MeLVA6fhl1hrl0N5qucRacQFIY4HTB2NG14jGV1PqAEgJACkmkbq1SlkLBHOCpSOgneSggfVEi8KgQ+y5Yq7rlLirxv9C0jJ8ghis+0gRIwP7SgPTXoAOLNfEblxad6pX2rV1PyaE+Tatbo7MtgEfQU5+RKXBZ9QR7ya6mbKd6K3H89mjjaxSOhC+FekfGBlk/HOfVKYongIFhi0Kne8CAOP628AgQ7kIVRnrxB6GQ6KKNo6JFlcvLwJCzbSJygcNqzNmzsUcOWzW3qgGIT+cYn7jRucL6aZXiK3cUvuuoRZ5b/a+7/s8BIrmpw6VPNN4dU+cqx/Sz9vanRW2LlNocdsZnAZx0xlaKu85H/RGQY+ipR1zKVmK25mUaOJLIsRcsV7P/7smTKhASEXlVrT0J4gAtKrWVjjRCxb09NJLcB8J9ojaWOyeoAmSNwCzjQwTJhjuvQCIQSmCOOmk7Im1AB8ePEo8vWNVHYU5T0HAZEadNPVyWzSuWzyT6tcZepTjj15wQYqvoN6O9EWdSlpq5+D8skJWFtqhsTMRsvY38ZNpqXWIW+a5XyaMZljQEwi62le7eE9QWp/97/sXn+SCqjZHcSqhG5tdzECkyYOHEgEwhmcmJHCFwwCAQQHkp8wcDGChaE0aBajYx4TXK0JPJCtHdqc3Ms+dxhWNkqFGAQihANQqIZgcJzLbEDb/KK8XMfSUiV/9rr8lzf/bVmeXW4eRZboFj8tUycqt/1MRkD5Log0+ou0RIygtN2YZQfRullOLUGle9YyrXVpyOuopCAuOKcFY8+VNFMUoAAVSUMJik5mOAsPDMoaM7g8wKaDCxDBgZBITY2wcybDdQMAAVoC8r0u0mMdpYKGhpLxAmmNKYdAxScg81EUOSkbsrnpJKa+7Szb9L8FRlEEY8qs3UymyYjHHKfpWYaIpEdKjg3LOVcaPHyDkn1aqPu+cqsr2NKLOWtplCyOs2eZnU6Z25lPRlpkVaDQ6VmuoBPOy8KEgz0LQoVDTIdOSJYqkASEB05ltHCg5gcKAwwusHFrGeNMwMHSJk5fBeZEXOdUOW4spvYdJBNMA4QJkXKt3YidwSaqcuH2f3yxuM6tUla4+egfjJmElBNkcEuemmNr0v9rf0i0aKtu/m5r6pn80/TT/8nDpH7fSrP/vI/T//3MuFfw903L7NhJ/itfJzS80BIvLH7PUmzmIQdknhgAwAOSSUyCc80o//7smTojES0WlIbbC1Qj8r543MnThQReUJuZSXCCSEoKaQPEEqk1O5FUDKxxQQEktQKAb8GKQUIReCAIRybmsxnJd8aKQcQBnmUVrRhB4RDkmq7Ao3u782/nctte1S/hIyY8fF5yTIom1mQmClSmm6jQ9Myj4VpsafMuhcrXvaf1DIpyh08/3BmAwsSGCieSXhw8BB6gdEIXKgTlgG1LLxQWMeQxhFOZeR7PAy6ZwHkAeTBgsKrgRGEgADA7/mAARdQHDIuMLSQXIMeFtgWOTxJB7Ax4aMOwojPkSMzhiQ8xJwyWOSmbs41yIJOmTzu56gxROpnloF03lg1vTa6Zi02JN83Mns583TRvWo0UkfU8wNi1u+XM6YFx6rLTUusslV9B7zc+6kkaFq1uyDqexOHUKWlNE0GICbmRhARhg3YJO8BOWy9Ks4MEMBajVbc1UNEQgYmBAIdCwEUBrXUE4JACgOLUKXukmaAJQRINoDLBvg5iXLogAJICVG0lSaHAaCyTJyzA4ZjuWbtHaWuo0PmeZH0Gmazy5dSY8WHVKTbOmOkbvUZl7RpG7nvR3dtBI9UroJOuYNS6bz6zpr6dZqfoK1IOg67spNGyJoi1RipZ4lElGBdN0XM1IThq2p16VBedJQDaEvDtgezoA0jyslzalOzWVGTGE5jFQSTXMXDNIEDS0NjNYDzIALzCQKDEgZDGYhzMAGTCAUTYYcy9oMhOQKNnfJxmgIISoxsfASaIlgOkTCSYGghhpECRFO5CYMgj9iEJVISgjJDBgwu+gMjKVLY3mZu7qBCRtvHHqLruhAivLUjlLSn47Xp4BXNJpqZdv/7skTrgAUwWlCdbmAAngu6I620ACK1jy5Z3YAEVUHodzcwAJX80y+bjS7muODG5VDdqic2khcMS6XPJYdi3Dj/1mdxCXvrKIrTu/JZDat26aBeQxH7Vinnt143BUt0zmS0VNdpotKs/vvnM516e3Lt91eoozIO08P/ykl/bFFy18/jn3n8/6bc7WtcpN8y1vv/lI6lTHOLSPV5xg1//9Iuj+l+ZPi4AAAAAAAhFokH4uFwbRo1gcoJCiQZm1mT7xyM+Y0gEoeAmky4ZMRDB0lHg8SHlmpHGJGICHwUmKSAO4J4AXWECQ4oFOh/Q/QPwKoYLD3RSQhwdYOuJ8DqkVHNJ0NwJ8DvhaeGRBZRKGqxQZuPQyRKAcmAbGAMMAKWSSJTIEO01KZFRzRkioZFOKUGUIgAEQDAIUcsLKJkZlEcowHQO8gBbTAYQBzWAEcMZjKCtBwE+XEUziKJKl1ArLoFUkyYI9NJBIWYMgIJkTyRLKJkdKxeda1EmdYgZmcLx4zSKhDxxiCBBDQtikBOAzZXMqlKY2X/STWo4yC2ffNBhjMIE2QctjsL6iDn0BcZl/////////oE4xcP0xEJMEREMkIlQWjAYSymnm0gDB6AIx4AiBgEgm/EbfwA5BRiMq3BYxHos0oYPEMgbGimjils0hpaOxflrKyFQrjUam75bsoYvwmAtBPCXN0eDCBIPHAKQSHUErS5jq8mVYWIdgemtLdTEkUG1lALk9TVJ+MSbUo5HZQtMtQytKJ1YCbyHoamc5+bnJZTynlzHlLcsv1HMaOJRi9UtVan370ojMqrZ3ZZcmq0HQLQ6pML8igujiUsnv/7smRbgAd9Ylf+ZwAAzgxrLcxgAFMhe1udhYAKBa+tN56wAKuHcOx2W6s3aGI0ku/C3auVZI3ZyZTjDT+NzfyrBGEjlE9YlE1368ur2e2sd6/liz38qsJjHf/4rUJRI4y1M5EkVQUkk7IFUIertMNWzkRg+DbjAGwtZpB1CcKdUuact4eOpgvOLQDtThAm+jLKuK7FwxxOQoUvJui5JNMz7iQO/0APLBcKbHEHGq/A0xlSy2temovIJiL/lFqeVbxrYzFqlqMMb1xWwy6KWpVf5rK/dtb/XLNXW6lD9JlRU/J/GU97cuzvKa1jfy13kxbo7tv90NNVr/f19vl3Grldpc7fc8O6y3nRQ3Hr9WbzjVPbpa+8caKgnu9x1ds51seYVtfvDnceXEtDAocJAAAAmZJejKgc4EHL5B3gYNCNc9EvhQJBKnxKoCZwakQQYhAnFiJ0Nic+h2GGdLlVlDYlFKKNkktknkzRNDV2iTSRF2eStrD0nzyJyji/Dyack3zj0Vzlww4Xy1M++dL0zdtZ0vOy47FQaN4tCsopflRCpagd0JZUGm/ThnPXFV3sn2M9l+aXVQSG1UMZoGh97v66p2xDIn2kjaLKTdTIRByh6ZlcLKI/AJKtmSXIyz7QyEujpDgaNislHjpiemuyYmxRiN52FmqHVvmjvdOlc3POslnoppxnNvnqHTZx1dPOczXNH/pf5ZH3PMH2c/Ootv6bU9084yn67b+Z2Ve6H98Xwc+nXwxleeVl6hyek791W04yyEFJyEknSUygWQEBz3LM5FDpOtZp6SaXUmedId4WuJMvRE2RCiGwLMwTJUFpK9M0OP/7skQXAARwXtjjCTPCjkw7DD2GalBxY2GHmHVKJiyrsYYY8JRySD2h0MEVBImHdZ5R6YGonqBpJH2TNyCMJ/Z5+JSfbObGFbmJPrbj5nkx7jYlPxO1u7eHw3ze5+Zb3/tcttgplbmzqK4ISUeZOuzNO/IUcafuXmGNy3KdOytfj0Nlq0EnVEnKAD2BBGcAhBQEGeBABAw6opOB3zqEMoCdxSXDSMl/pyatq8Yvpkp4ystKzMx4mlJKPdlUZZqd3iYwo1DLj7CWn3VMfM8myPmLPuS5KXzKf47FXG3FqtC4fSe4YfLvl7Bbbh943Xp2+JeEnndNQsx5w6W+sy5yZWsFSUYbPXHXBRGrzLT5VKtLVUIZPtthXAgE4AtjZJMDJawkY4yxEnK0nAoDmcEiiAg8NWnYyvp9tapcIcBuHRJIUigx6mXBc9P1C8UmWRMp4Ivm2UCrks7otbaBTdyXl3lezKMz2bPEYTm6wnIM5GEDIQ7dptmwIhaUydOlmU1NfezleTqfDhuajmIIZzwgY+jh1Ejv/e4EzLGTAAArpB5KcSOCCsJh5e4VBuqAHAdGLwsCYQz9s2NWd4mkl2WmAsfCUNrVD8wkkYXillwqOaR7HApVKsYDE3ob0GbuBfHtpMzPR5Rx5UUVPKRdcxisr4xIlmHHOcnTZt6zJGJqKuNdvW+l2qaOj0xb6lmldioaTa0rIT0ugicUWWA1rSN5WtVkuHxoyAARGQWgnZCwHwehNhphBB6MkveAdjIGZPAcdFdQSLHQDEpNqkg64w9f1EDILVVNPc8ifRDSlZRIso7JIja0bC3iHlFLFF8hRdCpxDK3n//7skQpgARDWddh7DMSjIta3GHmLFApXV/sJG9KDC7r+YSN6f0R3EZRvrlrl4XukdhjSJmaztjNr4+Nm51JtDMYt+8Krv87HP4mdAzNoqUUhgYLVrHuO+ndRCWbjSkAAqquW4gI6bSkaiegVAgjmHKXMgTOWBnXVmY+Xk80ZVFKFFIhZBWQSI3VlAIwZ8Y22NkGkcsxdVQc/YhIKSOXWOaucEhrQFph9F4JSidL8CHgUyCAaKQ6X+THR04lJzJEhX7mM3ty3Y4y4jETC993P7J5Xi87vLO2aSP07A9WlmRJ+oKuDv9LCmqKymQwogAFmIBqeDHiDYBfikC/Doq0yJC1DS0/cumWmYiBEjejiSbuNkwnVRWjf3S3kGqyNyo+sYnAhCrFsjA0QSyjpUg4SRR6TwVSCXQ2UlEjVgElAsY5Vet0jcreSNk7d7t7Q40CuYk2pXusXU3L/zpBaAR002OQl0ozkjdumJqSpCEeyAu8BEebRzAI1Hm2FAOY9khTmWAgeFO0yB3z0zAAxWa0oi1aAmRKay1OlN9tfeLOTpNZdCiVTFIcKiwlBxyY4Kr6hEYGpVwCECINH1viSmIE56yNT6/IZuDpAwQNTpGCM3RqUqKR7Sn2hIRMZ/eZ2PEZxzh6jKCSfU/muW2qtVdlqdJIBKhKIo2oG9YME1tsaew4ytTgxhAlStjwMwoT9Q5JwVMzPn8OdgzLAe7fszMwZilUxbC95RZvCHYErqQXI/MsxeR4CrvdUVUYNV6TiJbQg6st8a0eonPjOoJmcQcHIivwkU0TyM3I1UKsc4ecPvAcElQHK+CgeI121nqqIJqksqkeCP/7skREAAQJWdfrDxnyfKmq7mGDdlAdZ1unmHVJ9axr9PMOEQW0tHqCUAxUEiWqQv2u9ULd0UGHKlUcU5dZ1zsBg+JznXTnfP4H3ctqFUkhKFsSLUWi4Q4wojGeCxpS7HKjoysDQhbowZZWDM1qsOxTHPU7oeDaNO7zLj6pFEmnD4Zqwl0lJaH3F7OKs50WE7JqmbzXT/1Fx+mQ3ckiwSCAoCjJkRkVoHNC0sCHJu0JQNwKknhYFD025qxaTL6BSIu9QO5iDVB8qtec6sNw9lFI9icjs0wm0k92IfFVp+Fp7m4iilJ2a5BqbE0YJw8qpcq4UufNOqRHkxwXaYPLKPymsdzntkSxauQL0Pa4JDECTcCNyGJezO/+U0tJr6tuIkEp0nIPZWAqg1cM1RZRY4prEHLwZBIzSOey6muvpkyZxNZ8BZEkKDkJKmmgjZg8epUQxwZQBzEZ17r9mj8wyhkClwOCmYkilIqb3qaS8cmyciEUjL2DnBhKXiCo4Vm1c7mEz6TOTGxblyFBAIONmoC4lKrcr//tfIjXNG4igQQ6FhIKsLAKAwkmfhAS5a47LL0u24vgdA6FAsZF9y17NBNH/JaHUeW2PNPxDL8Ek6dNM/ukvlKemKptzM3wmjxY1mbTc+N/UU14fmV43HfsyOO8t+pXZ23/d/b4zZvded812V0u5c53T/21eC212PvDhxuvqWNcx+psnU/y/nwqd8rsgMNrZWAAsDghFHQdCUyBpKHNtaKKhxlqP2ocO52JS4SRcuX3j6EsnR4404fHFbHdAUNTB1IHSqFBiHZBeYu8ElwGJKgliUSXS2+N1gLUM6UE4//7smRtgARIZ1brDDMwfAsqvGGDaBClg1esMG3B7qUr/ZMOMWgYkyiEyl7EOQUo1D67hrArj8ATLRLMGeog/rlxTzcy14ZA6oTvHMY36alHJWWmAACon6N3Ki2WB2lSKWCoVNU2bCoS/rfuqHQgAMOSWjGsc1HnYgm0ikubGhtd0r1qyzGMdbkb8vnOzjKmYMt2bnaqKPMF5ICJBbFKJ8zYjEzgWj6xuDb3V+B/yAlocX5s3dvMEeUKQp5gp8+DBj5Z1nihwqbiHeFRvTOKPnoZScVAOiJCshNkpJymC0cAdZ4DLUEANO8C3b1OnKwV13maFZbSMTkvkJYVP5m7xFhauXUZTJbNVvw39sx22EucZvcC30irdz/uML4w/oWDCgB8QyoSFpbkZZAhpk3kHaGrdCtnqq+/B4P4BoD5CJxLYitjMozIqut0n7v5zX/yVAlDVTQZGQipVSpdPagjT5jrjBxUIZdfZUwJnGj4ThSfvoCtXlzyu9RKWu1ZSJxIXfD1Setx24lUtku2rfK89p3+HjO8TcP5Wg1y6nfzrvtM8/dZl7O7cvWd30+NjzLubed/uf3ElDlXaNx/Xor373+DXaZmWz6xRZqWzdAumaoEl1iChAALheg0CTfelSEbSBQmoGq/20pStQRuoAAEJgkQgANlSVVRDDWiGj9JM2oKQbQZZEkiYMRWFHuJCt47H1yYYVdqo70hSoRMY1kJf8iotKikhGsXfyWPFuEZl2XOP/wO8BiMwYh83LzPBjCxcKSm5U9yaPAsaoV0OY9A5kWpRCdZKOoAMvA6AgYzwCYnDOGwW0SyDKQhBboU85eniAkEKP/7skSSAAP8Wtd7DDNAgowavWEjahBpZ1OHpG+KC68rNYYNsSMxdWUTKNESVBCj1JB00+Q0sH4RTox1U24P8kFyiW2vEb64sSguIgM1BaFBQhkq1FQlFUuB1IzLFQXsIinzMou2lOqbC2RXMhMcruEXVzRkhIikUe5uGAHECJFtirf/y37ZVtsdcbRAKjWi/I4NgyFSwrrCIiPisVOoqjgurYnVCxw5EQqmKM4K77SdiFhfih23NLFDGZL7R7bKWMdsDHp14OFwQsg+FW7mUQevvyTOMpH6PpWcyLpLMqTv0WGt3KNkhcc4hnERYWJVJmZidl41yR5CoIAXQOEQ3NI9HjrQVDvs/tWo6VyM7DDYjoF0KkFiASsBQAPAWRkn8IUcwZsI/jvYkArE8nwAmfBZZuIWClDed71HOl1lIHI7aSF49bfD+YupAzKiHqKKrNBzdNy5LbkpN2clZM7KXUx+TzTsFHgy5EVOIcMz2OLGL4qNmDcKykcxBs+PihW+FIRmBotHbaWRpZUDUABNdFjkJWzpcx5naAJDd1HpYGqZTGEvJGYJkFyE40Wv0DoFoBjgbSPRKIs+0kYmeACSRYKFf2e9Zo7sBXFKqn12P7ecE36qzUn5z0XOfcqsmtd8QdHmS821kEssi2ItJKO9WR7tu0q1o5V7PKiIcNOYgdY5bLUYc079cQ0aTjRBAJMcAosysWaXOplMnDRaZJmqq2FhkbprLZpfae+HYxOVLMNVqucqrVMJdWxabE8h6DdWPUGd6w+QbEEZneBEOPFUvmxo8rkRZQDgk6aVlqwOxAjTSjboSw6s9VXz3/0LVex/+Q4Z8v/7skS1AAPuWlXh5hxwf6vanGDFng+xcVWsDNfB/qzp7PMOsH2eLaEjhB7/UREAJ4SF3THaQE0IyYBRotwHUoQG4qE+OEmxfYxiJRcNJ+HYXtXk+P9CWT6gncxw3kI4ScVFszQs0zdLMV2hl4vE45JrZKCLI7SWQQX2JqKW3zw2nyZsNmSvg+JbtO9drSLEbfyMDGRAUIlU7oSG3IpudbQ+ZK5FGBHa8LuiAzInCB+GhMcXtoWAMFwEyAAadASxZIQgdm2roIdGbMUnFVoYQjaMEx2IQ7PFpWHkS48H8f0pOJx263Q4prStibn3xw0p26mjqpLVsQmJ6Oo6xS8to3GFs5pCwQG4lx6UwiiJUWbV1zzQ66qzamBv6rEGrzbD4PFp4P+6blbeou/eeM1vHRX0XFA1o1BBH7DY1GHVUmMxhaZTl8lMlSTQyNYBCXAJmbqrpBPD6klh012Io9MrIYGgakwTAKqk5QM4VLC8VgdSLO/YJracv/1yFizj0Z1Zd3lnvwIAtgxA6sxxrThMImQE/z/hrA4hg39lPcHaDsh/9UyqL/+v9pfK+Xe2/af0vL9WXpCYqVDSgARAAAAJAGJKrTOhYYKLYs3C4JVDQpQkAWhQwSJeU42noXBjWhwHAsRX47SurMnysWUgiSRICgXvSyI0yJBnqqwbYB1wue4PD7XBPHTLNkeybWKyQ0QNIRWSvsfJxtcRjA32xkSsLOei8FB3dLNvo2gIbtEt6C80CSYnT1I6Tfqk1ySje4UN/k3rypXPr8p9T8VJe6Vl03znOlPadX8ZahiQVhGE5yFIogMgAAxQMXQlMGKEmJVKvZ2tp//7smTfAAR+YNNjDENic4s6jmGDXhTBeUNsvSlCJK7pMYSOePcWmV2B3Hy63285bdtQJOYDhAIi5PJdDiAVyqEYqWoshQZ1XMrS1Er23RVQ7yBIWdGmZaUF5x3kNyV2XhJ/MjcpMzOdJNad7CvDED6xqdalHIXB+Hino9wlygOHHYEkrdDCsZ1O+flnXNjtSbGnjohpdNdNKkJiAEAAgMAGJlgVDQGYl4EziqbOF854RjLDLai0qkacyzZTKos8cHdji+7UckVPQ8u283l69NSSAUo1Uhp1goyQUYwPwgAsVdcWC1s+B+JOe1bQNufA+DFJphSU5lFbx0dtwUR9I2ZfU5reCJqfhqQGCw6gccfkC2qY0xzbBtSk4mKUeqiYg1L7jGmAruQx8odHIVjNGEYkVGELAAjHABCQAAEbpLVGDrGOzjxJoozePAHOBIBLDeIKNkV6nYGuDuBRnapt4lUelInicQrSPlXaz3wJ6wLJW0JknIWsfkorhYQYzQ8sc29MtU7ZH2dWv0NeNBnFCRRaTzAZcgm8ysrOdJCu3uY3orkammu2yG9uJGdVElAVeIjzJr60OIIAAqADBghW2GvDRBFfLgSMMONFj0mGA5cZK4eEPs3FnKx4ykiuhhctlLxR1y2yT9LGOSV0aO7k/q/pzteHqZG0eDqpodiDVpcMyTJ0PAytUrnZafLJuTplxhVZgIS6fOIjkirIG/8uJLYXhqbi14YziQpsI7RKVOQny6Nt5B/yYx8l5LW8nsLkm1qyzZXj7SO8JyPXvWoJ17Kvw9q5qaTuLZUks1tyPbmbu+/k1tav9NTX1WqIkFgQAHER4f/7smTtAQTaYFFLKS3QgOsqTTzC1BaZnT8NMNlB4h0pMaYY6STGMdHLSoAEMUawQDAYPJ+Ug6DofkGwQ9REyLGFZetBkVeJMQfT8swlRkMe6Oae4fbyzoVdVjx46P6M0XjO8O5Gcy1SWUQjCu3zZej2fmNmub8GCiRfZxWCxzdor0b/V3D//vmCmvnq02/7tfr6v3WhAAAEYAaRNBg+cQ2CTaVbqDocFFEW7w6CVULysTgJogkBZNDz8vumjPYNlZw0J6oZdQv5dcI0bbSI9uQCoByDBxAgf46SqSZFQb3YEVAvJiI8xlJKj3CqJaziEIRt5xJyy8UzFVVaqMfQ1DR9h6euUHopuzmmz1E6yky/a4HEzstN+ZKkeh3rDitk9ba8/vB35at7Ovabb6Z47DtP5JP7ZyZbzatdz6d2f86WCzSgAAADGN6wisSvjaFNQgJIknGCQIpB21baNf7pM9x7ZUQNcu5NHYLTkIPHhWFFLDdHdKCiFqF0UhpQ1WE+tOaYg6RlLhcM0ylZgIdvaLgy2KQP0/4XtPU/OR2j96VZNa/7ZqFfaM5W51UkleGKzDcJ9tGd+Metx29X7tAhQFNEJLiHAIkDAwAWIFQWICAQSso6voYQImdcWkg/AsNNuos3CcxlZJEc6KBH6qHwkXZOgZo7lw0hcaqiMsK4s6FDQx9egJILJOJZ7ezigxtqGOB7OcYYmKRAeouYeqdjo98C/220x9flyDaYKnyPZRIHV8+3yRI80CSVIWreLQajiL6UalLkFZuoF55Mjcr9mjejvxMZvkhvyMrHxHe9/5//u/lsiaMIkFIElVLBoLNBGZKx/P/7smTvgwVcZU+zTDVgfMiKLGEmclTFmz8NMNPCAixpNYYNuWWgIQotUrvKrI/qMQa/cbw1fukfzFkMdd21LWYrT+q53qn8ZO3rkiNpcjhtza71b8WVYlMOdN0A6gswx2HYJQVhii5PGeIhR9FVChCM8yLxobNhE7MzIiK02I1e0ymVm5MRdglgANogYcUptZj/9fSAIlBklEgAqAIhEdeQY0xjftJMuGXlSxup/I4oxNLZ4uiphBU43drV6A4GaUx7OGJQSwLiGzekjj1sds9JEOEtNtfE5iqMniP9Tc+sV6LpupalYcQXDZRj1WTPSUyHfUoybz+zv7pbnusx4jha+iCDw8Twd8HlrseCMrSLoWZunmlgBT2B5NUMsEF6HZbN1sAIBiADqVItksJehvBRfBLRIRXd5MtDmwZhqAste/zodhmaFh9eYY0vbSiQCREOA6pWQCZCnCyRhMNmLwSp4RRgvB5mBkMaDzTCkXUTmYw2kk4bS4+dkUml/GfS4d1vevf8xUdrrc7fe76/M36z8d4VDTA7U/eAX70sowAUBKz93Fevz9ggAA08M78sELAZgNQkEgocPMKXJAB0hEsRWL2BQeq9LYmNyleT8Qtxkrp+WwNUgeCW3fmS7iFE/z3q6uBUG3DJmxKGTGh4VtUh0gzyIEtXbJsTMkx5PkG9ZpB2QyiyBIYjiSAUbR22+u1dxP1Gzp9yU3X5rMZ2ZRwwKvSRiH8W3ZmQ3mBJ4ACLgHMPOmKK/tkjSSAGBjMMFCLhb6QAAIAAIADABwe6IcfWYsmUBCqaEK9NpBwwY5pJmAyIYVFCIBNlwm1kACGOvcgFZP/7sGTvgAR3YFHrCR1ghMk6GWGGdlOFY0CtJHeCZKxoMaYaUa6X5Dslj2DyNagDDatHaI6IK2JSJBE8r1SueFLhISa9G07A4unTUxdgbrSpCi0+qNoftbRI6HSwqWn3vbsyWworW5V2zHzl7MuyHnzuzbseTPv3P7mRyCrNtcQYgfbufRq4zDHB8/76p8sAIAAAAYyZfI2cxWDFqAjaJjP1XmdOaiheFM1JIlSlUbRAWaj0+VTBYciesHwyHlGIi7rjy+jlLalcLL/XTvbvtXth01FL23mjXxIfzXIo90+FbdPmvYemb+awzZg8+2Xbny6mbvn1rPqWvk+r1GixuRwzLCJ5yXD/plei+8czAXHc7aKL1vkwLnVsuFNCfyNPFAJ47nuwh/W2rmdlo07sDy7+z8GIAhUhFRlJK0LUAyWETk8mTPEudWCClzpWtff5Aez25CK8FwHb+zDkWkG69Wc1K8SP1CmSCDzo/xPWn0r/527p/yQD47Y7R8h0xHpmrP/ketbc/iHf7nbM/3czsbtIW3+bpe283GZRa/ixRf4jy/2WIcV0Iay3Zg4byxJURMWQ0HqaerN/+msDF/dNWilQXsgDYAy0jX4LZhXs+joghiCRTFPOx9lDbo3CqaeMYmKHh1kNUTtKp4maNcJSoMAEYZUDSqWEYpJ7ejHZrhUh25ofTcRu7XQ2ngjdFSOQp7R+4mZxEIkI7gzzVIEY9qIxd2qaRU56HbUSlcCj71B8msIoTTauSU3s0lc+Q2xVJU+v2rSpeXbxhZEaS1JOELZWZk0SbpfGHkTglDaHQz0BLKzTe3VVE1zijY152nZfdD8B//uyZPIEBSte0Ut5YHKPK+qdaMyuE51pRQy9LIHurSv1gw6sEbhIFL2IOhOutHnmg9or6WK9aXOlFdSmCpTP2oJU/9dF8eIgy4LWq6hTS22ck+JHK//37P3TU5qu4ryGIUaBVW068D6GZb/V+kkK8Pkzpbef5/CI+39n6xn5H7oWwucCoJcSuCrF5ucpBDUZ9kXENs3QuOFQuBi5KBaSw1E0DJHZQ7rFL+NA47bYGx3cJwjE5CeAs3wVVK3IWFLl1zSnRkRX65pheBWXiSkG1FAlFOELQit+dh++iyeQR3BQkbQYdcrfwHI7avnHV7ju7i5FbHdDmuyjx2cnzU8KPO7Jfub20qBgqmUOipXVsETsVaR/xeNguu852X6AA8BoQCFmUyamGC0xQAGQIu6EAxEMyhAUnKi06AhBS/yR7O38iZfts2EoZC9stUp4SlAqKCNhn5JpPOIVDiTZAkQMJR7ZUzmFYlSAfiyyLIiJjKiUqFdQ9m4LhvaN6RGi+odoKdGmeZxy/xrFxCTdqNa8bSRvHLmXM9tCGXNdZBrHYfB7RL7Y06kDuX+kBAAm3s4bNIJisFGDDSMCVUIJCpgQOGLC2hSpFAIBASYZCJEDYkmkXWMGAVx4QsOrXArcVgoKX7HkK1NZRqUsXhmDqu0O+Ow0EGsJJL3svjtti4OwE/9aSUS849nRgCiF9rIC3UDZjExM01xWhrSJ73qKLeYoLEvoxUvnhzqCWqjKWJicMulCV6q6Xs4ia6U1LWObGzFX4rRiha11NGmLhq0YvMLNHETblTAryrYViyZU9Jy3971iAUAIChGHrhxyMDiVMMCAJKCI//uyZPMABHpd00tJRGKNi7o5bSiWVtWLPK4xNoHAKyklsYqxKFA6ikIgdJVVVK9CFxJYqFoC2nQpa1lpHYr2awmuRw8iegxwwJKG+0y4g3DPKlTBrubGfzpsa1qbw0NKc20sPO7ZzCA6dsTTSzWZtet+uZaqtd9rqy4YbjDm56hq6hEGc+8yOTSDJwIxgyNtNjDBBTMiBDLRk0QrgYv0AgzGgedugkKXdTVGgndgRmDcGqrnZIyys+8ol2NZ0JVZWQlzXCqArUue2zI3CSwpEGxCgUmdCp3N03DEy4kJbs6FcOlmmZkg5G4TKfmkqTONVZsBlcURiNil7P3rBLiYGD57yYWzB4VbGkJP0mqfqKMuih/9V62zj7Zhu3vqDVpE+M2sURM/KrrG6QEg9ZQAIIIopQxLsnHiQMKhxAMTSC4ZElOwto08uNNt8v15Gz0yDDFoX2OuPfhyO2LO7nYpvijtfUlcxS57u7GlXyjpjZatzFJGgl2NV2xljA9rnAw4QVFZak2L4Repl54DWzJ4RWifLvQrTOkeftl+3JU/8nZi2EDnSKQABc7bpOMIAMFmbwxjB2uoOBQUYBxCZkeWUAqKRlYSlm6THgwTLPK+h952kMFbG0eTyaOMFljLzooA0vJAqegm2YxkHwzdCUMoZaTtySJVc7CDNTXRN2on7KlC2QPLyyrve26vs9viGFlYtfrsZ6nnjbstc8/145F0vm1/GvtoA4miteMnFY5Y3zLOCYDAhnS/LP2HeCNexjgQQADDUkQ4++CDMw4VMRHQuNmLGAMCR0BEiMuSYKJl0UqVNXhV8ycQAhEQq1U70pyyBs0Q//uyZPiMhWFeT5N5SmB3qyo3aSOYEyF7Pk2kdcIbLqfNsw6hmXYxnDxZJwlbmpFhyTJ5Zl0crAxjDi8slLXrFPKHuzrXuL8kMFAo0cHJ1EPOmK00IrTiMnQx+K1j2lYeuZz++ZU8vO6c1b/5+XrIa8CsZCodmSoEAJICcpgn0GfB6XHMLoYxwbBkNzhpQGgubXa1DRMAihSSLBXBkRrpnuPgzeIKrIwJTpuTkVfBPVyz1ZEOwfEcrGYth6XgNHicTgrggH8aCJQqHRKuJxRLFOhTn2xmzloV5Relk0T80OzXQF1Fe8KOktTf6nqw/kdSkfKsSLLylHg67yqp+I9EZhiBWYUFCyv2KSJjEpfY50lq1Nh9LazqIJjx3c9ank/0SNuv3gQl26SDP0yOl2F3P60x1N+aTdu7hSugEAgBIAJUNTKz4H43oZKCwcDhwNAIYoiW2IAd+gSHOYFwBh8bYpG0M6J9ohXWVHGa3ILpnuqOcDwRadG3waqc0o3GgXE4kzWt4Rtar+FENTRPBGcR/PMpnVzNHMl9r0Paa+ojrfXziKf+6MXPYTVHutaj/7Wicx29z9gAAZpnCJpqEBiKJhiYGJk0f4cAZABhgcEYsbZlwAoYiMA5M8oOOOJjrWC/I6UAqIMQwM4ap3YHAKHIRA6Z9l3ulAV6s5i/4eZhWhuyXBcfiy5y6Z4cDmHk0L5m+dD0IT9TqjlSLq9ujjxbw1DQClakokuoRwX2qoa+N26VVW6YQWMudR/Y/LNL6z28wx8DtW5Tn5p0a+ZlhTWf+mWhejy006vTNW612Wtm1KfOc7UqJ7Xre1Gl2xTm1mWv+XQX//uyZP4EBhxjTruZYXJ6JzoKbMOkWBGJNE7piYIJJKeJtI5hrtcIgNmpJoqShLIZgMGZgJVAjDzwrGUcDESAhAgEhuMlu0KTzz+gkRBQ6xSbdNG+GFacHmxozYCFFyNyTJs6SkUD+csteeeNpE5G0zNak7o2onMnBGIMhSx4V3t5wtRZmtfDEXwrfdb/Cqr0/M9czPXNDwYunuifZMbhX/7GvJLr2y6/VQAlFAgKg9qInAgACB6YwomhElmgoAABUCFQBNBgl8piiaDArZsaGJUPgBMhBcq2nuDJWsLxqkESzOpylS5+dQTMVRsr4uVf005y1dAa6UCvkJEZ9J+s4mbY8F/fpc82/vx95Ru9zd+kyq8cjrtH5Q398fu9V42/lHZ2bfzY5lqzt049RTjib85RA0lAdURopBAAKdCrwfWLC0oYyEBB6AQQFBAKF0xTEwscBntRyeB/nalUMDoSgOfLCZZIxKEMpJjrPGuahmdkktPKUzo5NFNpnVGy5yfDc6cLPIcf0L//Mvp5pN94ZUz9pI86fz/DQjp7RlaPDSRxvuWCn9Quhc61Qj/Mjg2xYApWbR5h84FGHCYZtfJr9VmFgcBA0FB0Y8CJlJQsXMGh8FDMwWNC0rhRMw2CDBwvEgSmorAWVXNLyIKFjIUiwYpxMzKaBMiU0a3FPsdBzJwp4qZNOkfC6TrJEVSpIfq6XVlZj6UChjw1bF8pAFXPVEuRpWhLleVeHRaTxXBIteG5wmi1hg96GvlFiSFOFZWfNShAEBh/NAbdKK6ovQjTHooxX2oUfyAhRoIpMsvEBIYkcUIh+Sj0rI2l1kiUBwBk4rDI//uyZOUIxH5cUjtJNHh3q8oDbSOUGnWdNE49M4IFHqeJvCR5qyOTXxdCYpJRBDpVf8/vR2sAECM91wGEG4AJpYkHGIDm0A2I4kR4GZGcjJEO6mjgOXdQCo3vPJbyPSJkbMiYoZFEQ8EbSnsiVGa80Wr41Tc8hloY/X58mvrd7jvHfJVvO09mtWQ3iazEax8N97dwq9yq+whXz5a8NswI/B0TX+nerqYH+hTWU9lYAQQDB7Aiz+8VAABjJ89NMmkBAAWGxj86DI7TQFRWZXFBoQlAIFAYQBUImJgqNB/iq4gDZAKVjS9TJWcmAcCptMqppS2OXOMqnR8ZgLip5w+PSV2eO3YHCRPW7gS82XRLXMH4klZQAI2hdJkbdJgnb04xrFhyq6asA05OSNcgXk8s+wovFeErvwXTl6eCSnHZWFA+QroayhGDJu2y/faRD/bFr2W6LW910voZliZHkj+rejLTos4liZuVkehvlCoqvBvzxWNPr0ap7mPFjyNed4pDt/Pi94kfq3doADoxlKJTAp6dSea4a6ICIrlT0Q2dguMthE15VKIOv01pQBAE93bzZft1rWcj3TPXIZ6Ld9IJvaaU8YQ/y8y3peG6mjqi4wQvnDch3zlOJltdRMOtfwwVnSY9NTKTWUjqey/vdqbO3dy86gY/X2amSyoePiRm9xYcZ1WIseOCY/8gINLLjt6BDE5mkrwLkeAtlYQT7GkcGp03qNRXjyh5OfHNMitccyIBG2FRzp4JAoWbgVNucEBQAAzAiZcieJfMwAFAIIr6aaazAt+nHDUsHMDbwhpeZI4fIHVDpNH5CGJ/xTLpc9gQFl5v//uyZN4Mho1nThOMfXCmDMpKaSy8VW2BQE2xMcn5rGkppA5wKyySqqPmF2Zd5ny3NXKFU+fw6WwdGDGn2krVvTTnrnvV6jLHIKL+1UFdIwj84zxAMH3RKtVhxqRqCoql2CZvFkmWrZmti/XlkPA64TVkk/6ZRH4DwJKszBInzFzyG1Rqcu8b4vuXFrGcRBIBAsw49kiAGWBhcUmg9aFcVFQrPi+kAs3e6HG5u+tho9/6BwJdTFC4qdJYPliKJTxdUBaKB8eNahJyzXEba76XMkWVfzxP2whB1fJzujz7kT8I2hGTKZuuasetAbav3px1Psv88yu6zI081ElSL0btCiCosxDRQXGp/cqgDX5I+4gBySBJIDXhkYQIggsEAUBDQkVWMiEBEGhcpeh6FVhQDMBBFCpDKnSXNNvG+z+yV1m3ERS8TXDbbKjytaS8dKqPQnw8qWLLrRtcXlrFzFdqYsLa4WlD01J5/HhSf+SlR2FYQn4qmkzNxqj71lfxCjUywbIFqvNWsI0LNKuniwWx8mkU8nq3XGBKlC5xqNb00+ZTYELsIOvWszrDoEMxcToHeMVvWTzf9+NVVtFmb3/v/jiSqCNSY8YHFT3fpFYvG9zPKZuLrQc52NPLS+xeyDrtA0OWdFVsRVw5gsQ0uJC6OWl5Y52IvbWOLqB1bqJv5v/qJx/tsAzXnf5iSbkpLPw2e6wVa5905f7/1i3I/39x++stp7N4cPLoFAR6D0ZnrgGJmQjHdkyRbMOGi7ZggAHAyYhZsx8qMmNGvCEAXGFxZUE61ovMMBkqk1kiD2YhMPit0Gg/T11RTj9VYg3WOljmWC30//uyZLSIBYRizwtsTWB0iyrtYQObE4l5QS2w0YHdLqiloxZgMonO09OrISV22QGLbLYe92Oc/r64+yAoKopYK0nABp9b3LBA+mnNpXW/ZCmu0c/Iy17XNx+5x6vU/ujM+pn1j42bnOJIwck+P2LiACQpwIhvlacnBVjpusADBXtQY3Qs9iMSHByYKkAaDIhJZpMwoLuSEEEJSgd23HKaB1MZ2rUYDXivIGAGYdNRfgqwTnylVOXhz5jNQXp8ZiBy7UBHfK72Jo72MilMtme3Lb+ascbQzd6+ZWmPytqclB7VsVatUjmmtDqaCg9XZHiJXMZeugFAI4NAjrITVuM9sUzAZQoKSUECIamSDoSDEHCjqoJQONsu7XXSkuZRg0g/b7NaU8wN1oJdZ6oEb6l51yILpKtmGXW+7DkI0q0pcSRWPBS9YWkZ8MIiKwJQIGKLRnMhKEvTMS/gSy6hAb3F4e4nmtVX3aWX9br/Hs7IdlL3V/9X3eseCsNshfDld/h4+43lW52JNzyPKtQFdrdaYpf5z9xMPGkoltoAREDCDVdbrGlBDoRNIpl3lV6FWNb069LA3fvUVE6j8rGYywy32MJtQ1JkCBoTsprLHRhOaxoui20GH0ElhEWwsGjmo0UMH92AvgMSimMuRuqyCdnmDHHgeWQqEIHUo+D2bV1Nmn4ifOipyJXIDijjZZ4BAADh7r4bccEgaZnDmooBQsorCpECBQ1YbS7RMEQsYYIFAGwEiHQAegeDLgn8QQzUoxvVMcRrPL4T6w6tpmTXo8nD6QSaDQIMxIibLcHdiLlRR8OUgPSYpHdceX2SOpnV23zvZLO5//uyZL+MBTJezhOZSnBxpjqvYSOVEw15Om28zUG7k2o1nCB8Ez1TZ+ahmtnwKtHwb/33W9v///TIlIe/cxs6Umdp+5ZKs6R1Up9dEZLeK/ci6+Ysh4AMm2bRy1pzAVsnGCF1BE6GyNABw2rpbN3VCm6qZWHK03IUGgHkWndRPYBOIHAKQs5KnMRelwl60pIv9OZR9n1NnJBOyMLJ41x8PBBb1JUBHiSgi7I3qMLDogaR4O0BtaG3pDxUUKmdKBKEmk1qDtUAkFN0yBHTPBJLtmFgcZBFYEBxd4oTG/iGSbSBTdBwGgVx7f8sCQqLZa1KCJx67zsPvKs3Sk5UYLgaWtCU+YFDRGwiKqBci+hQZUDA+aNhXGRVRZfuII/ULkDrFUaHq+LfuBEnMSq0iJgoX+O7FEaYqeEFNlP+4i0WazmTnWosjjdeLSuC53CGpKNk2CMPuVi/WAA9ATQUjh2gRrMQPBGyDpTkIoEIzBhlQGTGhYWAQic7THXV1DaeBdVKZ/I27aOMkjqFezLPmvnbzZlTCaSrhsio3JUgTxCZRxTKUpN/9vU7IQ9BJaq0yoaoQUXUTe+x4wcZRESOcYRHcqI6izD5wzI1sRCQztMJF6WgAAlOGruUbNLIkCzHjEEZ6BQ+AQYMFjsx4ijBBTLshwAQrMXAh4JKMAEGgQwGD0N38a89lSVqaxKR2V0SfKWYr8YZa9u4+e1AujZGMcWtt5ZqNfNosdgYYX/enTLfb+oU+Vx8OUVOW7jLSn4N2aKSXoov/6Rx1QZ/FaXAWp6IbhRPNeiW9l+tv7zU88RulQ+lPtYYmt2mNsZarIIFY1rvls4c//uyZNcMBI1bT5uaQXB5yIoKaSWWFFV3OG4w1wGkoahprAh4BAcAEspyY284+RoOpAQ6TgJbl8wUZOVioyEYS3yFSzpWzZhrVBocC0lK3aCrRwFQE7hAws7mBjgRFRahVTpFLowlpg2hfbo2MzqZdDGSds9qI2WuqZdSB+3dxpuhMivQlNG68WMrCLkUKgAAc7qoTHJQMvi4AuAyMIzFpRWOPBIweFgNACtZh0OhPZwjqEtAcvVUY8cDYTwS3GhOgig2i1n4g5VVy5JLUu3ngcaDBGAMTlVjbZYigSJhSJdBAiLbaYlZgCRIRPRG/Ujy7EyM5cXJo46UNXXe1ttQ+4cY+R25TRbfQJ/FdzDZSX2989zzOIvDz33P71575eHl76V/Mkbyq1+Y0RepBth805KC4oOdBF5Mhq/9IABSRgIpzi3AzMcNJNQVLAwfMWKR4oWkZuNCIDMPClDCQPQlKkXKimWBJLhIt53giqjI9aa0dPVOOkLYEjR+z3UCs3Z+Ew4lbRe4tiVxb73G4bmRKfd8HcRe+EwM7FPop8sF6E2c/z0BI8Jv+omCJ4IOAFN1nVSnJOgCePyQfKE1LNxUk0EhjTiMNPpY7MQQoKwMTjIACBh2OKIBEMw+DTLAQMJqsy6DwEKY9gAIKmSJZLUewhkKJ4BcJDE2RQ4tYVCYZYZkHMnst6Z4c2xgVFApKlDP0NwaOJLylW9XxZxpq0AYQaRQOMZMTwE5K7Y0PDVrg7ydFhKdSBwAQE1zkO9HKDB0H4Sx4fxKSXqRsRhPVtrFPH8gXM/RM0OVq4Ux6mntJC2OlYpGpPOpXNRw7TqdycH809VP//uyZPKOhWtczROYSmCAKMnTbeOGIQmfNk5l7YOVMOl1p6dlZvn23qRkcKu0Ixdvmd60/YGSrAwZq/PxC47Gc7UydoYlHV+5QfXM0WQ9VGdiUP89nryuIbG/3Gy5zp9WQKT1iXljz6zRzqCdQ+JouwWNEj2oBwpyStmmSJG7OnZumROGABAgsIDSQrzBh92QYCjJeRN8yIWMw8WyDnEwJBzAiSYUAkC44BVKu6HdoIghBNQw8kMJcO9eV85BdhnDd4Ffe1AwABJWIoNzRPKBhcnhdCYibhpwC7DWNRFHQBOAAQOQWxKizl6VL5QJNnhVLwfalBzpksa6P8wgf6ynjICPpxJj4N8+pFOOOjm6Wjgb4BBEYoJJifo+Iu2Z434gEgPFDGxxc4srt+dG4ZbLZb2yDiyM3dMZs+oSQua7dsTnsM+fIFEB0+9V7dMTkID3iZhVWzaEgQJGKgAAkBQRanEFAfaGAgGfOlrUqlN1LwqGFoNZjr7kAaHFgobR+LOFyUjE11HXY3E3RpZb9Q5OZ0Xc0LRWEoGRLMEQAtAicA0jIQCkxyD9cl+uzFckDY4HlpMaphOKy6Cerprn5Q8Ipt780tJSaIkYcgP5a7eLmhRiBHAkIM2QYhJRhSDqQsRmggwu2gZ4sZgZI7XedgoX+eiTNNHxnzI4MZpj1oW8iQEmLmGIhpKCaKRtQkuavP9ukNBQJ+JRDJ5fKzv76pCVjxrZ9thJNyXmQnGXBmHAmKkhglnjMC7KKQdFlqOiuVAIfZjToRK0quX+5bwLhlkpDldq9CjNoSmb3FarhALcZ6ck4hFo5MTwssNYVjyyh8TucotZ//uyRIyABk1n1FNJfXLhTQqTaY+YFkl/Y6wl9eqvMWu1gzLZLyJGvGUD1qYLtu1yda03pxkvhgftk1Z4JzyKdVwY8sJwUbXO8OhUuOqQGS783F9nQhmcWI7EMMh6XSTC7YjkLYjF2uzIcKuSkMg5EYpFptU57HgxMG1unSq1RMBHE0rzQV62c4h5UIS+Qw40+TsJIP8n4fANxtS7QyH+dC5EUHQtIW1sTnGh7Z2qNfEksJlV7/RDyUSDbkcKsTiCApjhU4wGPFvGXzCzbjZ0K2bNzbWliEUfOESCO45bmZTT44TCcUzcBCzMqV9rwaqsIG45r4K3ssxrXKh8DMYxlsO9yaIPgAAOxA80K4QmqIouBmkt1athFPIVGcrTTvGl5DygXZRNGvNg2qOMnSsFGCqElRRV7EdKYethqvG1nLvBfQ0mSAl6eTqbYYKqY3jab8Bcsi2+bMJabE0aNLK1P48bZLHo/vWuABjIkJOJNO0KyJxGKRmqNHWJF0yIESBglXjA1MmTNOpY46sCwO/l2QfdlLb3rdzs5qbi93a0KEdyfNObSaLx5V8rYvMRJlBsZvcXJxcCh6KtarrI3LuLTzzuKd29m9brkVrM0r0L83efqYnB+trCq2U1WFsC1l1tha5baozRGWojBUkWqysuascLhFJzaKKG55ApJbbwuF7SdooqLnTyp+BMlamrvfb4X9oRMwMAAXEAjCjF0jG0NUUHDCgZe9EBLNg8YUizdF9S5vo8xEFRCBiTw5erJJE5Peg1kaalqVtn6F6atZ6mtugqzam1+OvWc/1zJRv3S737sd1lEv+xrwsmhkw35Ykdhrm9//uyRC+ERIFc1UssM/CPy5qmaYh4UL11UsylEMI6rOoJlJrYnOV+UI+fWNSmu7ZsJTEbbfdx7u8VmSxX+xT5Fm4160xuxYlDUSOnxraUDQHIx45iNIIAiAIwc1fBnRQOaEQZkC9FJA4G50vQTIRiEKlw4soTVF4BVgNwtFrEJi2kvR8oXbR8hY+ht7tFEOltoW8Yq0Kqr3nkA8C+aqaWIkNlC6FXxBMDUPHXMJ5IZZ1katyIU+MNv9YEclblFyjkpneutWUseZenN1WMjHajVVbke1WfITtBwgWLvwxrK8Wtot3D+hAkwJL8DmjdEMMo3VVGFhFQpwoxQoum0BQxLhWiCmVrHZ5E38FEEpiEjIT6gzKOGkym0kj8bzTYtnlqb9drqVkHQagSl2lXgaZHAty5yZJxI5tan7D5YdnSTambsUNU26Uc0/3a0s8PLQ0zVk73VzClHPNRJVOp0XHZQqoeyccP+K5NAum4aUAPLQfENgcwvgN+VCS/7tDQoKbuBYlAckIsCqJ9mlpnOCqxwG6y+vNvqyZ6tUmb27xheidjbIOhn8PY3Fk7PbYTgolr9O2sWBwGp1cY71YfSiX+JoTUGo3KKndj42rdnfNbrJWzy1IhPZfvyjle8SbaqtqmydnJ1yKMtnglMEhzrd9hJwl8xM+LDAbCfQoQCom75hIExSY2vI9EIdMLPQeJVgGvVjAA6IONmvw2vMHmVueClTfQ4NTiM2tFm0ASp0LkJwdBzpXBschqNUmpbSdkH3hwL8yfQMWHz83eklPclP7m16Nf/Ec2ixjfP/CSPivrv/2JLmsV2Jp33rPcma4mt/QflmRL//uyZDyEBJ5e0qtYMnB9yzrKYYOaUiFxTmyw1EIArGkNl4oxFZ/2N7War0pHvtUXg2eTp/QKBZMYj+unEa+sGADXJpG1QA1MQ0bYMAhKVBQrXJW02UJ8wC2N3U+7UVkb2MfpmZKcRvmrYUfnJY5txKjrpfCBd8eHXzZul913+cPHqrmdlt8idn72WzJ3ARlAd4ebMKPwds7yuf9wYlOFRSRS5z1ayUsg9L/8/zX+fvfY+LQ0DMCxt5g3Jn8gm9ElTeaB24OHO0My1UllwIdwSEu6ZU3HkBhmGI02VFQeMeZf6qyHlqgqvquuPUkBFSuBYbX4yXF1ux6i0mhXcEM7Hmncn4f7Z5ECMGYWCJhzQVF4AwolWjiLe8UqjIve++mne0/ser543QZytya/z4/2u+f82N7T+1t/jPOab6bcdkp0aVWkcZXORcAg3yHBgAikAow/D8jOXQC9GK6AXRVaSp6iQM6bqg8mmgXrJDJTEBGEDARYJ3VGEwqYyTEonjHyrBqUU73SfzeKY1N77BvUrlFz/G+8LX/+saTAr8T1leabXFUzS/RKO+oNk6bGNQ38zrbEoKc+W27XR7q+UhnmLzZS7HStmkcKVAR+VtBNAKkSVFjoKjQQgmvwYDMACNqUl3AAgCxrDIEICIXMSFC17apkGGAJAAqFJZomlgCvRuIq0W4wmgwi6LchhR9KZshzYxFphw/1Vlf68KFijrc0Tzd3GE9fSRfGx9Q4uqm7WHSVvxNiC3v83Y7WWjqiEehiarMJEcRApCoZkjHNlMu95hjxVGpetHxdpX1YpI8UFnEgVnIWawpLuKi8ViUAgABJP9b0//uyZFKIRPBeUhtvLOByxdq6aYiGUqV3UU0ldOIKIeiJpIsQ9zLiRWGkcpguVK1wRkSiVLkALjO0zRCGigZ3FTxjMvmrWQl44R7AazswLH9aALl7QGXckGjLeb+X7JpjAFKoyerNukJN0aYlp5M8fn7YLL/7GKgBS5rGM1ffb40ymd/+dg/ev8knfRCxY3uoDAm00lTAHRqyIxBoUJ1ySAFRlW4u0ixOFzxoeFQC7ovBC10oodpmvW4RedGq1KpOzRILyGnwE5AD4gaUJTMAWnL4YBefVSWYRHYupWBpw9E6/6+CIyZGFcsKa81Q2HP3yzVhlbJb2pF6EaDzxzdFWYFdLdmfw2ok5F6XfxHNerDPTXNa5PHct3ayCdqNmdQDSChpxNARtOYxmBYBjrJxSIUGmGcD4YvYQBzXgYga0YXUJQJMGM+FoofIAIkGKzDQUXWXvTbgtKkYBQ9AMEPr9vkBR77lMvL889JjcVSSZBPH+6QVeVv8B67+zuss5DH+TetfoadTuxFbBoaOW6A9GyuruDETbAK9jYx1SVoeKrCBgFhq1rPdagDAACbuknC9xinl7D1YOTsEmU5VDFDUBtpejOyFUrAlTMy8RdhXLiL9VRk1+Z239DFY5GZ7Nslrg2WifZkS3Mne/cHUe9bbxfEF13bG9p2tbHlF4rLK58KVvYVMsIJoanxuTc1vQ/0ry13gOBF6q7k9vsCf8G8NN8L83VzHY258aJ6mLlsPhLCiwKTx1lOOmGgegwkPzMmEIFtwIwsACNYZGyYcaiIhOMsCdZrAcalJjgKJDmq+DAU+0FPtNREmXwyt652SylhUCXcm//uyZGWEBLlfU9MpRcB+6zp3aSLHE5l5Qk5lCcHfrymplgrQh50P5xmlypWe5dysBMtISH0st2wLG/8pumeKai608hfheOI79Eqt1VQlb837erefvUgJZ32MwqDF+VlIXReu/kNnk5qiRGokmXwXAahjAwjNJgwweWjQ6wNJwgwqEpSWYHR4W3njL7D9BpA1RX4YCPSgbV2SIUWOGGXXhxuMYBwaDbauIkLWqlgyKVJRDUMXbVyESyw9OuyhLHiq1RghEj8WxHwLEkVUk9uKsLqJDoYDx9bC4fmZPO5otq5PzTzDJNVfQ2h2k/IiNfR33EVjL90XhL4iLRzFsnJuEIahtc2GyOirbx1GYAMAAFRmt5G4y2zcvTHFjiE0ZLWWwwBPP+aKS7VGkFR4DsYaQg5EYw6DU6HUAsscJqFfan84j2hMfvQOMv+F/pabjgpL+9AvZ/svlJy2l3nS5un/0QEzggRHZn1sch2ogLp97Ps2jWU/VP09UI9ZkCBdCCNWwQt3RUGIAJccRMRdM85IMskYnoqCkc3ZV7qWUSBKBHhJk6uDNS6FIWqHi1JWqHJlx4BCuBDDRTNgDZ5ql7VBzs7IeDD2rcISeA2hXtsbNtMoPPLTf5XgY5t6zJ520pB/9/Le+e/ssHltj/664jP8++6Z7vd+w3MzsZm3r6xCIfmWuNQQRvWKdS/Ok/3O8eJyIKjtlkzPx6KgJRsGVd8v65Sy3G4ocyRsUYXJAahGqQDwuzfYMlHyI1qXkCBzDEAg5Aaxnfws79NDHPP3chAwgQIR9vWc9NMzXe7TfPvISTvYdkyBurKeOpq5EEDYLC2mCfoI//uwRHeABFNcVVMvMsqUC8rqYYZpVI2NX6wxL+plL6v1hKW8O/iDx55j+bPHwpJtx0yjMjwdLHk03aITJg4XBajyZwxYIEBmgwyeTJwysrqHuMjghxNglO32OZ/EmBwcBhaTcF4vu6jQLKOS/mEsUl1M2dUUUFGUnG5ovLv66omGLo6bRRbaSUumfmnfsXyzWP7T68CpILT5yycLKqSuVSOHALgDS0uwjn54N2ySRyUyFNGrWulNHj+umrJRfTGhdrETeJTbgbnyScHIGlXwgo4vKBJOb4mo7QbcgUc3Imkhtyp8SDLJwsF/UGmZqrmMajL+unf9EEEA4ozCr5YmqhgXntA4YgY4KESjrIFJ22As0YmkKy8JogweNkBsy2UJijXJL6p7oVoKD0EJ6ANubhSM46EY19t+5k3kQNSWlRyGyQjKwjFAXh4LI5/MN9Gt7u1bzZJZPt5mr3Xk3ybAvFZ78tRNVqCjnz6BpEqlDJXKE73djm2y2lHb7T5ZFyEmKqrqCGUVoOSo6gY4itPvkxSEOmVFy+2JKKiQ/WDRBBLYAT6jLXkc82mp5KYM7bdsr0RW9IoxHqLn4S+Oz92YbNqzZuEbSaZND/BtnLROXqks+ak3JB1FCiOrztfa9KvWIvmwqVNLv28v5MmRgy4ELyBFkZwIR/8x42aZ+Z2ERH3vGMr1VnzmzWBRWPlK1oqKt/6AtsBOxkgJ1ytIyMBPNe1qLdYgnMlHohApNTVWp1HjXUDA42QAc0lZSQx5hQJ0SGF2NVmKdYrULPxDc6zXJRxJHFvEDLw5F8Xf3dHHG38cvhW6a+/QKi20ouuDk+sy4bv/+7JEcIAECljYawkdyoOLKtphK30Q9XlfrDDLogova3WGFfwlzb544PzMWx/VXEMZ3du5tszHW9H3uioh1SqZvpAQUEgCN7kA06w5d9Kkq00XUQphJiNAZEBsDY1X0yJQHwHE4PnQhqOri9cGy6ri6AZwwBC0VkAvFRhjQRgYcY8fmDGNTz48ZctlM8AIM79v3dTqNOz5TJEimTakf+zq9d3f/f6t9+O8mW2XmVPrX7Pv9slj/G7x31Fnl3KiC2+NumkzQBuEk3ry1I2tq6lkCIJkgSWskQvKDgPYDvGaTdljpFMtVqwUdQjYQzhrthtXhmMzsHoodYO2or0R5AildkUI5UWO8k+nP0356LK78Kn8WWaVDB+2R12U6BXJtx9xEy2Zn5C7KmjvEhZDypKKGWuctp0JdVRHY1EWmyPaqM5TJ3ExQaAhpDpU6ENHqxa71ABAQAS7NYiYokRGCwHMOYOGHLcu2OlUPEzslOHZX3HcJJETyUbgdjkla9SIpdZgqU+5D7IhqjZPxqjNWWTpKFr+ubedlzirawsuLSOHLN7JHw4S/MCJG0UOzFDoccpgiH2RORDyFXMJPUcjFUk48zSm1neUrb8Pqs/ss8rWZqr2EHcPsjCQQCeIkPcc7v5JBGEVN9WjFgwuARBDMtDcwv24VLFryPJEmijBeac2pUlbFXLqXt6WeLXYpcyO7vJL6KLEfOOh0scfSjMEqcQvSlE5Np8BKELY+LlbNZWT5k7tjt+bX6fLbZxM/e6lVlbowt/UDY4mTUj31Lwb9Xt/RoFsmelBBTPi/kA4AA661t+Lr5JAZiRQPIvfEkuETl6XWnr/+7JkkIAEdl5V608r+HnHasph611RdXlXTTEN4fktaZ2mIiGhsNtrwuRqjQqle/4cK2OqU1Wh2gYIKV6q0pAdRcX2ZnJMNlzt5clVTN0y2gmDoWaGt4gOTakRIXD6qWBrXe9NJ8/RfdT8sO7ZNQoSP3HT9KPXZeV61u5Vv6uyZRRmcOtUvmJOJFBckcKsPVhDI+BU/zXIBCCcsklQmjZQRmwjA8IiCDgJBuMwPwKkoWlI5SO9NIoMU2dWeEkzWWTkMUEb0wzlJGnPc2oX1fyhepuKVe9MtlDLNqrJHSEFwkXc2PWrKi1VL/o6aiuKm2HxMNa/7y2tdQTXdXUa1FR6UN1iaXu/vX4juGX+dXUQTFgf46jeFREBKSFuqkDJwqdAIM58wLjn5C4ZMQaUXkUE1Eik4JE2FkEOuw/rDm5vfhkGB9QjImsKi01ksXJKKSRozIq/uM0jmbNUpEpUnkmOkdsPudThQ5dEsaS3VRN6o6ib8lr59Vu/u/mvRV/2OJl9+V8iS2Yi0erXBYlBiynzl5WzraU0xz+VvVCbA4Uj9MJDw1ERrj+SggwBS3SOckgQ1TxAxFgnrA0WaS+5XWSRDedtgV07K3liR9Fw5S3hs6StZiK7PnbWuSvJ5d/qqrdZhMcK1MPSTZzLo6CEbDhscY45Epv/kqJvz5za29FOZULqZV7syWNLLfcvWrdSOUkXEBYG2HaiEhTJ38Cdtsl8tMIQsMhR83t1RqEkhK1xomcLlF3iqCwGWVVmnIeH4UtlH6HFbxa0gbztcSrc2BjqDiCbmXWhizpOP4IHKB03fXfiZ0QAp1ykVGNPsgZ/It5LNfL/+7JkroAEkFpTu0s0+HEomqph520QyWlXTLEPIfke6A28rLhFfjL6HzJxzaJ1Bc+Pr+JqXHcktfT1jG+KGLI16vkezCoVqDTSnmZo4txdvQATGkkAg85kEMHfDPBgxYLFEEyQjBMWazdpQqsRJChZgBgMCEpAoSy+g8/PFgzJrG4mhyHRnNiQ7w2y0fqG420gR1nsx23uNjJ52jvNHe63vhoERkUMepUygaHNv3zH29bl1fCrp7n5iv1OHTzKs0gRhxLlBdaa+yjVKvGxf3IQAMkkkqN5nAKSMZmAqbPlEoOwsziCC0EhytIkMmDAEwoZbEjmuqG1nJJOUq6AXoYQ8DxzlcJgRWQ1RaiQRkGKKIGBFIss0O01SbDrgRqLGGSOMe/XyBapFgJTOKD06GnWgrfpDZRzX0afxK9MbZAijEh1Ws56w7hfm+BX+brha2qbIHV2IMD02HVAsJTrHhAbzPPI6n5LrAgk4yUqIingwgMCsgwDRiYKibd5W8ChioMBHBy0QaEBKTisZ07ul0G1JqRJnhIpHNsd0pVK7v0CAMk5SvF6xAh6uVVAGizl1dd+ze39O5e/VaFNsJJVWoZGmJzPntWn9eZ9W70FRVmwriv24Ck23MYUUGbg4jbTRCgy/rMYBhYCAIMDAsejl1N+kmIghxY7sR4bgXZXA/SVNzUYBAkaYMed9F0YMW0QuMTvUCHtxPbFBOfOMbtzL/yg7RgxLeveUWT2HEzf68f5RSlLNz82xkPLPU9/UU9K5ummXfK/sk7qVNf6nv6d3TD5/3L3ct1yUNXPM3DNhMqGj80iMj6y7CnXuVO/TpQWZkKFByz/+7Jk0gSEvl7Ru3lBcGvrCmdh5U9TRXdEbb0tCbgep8m8HXBSIqA2I9MLITHThZZfAue0h2UxB7qvxwQ9eNl6kFAqlYmDtRRrMTnV5pvqtjDYVw3HixklPlzF/sc+MD4oUV2Y2Ne/1SFhcZc61D0jqPR37FqI+6+mrPsZo2Ufzs7VmLa64rJBpbVOpgAgABZVjJwgFi5ibGb8xGtdRhI8EGgXEWRkVEnEjyamiNZccv0oaTZU1RbKEJntux19n0ao10lDjUiNWs2XVoHCbMB11NoOQ/jo0OmcuUyeq5Fxo8QNo3+0D8oRJv7mfsfo7RW46e10SzPot739FGxQyd5W6hD97e/mE4p9ESnvfq0p5e0qfsYZFWU7wDvWR9v2AAQAdbkcwjCggkYRqIWxoLQgHMHJBsvInUwOET0yx5ElUJwk1MVHGOd1FyvLyVRDl5i8gF3mjJMYESSjpAoK0HRIC0sVv7iUXXqMgYEbfy5+FY3syM3Ck5zum2icnbSQXdEhiCisnN7DbpGm3Obc10F3RA3CsynT2fh5v/nl1O5J6gh0DFKZFeb8lBGjbuc1iRWYXNFthyTFCSG7FHKcPDNTwGhH2ilJr63OFMjKEUQFQwrdlfavVoNed1a7Xbz3UUw5KveJVwU82YEJka58RGnUZ9fO5Xjd86xEniapncT1hSeBJFvH1JDG4IWnELZHjqA4u1GoUeT8hiOg1MzA46YanUmJvlb0vdtpyOLdX5FzbD3JMoU3lja8yX/S1DuW6Gb9eO2nH0/Suqo0/csvwqf8JAQLq076Y9JTMUch2TgUMysciBEhNHh+nSDQaurV7lMretv/+7JE84AEj1rPy3hCYqMsGkpp6UpW5Z1XrD2P6sAvqemXpj3tObRq64ERgFJOAlsRFwSoWsQEsxNeCCRApkz+soWq0eYh+SLrtxWpIITRAkkVLd+1uUl58Zhv5pZMxNwvrOJr1+LYxa03m8k6nPp8zZuyU1FRalR68kxM0KorTmQh5Ersvl1UXuBvIP6ncWhBduOwXVjI5swosZE6AnX2aASGhxiYJ1N43A2SFYIFS7DBiUj7jTprA+jNIlFyxCSwgiWPAbBw2dOhbIl1m5LrDjDUZmmd3vC9VQE1AbpJACEBAwQEYEmcKnYWDINbxZ5fCCjeqPHICyTVUkE+fyMcTnY3G66ZjgknpR90VAu2xWN/7UZezTM27StUmPTyzB06jpFqn2u9Sr6B6vgpdhQRaq/7HDt4eoUyvHNXR3YwQvG38bmwt/V8WWla871HFdyo6eW+MVtSAazch6OWGXLDaLAz2gYJSKpon3tibr0F4JkDORh+EmOgN9VrI3BSlpCClYBfsqcn6/PTMBamd7Ow+7rijWW/4Pe5p1PjftH/y6uqz0cEf02eZzKBAEarMpTVLVvpSv+fyI1PS679sxql7UytqzbtkvKwl45ydUFraQAhFWEAQEHFu6jp4H5/wYoAIhZAZcoOWxdmxap5nsqRNbF6Bnbfy/A8sgKLLNqT1MQFMG9yQUVLZhlmr7KL1zMfMjlxZiQqLvMmXcWFIucd5ZK7MOqCq8kHrtWJ8oRn4EIQf0qyqTHyMt0tN3lDPfZ9u2/1PscjqdXtqot6pvHyrH2WE/xCwi5w6oVvcqhYgCQhWZZBLGQjKTHtA15/lOnpCpD/+7JkzIAET1pS009C8GwrGt88wrYRvWlFLSE1iceu6bWWHeDo/XUznlDbUria1jwikezgzO3WEuR2aVbB0uvnuhIvT3Zecpv21ONzRoBpfRsxHQm7dMe2u3q1fqb2Rs5DlRl6VR3peju0j0Q+jF6Pm1PZKPKjdkjhNle88owx3FV2QAMKOxGWGBhJ5gqdADmTjiJxhwAIwUOScVwCEEDAUoBH7Y2TCo8BoXJxJTtEc+T0DbIkyS5hHFPV5XI7JkcpEz5gwPL1tf/dWsytaQ7asvDuGRzwXE69ob/8xOv64rWNFSqVyBE360GjxGux680VexrWTNcnhyOsl+ySBg7D4q4OpIc0LeUzWU6HQptziKfDj0Omhc3tmqyT+LR1U04s9fW0nQAC25SBGGqRlYuCkkVC4sMgKvYAbYHBjFVNFCysBj6eESTrc6yFxaWcsVLn+HldC4iE4neseLbLKKdt/rn69j+9f6SxStVpKBqPzBabjxlMuqcfX5FXLXIy+5F/I39nB/6QhcE3MvIi1U8zbKOX0jjTnV9jWHC0O7jCukXiRpYfVaAAEYgm5bWnTAAA0CXJOwoPakEIdfgNFDANf7qF32NqhYe2Di74chllzOoIkVLlB6tL1Ul+igXF3HzxB9BI3+KMeaFj00phaqkT1qxEMNWJGzdtLvq3y+ojqkziJOSZOrl2Hi9NoYY0EVw42KYb8pFebyFSx3KRrtUu3xrWufAlHfEHNPDSPZ6pEpZGGKDw7oYpM4xLuBGnKZ8L8gdgILQTOWGsm5Zm1NCIOBjZERL9O25pmQIKEoAlQpeMABwVLtQtnEvR2cyR1KBpD0X/+7Jk+QDFEV5PE2xFsINLmgNtg4wTdXtFrSUXChYu50mkDtgdl65BqlnbjEsOE084xvLUkeqtDFmGw1wYLBYiGleHItVBV2CgHYgIS4wM8MUhieNy/4vLI2C0EXv2UGJmkzVDbuG//je4XtDX+lqMMOoRdhj5Bz6FMsig0qsTDpIOiK499ZzHiTQFmFUyAguaHE5MsdiAg9BDBtgDwK4QXsL8GoOTGmQexhqbIraC4lgn87jrgRCNGHQRwHgJ9SNGNBN4QWTWcAeqJuCfGhzqR2u2KyS48tHfVeYe1IyjiTBC5kJyc5Vk6jrUpb1GnmaMVZu1C501L5V+tKxMEfVU1q7zBZYdlhc9P/W2kqFVZDW9PV37V52HLrawnPO7Vb1UNXfMRgsJyy7yEr1+v6gKUcwYkPoDzJqQabiEtAIwYWEEIsCAkrAmSmQAC+yEDa6JDMADxXLVuosNosE3sM1ppzmYXJx4ZNqUd0SprC24i6VVdjLy4IZoHCna3IDRNdKkcpMyCd6M7VRNdVKJv8zYQizagSrLVisrlY7+Z+RaIbU7XcuYzrtLMMUMPE4JFn36QmTDqcjLTITbANOP5Qz4UhQHCyoMLlszSJljiRrAAjMVgsmCqeT0gIQhAba6LEAHCJAjBzI3VSrBwRep8mvw4lnS1H6vjUYOmDeIlFoUxjZOtvazblLoZ8oR1xnoQr7eyz/1aaqqYEntk8TW7jh7qQxXboaxIiXXYpX0idXXecQKTakX4Ebi3Ao/+7kIB6Y7E/RTd+z+hWctaf+SG+CE8g5FE1OP2UZn1/+bsSxoQJKkZWbHRvJtpeZuxGbqgGJjmBD/+7Jk/Q5FrlnLg5liUIKLOcJtArYVrY0uLjDXEgEe5pm8oLhKYcwjYqIJmCoDIkJwcmj2DihoVKxPlU7K4Qz6VUyxXqdTphpACRg0hypDnlrYYLZIsIFUrtXxU8DlOZ6po2GHDonqVtUqz78X+HIHXjIbVOsfUWleowgQuJkQq0IHB7nuJd7VryDUlJdcP9YAQGMLAo04RjECkNaFU2BVTAAuMdAIxKQjsGA/6vAeCCCCoSLRuMu4tCAvggJJABKgwuYdiBVtkQkbX7Uchi3aWKT9j0O5FUwLDriUbnl1R9H6dO6vTKXSxA4iHE31EPjkh1oKBk7hhW/owT5ZUeVXydb+bn/SbuznTzx/TVi+49RH7dfnne9nbf5u4UNjXzG067iYzrbTNy7lQAsefA91WdAgAEAQTAhxOGmoy4DTLpcMVG8wEQQ5NGJBSaJphgvmA4THEdxFEFFLlFzCINkDT1iIEYbePKZmWHtWf50J/VNOXSKMUJHFSu7o6sg6ppNEVlOoWQ6qFNorSj0w6jVkmP/OhXs67F18yoJs9HnUwt9iChSdPuvR8t+Ro4JO7CY5nL1EjWk53IAFAMa+NYNfgC9pnP2EJdIj6YjJIFLA8eljnqwDLjLgMoBkruGiYJeCEoMTIowoLAcXgkhLYowtPnMrFxwHT1UXTldHfREEGo8oS2yHRAPrsr2H0JxE7yltXoFyPaLG5rfDtbq8hM20v06VxwP7zbmXmjs831JnKPTusTJzT8fURy5PZDZj8LiLZnHZrBfpbr0tXtNstlrJvlOcR/m8vxo+6Wyw/9ElYJ2C8aDSgzHVv//94QAZBsxIDPX/+7Jk8YwFDFvMk5lZ8IcLyZlzJT4WXX0uLmWJUfIvZpmzCtAQjSz80cLMyRA49Ax4OFCaqnlqAI+QlAACTnQJIcDAAFA5KNC5VeIqFxitTLobHLaz1UfxOdxPojJPJnzFNkg+azGwteJesMQoybLuLecE9HB8rbtranp6v+EB7cMS9vX0LKuir9yLQGqHTFoc77hGUt5BidMAQgEAKOgRhwwdGNiC6JqUw35JCMvIDnRRUwUOf8FEqqxCLiQDceJcwKDUzBoDRIXTPRicTdU4aPelg9hh5La+BCL9oVqEmxt/+qeW+fy/s445jjSA2JKsnc0euON3NlygiRbuy2baIPevrwtLJ2MuD972fbE6bDWZ6P38a+vaP+4h3e7/bfdxl3+9mx7fWj1lHAkZZENGQemyjoAjlvY6QRg6sbtFm0V5t7eYmmmAFhuljR4UIC4kdNR1KlwW5JmtKG2mOvMuN6oKWdD8efqfdmnkgyzxIhGNPgUeU3OeTxCFT+T3fqk0Gi7hPHv8UNGjTxtzZCJNopd7p9pTjFb9Je1gPFMMkXEdBd7M+ZhCB1c93ogwhYLLF7IyAaGTJbnSepoyT49JLF7I0PqMsOATAglBpJxpINJDCVoeGTKpQwUQYMBQQcCFBWuGTjyVZdFQrUiUtV+3FkysbXIVI7S+Ze+Nq9E52vFMtRQvw7iVAi/JhAuvBM/8WuPpGnQniRQ5olNOzqh6FtONxP8t5x6hmgnK4YXMt/eF/zPnCEOURvZ05E1AbIm4belJ7nArplekj4Skp3Q79uOR0j4KTOiJKxEobXbxDHcjWvM8Wj9EKN4dqvZ2tOeEhcH/+7Jk7QAE/11N42w1Qo6rKZFvKC5avZ89TZn2gzw0abWDPeyqYHQhb9oNNGIssYk5WOBMQY7a2sbsyG7Q7yugubY35+MNcbfjwtZbIe1ASzRmJ22WOePEd0wlNyASxzYwQNTnYC1IwqTRZTI5e8bSpCVERWoIUExrGzQhVFTw9SxDn5d2vdVLuk7yer9R4ymSME1dt7YzyVkhsjEqC4GYeDqMTxQq/FI8BGG8crlAb1HhiXJ/o5YjKlxuzvlBSqKPVzfzRTcWbKxkPClEW/Z0g0OcRygMrg/YIq3LAjo9t3DLfPVtQ8vbhSoJs84qpPxZgn8QUxobYxDkBOKlXE8OscDUqEwoI6Hl0Xjweo1XtNIh0UgQ5807JHiwMxMqEgADsECJRo2JAjYwo83uUKhm0EZwaVCCyXVTDRecSrdn3CduiYIHF3TsOVBdNoCSyxAYRbV++trTjmDTaWVQXm33/FkdZ9Geyn+Hsq9s6cLpB0QGK1WF9ZnspvcMv+UNBO8hbg7YzmlZQ3qXjVdEcCVTYVVuQsgVQHJ9OsWnLwPR1OrL+Y+m3vt0J81n6zS2PrFEKAEGOIZq/RmiKHS6cR2mO37MT7BVJIkLNp1qcRdgFHQkSl8R6LB2kwYUBp6hpMlqNU1EOeoBXQYet1fg6KmsOaOc3hojq+Gevj/S/QsWuXmeim8XDYiwR8nUZByF//Vb8036+/86zM8f9xPf3Xs3BM1qMns1+KYRrGf5c2zDg9skSIa8E1ji5VXH/fJVgDBNBC2lkAMsoYIYqYjmcCzLxZEuoobAvEioZQvWijIJ+MGyKSyo4dQlVVRHgSPtj+e/J1b/+7JkqoAFQ2LQS1hhUHfMCo1h6BwSOYtHrLENgdItaPWVjfmXU5ovsuYvzJxZRMxdwULfmixIfGLjD7uSA9YVlR17ktGINWx8eggtYzmpUp/GDf04PWtavYWS+x8/d8nMfpN8P8R3DlXlvFRaGSGA9HyDth6O1kZxJ9NHcoccLSoAZkQI7YBAC2JwgwQQjLhixjhMSiDfPaspsgYOx2QNgbraR01ksb2WTeJTOySPpjMXD623a6szSFO+P9h35RLK+b/7k6he0jiBGdOfrGNdSz1/Qz8Htab66cpnln3coF+SF6Lz2skKkvwEQpRIsgSL5QdGflUQXUgAAShwwxKaM6GPGrAykiFjIBYoKVxoKA0aE3UgrGm4uHGm9aJH5NHb7KYy9EH0CwFPVZjG9UiWO3ZTIHEBtdONnUU1XtfXVj8pkq1kNQ9r+W/5XKstIgm+KvtJNW81wU6cU9TJjaDzh5Vm1mApVD7aiVW8eJTIH09FwJvLGNjeDnZR8Eh6c4gmjNkplGAudnMTiXtYFt1/S5SLjTjJABKUb6p1+oWRVSoMNUTXmwefuOk8OMhpkLrM1Ty6q9se7dpeEkqOW17uZ2qB+pFz0tMc8qOHIxYcgCDovqFX4bqi0FNQ7t6Cnd5j8x4IG3fq9fMVplfuyI77PQxqb0UrKyaiZF+sNKQpGiiWCGJtBAggHBAAd4DASXRKDHCIdCviMMkISCGuNqYFfDKRGSCmHNJcupDjOvIck+0Sl8woR6PqxkbHdKRNqZ9OpVKWLCpmVxTfYRyW0hhXU1bMS936/sqY/q/qJtDiJROFR39ZZSVwQ6sQ7Xur9zjK057/+7JkvogE1V5PM0xFsGzq2iplApoTIXk87T0tQaUhZ5mkCjF6Zl7YQykpv9xW8JVvp79Th9nhNdirqPQBYm3V12fZ4OEq3LBAUwAgkudMoZAKICoQBa+RAtNIbpWetYYvY/U+xtjEVpIPnVeT5CEQLkQPIrSnH5crC7qsjeW+p9uuThB2cZeyLawF2MlDVNK2C2cm7fmM8mOpzbIZ4avvPVcmv/9NpOqH/C70yi4t+2kDFAFIo2jDGiNA8doCfj9SQTOMMBAxgeWjoWDbYGkszi0rZUuiceddSjtjP2y5PVIKkO92+j57ITshUWVCpSYDtOa8b+6/5VvnUE3KHxSn9Zx9U1Oxgq1tilm7tN3tuG1KHoqEzLT8OIu0L4LpFeie8dZ2xa68RBM1jG/b45qViPWvpeRURCG6Hpk/40z0doEBwREHJTxGDRozKFzHgRQGHFFZFAmovbKHrdtPB5oZKDKMqh8bsG9LnMJ1Fe6GJdZVUqUFEFg2CDv/bcyBh9F0c+h07dTlo7LTWun/mORGYOiOdkIpaJPQfonXp1zW/RzJQVjCADTSJUMfFg8XHXY5c/O0DTGy1SkOOjJ0AxAApQKaAY3MiC0jIOnSgsAxDH1YggJRtlb6QUoaUC7dlaZ0yXOg5EKlsvF1jp1iL4+2lbR6QETOt7UrTWZjgpt5AgxUNoPbwfl45+7d4GgyEGO2seCUijL5XkdtxCq9wQfV8MWijEncmxveQkJbDt5gcWqTU/+pC2gTax2tPcdaRyVldQ8wxYffrKF0A8SzLHghjc7Dj97zxzzn+jfZtndCaUjBYw2xZNIlwE4BckMMBDIwt3j/+7Jk4QCEeV5PUylFwGRLOcZpgnRXPYsw7b11ChQj5gm8IPhj4aF50GzJcxJVvX4h0QFtOVPLHUT8U/XpoZZxPwmlgm/cp53Q1R7QNhbEBRHskWHD7ju7pWrlKcNvUSdb4sOc8xoOLMtssKbNfHzdl7bJXlS2mtEiRr4aHHMjDR/zNIULOVWp5Ym1CpdblBMVG4C61SUUUTDKlkx8sMBJDZ0kPHiQdAQOYMFhBQBmRKwKE4JAzAS4ODaVYAGBoDLEBxZwFkGBFJFMS0UuK3EkLgnUrFIWcRJNIvGSJg44S0YGCB48YHS4taTnaJsfafOmqQ6zU1NlnUklx6ME0xcSmUgjdjEpIHTa0xI0uKLpsezI2TegXUWNDl59NM+ybGRujZRs9SLWPHmqdql2WhnVLaU0EErrQQJskifOGhuy1Fs+byyXH0Xz4y214sEHuWNlulqxc8OSMJIWHZ4IgIJgCXUzoJ6s6a9S1l/MkhD4UDmFDo/lKyZBw8ezvS9PlVI5plsctUdVXFtSZdbl6IjJ4q/g3re660bjm54d/pX73/f/Nfb/k3run8JvOab/fFS8/Ffx8OdXXyvs2OvljsyTpmde1jStYAACBQCAsX4uEgaDYJBglZpBQ3OOyGN4EKoIA0hZKZccYIUcJEYMWasSFgxmhjdzQiw6Sc56GTBjADMwgMYHAQaC6qqKlTzIJzYQUinsv9wm6wVC24qVInoOmaa0Ne82WycBLpNBOqOo7MSNlk33widFNu1t9GHP5LYJp3QSmgOA2yrUSILkLUaWYJsgktuXxN9bL9VXTluUswBz5uFK2o5gIxTR1JVNXIEmqOX/+7Jk7wAFs2JMnW4gAHsLShqsrAElgiE3uayABHJEJrc3QAC0k/yzymwr5yyef+N5qwLTYO1tXcLvdyc+audn7t3+UuLUt3bFXVPeaAietddFL2HVzwOAi1Y7Fe7rHtrv87//+NWc196zj/9//+0y903Xch+LjEH4479acuWP/////////////////////////////////////OX6w+vbz/ljYAADJwFYbHw8DYbDYIAELhKVM6vQVNGLj5oA4RIKUQEFQ4PNMBjJw8BG8fMYAAqMBxcYYBAbDGCjYLmxyAMUWEehbkN9GiO4cBJBdWBuDAeqOSgTJKjkEPLhZFLiUQMCBFuDkRlygQIb5PlczNxnAM+jA06UA5eFwYpw/GgnIhCSG6SDkNPkXOiAANwA20FKBjcDCkyuThgkapKNibNjREm0wBk4GkIBkULKwMcCC4AUoaJGR66EvnDFGmbrKJuOeRcnw3wNnDpxC4YrFvWkVU5idNlJIInS6Wzc46L4kgWvhjMOULp8c0NXj2BiQYYzRam9NX/QW2r+kLLFbilxOg5h4PkHAwuMpE4ZGn////////+mQdI0l83N3Y0WpHh9vKyXJYLCYMBiWlKiM0tyGTJEZIDiIgjgrgapCawKOin3C6AFATGAWTvqMlx0qPrjq9etS5QUHxTFfdNVq9JBOLtkYXGMoGxYymleC7EIdEYU12BPHA1WB3JlkW7FnAmpU7qwmEYbi+9BPZdm6elwlkCyh22GIhvG6kNx6BIds08C2q9iXyi1OUWNS7avOjAcSomsUnNUuWesO6k1u7lc7ZrWmovllFau7LWIk90ERS3/+7JkWYAHZ2RX7msAAMpsSw3NPABSVZNdnYWACiwsK3uwsAD2xO58pquGONXlmr+71jWcqcpfkxlDL7tIby3HLkbiFLOUn8yqSb8crV7u91IzO3e1ZV37uICK//4toLlJmC0WiiGBAUCSpIOuTO1gqfMSiT1YiOlQcAOImAKWEukQiEkQSCgtdQQGAvl3XZM2x+vhel/FdJMxK06pX4gCGGkS85VexOasVjAhNzqTU51QVHPeI9e3mUpkHWwIFUvVTI1MsGDZh9dEEJyTVNIS5uk9H1PeLI7ve9o1ocaI19gY5KP7Xg/OYr6HFtB3G9e36pD+s5dvJMxYsHzZxbMkKZ5H1TEL4o7gMLuG3w3c2IUCs8NHH7Ath7uCuoUHddQM73rOIqoFXvlF2FIIgA6NB/UjMn+GELpO0gUjbRPOrcka8ThymGYLJxSSBRMD6Q2i49cEwwpYhmnFNEhdJ5Kdkwn0kibnXJKmTLtJLay2vNzroSqmrHj8IQnGTG+w6e5TuZz39dwkseil/lNfqEGaFL8uhabbXbLvP8aTZ3qnKjruWN6YaMk9Pn2n3SSz1vm/QWXvrqeY5PydHwACBqIAAAAFfMO2UiXU5c2H07ULTvLDuxir5xIanmHg7CI/mpw4Pp2qYXpPTWeskmUU2SFLWWUtMoskNpM5TaNDV9rkOgs8dh6eiYXXrOqDRW+kH0xAyuT5Z9o30yrVy9k2cj7p8vd7oWfvubbDd8P4Q775v69iC3ze9A4/eRDjEwjOre0ijWLIVDPMqxxAIAAygyWxYEi0j1GnuS8YCpOlZynpBrSmrVodwhbNji2KGEcZKtnCoxD/+7JEFoAEqGHXYwkzwpbLytthJo5RrWNdjCTOgh0r67D0mdBS4pdppURSisxpWh4JiDiRoUECC0MuEU2A3U3L5DWMBMTrULXUgaNDuQ2beljkaNxalwT1bbeLkebuzeoF5jOa3Qmf8snBaFj/1oEiFqsgjpm9CZaIOIioOLK9Z708pNt+Wnmiz9SkV4UjG0AALLygj7hGkenzeREJcTvr+a+sSaU3eagc3laBadAjkoS1JJeK7yQ4mlO2XHEwkiPoi02pMQmsKGxSuoYOkRmDbcm3oNVlFaRI0qjCiB0UnTYSnNqO0+Hkw0gkQtLjyRBwsKVnXTmh4i8XmiYDTJH/Tcg2T+58UouS3Qx2kkj735nwzTZOgvTrvL1cFE2lH8+7PWq5rrETCAAookTWZJ1DDWnqwp+M7bx9VzIRtZbxy26uEgWUB8KuwuNztagsm1mKvkZQQciRJnatAUgFolmgr8o8oxTkDltJDnLvsL5L5Cy0myTyDEzPRSMcISsu8qvOuiGSoFA7xc6XqdbCRRZBK1omb5nZkrdzH7Mt9Sfs/bH3vNnJKhILg7OiIHbY7vY1JKoAcAAAXA5yAi/ElfEuAdga6HHccI/n+ScJ80siqNhmU2xlKUFhxCUhEtgL0+6J2DHRPIR2cSNYtASXqzypPhFNzl5eCyiJmGXv+kmQJEPlgt78k8jS8o3YWR03icd0ozzSXSXRBNtumXNN5Odd4t+k8Vt+iq/mY+5JfUNAYopbQ9UeUz0KZUhFVUM5AANN5HuICRhVTBG5p6oHO8kxBguT0QBjMKNfNpzK2gccFLQKJHpkJjE4bonCSKe3Z0TVIHn/+7BEHYAEZmBXcw8yMIeLquw8w7oRTUdWjCTRihymay2HpDGFGr2qSP3MtdMRtBAydcpOLKQIVU1rXb+DMy0Wt7N/N/2tKXWFXnJHGZ3ObJLRjN11dPUnbP4tqd1N/ueLRf6zoxF2RI4ilseUcuIlQ4gMoEW5tyXWNaAASjFqPcRsYxClAVYQ5DycDhHKSlwMU0U03sBuNsdgZXBi1BxGZlueaLU/+MHIpIzNejKFQjBnk4kWcVk4IosxlRfbUlOnuloLyEfDHa5d89F1ZpTdGnzcPQYoeCcOAoMcWLAwOCiazTFjZ2u0sCLO0o+vonuS0MORKRYQUFyZrSuHq1JEoC3MXE75WEVXJGkN6ypTWjfN65fSwdjAvIaeHAgQOMA8ylMTLS8NX0tDaD8WbF9WtZWpMpxnJ0qgqjUVXIkzk11kJypohtHIriSMBPuE0tLlEiYWEqkJRQ1TEnLRbNpsh62y3c84uXNHHpN0XRjXOtJ8NVm1lyQOfNXRrbtkYqhnAmIU+p//Lm8zWyYBChQhA0bDJghKV4QgvFTYDeUKUQWDESKhZS29QkT7mGj8UUE1qKeNo2a5j2ZivRC0tcnzhW3CDEmF9YpJCurFZ1NpEJIRUhpK3kXyJKwnMSyWXMrY30UElahsKjefdWazJyjGTpPjS9szZtaGPzGk+9xGCnr5phInLQSVS1KzSZ1nbtD5K2VKAFhUAfAhJKgGSOTcrBADuVg2Q0WFVn042WKnR0y6pjC7UF2ZVBaaeXlImptxSpeWIGU2BorCeCxpxzHXgU7KCcxARxIgUwpgwEGtEhnNdAoVW5uNwTVE/kmXBdIJkf/7skQxgAQaV9bh6RvSfUu63DzDjlCBd12npG7KC6zr9YSOOBlsSaEYkUEfZTMWtIo9PiLDOTtFOBRT3lZev0KelZf/YjLpIVKgDkCH7BHoChSuibBMoxCyxA5YLKbbe9q3TnSEyw4wkgafE7S0qgvSyNOgXHQakIMULSow+5QN+XGnxMSe2OFUyDQvBzqY5M3yhaRVxQUrE6PINKv8TNQTM4R2fLIypvEenv9fyVYbgnl8oZgnY4xFxvIVB27Y69PNE7b63ESCSqJOBovAnAc5ttQyAIZxspQBfF+Xkifhci4mUCZiGGURvuE5CTFidAuDULVcCVRIKhIDwYNx3IEDJhGdtMmJB6aHdXATAiPFAmdhKlKRKzHWHMOs1R9KSkTlllAdpBCLM14GVeTOoVIsmpHuXf/BjgwQkjNeNjCVW5X35bnd7pvrZEiEk6/KJax1hBCN/0N1Spnt140lNJnTtvFLm+wiN1+ySKwpbaSXJ1FWBeDVRVyWLSSegi+24sKZSfpvLb3YVfq9p9Z9zW5mOw1tZFqrbZgvuUWsdERwz4PSpmZEp+GOAdIxC5zG6xN/kRSfUVyuxc886qixRB4CioqGSq2+SVWxNzWJMkgAKIoDw0ZwUIFEXa/qiiZ8M0zcHle1YItk4ii5YWh9NVLLhwfM/yt5LfN7H91P3e27SsNmGPbcWVTOw8sgtAO9QzYSlCCqqmzTK1q3SdY7ox8BWziNfj1D2PNpyEvOIsWfEqkrvmVOIbkaK2moUlEwHSV3FQSzPE/3EtiSju8pn2kpABHIsCtUV4AsIAEGXAibovI5xX7FSfRgP1qO8eqiR94KXv/7skRVAAQdW9ZrDBtygOvKvDzDqk/tXVeMJG7KC62rNYSN6dEotky9p+tndFHDphyoQp5DM0HvWtTIoTGMdiRzJfT4r+oY4rUmSwtgrUMAyQPHZmzX25TBGudsBTFMS5Kcz7TUj6ZMb2lwqp2mQQwYlgkyhJiIC4N1+80WUk0OWtaLAA2QFQRJyjaU2XkV+pQpKBn2THVWUpjDzS1rrCA6Hxj40gmqVUO05rKGsBOHEbZjCAohkOQBobNQNYQX2BmTlDoMQqEdb9oCYcaXXHpue5kIMohjBizUIagYvNRzYR3IjXPZ8fpspZdpIzXI1TKgpCjXIFvk2Evt/m+rs7I7WyiASXAE0oqssZmITrhbAqdKN17LCFzSnjqxtrIJAugA9kGZnCVSY2GEnryrv3W4krMrVke8mG0PUhMQUyBD6GUqELekbkLciuG4cZgoAs4FJYp2oZRDPJw05ZXg+R9V7dmNeVxnO6jCYx32GAnQyOGO2+1IYXmFu6g6y/9fd22k7uSERoAgqJ0E1JpYqFrcUBjD1NleyljbPW7UA/vhGPsAa0PY9cvt2kp4gsHTpj5UTv8e9t77Av9lFFsU0lFMZlUDoO8NYpIYkCCs6ig9VTKWkkxbExGfTdtCXNcn4ja5k7hi5EUIVj+C0C03M2+jO7QzSbFwzIkusbczTQx5ShhEwiMz+NoNEEAuIEHxdEQnV48qo1UVME9nYTTaC5WxaYTHExGJAjeob9sFQShNASKYxO91NNiM+eyJmMkMOcMdylV4AOmLEAbUIBgRU44R9ribyncc6MRkVxCmiwUpHvTDiImpHk/7WFobAwCwMsJijf/7skR5AAQaYNXrDBtghAwavWEjbBAdg1esJG+CCizqsYMWOANh5Qf3M2YeOdhKeaE3DzHlDpCTiPs2e5kyJAEqCRiQ8QSvQDQhnbZULH0aWmIn3TO4zuRspbEVC4s1bVwXxcUI7czNVGWfaiJ+WFl8nBHXtEdhckJ87RZuvoaUqxuRoYK0zeEKdWIksBDGpb1DZ4wLBevh8jKNlnGLsKWuyuzYMqxMv26UiuZmCjhN56oiRkI9gcOu9eR7ekK5QBwaEu1Nk00g4wVTIoqto5YwlFJrrJXUirsy2DXrtBh+gwMCEIPJBGuNeiSXKOchhpk0zhctpkp+yrOkU0ZBX3IxGk8e9qHUdr+nOQaXRBjMdUew97GK3Q7HXVGRrzZDMVqmRhAWKlblPYkxkO2TdnAQ6CjAgOBMJidQmZ9CcPntTNIAOK6Q4JMM8BdqLwBOAsqAWQuQjpL0WpmYsE/YmJQzeIxxPqK+V3cKxNzMLi9vBl+p5dY3S+c1riXLl7QMz0EKJKCxEVWHBBMoKae0h1OIkCM6EWPG3yhWrHJfn6HeGRTKxziHR2qwSdojtMqTD78yU59B6x6zvqiwCM3RehORNsyiAQXIEAsyMAKpisIyBAWxPmaO2+jFgWXxKOR6WjkSV+9juknHWFUSRwlRvDGk1LwpVsRmLewrUTD02Jknc5uSfjR6IgZ67Uv9lOz5kt8ubUu93o+39ZjHRc1fzDHnWhruyv5a2dtjMeZXrtuT8p8mX3uGTaGDtyqyGdBgG2xekR6dpIoATSi1mmDICqrcyoQMglpOxLASCYT6PcznWGtVMAZKhZAJbAo4ukyp8Qzmaf/7skSbAAQMXlVh4zdAg0vKnD2GaBBdZ1GMPMcB/S3qsYSN+bpR6b8sDg0gb0L0nUJQEN7u+nSu7ae1zrFnzlmSpszN023+VFG8vJh3j+mUR7U2fNxJmVjvjt222bZ+bTzsdtr9n/1/jUGs6yzg4PLMCNcxbGpK2W5vkUX9vWsiREA199GS0C/clKGENYkkfkTtjBCGAOLLxJwQDmNkySkKU2UnLwV1l2NvrbVPyhGvHLv1jGEkrMZFfMtSaRuNaHNsghjwlywbpeuq3a9PIvYBlQhtjXhJtCM4Cg3xWaNPI4jei11esSiKJJ1Kgg/qCrtteGP72Nt1cSaJBKi3RIKegqIqpsT7GldM+gZSl2lyPieDUgssqC4FFHDQZNziWsXjKygligKSKBVukdAB9w/jNi6t6fVNWIS5+WZUW/2/k9o/xT1ZS9rdZtrvrJY108tGtk47ZW8vP9yv+jj7ys2mn21M096xt84ezhNIwlTZ2JHQquqpNaXhY6ywyABN0TXQHtLCg37JoWQlk87OMOUqnjW2LStvVPDqIAYpNmJGl7bDnYi5umo8xNJ1Uakx247/kJS5ZAWqpo01Rj0xu7i4POY6azDnhscpaLJU+deHVBLaa435T95Z9rsTyPE+vCnbd+3WUe/3sbsap/3wx3CekkkcdUJi1GtuFkYVGER0KlAbQsIsGGGCBARZiBHBtq0lQtgnBOYBiVPJzN9FlOKh2AqIW7JQuhhqQkQY9ZWWrl6tGl8x/euypCCjSyy+uMWS5I5DnuVCRThNaIMJaJRbsrbfUJOtV/ziRR39TsUYqbd3EwxKlnzphpH6DSSFSBkEjf/7skS/AAQWXNVrDDMQg0tKfGHmKhA1cU/HpHFCBK0p+PGbMUai7cQeFVGrm0IZOsIiCPIAuEtJED5AhgojzdGyH1BHCTQLxEs5rOSei9FMSiibjP40lYMVRuMR0z5pI4Y2zxQoEGDRhUxgwVKYAKqi0QhlLZhwQyLdgjQiwcMRQ7Ou3no7ZUicqZeFoM9MxZGyi4/UkZo1G1EEuXkVY6foRETdZ6pmrA/EBSCT/111CnqGZDkaKbmEgRYRVEw50OcPAYgLhlriYhcSI4hHBwrE4xOJg/cT4ljrTv0oAzSTRGQ0m9AEJqoFpJlC/uKr6KtIevO3UXjH4ssWgyimZWFHZRQ7YdVFIdmbioSDswCo3WrFzizqCnpn0GujdSLuOdBgi8add0qcjsZVoosaEQGZjuZ1oIo7cYkexFddwu0tZTIAIMdEOcWoNLHOe1xk+SZUAyNjxBJICAalkEiIJYRpCYvZPDpDa1zXL5CYxXl0+vDp4sWztmESTQljTAB53YjnbuRV9+q+jfkGN6I8zugsvIulfjEUI6cWzh/P75cLy5/+uf/6CcnBjHVLgoxjdN0Z2VRCcJAAAAEKEJmjLYIIM6RWpZqPwNFqy4u4slmEPTLdm2gSYmq87YuP42WL85EUGHUJZDMKAH3WIqxtGGn2CwNSwnNAuyWFBN7Lrn0yRt8KNbGNgUcQttCJ6sCz+gWawPA8vnGxaUlDJvIvRNemVcSuXSnseWVj+ynKkd5aVMfFW4KlyUc8EA9drwr6A1KADmYl7R0ptQHyh0q9CYXsbAAABsA4CtwdoFBftpCG5hwC1QMhPLKxp+G2n3yf1sdJiP/7smTiAARtYNV7KSzAduvKfWGDXBNdZ0OMpHXCICuosYMOOAThpeaWWjKbMpd255EUbfKFK1EoqTbHCtAZJRRFtHDh3je9XTUN0iWCuEYRZGpLEpxJ5BXqBxA4GIJkkSiWNc+qKNkepRJlFJtTbihxnNznCMeoZHqX086ISEwoBJIso7TRsaqgQEggACOCmWCXtORo+R5WXJS8IlndpEh1A0+mK4QGp+DY9A2bjzvYeZpGqWDXlHul0EjG7JCLijiedjujqSgJubpFhqeCSXtLhyTX5PQrVXeYHfk6xSb3IIkkXjs+NlUlpO5C8XkvtxNH2KSLM3Fi7MwsqdQodmlWf0lKjjsP95IzPS/3TSNfTIFeCmbtCH7zbpFjtYx8+sR7sV5h8aTt8wp9ZW/7l3AFGwSAAAYQtASX8QxTeeRZKP6ly/31QkqVLil7V6k7A8TpHiEsZNMxkgoiURIDFGXRgRMxQ+SMwpbLJlEg7lkZKT7iy8In/N2I06gnLVUS2jUF6xZ2JuQwZUTMrWUgbGQCpOKMY6RZV5oPkFICMjkhKVh3Q5CBssUHFw1OC7g4HwOgXEIQPC/9UACADhttlpGaEBqAmE3CQqPBnfn21QtVvl0BNxSEZtUwaydaPXJpjjM9tXybw4q/DbHKAoiev8l3YUCttcJyUMp7Ie06bmIoaLpFjIbopvssedQqxcT6hC/fY0wofVSpE+at9WFkqpikbsyM+4baFimjBi/13m1OSgjP3mVMdU7pNYZKS6LhLdnh5PKSh0tWFpTaBs/h2C7HZxxS/WyUKJrda++RH85Eo+PZheb/fwF8ShpMIBLQSyVWCv/7smT1gyU7Xs/bLDVyiQnKHGEjjhYpYTsNPZHJ+KUoZYSZsJSwl+lGExHAnJppVLdZWJlBMjKjgMEuTxgwnCKiFYiIiF9J5qsrzT9rtvGejkoWJLCVWqGNaKc6kEQU7EwNwQzIRJZKL9HIKUfumaRieVM2XWbNNk0hbbt+Em9Y2tr5s9/rSomEQkwgfXKCI24yHgKGyHfRpkBxAAAAiyiUKlAEZOEZDR8CEVDohW2RXZcxdFSlhplM7tU8jcZzrjug8JS02fKtEM1Krza4fidUpnMCOpyMy1C60jq6pIB/kYlzhS9yh2ipeyiHLFVaXl8ArMl8Cw66boiTVIkUJPVtL6HUS7dQhOv6p1i+Nqd0xQbQVMnkECENZr8uCXkQrWJJT3Kn98zuJfnO3eW3U1f4OD7Byo7sn3PK9qmhv0YhxqABQACJrkCkjwdJDg/7BUfHRWHcRiqwTIFzoiMzYdoIGJITtHEGOImgEkUAr68IUBukidhinkVxruJtc0sgk5mtqKr1Oc6EyZusn3OhDKbTpncmslsTwp0rfDTwtKLM5cBBMoYjFEDt113YWYH0JFD4RZGuqsCSBAAGNu/PHdMHIAWkzBlAg3AvyW+JibL2Mo1WWn3o+77+0L4MNAR6ZoAhfEa4rwgIyc3a574hNDVUTCZvBDJjka+vvUCnX1/TYI4QJjTNMoW+sDUNqpztQoY9L+eOvucv0wiVuyTdnrMLvegDfsrMvTf/q86fzg738Sb6hb1UP21kIo93NPAcSbn+xn5TxdhfSoEBQCCGAATE19nFKAzUSMBA0BgYVmOCDJC1iiSgqNbY1zMF7GGxRhx2eP/7smTtAAUtYU9LLDTydydKHGMGDBKZeUMtJNHCQ6qn0bSaMUxlk4PD0Obm0fsgv5FR8rFwrRCyieg1c+OL1j7rFDM3kwKWTFSzDE2CSEYFpowg9aR5QODiTOkExsCKpgj36IVlk6KzCBtkDU1Zmv9Qq8LT8Oh3eJbC6+tEVHyb8fk0/LkMPAD/hn6/lWWAVGjKANmkK5/IiHCNgwSRezxKVKyL3aA+7LFysXiRVGwJ+5S8MdKjrA+jhKykoLoPtJZ7OEMnpkq+ChZ0Z2t7CrlLnpI+yrmrQOsho8RLGRqLuv4P2w5d98SwzrfER0u30D3LkT8GyfwWJnKancvNS6mMO8pmfbzFa0Z9RJY7oE0nHXyaPeCQNBO8NFK2GbsgDJZuBy/6tsWAAbAAAUF/pJHPUvR9YIg4u4IGpgMQCwF+2LMxhKcClGKxREDgnDIqIVyBEp1MX2/P/3ZHewpndlByjSS25UulfcQBeEVIU/Db20hIlfceZtfMrtZXWp9JrNmdaYzl9n49ouh+nmcsOtrJ6n3ZjhWZ/ZaUkV7nZ//Y7HOIZHU3QgfP10CStkpZNnn7DwWX17C5vKHG1bWc/dk0oN3wAB0/ugACaJh5sExwMhM0VIlG4vEEDOEQcuAG8xDmeKMliQWRixYbx8egFiuRwECZk5YaJIUcapCShp0ES38JZziBv3aGKeDeRaz+4QPUsarSIVlvorGfNkTmtRILu8HyfpLpb5rxqZdj9d85EAPP1Nq9Sxdmok22k9/u45a2sbHzyewxZEfS6kd25NNWhBvIFMXzFvLF6nOP5+lwKYTYzWiBhhU6wU0wUICGDAJopP/7smTzAATRXtJjeFhynYvqGWksfhNda0UsvSkKB6+pcaMWOAoUoGp4LuV1AtWdak05t35uzcYBugPZ+6ysrnxT5jGH6lAtVyhoURkuEUqT3HY5iH+W3+PklUlEJbB32EsSbZTVSujLYibpNkLJ03UyOiK2iVMdpjLKY7Ld9nxq5w4PINAaLEM7yD0comybQOitSgEoEQAl9Qd+joEZuMKyLBvMkkc1B2XabeLtgfmnyWi/MxLHWfd7LlBCmDYVY8QdacPFLZ8ft2SHZ45Kp19iFXFL45hT9HR0QlqXIFo+Nr+uVlmTpVY+pXO0UrD21+hvHCtfpPh61MONdAcvWnjAf+iQpesnE5yYjVr3zI7UZCmYyj3ey8pRe4850C6kVNc6BMWXJeJmxdkcEsk53rOnUU/zU1cJF0wBbYAkDaCOBMxGwtVnjtEwgFXaCRWBfr8oiz5a1t3DYuz9oTuTIrqJkMW4aR90ujkiqqEhx5YiCxxZ5HTQZE3ZMKNFAUnyx46MqOg9Uf+8SWxzQvpUDDzmhRs7cchzXNjBh0ok/ccjLvvnaJSSr5mamRgi3K+3kcj5rsZK4qLWzfdkWkADQABrjEAp7mnx5kC5pJM7EIhVg/BQVKxVJMVr3LS1xuhEqI1UyHIiiTEuAFc+o/rHMePpnwTHhzDpLzSIYUlKmBlSCsNF6SFbpCLTD7J2rO5uWFcyp2LiEugxMgt3ow1PnnGs6edfPZvKEvvNlyj6wHKhqbT6VjEWKn657t8hZ3MXs17ei6Gz0WWVObVTsUG2fqyeue0vgQeeCpxbLawAAHWgCBmzuei1h5M65c4tqrpKOE3GJ//7smTwAQVDXk/DeGFwgSuqK28oDFPpaT0OYYGB8yuoLbMOcApgGbD1JMPSYsSmHWwOdP4y4UveouHYiR/an+GwgW1zRxNNajfvpveTQZJpq0Y7l8sxERIKp881DI6u2bNhlW9W92AhXaQhSBQ20t8qpDmbGVit0m6p92HlEk1mdCiYWFhGVnb+ujw4ON6mgOKxhgeBBIf9N9GZTQFEFiywQKACb0CMJPxHFNBFUiRYX+mAksXolcuVYzcwT5ewmnro31ZWC1NMzVYkCM7Mf4xYLUchyOa5OW9rwkNIkYZJ6T3kgTXIQgxK2FsN5ZOxI/SdAxLpfzCuIY+evcJCvWOPJinOkPXq2s5BPI3kVYULb3rWLlr0WxRz0N267dus1dWXzf20Bj+or2tWFbHOW+cVfvLSwYMCqAARBLGkOwtXmHhhgx2DQJxAgvSrdNYBR1sCjVOWHyz7yxMgn0rQ7OFo9mDS/jtcxLxJw7WPlyBgvvLYWUTjvlFMyz5NXUo04PF0hrDBQ5ma8WqYGOr2aPYlIHsSeYppRjpcjR8RZ6I7vAf5FKbaSkkq6w0TTVOOYuv+lX0K4hW4yrtJG1VF0gKiI3dKgICIEBAAGOKSU0UYAwUA5JgAEhAJSnVVLYlAUR8ipdpdrdexdLiWPC40I23808RhFageF+xTEoQdpysownB4dK1w8Ds5guJ+a+bq3kzcNZWJFl8sbnti0UHMOjMu+vEsyieIRKvz6p3Lv3+UMmvV9c65Vg2jmGC+XK2fgwKO+dGcQqWhKu1/IJmLZCl821Zj5rT6Yo6tbKJc69iwbc+VItYB+L/bxQMgAA5qc2fk7v/7smT0gAVTXs2Dj2Nwj8s52W2IbhS9ZzmOMNPKLq1nGbSZ2GWkhgAuABgQgRgoGRE6WTc1bYGcJNG++VK6yXVmJ32XbaUYUbhZKGXZQWj5RBG09Qwkedu6Q2pBLiNw2wlSkOecgUkijMkx/xUuVjJNVEsMtI6qzakyF0jN7qLqLOPfmnvM5q/G321tzJfZ/ea7N6hm7zmM/f1EEeUSd0gEpkyR66TFAAFMTJAAAKhi28GiASlIYxBZggJvM7IsEGjUYUtVVYONBjTmusW5feAXsutcSawWu4jW56nauLRLgIJTTxDCGFigZbKRFEbOIDfQoWNUCSHcTTfbY+s/EDOdZ5TlTDPsmQ3i/z1s96GU7URQja6PPI7Hbl/0IelVNsdLK3rP3qQn5ZT+bU9Xe55M14pz6TNfytvMFJjrsLwT1SgwNfC78XABElNRkAkASlDSFQDl4l11QaApKIAUHkonOW82ZiLHZAxFn7OqTlWOvtTQyyirrrSzZMba5BbCbocsM9eLyJtXDo7VvBMh3zyFeR2Kqg2rMxHcFB5MUamH/lI5D8+kFBFzyJ+lQyQsLKSVWSZTHItZFC7Agh4lJ7wA0AAABjPuATMsCRwAEgDAwAzDcA1uAICSyYOA1OZaoNAdO6zKbCAZX1ViqKiprWlyNbWCo26aLx6tKgjnTp2PVeRkQeBmkNtWNkECRbo8fHHWLwqfqulItWD/DzQjA2NITIVh3Z4dR2jhOy0aVTl21bwquvQWm21P1vQnpOfpibLdzNsL4j54nClOWzYgB+/j3ldx0zO1mzSjVNG0LTwrfq2eW6NpMwxNbftfmShBKAgADP/7smTmAAUEW89rmElweEiKD20jlhW9iTUusRWKGp8m5cSZ8WnToZDhRvsEGKQeXIGgGKh9gDqP+yhg6cq0nyl76tqhjNYGAjFCIAlIpSuUZTMayRi6a8h1lEVJYMk+MtzF2m7YQHdik0vCSVamGP1IA2QStc4Id3eUXLdPI9U7c5SM27u8y1zlZqY3uEuW/Muih7Jrfp2x02lL3IkthPiqojTt/tUAhQAAACfYHhnV6GSAMaAGJhQOiwaaYIhKgqKApRQmDYWAIOD7J2nt8ztNSAlCGbkcanPQGaN1VqgdqLYWYvCfetStQ4m9WAwJ1VEL43qFrWhSEll+ryUutFcmXT10iVXDLqm1Um8pUgyEw0mvlVZkIXpKSrpDNVTODwu4KfNdaBNWxB4TVRKZQyGjENBqO4aMGuYiGdjJT8HhAltE1eqTj7glKaTG26E7xWHUKs5vt13JuODsKqD62QaRPo/oACrbAaAACMMQK04IkDFoXAIAEgGVQG5AYATBAEp0aAcBVA051YXaeJXsWoYvZllnVLeq37+TvzUQanDEhB2HiLBaApMNZSKOJ2BKReDRs3h3i+wks3GMio4ArCy5xTzHI+OVVaeiHmhloJxjLDsKMMRxA49JnkJWQoX5ZtJ/MoS5/wMEgaQGyQdEIt7EIAgM17LjogXMYAQwWIRYLAYIPAKA8ZArdnlW2gSTrXdTxBA2CW7NltOvFMo3ATMqeq7Cp0wMhzrcuGiZgTTwbRl4eK00qls9bLicNFidoiMxFAwUxtIS74DIbbdCSmPSTiq4wwhtQrTlnEJF3f5u0Hxbix+voA3GNv8FTrrJ5/Oa7v/7smTmggXtXMxbj0xyjisJ3XDDtBSZdTauMNVB+KdnpbMOOTH/QjPqDckhLEOmtmVTQSTYxsf/HfSBCIpHtFpsNMihxWYhAIMsAQBsyzCNPPgcWAJYIiUqAKO5QGstfZkyR0Swr0MGOVnM0jtEJYkPD8gCd2jN56D1DOxnIwcY6WmXe7vbml7pPvWVv5yreIuHoe7SZDX16kz1+Fm0Ot3lcchb4jUyiQigM4LLVBAj4tN6B2xAkQLmVCm4zB5fWSd0//r/6gAwAAExfbzMqPCwsGjeYZEg8WFtRMCANH9n5UAJfRYKWzoYNYVSuGsTNC226tKJctqibYFW5kfxdtTcrcGy1N89WE6d9FsblHtUo1mU9ULYmBXo1CkQKGJbr6cisSjSJrHZ4et3Lap+r5wAyWxI1zF4dxX08OX+k4pC4kEn7lVVMbA9O6XC/WYBIMFdTsRDzXhOIm1XLsokHzI6L6vlJimL+qeZlRHWWXsRwA0Bw9sXyA7fEIiMUHs+u/BDMzLNvz87njPJ/KgIA0AgAAAAQm1ju7oxVAPSAbnkMcwOIYrFniZ6gwFxG0PTtvIlrzMWoZCdXobbzDKp/ZvOZBq91o7bXzHb6p3nPie/V9MQyELH2Xn172OLNofP9TbrKWrNVZy1W9GJcXco1ZP0mjtNYVzajgkO0WOIHYd3fSKF/P3raGAwURS23b2lm/lFMf2EBR7zcdnTY0/UAQDk7HwcQHDaxNHBAjVCAJxotMTNHPGFIIc2YYG6QAE1E0Rg25UONFBwDMjCjAwosk1wwMKAgG4EjEQAFQCYkEaddON4OSN1i5xKODMoKxmZl1Iolf/7smTWgQY1Zs3Dj2NwsGzZ3W8sClV5fT9tvTHB9yxosawgMHqVjVDPutme2VHenhN2tQVfH3mLbGIcZh0w3l3hSXmy2wr94WstqN7hHrl2/1tl1XnECC9ZYfShu+mTlMs0i8UABkrTJqw5A4fSQ665MsSVVaZpHjt1lqoKUwdYCV4tT4p0VuTIhWlgGWPaDG7KmHySHWhmyGwFXtUlCCAmMpm8hE9RY7eEIh6iRkPQeyxS5R6GX8qy1vakUFCB8DAGCeVuUdVr1q9eMS2irN1pbvNI/jBDOvm7lG6UQQU1uapA2DqNsUfvRnkjGVXKN1c12kvNLHzj4Jh5p0u2+YtsZcci0c6m0Nv9KrQWE9wYHRzyp8aH/roAAWkIQAABtLcd0HAhINYYgGMcXQyLny17UUho5qGxmu8KmAQnIjDziIeHxgTaSWxE6FDMqU4k0+ypusJjD0qCt3NUQ/g8uQsXPT6Te7M4hnW9hMPIpTx9sRldmxcRu1RTMwlY1qloktK89emFQf1/orQFpQplnr9Y+Yftp+zMWXlhObV/1mTC5Xr7jsLi13i4s2NnPvaAXvWXrEOZ/6TN48eGWJ2Aju05aOn+rZKgiMgqLoQigBZAXAinuFQYsLLjINTlt2wRP9jCg/q9/mEXJk2jkERRpRNkik5cjH+l5UthhHGLBQiNj22O1OUaarchQ5LCv/VP++1vAuX1Zbv3nCNtPyanQAy7Z7hpUNZapy0tAjpA4FmElgRu3KATTwaYBGEYeYeLbSggeIAwgniwHDAGgHpOp6mBAuMBBFqXyxvZMtl4Hag+L359ZUVnqGCWDEzgpR6807tozf/7smStggUrXs9jeGBgdys6v2DDfxN1jT2OJNUCLCyncbSZoercUXUJp/V4dJvKpIzFMDx3ZbCGeFob1GZcUSxwIrX9b3PMR+E0Mdkf3XlmN5ZQmYTXWG5K+mXTetZiRKupfyNyYmsc4KRgp3r6mEJniic6RT9H4c8AJ+3Q39byVIDSdJTgAAAjuO3NzNBEiHBgXMSLRZIIgJqiBPBEIGBYiApW0smnI6FkP4pFJI1SqBJcMCPOYQW7Jf7wKUaqr/JNxjK7aeaCK8sVjfT7ktGItX5Fe5Dp+N8kcnyXTd5dqCyMzPd3lmePLVMMuF5p152gtzWN5YKRctnV3OJJFJl/ikv3TVzF4aba3v7VACMEADllwH2GBQEARKPCkdBiG6agEAsDR9W9JVh8cLkTonrPDCwJwaECUqiVJzbi/IzKaJdFFYkH5MgOL4UXQtLEZMtrJMQMFmiVnIkwisW3I2qGFIEQ2TSLBdipthvJiAoDWsrw8UIkanJHuXMg24RY8qnAsI+l7pPL1lrlZ75wfkhUenaJj5TSebFPKth2JZPpaSZzGp+JwVZ7iz+47rugEKyKOFBDMwvzHSAacBZASsLUoXoLQwq6WoZpvsmZiO2ABpkVEgKnuQEoRp4VVVaK9vrK74afYMwsVtjuuquQ8QSwQwEobWOiHnBzi1lnLQx+DU6iuSOxfax5EdFU/+GcZb2S0FSy5//t3XlifltigZwOHIx27lLIANAABHf00a2OxicDAJRGIQyYeETaCAGAgOonp9FvEdQcB3nxslop6OOCrOz6U3Za1d3c677IVkJSnv5UJYyleVwaoFNhfuZOmfD0W//7sGSzAgULXk1Dj0syeItp7G0jalRJcTMuMRVBtivn9bSNmYZxeDdtCJurnEhJbWtlQ9X8nXdFhgdOMnFP9NrdPl2/Auj2IQWhZ78Hj3iz8aDwnFaMFa804fEqsmx+KydJa+01zcD2uZqha+PWTm2OFxZckViMN3/MgAiUIFEokp0yaMOGQwcSA4NWgzRlir3Uk8sk0YRTlruVUKriI/+sUj2Hg9FAUwxkm+0DADUwTWkBdIMlCucAmyiRYf8hGdvmKQ+lzL2/LMvX19qWtfhn/aTfdvhvkax+ZUjyUvudJYChWSh2stoAO4EUGsz1gTNg1EYNMNgoFDgMDqjCZA0EmnQoGgAQAJiXy+KqwSh4KB/Wh1uUgN0rTZE5EAcQtxrGqVmkZ0SoWkxBya3o0vUBUiS6JDzkMhbiz+4adkgQNeLHQ0Z1Rbw1g0HTCrW42Ykkj97w9Yp4WeEGJIrDQj9O0XKc8zfLJcb1lTx3Sah9cKPl4fqqwnQADYEICuei1m+9o6MGalYyHCEQMBDdrIhp+24paQI4zUZS9JLZK4FvBGHznsS7SigVJfjl9OEamFCq5i0RC0vQFeCRLUlQoHDyMPLB3LIiKu1wwuWktU+iRxK4Jz+NNHpUIxokYykgN9bbMrqVLMi1zWI3nafwwQwiSdTGf1gwAABzN6kDQUFTAMKQMOhgSExgMC7pIeBwBrHfssAGSAEl1KZVfJgIkU0uuKqnna0jcWrZoZNLrEVeJtJrtLT3LkTiL+8oGpTtrlianN1IwzlCRHDqEkSLXtURdNC09mHeVKh2So5jLdOhgb+Cd+NUcsKvWSJB8HON5mu5//uyZMUABIFaTkuJRNB9itmpbSN6FIV7Ms6xGoGkK6i1pA2tE8zApeMLpeTk2WlqOuBRufuL8ZN3iBRdaN5w45BcRyebq+TLugQ9rAD9jaYZJBTprGo+LIgRQTb9myRDNCsCGANM8dB0Kx23RDj+FCMPdj/hn5FAjKsgsPJAKXKHwecZSsbjDf0+4U7DpcYvbycvpe6p7Ze19stRa+X+5d/M8uqVQr+Vat8KfebKUDjIV35vxgAkAIAAAVE1ubaMwMDIYpBIGmCwSMgOBAwHLNhpfKJzmzEaei+Ow3B2IMhz7iCHoEA0OAOT7FyBHSQmoXk+EDEaJVOGz4KdkpnEX2ZtOwXFhU4wb70mOYaEtC1yUhEHVOm2Xb3VxmZyaOT99cWlzZzaos7m733Ndl9fE8RK25rNl1xcylMbEDdz/q3KkmpVD4fOGAXJB+hheuQAAEZABAABShtuPmiykCQcYCGIcGNhUAMaJge6C4mQICk+ZbMPA35gVhuXgj7DQ8yniKbU8eR2mUaJ+0DfXeUnJ0X9uWbd52oJyA7s8rO9LcxirLtRkMo0qphLY6L22h0h3NnTkQvE26OXFjpZN77c7cXt/r1u5tjNjp4v4qqqH3+djWKeVSRFRJxwTDpfDd4ASNIjUAZBYgFQTFQsIL+TEgA7oGNLPzHHA3LQDiIMHAcfGVmpnxODoMHGpUEi25j4KY6AmEAzS0mQV+ZKZG+YqaPz/MGQ6ExxculQzU2dJt27SYxAgMIn4vFewOgNFwmdk243Qz6VJIOhtCEzy3gjEWiBpVVnAZZcjUhmGlqaK9Lpo/w+q5MZTB33UY3L42shjjyw//uyRN8ABNJaTVVxYACPq4m9riwAI4mZPbm8gARFsqh/N4AAbbfQuQ+pcdKUvnATU5U0t22vPTKa+PN3c95bDm3c2uR3W/dduixJTStbzlr+wiG4do4TLZdZtSuWYcwjl7b7svpoHt4wmN0cANgd/KXTtM/cEw/YlFqpa1er4Ya339N/m6/aalgbKvYn6TCp/Wv3tStlc5SPvP2ZuctYf/5c2CAJh+7+lxJBFYADKDsbmCkMCGQ7HgzFY9BhiMKAByRyYSHmaM4RDBY+GgQHARnQ4ZqQiwyJHAgBhYwMQDDCQEqloqMmoDCMoNZ0bk9qVWtiC74aT3TPQDPalQoYtGwj+1+B1jLiAo1rOo40Bvw+7DGITtV+3jUDuqDuG+jlOq+kshy6ztnbX6uLXnieluziv3TzyqDis/ytvA5Ule9H9r8jduVQc8UNOG0iA5RcodXpBbvNu+7X29c+lgtuFDVkcsl+4kzh0XqwpZujwyt2MeVF11aB1nxlTkPvL4THm/jVuJSCs/cTlMMWohYp5i5P2btm/a53+tMQlt9OzT+Re4/Esn4nfjFjL90ddm/YvLt3K1gEf////NVFGroBVlSSCW7wBURPCFtSYGBTpLiBihfxlDfKQh8uYRCOS9rvIJctCCX21m1HneUo3xIENnc2e0kaBCjTvdTWfRoVn0Wl84vSvv7QGddahU1r+9Z9Wznfhxv/ujzzR80iZYJZYEV/WmXlY94bI5UfRatj1Rqt+rr7ki7Ujqd4o4/jMDG/759AfNto1WeBIoDgc9r4uce6oblAnDtL8oYDGqB8G0lSbGYd5PFCqkWdagXlSYEFxWWN//uyRFqABhJoVddl4ADNrOqq7LwAUt15Usyw04JUrWqllKJhpvDcqNcLdtYcJ3sKJYALlQCkUnSG4HskJAjIDGErC87fIJGAxtCcIATiiBw6gwMCWUL4eS5MY0z7UM8Y3sqh0uFnLWqtMj5ut2JmZpI8eeDMxK5mspoeYLIpGW00tlK4IVFanOM8k1EZHyocEWr41XkfGdyxFjvn/zGuwN0CE6Ypvh5aJp+w12zMkyflOt88V/ngv1t456bELtvasdsj9yjQG1TxruVYDxjV1b2QK1BVrXGUinQmFCT7KziYHiil2fpYpoCcXbIyMRmJpoWojPikHbXnWNYzWLJMBAJAAMeg5uAsMBlghdQJUpMClUW0pxY9ygCC+6FznMueRNaIRiKMmhi6XXTizZyNlt1bKF/JVcyxU7RW9cpatZv7xwFajEfLF7KHX8mCeyza1KXVHbbWWu7IaVtvtKZ7lQL+0m7aak+Ya4KaZvLSbJDGFyl9Liuaj6NxFzEsqVx2LBWHMrG0wpzIOWHesRh83HorTr8zoAgABYEBNVszZRhc35haeHmQFsljFoIKQkpxJBK4Wb1iSXLiyCMKow/Ipk6TxQRIBXSMTTplx8cuLHFLowIXLeObPMLMRjqBYYIsty37FqJBUQFjcJZZhh0iRuJQPz89Dx0sPvySNklBg5Xxt9jYQWjeYa3Ztmms1RjDeEseULCNF1Fl5qG0KhtDSzTLC0RIJkW9L/+1AhAAQgAAEwKbDpwZGTHRIBXqHVLECAIkgFFag7rkmp7KZZOtKCOyR+GJvollStZg1i+NNK5yL3I689UThVkZOKgKPVPxj2Tc//uyZCQABUBi09N4SfCBK7q6ZehOEflrV60lcwnqrKsplgrZvRpfU8m7JNCVIG2su2M32aji5Rj9WmqYBY1lG2Y9YKj0yGo3dktehobjtvtILKP1zDXVEKjeojEKg2t1kJM34pQ62v2aXa6RCxyNKJ/Y5FYZImcIUDb/G88UEc8cy6arBoYFyBAAIFLHUyS/k0pNUkSYJDosvTllGaNQZB3BoLLidxrI+AVVYFm83WbFz0G00biog5sdIFJG1KxCUIZR9Pr9pzC8oHYPDtUrn6w6ivrjJXWr/+GueI7ho82K5WeE5+n9euOe1q8nuZ68srjVY8qo48gUc3HCeiZ/GDmKMrcKgHBgEAyJtEoxFQBBQQHMaTHjzR1Ly3KANhcPCICq0qCFv7pEwWbvpddhqki5ZQka9FTAdTeJ8G0wQEDcRkIcUJK5CJLHxfXuj8fSJ2LR9bEzD+WTSqtVJKPbmIHrVed7g4zu+559Br3ta/zh53PG583KCVx98Oj3N6nnptXuPVonaudZ1ySTl2ib+i3QTlv2F5BDkeiBYcQd6ZMoECMkHBEkgcFAiVHqSlbL0IXLrUcmgB79vs8lH27DFyi9hUp1SWI49F50BKmKqHszpxTM9/sgX1rTt3B5Iw+0XbfImXXW3DtQGJoOzswtpkdxT6IvzILV6P0f9LS37PQ+reWleVmR+akxRS2XpnjVEBAzV60M406grVmfAwIJGZBQKMmGTWwR3gbI4BO6y5jfNaTHO6pct5GcsMToh/bSQ50BwI5Nhi2M4q/AUTMmjy5mNTuXgSxf1pZylSl6IjG2zH9pquraHwQJ11yfPRYJVJbf//uyZDGMBRVg0ZN4SmKD60pCaWLEFJ19RG2k1wHarOw1hZbcGdocY831GH6zUP14akG1J7db5ThK/Kf0zm0TIWqK7/cc+9JqossdOEPHk30ETZFJAiJjOTIyWGiacfTTpnSv0AIBG7FHpBHdQm0SGLGEQcLmHGZ3D68jDBCIWhNRLAAaD33TnAx1X0WS3tNyiEBw7AD29ZkzffJZTNdy3H2A5Ybghr6LT8bFq47i/VYagzW6at1PiHBdS/lOVcGayFodvxVqSgUAfVboGpIZJjtQ92toYC1I6EEvlKyuKFtIFYMCNpJ28AEolQ1AmC5QMppixCD84iDxoclAIDjrQuHgUEmCg5KilvWzL2CCowwGgMmBiEAh8oHYymSylXzsy+CYZmr7IEmsVjohELURZjrPvpD7VchNJYjVBufeROgZJWL61etUzQ8Zlia119cuzkmd15X6dtdl/80j5nKPFHErKRnLr68FU8yz9ED5WIx2O/eTVc4iSo5NpdaiMALri03vxs/cXq3KNQvDgLoMaLk01kvUpFqhBYqAgjIy+KLWcOyhd7Jl4MYU1kEsfN3aSlg2n/UzYmefPsfuZ2Js0dwBaJ5O3aiZ7pz/hDn+ZSHM3Us2w6d6b1R+3ulFYyGvt2VXR4YzmLVyPY7O/YrUMTcpUraaj21uyI7KowWIIQqgNeoQAALaKhmYkcgNmFDJgVMGFIJN2lF0TFQ40UIojCRQDJxhBwPDTW0FVqGKArYWnAQDEYiREMPrteUaG5Sx9fKJIZFCWD+hr6ZrqDh049gtu12Zu141dabcNX+qaqMOjz4kmzmr93wKFx+SUNncSAhu//uyZDgGBSte0TtvRUB4pprtYehdU+15Rm3laYnsrOtpgwsUHLRN22USV4yR/CtUCpnRpdUi9DZFo+vgZF7r58T817fCF8KbadCx2JRsKgsRYwjjQmIaUK1gNxIBJTbaydDsX3BLkcSUi6RJyV8fSokiDh4Icf5H7gRDrWNnahTVprRKTphFpbeat76lIQ793uUDUhGHhQurFFoYGaiJ5uwQPjyox8zcrPrPxSXcPdv71RG+5vKyn8i6t21XKe86Yie6zZuR9tZt1lnXU4t/X//9abpjRmbiemKqpj1cauPCQSXKHAQxZMBIs3oIfISjnKDMICmTINOFNXq3EUiRNqMAwhrkXuQMvnNjsw9EurtKy0nKSstBLm9U1eczVHooTRZGwseCamc1EFrhAkH6sTRclLbiDk7UkPdnN6L61GM+P07peTX53aK2+Ui34lN2hUau7ibue4UNY4TNVVmKtWyUodtMd5+0k+6SX/asMF+joGSkKy7W3pzi7kEYlVYNbAYBvn3gt2i07ysZddpFujaa70JsWHzy5dmKH9PXOfbxxcPC5dSooM8uFZ7ClTvt/Sqr/l6UHQeZbLZzluOLNhDks6O5KZtyFeCTg2VBhoM4ZLs9iA0gno9XQsatcm66RHGfmoLvQGGS0ax2tQMgADjuknBIADShExJAx0CIyKVIqNZwGIzwNCI0Aw2wOTQ0y5EqEtRd1urr4QzLGbSTcpSG87eDCxSwUsJG46SMmohkdaHpyRStusWMI4Ynx5AzEgDBWyA8KiCDieSzb3c/nL+dfGfp0pAS/H8K4/GBq+pblP5tOYjiL3UtORFu44bEpKy4//uyZEMABI5fVFNGRSB5avqdZeVeEml7X6wk1yIDruu1h418YD+ZEO1aEkeknFu0AGggACyXW3gw8+EBzAHoIcGpKJlrlg0iHoAREEOALgCK4pMv5hK1yMyaBhvb3rTiVKbvmAxPoaRBjrF71izeC2Te9RCyBSFqc7qMFZL7aMKgQXZDqeabch6Nlo9V9L3sp2VeqlLRtyd2yr0b900HT5WRBRgdeWoJdQBrxYSX2mcmXKTITvHAior6CjgICxJEsMAXkRAbaVzaxm87y1HIP3Gak9Mbqyq3x6N+PgKCwIkCYVJ8IEM8ieKz6B3xlK4d4+SQIHffdfsRu3bU5Inf94hfZG3niG/v7/uf2ffJp+Ey1sIC25iTNBaOtzR8QCE9+0/aG775LuDMyEbbD6zCgiTyJDefa/Z9jQ/EHUCHASCRfHInk2g7JE8XA7asq+EN4cRysNPWzq2Te7o5kIW6JhWSblno5YkWMy+RcYgxCGxrb2dM9auEaBbd8wq+Xehzhf/nMDTldk0/QilV3czBCHLR+INBHXivCzd/Kn9PLc0c/Tt6B+EI0c9XNMjcEFFgABSDi5CBAAgPsIRJh9UgRlMkq6apPw8ran+KHEA2wowJMcITcUokPPMtJ5kYOpafcE5VTmD/J1cg2GpzG0NfR+TyLjtFBRg1cvN3b9jf/ssZUIjEsvNpGItPw5NqWNDW1FRIc1lIPmMljcnk9ZgZz/pT5lD6eiX/dlhyU/fOMtd8J5M2S2+V0d8pH//d/sveWLMwzdoxptThfAHoEyzo8geU9AYqnJGtBP4mWu62bhTCHDHK5conNCwQoEhgBvUM2vy9//uyZFqABR9g2GsPYUqJy8qCaWaaEe2LTk080IG5rmy1hhV8or9jRRfy+YGYdUjiRjW1xV4k4t2fIMki4nKCwtYrbm1vBGZbLHdtzh/6j+I++Xgki7S12v1zByZDAktpdXe65xSU9pz8/02NbPGNVZ2c7C6xLfl66DbWfapEf2ib/Lb4yO9hKdZO/kk9uiAXEMiG7EP6P1SDU+10w2gBF1BLk0sBSTf3i/CeSY4yhAQt71FQwGIhbO70whiPDm2aG08Mas9k4rI7LMlkFKXZGSGAaeKOCDNFjrsoOyeZR/4KlT8DI9TtvfP+g7mhO/vc/TN74/54IrpYd31e/mJY7tuCTc879KH132G7azU2763OX48O8HJJfb/v1u0eI1MWEq/N3WkjneP/zXNrRFs0UEvsYJq+QaZUz+2oKcpW5kSYk2muEgSCCOriN0zVYVygdR61B0lItzX2z2e0U5e+85tFsf86u6ZhZogIBNpexVwiLJR6zTsxk+lNuvX1V79K5VbK270RtE6tmd6PyHzQ8VBEOMju8RCKif1KAEFRIBcbSJYhAgAMycyxAxMNGZCQQCWXlxn6T2UmgEZlVyZ0sE3sWdx4MRXGBMmSwFddkxqUZk8kipKxiFbDzjNmnoYN6lhZgfFq86r4NmMdfjSa2EK7k2/oWrWv1Fa+xXq64KF/irtku9b+tfHW3Fx1zbp1EE/R9XDXGSGmxVhb+a4Li15EAOFYgGaNNOUgbQWK3dwXnA2U41IKwuyiy0B4oGXI4kbBdGLFonqmbQtpIs0jzvwwf1Qug+ljmvpH3K29NyogkKtdACHa9LxJPpEmy/UpCrVV//uyZGwABDZe1WtJRDByC7rNYYV6EY15UU09CYHUrmu1hYn8oZciNpZD25MrZ/mdDs1a0KHq8yEG0fmDhsPFabjBq2RcBAgCpJGVBIIHSVWGaWGi0Kjd0RhnVDiZwimn0ApCMvieiNB4HCoDfD7Ss+EhhSwcJ9o7A6uXQsOGsYjOlsWSINcM2ziWtRc4oJVV8zfQ8f5VtnB01YcXeZF8HD7dprl6gsUe5Hp9czM/1d6qv1XCc41Z2lL4G1Fj6aztoqzlQWccSIJ95TlMxR4VI/UwG0oEXNbSTVDgaUcpHHeaKnOzGVpWwGrFArY3Ab2q9hiHBw4Pobock+1oFoXhM+0nV4F2W/JTIguLbbzxtuo+n2P5bt09rrc2ECzgySjMUZRG6Vb1/o6ZndNqWol9Hvd6kerJSvvRH3TKMSFBDurFaOaW2iQqBGQjDUw2cPDBs2gDNh+wYYq1ixODEdPVb67itgydRpORxEoMMEFr5EAjIVIXZgGClUFTtVceCqdzZhmDNcCbGMUQDQ2w7FTucs2XOTkaJ/kt8PxxFwQ3lDjbQXGcB2ckKUDal5WSoTSJrla1J+hl+FxBbqG/v4pNlrh5qYe/2vZa9ZuIT8VvDkxbg4m8Y/5q0UAQCdbZLuHdACAoKgkOaAxZZfxoaizC0oF3oaN1QPkc5JmkOrOxhWKexQzkOyhg8sXbRsGe7UCFrzqFF11XOZpqleDPEgVRDwof2SMFQ1I6v6zyj9FAUaCSoke5pYu7cIvelHEURUu0G3kLpJgbdkkwyhNWSCxU2Tk/15QxTcgBlAYw4LNvFQF0GtafZuqdasT2s9XzA2HA4Jic//uyZJYMBI1e0RN5QmBsRmpnaYOWEUVvTG0xEsHenqoplBcQ3TJqwFsiuFbRLxPA4pjRNd1as/tD0pBsVyWPcICUtmSuDjB4wLzy0pEoXOTbbiDSRa3jB9+9c7eKDJ4FfQ+qilnp5ixs1MNfrV7/jyfkmH00ZhtXUDYyjRI1xStDBQBJfbbyVE6ijM8DBkeCUgQksGaAsPEVa1XoZLvVutyN4GLt/TNge6i5dcpsdn7L2flfuSyvu2s+kt9wLWJI+pFR2pjGxVcjgWWMco66NFce8yZS7lDNGP961+iTZWDCRK6AiQ2bA8LJxaYCpF8iOBkEh40C/2UNpuSZGEzgCTUNIMzpzEwAMbYcCAIHmDhLululJGDgy6ZBdVMnyzJ/1pLwhcpjAaFZhe0PRvIrKDHxJ06xgoL7F7K7AoYf2R/ViWK8mMH7W519xMblBH3N1HaCa5GXXBlwVNXtDegtyU3A0Ju27xlnDoF3n3G1BZvitLz8J/2TXdnN1LuJQXdDBZDRrGKDq3FH1gFAAEzGnOmIdhiAiRhQrPU61VQYDdItY9bOHPHRbaESWQwpwAwMgTvMKdWXWrr/shn+RBoO7lqseVYoA3H5vdH1XD+ne7bbaYGoJ0M8iAmWf06LpTr/vqv3N/V71/01LS2pdW897pEgg4xHYan90OagAMAO3e3YqkDCGUvA6IGmUV1epNBQKphLmcpNIIZdF5S27NJA+bkqoUWFQHBwYmlI/w/DlUjiKchRCYWDiVKNjUv27jZ1PLWOo7FG6+0o77Ru5SGS9SSSlu9QmWq+7471VWXwdZ+d7UvvNDk7O3cNlV0cX963su+k//uyZL2ARI9bUptsRLBwazpaaYKyUUFrUU0lc0HiK6kdpAsQK74mUXTtdVSlXaBl8nzbJYDCCSkjlEZ46sUOcGVNpCkJss2YgEBQA4CfgwI1iC6FjFm7DywtIlm0/GkrJuX+teCWp1Xofner8rq1cs1zYW/wcH9GHXdVU791K3uGIIvqm75tyFwiNZGenjUeHa/kKqs8rkara5p276MZZVXXf7NV3/HMFAC4xK+1AnhBuWyWdW8arFEDKQPWJCareIiQg9h0CJ5MuQQN5lcbVrUlhTrNikHcDipbZAuDRGTEDaBQiYZ110Qt39f2dVknyi8PfC60VpMvvN3VE3+RFbgya4Qz1utyDeVGfMG1P8lvaCKLCbR6aQ4U+SQSXMk3njyETbbqopXmsaUf8HpNiHWeHx7GLc+pehE1dIAeQA1ZK1OluUbGtCR0Rn4KwpWA4BmPBShgHgT6IIFhwYhqqjSTRsCPjyLWUwTd8sOZ7xc75dc4/V8S8JtiYpV2nJ7JURKjodndkSMArOhT1YQFo1nfM1fVm5u2qae/+3kPQ3K9qdCRt+yKJCq6CFgYSOb+oputJQiCllCRQDihxtaJcWEAIwRNATIEBKWMbfexi18Ooy2QrUUjaNR7F4YokY2XkVlcY8CF5YWG2mNt0fbfGcVfR4b550neNc9tP3ioOQcaSWD3NYTA3zAM0Y4tiabDDLdkTE5YjZdKFZVpqZdfLTUdUSe7Qaq9MXaMpRtuoOTfRAbqsTQfZbOkcmPBBuTnVU2s3ql3CFw9xaMTolz1iPaybf675ymYGnAi4IuNBg0BYm5koSVlrWlg4A/QGBvy+6OK//uyZOKABHVfVVMpRNhz61qaYeVfFPGBTm09L+IanSmJp439QFNC0qLqREEaZqt7vBCj4cqyjWvAfwXLN6mZTeqKeHmSHWsdXqRlfMkeSHJGiZY1HisCG6nq5j4LxuKzgxw4YYWroCIWBwhyyrvPCJ7osG2GGLEH5vd/+eY5pgzsBxYiAVI5H84jWfxGWd+aFAC04jPA0CIxihCQTRkRoXZLpBRpnZQCoAhKN6tzowOtKBJYmBbZHIYCQmMQeTCKMAfKEYNHlkXPqEs5UHIswo3e33ckFDUUK+FR3U0vO3nGQYE5G9AmM8+nfTzfav16k8vZ1dX8pecdwiSz8FaHwaKn9hPvmzmxC95WZ3stPRP3MniYhvJZKOtYbrY2BgT7KjJKkz5xCHEIvWcZzq3XDwCASCkZhk4xCzNiPEx1xQlWAvg5yAstsCBFxu6pu4MpgaC1Mmo9eGXSyVyqngDk2IYLoEj4tVngDzc1I9N05rr7nlfgOBDxjo/lBpqM2eg7ZPmDRjmTCc+PqB08UfcOKvdIHmkuc/NuMqOu72FK8xCpShIrkS8luYlCuqNWdx42aEfaUAoRV6Irmo/+mRrLvHhc+ipZX9Ypkx/OPsQAAjQQaMGbGgFoZZqFfp5gqQIwPBSsw4tmimr/tNisQjcwrC2iL61GMwfiXDLAYXPCcLECo0ichHMI8vGDRAZgMDovJMf3qsoxfHhzIhHR4hPRUkHY8AKvbjjquUsav8DaanI4g5/IF+bO5G0P+vGJnd3e5tXJFj1Ncjs1q3l6FhHmrG1cSYOs0S28BEfWw5+RUgi0yttTLsURLNzSINdcX0wciMX9//uyZPGEBQFjUpN4WfCdbLp3ZQyuUsV5TS0xEoHyryv1gptsDIr1bMqBPl5U52bKoPUnjZopXPP1vCn7NXJ+avXbuH6+RU/5XVcX6/OuJay7a1reLN7qfh4M6c7YkAw+ui8129BBDzsjaXa9Ud0Svujr2NoaisW6pVD0URattXdDjh6Rwk+osjnlZVAwcmL5GuoRFAAlmAONhUgJhwxamMyCWglwBYVRsIgUlAECYVBoOY2IOUo1gEYIOQE87BuKouKT2b7BmAhqSNRkQ5NRlO3TOqjnrF/guv5JPrVTYxUGw0IBSqkOBPyQK7wMv6a+yauWX7EAftPXYrHFmX3XiEMviF2FqvZI+p6Ogf91jaMqElsoxaFJeiuqtAv5TjKQLLC3IjAAAEIikYGsDfkzBBijoKCDAA2VgUUtYDMIgWrVUM+Nh5oLFC+AKEw0JAcShEjXDItpTVxqPXI7BfV1PCP+JvEwQ5NbviFjVtYv/XZDtzglN7ae4l95HN/l/IJDJXOf9qUrObLdkmxxV3mnmotEKz0UzH5n1o+HH9gPNd3r8wZbab6twPXS+8wx81JW1v/ZDEv3EBBiCiQx0OHYAayKrINjteauDQQ6JMcQeMdOlcFavZC2yKXuUuILlZBYebgVNCFLKGmYzGpHlF4MY5/VoUsotTlfBG14JDyOxg6p9eFEuBl9TAjcsPu8WbkQp9yV31jmBG0p6mLrzIhrqdBZtanJSeSGnpo5Yd9qvFxzrfbLDHPXVFOSOs0ccRcK7ajj4ueh2k0ZCR2OwQNGNMinGgRbwBPAwAFQgJMgoUAjY8FL4hcCZclMrPSoWiDk2Igi//uyZPCExI9a0xtvQ2CTK7oyaeaIEgl5Su1hCcI4LOjJp6IgHRh+H8Qo9TaamIiZGojBrmRTtaHubtUyh3wfu0L/pt1OQOiHCITCeWjqBAvGWIDSQfXEVFuZVtHF93w36pKiZl176iuWr76lYr2uo3T2XlZuJm+WH8pHnG9DUNw8GS6yuuTqEABJDCgMYwPkKgaurHwfQffs0ABWZaPmoDIkRF1DMEBUCP6NDzqbOQTFFVZGcgAf59RDLBqeNDMOCs9zrtWJEwKmNO5kAUsedBqGCyqT/+7Id+olBv1Xa7vlj5qWBnRojVZiLu4kszVfqRWsfHWo75G23BPQJkT9rrQrU7fItdVU8E38N8NFxUVUPPNC1YeONNLEEGo/ks2ILpRSSdakbJXQDEc5vchFZowAp1KZ3jMEDBRbw6gErRCQNGE9VqKXQhBLBgobWX0vWJpVMwZ6vmHZJAERr3E7JuP2MsVbLNPlTIKQrH70xnzy4BhuaDBpgwVD4Rh63KrhNX5YrTCrjGaZGJX0NuCnGe0xXxC3fVyQwovxHEDDopPokjrvuv+VHbOl04yv7+zhtLjLWvqTjZv0iAJNOFlAVRCrEbOanWn5+4CNA5iAIZETg6FEgRVcWwZWIjNjXirYnVZAq09kOzHZGaBLrVDGZc0hTeXZTLlrNfSbgWtH5r4dxZHS9/86LL2HCBwV3VKIdg4Iy1yESjB5b2WI9ctfzf5C7UHQ3piR1s18mpdtO45Drba4Ne5qL+Polx0bX3N/6xcLUpA/UdwcIztBM8EzoG3KR0gAAwAAROWTZfJskCGEwRlLm1L2NHbkhyBRKki36VYi//uyZPYMBPZe0Jt5QvCTa6oSZ0hsE1FhRG3hC8HfrKn1lRcBCMcGtB0+zdY2NO/FRsdBK4/P9sQvnY5IbuqegTdw1ZQBYs9UfIot4hoAwMNdqtiQITPe5dpSshdLll9fmojGiq7UqyXZ183sVlodEJWhoij0syIYzMorWWoATB8hTCgrDB9CjUlhTiR0zlUPg4xzAUWjDFQxGChhICJgAGgYvMg/DtAdCThIwgITGsDm2qGQIiEkPJEiDg3gwaBqKUwcKCjIvezRmYqAMWbDArvQLM3YChiK0l8eEJnXLWp1VlvpYcB+lx2G5Oo9Y2lxU41Wg3EGwiDuNiy5CS8tcs6ZNSXbDfvmT3TkamDdfeke917SueYd2lce47PL4redOQv18fXOpRrVUeQval2SSx9vNVTsOl3nHvPRG9VQZskkzom2EGs3mtOGMIEgpf7AgCORNM+HSwURiZb80ZJ7nNSPS4DEvRsnCxjcP4vCTSzHFIqzpSEMU0CJHBNP/EyGvW2LUv+16OiIrIGl1b4QhHP9S0zbWpVmST0ZRl84nXWQYyqmrOtCuxKzA7dMEjhmKiIsMfeMep5vdPiBgGCNLivWCEY28PCoZmABaNZNT+X8GJQkDhQdMbOTDxceK2VkQmIgVRtSx2isHJg1mpVC0knLh2nISVQ1Kx/niJQJzXyssoQFxtjq4Witx+fAs0Wf+Vot3zIaV5Y0GT9+5jzqioGid4E9pYggjTKohDJkOxSyqqsYMrnWpSk5WvMTKHK/SL3M3MLfKpUkr41b/+94g06POIveBzlCDTihAk0P7SFGpEnlv5f6gg2tdr2HmcuYiotm//uwZPsMRgVezQu6WvSESHozaeKMFK19Qm29Foo4rykdlYtgWwYQFyksgcgJQDRSP7ZIIe0nRijU3RWIrq8z2K2WnRBwox2P0Miu44L8o6mVK12lr2aygkKx7q53vxZuz6i+CUORm9E10iFk6ZWdbByrehN+lPE1w48+Kk9wcfUfHK5/TecdtZW49BzMF3dO6z4by67VorPZ/TBme4YGRzOrIKT28jUYpyy8qjRkoWASgzVENorTmA6CC8BjAKYOBLuf95jAAxnTcX/aeje2xbhVpnqOMABBczhmUCuH4lZJxXynURnoYnGZDh2Lmow4tNftG+RgjrC1yw4ea5lQNOsYIZI3UND8YKRc3imzVPA9Y5jlhQRfO2kuuSBDv3nk8v4DV+i8OnM3HTjaVb3NNWsNjk5MYsaG2OGBkg5y6ppOkcVexNEWAwAAQuWN9zDjlQJBEKMEBEQzFATKkZUtsSauIrx51sGFExdymgXkUb84/1OmTEnJgCfoYbgTCajq3Gm2rc0023QXvXNRd/WWX+agV581TwCbY90HOVxGO+oAmgBdigB5LM1t677Z9ep2p0S1P/f9f/q69WmNlGIygnZyDEezoIAVhUbmmx4jSbHhBtGlH9CmYKAxgcFEA1MLgcMCJakygQ+YaNDkoQgkBT4CCMWEirQ4kUTIDnkMIFRhRSKEqKOEOzbVETyad6pTBsluZv7BXVaXmoubsPL+3KhO1IWW0WD8eKjY5UECzMHqPXUNo5cyfNT/N95+CPxV9s65Htrt7oo2TXiHRqnKpknb6dV+c9TbL7ZoMqdhObuv4pN0waPuycd2tORIJco7KAD/+7Jk5YxFAF9Rm29EQH7LyjpowtIVWXM6TmVryhksqGmXlmgEJpJVD8hCNII3mzTSE0wHcGJA4pNUKJlm5CXtjJloPqma5QlEHfShJxx3BL6H8ep8JaRnFTupglK4RtSi1XhTQRs13/a38lntJt2xvEBJZlja1vFekptU2j732IakjdlWxLfne0goVzu/119Or6IQiOc/21NbuofCzxMRkwTD4hMlwf+1DABRUMOBzZA4ABp14YeUunwHo4BEAqY2ZAqgFgtAEWdMIKxYbV43QiEUzX8EYMGBD+lAGwsqmoyAtZgaJDgDFnvoKSGisFkcZeGak1AyCN6UOk38/Kxr4PJNudVWIlIrEn2yOPSUXnijHwuT3vx4o5UV+dYHx7ECCb4WTt+ZcRO0Qk2RG5m7Da2eiAgMUVKMQiuJ59GzGZwSSuZQjmROuKTCA/dBcC0EmPBbCcIeamjOEMccw1OdbrneWN5Euq66/f435vvMZ5oFBON+6chpiogLgSDH2kfELlmFlisdGb2EPyJGw5GYahtpuanVatFow6kqpI9hCeW3plJRp4KVWcAwOtWfdZ2l+pgTJp05OwVzrL37+weUmby06f0ylNgZxt9JWKaUr3HZxSzsJPeYciOPn+u37GfuP44sipOfX5p00oeTMCyb3WRUZLazZP22zk+Og8JbSAW34i4JEbi5XuTCf3lv++CK4GCgQgAAIcDxiYWhYomjzaQUYAhEYAyAgDDgyQCi1hbGsMiJRZrbwDwmeOCCRl825Nt5icivKIjDDXXXfO1LmeKFQzAeVWFRxwopVS3sa/9S3n2s/Ol+OmSeK/W0amXdiw//+7Jk5QCGQGfQG2l+0KFsylNlTLRXCY1C7mGNgjWu6d2HoXiWH0kAguzVlJWfsb0batk2SL5YgY/YTj78tO955VzR2VF2sre1CdoplOfVxs6jsyy7bXuWT35Sta3uiKNfq3rvPpn4GRbV1CL6jMXqntZJztd+05kP2vDcDIVEVFUDCckKdmIFi9y26l8NFt3qR7UZvl7ApuR5sCBLFhdblJ7aSjhZgh458s6vxuQ8s4kkEmZM61a/39J/A+9Bp/xPesMNEEEQtBAcjpFJMQGrjxFxjR0V2MpruGqK6SZSI1m9auUlpqbqCr91TYVfsqIiAbTUX/m8liwJWSLqdcCsUWPJCRhyFJ3LAgAA1AAAAt2bOEkp+bfHmZwJ5Y+YcFCwcFQ82YHKBEKgzKhIPEhWAIdb9F5gYiCC8CnUYsmDgSXsWpHsaQxN5qGgQYX8+jpzsifSkhtZ3Vu18e4Ukm1/RDXyCVVz5SY8jltN/K2c4URNS2LTErMn8udfqg/DZ9bbgRsfiIg346SwgGjxsc4fiHpc7/WGGgrTkdirzDzXW6CE6eu1xebAEPuQKC8QVUY4moaDbwAL0bQAbzhIja8NoMFf9R5ZyPVGwQUA1tXjokElhWUJW5vXCksy51dgNe9TZNZRzwEWhb+zDks8+v/3rOytIJPMAIAMzK70mKFO/VUUchZSegtNVtn5m3YxVLXZkUjNRNUV4m2qdXpRXQz0UuecxRQc4AlAwoSzFQgoJIAJhwyVRwEqYdDGS1wb1u8IAMWUwdmBwWKA6+BgDWvCW5sYaxbEAKmnQKEthKhSGOh7PDEU08gLgTx4dS7YDVcGI/D/+7JktQQFTFrQ02k2sHqrOr1h5W0TgXlC7b0SwiUsaImnoejXwTKbHx656i4rtCHZIsJJA0SNUMmMKCKpgW+RCWipY5ZFanxo7Warx6+/0i82J1jHVyTXKDW6VageetLa78TETcjA+q4D6bjHDdgFmtD79NJQ9jDl1I+iEOBzcCBFjOAjMc5OMSMMZDBRgAxhwiGBhyMdXeoAYgnMLhZyDClYHe3NJY1hQsc6L2U1X6+M5q/wSz5xCE0WpKvLf5PJFCRzKOdzRUORUdMT3Ayq1/+pxao6quvoWvqYf+nySJ8Z8rV8bVrddovxd/d+PbkVNqPrZzai/zAitUMAwqwsSXoi6hCUijCUSNuBQIXmVwBzvicGUPQQgRjw+LJoYLDIUvAvAy5v4HQdUzYgXUTceNKCNGCASD7jvjAy+HMg668TAGaPjJZVOyKpADrLBvtzI0fZwjc6tfD4cDl4FWsYeWdua8zLdThuVT9bJ5nqIXxhzbUtlh0pkW8RJYzkl54LjYTnUwyvlbqUa5kirl/8XOwgUQGPNAW1GFTUkBtZmGlakAgMAE5a62onYpxIwMV6x9k+yd9oNhhdkwmDGCKjRVy0qnS/PpO3Qhvo1q99Z7IL7Fa0LfnFcDecP/i32xDuRYmtRNgKzUeozWJLK7KtiKytjdnH6NZuoqSSg5VM/M8RMFRskl92/XUXN+nv402k+E5/khB2nGnWQGQkJg5eZG7HKAZixkJCIcHjAqYMNoACUHZcVQqCdOw0JgbBEX1VV5treBIMW05nvbSaJqK8PwZhdSVhfi4EoT4/2bYzUvT+E4Y5LhXWGm6RKsPPiREWBO7/+7Jkt4QE8l5Qm21GAHLIaq1h5V9S1XlE7b0SwdKsqnWHibR9CGHxVyJBPK0h0S4z9b4t6nKvxo7Vnug934ia0itHra/0gd6/LTy11tm9pf13nUkq7VjL9TQ5/MgAOQENaWxt1/wxy8ygoyAJyJFtpFAwymxnC2i9k5QPj1Lr6YIdtcz2RG8K2JVD0ZmVMH2fuYijE8c4VajZr/8X/OgJbQrYkSBFZUUcgYQhddS+jmMmlFtVZn6PXdjqViss9aNTsCepSG/rmayOn3VjGWJnpKodJyS9jhqIQKq4YbGZromgJ4p/g4mFQwaGS3EbHSFrTe0jfujRonJhMZux0ZGSAkPwrRBT6i4h2FYEASRhmmoTkHCgsDmtf+FF/uwb3DuvwfuOvzBF4PgugdHLvmOsC71iv6J5nNcrfyX2j8CcpuG6GDivu49GqXapD2J/jp+u4TU6k1eZHBY1RDHDbRI+x7RBQ3lharbLkUQYmMg8NIiBMg0Qcw4uCENEkxIEGFIhJlhgYJfWPG4QVZrVHMJ1uJkyO1w/NrU5sRzJj4WCwvX+24G4za1BxL9MxVbVtRQFOlDjyu0OOVqGZ6Igsqp73oUnR5itTcSY1OrKuPX3Kme7+6dsyXHHmKA2YKZdl9IoILSoMEpqIpAlqmC3mGpQ5gLYwYPEBmYrDR+MHg0weCwEKeziSCu1gxAA4QsOKlgZlgqUThgrADFhgcsV2IEWht/XchpZEq975MOgZp0FMMdPawcg//uTuHiCSCi7N1xohEfX4wTcMySoMR0aPqex/ad54lHYhEH/iC3ZCXaDOVMbmUyi05GN+31Y/47uHXGR8O3/+7Jk0IxEnF5RG29EsHpomjNp5XpVBXs6bmULwbIe6B2lCwDue9dqPsTlC7rQrjBWkxKxt8IuU2gEIlFtURnB8gAZh2mBkOx1QwOSF+EvwIVBgZKJwnGUka0A96oU3IJUlbaJNwYhJfd2Ze6z1UDq4YsYhMBa3PNbnsOIAGGvR9yClbtYrOmRnyuCZOqf6diPTadU1RJj8F1k0vu3/zNGoH4n6zj6EBCKUMSCY0YUx2VmZoWdniwKogOKZiMJmDTkBkyEJIBCwkRPVxNEhAToAUICAS7BJwR0zAeHg4zfFLSZJoyo0MU41xVn+KoI8So/HeNZcSKRqNezSn7/6pe+4cBlxtnE1YcHoSl3ISVyI40QIKErvY4Oax4qS6mz6mz1X9Cxv8+dVDFJuBn7iOzyGBZflvHD7iFTdZ24oh6exonR5pqxUKD4NBA4aDZNqC+H6J4AAElQweHzMobMzJg1kITDRMOniIwEWwgQgIBmFxwY2BIGOJMsBAzENOoJPZZJdIIjIsYQlM6kjECDYwUA9ToQEooy/cbVSIhJ+zhisFnrHadvf3+Xd+SMXkZIVCMTXCJBtOsy9XN3fO9VLtXqv1Xq2k1n7vQ16L6fo7z2fLQc5eHmkTn6AAhBPjSaVBIQNFjq04Bgyxk3IUiDtAEKwBIDCAE0omIAM+4LzMnViMHCQ1adqcCbLCP5iWDQJu0wznDvYSYQXxbllfMRa2DCHA8iUkiw4j2IpqPKXfskSBLDT8WPvMKHHhq/ceJDZ2d+/jQIDyPeu9UxrW2u3vrHzinzeeJ/WLrLdPH+9+8PUePaSDe/zfevPfd9Z1rXzn/Vs23/+7Jk5oAFaFpOG5lC8IVLScNzIl4VmXFJVaeAIaUXanawwARuus/HzNeSe1LK99/aOwz1iGggMCFJGWKxPPCPCL7GgLijdyaaIs6rtlc9BSyGmNZtQMdiA9S1YDta8xFJwb3pARGepwEV97nAAhvM0p809ye6Z9Ys7b32ZnZn732V5+Zn6/5o4vX3UCAIbtG8hXwuTicH3y/+5fiTOXLqAABBAAEAZMyhtMSpyMSnTNrk8MZSYMClJMZD2Gg1NJCWMeBfM8EUMSR3MaAeAQxGHAXmHYAGHgRkRDG2Cp5mxIGrAELAmfgsaYcSkMPswgWlMdJyrKkiKFR5InY3deaELOoYCiEDPBkKAgaKbuuDKlSpmbvzkOBk9CEBFwM3QmEQExBEvSKgmwr8aO+cthkZFq9W6whacLC4dIURhEHQsoRTLzMmiNmAgKeSspeWgMLBTMkBp0o/ySBHalVWmu9lOM1S2rG6uuzFtwJK67r2X7pOv25L2qrUThT0Wl1b+1NRqdsV88dWeWoJZPA8slcfiTBFmSfG33KvXr4Z6//18b3ZuVNztLuz3//TLF+P3uMR152byyvI7FufDFv///+UgRwARFjJRIkLhJDYtNhtY6LHXqxozaYZLmSg418GDuRvAWYkdAEQHEgqhRkJ8YYNjwsY8DmMBBe0GgecLgddSxsKQCEtl6g7H4MBIQGRxRFWB2i1FV0843EkMwIIswrxdsYsXGGLDTDtOpYOlBcAGGCsMQhxdcP9zjceyhl/XjnmGdjErFgCMLX3sdu2+juSxiLYiViRUps1gNNFEMPJ2ntwbSNRSxnM53rsbiNSx+P0lNX/+7JE6YAJD2XMtndAASwQej3N4ABbXYlZOZeAA16xayc08AGfSWbUzUHYO4qx4u1x/KSafycge1Up86SNNalMVq58vUXoZoby5TeXTkTQzQHpwJz1f7Wzr58zy/+/zC9nWt2/3rmH//hx1wP3GHGUAdQu4rx/3kdNp6xGuf////////////////////////////////////+FPbeAB+AAAqAECCAEEEDDQs+WqN+gOBAKY0fByPpWEFkH0flr6wyo6NjJMTuIUHMdxcToDQZxbTEMk4C5t7CnDlN4zjxYm1EKpdoaIIOE9jOQw+y8lxOlQM7Qci7ZHE91crDKTpmLCwuElBgNZxzQVySguylQxsYHBDWaKqXFvgt7Hp7GmX47xOH8oUexGQ8syOoLi9n21u4smYDm+fWOJAtKue72bi5QlMTywH73F4WLWxBnhQZMxcwNrLIoL2rIpmSI828hRK7xvUKfe6+v+Jst9L1iGDS1o//ijHKX/6kJGQUBEAAAIKQsANRBSCWMYAIYQcZM2CnAyEBxEGgi/pcFGhPhrL+rLDmICPI3DLJoBjMYfAn5puJ8IYfhsl5c1cn0gqC/LpjPNoEyK0WIpkbFOkw36pNRMsDWtnqpUauWRD1C5HXBP5dqFKrHc6nCfifQMZVvcMD1kdMNVq8XNJKMllmEzsr1iU6oWrQrq9/F2q54j7UZmixsyJpjWnT+Dd9Fj3pPaJ324ETMzLdtn7ysCrmn1bWr9WXYcvq7tePK2Zb4Tusmvq2YK3Opozx1Gv1JW3R3/1VT2QAQAJ2kx0nUODkgRKDwWJSMtlbwPRAbwPXZgFg+coL/+7JEEIAEZF7XT2EAApGL2tjsMAARzXtj54zcykQs67GEmalwaMBYGCzDxcQYHCMsE7BbFrEIaLB+KHECrmnKUJ3H2wkE7Zto5I91bNVpYs9FxQbfLUQWe40Zm2PpZvXNam4akpLKlrarm5pER6si3HR1Ixek32umLRb9alFmBUWtXQ2e6q5kelBqj+x6PUgEEAAFhmIwUGDIBCDiFrWlmtRvsMgys/MAYXeiMFxKFrKUaHWKn9j2ytm7XwrlzjJ2aSnUOXijvV5pMx00hNHO6JiGFRRx73ro5Wnh/0fNQ9tXl7axfd5uju0yKjma1i2lr79HPebQrTr1ey+Vuxy6zbH0agnZXVz4HL/Sta887mbXqfFeWvv/fFuVnpnI+u3pQAKEVTE2iQAFBHQingYIroByIkI4K4FKjgh4QcyCIDCZksyrhbYH6awyLKvwxwNOmNWQJ4uL2fPpUOlxFl1fdMZmfwYD+zhjDveiFmykdh0RqYM5wnBrG8+LPpmrp9hCz7lTVy9ihP0+cL63BmOh3OYgmchcXNZO4xsJ66YOFQoAUhiDvqDIYQzPnpf+AciAXEgJgAF3B7RKkKHYyBljwXaTMduINXSne1OcCbOkpcESQGifsEjUGdYNkpZyiJYumhmQjAIeMJlqtRNQEWeaoOMwqdg4NZi6JvMuQlfLJK+q0RHO05bopU6BRaZsLvnFmE4W8OlMLdnJIOUb2RczltniextKQ7PCLWQu32vT70mnVxI57XzVrrs3zftjf1LKRErthOooPOpMOEWxTuCxC0zxDwl1RBGQShZORNCpJ0wUUx2H9NhmE6UmWgK4OYvOSqf/+7JEGQAET17YYw8yso+rquxlhmQRVWdbjBhzyisv67GHmSAsihF8osxk0GOS7wX09Y85LTaw1FpwDMp6PUet/0LPZCNmP3583tzD5sxuHVD72K8S2606/Q1tf+e8L3K/fWbU8yfHV9rNODJodOYpb1LLzFscG5i1vcbMiFVFEUQAJoqmCCEMRYMMwpHzKabDoSpq1pVRexbLoRIGn41D0EdOPT4SeovizKbEidNZp5hGCJwpQdZRxzMcTYYnSSgRsDecymEmrhKpxeIcy0kUmo5O3XEn6hmSluIhM2cBS1lnk3Id45i0VMR5m/9TVWJSa/vv7q9mnnH77qkj42IQKj7OIknhcXjl5Vz2AAKUVIABKUKCswQhamAREQIZYE79hBO8ywLjw/SwiagV6Y1AH4QGcsGC4QI9FgslnJCh40fAFBt6VQhw72rpEj5N3aATaNxNZqdOKfcNoaVqInd1H/C0LIVny8vCXxtkki54COQoU4cVmjWYFQcapExJp9cao6CZ3vTXlqYmkLVhQ7QS9GarK+/5EEPNsuQAHfgOCqmDgI5iACBOUGEyGwfpiEvKOMgGNkZkuwod0tdX0jgKDIEsk4o2908Am+7g35vCSkXK+7tVlvl5V1a9Q2UKfi0yTFOdOmd3ghbqvU7voc7d3blnSo2trDd3KpnpLad3U7YihqHKQKeWPV9+PTGy7+UOSnnQ1L/amU+WvAyhrxAV1yRIc2HCAFR5JpI4u4xgA5KIpGAADSpQkImaqovcYQABOB0MIS08MgM0kiAllZqDW2n66OOJL+2oHfFbYhrPDbsDEWKlbPYKwwVgJkEwsYLaokT/+7JEKQAEGFpXYwkbYoHq+vxhg2xQMXlfrCRxSgsr7DWDDpmUFGyiYc1bWZnTtG7S4MZWORZrVaMDBhByAUDElVQAhjJMuTN8MT1aP6hIUr4dPzubYEU8ZfSA2ocCnuyXcfgQ6UgydEB4WDwhHxbkaCcli2CIej07KOHhWZ1lAbddcPnWFt62PYXW0TkMXrWmnYyHG9QAGkZYzEblsB46koPAadSJcneCjq5G+pPJkRfpcFIEFheqNBOSGSkZgGJLV1VrREaqXOvmZhQj8lqKDSpr6jqdy0FZ+QJgsAFUlOYBcaMjeXlSap0OgcqAAUMiU3yZC/Yq725Rt1hUakRCBpJ6j+9IiqW1Wfbm1O9rWHQbKJvOIZXMmzVm6GchlhmV71BTVVE9pMpNI4UjL0XhbNzibHURQjwURnPpRTGI8yJE1JSKFSnD6pMYqVmazOONeH/w+EKMdnYC5rc0kiSZUZQlyHwdBaLbpmvqwBdkPqdOW9yuWnRichyhpXua3A0ZhqIcqS2pWQYcqI+pHVpSBF0PhCdUUm2jaaLnndnKyq1LlckQUbKonrrtG8Sq53rYQut3y16jpNVL6UhPgQMMTgh4Sm+kHMYMeUytNaKYCrR28ptNdGisWSHsqkMHMoNSSEoEBRrCJKyFvt4SIQ+W4xKS2l0JPwSzSD/+SzVNB2pQB0HFLCDwwEPMRamrPXynaYvzFSZsXjkszbfYrbV4zZYqA7lbTH+cMdHNRvzY4qpCOkR2S5VPqsHtMDZ8zW4VtmhVjekVQ0MjMqh/CBthg7pLqdHe6n/9AISmkSaRAKdqrccAUCwUUeytLRVaMrVXez3/+7JES4AD61dZewYcen9LGv1gZrpQSWVZjDBtygkuazWDDjFlDotBjEnd+dnIRK915LQZ3J2kmt5duXpszOBIeFg5gMFjoMJOKWFPiZr9KPPJkDFl6XKrkjnxEa2aMfSMn7zyu/tVzdKgT971LFm1X8du5zb/OfXw36+P301doFVP5DHSt2t9u1oAY2MKVBLmCIc0WApVmkg0h0gSJNqJIjqJLDxcAxbgI1DsXL0dlNiMhK41LkLWRXu42yndZ6L/atjDTUCtv4NhaWw1hLqVQo4XQVWhquOnrFMcg5GIgdB+CkmsjLPTI43kXyaWzRcnLuakC5U6+xbwhJuZGPQYlhKwq6GZ93fzfNfOgAiogGQACVFhAQEhIZCoPk0R4bRmGMFpXJZs0+LwLJX2hWczIk1GhhRjBugTk5JGZUBQX0dqk3LpBpMdPsGdHZnun8qnpeFHMixLyEc5oJzVQhCviqKatpnpphrnwlyDRGWk7CUNW3hEQNIS9NCLZdeKbNMLtxoRwHQUQZs6euqy/tVAJB1h/KlbupFJoK3rCjtK6XHTiXXOL9aa0SfgWXuKSG0goXlxokwYDxHJg6ImUMIWMsoXVS0Dba7D7abAnCCjIBO4cTmpOhzMGKSshhveraxT20fPIiN2/p3KUE4IYbZ9waEcOHZ5M46EnnRcCuAppCnESIDJC3FX7jtCZkmtTkaSBUjxQNHorQ+wgQoWu1ca7oWsZWBtH2wxhEV2+0OTPQLEGWouQPKBaKl7Szm4JeLn7kmksucqk7ZopXajWyafrvez0Wfco+GYxkUcDrs/4yM5uxbEUIE4M+lGBghjUY2BB3P/+7JEcgID3UpW4ykb0IKrCx1hI48QMXtbrCRtSg4uaqWDFrEyK3momQtCNtJeKFyt95MyMUgyDQtL0Gs9e9sGO1lIpWCytgVMZQIlBESkcRRud6BUATYF5viJwWBc8ThgNmyTl2JFlRpNKRZl3RwK91ly0oEQkSTXRYYpxftXR+jMQso4gGGWBTexiDKurHiBNQm+U0NCUiYtzwWRr13B1uRQW1ToL8/9p00y3eESqYsxezIEejpoIfi+84UnrJ0AeQEAA0OoiEOCMDC/QVAjQ1xIZYeTrta468MfGn1jt+RxOVRXGS7vbkM0lPOR1gMxsaf35aNypD42Lx10h2wkay7xjnVDnXKSM0kf3fuv7mSWQdlxdY0ofmXumUpFoNqZFV8/ZSSCpKGalkp0eiud2eqEU4aRR6DWuJvEtIkEP9fM1pUgQJpqNIBbXAiKqAw5GgdQhORORoWtI3obxYti9TsHMqmAiCEMdJIHiadD6cP9unv+4ydzBMUUJNp/MK4sgqhfrcMeXS0mk0OSYTLG10Ms4qZ3KzVE3sxHnHFZDJGz3OIpmVlZcRdrl0Qu5kxZqFtDwdWUqsphQs4eHuNBZk0qO8N4lBBIiQFJQIBeYsHThR/ccwFgFCobgONQ+mCxd5lN52TXq77Plyve/v1rk9x8Wn2sq8dqXRJFaxhReS7m628xSTEJIJTbZtVu/WpmdJGdNzY2M08g72N+c5/V1vNv/o+uyff60WN09p1W+t7jH5Q+gMPRfQSXQogoo7irAoeSHZtj+bQb2OYQWY0HbQIKDCIgYNqCe7YB6dpZKCyyHVqcgQKRqSQVQncCwdxEgWj/+7Jkl4AEFl7V4wwr4oHLKq1ow7oQJWlVLDDNAfqsqrWGDfjteLSatx1kid8jmlhArWpR7M1d7AW8DON5A6MZ5Tw8uu5d9krb82u+Zj/V/2r/w/c/cfaxwRvl7fdHMbXz5me9Z/W42NXvbz1Vfvm+vnNUr3BrijU++LsAM6MGpBAEtqqDC6lDmZG/BXhazSS6rziEAGAyltGB0kUXh4vgue7sC5Cj4xEQtHDp03mergr1UlcWxOZO/9+v3zP9zR39c7WjHr807SwqrjkXRvynotpyPkE8HqfxTpQ1ZJ6noRZ1uly5n4KHZSvvwl8w5UMOCiKCqFPXUzoVlgeGqLWPtpG30hUDGEhB4ZSfT1jyExiT+qqsbnW6u9El03nAhUS7e1L4YkFBheNTMB6tnuB6DF65BW2WXWEznfvZeF8nQq/P3E2eHiY1Ras7LUjNVQTitamYzFRVU+xy2V3lr3N62VEZ7mtL29HvwYhgE8UhcyF/rTc73YARMqDiSRKUjoYJDsIVsFHfIBlLEJzhy5I5u6+VxNxdRBWUwYRVeCMIjq6GlzBsncah9G3LSQ6dQOqDN7JQJ2opWD5gQMVWHQIFO4QcOZnxXyhm2pXgSDT+wsylS/TWdB0fZr5ueuU9106Tl+Zba5sd/2HIkJIQxN2Krv/+r/xAAqghIokAqRAITHjCklMclj61lN4nk6KXzLVD3GhFpz1ycJgqnOhCAw+UJWWYzyTVdpRqosyD7FdTinbqHLooMRoaqGhuGHMgYRqUJnn5GZkNn1djvZWzJpYvxP2MyaG6Gfl2EPmOnkrWuWUHPdMs2Mhb1VgpuMLAYssILWr/+7JEvIAD4Vha+wYVSn7q6r1hI3pQBXNTrCRvQgyubD2EjezU1BiBmkKpJ7Ykk60kSQyBO93kTkgHaToblBSGLFWVRZvppt7EAyCN1IlERImLRXRClgsnPGgXfBVDMq0xFvTuydopGLemQUiVNTiFmlpAj1bmrEolMYE4jm/pfBk9xgr7IRuzkbMahnKmtlIfUHpXVm3fNhTmsRuNsD5OBrwxTzrhShqaldAljgABgA0DJxWADLmuWCZmCJpkQSmcjC5Chr1zub7pzOTOShxnBo9KyM6dGUSF4Ka3rKKVHwsCXyZa5gvu9tcJE/xAUxZmV1yb+6G5vqChM7zppjE0dc1H5CzK+h3zm3BVVGVBG5TdeZOPUhdk7mqj3sTlaglmdhCxBHM1Pmu2XBGaXgX+ujcnSXNSSAMcwJ2sOBigHLofc1yy1LfpUI3Mrz6cIJMi+Z05hEw+PIFsNjwd/mErY30d4lnTanw15uJp+LNbik7bpTsrTEPqWri+pFvV4p643ZSM0/wEqarNKdQKUxMamPsDPNljZqr2X28ulxv+nmIXIGawo408hostogBhJQAXKgIfhDpwy8wGpgChKELNAUCa9MocW2BIRakjiAsRidVy2msBy41+Lw5LnljxZqYqaJakKyDUxqbSdHM5mSG5QVfAQp37ZKs5BR6bSG40SSxYnMVcRTcITY2GZV6ql6Ia2t7HuLGao7OL1D4o7jYTq/UmjD8UDujEo5Kop9EejKYaDKpjCehjzPxiPATSUUroAAYIHACWAAU7I6AA2CRctgaOhBzoJAaVqd0ZMLAL7B0alfVIOkEM0VDTttTSqNXHSy//+7Jk5IAD/lpTSyYVwIILKy9pg38SkYNJLSS1gkWuqTGzDyCCKXLViKdpsYKbzkppHMnoAROLTjTq0PhYDyyI83NZ5ISXnVGMvURhSL57FV8tLYSCel1WzBWvyaS+531IrtDLuSEpFpg2IVA5R31h2p4VUuvlj6A0yq+oU61wFo2PSsAVSRAIBVAk5pODqBs4BVkzp4uFwAg0oiqJlMuQzeWTN2LpxCR8ZsV48A6CbCcIFyD7IgGT8BTMDrmKs/DjuyuPotcUrPsstOQORKLSd0mnYLg4aJUdTFeX9sIDy4kO9xw++pnx01Nd5n40Y3NTyMv2iubW+If7HcMbzRMc11uMtjSj8iw5pB4+9IP5mX6H1WRPnUBAAUZgACTBo9LaAIrmL5yZGHqIACCY4E4yYUB8Pqa0a3HcZfDzBGm0vvPRQNSQ0o58ut6NGLI2zVyAkhKvSSIZs9I4oOuMqIxUwysmvLpqwVEs+qjxZZtEO7Gxkqyuwfa7YoIHQkzWsrJTQorwyxt4ovChIRQaOpx1SMLVQYPYJWlCsGdBvdHzrZz+nnQ0JCguw6UVDLH79cAAAMBRBJKdFip7B8eJo5qAQEKeoGCg4YPlzP2UMoe/B4Uwm7Qe/CLF76inU4/Ey/Fqxb01qNZaWmDIHk6SLNIL/QflkifYibf0I8lsn2LSR5YlTQIA0xQMs8JhU5uLPCgDHqOPynvzxUAPETYiJBB/u3HH5JMzH5VOkY3+XEbxCakE2IM0amfQ7FsLuRWgBsCgAuz454QwAEyihl5xqJ2QJfCHy1iyjPghEBYGBhJFhAkAYQ4xNTGC8c8uFxQvRatMC6X/+7Jk+AAEm2dS0yxEUJjK2gVxI6wRwYNNrRh2wkIs6KWmDbmy9CyQxgj34qOGUTzOO61Fdztfx+C1QbELCYZZX9yIIAMK3chYEJUIIHgZMFnspUMOShO5jK1aA6YMJMwwVSaNMKkVOTfJyUjNVLdi09lIJCFGSprYOE3f/6/VAAB0PAYKDICZWfmXh5i9QUDgUC0mgxCdgIHW+UvTDl0AowuRAD/ue3B+IYe9cKmwJUm0gKIGE4llRwjwlkmym9GLgObZxlA3BUKKLpP24CgMMIyM83lrtt/FFp2y6omm518u12MgorCWNFFihexpTujKFbB5wFSgU+xehhLhYsB+SexXJGyWk4g2TGF1uYRvnI20ACEEAASVCwGMiPSFN3FMejEOUrASMMNByKATAhI4W/Q+p46xQfhxNQ3ESLwJndRpUrDP164mazdcVOZ482Xcr6kHoqBFFIiD+lRlk2UlmBms/h8BwQEPRessgFF0URrWPp/zabcaNMdOOUlf3vjPk8nOOlruXd1/sQNXWdnypi8aW5X3dl/GbTMGS6IDE0HCJ+YSu2wQUPEQs5ZA9QkL+zMNB8EZoOoCtiPdMuETKYikUr50kJ5QFirgN+/z3QqBT4dZHxo8WtnrnnVKCaeLY6chrXTFFeyqlImXTNmXINRmyoB1Xa16COqWWF0MC2jzX3zI2rMOO5NN72qWmBKli3693TsPlZkLZPp/KUupGGmHUqYIlBTFAuv+CMzPBBEfVJ7bkXQ83JaslKCtpeGLSnPKm51mHSGUVgYMYEWoEJMoZMIJUaMQQV6t2yieDij2QXAxHL5ACFWZgXNYgOHQoEH/+7BE+gyElldRE2kc4JVLajpphngSlYNGTTBzwl0sKQmmGjEbNsyscdjgosXnag6JZjGWrNVrKFNKravxrSYqdc6G0d6364PXU+Uz6kV2m5jy/xElrkUcrZ7dqfMa4MpXyI3u77lY3zyYSX4qPLvl6s5+/jLXrtohA9mdtfgnOX7Pt84kCdGJ1ttlXJtky3aEYUH3ki+lbUfGLpwWhUM72gccvrORh92ewvkc+JTdzTgRuglcppIzhqoelDTR1MtplCJVUEkxxIvg1gsdLirZBLwGZFqUxPUsR6YTZ0aRlK1UW9bU3Ja+aZO10Rf/CRPeug32cjs5MQpcchkypHAuSVFRYSElpKBsciZJqsA59DdAHnsE0oUQTc8MIWs/biQSCgSQXRQOCDRq0JNRDDQxjGQTTnhXpRmKD2E1Yw1F9azaQl/vXhA0tp60P4zvI4rRrlR6DXkDQBhFHnapd9bQMZRoNifH1CBMAVZztrHDtxHGCI8ua8ouTJ1w8a79zzFdVyt3li1INdO0uUeqZLuUF7SlGGMfP8px2fU+AVq3rNOytTH966IZedPEMxXSyhxy8tQ39ht09Eff7l8AslPIgCr82O46OIwY4oFlgAHN2suI09ww6BAkYjaVItneZ0m4M0JhWEXgVyYJpPqMfr3bMo67isU2psHTr8xzJi2HHeVBJbM6FqY9eXSGW9kcZtCJFcpZ7N2v7Lfa8EyO0Sz3VRBnpEnt2h6MgvGnXwIhPJLNuOqoVrolBuN4V+KKFj06IuRlis4wNXbnX70+MPXVAABBECAiIIfZyeB65IELmWBAYmOAVeqnY0YERQCENLI7K//7smT3AATfX1drCE3anKw6Z2kMvFJ1d0YNJRdCEixpZaeNsGiVLudayCSf2asKiAs5GwcuMPkOdb9Tvxn3WtR7NzvUsavFGQ2YoO4EcK3oJh4FUBjwYPIOzAwQaXeFhMHZm5+nPcLYW3JDgaU8jPq+FLyh5llwx+l+jnFok4FJEjxU8t/TXUBMCDjoA0HGBn9ICE0SD0K3gMsTTNwl7USWSGQoyTMZdEvAY3SuNtJEUiZV1wXLX9BcJjbdVvfXxliFdUHRUyOomZoVcpIoZ8EbJ9ZQE1VKOCdUEAglVE976b7XERW+IxllMjCsfM9O7WFhNMrq+WkdVpcuSSsoxiRMKGpMoZXMiysZbrpW1izmm8bQV4Shjp1aRYy7CNhVpaot8sKWqxsU/xjnggnl7n9ssRWAAQEwgEI1BkXJqYBohgFLCKIW6TNZtCcQEJ2Og6Z3Yq3ULOeapfjxu/6fgVqRoN+8j4/4v3se1sx9Kh5eaV8/k17Yq9vnEXWIsFGz08tr2v6ZfefwmMUbHJwzmefTIivBTmunDTvnPP6+XajwL/JfCL0va0MUOH0DjYoBLXLBDQDpAJDEAEooCOHjimTInzJ0gaAMCTCCacpjSIdGFj5iwDdzBvVnobMsgoaYzkveoqiIYyYxC3luy6UsBhrsZnbrEWEJGgslYchajROavrEAW2SimQUePxP0/KVXZpYv+aiB3gVSDg5ruVgG3RRdaHg0PYHPABWdF/blmFXJjsDN4JvYpucKGxdVf3WQCclCOJCaat2iSBGoJtgrXmPAhixuYqJmmAZawRAwACo2BVO0CmCy0mpcthANDzuXhGUWBP/7smT2AIVhYtCLeEtAgeuqWWnjfhJNZ0eNJHbCIatoVbwhOHWs8XZUvY3yhda9g0e7vU0XfvYwxBpR5nRZPy+AM7aGjLMCgbxBosaPdrpuCCEJS7zWqLl0mx96JDc360Jp6i5Wim46qX22j6Vb+19Yu6jmNokVWoaOoOiwuRpNqQQAgEgqIJTlpjJQTCiTzGwQQKB6ggJCGRCXgYHYUAjgsKgSXF7wgHyHXVUGIgFd9wlAklOiUXww5O+h64tWHTA5qED3aroIDvSIB0FlNjFUH4RqC2BBqmdQXUEto0o7ORIodma3LNnMyd/zP33fiX57S58x815bIbnwl/Rusfn+FJed/+Qh5Qby5SHCijfoEDR+nOWlomJPDNEoAEAADBiacI4GedTaGXMxkEWAsIaDBIIMeF06TEBVmoFGoEEhSmW0NHKND8wCOD7cZO0Z4i/8QajTKzo1U9erDMDfjMJgX7HaExalkKSVxXPwVlqjc9WpYGmqXksi1rp45Q7kHSlHQEEBEKJY1CA1QVefUqOViCqj5GS9XNu9gee9Y4X1QpUmpGp//CUJmYBVHZh9UJc/mwAAcOQT1h4wlDAk2auDKXM0JQI4Bk3A9C1CcDCxn7A0ohKaYqANyEtugj8YEiPOZUoCwtB1qrWIxOowzEBSOXvSQAgCZEXZQvXMSsSAEajBYEqGDBZqRah7Cc2oxb1D6VJDG0akzxSrKpRn6ept9J9cRkuQm0667G6+8tFUtj/5ffU13eNVluTzzZ/pyH0+W15b5TrbZV8Va28dUfTX8T26udv63AkEAoqQUJHmWnNXmsOmHNmESAwMUBUwwh4tNP/7smT5BITXXtE7TDSglytZ9m0jxFTBeTxN6SfKEqzojaQPEBp4RUany0WsytYGCJ+6KAXnxi+LEI9CM2iw5dz1HItjTVla72dJQiDJexFTaTJsGtm/1oC24aBsrDHdnLTE0mJCNwgpjg5uaHMp3Niy+rnqOXemRzpLF8wy2SNT8oyGtKfmRKvOiTRKurzaABEAABJJSc5YTGVgjGkEGzWHzAl090BJl5gqwu2KCLECtaIsiiYWABwEtnXFIC0maBWTFp0lopW8Dq6iUbo26ggQJMFJmS5LfgK5dQyziI8xGopv9U1PuPvpJdPqCI7LjBFuUez01PbKE16RLRzFyXPFL+iHfbhDvqMvBSe9876069yezSDT+6gRasrnqkN/5LPKLODAZ2bSadVBWVa2QT5b630W6AAAC6NBx8IWbgmGTE5jxYZmoAozXK0+uj2KAK00aU617R+kJh58XPtOIjVFWky9kcNQ72GSYAsWbLYObsUylufMIEFHoPCYE9u8MLC1xrC2EV09kTNXXCiFFfZO6xDSMV6TZV51X6f/apJDKf3+HrowlxX1VQptrs8JaT5pXEnAOKDq7k0vH1AADggAAAkp0dGT8RIhOzQjA6d8MADx4CL8mEp5jYqaLRrwqSCaQxeWMaVVAZsQjS4xw1p8YUHeVhsBwe6q+nnrzV2NLEUiJ/UQtHWhPCRR2zlJ8WATQ75FNiIj6kl0bU+WIhJHZHMpolyjkIeS6+2iZQW0id6UQP8jsf4/xVKZc0JvZf78a306VZNq5I1Pf6u3JnPbXy2dy+/KUC7ppMs/x2sg+ksvQC32q0UVAZlEXw+/IpwnlP/7smTyAOUtXNFrWUnyiAr6A20DxBVZez+t5SmKIa8nzaSPAemnkgCEnwhiKlUxUTlrCFMtB735R4L+J5P1EiAQwd22MTCPFyczZ4TDd005JJDczjCN1mxriYtdIjZE3DDBnDkzEFRcY77gJZDnhwzGACQxZbpCFOuJSiKasWaMCxZiM8mQsp9iTBrqcPpIvys+y5/p8v+RQFlSSH9/GXvyADAAAADMwNE5Y2DEr1NBI43NxTABUHh4YIDZmRumuQ2EAQwgKCgpGF4ABgcsG7hoRZy0rDo200BHBa3RlzS64YyQ/Zs11pxMrbo8SjL9T7WHlfxkrtsQcCUS+alL9uAw1gztxtUOgF0Eah4AQT1hicBXCdoxLdkbBKfeWxrAnWA4EVb5LD4sUSFx2iGvehw/DJD107do8WkWbaNuXj48vA4VUd3CabyhnduxOdUnpj662N7X9Zu1/drcO7xyxOu2+bTeCrS7FozYisdrmbY6w9zH/LdmlWiWgCIgEQSk5i1hzQOZEbmJAxhgCFB8LCohAoeEYEX1RPQgBLNp86OMJ1DdcNosGmeRF6SlxBi4sk0p6zUgYF1h4i4g26YnbPSDWNpB41g2/bzYrzs97aHZJ4jHTz5dtcZy0juHsZfaCOfZob4//+XcUlg5fro1pJ/anHR+nDFUfvx///YCEbMRhs2UDzGgTMAAARRIwIChoSNoYLEpkcEQaDQCkaYBK6JDT2JrUDClTy9h5CIEzoNL6M7cuIyRsMaVqh5iL4OJQrBKRceGXGQEK8lj4u0xSJW2ngABNMqmRYUqnweC+1goBm1VMcjVEkAv7msHg+XQwKHaFv/7smTpAgbEYszLmmNggmaKOm3mXFcdgT7OMNqKzi+paaYbXKoKD+wlBCO3HIlD7YoU4j0Q3HRyepLPSBq6B60tKV+GV+i/7Un42v57e1XlvVsYneQ6PjKZocmnZSd/aZs36yrdqAAMAsooE0w4oyaMzcILAjDhDADDDikH0lFRvqqOKLFYsHAFvu/IoxCPgJpj60NR4OybjIFEaeliKRocHV+0VI4FDAcTiyq7EIFk8fdBlb/9a2rwDfiWUnH2yyFpC5REW5PDclKWH6n/nbC1cfO3XrVxfHPYCePis7LI/o5iP9/K907f8hy/xoLMxIZWVLT4TiJ3Ox9Nlu2Omex7f/e0tlT2evUZWqa9MRqT9emKLiMQTkznKgAAYzRePnSRoOCH0wHtIR0iIHiRyGhCLlyETTHgNj8IfZYgGKInLmkCIKpJl23ZXtnahtns1hBUumZTDLvQt9WUuLHJz5VA2MpdGkjV4SBBeyAwJPkqPNHjSPpFP/lnXhFO3CD4rCit0I/7H1jpEP4/+8Kzj50wiTTcEP3tBDMrMaSaUd596mj7FE9BKxrhAxsBAUPcg7I3lzI3CqkFS+xAZGOuJ1BHjwH+f/q+/NX4lSADAAAAASqYbCn2tRrp+PA5jQqFxYiUEqy5AcKhtCTQANykblEjBrlxZYon4zXI+HIuqng3jBv10wsRrWa1ITdykumRHywDBpRYmii8WV/cEeZaJBVImY13r5WOjiJZz/e2kml9picJatknQ/3f02MhsGbgwwzmF5eTCfvZbS6Oeyqo30e3lld9AEdr7bmoNrepKAggHyICQbTbTRwKGRh0U0b6xBCrzP/7smSshgWNZtCTZn7WqyzaKm3pTlnNizquaeWR+6xpsZMXCd7bGxxAGdvcaDXAwaTRgUNjbAwsGgoDHG5pp4PsJWA5OWVMD8aM6aqBiQZsg8qclyS8xEZgdMFcC9azHcBohuVLocCE2RLKysDaxpLKuRT7cOVTyUYIaxiYwTja6nMjlnJLdZj4V284Vy+yRk+Wkl4MRSvqOTma2urauFXx+RqotvTk0rOhNNQlIv3gOLQ7frkqGbOFFG0umhEX2wHTFw/zHiwoTK5VXnyv7ZBbokjZCiL7w+4NLNT76nVkSWi9LWEhXzbE77yqmNjc+/nwLGqO9ACgagA/iRh9E6hjeeCFwI4CTxp4zTGlMoSQUubOrey1e8egSklWW1G8LVvkkq1tKdpBX/lcoy1uqvS1jX0YYVhEictOstca0XMsNfbuXMJAEpiLQTI6CqinkcatlY1DlyJohnpT3lRtnytRWaxs4x3ooqyu+cu5QWouazL0p1dADo+RB74CwYEoKdHvoWEBaQDBAz/E2QNFkSQFuzUwyY7DzxjokBa4lFVFgujJgj4IeS9X1K90M1EoakSj0YH48qYk88oUXlIUUVwsEiGqoiQy20hWq8TPoLyflJOZv8KDMdROKj1i/x/ReWEF2pps2KpfGPOJWehiEZmam48fBF9tHpMxLcT9VyCcX05Ocvd1y9yQWXquX/Wtd57IHYViJbVCPFl6RuObIQOupF51+2xmavxizB4qxegAEIIKyIsgFmhvGgPmnHDIUEkUpQcYTzX0zFFOLOSljMih5HDHc8goRLq0/UUBMpM8KA4SUZ03jKkhPn4ZTquaiTQ8rv/7smR/DAXQXs6LmmHwf2u6XWnlThd9fTguPTNCACxoZbeVsfM6uTYVxELCQ5MVxAzDAi3MxFEMpEX1dyy9W5m5lbvLTI+nMqTCbaSbCG0r5MVL5BdhAOznZpBzDXbiYAn3JIYNS46VTUABPlUoOOxEBTAYgEBhMhidkwcKggJGFBuGA9zXrMCAQwyEmS2FKSEivvKEEYqSayREJJUTXU7YdDW/P5bgWVUGO71EjN50Lzjd7BgZkUrY51Uyk+SAxr10vKWn66VG1SEUvmwfamXNE3yOximuJcapnMeYr4GHYVpE/4+8e0iiVVi1IuUHoumpOyVChi2oisrMpNkhOMWWDRL0IlUaqETWKI0GwNX4rMINQoE+KhmBYioAADJIFBMMZwG1maDwcHmABQhCjAwVIdIRKxTZc8mGAZ5DRep0c5MCmOs5A989GMV6kRiO0HhmG/YnXvKTm9Pl2xzbgS0pWiILuys9giNHIWa9kuMUqoIzMqSXZFiMz6LzYiIO9SupStVrd5ULlJSc1GfES1S2Yz240Vugo+rWQ2oAIMMKIttIqB4oPBNgASU+41rqJSCMRARJEs4HAYMSWh6blDPksectJGvPhGaBzpqzLJVI8sZ3WdCEnL3QJYXDIlE9iF8CNtDnhRjFFJZ1he9V2lpSWvRLHdYV7duyFrwCecOy+7F38f1QXivSetLiqf3q8m4gc8ctdFTNcoOpjPvD58RpGZwgg1cIIhZdPAKFRp122SR4vwMIBKLcCvJgFQQZigPEMVI/4bT2UuVvB4QWuiO1Je4CLaeblsvOgOoubOLzTj03+jOzuKipMlupRiqua7nz5P/7smRrgAR3WlNrRkXYbmsqzT1jfxLheTrOZQfCFyPnpbMPCKj7Hkq1SLU+n2Mupn1Ll/mcNV07x0PPvl9Wd79afGOxU6gJTp16BAAAsZpQmmQDATAcWSJ65SmPRERBJC0dAA60bMcIWEDkihiGvW2KCuNF3JTQVilCPUFNRjj9yb2pah+7Yo0wIDWPbFbKWiRxysODuBolMqBhptOhlSgXnYQxl0C5qLDkO1lx5apyl2LxXIh9WfWxMfV0WGu0JFZ4h3geg+Wm/O6gY3xf9dxytVz6r4qbquOuWX2HhJe/hwAAwGUVsxo3PqBzJnkyUWMyIS1phQ6NBQ4BAY1W4kXHQAHolIdnOVuZVegTpCFQfLWkwS3KgmqZbDTeTNxudPMxqZKoDSzd9ISmgagAi176bZbSzlYHYXkVj9jUl1QzbbzycmmQ6s6//+P5mUEqFVzhv5Ead/CktDGNYQsAIBXh2dOlazvpAAAEABJBKcpgMUGqgiYeERjAFHH28CAYVhx0cCChwASzS1MUQmuC9jbtsLEpFLl3FgBB1Vn6IJfSEFRMsKVS6DipAcOowFxeUsaIkYvcYZiR0j9N0h2KeXR1R3TfueZ34QZf1aH8mZ3hjIPWa8pZn6y++8yKp+9n5+nJbjVQup3tQjBJOcvD7t73pS7uszPfFJ9LBl0dZUXkEFAAgSWo22E26MyMKRHZPIRoVhL9OXFWWT7BJclJQD77wsP1FR6GEYoTAqwaOhcEeTVDf3sBxiusKUW58W+DQOySAuE9X/MJMyFpsOqqRliztBlYm2VsVLCQbsvEetcsYL853/S6b/fv33bq+X7aEAAAAf/7smSGAATWWk/rmklgbUaqbWGCa1XRjTTusRcBmgxoKbelMCYYYDqZujqYWlwDi5NkKjMDgxQeBwLgAIwcxiaoFCZEqGBICo3DjGAMBjLbivBQGEgZc0xoSlsdb15V8upTKHwTNxxkiNStM1nsB+RoFodEPPWJm4mqmGXP0Sj2I2OgaZQNdC6L/IxcRNLFEy40zMDt+tg7HUE7jqgpkzTSLh3xh8NvXUDSMZMr1228zEWvHXwmMpvGCIv3KIKidXFA8HwNHVVY5ra69yG5UAAQgAAS3TAQk4EcMnYzGQEQHbOC1MkYmW3PsUt8IGaiXZDlSqc1kmZibW1CXaMsKqEV2NVkfWwDeTzFWsUJHh9IcCREeA2udLIJnxp+CiG8u0v6GKi95OGUE4C6rN1NCww8FqLj6AEHBIBSbeMGi4zWKBAGDCAWMa3YWMAOD5ZA06z4PaGhxdYGCvc9D+O6r2llTvrQw01p+ZVnS3462axGpzUJGJwjRLhVyL3ImM+jJn2hUjZPMkghMGM157I5PzViQupsT1aW16WvPiT7uMPWXtU0rcEG7Mwm34r5mk/3Uy+/x/v1vhCe378Kn0o+8SZff9Xywxu0Id/UcmVGGw5QfZXWBAYJBKTYpghZ0FBpkA0vMA6DhQ1Hh6WpJugydAbavpj1T8l9jRQmhuqM/X8SkMxrSWbLXmw4WvMhVUXJ+l5FllTWjSQlQqHjJsOIaRNS7llkJUKqwX3lkLFu3//TQxdQIEhMvKk2AJhEYjEAjMw9ExoFwqAiEMAkclAXQHK3N4CAZEqKovkeAcvkK6I60/2fy9qFeFwUmG1DFLMel5a2hf/7smSfAATvXM/TmUnwX8R6GmnjThMJaTquMNTByq7otaYJsRRUtnOUPWkWV3NhO3b7QyNUAcsn2UmXBgKQMWXeMQM/dke7ffw0vv2Ismnug9RG/Yu6/m9chnP4XsRCGcuMZohsdCIfW8R4KiP+9sWTKQ05V4ILeXEGq9gAASgAKYCBMEYY5BczocaBmRVpBpYwy0gvUxFB6MFyHLHw7CAZKLcFtJIGoUM+h2vk0i2JgnZd3mm2W10K7NyEv0nkb/qcQTt6lPkav0nQhCE33oRjoQlqnzknzn1O+c9jndM753/yBCgZz3IqKLcR5k/aAgBAAAEJQEmRkIyYsALCGyTxWKqBsBWqLC9tdsyic1CfrvA5UiwlcTan25MKd+J11eut9G6vsr3qbNp6b26TuNhyjFIF90ZfBuAcnmb9X5uvXr16yeO/Lg+N/zmiGqWOOZSyQ8hX/AzBNH1/IYlvSkPG8uZP1coGJlVL5gQxwPdCz/TyrspMogyGFbQxXxFXGZHrdhkY+umix3k7R9jriRmAggmhLK2VacgjcU5KA1A9BwF8cE4cj1kJWTtaUcJDNtrPbMNw3em4avf76QAhXWam5I0+zIWyxZbhgxB7FJO1mFPxBkdbm+V994xPcpNyu19JIp6Y+cqX69Pnrdc+FmPTcDF9dvnzprVemeEhkTSgirTEEgKwuZxwGdP5c1YOck6qRJBEAQd28HA372iHBVI0b5xvVen4BIEaunUc60sz9OJxUSm+cxtcwjhZmU90vpkFwe2b2ZQQWRkRRc3d1AXxoYHBONLa4P2Bv04KBPq8YbvZsBHEpZPSs5fB+DnMZUZkpf/7skTCAgZoZ9FTbHzw4ozqrWH4v1ppl0Qtse3DFrPp9ZS9+ecBLUwFjppjIDMJarTXQiCwi73nZikW8UeiMGT8qfiOSV37dSrJZHGHTn5jhYNNNCjESCXHJsasrXGWplK2X1jR8hD5SsMVotTLSU0GWUaaz34oT1RO80zU6rET5XUnnooLRLeXLPE5zlyMwKBylsc9QmF5DjtxynqxFSGYhqufnNZCM7jOZeMpQvOG6Gzp+Ays6ePSI1siLa2qsWKw3YTolGYW8ZRyn4PpRXU5fEySFHKQmBgP5TjJc8GCekFRqtQnWqTnMqOumw/i4srtIiSELL0qEmjEVZqb3JPLaXGaXpPLhSFzpVFTLLU+Up9vGaNFpmJZsxNu1IxAFjH+NBDUVQaJAJKi5DFBLeKUnKqpu86s6w79P7GeODK6OWw6bxgVHX8iUd9PsGm1F6+3it2arqS8cqflq3w4w3DECFEKm1bpK6TcNoBo6ilkgMLisqu0eMcN1es+9WtRqxuYGKA7gPFe8g6eqeFOytEZDlOZz7cJVXwpkapUY/STY5SRVFCVzuK5px8i2VyUK7VzIqX88JSKI4TGUsZXLp8zwVWeyrLaihLLpJqYoVQ2KdoSqMYWwilA4LKzNGfYYI8fwq6jwIOUlRQFRnplXWlEkN6RIgUOl0LkhagKiitjiOqzmNg4BEZubnuc7cxKo/AFN/LFse1y/BgN4CTUcGDIOZRc7rG9vmbNK21gQXDb0t7+uQYlk5pxTSUhrwz9EE4yGrxleUVU3yw6R3cVZB8z0m3y8u81/M8rP1D1F18TqPKUNQaHjG0t401BQn9D3/1jaf/7skRFAARLXdZ7BkTijAtavWEoeFChdVOssQ0CMKyqvYSaMAv//fspJAKa2EuBpmJC0FPoCJcgEZw0JmEMEIlCpZUcInVAYD0MbD58iVG0R01bLTVWyxvPEK0KDjmmy22buSXH54hSCBnx9cj4dBleWITseIS2sJehA+mgq4sh/KFL7uJFIrdJ2LlFpH7t4lzxS3lYW7gyIVlVcgxDaerGiUKIcIUCDXVUyBLdrdugjSvWXSEkAFyAgEgAZ0GlSxD59oFLwvmsasplNDc4WgOjhMkIfJKlVzL7hXXoliuOEWU7E8hgakspgjXP1fj6myUASLTpvpx1SUfUZL4dG9Na18CE/6xFU08isptVsXV1fdr1VzHVM61Yr1MUisa19Ri0SLOo6eiC6DmRY4eUs8QPBNtNAGCLEq5v5K0SCw0SArCgGKLP8uWXIaxFlRedbDKqDOs/DBZXD0GRJLCgeB1U24HxQaLE0LrwnjyKtMstR1AiyLyzcYkcG1TaFQDgJdNZqUJFRbvY+XZFekdZ/hFW8oUO85kt81v2he1c6nM7t82cls6rbHZOt+Q/2sat2P4JTVS2N8LxwC+KB6fEor61AAJkBcIAAQcNbQbYOGcYuqYJwNFCAZiVM1Z4040WYcZ4pmtzO1ZpWK1IGUCr+KiccYQosu7r24limk01iGz3/V+Tpm9TZkPPl6Qts/VUu8zlSafPORIa3LlRwjIrbQxhs63pCZGyq2+lw9DLitkl0OuSESF3hE/hUgYdJFUvUWsVtV30kyRyVxLaF0WtLJ98BM/30XjMsL9Y/oITktm1iJAC6PmEM5MmrG2IyZ3GsQ83ff/7smRZAATRXVFjG0jyb+s6jWElelGteUMNJRNBwy7osZSVqLRZyKcfADAWKZbphUnVWJGFCbdjDPaa7MiLrbS5nNhjLdboVlMcBh9kelJ4loj1rIYz5WvTp6yl1dByufS9SLVUup2ahk+qHrTN1Kz0HkQYJCRbqUieM/sjJY/hJTZxwxIUDG5/eg1UDiKRiNkLaCXygtJec5TsTWXuq/0y9vvSBRg2eBpYdSOuzKggy0DW0ld0mev0ajtd3udmZlCe5V3w6p6MCRO3ipXoMFrghNtDaNzzaWfgSjOCZHUAFJD3LUr0VGujco6ZyUmQ5E17pMNNPNQa1j1uMY6g1MazbtsbF8jutvIAAuZkJ8QCKoZyJGgAwo0XEWhJJlFKqdSEMNNSEfVDoyJejaB/KGFDlRu5fJ1GHLnleqLDPOzPpbUuJDwBd3Q6mTauVH/K2QS2KVFKq+gspPHqICzupTtMcykXjWRSk6p7ylxgsLUu8bOVAkNqPO84q6oAIAxVQIaKTZCIkLDGwU5DFGllpCmQ4BEQpDIKCYkgAi9uJkQAPCWLq7w5UZg+auKs3BcDMieocgBqUGiaO4cSvtzHMjG36cP5iFSE1NvZsK3FdNzhkf+pJRldIkW8j79TraSy6ZGM+JoktVKCKzt1iRIovVlGxyMXyirkyY544RreB6MhL8SXUCEOOdxEzeOrtx7gdrreoDFUh0RJussBVfQMaaSvyFBucJYfSbiI/rxIFzT3nZ/aDAvvK8dBWUlEX9Le7zdmVTPPGCMiZgQjv/7EZKomweAnJ2uDR2VL8OAMh5Xyzn//+n64ZDVZrfjQssty6dGz7//7smR8AAS8Xs9LaUVQccs6n2GDTxNdjz2NpLVJv6unpbSWINThGex+3DWX5Aw4BHmHodr6ABAik3RCBgIQNYLWBmTgxsPo+6D4BACywYYN+EBTKguBV8HgVhQCSxyIupgiPNI1Yundb5zgUjMMqMxICj2V0cXrzr3A16YEZx8WsuooDXOKs+1Gv7EFWQgg11GxRflEI+CD+WPMFHd1mXEjPOWNiDyJOJB10lDO7Mo5NWLy940wgsQUSH3HA6AKhoKodKNGISIhuqMykIP4Ta2ACUq4gAARg4MZMsAUhQScIbA4TaPDpepX0vzq2ZBNu0s6JyvIQrWCIjGv0m3WpbeRlafRN1MqTuQniZDt36kmOfK2IMyQg2i6n96rpcsiEZSOXK9xElimvarRiRhS2ZkuUf07lPuiM9rtUxYoxB/oBhVIBlkgFzofBCcZFYjxei1Kl2FoXOSJh1O2IV6yUSQNS7ebtCrrMRGKE7QJj6psLHoFokrMcE8ihskb8m2ZLjTW3GD8JmIRube2k/0gajJMyOemf97nbLq/ec3MS9zV/pnZ11xRxfmLuV7WhUQH3CfDpvmruKf33ar29qJ3Et4sgiumuEjtqJxeFCGlK++t64AcBCogRYWm/hG7UApqYHWLDTEDGSSIHG05C2EZQG+4JBYcc0LDSg1FUSecLNK0tFuTBj0Dynchz7Mw0mYRkQiK6DlMDpZCMq3jAy8PEysIzv7ZlK0xe53UxaCY17myDxjzDu1lIU126JReR33fsczCixrDYZg+nUy0CBMkFwqVAEXEk4YvgUhPMnY+pet/ktn/TJfKugnWHV/Wfan680QYYf/7smSZiASJXU+zaVzSeOtJ2WmFXhJZcT8NpNLCCqvo9aYKcDnVdCgYejIAoJ9ogEjCkVyR1gOfcA4FkwrAZRCOCI8sHCz2M0IVBgJDpmmPBSH4Je48CENPu+fRPSjKzvN/3E2d90UDa0T+WBVPcvfGV9Kv+fHd8d2bcPMiykjsfZU5896AYfGLUdEbOFAQs9xFGUkSIyQBnDNGy9AEGLhHQadwNFA4MwtH9vp5vl3qzF55BYvcUUYKw9daQnq+hEM+BoaGZhUzeqAsD69X7HXO19lkIkFjrS2/AsX/Sd16WF7+zTr3+zzFNrLa9Zt37/ShHdGU/VPRN7EI5zt2vdt30b+i/p8/yQQuFyKh5UC9dSOtvViaSUQRA7hCEGiiG9q7nrBRRKKdbrUgE8TaEnVV+9YNvlEiHCkJrZfV7SjWN4OpteBqg/Uqsr7CWCXaEhfHGzoMu2FDvyhVGIGJOUDPLqSF0yba0q/RIo5epd9PT399fe35qf5kbFiFfY/x2/tLtDr7037d/7fY37/77QhH9U6YEEWQ+Xh59cgYGS56F74fBCSrjKsSSIhcc37zCQZoXTUig037MmfOVGnjb1hLDbN9ucQrZSqy5V/v587Zmc93WlLDvxTtdBQLGIUtpuEKsyqWLqgmswGIkeajEPAmdAwsK0tXp4yck/UmNdPs94ykFegJYI95Xo96h1O8iIqv1oz3s6b930875Gf1OfIQIHHYZiiBZgqT9lhQMNNQB9gi5na5ljZZoBPzIPpdI1nKKKTc9bU0lk+UvbErU5uNzGUznwTTv/2VS5UUMINbAFdOkLRBDwWucFb2JTuAd/wef//7sGSxAASQXlPTLzLwictabWTC1BRNg0mNGZWJ2q+qdYEh8AuTfy73nidcEEjnKWCIeiwryAHx8BKaDfrHrz89+6ZCUNOkNfKyrpYWlJ/JN3MsVZffWMUw4f+aORWa3OTr0zHUaWqfsd5xYDs59CAy/a6U+r5CItM1dL9LclQqgCNvMMpglFwYSE2SXgBIilTVgmNNdl0H2Y1qXRF+BQJH6HMjnmeju3dCFE5iUpp6vsQLcNF+7Q4wu+qb/3hK970pmGVXOPqIi/x9Sj18TcDqSbe7gbHLo+4jz2LpfYXEQ1iH1kWjUMEyggMPrGVQxkHwcSnhTF0IVs6CbKAJxnIaWFAyY458xYEtmIgS3SGEHt39HWL+3MiDVv3IWwFz1HAdD0QsSIWEjZNfizm0kt5Icd4v/u4P6Fp3xQ5yCcNun5VQjxEGs/v5CKN2K3ddYjaqeJb8Zv9AW9SndEIfd/kOkjRS1y+eU6/UYypdnrZ8qOuTTJa9bGdxjmF0U9KJNbkfK9alY9T9QABAZQyLnCiAEYLAJgQTivpOkFEOSCib3bZdyyeVYERpPOeXtNzpWXOPFcJQapful0HlYvdfzfxPy4565BFtOvrvmpN2Pb6DcZHZkz+PtwpxP3/Iq95P84U+/nb2kfP7p3pTI/sLUIGSDixxvSXy/p2gAHXEZHSSAEaOcYgJxI40gpT2noQlKlY6mhHBwZFpC9Lere+cpULNE64jWRGkB546ib/bdqmLwSDKpJJdE7K4uClHepNAaLVyt/iLNZ47yZNhSTazb+RWtePY472G1y0QLF8LddwdfCv1rwcOna03lqlIqRotGMLn//uyZL2ABIte0mNZSHBxKxp/YWN+UTF5S60lEQHsrqkxlhYImauRBAg1MKit9zLyQbXKmJ0AG2/zdqgI92cA4sOnKPEpnIsSpvFnuSXed4EFQ/Sw0utpLbR+SHYZVdsSkp7qirvOd0M6RyMGncUKqNp2MWcRCAMKIiKqoR1YR5zrHCpXY1lpF2WqJ2qVXxiJcj5TNUroyNnLUO2oQ2ID6qtnQOug9caHk0BnquQe5vUqBCmZeGZ/99EVQQ1NVKdyh7zNUzQuhmJfeTI3v4HDW7L5SyQKOitR/Cq8VoHnV6KT9rJ5Mw+4tOIkJ7neZSz7R8tmjca20rYmg9LNphfji1Zj3MVqCQuxjB9mMjUiorcyNIjxoo6DG0FEfTXeYxrM2LrURbu9EtYUshla5QKIuQzCwUCjkEjkUoidPYLABx3oaNyNEEDQAesmJZ6JDL2BUaq6wqu3vZDDxfqii76sTE49N74kFYdmCqDuy0u0pBtnyVbpM3Ou7S9DlOHwLADhWxzkacwKyIWqDayk7qCPlKMR/b/GRQLVefwnRCw+gp7YrjfiuwO9/XwrkVOsMf5xugAlAAA1vUPdH2UmAhZ5RuYKAtqQhoUAQcrRItpBRhhGsPlJysBFhGOROIMASb9mCoJ0htCcO1efV4kcPMZiR1+ymfoDa/0Z/9kjPWdaPbC5k9+GzNuaTntDsEfoZvygVCP20fkwQmtSeozUtzqo2Y2neIgTaILRsp+1BEblNlq3q5loWmrGm5fNjlwyznaJIrD0cWoLYmStquQuSzVJ/0fPavDAAAAkCkEADhvTl1jXxiIAZSXAxihjyOspk/DCujAO//uyZOEABGNeVnsMK/hzp0pNZQN+VHV5Nw2xM0IbK+cxpBqpjjS2WUORHIdi8svXKePM6rymJyKmsIxJEljWJq5gdKQhrNvMp1q8kCcJgrMjV5UWtLKKeGevoS70MrJYVkq7ThU/zm+/W0OKHIts3lUye07tpomZY2Vf9/OU3xqvSKs/bFthaiQ6jvs1BQAJimmZPDGQqI4Wnp7xErIWhwIHDwlDstQycIADyXT2SkFAaC8qa2+w4AEQFNs7ZywKJTWANFbQk6/kYlrLGZMFz6Gh9bjGy6YWt+SnreyPittQp76cf1oUj3nRrJpx0CY49euWu9Km88sHiaTl1XX+xU0IV2uZiqKiMU2KS25BDx6Y1GdqzSguISSSo9CWJSZwuqs0lSjuqum6nz/bGEPmRNN9E1Aoadh7sAAFkADKwcHx4ZYN4WDRy9C1gJjHSEwl0rpTLsCgkH2aVoMVjNJehhZleKgLgeNo1n5VLFyD8XYT9nF6W3Mc7SKjq4VQ9G8LVarDQN3iWmNiw8qCk52GRavDTA74GXSrBIoJDbdktTNcoeMqSrWjL1a7biZfpE2mq35hOES2KkGa4j6wAlAWA2omBcSZILkBCbBalZC5IjCAIEI5K/XfPgkCXBGo6yxEbsPOgPo4rn6ulPI8iIZPI5K+P2E/MMLe9c9NkJVWw8ev4lcb+m2R3ma9Lp+JjeLW1iR7uJomkvxG1bNIdfAap9Wh6QISzXApPUA2vgViA9NWFTohR4+jW/W6kaO5p6pkuyW7ihg6muDeCFxoQ1mqLvNWOW6HTMKqMVsMEQICDYyAcQcjTCI+BwLihWEkskBBwAUi//uyZPMBtV5cTKtsTVCCyzmocygeEzlpNy29EcIsq+XBx5loWKtcFOlml+mFOE62K56fy7ew2JpgvcezzUeIBkJMWl9sAhfaju5VZJAHDsFVfz5lCDFcoxt7v/KATFksb6EJxuFT7jPj0i4Og5zb885hhEDR5CrY23U+D61OW7u2Q+P891vT+WuilXbph/+roWoAIUpAAE3McNRVQUZigoa/YGKhysI60qIL3KULVfEhbK4KfQrAqpEa7tMHczJYB3VjQBJJslCeqTMplgqgZD48iZmRKz40xLIvvrMitrIl7ihyVVGDN0CWTOKsbNGSztpUSySKv/RVHpsq/2uf9d3pdrrmz0KbneSNTfRRmXra9IY/pT33Kfhs9Uc6WJH0M/FHOiwba1ckZhCrrpBTgYAIkYAAYGrID9jN21FQdUAcOmLC6tq6yYDWg0+AUXZDQU64m8vVajhwn47AFiGgnwswrI3KLmZPHjuLSpD45YxlbnJPC1YmTkpq7KLzC0wwvoTd2xb1IO0qPqXMtQ4CtXZkcGMin5dR3Ji3ZLJqTFHd7nxEIcBEPAplsmK0xYAUNNlRNsJzHAcZ5RUTEjypCEEBQ1MVDAyQ0njCILWNqle+5f8xwR4SOwQsJFWzP+77D0rHciDSCzCYC7GILkR/Z3NJLJb1thR92Q3y9l8aCoCMOi/rTgf7nDZ2M5zQLgnTLXYJtBFsVBpo46IlNx6xyCK/vQXF50TkXFBzuWL2mLj60QYkwQZVCd7qHeRJSZQVSqeXsaNdxkppFQMSnemGciMUnwfYdh0PsYC02oo8txgxgsQjJy0AANVgBMAJni57JRvp//uyZPCABPJdzUt4SXB+C9mpbQKaFvl5R6y9FsJ1K6cxp4owAQIAk05rUz5xFkaBGTElqCzqKbUTCgxIsaBYcAoIAxlBSSCq4k6HGRKSAG+Jmo4J3j1pt48npEgQznfyxhJzycXwRwno63Al5spd4r5S3pd65nO3JE4hDCjR6wQc/UvVD4UWNWcOKUhdGQMq7qLBsUWSgkDYjHIwQRV1cKjrJxlaZu3ZmT9OrUXu790BYrRFKgQxr77trI2+YIoJHW6FU0R26uALCIdIMLvNLFkTQlGkh1QqG3gcWpfGnkCoJMKTArVehW2WWJ+4rm+qmxYgEUHHQkUkcSYgBDFtS8ywyerfprJ/KOjAiE8s4pAD0SgdkACJk0+Ak9aKoIXLXoh6VxXLKCY7hvEYxqUzyY1OkZ8qhPTlEtPTldy7H6e7OWbbZWsUJa0FRUmQOqDTWkNxyIwbHMOZu91LIp8LPBmMphwIUbjAZuLEIFh2umdfHW4AASEgSUiOIY5pVZEXAiaJIrAYWoKgGUzB0lPlhUgOhS6bxhAEwZZA6jaz5uR3IB3bybqkRZ1ZYQdtMnCk6zJQ6wiz1B+2mo3GN+9kFueStMAVg80sUOG8ATmdEC3haJ/q6nFCdtpaoIh90GAQSGCQBAEpSiGJMlAyQRJgowEQxlCIKgBhARAqBBIICCTfXFfQwUC7V67KkO782pqAIxjI6Wmr1IBv3JHUsPDnrsSNwuc6jWmkXzQJbd9N9bNYnusstafTtms9/4Q2U/+xe66ea+NnwsreTVlyA0uKJ/8EA1tYAzysNvF0pCdo/jvRZdx//bZLb+UJZSf+5M9OVgQN//uyZN8AhfFe1mssHrpupGpJawk+FHWLTO2ZmUoKLOkFl6Fw7pRnW3LzykuK4o26UnOg3e+CwDivZ78mJeZCpgst80QOec4Civ0AhU4I0QQFWwD7JgF/ZNKEdRbp5CTp9uhPBqsrNAbpL5dH3X+DTeEvvIvgKL3fsUArw8x6JFDRr/LfxxCpw/EJNRV/Fe0/uIFIW5laM6OZ2l9QSI7S4/qB19ihPyDhlLR/YrEXjBE5KUyH1C9rkdMgTfCo6cOAgaF2410AkiugIImrQfkctHRR6oSvYK+akEvC6kovoqkgsKkzL30UFzi0Ow82e1L3O4wshLMJTNWhPXt9v27L1drY7hCSdHufx3YxU2lAKq+uhl8k/I36pNJTwmpvtDn6B/rocxVWeXt7TCu3UP03OqS8GbhrGwkrKrnqqFi9lPPcmmkzx29XZQbW5vSRPRmrQIZAabLBMVhTFQxFmrCPGzsaPDt5kLB28WjfAszCEQHovLhGMcgOLuSJhEaxheimYybedi/Az7u8wuSiNHqLf+ggHU3o5WlIcv3r+nX1U6adHmto+71V2obm9mo/XnFCmi4o4xFmht32gACHKAx0YgZMUDgCaS0AKMCgGh8CBhIcHGhb4oA42YsipszknSGBxYs3FBaILjnIPbksJm8mM+1exLGhU8tdB44zD8kduw0TGJbQIavMRQvSRMmZ+myXBASZ6X3OkZ77Lu/gs1WFmv5Z/AjHclcvWEz/2iXdzboiUf43LZoo14tzvYXls6r8lDFtf2oXlqm36MR10deo1QJ0sO1BNfa9vBw+eXpL7eTBEaCAEdUaahZM0rw7MawBxcUK//uyZN0EBLpeUYt5SfBo6yqqYYVqFOV5RY2leYniLGp1lYrYCkjWxmKA09JBvFkQ8+MNRiH3VxsQVub/UH3MfUae+7nOPG/6DKtzSp2qUIsa1lw9/MN5kxDj4vvit0PO3VICWVnb1elV5eCflVkIc7pNuXWSVRWz62zpm2RCutc5itBEgnUG52qpPeH40UNzEgxM/kExsOzBooHAEYdAphMamqQGkYACWTF0cUwiASe5Z8UXtlAsChzoUubaHxkREAMVdh3WYqDuNEnmFin3vvVFHvis1H542UHVLOIRhAqYJWoIot2kyRmVQmhWuXuHrZ3ZmPgRL7VHHyn7uluKe5mUaThvmZRN5jfkSBaUpt5qdRdSFV1ulWSMj1U2hjisEbLrK7fMt6cNNMpWtOKcUstyPJxmlLX5E0qdsWCqkACZw2eVWecaZxABnDH1QrDMAC4GBCZs+pd+bQqiD0ALIAx2c6hYEvBXT2q1I3DW1t6221ZtHbDxnCxPuDDcs+6rjRpwvOwxHG9dlIKUqNdDSVB3CoZB2dJm+zar/RS6O+j0tq7zW6aKlW6rR7UM7qy4UT8R5h2SbgThNRjWUPxCO5iak5jQBCA8wEBoLjiIxGNAxZSbEIyHUAnbtjYFtC2DKDZh1N3RJl5C4CACsgQLT0EgkFJ1qCorqQfFGYiJLTqOE7kHNemHT7NUt69W9oUB3q47nTIfw+kimOIqzwGUG3rELOkbw+7nU3W7QEF9sppsbF2/UpV11qwetyrrUDdBW3sU6PlJaog32mx75c9xJXvmTtOdENXk/bi+bSgPJ5UbH9KEAOoyammdpVA8pDyLytBA//uyZPSORZNezoOZS1B6ytozaeJ8V1l7Ni7pa9HqrmmdlYpoSukk4XSNE4JTLICQSeqfa12gKARpNRb6wtgmAh2nbqz+eweN/YrWMB/zZRUQW1rD8SoD1xevfnO/NL2FcXtOOSPCIfuYSdB44vKIYzlZ6Wnsuatjc1+jvoxQKR95TSmVzlVlK5pTH/puXYUTo9CgLhQgzhkLUK5x2SUAT8H5M1rIywvzAsdNqnsLFMwcCgCIjOygOIqpwxCnNObOUnAxNrAMJhAEqnVdKjAyAwYQDRaUsC1/GeAvHA6XiQY0Fg5CYRB5Gq8/KRJPgPlV1csWtDmdC6EqoFI6khMJJ20685IBm63vdPMxJ46LxjbqFY66b5G7dja2bWuXhm3ZV3pqhqb03v9Yh09mXelE/Fl2XZtbcuVtVZS0zNpmk5Xcndrm2zPXavQV80T0rPVrPremYDK03SQk4FjaW19jvHQyZ0WmOwU5A38EQQkPL6RqKcQISYWwM815i9CNRm0qThf7kUmYlF/Fc1bFVu8oVbbAupA7ILI4jqfx/ttIgNk5jkUs43Q8+iOqqz39epqW/6JNXkpZawDe/vSQiWpc6RsImxEAQ6wN1uDSbkmAPwHhoICTBCow0WX62xQFhUyCCNoBCEAouFQ5Z0uamzIGAPMHDUXatHnqOwIaTUInGvjUnaXOj4pLkMbC/H+4zOYHrNPs9ZCYeyNLWQdHpFwzoMb6CtViMT6UcsSZ1Jg51iB3lL2YLdTXiUQetV8TIuNH8vMUiHHdwvMz3xfBUcXX29yKiY+kOFLGAds0O79M+gYgZWdk5uNg1WOiDOAhMiYC4AUF//uyZOqMBc9gTIuaYmRxp6q9ZepPErltQm2xEwoZnuhdp6IYmTBNjM4LUaBx1s0UZSHGp6UF3A4u5lMYJbkyr14vasi4RKApnEixPDdi4T6koTVaCyCnRHyEj/LxDDA2YI5gsKzTB0Y08ftxX3LxnblVZcz0kcFq1P/ZJ0AtOCMqLKuHqJyKxYw8NJHbkpJiyCyTYxNXUgACUlTbe5MepMkKIJaxl0Do7QUBQ2BTwCmjFQKPRWBjU1aQqaI3g9dlyE0CDrFm7CxpMgbJmQ+xKrVUUooINrEIfFJUfPtKox1YTlyZGPIK8Ts1a3U4RLGvlnWPevPQOEe9NMgq5oTea52LRJ2VkkV59Pt+2nZ5vzVHVk1627r7aL/MhXRS/TnL1/5/fTRm+k0pvq2ovTTeuuj6y+yykSx4X0hbv7mEQIpbfuakca2QNYjJASAWud10D1KVgCqCNDUUZng1DJazIFwcYLAZctm5756TIHcuMrMDwRfIbmGYszrHVO6mFCSU0qwWCZlO+68HyoJ2sGI5l5rcqf0z8uwv9Gj04CwxQKJJSaaCFTO358/2P4eV7xQh5BYe3+JAABz9mcOfoYwofTHC+DPyYdAAIAYQBjHAqMDEpWABCQSXg4h2mp0J8gyowfBpN5RUMLNhzdIYY9EnzVYWtpW5RlsijzNIGd7VPXdW1L60Im4tlTUTZmW25QiJDsDihKS8RAiR6ID+5NlSuVXZjMEoXiCfiyq+E/CeWSMfLnfxmvkZXSW5FArdxzPZuTrXNV/C/FSee9rpw+5CUJNot8Bd2XU2IyFW8jFRPGy+J7JyWoeLiG6ESgWmVTQKU5TG//uyZO4MhTJezhuYStJ4C8pHaeNOFqF9Mk5lLYHpr2eNswsQMjEjChIx04IA8KEZb8GiZhYKsgWMVAV2rqQSw0ysuEhTbf4kAGvNjlj4UM/TcXgrDXhvJ48ZqAptQGhrT0x/Y6tUzPXNvKd2pwGS1uVvQ1JupivZFpJmZysdOuS+r99X17p//sv0//e3Ihuh3w1qiz9dACTKUN/pjzlw0oZM4BxgjLWGBhJdJAeYiUtaBKEtTlZhxfqPO2ciYOe3AqiDhP7AEKXZTxmgfBzpdGqSIz1aWRxwt0cxQ6TZMEq0KKORQ6KGGWbNWAgDIr0Ln8jTxsioTkluI61pAqOGnmRdUO+HhLfe3mOp4GDYpjfkRCKnO0q647SmioRbmE5Ldd7aedCZHikvg1IuqSnseRYGLY97wQEouNqHj1neQmXQiNyDDTUy4iW6QYFIvqmiEIQUUlbTYpGxo41Ky+wWvloShLB269MK1XAseNKNcUEm5+sdyHYWjH1rSLEyMqo8xgXFCrS775UGVRsweJhs1mB4Xb3E9UVTu8n6SLls5A6XEe8se/oiV0Pl7t4mXe054p4IqE81IhY76eSg4FKLNvl0MEDRwIOXy4AQAgBSaUaeEeYZUhYbC4Y6o4XVdVShCVPtWXur6Ey5rTd3xhXZtn1W3cxpr1XrQRL12nCNtcpKatavluC+9ZFV73J5ad7L7yhstj0eMn9DzLxrG7kwfz97Q7I6HbbOgfKhBA/EvO2UyAkLFNNoYDgwPLpx6Ity8YvLS+vVrB0Q7ldcsHAfHUyGvXOtk8zVqI06fXlhiTjxdqR4inXXyDo+Osz4T5lmAgGe//uyRO6ARPpeTpt4QnCT65oHaYiIGdmhSayx9eNXtGippL4okhIBcD/JoWwmISOM3J9PnWsNZsEkfofHUfiwKvIM3m7+zi/jzAQAFSyTmuanGfmDFhdqAEqjqaSjpVAVpOhOWyW6kEr69cNNM3HQUBIwGkIOPi0dPRImNxOVnNnHurIVZ7NOwU8CP4w8y2gSdsCfhP2zUdkRB2oWf5My9scJWE7Q/GGOIaSdUhb8szA/OxcsbcqE/eJCTjiz3Y04tREOWYpfDlOc42M9FPdcRFYckVuXDP4rxdoNSIxQTwFY2JSqvo1sj8/6+w3HTOxxXM/0OOlVP4CPGGeR9jxPlQAN7koT8VJY0WimIkiqXSca82Y37yPPeJBtDZGfE+EAIACBNAnCdaMNLTHjsztgKASoSkGcMe5SeBboSfMZGG6sRVlIvksaZ0iUhWmVQSKyG4lIRXclMWV0bTi8tRKSyoab3KKaGLkxVp4mo92NWacaznwtxR48WDKRxBs1kpzhfKyIi/pl85EnWShJOR2TGfbJyf5ikx+Mhkg+/D63IRqVK3LxNnGT4/o8hPXxG4i9vm42WWXykvGDW8nrW7Bd24+hDjjZKV9A+jgy4krs+O07sDlyw0AN48JqVBkFgHoHQNw9V3HCOh0qokKRN14rNRlYhrXrXhsmphhvcyFqm2vqQetY4a7QweMv5v9P2Jn//78sG4mtzagc8uUwvVRLgohgtCKUorHwwzSHP4dGYs0MuN4V5gnmQcYpYKOCV9IWgELOgiGKoe4KBUP0UVARAkUILCORwZPMhAw6VywWg+WyLy0KR5NhbjWfQSQIUSWhotxD//uyZKoBBbJiz0N5YWB4a7qtPQOdEOFrRSy8ywHwrOjlpiGoLskFs7OvYjJqMFZvPSB74iFuUwN11L52K3NQTgLHtr5P8WyNic/w7HhJHaTbecID4XhW+yC/xSO/r7mHN3zcpOO8qb727pHX/DcuN8u+tadfNunjX0CJr5FMzFCpUP8Q0VglRH+IBAxscAmZwMYMGmYIQ8vSAb4IAMbW6RAWdXh8nCScIFQ13JTE19qEaR+49VF7aU0nsxL2Gvw6DbN+efQ3yRoLqj6+JaRFiueZQXuYfj/zabaY2X8Zd+Mk3qr14bS/v+1uurrmb9xfi9q8v7utBAllNLoOoQdGndxNACVUKkc1bRZj+lR9PkLBEplO86ZrKFHE00hXNT9dZ0Xuc5oM3ueT9dWtWEZJayNCKWS9QYklqCoWyobnFaTS8WoIXIOQNsrMNlRkiReN+aqhNJFQvuC6rEJupaYIWS5L5HOhkHNjIx1XMyVS48uV1cknTuXY0v1dWbO5gngFDHR2HAtkCLha/1Exk83AxU5jCxjCzbJniECmUux2l2poLuyiUGPMzmRctCMIDCJcR6faGDenTJR3RSaYgnBRdqLMpzx8LuNoGpzZ0sUApa/l55E1/E7kBJGRBkd9vQUdOdy9Nh1vnimYzltI8oPsvLCuTfPXa+qmzCqXmvAI8kZVjiyKAlJJEw2w2OPHQgpMcDhgbFQZOJTRywgLdFJY4Q1nxHvJJBLP00JDGwxw3mpr1mwsxs4mqEkESzwYXvQUGHNrvuwpc6YlYQ5ses/nWZR3Z3t55w3Dc/3Zblu0O9flVWzddzpjP3buVcNnfLZ7VO0V//uyRLiABB5Z0uspHNJ9avo5aSOMURVrQO28y0ooLyhptiIg37VlPjazXWffOeFLIaBEjFgHkjgION0myACEAtpNpUyacWWhWTDIXAWJtogKcQWBmIM7UgzaQN7c0wHClnQ1MW24SlelmCjdbSCJvWCS5y1K9D7TjTlnq7a9Zls+AXD54s2YTGZRXMW7RjBWb3xWVXNeJRY8pounToLJVyj6ykNEPxKsqKylV8Qq1HEw4+0edrHDlDCK5WKidiBgtaEmWth3uQRFqm61ZbHMNvJbMqAQI8axZeIODYkgPV+nTGgCC2tIRrFR08N1I/HCQrjm47GtV0JOXpr8DTl9giy96wK2YhRk5sRbdUOqAaE1Vy0HW+EgET4cOjmg8hDlHjL8oc7Wcjc1wJRNVmpeBGD6Jmb0t4chtr4xo2Bo0VjtUvazVVhZjxjcXay5hDUYrZV+xx2+T5oJSZ61V6/NuiLADTEC5DDmYBQCkYbQ7MJAoXvXM3qKlLIxYPa6oKA7JK2d7lIYtNnldVDTVlZ9Sok2J5UyZ26v0ybslBsTaPIqNXYeL0cNdKJNVgURmCZV6RyfC/4cb1RaFUzY39Sbv5E3D55T+/3ORvz8ozYIc47+1ADE5xLvmnAktYx8izGIUBAVR7MQcY6OOqUELAcsKIq1yp72gFUpJmLqwEAi93SZNALcqkKg8BWkjQXMDhVGBES6ZHp0zA60a2B5jFscuJYMdaPD4sTZVw3/rUCzlpWjVWgQ4m3hK+W9HtqZcf/nyLf9sehXt7qH9Iws1iJB/bC3pRnxdV+/fhfy/98Xwh9xjkA/lnPJmsz1Bxops6ASlY4V//uyZNYABIheU2ssQ2h56zp9YWN/U515Mk5lJcGPF6cJsx5Y5MKszCxRFcSOUeU1VFBEBl42SqdQoQgajCOMFRpaqmlmPKPSD7zht1EGIskHRXqOgzy8Eg5uq5OqXpvdcMNc22ehjqUebP6DWBlQBY4UlgnlgWXYNkE4qgNbFRXtkUaVAIAAikoY1RQYghGIwOMTgxBg6mDQKplpaCwS2k4RCBrAjAACk8oNYEgDFgCcnBMMlACkpVHwFhGyVkMeVFT1L/VHsnr06Ect0s2sWpVN0Gmd9quVtfMuiUnErFf/PE5y+C+s7Dm9fzy1bfuGEAqTlL7oEk95SHZMn42Nus3KCZ7CUZ/S2sxWds3vDcr9i2n/B9z8qeFkk2IGAWajkcpFLaf9jyPQQGikobCJZzMpmcxQZhEYoFBQKmEQkiGFwCHBlygED0aESGhJRxZpKc6CtFDrGncl9UbABCCoiJ0aRpZZWLgPQnU3Vufqq3NWKetKv1ODZeAmYrZJu+Ktu6u2MbVHoZ73HUYQaII+NJKVtQo/fKNPIR7NdXjtl1Zl+LlllahWGCIfbDikqyUH11M6AMUAJCbadP/0xGEBgEbMDGQtxjAQPASL5ioCYIFvUYEBOEIRBXFLH1YAlbnKbhRJxJG4StVRXinYUC2OT+lHKOtMm5lR9bcsRZaWhXg11Lia+Xk7l2Okeazbn2Y6rOIU8SbuGtbdW1d+419ZMQd1pfeZ4Mn+P+4x92ma9+v/vHvHuvsu/vNvTcTXxqJ6fW91x4Nt43damt/W25nGPqMcc0+sRz8iXsCMNQ2AGCEk2ocDPHHLRh4aLFY6BtuykVAV//uyZPeARSdiTTusNOCKa8mjcSWaFT1xOVW3gAHxq6cqttAAKS8yfyakpFQBz25RhxAZhzJjKLQvo8S6YkVFE459aB9E0WaIlRseNrOjn0D86rOqUlRWgtixqOyqtakNFP11Le7Gi3WtFtb6aep1OYmaFaSV0kVZ56F1InlNr/79q3vpUj4OwBD29QAAGAQKAwWh2NR4fVaz0jwzYqOeTjGT01QwNSPgMamKCRlzWb0aG9wZuigYkDmECxhRcJCBvSKZWTKSX2C5RZcIJQBMnDAFDFeg6BEwVFW4IV2GPw+LB2orXXC+xct4iEhBR+3fh9l910Io+yhjNEiE5BIBKuSQO3N0UsYYmWkQ+09/aKtCH/QBsTVZRwY+sFTtaV9hmBXIirXJ2XPIySN0Wqs4tKM3JTdisWjUasRiWO5douTtyNv/TtrD8bntw3OMkidL9akhFSvXgSG7z3v5OWZfj27G4IicEQ/DFim+KT9ubn8LXcK2HOf/fmcZrU9dgOzb7SV7/NxiiypLNSOWcaSZlv18f//Wa/88Ejqw0AAAABpUIRoPh+d0Zm6G5FRwg2DUc1YCMKEzFTsxoKBB6ZgNiKTNUPwQJhg+ZMgBhoYHGgogAYD/ixpQuNFINrvVgbmhzQPSAMMVJAtU0NJMEASlQ5PtqtmBkEkMrkXoyKBU+FmORBr9NOsmumZIcHt1ehr8AvPDnbTqQXCpRR0rTGXqX31KAIBNSiHLPJvr9y+rnasZg4gWTQEBgCB7cGmO1Mz1D9m1KrWcos6xuz852ITsbRQVIwRMNp/b0MTfJy5RUVW7X3N3fkVTCvOzeZbMvGteTQ3L//uyRPQACIVmT+5vIAEq0MoqzeQAXRmJWVmXgAOvMqvrM4AB5Q1iBFzor0N2vhNY4XPw7/f+TTl6kj1PJZZR487h/Ek2gpDrXiK73XnMM8ZXL5Zj/////////////////////////////////////9pOfrCxbeHgAAIKwIBgMBgImgnOER2hQwwzjCmPtsGjjQIGQRDLpNaEBzrCMVWl4qYtBngC0RxOhDifhYPwbZnIAo3yHrIzz8JGJ0yP8HwjnBcAbwVQjBSKQrSXHmX55Mojvd1UouomcETc/DcSiyuzrirUE5+2rgAdgNoaoSheDcOBPKxPR9q9halI1Q1dFX2tTmmd5xEsTz1SQZZozlGhKpnXbLBtDbHH2PJGKNTxvRJljY0RO2xob67yBmz6R6n+wQ8RsZcjVQBPE0pVdBKxVxEIfwFXA8sH7gxJH17VzXM1W9biRo6zQBgP3f6ydQEk0VPKRRLSiURsiE8WRMNA7BnMBxCO4kCFhoCT/S0EABZ9MeBwEAmAXdIn3VtsYXYqVS6HFivc6rotWeB1R5MM0LtVJU3d0rk7El2tPVC8WoecZuDxYQuSRmDZc8cAzr6Qh3HdkTpy6hlFDJrkvnaBPpfcMPLLIHgWvblWozKaSQzU9u1WuOI/tSNuo/cPuY1t/JmM1cYxTVcYfl9uhryCdldael0hgKSz1h6WcyqU5zdDqnt7ndXPzxneTF769u5uFt3pLVaHH3eCB6KGrEam6W3qPRSpXqfe5nrL7j934HjOU/IamE/lheV6IcLKIKACOFyhZAyiXh00GxE8RDQmrXgRWR52TOCziJP2AmOgNiWX//uwRBOABGleWGdhYAKIy9sJ7CAAEsFrWwywzco4rWvxhhnhEIoqNggZabonKJZxRrkkTRtIns4+s8pbGnVH25yi7vtKWH6U9zuGwcm4m2MmHsTP2i7Y6ap73Ok822y2uduy4c6r3zwyGxL6q53w09Ey/lzqcmxt/77ZyVIrQg9eNDmNVyAJ1b6tmJSCiQjKLlpy2IiExlkNxBtO9e82rG+5f6Rv/LoUAaw9DkBxpYghCDpsh+xLBOaa0MI5cwIAj4cHvBZjFrQoRWg0wyqHFCoqJCipslBFQ4XIlOmp5s9zHeyYMtvLZWLUp5j8a8Wje3xPTsMuaPq1niTGm0lIjVaOHMkzorVRJqU+enaLXJ1XaiAaCggCnicwaIIIIN81BIn2UArcfSRrCwUQBqTEEOSUFQWj8+IZJqYVe47PEiAngY+JckXKoUhBTXVIVqOQ3onVoam7CKDkH5IXqZlH7ZHj3JDWCEdKPcmfgqpWxJGkdaxYrr3Sj0wgMulj1lF09scpoL8n58tsapyz9o/62orMy8udzLfqZXQgw16J8/z6mcxs/NIv87IKjQRYlAAm8BIkcgYRZyZacLUk1EAdOzB3kP32jUOsCLIFmlYJEhsOHUkDtDwZolTixrHMddQh/FoJmNdH3Zo9elpK5U61jMSLcjdHMnqt1FPKeFIvnOX1Vct1F5s5zYLISh004s07Y52OVP+X3+93bvU7fiublIXb/f3vu8ebKCWgZqfEyUI7o37lV+GLAJmKKKICuOmQbKgGuIDHaag6CmKOjjItnYJAoDgXkCaD9qO0/X12YHImD5BIYDbwy8R/JJ3HNotNJy7/+7JEHYAEWF7YYw8yso5LuvlhhmZRoWlfjDzHyjUsK2WGGaFK5cE+ntFnHNifirbTLxkY7RuI3dwhGyZfVW0241tuUXjIlY/NYrxMbVIJoG1MS27XKPwp1f34rV5ku09u9aLJMnyFX43Hwk3WQ4dDqP/zpQZkBFEA3nDuCA6qIlFaDrrea6o5YQzXUX8ip+0HoNVRsIInravmaDAt9AfxLMuCULTspA87SREiTIJRM72HspdJkSEImMdVdwI5TowkfW9aCZxtNR1vr4Y17VNOaklkYWnizz7yNeMKLUY6G3L/685rVv+58tt2ad6+/eSCSCeH2TLl6vCOAwfXeHtX/G6AKRTMPMAOpWTuDhrREhJoqnaSowBl6FyPEQ8rRkl2RcQy1YxLoppSUsOG7NWRnuvyrlPrEgwBCoLNslmdgWzliEZSJE5IrSoP3KbMMh2NbN1yeGPaXjP8LyzGbUqOjm5r/cXR2wjySVpfY2WZbzs/ffSUXeMZbzpCY/7+XxtzNLhtQqZKmvNaLppO//mAgEABACVVLsmAwiuaRNeRYVO/SSNIp0vxa0OhcuCUSyQP5aGtXCnHmjLNkS7ind4jqSQmkk4pzs0qh8BaZAOcuzjoTPUE5wm0JNXLJy2ARAZBlZkkNNcgCXgJVulpu8vMV2pGiqJy6kQOtzd87NvmOtn1K2vO+d8Wjm/H3Z/+tVFtzS8Re4XJGUey3/lKUoQmpALQdLoF2BUpd2DWHK5nkFJtW6VqCveEXFsZmBZWiod9LtUBCUHJyPz7Le7E9jaJc9C5NlMKah0ehVlyLDbjg4rlARxNYpsFGbA+wZbqJE8MqJP/+7JEKwAEBFnXywwbYokLyw1hI5hQOSVbLDDOyhOr63GGDbkcj2uf/Vvbasgzkssk5tVoIIDQ3EoH6kAIRkn8JHUgcSMQ0ZuWq/A431qSTA0DC0kQUoloNibOCkiqVO0XXWhSUEoS3VyXVdR7akLa9Hb8tdFZ1I7KpGXwhIQ4ym23ApsVCizUD+pbj2YtZ5tZDOqgXWBC1auGYnJQCExVEF3xES5PYZmOLFY2xpb5vpieApAgsLFCs0pivYygdhRsO1PfEbXIvhmq2C0tDl0rmwtd9loVuTApULFAHGSHAJjYl2b1KPP+nwFgsjkqQqp0/HVXRL24NCw9fIB17Sk+sp4Vj884gtHHVAhLwgRQZUqez0kB6zLb2SbZbuz8n51hKNR4SPql7yMvKtRiqYjlTX91318V3Zs7a6ESY9bmfc/26xZ/NzPdrCb/YKTGwRWvGk2D/5l4m36AFAIBDKAWqcuQZhHAxvcwUuOUCQZX5MKKMLR0e8P0pCAQy4fmBbhVLUJnWfKFHHoXDhriutiWttrsf/IXoLuPdZTlnG9sZbr4tGUEPAbI6hZSIi64mCo0qJG4YJcGexfIv9R42qumR90NQynFyod35BzEM94ZxiaCWwU0p2rWL+tuq9/tVSRG2VU2kACq0sWnHC2yHsaXw8jyNdm1jC4XKB1s6Oo+PrTplDKuAZ+YLCCiaRxKrc+z9qTHpyqTP681lq505dvdPr097lO5aHnc+1jRc5bV3pt7w1y/O+s2bTanHaZONedE5mOWcc52VKOevp1Z/G5raf3b/XorTkAwcVYiLBvYrH/XMwZI20m2gQXWCgaqhxewgC7/+7JESgAEHVjZawwyuoKrKz1hI3tQCW9nrDBvohIua/WGDbmDYXpbigzEkt1vtahbTqeHTI+OHg8lFeJuLcThLMjaTT80kEU35aVsQRdYpDBkCo2FfiSxi20cs1cSYY7lSJ1pI58IvhmZFs5Ml6jsfGYhNxAlHyBlQQYKpmsLMJ5YMpqQU9eNCDEgGoW2TcPQL1Nc//ygMicWSsZJCqGoJgksnMIiN3UYaY5iWl1fMVUbdpodmnJY3QXwXCAnCSy8nrfjSux2bqwyaXVJpj7mXKw1lt5/8XwwVh6Ez8oCqXExbt3ttSmZAydIoY/Bm/LSa6FK1byL2m2R/KcPOo2r1S3Phbyl2yicEBKKNSiDCMLjB6ePeMIGaKBSqSJMpKgDnhBbgxOZ0zFNIu6KAiCXknT3ewMDA5BmYKV5ANUOFx5hUnYXyyg6zzCsfjA3e5mrmWRNt5RG9zTt3frW60wRmCoCwcBoqm0zsipEXNSkdS41uW/5ktQ7fK+0JYU3jlPSimMMV3Ksilsr56NT8Nl1a8xyPsZ9mHV2avwYAgou04T4RSDjyStwUml0MJLi5o3KwK2RGDK7jPc9730TR5zcsQoBmCMiCN0+7lkCZp87u3QWmot6TY2DU8Q76OukqUzWsn4HGblVIV50ODBDTzrO2VkJFIuDHnuQ6KWGfoV+aqsvmuN68m67pXTcXTnTRGm6H3+l9+O67YhhARsLmhjRKkMLjFaIaOLhFvYXgg2nQzV+6HrEpQ2kZlFpcMzKMBMaIiMsHUoC9NsGkXTL36rOoy820ed9slXspKoNblb8jA6myt1Jsl0zD1Y/LeConGve+77/+7JEbAAD6UpVsykc0oDpKrZlJpJQDUNbTDBtigOo7PWEjh3LrfVfGsxWyre03/uz8t6XHXBwpbtALE9KJLCwXbQhLff6W///8oE1ALZKCceUs2iAZ3nLChymEZX8oREGEwKmtfH1SBwIKyZjy3SumzKuB52yaOrEK/yTjjHV2x759Hapkrx2McjbcEsoYLBtwg7CZGGHpBCahdYdIs2yKzMjMypHshBBZPenhQ5cWAdqPMBPB7pok6OYYviWJoCMxNvb3ev/y/86iArqqSVjbJdWKNNhtF1FTBB9TFXylrzoON4vKYe6q4Da2bU2H2NzSI46mj9HH1TLRIIkfnXMEOjDvAZA2lODE0YKBB7BYkhxY4NsYUYXFIwolNIREDgk6zZ0xZS+Ske8KrZPOx/tNk2clUXWalnPBeEnH7iXwYACTN8Hcn/ur/L+1Qj7FFW3WiApBAc5CsEpO4bKgDFF4qqO4l83ytsOQIQXngemlB8FxapVLhGxWW/elmOCLkzNXl5yPTbTV01GdfpHbWX2LrehkG3UncBQUKCBGRgtdoqGjrRqtHXfyYMn5wyhqY39mTT3O0vfFfkwPztviGoVy2oxICJxRYIDnF4wI0xSVdAAixaJcjiTeUWXylolKCztwqJqSlCQzlg08xt+bsodGG2py6agmnq/AWBZoWVxV7JSChJ9pMYlMuTM7dN9c8utkueXEUqH3MQJKQlRqr2KhsjqV2S79T1Vo/KokSjyyI9zohayu/U4lvZcxCreYz0OLBgszDBFCyxpRIa6SUjUkCYgJlRdBGdIGZ5eoN4hPSUW+pwka4SbrNiqCvZiTO1rS6D/+7JEk4AEJ13Y6wwbeH+ruw1gxZoQCWtXLDByggCsqmWUFnhJKzCLXrqc+TKmk4RP0ouv9oS7DT0xwrMoVHMwJ3CgRwHCYAda0MIyASgwxkykSbevkW7Qkud33yBRv9aRAjuj+i//9RzNc2MkjmfGPMiPTVjAhg8MwxmQEdChfYqoBAgBQAILilHxrzFh4DkKbMRYYiIgJhlNBC9QBLuSQU3VCJm9NALuudTS2ASgw4OwqsWqaDxA7PHDBck1SJSHeWJLK5JKRQ6kckwxMsLbDVqp9fmzvTeileyZRJPpNFun1ilnfZypOS1+gw7MXKrMpd6Gz0uzOiAhmDg6LkSzxlIQCiAOJFR7QBEhpbR9WhZlnRALBQoFLHWR7XcsO1q1BaXzColCWVIMNDry4ERWWEjAjQTKEVrLQQSXGUTNI351kmbbYbpNNC6d2jsu3F35zN7eVQcry9fDXcUOrgWq4Rbydc6SttOBYusl75ivq55f2gxctbUjL5tbxgrNjUiuKGbBLSlC7tMj58yBvfmdCf3bCWEFlKNKP8YDiOIyFvmQTrbQw15ujYEWUl11uf3GXyO3x4ma3M7KDG/AlBXqf9EGKhn/pMqIInJcOlwoaEUIsRfYXXUg8woEK0DqCUEVdANGludNnezkzujf/+eSlzzPv3XrEUnnLCq/sUbGYJs0COgjLDCwMdFjOSY4hbROU2aYJAgKIHMUYS5RRcX3pUsTNWpg0FRKtyeMAJWKFWkTI1NWvjVoUNlVEcafx86qU1Zrbobwww0x2KOPxE/HCcY5XVQU61NiopoIqlkepFkVtRfI25n6PHixqp3BUjK0d43/+7JkuIUEhV7UM0lE0m9LGtphI5QQvWdQzbCzCcKc6qWWDag95h9xtOrw4Y1Bg7gZXF8h+vs/quwOYAtgm1KAPWZFqulTpLJ6CycIQ5vAvSEM1b8UYaA+AEL7tjo3kJLIF8KuXStpjiBuIj1oueuROblqRkOQgTRBhnCk6m2V5aXDVPVszbLA1OCj5kpLlgwkG01MScvXcI5p1Jc+cYpg0646EiDhVpb9VQQFABZhJaZ+EAwCNHLTH8AqBTIBGBKkMsE8S+YkIsoY9FYAYSlq0Bm6voGjEvoHSZ3Q3JiGp3Fqj2VgWEQtRoQUMBh4E5VEIw3ryCApnMx+TdH1q52YzSwZm6EGfEp2y0cMjLfFZVPoIT1l8eFcbzED+rP1b5jcqNnL2xgYJzOjEW4x7sx0UOsw6yTCUthax7GBACAA4mSAmATgMiGCPLyZDwFk5JyEhy0ZzgUuu2sLT22HTy1hROwmpVh0xmkKLgtS1zj7ZT47ziZH01vWWHH7nghzldXzMWYqsgN5bZlNZ9IZ8z00ktl5jq7LqnZxxAZkDA8JJbTHWbyAgAABKgCJJioFMZMlosxBARED3qQ9N0s4BG+MARZZCAjhK4sqdQdXakkzEd4ZlN5sS3m7zUcf7PczAsgQsSy8i6m2aJbgI5KzKEtFB2KzjRwc6QMqC02c9bJFBtQgf/UDrSq5wq1DSBapqT+Lu6kfcms0lw/ONvtvR55x3B4jV8mdMnMDX51reKUgPYg2A6uXOOmrboiG3CsvrdgAQAQYDC0447EaWFRIEBoABRYDIhNLwiEqhiwKRAyAtfAKF5t5i9iSLYImzF156bgune//+7Jk5IQEhlxTM2YdwGnpSu09ArUTcYNK7mUHylIu6Q2zD1lT0/LVGLlP+e62Gmva1f1c/K3E5VdvzCOdPQrDSeXgXMnrl101Zp+zhh3wub9gVfLWmULQO7+L4TjYgjO9HKUi9s5MzYzb/iuSwln3O89blzrCRJuCu7NM3Co1tgvVP3JkwgAAADDCZEMiCsCEcxmWwDODBwFAQGgYxUFDE4BgUeD4kDzA4pTtdpeKKTjBwPlSA8gBdSmdxuzfNFkkegdz+UkhpVhCKjjiNWTlWyapik9GWNoesSKbSSA9h+Ecpqn7gZI7tY49NXM7eXqxReMxrfEuRY7yqH75bNp/Ad8KCbxjPFH9UyRYW1Pc6eCXuFbUs8YOKCgTiCD5mD69I3+18nhWl4CgAgAFQwEQ2NUEADMBTRBBgYGDw4swkZEvuBQ1UvCnSAgT704oABIEiAWH4QOjnHpYExlvbZwPunaQqtfy8CrDGtnaTHrKar4ZSNBrLTYw5hUmRHVJRX4pmYZjrAAQplqjQSCeYpy6DjwxnMjvus5Yqkaui2BlWVz8mI62cnk/UC1FQ5ZGgcDzNSqe2/S8gEAIAAKgqcmljYVITNTI8H3BRgIwAHCQUMdVtDGohhjYYe9ArgD1VcS9jqDiHWLR1ujdFrUsSuQS2egdCkzByxAmiOC0WCgdT8nraYHsyQVP2EBsklePIO3KOXPLSrCjsabM02PXe98kq/bFd6ztb65IpWug33/8gu/eT9hXfu+PhXap75Su6DZ07XPJvtGGtDoxzrf+z2LJgtHkIAkFKAZOLrjftTkHRpWIQSEsiDqxCEM0cxhdjoyCYWX/+7Jk9oRFHmbRm4kd0I2qykNpg6RTYYVJTeDHwhkkKV2njeFisXFFKBtB50OwUtTPkmMMe72GTAk7pTw7uVPQ+KY3h6AuUBGGAMMJ3HjgjKikBvHQ0noZ0PSLZXZeI8ZCYlSs8CjGYM8w0F9m9wYLKMIwxnVIFZx7DTKwp4K6+3xd3Swo60HL290ATHwuMQhghQ5ruFHWK8PH4BAAiDxjM3CpMh8DdgQg68ANQ2VIpFNEISIJjSy8Va3FGEBcJgb6L+aY8brdViTouV6NvqOhpJPFolmnnYhFE6xs6OyLEYITssugsjPlvi4JM84oOc4jG4zTmvw+Jh/Uk9nczTXVPRy9bXtskHM6snxwia+2r4p5vXz9J9ZGnbZuC3mxeVBi4bl/u8fCNY0yzmI55K2j7EJeVdIQyAgESYYp2dI0DH52BKwoVGkgdSt3AMXQ4g08j6mmXyI2Zy2PWPg/WwO5MPVeequI2g7pgi/3JTQ8Yqf8TyRVReFEwyp6scMdiUgWnlk66mpmQ5BwIIF2cSJDhQQ+GG6ispJXPYjgypyU/zPrZMeEztvNjhJDTJ/n/3LpF8GNihILsOoZGawBAAgAokTix0EdIUKTgUw89VCgyAmAaPzCngITV2hwaXoBhKoCyZVMiA0jlIMtVQQ5RzVIoZWgKBqSagSUvcqyVUFLi9lbPfE5kfVBCOfGBkbsKjBJubKePRpamFUngDBMAYXMJs7Jw8YSIqQ1JkmXXED+jp5oj1GPBQcCb0q8sUI4afKM5ocnBHScdnFPzW7yk6iGL8nFPpdPaGclxuuUkgUDIJG2JpzkAhqKP6Ii9oBNZWwVapX/+7Jk9IAFZVxQC5lKdIUq2kNp42wUGYNHjZkYgd8sa7WGDT3BVeOo9BlGZHIsV9Asgu3HCjn1e0jseTU6Bo1BAhVAIahSAe5DLhNTH3qkTQqR2u7EMnCIi+ExkfTyN5Dy/8yfi9I779eaEdTTCkbml132kRYR2oWZEwLHEBrMZB0xylemVQMAAAJABcMGBMwuIzAoxMpkM4UEwgJoSQSFAsCBZaxctE1ZYivqVw0ZlwP0t5ZJKAITYephDuQVMUkebN12YFl2dWJ9ztXupcKDrg4ItoyMk5GOyyPM02ssp3TOhwIxW6+t7POykevu2s4QX2MjfNz2BiCqLJlcUL/kgCp1gIG7g8eOyvxhdjqSF2Hjm2osJCC2ygVSgsF8OAACpFyoCOpNozfVF3PmxCqgplahUDCgI2Uy5lRjciB5ZxQXBFFu7zKmiKHIIgeHsXIZwlHMXe2Oq+2GSyPgvPM5e0lJQbIacetVI+KuP5n7+BYRf5mVttDJPiRj1Szly1w8dfH3/3fF19invI7tLmJTmq4sUm/GvdRUq4z4B8+7tJQ42ksUDuzxgsbsPpiCy6l4rx0lSIQAWQDXxIApJh7mfjCAgaZIFzDjiPgB7EKWQgQxzIBiACRHB2zq1qDOU02NN2UemIIhEsOCU6bAVpUq3uYuw2UKO9RR+oJPyyI5D2SsaRxS8lNjehNrrBdFXotH7EzzlbuVFWm+h6cif+0K2Va+RKiFeNtbvPOlcmc+bkrlHNatrNjC/6xJpuGXDcpVLKmPZDGXWHhE9G8BCQE4ygQzAHM+gsBAoAKDMrIB1iwkue3EVDYkutRhpkCNB4ruNWH/+7Jk9oQFbGNSU4ZOUIEsOqphiFoS7WlGreUlwhEsqemTFxiww5Yz64bwUeb4sctXq8fpe0lG4tqktQMSCETWokI3YfxZxyuPFr9Z/TFypziSRsY/lr3S4OZ9CTMjvtz8tXRSpREOhpVVKzGzPqVMrd3qzacSMDMokSBXA40NnPpVJAAzGU81AmMVZzDCk7T5Dg4OZIjzygBlM2YIhhggY6P07EHXAQcy3JAaofQcdpMpdNyGbkQbgFDp4MFyZCTtoidqRYt1lzbckeA++2EaalCBDyxJXplqftn50JNCyKDu0KWc09fuwoa8PHemSV0ii8dyc+Ws/UVZXbTtjBdvzgh1PWWLgvP3/sZ1tLGHYdnDbjjMgVBQlxMSBpqELV1ZA3d7n6sZaioAKADGSCCxkQ/EiIA3jQAanaqFAIyNORvwaMToC6gAsJjrcAszUfmaq5b1Zj+fSxTV/u2rl3VGBxOC60POEMyyiYqYoY5juhtSolCk9Jf13m/XxOV8XEcPcGSstFXFx5sVdLNRE/8fNV1/xdSV/98I9a93M3UVHkCjrmiNzfehZsrkQQQIWLpkADkCPMTGo2PHAcEUP3HMp8ywE+gYGXLMDVmWbPCIdQBcrTCIIlDbetTJPMcjdulxY/TMh5FWomllV0JE2nI8+MkG9gShR/gO3BJ9xtm/qz2umU/iTEbsIZxzsoLV7efEz/WbqVX8up/xW3aiRbWv/u088al/86at/q1vq6lvh62WZd1t45bYilh8kzfq7hsmjq8xSCCBFnwqBNd+PE3KiBIgyRUmCCxMIDImA0SlwICQcOBweJreZEPDEWYcdlk9WzX/+7Jk+IwFOGLRE3lJcIJLqmpl6FwTLXlETmUnwhQuqImjDxDcZuzaXXgjMklVy9Gt6p3R/KT3coE9Tymy67X/iP3BFuiZBTV5+EtfFEsQBis1v5m78LQvaCynm/sfMvdjjOvsxeR8NeSdTPqqUvmK/BVoRQ8Mx5jb7loATDMyg5rzBNLzHQ2jOquTEACEJ4qFBkiWg0wyKACAtYwAGoOCVTZN8lgNA4ePHmQ1EcRURbvERwYFSKzq9KgDlkQVKFyWDOq9dFKYjapV+tSg92I9JbOtu3P5PU/S78qlSeppRCJVr2yNLlRWRLRYNgQydFL2ZBhhOyoVCHpJacyFaWKBebdZN+YpCLQ2KN4NSR2udYthoqzRBs/iJD4kqKFnK3ySUkVzdpyjGRYrO8e9IUaUqjGMU//OEvJNyjesAFCAUim1U6A0UKohbSZMKqtFgcFTBGAqjRd5UJf+fFgUXfxTpakJtLIQOeqGrjOuPl4GATcZjDqogDO1dRLS2ONp2INWx6Pd3ETcJVv9J3cEMVwtRkQMpqVis43Q1Ovh2fvSRkU0fS30y3Szyk9pd/tY27H5dzCxmY8w3HF2IFhVImFy8YEb5kYHGVucKjIEgUHCM43o4pe+hQPQDTnWvu5AJkBZgQRdJXIsbfll0OOgpkpw6LXV8RGSQYpSzrI8udaTOsopHCI+6x8jH6IGSnKIGWpLfcSVSSshMGbyJHi7PfBcnl6jX5tL2kcj0BKifPlX1fn8Yz9jK6v/lDc/Q+kvfp6V2xPdrTvn9lWbGpK2z6qKTUMrmo7du/6EmLFl+EoYBJtuXhcIPgdmH6SCRm5FEIAVAoL/+7Jk/A4GBmBOC7lLcH6ralppAq5UbXk+TmknweWsqZ2GDeAklnEbuiiqqkBHHlXFktsBYTzm7QdpXNgGWvvNJd90c5mMzBsiGdXAXMBgD3V0CDysINtV0Re7SmMhM6CpwzrwrnfyI1fjKkJRX6Ecfnyt3U5/NtSjIa0j735ldhzgfgrfiJqm1QAgAAABCUGkwa+CBkBPmYEeZn7pg0FmBQKQDMw8YjJY4GtFGwxADo3ZL1D5aSXgMAscFcKgnFpmjJ/C3XxUzdqEKsthcMangcgSkhQLqhfCdAJqTgKn+iOdIuiyERmdJFLZmRMxtUUHOdGRU6RVBCSiEl/ablZxvJLVm3yaVyTh09ddIAXz9WvBBsYF8j54u5Qr39e4dKEPls57Q37lPPFKtLs/2sR8cWC/CXlv90xvAAAsKA5wjeYGdGmGxioSpQZmBjQoYKHmbhYioGmFrlukpDMlgCNYNGdRET5ckcmo/z/1HeS3npS8bJqN6JXPhAWQ4CjHj7EIXSxpw0pjhON7GHMqu8HuMVT7tkbnPPHe9JV6wl1F+z87JU8Mnxf860ndcfzf1x3R1Dp27/GWy82r0dBzyPu3oBGmDVMYZKZgJEmzCicS+hh8PmJQyYOFhodrGKQyiSbOG1hzQBjpry06jMCx9hMs3jINDUH8Xe3YoY3dNd8pCjC+rD4dfOmxLYR5SqKuHQkN8HorckelRltBuV6+u52TJ1dHWpvaWWTe287OpjeksPRTa9/2yi2Ppemrb8W1TZ0tz+WIje3MT//9qbfBTG2q77v5sDPV16vTBF01/phi3pyWG2UZvSFWjzF9HN60H1+87jn/+7Jk9QYFglnPU5hKYodJSfJvCExWvYs6bmGJifciaimGDfXyvjqkA4QW603Mkoc3gAJcEoancnomC2sfX0JBTzhxMxT+MaCU5KMiGHhm9BZLSomrIVlYVns2I9H7zy3JvK2aumno21tnuOcuwAYgzEhGVhJcWpXTMsyhNbRoplZWOOtpUOc6k35wmmgk6vJQh7p1Ux5zhN/3/S6ROo+zBq/6//4qAIAJUMPq04iGDFwRBZ1Pw+MxcIAUfzAoUM8LwzoEGKHGmeaRaEus4QEDISjVRLYjw4AWKqhFIzJlJbYe0fVfMSkDJYkia8MuFLC8jwFUvmL4nCS4YNk4PU13F5n9DopfKg5T+klT+GRkrxEkJn82WvbPzBuzSEzNW/7WhLQKJjmmMklv8qtzePN+2r3vdMTeWTuPNQ6zOLHZ57kWrMfq5n9r+32JbTYXEf51KQ1yGvlhndhRPzarH9S/yy24pUABwTTRKL6gZMcQ8C61Lm7PGgop2hkkBjCUHEEPG8bpSJ1YhXPlGssZEGk9vUgIlFYxMKJf1tFQmBe1oNSqUO7VzqDcmmZ/tU9jhbnz/p+p++VGc866E1dab+5nLM+eX//0tGM8ytz/6eVLPyoxJyMEIk1THMB3IywRCSbcw8amKBS5DWBo5hiT6XiFAEdCgMMYIswEIwtqM5YahtTeVKJyhmu5VE4TSSWmgSB5XlKcY02PYGR3RFy4QLN7WqKCtxo1uKplvIhfKoL0U7qdF0qYmO2H+eBCs8yIwh7CXOi54YH01nohce51PIip0lNwhB/OIPfufqa1AAYQohKQgR0faAPbfm/oAARKpgE5+C7/+7Jk5oSF82LOG5liYHiL2nph408RuXtI7Zh3CiAtqA2kDuFlYBxVZhDYIUmvYPqLCyQzEjYEygQw1JIeEWkfS5xYEo0XSACtR35W0ZP+kavGYwuGYs2J0a9YKot8YalXPXcRrK80rzUu9zavE8O5geTR58TM1Oevb86+RMSXhaGiXRC+l9ZtMtOtwm5IaCP2ilkUOerishY2QsxLZb07bzPdlQk0mrjBzI1YnIgE4IOPfTTCBl2zDA4MdhAO5iQWJBpjQYr/4KbEkCrWzRMppdiab+Jo0x5y42sDehghurkh2c80np8JgsdmAqKqL1AuibePX7G5iW6ktJSOR6RfksWph0pcSOrmctHWN4md12D2Dmx7j66dv5ibIsfChnnC6nVySEP5yhwoyAzelg4hvRiFui/O5vX6cf0aGbMBngIY+s4H4PxXsLUrGdSEIDEa8FmMd7Fyi0u32MAmjlPAV+dXu8g6zTx8tmY6QACylgodDo2FYYzcSMfIhYNLkAAPQVBQQ4YJGIYd5YifMBJBpOIVKEUr6x99bEFPA/0KmWyVbONSgKabCW36Tq1W/zZq2vPiMPxApJRLh1OUeLiMLmqDcpYc8FA0QBtpF413y7biq8ZLzuC85KQlMQ2y4HOZzTkCnSzUQr1qWHfjABBzukyUIoR1nYdgHXkQ9CIKGkh+9EiJfR1Mz+PKsdPO5ORPVkFiVBxESmxlINDDchU/gRBIC0wKgQ2oE7PsNUlzTTQaxRytB+DIAY4gletm9CvN6VeSqntyZvpU5ELso1Na6kmegFIVzieLol0iVyoyfuJEjZskZrbnW9Uo3EQBte1lm2L/+7Jk54SGQmfRG2x9cKZM2iNtDL5VMY1EzeUnwgwuqV2XoWikjE2dDGHbRL1iNHnZRfYry88T8kZl/SlL05Rm1s35L1dtOohtLItMZKS0Dqg+rVwhKoojaQ+F1pFQZfCCO0FLCFb6+X/Wy1QWFCSWQmBjzjCOHQzTAoeKgAaZGRF1ayyQIKUz3A636FVVyNswQfEbFY8ZJgxhfrg4mpJDESRJdryLzdtx8/fp1sSWukzGMbUVAVOos6yWpBgrmM7zE1l82vKN793VxERcf9zTV8T7XyMa9zX2MPuYkRak5vcfczYjcCjL5vsQIi9B26gxcJDNpCCAGauEp5VxGJA8EBkwgPTBwNOBg95zC4YMHg8AGFNueY8IDAlAYRsxtQxtGOMwyieTAgBSLtwbSW1FlvWISsaoutJNq8DN9yp6VY/OHY55xTlVymOg5n770sP2lhFlLVbmi4u5B5NR1qi3ZKopcsdWh2jRJyZPCnOvv7CeFZdN6v1sd06tDyk+893GaqK15Zxh//TQNbCweVlfWkUEO/SEj2snx2LSPqaqz4P6/uwANAKdVzEc3cC3BbwMcBhm5yeTK0Eq8xkRcYkAiarqKr8laYD94NkjUfsg4UDhq2DN0OsOaagf2imJvpNPuVn4N8lwirqkjtbGiE+ncQyKRF+KdnQ3ddn6SozGloik6q9UPKEfpyCNpXoRlo84M4zhxTAmQm8S5JYqoEYTDY2FDCB+DrKduy4QkwMXDFgGMnlgM45dMxyMmNDEIadPKwwHBQuAU0UmCmrWEcosqsQBVWOAoKw9sq3JQwhX2BUjKzsC0fTBEHK2rqEnfR2P2IX/+7JkwYwFnlrPA5hjQngrSllhApoXeX06TmmJiagraZmWCeDzpkwRwnUUdBIBlM0XmCqcHst8mJQ/OQCe260njQf6K076c1ms/Hmo6zJ+99o65sZlavvW1mHpt0DMtVvTz560sM1+9cerCk7Ux875ya5WecS2QzVfy9AON9x5m0JrD9Ink3w/3AA6urEbgPAMEwyQSEsZNYegjXahMU7LAcHQS9azIw7pJCUN/Gi9OLw42vx2j1ut3bXuJH/WhH6rIMzTKrPQGHa1UVaqy3JFIYzEMju3u/cnbMqZlSUre2h7K2j1s1HNT0tm1ZMgqXdYoOoEBSMcAAwubTCasNYFg4n7BQXhg8MAiIy8tjR5cQgMlI0BB8sFgO6qFLQZBfMmbCNkqrL6o9lUcIBn3fae3VcNMzaTy9F2WOwCiu2LiScj5Mt0I6ltSad7RtUJll67jE+1FR2FY5TJJvOqkXnP9I5FeDRLr05GfVLV09hapExn7CfxpLaOQr5GWUWy4ry/uK3Snf9wj7hm3zsuhpO3CI0+6k0oHJWWoEAgmrlTL/h1wMjPcsUCbQRkJ7INqNshTKU1a4j8nYRjp9RqrLc8Y3BsVjn6FW4eE2tbZS9lu2aEHERzU52C8cQzMUSiUU8EbRAhxsqR38h+HkJL+XvPlU2PyxijqRYkIaRIHkKU+SWNp8RqC5XRQAUkkoVSgaxCxCujHwCM9YMDAR7wYKxHwKTU1JHiTBkoCCy6gDthQbxsWK0OklBmsCkevxmdSFg4HpIhnuEpocnxBBaBMIitJ4qTh0ELIQclMMBaLyHv1Asa1qDhajxFHYxyuhDGlqlzDZb/+7BkwAwFNlzOk5lKYG7nqmll42sTGXs+bmEHgdQjqE2mDhgjIaYZfoP1OG8ylwC2Wxsz8c9RXcV9UPkbXrE8VLNeb0q3s3ix2zU8ZB3sLT19YCSabhigZlWREhDcRoSIUWBl0MhBUGGEVpmDAqNpHrQJiTD3GkYcLYpeDU3MeSBQXxiwhhtqmtVePOnv2qoRQMcHXRwWROQ6sWOalLiy4awzI60QwRE+VRmqOWrH//l+XDtUzjP+XVJvDPg7DtWid1mCxZb91QSASpQCezNheMFtIxINTE2cMEk4LBDQDjisAWwkYiQFpkIRo06TrqYIurlVABhbZUoY+9CDchbqxxr4AgJiQPS3IahEimCSnEFX1PEmgi1QwsI5Q6ibLNdcUFx+MTyYDqsVWqJ49jX8jiR92v/kxUt+Ls9jd/NZoub7iKlyrkWQxu0t7W4ah25g95HOsiCDYeyCMBQhIOcc2XrcoQNwFE3XLllESoAVAcyoGduMWfXKitOpXQO3B+X2fdPhQTCLYp3fdYzmeEwMefqwD7Dx4AxVnZEJz1829TVdRHcLH13tcWOEYc1aVaB6dMqZHu99M17a8T19M07q2zQNlCnd9h2MpWtpulQ6XndIH2739CABJS3gpINYERE1GDFprvG8hcAxsPiw+TLC8ZbIq4dSrAbgs6gdoKQissRxcpmM/Vm4fFg24gB7YyCTfkfUiZfXXwgGVY6PHqVrymNGj84J5qhMK6HH/ofULeyA6kMH9+4ryPsmqo60kdHXFQS1NIrPt+ZDY3+LWp6mKb3MGX463GCLCOenE1WMUOiOKnuoAMACWik3lMwuRMwEB//7smTVBATcWc8bmkFwcmh6emWId1HdeULt4QXB/a9o6aYN9IJM8KFSZAXiQ5gkSiYDi0YUvolWwQykhGB7Q5H4qmjQHWy3AGimBzmHHo5Kt5jjKy2eWxPHkoWbnxdTL23e04bfFzglIYM05RiJS5IKdnb0P+F6WNAA+uamVF1IV0XzX8/5nP/Gb9vzVhYQthNLymw5dSoAAgEQxzEjnpNMdyowQXjqn0MHlcHHoLmUyVAzZqTDgcYUCaMxiFSkQbTfCsE5BnwRZA0y3BpyL6W5lSCOuW+4t5GuGW+kEPEwHwl8FyC1jLJdLrzYHniuVythP8BxCN6oYCmqhsNiowQuITMCE0vtqzYRQBJ/PiLbW1jEml8+Gp5qL57Sy+kt7Q3CRVHPnW8zRXs5qiR/un9TLzzT31m/KnVR/+Hp563LOjbozA0xt8/IUFoMRA4q7UAAACYY8GG3kocrHEjotAmMJRrKWbKVGJhhoB0IdH9aEgBdKHFoVSEdwugaQRPploJN0yoLSVEA34ovJcdqWyemgrOemW6X68nFiwIwscqsxSlZzWdsogJudtAxUIc7Ss72md23XRDZnbVOaYG7VvmVNnydLfp9voR+1UGqCsOK9YICKsYJVZpMZDBiMVjQ4OsTFgYMRggGAAy6NTRo8TcXcHSnwE0SEKeBS6WihydYyEpeUPJv5IyryjLhJ5UsgnBCC7Dny1uhchSxsqK5ddAe6jsRlh73TibhhAKwQeWyEK4hEo/xyG0d5zCSHS1JptUiUlNNC8Sq9nLnHZTrXSgUhcD6V8Yug/DfVZ/lzXDi3ELJ4SyJilfdXrhko6YzTdxW0v/7smTuBMXLXMybmEtggMsJs28CTh7tmzrOZevCeq8ohYeZuXbOnz4SjHHkjxIanVaIVDGdaotDnU5l7ftjnfLGxIRWRDFupzoXZ43s7Yh7m8XarbEMix8wGEL8OdnP9siqyWMiEIgq9uUG74zfN72v833AeGVZR3lBnCFmqIaUClBzhDxsRrizUGALcLCNyUqSvD2lEKJWUyFTm8uj5lYSsuqYSwZbVSAbiBZ3j0V8f7PHTiERHM3DgwyMBL2KisZNR2yVhOt8nAAABgIiEF/D9c5CHZCGzQQfNgiB7FheaeTbKACH7Z+YAJyCARNngMmhZiGXdtWGIMh3uAAgz6Qy3KIIOTOQdsP0ySdZl0QxiGXm99MQcM3VADEAAlFK4zko7ggLGBJOBzhZ53lLggiLP1expmK7oF06sCS6TSeDZh847Sdr4TktlvLU5fs9hbYkqG4hRX0Y6pZE9EUsZrbqahtDDiC1t7BGEnkSbrofeuTdTxiPDfONR1almeF4FlzvRpvafKuVtl9HqiPMxtsf5P9WTwypV7tQZJYcEpdj/j6XZO0keExvj8iZgF3OJ0/Q4lx+JFPhlu3FDCfol2Tkk51q8O8kw/B+RzLOMA4H+hZyodCl8K5GAqZUSMoO26MvbgtRS9w5tWUePIXnian6P6GG5BPW7s/nI6aA4Y2oAAaMMDCGDL0gkF9C8CTXcl+ckg4gPRpE9NGU/ReF3VDBFRB1J6LLR8uZH8KBGfH6QmKxKs3jSZzBUdXGIzQU61Gk46mjbcr7um7YYiYlicaubTC09c2OC/S68yTK5QM9K7e4PxdK2F7Ky8skJzmanGHSA//7smStAAc2Z9NTT8Xw0WzKMm8PBhRRi1OsJffKHS7sNYeY6NVcejEv2fQIBI1o/0foxKaUzQyHe5L7xpgUWWpdp4sDhFYzzYYjiiHGR4px9uFDBC7VLmokPYJjqEJLkzt8Uu4dbEqzYbTgwwqiHpxW2NwgsL+J7s+MQf9YzADpz/QCCI22TIAACzvI8HHYG8pSprcqT3R1S7b5HgvG0lp9B1+4bdWnfaMRaZyq0dTt/HHCt/tUja84ABxMnyXJe6XuGc5WXaiOkFXtRltSRoYoQtX9DV3FsTfJXtpIXSjMp6gin5Mvztqa9sQsxTarnW+zSGX8Xt3HooxWeixdlpipzbiKgnTNpuq0QhlakGSZ7EXaNgb8zt5jSentD9dfth9fxAjYaqn+0/sbSdHCL2IVswl7wiS0hmcnCSF7Q/RmmIcROWtmTXXnrkqORpPiUyNqDHyxI1jyB8xT1Xuf3jJ5lY5phHs/fzP8iQVHwlrzScZB+d/2Ma/ud3f/l3/THNjy384p8ru9P/M/m3Psi3cpPWLBUeXmZz3zqTJKLCiCNwS3nIlgqH3D5mraAGEUabUBAAIW+jzsqqN5x9KySZS+BIYOE8pbeFqihWDMGgmlc0EFdycgrS2mPi0urYrWi3rWnalLE69bFBAnM6X3u2Wu7IXFxVJ8f5e8zCurRtuL8g13brVX/HWZuNCPGt+ZscuTh0c//O5CYnd8W1empz/SzHeby58DJ83NG9mGkXNU20wOxcyf2d60v2KZMd45sc+UPGH9UyJfbyghqm9tt5SBMCVjMB6lsSqcDhHOZKnbDuMklikP9XCiGjUVFEOEOBd/1f/7smRjgATvWlRrWGBSaEu6/TzHehF5eVWtPK/B7yzqNYSJ+JZVb8eWuyoGdO0TMbXqhucPBtO+lo8c3rJF0mv+zarzuY/SqXfZcx3+lnt99CG66qfVl2KnGyA3Zm5pOaGytQgRfjbjdiACMVATkHThsQAsmijfMGEgKFctVyBigoJa9Tzbzp1adIUxtDa0P0ddWX96teM58GvlwrfBgZ16MWPBiPc0iwofSSWw3JAdVt2fQ58sKzmqiLUGisri49zqVKoLbdOjGdE59HdJnTOItMXQxnnbSlpXmFmYwsjJOOMoCihjii1MQsws4UbWEClkkq5EQAD0FWEE9Q4v8o8iG01uaOL9g4JYCCZF/oPjs8NAanO00kK8FiXjQMxUgo16n7tBcz0Xk1xrP8ZVnE8wzclgHjUahU/mXgdp2FVEuiK7XfW75vuCBl1KiGm2d7MaY7crwRzUHaoVXRVSrKyjXYMK0YewkUQrRQECRfhATO6TlBSAEY84awCtJbiIYyTgKFqVJ0Kmhx8SAY+WnBaSYtHrz/RZ5vkvvfRtmuQyOWUsprxechz21fwMuWhy6yBGEaLxWvmTcYLG8EGfFi1cfRIqmPjr69h5V3Q+hoOEn+l7MVcLKZDrwHxtsOv4aeGhoVDKp52kUqBLZTDA6BtXCHLBKmWAyX2RtoAs14gwJtUQUxVK0kQQBDyiTojgDvrbg+xLW0eqUy/CvOWoFJKQuCDB+a9TUKVZO1arJK2twyWMOipHiKD2kjHxg2+mE8UNTpWHqvr7O3tf/zM++JlP7f6t3W8YuVn8/VS46H0RfYMbVhRYRfHp4KcwBAAC1AGYy//7smSEAARaXNJLTENwdataamUDmlOBnUEtJRUByCyo6YQOMQcE6BRBy2h1WAiEixUYBGZLhcE10LAUqhEDbWQP476q1S01KDJ+Zi8UfOnmIeKsSChc/uOW650WlqjW8sjOdNKD/qNdVdpDEhNLeyqbUuxjyA1ejpXBarLGtaFLrA2mc6+RBEXizlQBVK6NWnOSodydh++aNuBgs/a/rK7V9iqxqNmhIK2iwUbR1M5orTc1xA1vSPGOQLMUSSJBRomFjCxj8E1mGCig01RIgUWqiIiu0th5mzP43WlfSjm1KIDgkBthdzg/c0QYR5lNu/1vtqrjbeqrNJD0d20xcwu/+bP/Aa3ht0jXthf8iqVKDsGlO8OkvlP6XDhd2vE7nMGgr8vVV6CHsRsuAEws7NZHjASM5UbPEgxQlRoMLBjQjslGX5EI4AhYQDyv5Q4sOo2Tr9oDCUGkUdbjI5G9bLroOnqGgvBcsAqGos39IX50zSOvEi26NVFzTeITa/Txb9MnP8oOXiy8IeBxPYEMteN3kTkXyD67Ir7Mv6FAWfJeQNaeP113zVunO4baHeN75faC88ki7/QQcmfEmJerfv3TU4NUVAQMMAgaUByA8k3EBHWIAg58FUusbwCGZeRUi90zdv0r532c26x0BVICkiLu2Zrdjk4JSbB6Wf7u+t37u+/mxv1EgMt7pC29a121S0pWXM93rZnc/VX3U2+Gcq9UlsDLbYbc677sPqHWro4FJC9wXn6+h3/iIg3pPOIEBg7PHozofQkIgQEhUXMVoTHwpWsVM4HEYqiM3KNpRMDisjLhjIlInrXI1RJpmLdrbBrohP/7smSkBYTPXs6LaTVQdAh59mUijFUhdTatsTUJkazoWZSV4HeolRe6NJAwiY61qF+F51stGH498WTZCiDpVvw/mSsWK6jQTlOgWP3eIg1SZZTLks/FDhB9QdiPSjmsT1hZISU3TVskUjMIhLfjSP9A71T791/d7SRKtDlSZEfmlNPkCBnbTIdTY7tBgPboIV9fsIJpknoLNkgxqNEkgyEiwJGK+ehW1d7JIg5L3Nfh7XpIVwYREJefZqcsz4nBPFEMWXiRFwg8a/UxlqyhY/s+pB86vnbd1d/VaMc7IKE62mNRh295Wi9V9/b9Wt8mVPbH3sKke7qqAwABAACNlIDFB8GlZtbSY1smIiBjgAAgwxcjCHuiBgYqUiDHVnGJosph0U2qooZOzcBQ07eNIzij3KX9days4cU6xUjck5mOFRU3kmTmzTMMwaQLxttOupnsiOJaWIj29vb9rQdO3XNMOxGhUmyjfUb2bduKx1Fv16hMY/eMmb5Ob2XWhZ+VJnbLqeinVFY7qqenuPtbm4Iz2sKHuqKQXJpUCfPuAivFyutlRgZQMLBCEFSLS2IpAKaISWjwU/TM4bp8kIIFfeKSp1GQLS98h4Jw2WQs4lHoownEkhkZn0ZFeoU4Qx0EAbVOQgMMtSJqqbtvzVab76t01fVb1f+7NRP/+u3PIIYHSa5cf0gYkMsSCk5Ai7CMOaEUan5BokdBxIzgsoL1yz7AV9PkIa0+MVrhdL6hsrgoBohD84VvoqOuvibeCFQcD6rgcoWe+a5lR7JmBGBh+MdeQESaXIOfuBMd2BC4kWTb6mPZofu7Z+LJ7aCD2CdTAg+OZf/7smS9gAUoX07LaV3AZ6r6SmDCiBKdd0MtMM0B1KzopYSN0ZTWZWPUx4EE18qBkFp3t7El2dM81Lc06GUCBEnoVulMpjAfWH1+sBIkZwAIKJEoFmANE8UUpWUPFmwYKB0uoGciBpa7jpsjRKhKkqSSq6j3iBnrCE4XCLeCWGIMd+E5+mQcWQj/67tCBwvTvei5l5c8qHPyfggRnolOK5G7m5oXwnOu6VzzzkwhaEaBzJITn7wGOiB0jM8ezvk+HQIvQWJAgdLEAwZDmDaGR1rpTDGQ4hGrBScuIl+kenjK2WNTcWf01phdi7ZSZWNLz1oMHEaqWSts6MuXi53qf7B9Talbd4ojeCcxTqiwGGmenihZninlYN2UJf4+IzxJ/J4f4uys3a4UG+Lw5/h63bsnnmni8mpcOcO/gLE7hVSI/50q1me6ud/DBF1rUB5eDumoD5098ynXp7Tr7psPU41DltGO9xDUz1/tuMSbcsmv7y7/vneoAc6QAy7VHbHWiqVQuKZDhDnViIHSnl9kLnY1zudrKDxnMaVqhQ8vo1ZO9fXnrnO7vPuJXFK+lfjdf86+8z68E6CPma5nUfxWBWQn55g4JmoOHRKjFID6dqqII17rSUqLmqmCbsc5XpbjbfW6rgaP4Qd9Cj9oNrGBOfaEPsSZUWE8buLLmKyvxxTVMkfup+KchSS/DvUZBZoiqaS0kABG0GPgigpisGc48AYkNKrHKDISuOGWjufKJaxeBHupF2rbx/IFhEogYb1Imp9CIS7bCMHIlzDcaKklZo0JkqgiKRKrRjurBhVCIYvIbODPblFklcugkmMPQjscSEkjXv/7smTZgAXEZtFLSXzAkqw6nT0M9lFlfVHspLLB3K6qfYGWYOMO7JOsslEd+aMqk9hIw9HrqVBVBYCOLibBxyjJFURFXEmGSUmNlhlSuIoANlYQsAMBiS/DxI9K8YYiK0pTp3VbYwzpsLjO9HIvep4flGJuQ0cSos3LNiU2sRU2ONlSdjDMWGCQZm9dAidmM00rIRhJK1nno6VP1XoJEVOiXXdr99GZ6q2Y+jvs+cjTC6KgiQVlFSxJWLZN3U1qQGGbSX4ACBXH0JVWCQmviygtOBWAIKTCxUeRZYlorqJTa4XapqjrM9tYVEQhKBwkLy1JC15JGrkTL9dSn7pGa/jX/VzLRIomSff3X+lc6tBv5QttOw1ts7+sIR3Fp175CZ/szPclSopUY8GZbpZ+a0z/OF5JlprHpz7+1BaPjSRLDljyzNxyNWDLXZNNtV6321Fx7RzsvxsFDsidlCIAJZEBWMYgIREqZCgqK28EGOu0mNSmWWm8lUlkVvU2a1xtWedOdsr81yNCFLMiIee3QuoCAObRetA8i+qh0tFb8/p/GW11s3TR8nVTPVuqVOKd/fBM34Azwln3xlAIwAAAHGJpIwQPIjiz2noFHaSY8BGDtIQKoPJdKzGAhA8EYNGaALchk54Oo6lJ+1LhiipC+tqmDHhvosSsNWvLsLQh08sJiv+z6+U8xvcNqqfwCMEOpSrO/xjC1H+wMXYqVavLF4v2A8tK8uHoUuOLYMquOnWiucYrOTHWZD8dUWpT+j6URE0cJAKw7afWdqUipAzpqdTJVTD2erWjc1afGRYXnB8dOsvjodLjgcj9StUEuK0Kw5q6Wf/7smTaAAS8XtJjGUjyY0nKjWDFiFhhizkNvY/BsaxpcYQKaWJzbfMvnjZKZ6SAxdZX/SBQ8RtVsQ4BBYNehu7cmEqKJ8KBt0bG2rpNPdWrLqWqtaAo1Arb3F1OqzEzsdssI+NS+pnikSaUoM0jcJcOyw5ao9Hvt07ev1IpcrE00tsza9b1RaGVlVa77TKVcCFO4UEu6XSHb/5VAAMZAgABQABD0BOgWTTIE898XDgk0w+mL6RRgQQ4iIeJH1YYqqZm1JAknb5VbD5SZGKeM8tF0Km0PoK2pfaXI6rT611y+2Our5rC9llsG0jNl/avrsoS1b7DsfecLf21kLptXK3ujl/WtyFbWWTl7/fPZbChBNNrRqaovVVvGvmiq3wH7NNOnNmu160ELvz0T8b7+Y0bfjahn2j552dpb6R6pBAJgBQcgAACdAyxMPi5gF05AJA/ZcgIQIxCSqz309PlLpLE5DfkDjzErsWfYhpxeycUFhWgbhDVnjmFhBQ9P+a+PVg+riZ+0iGCzjcbwWnCwrSq3FL/szLQ8TsX2KItEp3uoU2hqh52+Xo3EBp7fXMU2wgcMk3GwIwAmVQgEOmUDJVQTID46QdQqEjcSDzutIx5pCTJAMg1Os3VXSxZ15l+KLTs3DESmnxk1JEJ2gZ5FZRRA0yshDR4mLFWkMcFJIlJ7T+VcytzWzE3b3I5vKBaB8HBPcUmlkdrZWcZa3SotO04Py7NNz+lMg5n4MiFv6h/UupXKq80UGNTTyKPZ+Up5f349VLWWLYqfXSWFebBJ2zKu2tRH1PmIpQICRABZucscXeHVpqKqdhjABdpshdZyC4ocP/7smTsAAUZXs7zeWFgdytaDWEDmlR9eTkt5SfB861nGaYhYBSrQT1CEpCFph6Si4yyrNzRwwgNiujGrA8rni8aTDDWMvgdBFLI0dXUrV3N3MNCbN3BRNQMrjhrHVCXF3/arcNh+4rrc0ps0sQzc/b+NdJ6iYRo6aWVeMatckjmdYgkRQ6O6UwDEAGBMFigHO8RD8xo4DkasIgqQlkJZg8pWKxioECmC8qOJIqkSqLr7seUHcaKzMPytTV635cA4RJnBY4uQi6a2ebOn+HpbE8fMorPUenUMwcyEsZ5MO00tU+dTDY9fDof2LtarvjCYT50eHur6btKsC/sgq1NUhbimrs3JSk3nOv5SaT9qhZbm67Fh2a7CsmD6X7mYd6buxf9Ftc95HJXIX8hYVPy81m1Wpm/TMun6AB2FOkgAsYImsMEqAhTmDiW22SzEIwwAuD0ERfwEileSiiXCqSNQ7A80EiJoOxm7HTglDSOepHSY9MqBkQOWcFiqU6bCiIxjoKijtV+MrVb1oyD8jPqm7dX1U18ntWo9NG9WKjkU53vfSpXN0aUqng44hylH6LeVIDMKIAigMZ8FmFiBIEmADx2Eig2VSQqgZIB1HKwgyVTMgJfZ/2sJeytr9d/GBz3YZMiCYnIBZlInVjcjbElhpmVJMVyqPf9/svbv3EOglK/UX1emo1YFf9ZKVUWa273+cY6okv+pFj+3Z55mZJv5m7sLdVOvx8PtnvdZH6nepf3arV6tsn+LceYEvxgDnjwwVPaN1cAIZTAK0JjAAY85TSTQLMjS05QoBIloJAAGL3MOD6AYDZx/L6a8TWg87qU7u8kUv/7smT1gAV+YszDmWFyeAtZ2mkliBKFZTuN5SWB+a8nMbMWYG9e/Munc05VELxcf4xgca3sr/BzNAuYHU7I6tEp5zvi6vxfRNRj2UZpbQlGoJAINPD4484sh4CD1sIM5GMWRtkqTpJYxmzY0xBSgqIbvoPVM4jU10HTAxlNFM03P8AEHSwDwaCzLBFNLDlbpLcWTMKt4I084lGDhkx1QDp4BhHi5TFQc5HLANclxeYbYLKzTN6qH6/Y2A8kxIkDIkZW4uqviuMZrZstiRblmCwkrQ7aoKVRVw+hzSLCnR8FJqjLxrOZdNOnAzkhF2hsfWEyhams2WRLvM6Qe6lb2u7cqImtl7M4vV5n+rNsjI9kZh4s3c1w9u16k/8Vz73U286YH7bH7zCcT6N/bWrXUyFxaORrMebQJraxHvP6fXtm3+//J/6CEgAAAggaYIw5lHBmeAAqOMh3MGEVSL3pijoSRIJH6yhVxT/vc/8xDnx9Q+Zjl7EAWvd74Wx7TX2Jf+qxsRxd/U1jJ+RkRQixzXew07mr9AymJKX3HDuVH7KPw15b03mZ9dzk0pmJ75koKbnZSA5i02pHUAICwSe2lYWOC/aW5lCKY5RtwMSDwEggEHKECDyUDXSCAoeAKTJgyw063kSTte65QFXFi9MECuxkdKGHDuOsDRJpPDu+0ix9mvs/m518TIkSCTW81ikVzpmjqcsR9QxcmtDo/oxTOhggXy2vgUmKLfseUhAig4knC4/QVx8l1zbK0EXwTKd1dkJDEMwuxFC2WwrECoNwbni6trUv2g6gAdY3v5uiCfXSyxJEQgBAwwJOMmJTO0tZPuApa//7smT/gAaMZsqDmXpAcyr5uWkCnhRhez2NsROJ3S1ptZYNlLbSXvL7RRl4coiygnAoLerAyyhVYACDi6ZDZATnac6JEO9Oumk1DvThduiOSGI+1vMwhaH1N90oGLKFXiJkfQ8dzEfnIhcQjl/c8tCvRZ/CLLanP+SJuIFmhACALubX1JIALSJRRMdYoRVmGNAYEhFLxYRZRNCgA/qijKVN4zXoFwDCpwOJZF1BzxauMamDS0/2ltMD87MltI6ej/GFmUOG8fYbbuZvnJLDMDIQ9iQh/CpFVbgS9pXKGKilKKPHzCcGpOsyGd4rMqpGLhUq854z7KfQt2/U5zHi/LZRhR6YSBwPTclwp2JqYGdzevoErJEQ850fLWikX3dXkzWwMhuRKQiULE7Axu1Ojy+MLUyIWJ+CrJiL49h+g51UrC5oeuFGuhdy9p1lnUfooIC7fO7xoUWdxZxwMLGQdYxGHAJkW+HD6Nfmy4CFY8JdhkC6X6bzUuaAXBIUFkeYISG4YlxuSw2kGtY9kRZD4wIQ6v1fs/stU6ROWp7L1qtIWGzEhDTDENEui7enW9uhAwBvsyCSBiMEVIITGk8dQEEXSdTECDPlmVrG1QXzqHVXvptKdcM0Q7JHiRTxyNENCs3bF5QL6XetcN/d84ps/FQ4sLen0Wl3Jrjr6oT6DVDyAJOj4KaUkFFluL62RlZgfBdRdV4/S/Cfu069OdeSSlKsX7il2Bhvdzkb7Taj5c5XjnR+xSOtWCDVnZYtyTadIQF6JEHIA+4IMMRZADtYS7p0QkveCgBwRUoBhBUVVCMRDMFMfd72xbfj6wh1rLXkft/Gxv/7skT3gAa1Z09TbHvi2yz55mmPfBGBe1XnpMzKE68qPYMiIP1Wpd+7s7U7CgYJl0qOm/RF2R/8SYyDH67xeNh7Xz3RMuZevLaUvLS7ZW5VYvEXojfdaEOxo1J89vFSkTIlAxZOQZPoupRZpTrpv0+9DHRAEJoZUSXFIgpkLRHpRUHTylbj0tNaDFljuS4i95HQOC/MojcqDDXh0ii5U8p/cOVU88BWaCGsiiWWn83BFzVsTQdr1BPfZKiCJQCz1AhPoMVCzaqYNrii11MT6P+rRhjJzcYz2hWaUa/hYenRpt4nipYRo7nfo5mHi2Os4+mepjKHOfDdZHMRbdTAAABgJB0MAmIgbW0NAwk7E4NEgGLAwB+hGBFt8edy6Z839UahFfJljLsmjkQAIl/lH267R3bQMx8jztxZLaWRfOyiTKEmZ3//k9PUKb+p3TwRTyKC/9A7cnCO0obM+iIxubK0i6FmosTxYix9NLT89W8yhmsucfGt6d464FXYgqdbHaxMSM45tTComUA94CqRglXWFh/oSgAqMnGT3Mldluy9JEOg0uSFs6sIvXpmur0s2wQkwG6D5EKpQe5zJVaV7CON0gNHKu+j6UzCOeaHdf5Vn60G56scy9FNY6iapyl81DlVz62ovX1Oae3rnvXWqq9zs8fRZg6AnweqTDLbicaZIAKPAs21gS1Of1nC1DAATOVgfIt+1oCrtmlzG2dUkBqifpWZs1WuII7wkU+PXMfI7dmNe+mmXtmrPfEqnEJautWpw/UrLbsoYMWZyd/bnz/lBXyE1eYK8w29zTF+YbW9Z4VVafOfADLJ7WG4+vR430j+5P/7smS9gASqWtHrLEyQbMsqj2UneBMheUOssNNBuy8pvYMJ+E2ekbPOx5adxzgpGBQUWp3guIBSFc4hvnU5KHOmYdrtVwVJczQ7ZEyCyWZ6cKENvEHrBedQ2GFjNNT1kxnnCL+eRkfRcrhsnNRZJmclNY3onBxf1J5/xvr3iojZkE/137vmRoQdUKKqV1UjPTlZu3fjG0du9fe1F5erko7VtXaqO81oCbQQOU7I8KJGsZetJFCYKCiAAAQVDTHwIRBRkhGcUeDQkHFKfhbAwwJpiYASoBx5WhPxmk9SbwvJVB5fn6uY0NU5r7aaY7WnG+LplZBpzBQ9ukO0m1cKVFvdNqn8dJbFqElb2yaXKt3BotGwlP9Vm1E6pZSrn5hX3Jm1tcZW4Sn3b4T1c11Smzmgix+NpdVFK89aOm1VbkyWpA+/bBArsHW8qglPDyXTZvzJYu1rW/J2SoBDEpSbsSIAMTCIrzLdAw+DhKUOkyn13P8RQgbGkayzaEQqRaUWyXdfg7zmRvSKuKFIrFLGQutbGsYOKDzOhkRV1ctWOqloNM+u99U9PpQWx382CeiKpSG9QNSsSVhpwCcKD8OgBAAAJlYAmLAACBYZYHZx0ZiQBRqMEA1bRhgSInEQmREMChZMyGUMEF1C3bY66yb725wI4K/pmJyuJvJ7rjVWqC/3MulFXTdLelkK/gxGumKJe9ZENaLH23xMwoL+1oav88NLQNUaceloka23l9WttYvGgriemJI/7KyYniup4A6l9Q1mZaxtJWdy8CPB9r2xh2cGAkDr7omaaxSzjj7yxRLuSBjKG+5ImG1zEq8hIZYaWU4OAP/7smTgAAU0Ys7rb1tQY+hqLWEiahaZeTEOPNXB2S1ndZSN+DGogqIpAAJBkBpsxATwpxaPKkzaLoMCVmCwbtIBpVZtw1Tj7YCkukZIQ9Z4s2kiZYyYohmUjz5v9+dSlF9XuZ3rWTNzik3m4tDfZ3Y/4jS3mDhpyU8/hxsjrSYPhmUjkZRslPpF9z/vrMgqH//qusr0cVUHfUpEQQwEptNJKmVCChMkPETk6gNoxZoISIIl3qhLQNzJQMpjcwECoIrPLIU7XX+wKZFT8yTrA+ipSQMNYThu2KJwl5HShL6Tzzo3naaQrBjCDbJWr8CM9KwNm9QmeqIQOVnvlikydkqi52brN+Tzbs0Wdsnyp1XdH/0IuG0s4/dc7+bjjluyzi3pzl4arNSRcdUQj3nzjtn8Kn8v3AEkCFQEGNDxyDBjzQkRiio+wdRVOVFeHFhqZDG/TvwnzAecDS2QyabmQokzOhvtHTnJFxpMh3lPWxm7uVrf1m9HAWn7F59asqC4SxjVQQGsuVmmkc/L9lckLwEJnxoYzIePOkhEZ7GR9nS4sz75dUioqtrgGW6zNyBNBhowKiDUx2Pp0QwQQDNliAAcTYdQ2gcVjQMvCDpNDbIw8gIGgCCAEskiDihciZN1ZSswWDsxzcdgiIm7THazBhx5Yb83nrA0wsaKFUwLMcM38toyLpSRbXZepAc6pjyLmG5YkYh2OCqIyPhq3k7n7biPIJjDXTC4Wyb07NU9G+M45Z0SlK1Uk01FMxYSa7MqNpVqyPMpkFBaamE+pajTDZo6Li66JjXtWTEdcWgxT2a31NMDS7rI2ox3dKw3G6sVjZWR/v/7sGTsgATUYs9rSVzSdwr5qWjDmhsZjSYOaeXBoCGm6ZYVcOH221/iu9eNF8XWP6vw17jyxICApQQBBMvsXsAjZypm1gu8SJEkGdsjizgqBRJyKDczQ8bKlnaX/MfDCiVIa1lno9y77ql4QEFoUj3ZJzHILir4q9mAZnkbO3j7L6tRGeqtqlVLoH22XPFIPuJG4d6E6KTt4slYRdoqAwABIACMWD5IsGEAxgLDa0BBIXIMDc3HHDA8cgKAtPGakkJa8BqBhxiuARyQEMApMpwGSr4SdhwnTEMQk7XFak9DgwEEzKx8iZHsN6pnGNVcSz9uivcN6uZbn40Oqy13XKn8OCfpJH94LNBpaIunrmwPt531alPiKua+Iuo+NPm3elLBpM0m5r5rrUNzltzYSVbR7vrVh03mHHnzJSnt4tl1Ws0z4+4kkkKPF0njSzaMS9YjXY3JsrLXM+cnh2e/FgiBYALY8HBToBFYOXnOVd2C24gWcMtc+ihxdFZjx0hNx08wMJzwsPwkhHcXKMdUIamuzDW0eR6TuutCg4P0Q1y0oe5cwHL1GDknCkP0b36P/P0fKX/Sbv/Nu5rHZn2oiVPNepk0sMWAIcvb2AAiMgAJCIEx6VCYaHDV7wLBICKBBhktDlocChexUyzVqyODEkygOVolQem5hbfZdjbR6B6NxEyGS1xIdJDa54I4tPcKiiJlYUjLDrW7d9ptU0ez0+0hMo5lKijXIUsTI81y+KlEfWm1WxKZmF92+sNfLYduWo/StjEwd0pP5KcszW65Ay9nT+lkPLyhQIu7PluZ/4mqxMZeK9IqwHJpM3LyHXYff2Y7//uyZOoEBgdfS0uZeUJsCunMZSdoFX15MY3lhcnNLycplBZwtCIEH8ABzKhARADEewTMOioTANYu5piT6lBaOwsLE4flkYcNVCk7RU8onuuiUI7mBkGo0scHDxnb/W788vfP/d/w7hMc1JHX0SeMe5f/YsekaVq/oR+lXVc4fQjSduxO7dUo5zvkZ1rac7rraIAc53j3ohI1GQfoAFCAAEQgGQmxYAIByTohnwKKhk9RGMBwhVyWkmQCyLN/3+hE3CoYgh1LOUAU1JR41a8vjMvsWsoxApJEgYkejRTbZKMJt6gk3dGxkNidtzlCSkBIXAGdaQUjmuTz/nhgjC5PUIJIGNxNGiTptuNphtFwoZoEEBGvgUIoo4cujFcCF6ekYnfZfKR6wrN66U0L8pAg4r+0KDxdttwZ7IoeE5bDIUikiKxGJ9PrycdMkFzm1Hkrma+5X+2CAA+9gAaIbMAYCGAU6FShgi5srKgpZZdSSzQWnYJcLRhVRuaYz6txgaUqdMUxlw4OrrOHlAXfK5Vv6F90zi67UqOq0vdfVsXchTLGEJYUS8Ugj5Tk4WKKSkVHrAt55mqfkVXyKRUY1pvuk2JWnXZ+/ohjHdPseHUTF49obeolm5uPZTrV0W79Hrqjy9cskVugv4UM/56TJ+tWSV5tgiN6ceH5NRvjxFQt128YULVjetqwcgKgoBWKkuaGOCpRB+F4YjkT68wts6rm0rIEVznzH7yVqiWWP+8w6VxsuUlAllxHcEKGpAhkNFViZC6ACJqKjsoEIsLLitclszjM6b3ecLqD4PUErUWQQ5qwYaQJDGRORhPP3vD1YlpBEqnt//uyROuABetnTeNJffDTrOm5aY+YFQGNRawZkwpvryl1hLJoWYbXzm4KKzkCgkwSkXFd+edLVW1FmtvGxDtYfyznx9Tqz8TSGsKrV0r/MsLUtnHFMd3D3UJWtlfK91fBB0US63eTkSthlxp55U5FygXFVKV2CT+ps1Ysuaa67P9aWJd2QttIR/2W2xNFFzQsYqgjIqSJSZQ9/E+uNegxYZ57z+rElsdg7TdmOagswL9kjYrULc10km1pnBu1cW9ujTccv8vk3YgTGhjchZ1KcCJyIiPhbSloDtjqVOsbe+Zhj2zd2+/4prnN58stuQDyzVLtbWNWUVkh7nPrdWrYdayGuV/q3p23OaP1+zXzXHXGrmNlmE2cu51bpVAfNvnH2i0gMastsgAAFizgqoVvBv4bUE6wpHdsIMEgOID38mkF2bebZpp01m08oByKxKbz29+2kbft0Iv2c/nk/Sd7ZCxtdciUI3Ry45vmb2CgWheLMtxgD8IxnV9kyHexqu2qLmPxUMe2n2gK+qp6ae0X2Ys123c6s6iVn5mrutuPR22ttcOPscMQRNsWcyw3fdTUdiLAYqbjJmlUbEhod02iSRDBrQQOslyTBicBLwGN1Fi0ywUITbq3oiyeH7L5xyC57OX7vq9Iej1LkPcH3Fa8ffxd8Il7qFn/r/iSo8paKd0OxSdQQCwWCdJTcW3Mxk12QynR6rux3n/0Jul9XobUGDIUQADjUH3pOzKwBQ61JagAkeFGCSieZo8oeaCF6mxIdnuVvVEshgj+OkVpiThLdsjp78xKA2C5MV19LIKCbCk1Grxkv1x1LZwPJfpZvUk+OD6c//uyZKiABLBa0GMJZPByiyp/ZQKaFBl9PYw9Mgmiq2k1hIn4AOCcdtD50qKvGRtneXl40rHernmWCwNWtUpxm5mqVFLlF/suDhqnsu0reM9GWVqc8qR8njjBWGu9vQuXuywmloiXQRT1uai4HSmxyKM52vUSyVymcS9ifsQ0XS72RskAqLu8IyoGo6zTQlNZXKKN0YomI32G34Nrn1VXlyeRIrSHbdeQj73/WLLXKKkJSz+T7qUIzxMhGX1e+slcYoTGzmwE2xG9Dty9mqFO2tsv2y5L1Z9K0ZaOX2ymdW4NJB2gOgAw4SDwBociZwVcAomcd6HDE0AVGswTLIgVLBpRS1NWWuWiM7iqDtukm2nHdnRQ+X10LldLr7nnSt+8nxclDU59X01bTfJgp9MabhwKnnPqqUNSnWvSnLEWNaY5/DyUrLYtmBIS1msNfHR1v8LxaXu62xxwIqybNxoWIbK4186YaaXqlL1kE+p59BazS5JG1vRwoZcs8mR7/PjU7RmqaPysRo52uS075FEkeJUAQIqyqokkTJAT5LgL6qwJ2W3QTchkOPLVpNSLnMikQASDK6ADnHsciaxaBkjbTHS8emiiqNXsjzF3D4CDyIkSkqWOive+GhEYjeCrJe6lYZbQx6QpxZRvzqQXSRAKIcpAjgCYDFaUPiU8DjxwESDBZQWDAIEIRqC6AcrADgJ05dAIQMmIAULjMsUKxhwBnh9AXbkqFiEzGsR9YyrNCKmc0qFc9+WVIxf1szwCvh8l55ZVvBs3X6M9tTVErGyh5TQT86Ya2Sm+jq36pijYHS5t0s9mgdMoPGj9HZFEyi1UkmV7//uyZMcBBWNezNtZYWBf5GovYSVmE1l5My0lc8GLLKd1hAn4mz0xJZWGHHSbI3Dy2IJRnHC7nctjcvvt7RBDIgU4ygACv5Q9RcmyF3tjV8ie5EEwpBCrWpguHsve8VOHKxjjBTTs+JLSubpjrrGJvE3cfO3VT1DBLWg3pZNTtSvm9feajX6fQ6tVnBIrLWfMfL6PVvp+hWUMZ/eZWaombgQEAa9HA4dCw8bCcHEkJd4OHA4qLNmQp0nAAMo2CRlqT+NiMUEYHaqTDaOQiCkB00noFUcK+6TMOfBeEIdQm83GmPKrYDTZRxonin05zsLJua6uWYmoLY3PvGWdtSvxbJ8pRqcB2mM227GeWIUdwcM4RNd0WplXq/WK6vpc2iwl9V9ZZKLBpMeTJI+aKGu2LqmZ9nfsuQVGmlFnsfOfOSlksuPctQ7zZCnCmJHOwuM9vX2Zmnz0Y8RyrPo/+9IiKBLAARnLD7RCqAgTOWsJ1CgcmJAOqHTIVDlcxGBTSRkiRMxQiA6lsH7S0MKeaoW5DJYOcj/k3auEW9vlxMmmup5OXd9bUypr/+5TItQEPHirgCbDTC0OCpJNgqsgnZeMKixC1qE9pqYcGHAIABryAeQARuJmOgoIADSzlJEaAhILMKKGvTqwhWWtLKoCpkkQWBBVtKo0BNHhQl6dSzlIT5UuMZwQtJVjoUzxu5s0Tba5ZtCoxzUO9Usl22TMJcxqbbH+Z/FUDI9RIbkKsqiVLNJmh0ZXTBPPJcEX2NpiR/VJzEJLFJRc/aPg+v2yRBOSFaoCMvPZsNtRA4XyqZQ2uhlFOcJRDYqjygr0/0CBSBQl3sJk//uyZOmFBe9gyitvZOBnh6mZZSNmF4l5Jg29M4HWLSg1owrcsU2IXObnlzYsRugT/6t9c4lns0uaBDMvENMSnCYya0mnI4QUJSR2Zana9ocAbPyUtWU0gKBl2xqitQzJMMrFJG6O63G5rlt2dyPdSCnFPu/yvlppVASDQJTzOm+6fSDElw6GqR7I/Ba/VtkztuU7HbBOhpyPmvkeVv/2eSnmnRsO7DMR1QAzEAh0ohnAGoNvCcVKbUEGCAgeZ0WVBKBIxIFYFX4sjL0Zr7R+IeL8TgXxbgRgOQRAji0gVioQrpk0RRIvojuOoHScKtzBFOgRBFkzq0Fm5cOzhaTczLeo6m0miyediKp1pEc9BAqsyLay9TpoOtZQM8xMblFFzqzdC26z6mcpnX6FTO9bPahZ2oJns4Xza6mWgYkkiaRzDKYrKhxCXwulxI5HzAApRCApYYACEM80gNS8zAgOaMvMwGInTTiJI9xAEg4DAmWUkYgt65HGg4W60brYrZHR8jngy5rf/W868TVYMatvn/f+P8er+NGrn1n163zfFc/xAmoZfXFDxX2RRxVzCJY7oPHn1O+FnVjXGSRB9nSAJJYEw4rhaCgiCgUEgaKKixwDkY4cSCCowcNM1MzURcypzM1GT00M3VlM+SzCEcyUcMQOigYQ5GyYy81HCGAkTBxExukHhFwdBcAZcfOLAeNXaIyogoNfS/UjmDxtPdWNuLzMmkanEia+zB/YHGjIEgcMFPadMTT0uvKJK/+a+VGZ6y2jEHElSNKFcIU2icZeOGajeN7MxeCdV2WFkEqQh4KPEoo7k58q3u28OTj1ML2M5QTU//uyZOUABSleTOVqQABwBXmdrTwAJZIPMbm8AAw5QeX3NSABqhE7L3HwkzvxBpk/ADw5V/np2myxl0GwDlLN01jtqyqxzn4ciVxuVw86iajxwZCnWxldqnrTu8eWt6l0aryuvRw1TzlXn837vyeHKGxflMOUs/I6n29b/////////////////////////////////////72e0ZbgAaMoDBYnHoKCIaBIAB7wxqyZ5FgSlPcJBTkyU0zw8ugDQZvT5w0ZuGIKBA2YYFG7qU4xS4Beg7BLAhUnjxgLUVRggSsFXDjBPo4TUrBaGGIA5UORDE5HhY2FvYIAFREeFsTsTpBRmiDkEAuQUQAbwOzE7Gqhyy05w1MR1mssCPA1YJwNARCA0ZUGaJ9yaLqZfPGJqbmrhqwDIgtdAO8AsxuDsJ4nyySSiSOESIIbGheQdJMokwQA1J8UuQAqi4xqCPFF1E0QQpHHRNismmboJomaag8At4zAlAhpEymRIZAMEDHnUDdFG12+6jdNA8p3Pq8extkoeNSfcihiXyJmDG6H////////+x5PJGW0IFAkTAQEAoEAgEAhNKfcyWWlhgyS5kjHuQAgjBHWq5EVMdFmwiDLMQOpQpNZLd2avu3zHiY8Atah+PP9IbLwBy3ybZ/n+tzcio6KWkOgc0CICgmST8JcGUTkjnJBT5qDoJFaWdpE003LaebkteN5UlvKaAS1rIOrqa06DaV4ZlNiioccKtPZr6qyKHHcZZLmWTK63DtUlep3Ln3qbuVSrlZ3ZYi9T7xuU0dM7iw8fk0tpb9ezlnNa1TasTfKXu8ObyZu47L6SZgD//uyRGSABxlfV25nAALn7Ir9zGAAUZVhXd2UAApIryz7sLAEGD34pH81DlJXyqfzvauNXncdd1chLIujHe3CdD3JDofBGIhEYk2tIhNGrIfiLSOqZgQAzlBqwEAzBTBDjysLEZWyAstHGcFyjIRt3jXosIqQDBGvuO5LbvyyRwHUja51dvCmC7MqoMFSJiNpbm0plcK2sad2WxSAuy2Lxi9bZ2zt4HneWAIW78qsSumpK8DuW1t+3cpLClTR4LlEpppBVpq8to5TKM+/Dl7OHMPr1pbE7MgsRV96eOTdDVv0lPdjEYsd1/aSxGKSIVYzHqTtajcmvf3NdpsrValw3dimNP+efXcsfT6w7g/LtwVaqymG9wJyamM5qvOfT59uUF25WzZmkCMVQhEAEAM0CTqjTRR4T6R9XYgwpOZZsj24jOndfP4YYsGwlKENQ6A/qhxB5Q0Uujg6PIbEI848hiC7UYomEI+7MMD0aymyMKHIV0ULaPTj0lB1zjxQgaLuWRrVzNRTkWa9azJ8xT1Uq2hbxVQtaTaJy4yZ1/e9IrSP0lvKNgUjBlbXh5CTW7FUnDB1AbpDKiGoIBl3Hr6s1LVS0hGIwkSnJUBbo6r5ug5DlR4d1gyH0nEgpJgfRA7loWOpnV04SJqqTkzzbY2z11NnV+qh1t2pGhobxKG5Uqs4dfn7g4tNPuHum0Laa2s9W32ugdP9H3S9dkppvzrX58+mf2wy3Rd2zimc74f1zL3up929+ydpupNKn4dxs03hnrMqiiaxVCZWIxVABjpaABcAoQpolxVqLmUZkTqvkgiYgjfB8OsDsQ2TMQBvcro0lmFc//uyRBcABKxd1/MsM8KSq8ruYSZ4EcF5XYwkz4oNK6x9hI3wbTqqjdGllmnlo/FnDQOU0lNBoWWjpByjY7UVGEtmnR1PLZj105mTlEs6XKkz0bzpqYdLLMVtamzlDKjl3ZiH7uvGQR+7sGStVp1pFPD0nuFH7jaS2IKcIJ2bo1v23TCwDipbyOtWkUgyUmNSMAAAEOORDKglB2it6PHQDq1uu4yiqwEMMsuwCyNQFIitYUxGxUnDm7tHJVZOCkopcEySJE1oxUaTJkSRAhLgyMIo3CAKx9YkauTgJHzLodIvlqN7E0mqzpAlJrg0s/kCE4yd8oNu1a46B+taefZ/MSZ92NQmiDXd5NKbMannDL6ROysR283S7LhyDWQOze1zsZJgAAg4LtsIDCjRWCKVAoShTktdcpRWHYU6kBQm/ADwzGBIMZcJk6ORWOwg1joTcpCfSThpt3ilJOI8sw5VpFT0R5SVtozSJxK9fcpIw81kM3ofhcvO5W3XqxPoi+lPRp+a2mezCYwsyTLuGzerayMe5QrnPP7vrQ+zaRvdEyPf7JJmwMphdPaZ3SxKMryqERxoAAFGpCsDCkRghsw7KwqUb8qkWaqeEP068QkGTTB8WNaSh5NTaNFOCpCinRtx+3lkem5I6dK2k2ZWlpu37b4jmC0PpCKKwIMZ5YU3Gp7k/mwJWHI4+ToZBYkp8pnsYN0WvMytzGcjJ4dZ+vntNm6xEos2XKHAoIChmRi/XfWFV2VWRB0QA05opPo+p6JJ0wjPFEGEyHEIQj2I4WJwfKs3oqiZX+886FhYIiuUbfTxQHI9AqDdWdSB4UmBIzhpI+8m//uyRCGABG9gV3MPMkCIq+ruYMOOENFjXcwkzwoMK2t5gw55FSw6lIFRyj0HSMghp+Pm7P+Og+JSgjJv6G/PWLopLK4TikcendjtLNrXxo6Os/7d3Zrn/59hLz2dXlSBLjSKWxLpa151Dg6tcEs9TJBqrIJaAARhWyNeQCunYvVeKHdqE8yxOhnEadd1l3Ov2WO5VXRQUJo7B4UF3nKM+omjkdf9XQMSFQhtxsyedXng+MRjIu6KlPWK5cH1qWrSOp7H0FMomgkoQ4ZUxoGosCwQ4MScQfUKGBwmp18QPbVMey0ytqmpnIRaHRKBYo1yViSAsGdCYe2FhUVVIqkAJL0HJVkQbelsbE0tVCWY22fo6tblrQo865OgGUNJSJg/KK6y2oYMqQZfKhHFIQa0pQLIJQbLPeThpPEDj2erKloZwSFqSueg0XhrviKLcdtapW4zw25+3zteQdT3RvxlMVXx8pmNeEvKmd/FZT47v+7/9j2hjqKeTI1WA6uv8qQ3Q1QwCQABHmhMl9pdqL7SvUoWa3ua+kv37hpvdNvVl8FfnXxqGq8lDsDoEDXA6qyaiRaXZN1wRuVSqO3vJg10I1A4092PX1DbDEsIFuyoqJRO8hUmkpMy2L71j/Ml6hKsydylHGBcD0gsiinYkHW+zFUJyk9obGCwp3GquWV9d138jtyaQKAAEOgji21CzCdLhy0jjS0vBp601I1STJjUpqgZDOWSiMzxlV3phXElkTrxpmNI++6JGMkgJ9TPw/Mpsc0Q6oWXLEBKiFCS5DwXWiQUpeSJnkazSULm3ZVDtSD8aK/LnzygntThzxSVF0too+Jn//uyZDkABE5e1eMJQ3B3iTr/PMV8UTFhVcylEcHPLKu9kw3Zvt04gW/duYn4Z5p7yjp+5rrOMumYDdeqWd2dlQihJAITALBBQhQV5vtxOADMvL0nBLR/MBglcq4KgGBsaEkYLpCNLSQxMKqP4Je7Hd8je8p/ah8rSmoeSU+tjxZDNOOzFaUh6iQdazg7HQq1BkurNWbVqlR1MfczVa0FHPg3nUyHaP67lMzWsf5G02/7MHdlDEUMzEYAAYGahgCdpkECAESEkys6WW2zOopzbzoYNfiN0ctZWZnYWYM0XeZeWKk/pptn81LMI1nW/sx0+pqazP8ux0mE5dIGpWQMEWLCIu9KmrjNDfmSsNqlvJNXbWYd4No5I7Wbjl2Zg9RsJ4rZzOCR6zSVPZ3d3W8Lrf+/wPYJR4CaB51vZFbVHZHZQGEAAEw56Vg54mHiDVmBpCJNpzZsyg2YibOKOXOEEIl318zKAwo8NJzXamZEKIgaPvjkvj8EF6eakRUWeRvvjlyrwJfYJ8z7H+P9dO1PQX0KS9I17bgwtKM35/J+7f6eZfThE46BY4NPRr+Ky/+fpYRVRWVSKJEhF0xEpYJQ7txLRNyTtSbeOdbsqCLN1BgcBYGCULAiZhmri0mEL2z0l5TTy7LxzGGtWkwoktrTcot7FRLZUo8MMoJWAZmU/nF1MypGWHEzIFSHOuR1Y+Za8Nptm2TRFMnI7nSQ9SM0Qj4rsWTKA4ICcM3XMcEZe3nyw4gq8zkuhKzIhkkQQioDnRdwy4KmiabaqNtJdVvWwNRtvAHToOLEw4CpIfLuWEmRJX1NK7pOGdUlQYeWkQzBQbOY//uyRGEABCdb13sJG3KCC8rfYSNqUFUlUWwkzYH4n6qxh5h5Ps4dQ2MWgIheEC6IQY801uhIVYg8UUJ4H8erVrGxMig0PN7GfE3tIS5xeWUnqqZeZzObEbwgh4EoMmWFKdCnNdfne601wnVCiABER2lPilc2Vl7DEn44mlgwtcSrJcOohdlAKwFWJZFUak2yQ7yjcLfscmnispYfbmLIqaJAZCkR554Wi8gSXlJeJ47wBJrRLSvUdTmZskGZ3BqDbO01p3U7DlDTm2aPg87c1C5lP1/ly3bDg+s2eSLwyiAkreAUBwY0YmKv+NzUKbZAAAMCwqiglRBHBvk5CgklS0EwibHgzoUwGUqZZEipXmW8kbBwwpbr1lZLSRR3CnD8RSyLqNJWLRzAS3kXGnPmpvnigiO7tSM5cxQx6zmad3bZxe3eQzpnf9r8GaA5giFwLpqAxV1KRUUkqT2hnGMRAuyWsFr/3/y1XqJyJzakQQaRCBcH4ehUjERZKhIx+FZFL6UZCGA0kppYPOct8N1nUan1EhrD/D+kLlrbEcnsznRqKn1U37gr9SOxcf1NKbcSUH25Wj6SwlhvlmgyuS55UQuZ/k8LwZEvzRXLmskdCUQPAruIIk+iA5F1IyYBFOxDiSQRK5f5/t9P7znm1iDaAITqH0sdAWI8iJaPiQo0GCKRn6SERgN7qVtCchRjotDUq/ijESTTc27I5q+ateVLE/eSs+KhVY/CnQ88xnNDQTR2jghosg5s1coRAjXIumxZkyl6QghDJ89y+tXtD5GJFxhNyNZAWDiTSLTFM9JGGoUeB6d/Mx/zKs+j7EytVmhWoAOD//uyRISAA/5R1nnmHcKBzBrNYSN6T/FnVYwkb4oFryrxgxY4Sr8hkuyzpEdrwwBiNlr6iisbv4sse2ZBogJxOJH0hULqMpiSaqdZJRzHqU0kiFSP7/trpT8S8l6WggTBqTl0KpkHdHIFIZiWdCWDbmQu08FOchzKtAmacO7d6ZwlVorkwrVtXp/c5npRzwSK57i3gAm/OVOW/mnasnslZXIoWg2u0sEAES6UbR5GBBQMnoE9U+79d+5FEZFE4jwY+iwV0kiyCFgsNKJDGO4ouE6arDz3XWdzbKysWU5rXhmQnK92TIPQOiOimhOzo9D3M6YxS6JbMphBmSjZ1s9jMVJBW8GEbWaYm488hmMKZ1D4miDQ/ZEYsYx5z42xNa5JdojygDhEnERoGoLGX5JhaAY5CDOLsSwbKMU7o83CCdyqDKCnoG65VEGlWEB/G2kKG425Jy0cWdO76KdJoMko5HBSm5lhDJrakVh3F+rFqRS22sRSV1+RiLr2M/nfOQoRFVhwtTooyKn+AmWWxmy3owJtxvnkoIXDZCWRWxsyPDGYttFBGLoXe+yJaUocZgSqisb8MHbIuFOejj1Zy7wAgwxdg0FVRcgG0CyLpaidRvYCIJoLgjfx7iDQRORBt3VpMzJxRQSPQwWBVKAzZtX8pLFM57f8IjIwZCXYkV3OhhL5kUjTMjioRsRaM4384S0HWDAx1EMWhXgchlyk1RLlYnNGqQFcss15uysAUIu6OLEXXEZeytgTMo5VIB45SnBUQOqeBY7kxxI1MTZ1b2JgieKcxXuzYmo3XI42LwzowyWbSv0slJLe33bgtpbMbuIRr3rU//uyRKqAA+1e1WHpHFCCi9rPYMN8ED1rU4wwzIoJrSq5hKHoyWJaC20My/aWu8ZszH1+7v8vWcyt3vkdmicv7/2+V/GyMQ1OyD8JDW0VPN+OskM3ZUQ+WBcdSh5HUpi5Tk3Gzsvfl5EGE6lzQDEJY4TBwWDxQyoeBMNzbFSyUFSso5dQttRySB0akm/TCH2JJmGz3C0lDexdUkTkD4O5mRlpvWuvFkUt7z01rBJddfArcwSi1KVda1EfE+9T1rq8fxdxwkc1LrImpCXMOCEwlLpR8ypUSCdVRBbIAJMTFflVBlxKJy0ACZSnMmcovSqrBr+C8FWz50WkDbNpkrmRNRwMvXR/AbQQJlrFNpMTlDntpHXVRbOroxBSIZfgz2nc6K/J2YhsWrqSGexvIjnWcUsq/3ueWYrzTsVo0KER7H86pkz5S4IKJBqtGWWwGJcTXudKoe7QzjAUspmJDSAJTyDthZihLegZS6B0KXEbWmnTQxWMQXM37lPDVJZppRBMszpaADEuaBkYYeibREyWQRomxexk6zPuGpyRPCfCWnmz5Iuc8JrjR3tkfJjxxFfFL5lhzUj5ILa65jvpLRsEKsRJFzyYs9zVCn0T62PbjNVQjGCKVAc7Mu0PBCkqbGJRAAKgFdUhVBxghC7YNkIpCBdCQBhC8T6WshEGGXsysOoalOVoGsjFHnE7IQTpI90UCBfrU3TNo97kopn0wxHpPtWYu/nDCeseD0cMp0TCbtTT889BDX7Fd9hTziy069YlkOkvw55KSR7ozsd0osVKQPPrMrKGuUJP0S3/IRlNETiABFzXHSkaKSEfwWEXrbC5lKss//uyRM+ABBle1PsMG2KCSzp+YMOqED1nT+eYc0oIImlxhJnZZApYrxvYqxxdgLCIJMOVJCWja5kE2NigbwXnJwQFmovh2YgTQJtAkC0sm1FnttNS+NtiqRdKJguLwmzRcyfuQ28z5O9BeRLZnZ7Tdqm6KeW5zWlpA8jTaBfTN7LZfqAtD48qh85/u3+nfqrC99EBTMoWYIGiNUMs6BJQwKabsUsZLcn6GMQdARWROHUoYKiLRcLMjKKWIjYkA00tKZxGRPEpQocYWC7SpYowQtzApPpFGoAwsuV04RoinkWYkKpi6aoyKJNIF0xqboxaeXLKrEaBqcGBbYYw7rvyhNCnvPQtU3UvNL+4XlUfqtuvWw88qtbk1K9r7e1bKsJNRCbQ0dW8RNtyQ6qARNkACBDpDpFKVCigDhowqor1mlIJytIVUhugbPKrksoAr7FgFDE3qfnr8obI7uPPEpfpeqw+qNrVHN5bxzbFbpktS354aXrQpVTK9g5OUq5Q+sXm9LujodQxp2iqtZ18yAHZkA4xHsadhWo0+pJMAjAFOBPaygJ3qktdSO3af5K713jfincvVzOt8t92DdDNWiiVXcgVFiYAAAOOinWqBD0A6kE9y0L11oeVVQcuuq9jsvHBcRdKNizdPGndRCYtRKUIFSbqlEOsSZJWLJBFIzSN3YQsKIU7TYTz1T9Z+g63pp6bZ6HnJeaVlA9G4gKbnCUiee076VFlXtWhHhpzeUyUnY7ldB9bLY6teqmdhb5b+dv54c02tVwG0vPzM964ho/DBIvIgAM7SFiZSNYXNBb4LFRXosHiehpVZtoLjs5Wca2Tc6jG//uyRPIAJOBZ0MMPSlCViwoUYYaOUcljRYwk0co6rGixhJoxErdEkhE4y1xGTMIkOIMSKDuSs1IiJjQw0XGyS2k5TiacUn6t2JjJCiGYBBQPC4dZpsQKsxiI82MP8Onctq5QjEn8Zm4bPLROl4Xmx27NGFkmzWaYRgmz6mzP/jQbjdPFEfn04J4/17Wvg3WAATEQEAAAATKXwFgcIWREoNTFVYKBVUAUUolV2BsPmo1gUB8ckg4A/BoShWoufCSOdGkY8omkpip0tmYjllMJ4CFPWJu1OhOHe1xGIa/jwXj9hUPiT2Ycb8ADD0mB0YRUJxSbSZISZgmYWbwiE0+CxVKvOBNR0+v4KqzwZZX04jT9uafhn/qTV6a79vJVtwNe1p35Kz+J+f2SHYxvvj/4Pj5U0zW/r8hP25BmJMZGAAAA5jdaJhKDUWAiIvU86zV2Ns5I8BVdMswVDXvyiZfh4g0mylapoUUtSCY68RApz5IQt0vCKR2rNIYd8p0jlMx829Qg81L8Q025a9YiRhR0baKEpBe0Mx2OT5sT8jAnUo5E7eczakmCM+AlVS8/h53oUNBsMGSDgsFyh+yrj0A0AJWug3deSlJGJoxd8mypF92SqaP1GYjDzBXssKeh17p2YpB4EqbTfOphi5PMuemtkGu0wzDhsVWqVUqvnIXtylXK5LpHbUKMRaen+by1dmY0TJB2M9m27ZkMw/Vp8srfiA59hKdoixWeNWilVL6ViQbvUsqVas3ZWTcJhgH6SIhVBZxM5gla8jflzpaToJms4nNpz5hXbk6e4jW8/FrlGrmcjfiaz3mS9SRdZstheHPrxbFv//uwZPIDBVNez/NMS3KDqsouaMOOFmF9Oww9M8Hrq6k1gw5wlJBAIJhiU80AlASybuz6uaSXrKQFLUeJORe7rsAgV/ZycW7WmJUenVUQI0aEg2esp9jSlVWHC5FveHFWRfG+bUtkZJG45VHr1lJTlM17zlF2ujF8ItLoojInhZLdB2S9hTIyvlTX0Xtyp//vczLEIZATSCQCL6MoJCFoIAAgQEudEwChpH7NDmHpKELiUZChFiEzLFEzKK0Cw8qX9zrSmMxWrFZCSaVXVUuHpqYaXVK0ttIRQUtOORsrcLZ5CciEuwTug84N/s0lQ44Yj4rsD2E6Avw4bW1cLRRiYgcTapZY2AzYnbegVUtmM5c8t69u7Hls/rAjX9qVdkwsbzSe+7b97b4OJLd0Z/pteaZ7S3uMNiIE4mWFqqX0aOT0uGQBLBpFK0dE7TACBkbnCVqTiWFYSyaSK2DNmWFh1IHGZokk/KhuiPpcoYm1nNtpuSh9qpooodPzDOX2y2uLQ2djK0dnMU0FuQfHOSRYOWo48o5MENJ0rGqvy2f/qeREXncoykpS8M8iNOP2eyBGd2qlcDU1NrzXeJEiABRwgkQDokw4KgNVeQmKe+KXksLoCAVHGUnzgvXsFgaTo00kjm9kJzDLDlUUFhPyhyqaVSelmmp6UtNYrmmw+4bwIcKU6SSrYkhhow3WQjGPPJ9ibPJSt+B9ZmGIs9R29Z4L/sh+XM9kVq/2/1Kfnm34F7hj7bLZ76mXjGu9GBHNuwd1XrQRGJCJAAAAF83GNeh1wfN32sDQqd5p5ZLY4Fka3qsX5QWoCXFtBMMoJlzUVm7R7sX/+7Jk6wAFEVnPWww1cHkq+jxhY25RPWFFjLDNihkmJ/mEmjls1aQ+YOnGsqEt4gQPm7Y9Rma6EV0wiYiwvDENWkgQ9itVS8VsG4U2IeUz3Y4hhbcfmlnwzRMTa4+R/WJ43tPxm9im2Mlbg+rmkA+APG5nq4H5zGX/dU2r0gAAABFlcnBOayYqacyIol3wQ1GA0kEgHlHTKYJb8A2A4yEZFAmRpHR1qk1lGeI0BukYaMm6GydnLJcWREw27mCKXYExGfLOhGhQJUHEgFoaEbaJ4eJxO3Vrk3SMNNL1SdB8iQvmhnOUwxuUQGsUtRiIeI86pIhN6oTxuZIJ8mfqCZ1+7NSGIqzEiwkS6NoSH5TQNlwbGiXjQOtMzOF07B8f182IZSks9XX6bHWrE7SjihIIggKJWMxElCIZClUTLgbUhQqdYRkj3WHDpV9sqwuXI5M4TMMXInc/ZD7aLR2b+1zsrUx3GHF6XKZdac/KWEXUtWweXNhdoSkalnytFgrJQe1t41ym7e0M0uL7Qjtr6PePhWNc7LbNxnuoZSCezUFD/ABzb3o6tEVJKnNYACaAuyL04gj3P7GNqZ7Yv/P+6FyKqJIgAKyVGIBlzgFpNajHXi105JCkaqmw9v2zASIGxrWl0/hhAwTsPFh9EuWRn/wmOYtPEG1zFb9sa6j8Jz2Fxs5ZiKqrEt8pOYgZcCp7EWScJH2Ja0+oqNB90amNvKZAJmLV5xHkMTGuNHPyhqpbOxS71mt+pEiVadHuwpD5XD0EEsxS57DTt8WMVTHR3NW33MhgVPMqB99+xaV9XnqTWC0z3TMtuUxUERwroZjMAAgvQQH/+7Jk/IAFeWdQYw9KkJUMyk9kya4VMYtBbDGNwfQu6TmDDjijElF+n2mUJgcVGq08SFL6uy5lBql5nWHVCNnMnRxhKjHlmxAzdPkgm95pIj8tLH34/PNC/WtHYpqqQVVYlpT5l5bNuP7MHwRXY7kETYkDQg5TbjtQszcsgqlhdcMxHFT0MfuXmRWjAJwBfKH7Ca410VJhJZssSAABLGUTCAh+0yJYWFmcDMQ4KswJoKpndJQ0ynleF6O1Clynz6PGzcmDDz0ohyqghaekcLg9NhlpTG2ncqDIDZaJCgQqipGwPrKR4xDI2NLwmhc7nAcRKdMldSr1qTAEnSJyXSKH78xkapxxJpMwNt86rWrzMH7InVUDS2pJmifIomMkm96vrUlgxHEIrSirm1EsK2tWRsO45oNh1MqPmo5jRWtWEBsEAQo8eEMhbQ0TQkuyVGFUq4gSNmr5SOGFmwBDrsqjlzjz7ocMz1FuHFjxBJkRrqD6h3Ti5fdddVEMJDLFLHR3K4fOh+7kiry/COjDadyq3jqfnRM3P9jjkUnS1GPAftqSUdNeHaH8TS3cpihO0/UXEuxEkUsgIQlw1kQ4YQFaHUJSjQSaLN3eVOlhNqBZOIhT0vi+elZTYLcY0c5DPPqd4kdOcrCyw/YkaFIOFU6WpJFtMLgfAJvpkO1k6RlTULRaXbMmaCnw5Eo07CSau6VmZ0qmp665AdcsO6kb6KOv7x1koa49cejJk8ZlZ+i9df+gr+miZVkaJu6Q6etKpKt5lq/tOl78v7tHj5Cjovabq0ZPxOnR5PfSstPQz0J6Mi/TsQSVVKSIAAQELKWGZCVoCpn/+7Jk7oEFKFtQYw9K0HgLqk5hA34V+YE6jD2NQdKsKLmHjSGtMXLJIHrDoMWdimTgjYvSVs8OCvLddJ0KmhVMwgLyK5AJsCwRDIBvUCZEMRUoFZbFHWYycegDgMsaZhrmr3UjO3v/VRuhSNm/mRZ+1Uz6R8dO9435bdzLW9CiaQUJ3jsxzr+/lYATAABHhc9jAYmZR6EtipVAEAQsIzYYCSInJ3UMM9g6ZjzARYFiZ+QYpm12iYGU8l0/NpnTrTk+DnhO2RhSr+5Yh7IyEonANUzWZ21VJEtu33ipxtetZ2q9TLqZEk9o8ItWu4B9ICLWErEjuOdWJikPJhaFGIw2snOCkgY3xzZ3lrkIhDijz0UFYEMx7zo9P7tu3mxlVXYSbz0/FZl1p/9KUTlL0s00JLzKb1vP1detOZNUTKUnbOpkaRgMACcYlYFGkhRir2Qo5xKNlmrqFtO/zOoXKMq3akSda1MPsChG2iPSX66O/A25dhciRsiBhu+5hREQrpUoRpMJLpJmZxrkEmKSv2o20ssvldrHn8pqVKPY8ZZ6XQpDysVTu9hTkWOG+TQwpoemGYx+IuLr72ZuaK90mtovpVmXGLEzkO7HksBlACXlBQZKADoRywSyeUqEGKAEErcEYYUoca2oh6HMtICUUMjjGHawnkpYZorud6SN4ybyqWDJ+JwucBtLuTV2u0OK61i0T1rqGA4RqyeHRw48lJBRklBCiQmggGiIvFQRFtgeVa8iLBt6e+7R0CUVwVLNqckEHrJoCVZUOUXQkkrIt3GXaHW5DKxraP+7J4d80zkfMPLvv7ts397We7Ns9rJxt6qZmb3/+7Jk9QIlwF5NIy9kcIkLKdthKJwWJXs1DL2LweOs57GDDqgmc1xwI1bRZ9CF0LCAMn4hW8DGhHy5xqqVYlN3BZyV6sMFwqtONmzpas/njUwjWcR2m0sKfyUbkzi1GUTRTO3Uh0z5DznxCiWr+LqGLaq2Ih8KO2zW9UlHFUgR7FAx0w6kw20FyRx1Vb/TPhykbHr9//nMrn/+aMCMGJMTAJLxX+ugIEAgG2pCMEIQxoUo8TW8moIwrbFBBqLFU60JFNkyhZ6RXCZVA3ELfCpKc3i2kvCNNFE+eRyJpKFyLihsU7oAvcKNWEHPJ6RDiXvR+EqOJwKssBb2eKuTpTMA5SsOVubYDDF0vPSXzJgBSqj4PwheVFSJX6zbFtpMlKkAijUmZ2pWNvOScVcqWlv0TD3ssLjzrIrdPIGSkKTfoZm+sk+WTNFSn6MS5NK3ltdt5ebvNYlZsyNefF5vIfTAiZgZkYAEAAqAcIKgKNNfC5bc2/R5YpA17FmMQgcyICAieMRNEYd2i39v+1u+H+yi2Ptr1oSlZqHUJ+uMaEKQ8FhCI3bVisXrhQGwjqmU0Y9WIj3vqTfSXPWMD6akRe2CX38/ySlbM5Fh7m/7ZZW3Sm7ZHdoNc+yAEQHaWaCS54XAJoHIBStCs0BBt20HQT5OQvWVP+76fEPN8XETrnq6eZcgLA5YyV+TMSt4otKdVTo4Sn60Q1Oo9nMVFS4Q8RY84rAe5zx0SW03D7yokOVUhjrKub4A3hcjwojx2Dk0kAHCxU2fhOZNDwhHD8BTIzViqB4WpD8ym0IcDdTdDJMNLxS/JguPMHorDB0uj7++djFb/vX/+7Jk5wMF0VhMI09j8Hfryf9lg2wX1V8vDT2VAX+rqPTxifntZKu2FbNrVpktMXh3Eef0cVp2K2VRiMEHCYCLMjyMOu//fUlPqgAkki3QO8RMFiANEZEUopKHF4DvQkTdzaEUtjyxEPcvP8iMjYE70AaghRKREYJ3SEIM1nsJLjDU3DbtQrAlonOr/sxGbTT1rIQqLkTb2+qa7dz87dN+Qbuof3d2hYAgiAAAABm1gGTjqItiArxbWDi4QuZ1pbhpiNhdKdcFUx+uezLF6lHqpCXC1IYfxO0/p8stUkBjQluhxW4/XJj2wKpjaC0VW1Fy7Pm87FplfuqPbt1WGkFDUOWZ2BiOedFqZANEi1Ai3XEyv29Y3dZYrhJiudb3dmxFkVD/fW5NXlni/NJd4nj/NFTryRrbvfG6+trV3vVK5vrOp/Dhbr9am1aNV9h/N90zfVZ843q181gunHHFABIAAIjBW+F5zSOHiQMKj+kebAzIofVjQwiF14Iyncb7TAMZAvqmCH0OJTMRb2VhL+YCMcF272S6ZibCYtLIb668Q3DURURYSLBHa0AplZXSVT8VehssBiVppHiwQD+N+Kr028VDahzkqYiIZLxst7jmytVDPhSw7b1Gh6nYnU+oyqjR5GFbdYguCt9GePTDadOt0jWxusa3h6kpjM/tmtviL/mF9Y+ae1KeSHjHkaQFjpaE3OZoACAIBQgAAAAHaUbgBhUUMRIT0MY6hkMBCQcZCAIKoGYMnG6nocbComlDNhUMHkBZKSpcdKY3VzLBGlBKEolRORpEhQMOdAgJXcuDk4EhU7HQcaaDnzweeUiKR5eZl8P/+7JE5gAFsWLM5WXgALbreYisvAAi2ZctebyABFAzJrM3kABstpWVSlqKtaPaAdJsLHJzUqvXvVLFm7PYwaPMuVK3NWkxxYftkSThppOIyxgrjUcjbCzdYi/ZHEZGoAWTgCMA4tP5kj9wVQOjROtuallt0KKQO3KKWngR2lyPxBMobNGGcMEltiW9vzk/A/Ltujvx+GY/8X+loqBrEheHOZiduUTDeSuNOzLp2TZ01HdpMtc7uUy2QyyCdPjOWpTX3vvwzH4/P15uTzlemp/zvjY/r/lLu3/HpqYwEEiI4CgEBAACCa96zGgcxAdEYWatqmwsQjDQoAmCmhlpSDEwQEACCgsIhcLJAMCh5M1FOYdSCj1yA64VABBwiMU4aa8hcQ0YSYIWjgmWvknSighQ3B9BA2z0zEC7LozrZVUorFGGMcR8dgYJKJhEGCo13OTAj/QK5codRgkYjjQIkIBxgtsgyCu1g0SlsMxWAsbL8ymlaZFa8hY2zNWxMtSkgAVhfppE9NQPGo5KohCJVLIpVlU5GaiFLfNdf2WR9wWRRXdu7J7FeM161XN85ROxC1er17VfBoMaabdfZ7I3GL7IZHGrlBdlGNqtjKtasfx/7E9LYxKHJnLlXGxu7t4Xlb+azlleltfCLFud1////5ipAVXkBQAAAICQSMhMitAgF6wUOPekQIpHLCFvX0a66LPFbXohUNqpCqPUhRxQ3o4XE5iesLjFdJ5JCMAOCmNk8ygFE0WVS8T8nSFGpBLEcYOVKu1OlIzhk6lRCTyk2yrpXK2ZrxGU8kOXvWZaTyiP1ZjtTFBvBhSy7q+wnnqpZozbCY3/+7JEQYAGMmJSVmngAsIsil3NPAAScXdDnbSAAlUvKTu0wAHra6q9ap4rG/prP8949osGaHDp8ZrNmeuaS1xiXUPcTNqaiRJd3YZLSOEkW9rU1j5Z2qZsa81iUj0r7qja63iM44g/EAlZInSWAACACSiEhGTB1gcIPOhTGPA8TFUVZjNN1AwwWHIOrIeVFBCU0onS7PrSFG+cZ12bZkWo2FvlIstoKyOytcJqzGVyBLuXImyqVsA/bzJ1lYWKrM+cmBmf94p4e5WLXj6lYIqshu9PGPMuW9ks/V8sZtjUbI8WSkaA2wp771hyiRYE2LYzfw6a1mSHfUuoO42JsTVrG3mNGkreF9atEvme9pE1Zz3a9cU3Gsb9Hzet4ivr5z8M0eJdjjRIdJqgFuRlGQAAM92QckJWsNQSrLUSZ4NBTLYKdhorSWGwJKIfQQJQOF2iX2qXCpic4Il2GFpkuxQJRYMRjGBFlJV6xMljttxZYrw6BtybM4HBWKN7k0nTjBFSBXxjOeLQ2G1JXxqDF403F1CmTS0vizKphPUXnCOKuli9y6k51iv2SS55vGrvPrk4aSsXOn5U8yGLBabQAmjvDKRS0oZu0JwE6sKEKK2TG1tJRMKddYBO94VpQSyzgMHgpEIt2jXHCerbWY18Stqlvr2M19bbt86mZi+vp1tp9Gs84sw7iyOuWX1OTlC+lrwbP819ne6bxr9Y5n/tDS0sV/47Zb1uzNsmYsrN7Wn69lsrbP6uX/bTObrT+929tehhZcMPWJrxX60TLzTaDY163/SqAkGxJBwCLjUTRMUvFQcsOWpZeWudZLAuUXVSZSsYGIj/+7JkEAAFP2NPI49LMHfruk5pI34SVXlDjjDPwdcsav2DCjULLANJIoc4NqaJsnsq2MSZmjMl1zRnog0ROKCqHpCFtYkREWJzME8G2CNYzDsqGyKNIzZtGmKRxnlGnLRA9S6PRjTAKj2yQFGrTIp9QPjV7AxdAifNXNecWxvGOskv3dXyEAsfvGK6smnqLJTTQCi9I0c2F2NvTgcjE5iN/u5VuQn/X+s3ZY7WALBK6oZcyARnsytSOMWDgyXQkDAAavWfx/U02rVW9p4kyHhoYQTmhKOQsxg7r4y17XUnVx9wlscyVulHXbAUsaysE55l3VfxpWF/bKM2TXnYZNt/S/cizVjkKd52EXf5pwHl2v8Xy1OSFWb0BIOoQSalnuLZJ2usRSS1tc0opnOGGBwIz0WFQABaNLd1MSwAEooykqspVaJRB7oEP2y8QhLMVpYZmJKc+5paTIu5EvlHc/naHfwPx72qXpbTLrWwwgTCYG/dblEUuk1qDiRucGLxjT31qv8onXLqOXpldoI5DfPpVP1t82M5B1N6b5KM+Unw7Hq7M7nJZpsOp7WY5Q6PCZ/Z9v2RbdGBE5VTsu318aJoY+D6xRgxRRSWkv1J165ZGoS/UkkklbtbvROGhpxZQpOK5A4DBigz4PJFwlFfDddtrrJCZMJkn8b6B1/ZjtXhqR85EUzJId/QV1V7TJVy2R+pezSmzX1Z6O9U0MZ+25WXwIBZ0EccLgsdt/fTVTaDvTIgFUAxhoCZVCB3JekgnDMQe8CabhtDf1mCt8Kn2oOQyyVTDB3ZazdgGqo3UyfYY85ylvMZyYUeInERZoH9Wx1yMU7/+7JkIwMF+V7Lg69NcH0KqcRtiHZWcW8ujr2LwcQs53GjCllKGNFualszuq2W3N4P5ipTK5UECrGdDDRUodFtHhom7Id6LQiRrXcDUjcebLhtXdtVUu3WG9tY8s1INn44Lwd1cG3WWtdV23QVRiGwMetH6PltB51ssYo+DcvyowzMPzjkGgwZmIsOUbCpZ1zTqfH3PEsRWsSye//3ApCyFEJcRZODghroBFAcCt+waXcfpc8VaewRi1A7qPjowFu0Q1xtFJ3era2OKKDfBhQvWSicHj32Zhg9hYw1ilEh7xBYwthlsg2DilV6fkRnR1owyYs/pJmruNVqk4JGJX8c5JTS6Mu6Xj2rn7aTdUn7P61FaOSfRkm4Vu2BEGoADR2FgMcwYBIkExieSZh6D60w4GgUNdhQIgAAVwj1GUgjQnJiM5HhsnYRCeOYXhpNb9iQ58xMW0A9PVfgQ35/mY4trBhwhrghyH6HIRVGQthEnKQtuIcLJKSPtAghpWTC1HxOJpcxkLhy9guo3VLyZbsC1Ab6pqZUZZSw2k0LUdGl+rCeoHayGzFNWKu7i9mVtP2TrXWf2efpn5Vl5q/LZkx6bf/acxTtb5WWWLIzP1BN2SJhQAHO2kHh5FJVGMNUUJWMAAaBMCCbu3VYKWwta0YXdTXaV4ofxir1gceTDZrCU0RY1Gzg9mmg+PcVzuDowBqdYVrkZGVtrMY6rswfVr32XRlfVq7x73o99GO3dW6JdjWo+ayK1L7GM5VEtAN4sgSBiCAAALmFpuGBEuugYOAoHBJ/xwNmEwQ1tOYwOAkXmFQVQRNKouKfH4YggbHIjx8JXaz/+7JkGgIFmGNMY49L8F1jaexh5igXAYksrj0z0Xgrqb2DCiyry5OnNGsyMjLoYLyhmtaDWHA5lcsVUGUK8VOW8p6k1kkXTtkyiW1XV1KcznpTF/u5AsBYG20jpJK12jE8a6Lqht+HsQu81FJyaM/a17QWgzU0N1+T+mieVVNOXirkSXFenWSt3nVShztfPJykAOB09EjPMNfX/3556z11qoWRBQkrICIDOR5YuNNaaMgdSKiDLOU4lYdxIDttY502CYJYygJH0bjfDKzrujE0qLQKXKgNYsGYHYYgAgIhyiU2YFHlWLdasgsUbgQXHB4qEAq4SiLSG0I2Jt+RQtTNoGAnBIYYrCAKAIcJAKGUrJSAAmRCpf0pHQKCgY11lkGqoLD3+xFYBLOR0q/QWychooYqeWUICRm2nYpeiFI1qLu3nY0M4eY6hgZaEpASSuUO4K0SidIKxDCwTNi2549TiZtMJkvXJrDqbmnsa5z11K04bIyp3WV76HsuZft4l65i0cs1jwJFUA7LxPPxIlnk0lt8nXkm6vrMS8KvE7WpLtXyPVtpiUaIx6M3OO7DXz1Juv//SoO8bYDNB07SaJSNJTOVFhcCXIjazNyWb1opRO9FWuTstuxl/qB4Is+coISjnfs/xn/9W1uC3WRCfqX7nVLtc4vo9XBau7UplaqtQj6Semz7vo3/f/6evpk7PorUXGJtHP01EBoAAACOEgkBCdvhGDyYUIoUoyDS9yF0cWoPAZudG7Ld2VFazm+njiR9idok6X6OEfeKhrLCqGaU7TpZGBEE/WmihzHLfmmTRk0znMnqQEwj38BNpqM4ML5ixZL/+7JkLgAFdFvMTXHgAF/l2dysIAAa/Y07ubeACo2wZ7cwwAERHLTYfirmkWIkaSiFRLQ3GbVm7G90ZYeKaj+t628unV9z01Afrbj9T7+4989gYP9W183x/TVPJ7euP5NYvuV5FxjFcYgME9tKmPrcqhgEc+p2kJUfOFYA0aMgWahCuYQUbGnRSuLYexBKzdIVxZzjxhWCQuJEQaWHM2AiIKwohD2LMqUoy7Lqs4WaquOdvlYn/9PiL8zvqZ3oxIYgU8tCmnkSUcYLUiIoQWuLP1f9Sa6toAcnrbqbSaQaUTSSZbRmpQiacQRL9A7KYODmFDI8GCACSRL1oDzECAGgRgQ+qUgDmXkjC0MIsZairJGYJrk5LaPAPsSjeaTCVisNGKfY3g5kPYjCORUlGZCGI5XpuicV0qISC0QhD0alVy90eiyj9VPNOJqJLIqFErgmF0qIsVs2jV28ql1Ghb9lrEXTFaLfM1bdgy5Nse7+lKRGM/0LTjQqNtTFN5aRa/1Vs8TUsS9LQo8+2SFrT9/ulH80CNp3Bz6f57lBi2ctMEOlsff3Flfu4cK0fPiKgA47EnCk2ozCoUyWS2ZUieRITAWi9LA0rFDyiKf0ApIVUq3RpoePXgagPAyasHy4zKzfOC8d/EkXmLL6AflXbjodiYJSU61KcPHbiA40WMDmzLcWM7Bfjt9rLxNWIwmnq2aV7IOdospT4l93Y7ZVns3p3vmV7c0WHjZLV2m3Uy1LZ/bPfPTs9SlL7eWHKb1a7e+995mZnL0vv5M9MzMx453WrZokWmNaG1NlItCEIAgIgXFJAeyTgRgiE4a49bSY7ayw7yz/+7JEEIAEj2NUbj0AApSsSt3MIABTlYFZ/PSAChgvKz+wgAAnMsaHwoMDwwPXDgKmMetTZLdZ7GjKSWgY40Smj+iHQjPnseIh74894s+yFukcY4yeqyLHOHhs+KU6wkTW00aWeObsPxYUlO5ukTfE0C6vvDjMcZkux4+hAG0iVu///qq3AeUfMd/i4uD48ig8HnwuN0n37X9+7XytsUlgEioiWXCWO2664jGHPfSjQdl7ux1t7EagMFyAmLuJqHHiQPzA+BEQhFuRFFDhSRDEgKQFhjofRXJrEUhRWQZ+kRCl6iEOyRcoiCF5m0IMohC5GHrMii/R7p/nrN31E2ezDpdI1nZDXlLRq4SXtC7a3pBcbGNOezHp+ujyDEEVqe47rESw6XLKjFMFeIepdUW2JoJQCBODBGaEHHQTwqEEdZPXRvmyjnSNVLb0F0zia0WYa5PEUmpQ9IVWUnpJbk4bj9+eUN2tggBwDUmraTniA6MpDIKCR/Ost/4khkwS/34zlkb3fO68IeWTonYMmmTkOuozRttdHC8URF0FzR0vKCuXFA1HqignPqRkmzFKDCYiCpEWWUEM+RxaTYRiRimokZdHE1K9K9u9xLMjcJAIIIM16LkxUmmhNSZExVkznP++7v5P3DkOBc0LB6MQg212FkiyoqEu21DhmIhaK6Sam8jvVBziHURI26cVLMKPDxurOT2LWR3xS6upfND0mq+tlFYBqzFNcMIpJ1CGWOV4Yo5bjVpaFl1WIONH1fNVpVEiY6JYV+rt7JQNGMhVmZ+LzZdtKUCChbtQNOwJEEACLRqgMNRbXax5PRh4yA8Gb7kQJOL/+7JkEwAEUFpWeylD0HSLus9hBX4RqXlV7DEPycUuqv2BlmAzABB8WWIlqjZKYiqKCJn0iySViHVHHt8XovrV4sfxZZ+HlvU/PpCVNfQ2ejB9ykeMDoNZMrcjDH8WKqFHVAuVff8E3c7/VXy4vXdtBVNbq1Q6d6y8Iw6IBhJEkClxw6cH0NssmKqrvlVZKEAAmQorthgE3Ahoqih5K55m/QSvPC5Uv8iEukYQKQSupEkRPU8pHpL46rPsV3hxnxz7DrxoPBCi111GsiBejrU+zm9lNejrRtRP0KZC0pIZDHapdXISJ+iPRNkfUlCkecQEjuCjnM9Zh54So6qVbcm3mXOuNgEIQClCwScQkYLoR+SRZUpktRl7GrNFKpI84fB+ajyV1LBNfi3jnuw6ZtvxTk0WemPWr62urNspb4WZnUaXhNDx+dPYM24+5dhteVXyUP9a/URbi2vRm8kVp4WGoQnzTryWHxdYvEjVyTB68JfLLdQnEC0ZI67nsvQJZalK4idJFhs2+NfqZr4ucl0jjIICFEKZSxEEHWRiCsCwlWOrDzmSaCZMyaddt9pM7mWNrKXEZlHqdM/545oLiiypXePOCydIEgGbfqjymfth193fdFI5dj6LlEzbtlTu7TGy33HN2q70OKtouQWo6ZQMY0PD3VGeNIHhbYk0W4mXZlkYBAAAI16Q8TKVRKGAZABaBigo6XKVLiDVE+LcMK7AkjUpyjcek3Ellog3doST6myfRy2sHHgWQ7wUjuajnpdpuwUiL+eRfDxlmJkmrGSKB/tXcWJj9Gbho8YIw3XmUFR1dJ80XWIJx0WfFEiiI5dzWyX/+7JkPAAEWVzS+wxDwnOnqo9lAoxRwW9DzBlxwcAs6bz0ijG9NXZEXJvk4heMiexCF74zckPyy77d49Qs9bJAJdMti3BzC/LX0hTCMOMhrtRrABAYYp6vS3ICf11JAACcgXFxdlaIVFtxyGiANPBDDofiGbRjHesdaErQxAJjtxsWspb5mr0Xaj5CSufJ9ZDK7FUX7+b9Idb3qZFPi8jdQWwtCHRpOBSFj6QQ0d3lEL5ABRYdYRBDLpjMxfxD9BeGHiYaFzspd9wHQWGh7Fqk6QWBiSBG1Ch2HB7NYIBUD5GpNpTTPTGdzU8kiuutzKCofPqsbEZ/JzLin3uslbGGfa52bZo6Zf8Il29JddwbGxvScpfDXtWs9tuZ1WNlE9Wx8bbbcrMOWdRdW8mw0pWdZ1z71CQGB7+hURoqbpn0yhBLBJiJth3BGkAzk6EyNEqC3DReUOE7zCTxb5U61TRlGSE0y11qq38fUrm9JqzE4oC55D/fv3OOUsjD1/E44ks148uqt6IraPvT/o9/IoCyPY+UizorFBsill68uVcyL2zsKoGAWxZwaQhE02h0JylLXL6oBGRjQygA4StZhzyraS8c+mjU+9Tj2cYCJxdRM8PaTHUUeiJnxKClROy6+TmugmMgkhatq3JbBXOpBDRk1lF298kasFgklqmqC2uYEjsn9xlJa04wonbS3Ch2ssXcUjhqiqMxpFpS6mnlezsrMSKoabIp6Tphl3b1D0W4oZy4wfBQ089NS2d91V9b2/CjpCIgQph5d1WyNtJRgjumAnKhHWMkWt89XZ6Myiw6UKggqFJvaQXyIjblyN6Dk8cs27D/+7JkZQEE1GNOWylcYGSLal88YqpSWXk5bOEhiZAd6DTzDjA92tXuf/CpFa31faHqmeaGeW8M6RdbK7fnymc0Scyqkq0tf1Vty5actL+atWdmakMeGNZ/JgFU5GgQBgunXL0BGh5yagJWpuiDbSrWm+KXUMNdWKGsiAQKPkWBZDS4+RYmK0z/LPqKE+vOJc54SMmKpANu6kqpWG2IzBN6zN6YgWs6CU954bh8WL4wxu+C3idxn/Vn+SKX9LdJgrPXV5yEhpvnBf7a1M66qsrUPXllbvLyWj8JF3eCa3J6l2U0GUju/NxunTwfqFdq+qajSBAJnuAkQ7QJoyC1CjMdF6qzkFPJ0oBuJ/MZJEFc2s/KvWPb3K8Y2ym8lIyTEZmNG/1ka6diGb+9eWEdl/4n8nf50u086y+rqQR0gwrYQWHU3GnndzEqMqBGgcMl36kJUbxgxIAQK2xhuAKIRNThlwXaojPRpB0QHWHa42CAYzKrDPaQd+CqCmAyJNC0gseyQ120LpI9BZH8IRQoWC5FkxzpKbHGLUHq2OBdLCUKpOIEaMh1pY6+KOyXFbyBretRiFNDTwFzoereblpCQCf0Sd4tN8tVPacS9iV1+gWDphhhMBweOoaAAR4s8zGrE0pFAPVRjZYdGUWZAIElDnUBb8qLYg7BAlSp3G/VUaYzJ7HV5sVGyoCyV9OuCx9SC1nI9hNkRwmyqfITuHmkWguPMrgqs6j30dkFEzrvVvtyobRenVKpahtDxWo/d0yMattS28i5G9aCyQWQ1ygp1gqqxolAEgAwAOhxxS7YRNlavyQ6XbSA4FJJ3Xlsra2pWBiLROv/+7JkkYAEml5O4wZEUmqq+f5hhWQSiXtDrDEPibMsKf2GFfBEVxHA2PnYIAkIi+dvr5WNn69ehKac2fvzATIllW197nZbvCrX92aPtxc+8osiUodWLxyYHgedu93Vmcv33M+N01rokbfNfIstcJXMzeMv0s/iL5+6LKGdml8Z7ljxWpEIJQbw5AnbGj4JcdDP6fibLMTGOz2ONEKPIwE1xRrChIYTUTnZo8ZZ8OOsF2BF0tOREXpB0LBGLwNCQoEgSB0TmcZweFMAAsOakBAdF6vspvzc7sZlv6OdZhYvvfUCDKcUIkjJdM9KEP+Qh+n//6/////T9LaNfrj5cnRQOOMcpRQAAC5sCWwbBJ3LoV2j+rVDbTWVMJfuemPISEgb1nckL09iIa9q2PnvqwyuTYdoxbKc8BrmjMu1aXiDDIAY5NWSfxN+A+xmExX1cL0Sx4mBzjwqRnWN3zFdYInw+dT1F+9LBEdFjfrBEIT5xDsnwi9Jhzp+T/Rb2l+EEHHHcKOP0jJqSK6EesiKIQFRNGszCj0ba+3KH0uZZAKVL+W5xu4AJfKAC42ZZq4TsVsVudZLycre4pMV8PBtsBChRBIZUYTRCpmI7DGWVOUCUV3fOcF7uAkYseKGQYIdU9nqvnSYu7aEM4RvBwqk4GZRwRL1u+0n/yB9SgQxU0GBjrbwVGl6RiHYBHMPFEhqqiKqINVnA7iwgfDJRYIyURbZHyKQEFJvS69yXGkyJJih/s9PppxRrLpdLOW3W9vxLYNYd7qrtWsoJj+Tqb/tDac/YbfKU1UoV3Meav1EDReUHVsOOW3rX2fO9sYzQO3b3vpls1X/+7BkuYAEJ1pR4w8bcHyl+n9l43wRtY1NzT1jgeUvKXGWINgzyVMRYeqkD0E0dZrbRI+2pHXQwQa9S7+FKi8Slp2+RoQACMg86TF+K+cTFkM6B04PQpEUyKTynRGCMPDWc0c2o90ZuVq+L/ReuPhfnaLdvIEIutZr7jcYWf5XH+PiK4n5hVm33m+IarexEtltaxnY2muK6qBczl29B0dECv4nMp2rZlmYFA/VBJExJfc0NgIB6aF83TUGZIuJhmbhQACAbJMuhApqEBpxZPSga/MZVapuv5v25RlVB1X1jMiiGtuIM/hYrnk5eVWPfFFTMVipLkVGb9VecrB36yKQSq6gabOgiLYdCer/t8gdUzPuKl6WTxJL+Q1TdcnCF8VGMW6m0vXHcwZXVNzcaPFTI6aRfiFOg8ULtKF6grXgofiyUh5WkEisq7h1jqiIDEXn9JiOsWTrIaA5UMMVUAWHazMN1aVm/2TRAmJ1hKmUWdt70Ur6b1qPzzbbshte7c9xZ6ZWGmiyb6RbqjeBDwbUBEHBrAk6INC75G4N93k/o6lVqK3aq3unVerVbpdUgTILEGLlgh1UZ3JrBSZoaHMVCAAADfaAMDkvxEIJuUTjJLiQWiRC0Zk63TYnA7XmS4O2zGqCS9kCl3I+czEka8nJKuGHBqKkdhN5uX3r5/zN0KRSqDAF/pNw2iyFN1CPPzixpOdMfod2WSsUZa7vyxaPp1eTecah1km0UW1VXrlaOssrmM1z64WjVmX4b8wxV96sE1Sk6PlxYTflqwYyEL3VLPVmctSjtp97TxaoLaXyclTdiAABOOFc53Mk2ocgyVaCOf/7smTcAARcX1N7KUTAdIu6j2FifhQ5e0HtpZHCHK7o/ZeZWSXTO3QCwhKFGMcjA+AhxsFOpqqlknetZst8SrEQyJ4lFGgCgaPNTIKbrr9bNPxrfQDru9ft68T//jc9K8lv//GJNtNWVX2YbH5ry8Ov5NZKMY9/e7o46Pbvc9izteXyXszXU2+iFVyh21n/tDVzvrcsBTU5VDMYgAA1FB0wZOEABIJTqkBIFSCW4m0gjlKPkvuT7ARGqTBpFypk/PYr0UM9Yle1NT/6RxHsSEZHrrqhg5Wwu33o1zfvqf0Lh2Q5xxyZYeepVRyzqDYqlCTUSWel2iaLiXv1VD+dIG36i3rgmCsFkTEvORx3ITpLBFWRVDdymgWjkmYa5YVZmEk2YMLNTYE+xKETWNvFH6bC+aa0cqSbqBlpIaERNE2AAD2GJn2QlZwRsljKkBjF4syp3pdnTOy0h9UhmtPH32NZLL/WaaYJyUdravltXVN0EdcW1v07ZC7YHT11dGuWAZIzr7DMutR2MamR2O1vu5kmb6jtu5+1fs25A47w2tfbZeYlozXnNtsnOUnOv60rl95uXc3KeW7oqhjcKLjccmb/oAqmtgQNNwYWKTeIxt4mCy1Q1OURpusLBAigQ8SJMvcgDrgoA8M4LLAmQ/eQn5jhXIv9pXK8cFTt07/WXHx9snV7YU1FrxWNPDl0y7FsSzUw7mNBPV3tCPGT0MBj2avncJimLXGlXWXdLJX/4nHvWhckUy+vTzdcZKPULnZSH1vhMT5Vh8pnv5qyaC76TrUieMbXZbJsySfhiWnqi03WWWCFlFlAKJwqKpl0CAnSUEFjSv/7smTvAQUWXs7zjEvwicsaD2WGflSFczVuYYGB+a2neZShOSVydN+0reQJJ1FwSwLCguWJQNBsUhoeUISIQP2hdtPLajNUgjlqmXxi6MHx5M6cx/cjGC7RAz2lL2cYjRV824VuhlId9QPjuUeuaiFqaURSSLS1ejsplWGmZkcuslfx8FeqRJZrX84xGONkYNVR9WXWEXTMIBgXePAABAELSsDBxKCQcwIfS1TzdpMx9mXxWJTcxAFJVVTOK9zrPlTYbXsa8CzZNeAeEbKkiSbhv0Khaepxf8KWH8XOl/LtCJZE2071D7nXS4g1ilWr1d6sLPlshK6BForY9s1MzV9grPf2O58RYtfz61gpHA+kknT/cpSVwrtUz1iyblUweYM8vMLL0tVsqQsLjPJElI9i+LYBIdm6NnpZdiU7wFw6G98vG5AAAwii25MwCQjZcRyZOIIzCANwIkhut6EvCYkWqHTCiypVTLRUnU/nq6b5YMXbkSYH6Z2Mul7RVvGz8D3pYzaHCI2zNMrDQNqrTSfQK+UmsyTNMnxC/DSVDOUIcnwdCWsDYYs0bcVCjjPrma5iYjiNp1pNsbEJFsUsjYLv7jGMAgc1pAJ6IkEEiAXIUbXPuoODIFmwKIpbNTwiMCu5hXWB7jSuiilHE0gVFGksimaGu0Pe4yp41GtseQ/3M4o7lm+28/4q1lkzChH6l4upYuq4RSHv1hfFsVs1ENrFkukk1pgSTnrsBwucq5Ymr5gLLnakJHU1DarsCtVxdSnKAQRbqyuflyk1yotdESHNivCBczUjjJaCiSBc1cSsU0Yp/Zo7lR3Om9eSUCR3+j6AYf/7smTvARVXXEwjb2RwgisprGXoTBXxey8NvTPB1SrmuZShqEWGIRFSAvOZoI+QqMGFrOiAoDG2pIapkqVKqOtjgGTuhsUNUcR7ra6J/URyyKB/MyK3X3wEjcqTdkilqoZF4JuOZ7iGqhkfEJ/A/cqfko35W+qv5LqTB+sDIWuqoTEnZfHpC+e0PF/HK/fXPUJ8EDDcYrW+AgQoIyAQAAA6khMSAy5c8t8tA2cvsCgRURgwGBQJZLRGnwVp2UOcC/nqlYkBdplCqNyZTd97u+gtslbJF435YVJe/Y1Zu2oDy8q7Y6Yy3w4CiQuHXNvHvcvz9tdDhYMQJlU8xRqTtG5dz/EOtMtj6FTzubNrHp47x7qRWKvOY0fOpJ4Udvb1qX6xEthhl/hRL6xqJqDu/gRYm4jcqWqJqdu3WAj4113Gk9vTPzGs6oG+r/0g6w+XKo8brAKgWA8bGSuJaJnTmxJtmmlYVlruhmSbiU0vuO0yIHkNWkCH5zlDWatqDIul99sYxQ9dn1Gvefct0bLQbr3w2LzxsnxP/X93//t/tnz3/+9nCC9RN1XcrzVfzXNvZEc3Pffs8/d8VHyyC5Fa4XOpHrd0gAQIKIGIGoAQCAAAAIG5xwEA04wbgYDD4iJMwpEyYRDD5LRoAQZIh8ZdIZiIHGJRQEDgLAowqE19DRqdrujSZ2ugUwICYQikYlouQ3Y2iDGKOByTO6x1s0XeYoAIhRaA8IAcBLNOotSRMrb60TDQMt8sgYwgYAbSgYIzV/G5qu+C3FkjhjwdNEkvAwCEMmDAIIYmmG9TmS/sqg+GJE9qqr6v2lcLCN3hCxIHhp3IhP/7smTtgAWbXsx1beAAeMs6P6wsASW5jSnZzIADfjFmvzWgAOQ7QR2lUXddd8PyOKSqlZ0olJ1NLELgiC4hSrDxeXukm+x/srilJPybCMMFZGv6AW6w620t1FnlUlG3mjkFvXWpItHW7uk1l2Yi+DNX9jEQ525lk67AqnIJb1l0apbExqrv5Yz6CZRBMVch/38Bcydbkot/nrUiggb/LnBpJV4AEs0U8CT07Ksb0TTJRBbJpRJCFNeACoQaMkodVoPxGRGmDEBVCCnAGBuWaJgKGHyQwTWLa1dSuUlQCr1+jC0AduUZRvUuIgESd1zE8KkbcZqTD1s0jzOy2aAom/bYoo2GxffZ8not21muGIxfJUwN+/Ln0kYeu1LH3lsfmaVocQ9mFivLnNtT0rqT0krxPF66Snkms8/v7ieNLj25ruUZ/PmFnXJ2Xa5Yr591RVuczwr3f5+fNc5eps9161Jhr7l2YjsolVu7Yv2M/3/zNSzajVHOY2u5/l/1sqmsr9zNdQBCECgECgCAQCAiGi3DMi9MulIyOzCIkH2WSMBozMrDESIGA2YKBqO4CDJgMCkSGBwJQRDwBL4HeQQOBBSqrDVbjb7Yka5IcWqddSb8HDoJjYmYeCiAMaFwzdBNR09lmwt4QBsgLyhGZmAmGSg5BAhFB5ZpiKMl7VAgobbtBgJhBoJlyiwq11nluk42yF3mN1LcBrld+A2iovuEzUINTyLeNehhnj10bssgrspdWIx/G6kQwNiDXX/XozVnbWG7QTVmpbFpdlG4ai0NS37cP0GT8NFZBEmVu5SQW/kQhuxdk8KmY/MvxEoVWgSgjUHyiv/7smR4AAk3Zk7ucyAAdQyqN8eoAFJleUedtIABxi+o55iAABsalFHx+IIsy6IyGXwxH61qvY72N7wiVyIQzUopR9NbyvPBOUsed5n83CIrJn/rUtSl//yv/9gEIAAAIDCZdmwtLUXuhTT21C3Fj6t857oimnbrdOrt9Z9jdL39Nfr6EL69P3x8TEBhc5/rWYjKcqkUkNFc0weDQai3bT9XnuyvZB8g0GYnKIw/E0KjITOhxfdNMlGR57iLH502yu4TQpiYlHoFQaFwrGkBO7QAksrQQACjC780csAIQpyhjLQMEo2oTnRgpuSE5gzlTLSmfrEmBsW5srTC6q1wW6KbtRpNLNIiUlIY3FUzNaUqvKel4tK7KMo7D/0de2opHddCvXT6r//sKymJ/aUz+1v0L9hyBjlF/7ph+qE+/SCO9fP0m/kF16K75LphtPoDArYyiPOFAwf/Dc7pg3Pl3vKMV4wGNoAAEYCCUfToS0xaq77y3cpuZT08T9dr/V/+1d/P/3789zN34wXDy7SF+qjGiGfGRP/CFSnC05JaWNtJeF4cVu4gbb2htZEUMHN1Pc0IZ7S5c9RXQuI9cgoMRCK1DobSQHBtyUKkapNS0GUeGJxWcpUCZ2d4dUMhJALPVKBy8WSNCMADa+kIpsNBXLb1UCezYZgCZUA2QSUSirAbnTx/5ievW+Xk7x8clt19zQbNtcq936qqXM1iTW6HFMIt37mxKmXAhAm1ZAsry4jWTPHR5+8DebG/kF8213Y2uPvMQf3PtHw6G5VnU6tUvONFSItEvhRhlioL5cQ2O9R9ZI46uv8bFKkAt7m9sy0vqYAdrP/7smRPAASbYtL7TENgbwsqz2DDfxIlaUPN4SGBvyyouPMiGHVUFUdYYCmk6rCqZ/00H7oW/cVuhpo0SEe1U/+fvv7Z431Zn2UJnej8LqJ5hBTCzSfdu3aq2hAkVYXSYWmgtafSWzI/0nl/wMlvOSctbl/v3f6s7D8yLmfpntB5iycIniEld3UBJusOyIc4AAfXTCQWZhheQJC67AWepi12gqZIJ1VJ6kfFp5CXaXAgTo4FGEioqhaw4XQ5MxApB6dpOQdpYpCM7vPItd09DQ++Pus/UZ+4X3+SrNzQtb1ox6wVNahrN6qRr+ZJv7qTFIjvppy212H9piHhrWaZ7OwXn1YOxT3lqiuWvQRfsczxHsxnUMc8u9NA8ASXVZdC/EAA/U3uAE8+DFR6MY4/jZhwTmG66OtGsQS102Nrep+WnbsdFjJLPRE3aPn+UNqcXBUZdY75loLG/3EwPHxc6/5Rw+aKaeJ/DqbWG5R3vbaGlK2j5VtSG4+/INvbWkgjiyr0ImsYSMdJxdUFeUuYRCqlAD4uEMBx4WeYu4YiIsMC4Ar61AKZpAAsTSvaU6cHg+bA5AOmEiQ23loJZKbQS9ivEcBkamlNKuce9acneCdTpAaY4KoVfd1nRGp3yt9ApmPFj9vJzWyPu5rWj/am5zN+n79bn9m65R2s+32kc3L/0rTO9H47ZVmjZp+quWRbHMdzvCvxgFri6ZFVlqEAFo1WvZBAFvKWDu2XpWJyNzbqtKP17tZc3nLaIrR396vzEH443xL2UvsTo50+abMtOsmlCSfGNHlU5ibex+vYa1TjWF8PY/+/rMhv4uXfpUy1jL4Ilv/7smR0gARaWdBzaTPybEdaL2FjflJVezuNsQ2Bqy1qvYYVLEfK6Z+9eK416XwxuWbQoL22ytwrAR6vARQYcCpfA4nL/Jzo7KDKwLUWch0kcbEAyAqUgNi8OJ4FzxlXVgxWwONQkxG6hPutPrHMWGsE8NnoB5bQMGivy1MGG+Dx8ZAjo54htI0UD0dUBkQqqjJU8atJzbU3jd74ehoKKH/Qzhybnb3oq92nIv4Z/6qXJu+opYD6bEx98CQGyNEHPiLCslLUA+3m7VzMl0ja123TwEPjLzOayFYV0gVOAXPhE5c5GJa9WWIjiKI8+/0nQhGSzK5+5iOYz6IYqWdChjarVCmqJGobUrq9lzpy5av0a9XcFnMjvK6CTkYhjTCLmsZf1LuXIvruYTYogR1HxRQBFyNggCbtahYRRELWGDADCiYDlYsJLkHuTdGhIz3Q8kRdlaPNeVEdibWxA7ruSVXyvYVn7UPx27PhjgwtpdKNDyg0PrIM8BdGswTNQkOK1B7UYWI5MDbCO+ISH0oVdc0F5s6P4tdPVknniVU75PzCE4hw7LMtJHK2Vn+ObCY1RrqNT/jXjKW2ljWpNVH7XppqfxCtGpSl4Pcp09Hw4CVmZeQ75uNAmrI1J34Qkk1xqKZ4kkgm11IxxZW77trKZYIE5Hgi0I4xPzkIT6PwWRWVDGHHNVimMkhW0YzIVmMEnH1M9Iu+3R21XW+j3/6G/HkY8kZMGk52WZPKtjkcGhCCwmBAJJDvoBKKjQABGpfwoOoWhAYYSArIRbXmoVaRIUvVuWEU6jEiL7Qt7muuwe4OXqn1iYpHyFYlGJgpKwBzouEIs//7smShggTtXkzbb0pwaSe6X2EldxOlZzGNsRHJeaHm7YMJ6BR/hZExWhHRitbODqLFBXtnntYBwihrRs9mmLuqtCC8yerpm8Ky7jZ5xjnsgsTj94fsQBPOl0wdMIkrM40RLqChN8adIcPyXTaG44H7HNwOaOoHuHIEXUgfLMR62aVfk7oA52yCAU11BTWpQ46VtJBfjq4L8iziS9/YDlTcQjNFRWuQIU6ds88peGOQIlDJg7Y7k/Sqq3v8Aa1nrM3eZC6kZ1Ol0U+n3wbL9HK6qsjIRww1YeEq7ntvRMV8jL67qgc+AAAAjn9M1AZayTHTnzBAFQtHBl6gKRAhhLituSwaB0QlDCVanhspgqDwH7+NQ+Ue1FYnWRujMaVRSMgyuC6Sz8v9TJRTh6DxQknU1lDRIh9FJvlQqPUMAT7UIhXeDR05kmD32RDK02Vtq1n/tsZFhncVTY/bhtxv3qH+4wqSKX/uPv56jvp56/SGee9hckd7eIdXY+bFzFHyYlspA1i5d3VATJJL1DYHdpf6HVdcODAi8qRjBIjKotRwHFHXDYqMw8wx61Tehn4+iz0UBkudFYjs7CUM1SimurrCHXDkaZ17dEU9t0f83rufRpKG+9gu+9dk5jtMy0uaHEDyDCjgFw4+/LhlKxQEBzOEQBxFDCUSgZOkCgFojkIwFQAIDWnsuGgK7csVgh90ncXJKGmZvDGZxitu7NLFyQsaTYVg+m4/GJLORiXauo4DcRkb6X4HZ5DWzGaJZKRo/emW+jMNd0o5tldMvdDUOf3Vp55e5/5KTntezX7cfNq1aqMnpxsIWf75QfUIOfqTNS2NQ//7smTHggTwXkxLb0rwZ6taL2DCdBQ9jTOOMXVBl63nNZMJ6eX+oSX3FRCqptcG4mumILupj0K23+myfpHZraRIAKJQhlaOUadpzwBcxodV4FJuTGJ+O7l9JSwaO6IgDoiVsdvnzHpFzcAiaseXqr02i0iXglMdXeEKW4VqqZHjkzA0xT5mla9qa+x/wQh4PnsWRuTM9v//0Zn7TJkUO8G7YXUI+kAAMuzdINsQwC1upBOa0RCqvOs/E1FISQc5ojnB/vDeLdBesqAhJx9CfxX7xD+SqOuVpDx3sZQHCsunapXbehrSnjvpZCagHg9kiVcRaHwJGtkQbPSsE2IIVaodP12lVzC7eV7FMXppwhBc/nmK/KLvJgMQQ3Zh1ROU5KkMqdxXVW3flcIryzqQhC1zMtgpH1BPbogQRR4fnVNhcHogDC91YKcLCshnACkUmCztbRiDgpOskTnhhnTsRpeEPwrFVSPvkqbl9kxiR9JNSTY2WcmfFJrbpiNfcMdDYldj3f3yyZyItdvZT+VVXpZ+IvWn6eT5TNz+uc3My3DmgQRadK37XPL5ES/yG4t+u5nyz/OuDDnbDMAEKAKvWIsAgklQynhFZKlAmJAUBwCEL9LpRdQNaSa6/X7aWpmxCH8LTSIbn5Tecxgs9G2J5Yzcis4oB4taWlRImR11xhkrk7D1YvmPUyzMjIhfeB8tiRFieG3KA7J9SWZEzy4PhUrKSIOIkoH+jyEG6zDszoijk8UTc7Ep2QXPvJY5FmmB4J7ebWhp6VNSh2E65ZQmLlyxOsu6vE4c3wsPFjZg2DcbZYSBSL05UMFeiAkBhB5ZS2Geh//7smToAAUbXEvDj0rwdYsZ72FjflpVnzmtMffC+TQpPYG+nDNY7B0MUElCGsUC5111LDYnCmo+4ki5d0KbPpAliIt1R22Uyl06XyYfFE7nDEAka2gLkvNdWQydhdqCqWgt6u4V93K008eco3HZgxKoGaG26C7wRO83LguMEJ+cc0Z5Hj6vhvkmQxa8anUc/+X6HuCHyU166na40RjtG14DhqjewUhYiriIxqNyOeJ1OzREWq1JSNSK5PGMt6Xf+G3vtPWOuYmE1H2vi3rbxsT7TdSHag63T7eW8+VIIoI6TdSnWWBYcy/o4szHjELT7lhhd1lYnK/a3bg5Sv3BBneIllQ6gAYClSsFBlnQOAICyl52XBgIcQlLCtdjFmo+UGch6kRHjQcoVbhCdOE2iosngakhd1ueVDSG+q/F5f08zip/Yp85yjuyHZ+kkcPOSvTW39QxWL2vlQP/1i/hq3xIZjS1S9GVT3XJv5obySTV0dVSyE5QhkZnFySWLJNSq0TaVhms0DXu4OT5YfDCT0PWRCBm0srEKigAoDceBTF9NFuNYuAuImbij/M8Vah7BSGTUBAVQRW1mu4zOy7u6MvQlJOOhtT/2u1iGJU5OubS8dZ9cN2Wr0NteUmtIqroVrZoryrGjJaaLjlYvHDx+Lji9xCa8uhG5HVwLvcyLBa5GVVZ0EWszvSERMVTMhRIkAAhYUhWuCrBxRYjSxUN5HJt0xnDTLVIBomHIsxIHD1yAnbXnp56PlUez1lnFA1JpTZp+tizGSW2hZfHYHaMsZlf5+b7M1d/kruTOb/Ot81jPS1X1Jl/6JBvx3o7b/O9zTt5Uv/7smS6gASjXlFzBkxgdctqLjxIfBFla0XsMSyBzq7pfPQWaJX8x3TWWnu+PSnmTu8pdf4pCF1d7SQ++3I0W1FgQ5pqSapvLtoPRlEAsIaHOC+MsGEAoDLLQEGNwP4IKK8nioFoL6iG9/rEJgUbN8cEjy1QIjLGwS0lQ97cJLf18Qb6h0Eb/38cSJnb0UQdmcqdFuX6LzN1R0RkrR1t+iu0j9Opt2MylZ45nnnIUFCLDT3uPMkSxtA0eUd4REqmATRxRCLQqJg4KFEgcEChAQW4w9VIWEtnXg0pnL8JfDgexOG8ZXuhCFrB0uvtmjvlqXXastxsH8db7rjUW2+YI1V9itANStmc+3Ty77YodUBLNzh0erko+NU3hLuEn4X1S/shpx8VT9TA1NbjlDGtCa54mqLqCTemNS/QnsGztZ09PL1Yq1hyM6Fh7Z5mGWORlAEzwJRCf19Cw2upqplsujOVJGoOjcHS6WQ7E4hdJe8usyWedop83urZPNJSw+UjMdvOei4rShQWOm6Z2qXZlLS/1VmySjOZ0OTdHUKEPZnZNuVpbTI+tqWo5sKXe9UM9kyCsjjrXEtoa5UZhNQgAoTiTToYvSW2boLOU1cCB28gRrrUAqGYAo5kW7Yek4JDoQS/iejFG3bEssHhKOz4lDuhh+0/9zxaPUK3IJprivdusjlBzL64jvLN0LGFXUgcUTdovD/VnplalcPvOoJfh+CZTKkdWon8aDb35idbnrrnW2bxYvVO+yaGMen+TMNY+vzPTAU/5CWWebiE+0qMo80XSz2Qs1nVXPRIiZwasoKAIAAJVJGhLhIglhiK31CUEGoJiP/7smTdgAR+XlBzTEPwb+sqP2DCjBRRezKN4YFCBC0m+YYg6EGgHUYqJI/5v2MzIOBcWVEXTVSQPXYQRnBzY82KEhottxGrckDFBUdFwNpXfmBx3KezaLS9YuPobmXjW/4Yk2urIFxiKnMSsipzXIy6GFtMLYzi6pVFuDxnCiiXLN1sNsoqLKdBsNWX1QREmSAeWVkVBIQIFpDNiV4EBD7hwmn415HuGGhwBL1wu3cbq4C9Ko3qEMzvN29jb3BoU8dqOg51gvTcyxnStgKdQuBJWydNyt/gsEPM7KyLV4KXYN3mn1iNv9sJpBw8a4vyyLhpjVnavqFbFm0WLsa2vIE5TTYnrMCbhusrPtvJSxlJMJZ3OnZ2JqnlSKW3tPPpWEjqKx8ndFzeVDbzbQc04s/MTsSPvs4cAJlZgJr+BHwYFB4smumC67/FyE5WumCy6Y/Oz4WuhPf1jp7NXFWblcOV0aV4rNZFHiOCdW3tkXrsMVLeXAFqKKV0eR65VSsC1XyURbDLqrUeaXMMpK14w5i4tnD5hZxayjnubONuJWmJaIOdeWn9amltiUv+kuaGNYw+4Nq4EgBbAfUCGEFxYCQuCISVLF+LuHgtxUu1VywBq/YioM5TjpjRJ2p6vbVVstalEnxblyWXIYkDr24ad+Rv8pU/NEHyGYk4khESy6Uj4tvHquaJVJ49dQ2PJaJMtnyHbYV6bEwQE68Di6vxsX/jF+yNIWdAL2k17ndQYEfWZJ74HMobTTyrMvurR/0X7SSBDapaTHr1ac689TnyyGc4uXy2RNl0yCQPvk3HJZn/9H3EgTRPmQKMBEmsHRlpWkDKJf/7smTzAwVQXEsjb1xwfutZdGWIXlWtZykNsTjB6SJmMaYh4W2J8plB4DRuY6kYXpTXTQA/UyQ2fXRQXr8Vdx/k0JyWrlwVIWKPHip5gsWD+//y1XFyNMmrIuuURxospKMjTcB+ri1pHvVy1/f91P2qmlm0vtMS/Y+WKIh6H3982oe7d3zMMchBzfdpXf/FC0kAAACOzQDRQYDH6uDCwIQgDAF2wwFQJgV5ZamqgyJsD2F6K22jNqQTZMFQ7hoRRyeLuKQlWtg5FAhCGGQdp5uMiJUzI2n8rSWt1JYWE6nILFerBBSSqZ6Q1ZGr2s/pGNEE/l8j5/CvpgTu29u3m0JTMMBhfzfwZHf7c3bvqJvLp7rxJY9Lo3GO2Qre9I0L1dfMus/F64kv7S4i20pHUW3vNO/WmyPhkiRrSxrX8irp7Xv8RQdi0EfaClIoYIAAAAZk0kYOLseJAVzlrBQFV1FnETLWtg+tm5+wSQrPCcpJS8kkxkUzx5aKjElzh43LxWakV1TRTGA/JIXVZNN1pOYyamnYy1nTY9rZ5n1MlQSfWY63TezvmKnUk+pF+nnlOm6epN3d7f3Wl921pPuioe5ueZEqQ1Ot1mSV6FjZt7bHi0GhICgkAhITCQLL7HoXUZzCJrIBmEgGYQFpigBAIEgUCg4TmZBQBQACRQYOBZg4IGKRqYTAxd0ODT5JlRCAAISqCzp4UfVLxZYzQwNmgYzprqcsBQ2y1G9OVl7X24AoxdgqCy8eAvtccZeL5TBQwgsHCA4xpcCsYTVhMLwsJlthGgoFf+fdx02XpRto7r/Q1g/kTwlVakitPLcYmEHsQirB3//7smTyAAXPYkpNbeAAgivJfq20ACOBly+5zIAEMrMlvzmgAGikViVV97UOwO8UOx6V8ei/YizuPK/kln+3Iw2kLZJrsxF6tbGx+Gr0Qehj1yfrX5ZWo1+SdhjiX5yKQW48Lsvw2KliTpvIyuK2KbDDWHuC0Zrs3i9rGI3S0mP4ZaeeCI27758a288OfP8vz/6v//+XNF0vUwJClFR1ZkEQUEgrAISDYOsAkweLDhJ/CA0ZbHjtl7XSFgITANH4xgAjAgYMKiAtqhKMQjVKpOBgC2kcQCKMsdLAVW9d4GPsBBRI4509Z80wKPv9H1MYg8liDF3rnSWCBjXIAhuSUqly+BQC4MHkRxPoBCAgwsOyyKw2zeLwW70WddznGgOYcRuq1yIGtSOuU5MKoHglUCQmUUmclnnbDjagEhYnQRS/co+6+zW/lfDLud+kxfyhi9etSNAfZklqjl9/slltjtvLdyekWNJTT36rLcgZiDJIvGJRALjxe7KLP1ZZjeu3+fy9v4lUq0FvKmyv6v/r/l81uLvPRS956md/mdvnv//v/5sy8TpABBKCFgBxFQGgQCgUCk8pLYEGtiMchwwyI6zw4RtFWFVBPo/NE2E5lN6jtnKCYLwM/oooaLHsxc1kDkwA8T+0USLXraVnjb9Vaz95xiJFWIKMsKl61+TQNFn+t0VHE61tg6tivKBiDrR+lu0EslUvyms6CuahJiL/LeOQ3BtK0Nas2a9XfaSrf5MxvHJocmXW5MadPtixd5rGdpb9L+esc9YsNcKGXBi16iWm9zHn9pb1/Ce3hjVxy1Uu41v1llnkknC2RvNBjpwQvB1Icf/7skRnAAc1X1f+ZwAA58xq/8xkABBRaWP89AAKEC0sc7CAAJZm/kPPx2ay7/LWWWP4/v7kYBVkFlVf/2KRIYwhwwQyIoJlIJDoNmxMnJABdZ1MSREVy9CRBsWiyYjPCEQ2YUoqN3Q1SLcY0gC5TkMCaYHHoCF/geZXaISoy6MUvPvI0BaFrNS9z61q9JDb/z8P20CK90klhIDjT9wzGK+djfakMOw/b2Rt3ohHrFDQyqYlj+Q5YpMOLJgqQNrK5qQVpTY5amaSnr22Jz0srP5OW6egllNG5qJw3bt3sMv7fpaSk5Sc/fcO1I9GYrdvXqsAP/D0uzrZ2b2ONrDHGcwqWO6wt4fb1hh78xOBp25TUkBXbUxMXfvXq2/5urqsDcJf/6XSJmbKhEJBABKgn4AZHKI8HGJilhIAlKkR5cC5GinjVsnxU0CNgtD8VMBeIzQOGHlCqDxl5ubRJVGPTiyHVqZ11Rs61tmXNW606XVPdTxN1Bb2NjqH03ui6Hp99x1/yraTN/VXLpVvwit281v2kUyRWhBj1jWkXgcRNut8QSa/zx/Xq8Ka2pGhWbTfStgFNhGWYgIhEgHaQ4TbsCkzhs7a7Th6MBeNCg4WHArFTdYEURRBWiWEEPIPNHGt2ymDLsZIy5pCrXU6Bkn09SQWr3SmIRz6pVtNkVRjpSNVKLiyboOh2/mdVuHPl5qo5f6vm3u6iu55l3tJuEk+0sYZMXAoribpzoCIP4FFdUYyGFAHjCwnaPEcpol8BMCkkjOJDiZq8tkzMZlW6p+LMDUODAtiPPCmc/djTdQQCCooFoTvBcMKgzwKnmeQeoW2XHumxP/7sEQkAAPbXtlx4zXyf2vLHmEjfBBVfWPnmHHKBa6sMPMOYO9gbp8KF5iysOKaOZUiI0WF3eJ6ve8/JwZo5QuxXOuhV+S594PIQdi/nn7nQ7Cod3331PJqSOqmJIoAylQl9mCAFVVSqRLmSyf1r7eJfvuy+clTZLTEwoJG9mzTrF7tdpVbNyNTgSIZLLRvzqKShVSvPomacSlBBiOLCahRdNg3hHLK8ceMRoYRLwFI4dtS6gWmznNHHOrznutmjpbiXHcyVhtJGLJ9hIAlM065v0Q5BT42VZndkMyhIBALCMiTokE6LAWxoGEP8vhRKUQhiWTzUq3uC1p5NFAAho3LCwegUtfg3G1iSdxzaLuLLNVvclSGSucnUPs4/XiRaMqtqhsTLhDNdOA9650pewCWuF8w3l5oVBLKLKlnco5JVpGqtZVz88yuICgmgq8P1xVQUVMLVa7te3pq9WkZQAINQZgaxDg1Bxp4BeItiJObwrGckp4Lt/PCjLpS4jrsINi+kVwU3xwVnyFoMGkhCdrQc2OUsc69lNpaeKXhi0E4CFiJm4GOJd65P4K0Tky1IYIXKOFtHH45nGtAzQ84R8yHTTa0fMqedPJsu7BgAiIJ25FiShs2RtDTqrmna0V5ZCiKJBMEyBdGyA0mcTEZyRJs3qwmYdZ+L5lPUu2qxCUyMJpAI635NMzF8gX9RLUkhZd18nl6gxi5k04+8chkYHc3PqPBgZhdlp+X9LCMXnPP/WlqjyBVUT07my6a5180vyH1Ia/+cOkZ7GYpxJihQn2K4O01tv/S77X7MLQEGQXV4OsQRx9CCdbuik2FkbDmvWGm//uyREuAA+FbWXnmHFKBC6r8YMOOED1lXcwYdUoDJmv48w45Q65Ms1XgOOxGHJc5x44Leq2vcARZKab39PxWS0KqSJZ1d9E1qHVuNJtIZMykikgZWakck9D4Q3EozrhyMjgR1QeJUFAxPENtR4PLLJgZSSg09w5qq1TKP6MmkFOGrG0zBMWPCurMyzw0OZgcIAEFDKOKKIaqKriQeasictSmZIMCcB/oFmaSxVj0xSWOVJ+RVbtIV0eoyDG/IVpcfouVziLzS9x8k90GI7Fueo93gnak8FHQa2Mo13lFHgrwFW2pHSP1hzOQE1dgvDGNpsxqtDSlt7vI1Zytv3PlR3UBueoQKEnwyt9sF3ZpZDRjL6AGA1UszAvwXKFmmDLCMGEoSAmpSCeUrJCRDpXDEtCBeNJAdA9EgaaEJETiYUaKnloFEGCgYkbxsXDpomtO7GctAqvGfUyiaqN/jJqOidCHGIWMLIbTinw4dUvCkfX8nzXKHOsJQYwZA63U4RNC/Ts86tHPWKb0va+98YZYVmZDOIIglQBiS5Mgg4M8VQKob4oI6qEgEspS/FagXCG2NTVG12FTvpm3KNQgJQgz41SZCMNj+7uDUmNHZWoPDzlmAbLRD17Dopj1El0jEk0gcBRyvBPUhj/7bli6gsjXInI4dMhzTI2r8YMx7x8yP7gmyoXhpnDGeI8iwGVa5VHRkZCNUAHbOFzN1SiUXZMqumss2PzLIVrXoLb58YFszdBD0dnbkvBy0xaMZuKw46/wZ6WOh1R12hlr22Z8l8h58TiBT24NzVXjgVRqEHSiFH26wXJ7uPH7D1zPQ4zK5ExFpnlw//uyRHMABAJd1/nmHTB+KyruYMOaUK1lXewkb4oNrCu9hI2xhKTxuz2akbmVOZd7RuBSXyzXCZL4L8u/VMiK6ManSCCS6hmYGw+HOfFHhmibigbGYFYe2uGDrxCCUDKYHMKKjAfhAu0FQabBlGp4p3nT3YwuU4S1eLSeLrZRishNFYosRzuMFDKEH4BmpBHEkaN1maYksKmA6VzJVQY69SjSYypkrNhl1tkpAoZtW5cFy+v0QDYYYBkgmGjvWKt/wqpV2RnU1OIgglws8LlbGkQvUv2vdnKXcOrOVSR5dyhAAIl8UWBwMrlhQdZiviBCNKvZp6sJ6vG2kEU4Ys2ptnRFotvdiGpghNMDwp0KP0/SLXipQafVbxdMnwGvvc1KFmGNho+FXz3UHEFMdKkMGpGwhXi5Xl14gyp1Gh1UNAK87/fU/SqEMzR2Qy1UBzUYutYLmy1db5JKJxvbmz9Ac6KqS/3vZijPjgiOoRTRGqs4U62YWnUcf6UfveziuJrqqnWJQOtyZUW+ssZ3zXUbWTWukMKuxdVFMcgZGkBwVx0ilpl7nZZSQ2mezRLu1ND/RjtvfRCPhbznIdCkFXJmzN93P537926tSXDIqNNINOoftya2XtYYCBmICoigUsWkspLa87YbEILz1QdoQtQj5y4wqyTY8u1Nf2PN16Pzi9LPxq4Hqoo/2l2Ng9lniWGCVQYI3M1n/mRKnWRYEA0kGdBMaM12eE9GP3udogMReCQq3YTWdVFJDOE/DLzgcmCsCNF7iE17jeW0flH6nelZKgI2XSFs1RYy+nHToQQIXR9+01GkvdVb5/XsnpXHoaBFwLEn//uyRJaABANZVnMJG/KE6yr/YYNuT7FlV4wYccH8Let09I3QbQwD4i2zbxqSW0zqoKXFZjjWLd7Tl3O/o/cn9nLQUvc0qvduWWci32sfekRSmV1FlSqDjOCydKsDu+qq1mYVBs0iJnb4Qeob9IuK5tjmRKq2KvqMOjrJZro2mQSSoCxQtJi4Aui/sg9YTRoowMcJCfaoJKizpaOLAscJU0eTgDw4CHx3o1UDUEBKzwYweEM1Ua0SWAXwYZ2CEpMd1FuZxUPJ1RhFYsMbIpqw5aIb3QRDbdEQiR1Q0/NSOddG50i8tVhGVKlGdfsdULQVlRKGipZUjbYuzUq0SFIAWBOlqDhEWeClBuqMUoehgNglxqK1B3TbJBblZmNKwRZNOD9Yf0h9mKQJp87nM7sRtg6UmTa3dArOgqzDUrYso+rnRpiFSo9QETEuUajDWQctoLbIowK5W0OMS+0kf+s9qOzB/quUJcqIqW+kSjwa/dCUp6rl/7zXzd0hGrwiEQSABY4ZZ9xAA1RMNWJMlaSWzAWssXhyCITaedRIQFFe8WYuVk40kiNtpqFF+MEY1IKAcH2jibRKCzhAphx03AkV1FioIWwQLjoQpmauWMkGQ5tOnoDEhqffCGMnt0LfnORIaAeQI2TOlgu8J3CsUwPV2hW65Vf+t2+T+5buyqnlQHEmDlO0EqAbA5zLDbC4cC8DWFRCuZa0bhkZGRAuKEIDqWpdiSaaOUOso2nNVhNMRLrealX2lW4RI1i9LOiVYitBgTDGCQHLTNoAx0VcRVdgZMbA6T9pVNeI5/DsMti7fO1k1VnWm1b7mcP8/B1hHYIAVRs0//uyRL0ABAFW1WHmHbJ/yhquYSN2T91nVYekb4H6LOpw9I4xoLOftm6ZUm2TqADAFZCTMAaQWQ7BQjlEodL0dhNZ4CodG4sohePQ++z66N586JEC5C011mqWjRdZskirGAo2WpHN+FV0s3NafDd909zTNkdDyhm4Dgy5GLwur1iJ0DQgZNZI4JGz2L8qny4Y/FeHGYJ07ARcxdqZEmeaDC4ELvsua6PqVXZIeDMtlRtBG2ByhaCtxf5OVuSFsUYmXdTmUwY+ziRPJuhUYBozJYgv6dRBpWVThFV0PVNJvVlOK9e1abU57yUddFYSy5RbuatPJ1FhZG5VU3JdzhNeehN2/XolmHO6HVcm0PMPLUubpUlGBsXiNCzYSw56gxYZZAtM56gx9HJuqW2WEqAAREBx2qIpuUk21pBILFhx3Vhken8rROq+lFlL34k+VWwhCVC5CbZxr2RizTHsu4vHvsaac3wI2TJNeIS9PJrQJSUPMojHDcWwYyOWGyuEuQyL3wvxgmytCLEsV0ekD2ePSqEZaAlL2IqZMSrmQYOGhQBuobSKLs915ZlJN1AACCCL3YgOAGxYTIIwEEKRYNQP9MotYhk9FRYckJ61kAzXRtIlUZCnKkoQYPsonwRm6gcLEsyRCvKCE8ow3AmjVNG9Oh+edl6aEM10y6aGbkaJeGOhGKJo1sE2ULUWzLiylL9WtZD2pxQQ6l2zHsuZjOX8JTXji6rtXjJyerSbrZtfz8qmohmios3eQfh2xbP5/U9oG2NpECM25EawAIy+FgkNGHCQH6RPTReOAiWfieneENsfjt1eIw3vc6aSxCrFJZld7HNi//uyROWABAZe1fMJG/J/i9qcYMOaEvFzS2w9IYpyLmkRhiWY4fRm9Vg8SHMJX4REbKHUqDrwTQSDkY2abWxGkIQMvls9IkDZHFipsxlFEgFl9YWRGscTJrB61z/+FxhtJVhj2ytSz2Fmm5x8Dj3Z8NIkUl68k5QQN5uy88aWZksZ7JRKWyp83LRebhZ6qky602QAJjG9SqTMUQEoX5JAIpJrwMmkzKG5W2jIoAgWVOfPQfqtKAHgoZKNJYam3ayv0hYaRpN09eYmYkpPVZMjKNE2hGUDC55FhaGKJ6gEShgtGiNhCziZO0iYMORoBlDGpXGMTHTXSVleQPRNhTp3hu0aGYHt2up/oNXn5tVRVw9FMj2gnCTzsSDE+ROuX9MkhpIqx38M/4LMf1bQCgAEI5uZFQ2iJgQxJ4x6NIkqXFRVR6o4VG3obBKK9HLZHfoMAfdapAXKrq2O9JOccWbkqjailFtmiJvwSnrKE2hJSMDlyl9gsaX05RCtnYVKqQapXVSjcOxIFUGpNLU1ExFJ6k4q4ihZZT114VnfHT1B5acqFI2jH97RZBrf8blmE5xvp9AQPhJnNrGr7BrBJODbWFDIxJzVQL4Q6gek8FRJ8PYwwoHLHhWAUVak+j24vvHoKbBSCdHhGLSWI1iVSS5vbSOM2hQJNI0Zar1hSSM9NCuVUQJLvOYGGkeMsmGh0xF8CEXuZ4yy3FgnUTemJag7oGtqWds1XkLglM/ky9YklbFwqME9BtI/Xsa3Sqt3Hxpmir8FbVNnY6vtGwUoKEHjl6GUJi5uFCBiA08qqCKvUpwy8dGMgcR9ngVvn4HCIdhDgXiS//uyRPKDFNJd0lsJNPKZa9pcYSaeEhFpRowk0cI1rmkthhmYUxCe8+KrkqrqAbakh0ChlUgtMw5Lyi82DAqZjA4IkWTbdWk+pEsPHcst1rRlIjJtph2KIJoyXXY6LT+1nTRy97i5sLLTsxsuionSNqeZU7WG/XV4j+29Hvf90k+V4nIS5VHDZxkElg0FNx3WmiTDZGgIABhCpawgOJB4sFhyW6OT8Q4kSi48zOJG8jIA7gDh8AgNjIKCEUKwJULGHYg1aqBI25tREumm3FRC90dKsqkU6SONxHI7WyJF14dWeEeEMo4ia8H4BJzM3SklURrG2x3vd341yZKNpI482VTZrU1y76r7e/XvO+NV3W7Fb+zpkgopM2apnw4u7fCv691hlZIrkYQUAAwYxrA7gTg3wOBvgXiqLAdocxAiVkzMi5wMthsRjSRYQEgIvQtkrcyp0H1Lg89INqTYcejpyCNGRph9rnIp7B4VHHSZcYmxRxqaj5GJkqA2scWQA0X6ZVFn6URTz+i+a1T/2czKno+HYCl78z9OZmQ+EazPc/5j93vPW9s1SKYIxglrRqqRKNrO5WIqjNZ8YASmqZAAAOQTqqKF/0b0iJalEi2tFzxCAi1m7z5v9ATtSqMu9TzU7HCxiSSp61Ek1mHBucEalNqrCptYbHbJ2x5Vxkq6CG+QuV2Uvs4ZgHMc86MF8rcfaDSAYjlHDVQkgbZaxzoazjWMs7CEYtSPDTIcijqOhKaEFXf3fIUpHZ71NghMpD5isalg0HNZZgYmmVJI0CAADkyFwJLJhhcKerTxAB0UBtlSl92ywczWCHGl8zFJWZ7ZYHB2//uyRPEABJlcUeMJM/KVrBo8PSZ8UfFpRYwkc8JELOjxhJo5zLJJkVkJrYiel1Lntlx7YqnsdconyMjJLaTlqxPyaqflSSDyJC+xDi3ItnBCzlFtSZAPfIY+QqKfFU9uh4Qb7Js46mVt2z7313u9GuXmTsZ08f23e/+0U6CC1pnSpQrMrxv296dkxqoBoxkAAAARJBm6bw/cwNU0fcoALmiDxI4KKLMZ26Vx3KGICGHRrcNSs2jKxVHOjS8moFyEUjyIxYERchlwJza3D/fzQ1F0ZfJRLf4wI5GUQA63i5YKC1SDI6m0HRSeVGEcOQjJFAm6yPBUEsg8DBq759DFIcUqeR8R46K9OL35mGt7tzzZU6VOzr/+oLfpN3bStx8554pIuiWS7p1uJqN35vy7t9Qb52xv1LhIkgACbQgsMi6BijbiABLP55r75vwo4wWy3NZ1zcQ8uID9tI0tZVkIjjbM6XQxSNnpIrkJz0nIiLTiDqJiBwjFHYOoNqSKF6TTTMo3WkFCg7TtWUCgpiiX2WZHYSKRhjTcYjjtMR9Zmoq5Y4s7AvFuhleaZAFCpeZbw8S05dxWpXGUAARAABBLxJDXxIxYELLgoqxErMjaAj0GCVI16JTjrQPae9pdLS5ytarcqeA32MVMBRHcslUVB3ChF4Kii5CwTiZYVkhRAhHwtVF0TgpRsj2AotcJTJNeohBS/LhyZ6kHIVPeYl08dFYbrXVpbeqwXbK+oTYepxOO8ofQ9VoxnGWz6Tp1c7Eaqpka2JqsVuvXgDa4wg2Gc3HqXeSdOWHMvVzHPqPpCWrZ+fUu7r1t/7Zn5e/Wz0ZY0ACY//uyZPOCJUxhz+MMS3KDSHoLZSZ6VoWdO2ww1cHbLej1gw5wa1Ooz1AYiwaoR1ilFadtWViT8o9t5OPvGo1WfaR73yF1VII0RCSRnvJx97rmeiDM2c0o5Yl8bx7zmaVR03y5afQ+MmJ695WTd2pFvD3nWdTsEEZErIOyK9aHWVp5mg8Qsp+5//+3WIfbHw2YuraYfMWAg4gAACZXRgOx8UGQnDSVwqikoimTikga82JvdaiyndrbRHJdTK4vhi8N5vzCSTTicVuxQTh+wlE6xEQ0Mov0eKqLGVIhOQrRUuwTut5AQk1/FA5P0MjEkLyoCCejrJktdJNSVzkDi6z1osIkB90CqEXkaGBNCKSv16bSjQ+TxoeR7Zed9J7OpoGP0LN50o5aSKWJuZ9tVVwnClEOek2ctIZEiws64tpIqLiAA42EvEmCkVKmvJqLllOcAocV5szUIryFtttEb8qZNxgjVMn5EOIaipyCSFtjDgws0Q2VkswBYvLhaO4WxanLInUyJpBEJy6y9itnlHIlLrWt2MN5p6rflU3fyztcszP2tj2qPEDg9IJIWRoHTZZYuL+pxIRyQACBAUD8snQYXml2IdpFs7biDTlqGDRxrrlrAUmb4zCvL2mRgLBtTSSnlg0MCxJdHVfULj0gkXQqA03gXKNZEttYigOS65CrcPfISs3PFkZfPqXHEf/KydG7Gbq78vLpPo0T8OawGmwl5/dudi9c2khhm6V7cJY5qMDH4yru9w3u7EklE/6ognXifl+3U5NJVvymFNhlXZPltP/luZibtKoKaVviyrgcJICWgZInsly0iVijlIRiVQWQAUCd//uyZO8CJUJbz1ssTVB2KHoEYSZ6FQF9OowxM8IfrafthI55dmi3a0hnpu7dcbGzKhkxMjais3FHluig7SQ4aOF2ZxXqmj0yIiyo2o61WSN5yZEotBttFOlV2pqq0mSKpkEBuFNlrYqTW3WVeMTgkpH7iBNFhhoSe6OCNVXc16Fv7pa5v7ERJWJ3JVxkIy3CfLMXttUiV0hDIRAAAwslqEXLfnJBeQDTFFDalNVXAwJeNUEIepsbXr9tuj+BRtIMlBOwuDLVKyKM8hEyfgN9iyiCV81KNlETqQlpeA8m234szfRPZocRWUkhimTJbUUKDKc0/e3fcN2Oc+e6h3n6lt/LioeacL6Szyx/eM485Mi/onbwQIqz7LmtZWuNHjU3P0m361kikH13F0nLXli0tP8V/jn3KdLF56aW6aPoqvDM6IbKIRLiOag4MA4iiSQb0FFgUx255o0tfplEDQY9e7tePvnzsmMAeH2Q7Xm9u/YzP6Q150mgk1zr/W7VZn8fJ2GqEDKtQ+LaG9gsJQf9pin9y+xie5Rba2o9nUFa8PlZvz1t/G9pLPsyPfqAy+oAO222vtTJTU7iXDdNlNPeab8TSSYp4jpnH9lICEZQxEUAAAw2dR/2lFnq1lDBCOPp5pfARReBVlA77R9/TvrMzVZ6GKuxhSWD5x5yFfZ9h6Wj4s7xku7b1j0qOCfsCE8c15abNKdrOqTF7XALH3oxiV/hfHmlkI0LPCcxt5eFhxJcbecsw1fI9Pu1Hz9SRi2LQvVRYgNQkJtp54xT10PWTxPqrJtKMVZZEXjmo3S7QptI+GsgmSoNkvkeVZk4wsr0uSwk//uyZO8ABUNnUPMJZHCM6+pvYMmeVL17QcwxNYHUqmk5kw3YQZGMQAAA1GIPsVisXJohGOtMSFjjdQaGic3Jdz50P1QEUIIcLJYy6OMJUYWWSucJGAxEQWharQSrP8GDDw1f99awE9BjZMpYl5DJ4b6m6wqUzBvkeCRaUJucC1pFPNmPDI2QK6HDyz6ZeHsyHBMGJFTaFQSBGSQWI5ew8CIWW41IKgG5tdcoUAttNOMKjYVAY0LRYdoCcShLAiuHINCHWFYbn1/QW9qeEuj6pTDdYSH5RjWCEdzIruHLIjE+ARy2/Fc/LK2cLpxdgeisjZJJJOmjgvVU2qjOsqLw95tpuJtGRaTQehJ+MSUuXEEL3ZTocEcKGYK7KkJiZdb5DYLJxL6yOWFT0v5Z6BcJG8cL9RUXa3Yph47xyeIccz1p18Opkh9sa5nJOyoQUAAJwuQkVFFgqVfgkaAhUCVqwnK+0Za2zaJyhSBImF7Ihl/FGYniVNKZFH0Bq10NeMn5RefzM7MpgKLq+/lq5FH8uW1VlnyhVRjUm0aeCFfAkfrn5scrf5amOhii+QvAwIteG9BnTvlTuJHQmuDjawTBTQAAMK9bUeKWnVpQsUML3Ok9i91wrPoFjtbegRXi6XAYXqPoJEpUDQJxtGcCS2+liMreeACENTCXjk+Q1wfvVLohAHjQzoRnk6Ey5g8uGKvjkxPNQhxN7RBImfoKBpaSMdxzMCJmBOiRyswy6LKd84SkzfDy+xHyWcV1pvgfiamcbQ2qiUxcUqx5IWRebCGKjJx9XNmBEDT2UnI2JWSsNPZR+dSnGEk0Cao991Ck8iaKRggA//uyZO4DBYVeTyM4YFB1ayo+ZMN+Vd17OowxL8HeK2h5kw5pADlaDyE0IQVXHulOh1N7cp+SNbqs7bND1ykuX4BcafxgsDzI5ZlaUljNX3SUml4XVmgW6pHzisx8KkmNeaNi+u8dAwdhxPGnhnzUHaAiCVIcP+QKJ+qmdylIpKtWeXl1LarfV8ofsfU/BCvpeYtiK0pBIwgMHLOgaq+iFZggAOUrcSOLWK7eNLdAe8FbOA2xSKgfxnT8Qqs0RVDm41EWNKxbM6MFOBXhaBwt8fpjZiqASwZpXh7BB6EnkM6E8QbWouPiohJBUPxbS4fA9p2DBUs4fzO9Tg4HOV5OyKCROguSwfSfReQ0esUVSqeJ3wixvOnmJaZUqoaoVZm1vqtSQwcj+XYL6wq/gqVdP77MwoXp1QUSV9rf0b0pO30SLKqmhMUgAEFLz93jBekzhS8SgSl4GPTqgxDllea6og6cDITyEKgWAYgBwOEbY0epfUzq90VkmfZD8GiNuFSbTV5tpBKBOoxSdEADRjFBTWlwGMlWK7AiIVwUyILehkVuPltm6WwLQ7NfU4G9YZo5fSqflyN+3vC/b9gzgjNNDvsAyhQJuTsNRsASgrMo2oKEFF2U2U1mcKYPzB1ly24r31Wa0+z5wY+8CVpm64MftcdN9v+9TPPuV2oOpZhuDQr1RlrcH6lOi9fYqkIQlsnhao4hikSkrQliMgoZiMxrsXYiu/jATP+w6fSnvDWiQZlhvjIsyuL5cmqVOY6cKVX6djgey20zWh1V7pXPTakveTxDusjHNtD0xHGNs3C8+9Eiax0xDBeT29eCRgo6+SUhCZSl//uyZO8CBVteTaNMNXCA6un+ZSN8FdF5NQyw2wIPrWdxhhmgoAABYWS3zwN0C4XO0nUULdOOtdQNJnqGEU5VhucEKjiNewSndS3fzmjJ/4PVrpE8SPNEaQNSZjDZoWHmOogxJrjTTXky5z5jU7sdrq+0lFtPqs09nNxsMKfD5U4VDe1zM/MxW33x23Ec6X9I0/vxTUi7bplzmy83ykvCgsBja39VBNFAARdtbIWUMAsGoIIeFvYUtFyk/owmvapVzqgYNPtalZA0KXQYtgvDRQ8QpU0ZynRSyfhvpV5ozS6hzOkIUZODxbiDkDbLG6qTuqpxECdw4qlRp+wGVUIBHMCoIZrLDyWb0HUdWWsolO2v1wtOfi5szrBYM1YIBISsQQGRLREDIDYsICarHRO6ahYk8zK8KBa59HaDDjtb4sXnV9X2xrHyMfE/DwnjGrFxzMeg9u08J3gZNFKg0xSyAAABDNIWF6AZKjK2wSFdSMdO7TJ25U8COi3O7P0kWzbXWM80t30tCYfRsTsMXDHvioD8UK2EtI4h9JhNEYlMPRSY+vfhQbjU1tWMBiRSAWcldSdyFD3I6No/S9vNJI/a3cjPmLb+cxobucdT2hdk9vYObE5p3v57pSzFTWLDv2QQI4QACNsoYZGwWSAxszhCWEI8MLNAhBgQbDlEVjS1oK53Xlr0K3tyndtyXavGQtdio8GtzsIDFs5LlWi7G2PlB+KvWIAEW3nj9e/Uqoo9eXIMAnoC/Wj8JfsWBLHvzskCS4hoZkeVQjLvmFG1mi806pmeywdj690C7K2XtzmyilIhGnMub0wQ/MUVJnHaNHzG+Amt//uyZOcCBbRcTEMvTHCC6Jm8YSaaVP2LNY0wdcFulChxh4xoIduMEP9eC3QWHNqMwn1+w/HB+5QTfQgCip5UPEFtJJPGwyhbTHQs9wZghwfjxpYZizGEiarqVe+hOVAxyzF2BxJsh06Of5Gd1JxmOh2TQHhk4sbATx4+GigHSaFxcshFDf+w0PMUj1A5obAzYtRSDAAABE95yAsxHCxDPOYTnwvNMOIBydFkGA1b0uVG13r2MQLXxCZcQCEt4TEV0gQkWkawrcXHMNQkHQw5DmcBTzYDTbRNxFxoFhVRKDZSqQYwBtQscMn4eWKcQAV44WFCWhMvDKFhglc9HIBvUkRzFtByULoHg8i9pM1DIYdHYa464SdN+HFsoS+J2YvkKBNCULDHonS5qiVgJw1+AdZzMtmdWJ2eRLq/4Mwkjd3zDLqkIq5JKbqbLHHKNxemwYf1xMSsbfP0IQZNmSEPE6qqEXWxMnxnMRbaqu/Lb/66gd2q9QSsbxAZABLVWRCoIVhcdZqwj6g4kvnakegybbg7yhjfgWRb3YtlTJ6KAiRm2WgiDGDNLrGOYQkYww9MjTP8oREeRRxZqKuxufTHK9Yqq5dpy5HktTbzFG6dpj3FVQX9eZbH9bfP6/ZiANkto7mT//7fsAgQAGSmhD9E0SygQKYAFLBATdEtdByOjOy8MUaWwgcBL9zeKuW5VR0SXoKCwHUXF24sBbSUQoSsUJzQ0CcZHzG4UDbGkO4niChnIkxnwWxwRanmLyqj2mO05WDbYTNVVqhqfP3C8Y53O5XxpsUy4P5XUXDjFja/i2Ig3DIFhRKz6wCymzHeGDDNpFD2//uyZPACBxFnSrNPTXBxaIoNYSN2VplzMQ09McGtq+j9gw4J5WuSXHE6x+75oIQQvN0pd3fR3UEcevvuEVoeM0Duhr7utwyoGGE6JcDWVcpczJKSTlt3miMPQll4Y4jsHRdKIrD1ftpiwU099qSDWGHcpIMjSKPZPXGz77Gva5QID/zmpUghViYvSv5o+Q65vfzp28X/5Ifec6HYkW5VKcLMjqcIlvu++yfEhFTa/8cFNmOIukUfPQBQWQQAIElBgZ3QxOHEQFHTlBRlCSu+BUQgKDXM1u00xAfO3GuxFvXvzeBx41lLG/qUvuBKMpZBD7RXFwH/grlqVurP6cCxDnzHFy5UD7QBYlD1vI2NUQxmxWwgoDcjgwXvMDBJBcyavik/APGVgaJchOAcOb1cWRzCXbs8lED3AP9J+QmDCAsDnXIbp4rlMkLMhGsXvRJHt9OP82sdkjB7bfxe4TCPtSWglhpDM3ClSYMfSIue6QEQsyViMclLs+tZzanxnP3NH3x0pygQ0ncyYCJJVVshDX05nrdcsAeoITL405qa6ikPPzH39kMvlzgJnOrH2sD4NEBEbJlDAfPVf9e8g+m7vcj4kbRyz55BSOkRANgXSdP87b1Fh8uvtID2bmUgexc6vUbCTFpZnhC6po94S4wiu/5nMt25t+Cj+4/Sr7/bVZWs/82oui5CBoobhWKKIZ8WPpGE4H3zRSI5Ik2dh9WhF+OxPbtMMe7aO86vYLaN0AIemKwMIQFWq1N+hyGosml652Cwqnhpx3sD/grABJB5UuF8K3jEhHvQLSJ8Z0DA/sQuJlmR3XqrF8cSfyGO47K8JYNc//uyZN2CBmdnzVtMf0CobMoNYSyeWJ2LNqwx78H3Lui9hKFogPyeVPBtxi5hKFq7FYkFuMjQ+WCrC1oFnupEqkI6kQ3U1V2n6x+qTcmhtaIj3gpNnxAaFZtxOwjahkRUmKZOE/UpETKWccK+Ez0Y2F2sXVDMr/CZX8eV+3USacMt7O9Xb17BckMiURxe31mtcOdbNm3+V5BRNeNG/8NijoCTyiqjLSISlEiCACfauwo4XGh0SHNjgmp0LOkbA/I4TkCDIJrisXDxojyKZlCpyZE3NCtasruE9nMdavSTSRotUeRXM20XTOoqFB+l5CvOPQcfzVqM0+r7puJa9oJWdv8rlluam6yjuSonoWjoavpZvF/pVQ4qnApA6pa+hqqRKkSSYCAqmErQYJUrDiU9oZACA4FyaKzJwk+5XEWjQNXd112zSCpAK+pjKUx4mdyZt5KyJ6FaxZ6NODWHoUEso24EzUafj03YXpDOQ8LBy7I6l9z3CwYMIQTK7WLo5R6sK5Y+A12spFAy0u1t2nBTWS2KjG2MsyOAHOvm9G3FcFUzCx8Ts7TKnVAcJjldtqy5J9YWONpkACTeXJyNpWSjGAeak0MtjH6zVdZhh4yDjS9ZkySYl2QkjKIACByIpxv00igRd0qARTb9oBbZgjUuvdNRP+9prV/7ruyDHUygjsxNsQUtB41oufTv6LM9TRQBikQGAM9nnpMokd7+JrdjaaFI9Wqz8Q7HmQ1KolXbIjTseqM9FS7jdnK6GfdWnGxxhMHY24seiWNkCCgZCAaPNysg74oVOiVp9JNy+dZggDV6sK1tejd7cxFWkhbHskJMwmKY//uwZKkDBYReziMsTWB3yzo/YMWmFLV5NowlkUHgrqgxhKHRMU2RMd4adShADGQ0KOKoSh99Fxpo6KBFUsBAtAGhdipq5/NPgbQwySi09c8MnJTmLseLrzJcXC67pDWxQcvdzV5lZDYPtyqAubYVWq4jxSymTrpd2tHz4++Y3F0ufDSN44j1Mqs/g7J6Uyr9EMKW8fPHJ34rVaSyIZgKLSnaTorpRBDbv6k6aoUynLtl+BYDS8YizqiksUqr8hqIYNZFxF8qhQoaEQkvIFB5MCsz2IRpQ2oWoP89n40KOE8cHVzTyK9W6L63V73/s45fGP3KzKGHXK9Q1r9LWvUPC/V1JNJ46fKO9OthptQPnxBr8/md6xprqiHhCAAeeMueM4CMhhIKNx+8XQljQBVDEH5YrGnjXxnMPnJBPQGwHBKIdC6nJ6JhO4epyyoN2iUPBEXpD8m3hLAkosZNuoliRxayvbcJ6SJ3Sq2l1wd03vEWOveP7lCmcjGBtuk0RCfZyeq5Yom+ziSXhj4FgZFSO8cnlJtMpkLc/2zG8RGFcIZ11mkOx629M59TRziloq2B3p9hoU7UULN20G1uUS+hSent1MkyBUzwVnldA0LxLkI1l5lqqYIJBIqlSmrzhjDKx49Px/7KAoulolwur0UbGCc8yEWChbpQ6EvzOMRG2BHma0rcjBKVPi2VjLySbdfOFl3PzzxbNgTM2qIB5B3UuNl27Q3B0CmJExZeHECmAAhXlqiEs3aQaeZi7JgrMEGrhc9L+WJmQVJ1mrxeekXgrqMNPuuo114M5mHI1apo9QVJRGHXaFqo9TnGyFeVbBJOzqT/+7JkrQIFNl5MowxMcGwnqg5hg2gV2XkvbLDZQYWs5/GECig0EcSVLLp0nKQ2sQ7pxesWpz8PCxZGe64djcuvvj7F7QpNHK/V2uMlSt/HIn7BAmgrJuRXNZ/dA82msnbimUy2Kawu61eck5hI4QSjnS2thqR14jqcbLSRphSe1Sja08j+Wo8h/fD0k7cZ9iUIBsBCfZZQOmM1S6dBBZ1eQc9QyFYkOJmytdLivg0RlIWvLLSHGDfxaci60TqGItKWqnPqMy9XWVEoSn7uRF1Qq6te+at6dN9KTdHvu0y9H63Zet/Yzp+aUqIKdevEEQAAAINENcEqGg4tL4jOc8hSCXmXvejyhnMx2A4wXJnqB40lz4JcsmwY5NbITANKJHMQ3ptrpxWuvPkSebkbrpphHO3njdmjKaJDTI/XjU1Oby7bGYXja0OKU2kyUd0dr5sgQUO1JZvmdT6co7lcQubtAhfuIG04RQm8grH8k6Hpq3V4jmsm1L5lfyW2j97dxjVZO68odV8IedN8bKH5FHyd2wfeU3xaJWk1BAAAgcVt3pVSTTecggsNrL+E8rid7omOWehWTAyRDHzop/5JyUNL+wQvGJiUKdauajndLYeI3vWx3l2lvkz+73XKBRxLYC7lqsaTJBsNHRFWt6oxw4d69C61jmBMd3hAyAAZAgTREI4OIM2EO6sCqgtPOO8m4Dh3leeSNzX1P7ZEh1P27cdouyojnsVqmcUMFzKdWtiffyaQwvxxLboUpUTwX7Kx1gnkafXbtkjrzVQ0IqmVXzpcMLLuxlYccDNN11e6X+oDfCpAj12tg2PksEH9ghaDqM4slXL/+7JkwwIlUFtLyy9McGClublhhi4VPYsvLL0RwW4aZ3WDCagGkIpo+mEw+5sPkolmZUmNS6575psZnLln3XExIeBCUjHCFRY429RHTjng1zuqsHgJggBJQvM/HoaCBggPnBMP03ZuXsTniTHZzTztoEMK+HftOZTj6t4TZAJBNy5B9bss5VYOXvSH0Yj2M2UtVaiPuFNFQLNIIDQRPJoMr8f7mumaKB4MDChKfWyF4NsoEEAkugJ6pn0DgpmtyRkLmJBUFI1RH10Y2/0We0hmlRaJDzh1WN6Z4P504iWpEPyfN32gXpSZG1PJEOfKEW00NnwbrKtaXXvXc3TNzlybp1CbJ0qLauGc5M9pyvpSeLP8IdtPFTa3X9uvUM6+Y4hWolzdl1vrap9vTPLXLfbp1LiOcfMQI7SzKhBqoAIFgWCP0YHsoYl0m8S0Hru11gS6XdjsorOCDRKFAqgFCiAAInI0QJpOsyofj00c0QohsxCSZZYoRXBgtuLGp0LoCriU1LFz6iGa5GgerOeRVYjVTQ52pb0mP8Uh/CUfW74Q+23KNXtf7edJ8f8/rPOHf5QalqefpQS3bahVxUuno8vR+O5TsUQcfpAAA6IIJCAZCITDYiDYMABmSpjIUnwNhxbqIAiHRAIN3EYEasLEV+FSEEByahAOGICM0mC1FGYHqgRp0UN1RM4lMoBBoHdGWkV6jpLoUgvxp8YBq50HkUZjkqLvnEusOc12WBqja8niCWy4wOOmHcelyYlB1K2dz2mQ/2OGQcAQgMQ0wDGLUlcZbFSy6GbMcf1TJs7sQJXR7QdL5o5gUUtG/0NUP2qW3I4NhyD/+7JE4oAEX1rObWFgAI2rmZmsJAAinZUxubyABGezJ781kAB5TTx94rMnlFEDk3/Zwoo6saYAwlv8l9Q1CtzWMKiW86WHZ6ns1IHpt5VEUFK3GnmHuAyhscLRUhFh96udn6K1hnhzmvi0fmJLezdO9O/3dvD9LCPbL6655dF5fhF699X//9/+YB8+KNHIAGI4qGAIIwY9HIdCAZHRGADBhA6FQ4xo9M0xicUJQ6x00woyQAAozQgTKGwQjOOfJYpa2BETUSEx0+FQsrWPIwcGjSX/ATLOUSJI15IpIxJMyxUTghAKFgLMfHFkIbSbfRnSqiWS7IJLQNxL2A4pOISBQHvRH441CJxcvWCkEwHUYPBjUWPOqvtZWTtviVQnTUMdKYa4weRs3QceVx4eglusPP6l61mScpZdrK/S1GSWLDX4v8rjd+Iy2mmJuB4i1Z3NvtLpFOx6efq3reUYlkaaw/Ew/k44lI3rxrsfOzqA5h+Wkw5TQ/Kbs3L6KtY7Y5j+WDOGISCG5VO5TmWqTlj3bZu4srbCoy97aQt/Pi8bxpP////OpdrqIF3tt3mjSiVSqMIpGJMtBbBrqpuiKqsJJCwYGpFQ17o3KoFATImLMTQdCIJOZRLkOLEJYdA/RxjBKGROF9T4j4EkX9Sp47hclBplignA/glBEHEhpchvK9ge6YmSMnxuqguyHsF1eLec9Umr1s8VEyLsXB+StQqMvpyv4LBGSLEsp1zZpl2mb7nXmdnVZ5qJ01R87hqqKzvLvHOWHRlVjAVjiilM20OtTwFwjdRY8KBCjye71zX4Tm5LEesZ+2rk82pwiiGHBRenap7/+7JEZYAHO2RU7mXgAOoMmq/NvAASiXlX/YWAAk0vKv+wsAAE2nOMfjq0Rk1M/xn6ynn61AQ9VM8jykcTEf/95CStDNDNDO4kbcSSaaLIbQBExCFGVjSmIPAUoS0LzMULdMYVoRPDAFuCgbOl5jbMsTJTsICeAokjMUcJLAUgwCbKBsbG8elbcXTe3bcYCjLeClZWBjhXP3J1q9yXTNElP9uyk1YylwNeGu3LJhRXylYcuErcoHRbkaf0CKer1OIk/4phrmOk7NfUrSdScRCciqtsUqgeNamu+jP3rUqFcj21z3DYWppT8Zd0j2cGdQan3Ir4Tku3iqfM7ZM8qxMjmb63o8WdxVjI++/QmkEnL4/zvQyeKx2pB1GbF5LqaImz/bWVXPZBR3/9IGz7dQ6JpUCQEZ6g6q5WgMjSwQDKqK0Fq1G2YtjTQYi1GH5cRy0OEETkDx9iVoOLTFAvNWPs5nmZBtTa5d5qarnHMiel2bVGpKXEfW1took0fnQdpF1Q1Jyccy40uUGNXpsP3MTc/TaasNq4c6UbVSlKnVbfa1zbdzHbEZmZNXH577iKs+awVSuasXpFlKvVOh3Sa0gjvMVTIs1IAAQBIEBLes8QHOql7Tq8WHpm4N1R4fpXzd3SKjcPxUTrYqhclyUQlnD6EkwklqBoAWbIm9XSxSqf6m2HF3y9Q3VL+Pe3hx7cVENHdqs3tZdO/eaIa7FeGoR5w/t16UKCVHbu8vedzzdytVPu2O3tZ06Xy5I2P9dW+aPGzi8lQWpmx5u6nnUTocbmnysDWYqMZVkYAAAMdrRLvIkqXLCumwJirSESkwhmDpVafVT/+7JkEIEErlrUe09KknvrSs9hBYxWHYtFzj0vwfcuqfmWIdBBCZk4HwNQLCBOTJCKGM0oYRbNO9p4YivJPNkSILyVbSIi8aQpTDA5nv5nThGCZHH2vj4SB126936psI4VxLaSRnvSIxubK0jbDunFrwQI4Rgeh+5D1FzV7WS6U92Fp51iSPKIE2rjvxMGI4zN2YxOj/vwd/QNpu8qYf6JkAoxAVE0Pvuou9AQnk3JT6qCY7GJG3OHJLAb5wiBg7ZBcRCQUnupxFkjyNTA6lgbIhmzQ7PPHHoHqwcHAAU/XHekVg2cnRFDg6Y9qa3zbKnEr6zKt9l3Zu1EK8UdkRGoQbuIlc8roPNiYTQ8UGsMs8IdFdvYOiLLIhjCgAgSSxgIDCoBdFPNofoVP+mcIgCLAObh/6rTEJULFeHHamtSYphhSlYj+JrOYGPuZR9StitpK2Lee3bV1s3YHPpJV05VMvpVx1E71G1i0h81yQTdZUqh0uhZ2KYjAnJtqdKDUbKBAtJpGSu0wAElxo+lRakRnBwHieJlEpJQNESKRCREXOx0mPiob2jRMhgWaO0VmodgoVJGpiAg2k5rW5JPwlefsuPMv6KQZoy2tmOngBDTkxiYtULdMIZQEBYN0EikcqbKVL2VFF0qcbPH9UxWjV2ybVfia/hzfrsfUy3Hb3mmVZYhAYCUtMuxTOWaX+y8NXbxXvSjqqtU+uroTFfDfJP9HXMs+KwvtN4yr81sYLC3vLeLHHQPmpFW7GGCebmry1OjG2KVEvekbD4AAYHkYOOpimNGIYxEcEJGIIk2xGNK2IvqbtncXhQaHIhl8RFS51K33l//+7JkF4AFXl7P45lgUIBLuk9kyKRUQX07baXzwcqtqL2TCmnooFBayiRte3Ukjg7W3nLDa5i+LIux6ttgb6J2jMUBklZ2+GPHRaYlk7LdbJSqMNW0/UKIvFqUU2vCuh+bNlp51cWY0IOTY8psT1FzT62xWYvqUnQxYIx6r8gOU9tadRuwVyjJeRRJvmvWCWPjPmrJmve9ttb0C3CxFxGRpBVN6qYZ5ISAAjulpi+CtDKnHtPEkkrtStQcLBs7V0yplzlujNzTrxWLVvdN16svkGFX5h3eSakwo8tDy2QSI8zU8HJWWMAkP4mJW4hLS+HThvalrxy8oN81v+Obvi8TyfHzLcqzaXdKUtRTL/95NQ456cpL1Jro0ryEsm7/OZMSBUdkRMAmA2REBM1Fg9OQaDFYE5lvrzdhW5FSCHkp4JbnJrcMvvDNuhnSAjnAFqcWE9J6s01nQs7+n6iJEP8086ppu2uKeAx9naJpx+GL6oQutEqu9V6m2sZ26RsWTWRSpNLfMhYp+M2sP5rTumGLB1tn1rMzxm/pBvVWyuUsKPren2fJa0X2iMMV6un1++V0K7iy/UWJine5ri0ab3LBOfeZFFXImFU42mACjvmAQ0MojLLaNLmxI2xpK5u5cimo408UM8lL+TUssSqCS1XkFlOGSuGp5K7V7TjKYuqr//VZHUC4uHkqKPR330lJ5y++abRadDIlnUiiSu6ubc2dd3ajmSkqburOaFrz3OUtQQt1FEe4agQwFmTAJmteCjVHMEhwhAlnIiKILeYPt8ULnIdVW1oIAAWuSJwo0m300Q8kQ9V2XCLlFI+FBYTAjVXbarr/+7JkHoAFkmLNW29McGLFOk9h4ywWOYkzbeGFwbStKv2DCf3YdKq2Wx0+zK9P3WH72LWBCb6HoqIG5G1ZxiG0qrWiGRPlOZlzKvoXjCRtimDJLYeQn80hXS8kCPUyYz4gyhHpWnbMRMIbpscV9lVaTNuaiLc//N3lH9JhCxayooU8hu4ml2InEa7ONbL6onlK57tI4tiv//oBnlnipVK020Uyyr/Ew4YGDpWvgQSfY2NWI9mcVEtA3lXt+aWJoa6AC3OuoFhq18tPieafqnlWWzoci8103eiSQueJLD5VbBg2Th4PBiChuutTlXuAJ3eeJPSlazDgu1q3d2oAqxxABAd0LEzG3cCAyOY0Dw6IAGEA6lXylqtLuqwvWyZp8pkbsQ7JdWohDDo6eNqZSqyHZDZsYjinnKVdzW7wlIURypMTPpQissgW+PygjjojyA5cpqURReiHgQYe4vnL2vXOshSMdrNl/r2SXfW7qK9A7nNMcfrScbyqlqqQRrsXhGNZbcop48i/C9ju5vdTZo0Yn1NIHrVNHVyrTVY79FCLsVdemosmfpMxD4pV7r+4Jj93bqW+22jWiUee2BYZhpNFgw0Z42psOeSYiMih93yjSKKY9kynjcJ2cJXr3W6lZfcp9fFob5f9zKx81yBtP3jHdQ/T1yDtZgczaMVrsSpS8pkVSyuLWivVU0T0aqt/f9Weh171DM9hAt27ywIdXVAIABHRiAKFnCEgCnLWOOSgBgoaXIpkXFhmjQtRd4n4adffaG4tekr+oimnRKjhyIVy2YnnRA0T7BGZuzgGyb0iL7U15+UCHIrqXyqDeMHCmkRtTOn/+7JkLAAFFGNOY2lk8GVrCgxhJ04TZXs9bT0lgaGtaX2DCemtL6eSyaZn+DCU41N/OLTr66VlY860IhtMPdsBg4i1kIfmaHvfT+lim+3lpvDBz9d2UIzczJfdcOprysMzy1m3IvhvB25P7ORReaD/vsqTqwG0pPOHFfJfkWWAIyERnpB0gpCb1IEBxCekPPXijJvbpfLrYOR0vlrOhnKlr5mz57qhcZVp/U/UJiDxcVWaxGzmd9aaHef30V6vqyPQt37s1P/1Xuz6TWLJBV5GID/b0BMz1tiAD+AVrvMAgYkQGmFgpBNhHz2CbGalD2RcEWZdTKUZJTOly6Jh2FskWMG5y/QVRZgSPSVVzsGn9TG9mmRe2jrUQuJiT06eX4K2qH5+YqvatwqMYqj2kcz0bRloeSk/Y3tYpKqB8a9ED2OkV98Rq7TliS+IEbdWqfmkx8hCCac0Sc2lmXT7CdYKBJFdRHlpxf7UgsPwv1+UI4M2eWRpIwSDFVX2b14xYyCsbl8i1dmVb4RLoxLXeIiDHyJQQLJsnjXjL1j27J5V69wefMNWxla0Dcn+tGX/sp3tp+hNj0ZFXWRFO36v/PIx9bKqEyN6Oro1qAY7HOORBAjx3GSc/7yKAWNYYyI9yAYXlEp1S4s9C5xuyK8akLcVFmpP0qwBpPFDJyfJS6soPupiRNn7UepJdqUVmO9v7M8vvUzb8jtAME4q5qNuPCAQ8YOz9d0LRx00bJ84aTM+XJ6CrXddfHMuLu0p7LbY7xydL/mhgh/J2eTlUjP3XKsnVHTZuHG2FnMNFhyYFhmiq5HaRLPj3aAn/sIeUk4u5G3Tpyb/+7JkTYAE8WLScwljcIHr+o89aH5RSXlN7BkSwc0sanzzCnAKkIYBJJLKmZtNtEmHtGJSmn5OQEEovWC4zH+mbssHpz4b3VKWzk99f1Pvazbwz6U4c2beZ1nBSD7ss+zzh1x8fxAESaPHO/MLJz9p8vVzUx6Vyt3uLUkunpfB9Q1Xa0Hd1wkbnp0WdXATnvDVqUfyoKxCowsPSqJEp2wqJR8kw6C+/1PqF1tYqZY44AAAQgOKJiVYYRWgShFEgqLNrlRB1WnrMX3j0NTTltpfzhorfCB3ONExxZk9zxrlmGo80GVvHfYmqc0jPar144FVUORi/DmupcW1d5Adi+Ug+ooUTyht9m6DqfGndjB01KjGi6XiGvFamhuyvpRQsI8dRcxYr4wGLPcWbgunxgfJEme7Bi6rsmZfSpIAKHeEKeEOKUB6JCE4eQKRXGs/6icnRpK4vU6hbFey7ZZS4U1tNeelsGFsztjSW/7P20ps6zwLtL76rdYFEo8vMdqXCVmV30ZSV8/J5wp00oiOhkbY2pcrbdWtR3q3Y7yqJdApJAUKnip/pro2a4mqSGzYIACRLSbXIRBTgY2rCjsDjNbfxQ5TVhyZj0zjCWMqTUqNQenaDrR7DGvDhlyKJ+QoHWooLRwJhWIjvW6rOlQkCC+D6rGD3iSK8smpcQa82/scI1k1Ps5vkil3U7CyXqt24stanfG2ynD909YHUjxwUZWWQNZm3yg5OyA/DnmZroUlY6JWIrnYmeuodZGEQARzpTZE44JglijCG4F8HWTscpIplK8Gm3pbGn4g+JEk0VNplFzqm67TuWQ+U2IVbGc1/H8w32r/+7JkZgAEZF7TewxDsHErKn9hYoxQ4WdJ56UPQcwraXz0Cjkhqf+XTzPBOMXohhxUzs/REf0qy5lfIiSV5s162qpHhW0RcIFy71DMj3qHmihLnOk3iMLEW9siSNMkAgEj4P4F2BrDcK8DQGeLmjBYwXBlFsel5IAQECQ2gPlgSOz+jSW0hxlpz61VVDiZKi3nETHsy/g82M4kQQmBAe7EGGbiNaySlOozVy1qEj1HR203wM4LasqLjFDm8fVyiVDjTerviI8YzWVIyL2rx9amr8ObECE9UJDDQekosMxM3MyaeRNgAxFYPSSkx0YXkQYWEeBvEnXaQULQ4MpkksTzZfKm1fZrCQaDg5oemUkQHFrzCaHWvNtEaJNTIAgEnWK2l0JoXIshjbk24Hsbdb0d20N8sTzGVaGpaqu9EaxWfdsqaGruilbMmgo+q8r88uUTSbcAcAeQpWp5o9q2DhXuRuQuYYXtIhGkSl36gJ23RdGzqa5O74xvgKi2pFCVrrqh65Jj0N1Cjnr8u7QQ2Jz6LMsb2Gf1DpLqR47JVGtkNKiWdVHaIYoe7xayad9UlalqEm6gDgovtuS1UyxaUXIOdSa1YfQ1SN2eVX8jOOyIjHt0biqHnUaPJ2s0RO9NxyaJ/NPhBEXNVKKuiJQAcejaZZsIwESyqu3YCjjTexFPmkU1TFcPo1mLyjbl5Dd+FpN61qGHHr+9E832Q0dX6900FAeqGqhWM4kUxiopWUpiGRpXshd1+jX2ipHTlRV/wfOr/qXY3K+2jlRFcI8drRKYEGkcacoAEaU61lGRb5GeQtfUqErpVDFMDrQB9sKoPvEKGSn/+7JkkYAEoV7O2w9KImvrai9hgmoSeXs5jL0Jwbgr6T2ECihAVhK0mCfthijd8qHzNR3PGgyvXhhAyfIKKlSRWocKryfcHjBm41/IB5B4SCK24ekp48SRiVrmgeayizLsbdzsV2Pa2AGOEjyT0QacfDzPiaFcaNWCzU1VOE+j1RihGY+erqgvukCkoJBOOmzXkXtfqByqMWqZLdWonG5yqYHkQixClUyh8pacpXjy27DWXSjUefp5RQ1BARuWmpe6k8Xq3kgxQ5jQaGB61T+QfRFGw4+6Wod3VF8vMPphlVmFPdGd+dityI6K9itft66IVaGelaWMyt6WUpRgqGyAO3etBGh4d3Ro4iilAC5lzCQEIMS80qQEQOTRa0mkoYw1/pVCHHVzaa8spbvaeVGYus8kjrBGcRzDKNlediRMDA608zIL+oeTWgpG4wewkMfnrxhq2Dwo1YoJuZPCOsOG/F/KmP1T4L+b8PQfHVS3jEUfnH1ohXi5s4td8x28/uldKQ3SGIeApeUapwMYecfiSkWmWxXYk9aZALTVc1VQu8dcSECnSX6ES/koFWFB5dAKHviWkxOpgMzqEyQtAqSBJHbKDIoxYyJPZoID3ZaOhrGVRI7GuViqErbZ0rU2Ru3u+v3bqVv79X+ypo/2Q3vW3zGUUAJdjnk/YKU3ZCdQAA4E27isKhwEXdvBjKPy5nlUXUsRXS4ydpl7q0bBo0UnYTBHAlttihSGaKGBCq9puKiWuHRujWhZgwXC9Ky+XLdr2iOrJOuM5jwKZ2qtWgFPF3iC2xc+Vn+73zz8MwHAwJXILQ7mt8kPVpi7ic3T4dLURzf/+7JkuAAEclrQewxEsGhq6f9lIlwS1Wk1jLzRwZ+g5zWGCXjcz04ZnLxvhTZnfXkdlaRdX2PiJFsIKIzr0nOq+l6aPWlxIAAAJRiAaEoe6xBSbXC3kDRGdjgpINzhWCIQuF8eDW3yfLujPzq7yZO5S17yV4YJ6/Rbhfa3XkNKqIW36GO5xzZDNdT6eLK1Fe1syb1KHdL9BRUuMjVGXBQ8t2w5dcsIOQe1qhSkU0xAAAHym4oiDJmS7xdpsyCNXCt7iZpfkyQxIK8gyjlRRcCEzMzgFpWRAbN2kDx1thctdJgsCDJxEhZtI0+XUdqpCO5HnQnIu0XleZlFV/NcmQ7AbLsduZ+doX/wLo7TzXWRHH5aadaiz4GAFvbfmqo8YvAaZv0/U8rOX2/K55LcbV2q8jxN/IzOiw9kGh/ox9+Cda9k3RKmoUzrYSQTWOgIQ4A47/pn2G5K1KIqtWUzFWyHaByYHHRCZmxBM3llJUUgL+5tNAXDFEbvubf+/vQxrymaoREUQ+O7VO1WfQZ4N0zW2Xt116eV+/cmrLlP77uyCdhI+gJqNAlGFBI9KjTAZmYYJEyghKEHaCVThdxHBZiWJ1aRAs64gtZPEYl6HIHGQR6h0BTuEGPLFpZX0gkLbPnA3jkUHRgxtClFhoSJumHYsSF48Jtoho+lcS1DonpNzzJH1nzwXXMGLOcqHpuPkI9i9iT9ih2mOE4+E19sKxPNk5u78rCIwi1dFTFFBH9g4f/XWnv606nemMuLlR3LKEc8kdVTA6yV1a9pUvm+MYs5y+OUGCrFNV6zpHcgTAAAiVSAoiMDzgUZTZTBMhurxug2pfv/+7Jk5IEEvlpM4y9KQmQqag9gwnoWVYMwjL2Fwh0u5rGEoaB24KYEd6gUo1CZscRQYVjTDPMwt8XCTYu0TZRyIl3rBkUojnt1aNvYofmFh4tkITOsh4ZKD9O0RH/ojlxih+x7xhgVsgwRJtrT7ifQyX6PepLFz4u6eIIQxDCCYR7W0Qew4t0FEh3Fx7xp/AmqZ6/ogACADZIRTQtCCFQh5flHJtsfmK+hocfqp0wsx48oeEhM07eMvJlYZ0CZeRF79v8+vjC04exouq5Qv/Fk/LpbtfmX5ucV3KWPP84npkvtTfFndR+0y2qiw/W+kOVavSo38wGBhFSznZUlqqftZvL/T8C/1luy+UgnjhKj+q9Q2I4XrqlxSutRYndyxg+/RuZmevM9s4yMTVdjSOqiGt8aINGQtfVYYv+lw80MQ0zmDCdogmxpAga6GorVvMIrgz99jIis7NEfNa6HHWq+fz7I/AQrEf83m2O89SspWxw7MzutMwV3Fl2NTtRWdi/W3r4XzjqWgU3WLFh70p/vZyGYb2fo2Zv/mZWZX3nrpfmwgIrv1f1IX2tpaASGDc6HUf4UaVfiRSXOdQ18c1WUysXfL4mOKQ51Coa1AACdCtaqa2xRqAmBmSqjo1Lm5pkrQd76WQjawKixMfSEIlJGTIrd8JtZ5Vx65rhT9TG7ZVr5G85U/d6fJMBGHvomaxEddyuG3TWIqtc28Uest7tsYTVPCk7XyzTrHCf6OovXpRMXbJ9bkJEkv6Qmu4vrerS516qE8vxirTkEEDiGsKLNLIT08+eOQ0SbWxOnbZHaYT20//zswdXoGIipmVJPwAFWmSP/+7Jk8QAEyGbQyeZkUpvsuhxgzF5URYtFzCWPwhSuqTj2IVCEhQNYvIvQP4sAVqXF+B4EwXAQnJzhkWzxI7GuSNqxj8JTTQrocUMlrvfP+b7pL9glF+OI7JrKB4FUwk8OloKyKX/DlktRdNcOvZkdMMD64ixlTNj8RSl2pqkVHcFjh2pU24wfcxIi1Jx3uu1ioVqRdYSSryyjwnfMdNUWZWhYVShQAAAC6JQX3LIEiS/jtIJy4zyKsvMZcWegdkT/opAOBQYRB44jvIEa20IHoPh7Lty8uwz9mt86qeUiLPyYsboH5bj/Yu6YTfH6GDlpT8/y9w2rVZvSlMyLNG2+10nOziokfnXyEhIVJhif5crWX1azT/dc+5UNXucv8tbFz2QVhWIndQljl6R0c2Rg7VI2dfNrVmr/qjxVi9B1t1tTEJ5AiAEoYq9dQyGBMlHkGDDFVhfSmVMn3PTA+GycaAaH48HpSob2ipPeoWrzL2NfzaYcuQ+zQ71/f6G+SEoPJFpXEaQIKftEDQ4bVKn+5u11q+ajzq9GUda96xHpd8RW0xTF1xGn0RzWt+nmr8ZB6ige416rQcgS6FvsrBCdIZkQlFJDw4uRBCtUeGyAADEgQKNFZ4pQ7cVn3uYkWCd70S6al9SKvvW7VqwvFrbH+tMm9upfmilz5YVa3tAd5YnHcEZKubvLWaJ215HjUmZrSV+3No14LTyKofBnFpp5FdBuqDrLB2BM/MNRw+fawhIWWli5ALxcnCeEqFDiNJFMhepZlCchY0BRLSECVDSUGWsUbQbA1HxliCSqSfYGYFlqDlViHpnStIEAAwnWwXCLtNb/+7Jk6gEE917Q+wlj4H/rql9liGoUkX09zD0vwgmsaH2HmSAnIk+6oXBYDzdKk7iVHeFUpE4o04q1hSLR5qWlOSHEGOLZTzKhzCk8SDz/e9mr5KBjMJEjfn/1syNMv2VPbv8j723zG7rVf+V9NIbvLm3RNzvHxvi2NifzUNb3XZG+5Ej3j5+SO1p+8sJ+sg9oeLA310IgBkpmJkVAADyoFnpEz1kNTX68aLDvohonvIiktRkbbsafnKCbS74BjTdZAva3IJ1vW0BuN0OOSfACz+kzEbiQIvFVd6rzcL1NG9Br7iFlVbKoTDVuu7bfc9gLy6dZBCs/Bpa4VFH/qZ+MEZNrRTvGTVaQ8QX7BGgN2n+atL3dDld0hRL4tvxqsUtZvBYHGtmTGLVOq/WswsRlKhP9InxIEoalrAQmaYY3NpAAIEui0RoDAoFiKqqi7Wk56ylUXZrjg6dypUgpi154nBGy2yvL/zfiVW0qS9K9yVy2s9RvMRZBLEYEuvE4/J7/hcVNQ1U8H6SreRzkYV+lk7+1EUVVfLIAfVDy27VhL+NvlHwuUmL//w1ErZg3fdGX6JaXsmdzCmlOgi8jCBySBOACgaEIesQIgRYKlY0yBTZM8VB2htmb2C5bGWpYPRRjNHp0KD5a8738Zs5A2mmTpx9WnXFuckeXeaXF6OpBO4dcNTpcEp4/aq6OkncfPnB8uj0dWbXSL6RWUN0vZhfTPYSRrBo936ul1qsG0z8rHzXRhYaxqoRa+GeJC3CvW9lqM6kSCqxvEZv1Ky6coT6VheuM8H6ZVbnq116xfF354tdQp4u74f4c//1GaskQpqOAHEr/+7Jk7oEVIF3N8wl9YIKrKd5hJppVuX0ujbHxwf2pZrmWIZGL/S8eDDgFY4JUYGhmIyhsCKiVa6jEG5mpTNjgCQf0PjT2h32MFxkUell4jVK2nNJNLdK7VU2HxQjojDSHZ0q/arhU/KHtA2WKyBPT6qxV34y2u7qAhFQ5NPHsc/jhw9B80mTXNI0pa9wlalaEyb3XjeGm4tNsbnu91AA9JUQlRUOaYYFwQMA0pVEIyoD1a3Ea0lZQxOOuq816DqqegNiPJ+bcSG0RZ8squlspUfetEgo8auqt7V5ptWssm8SIuM67NOjLIU/V+mqO436lb1S5F+GO32wpHtt0bmSLdRfUVHC1E1EL60gMbKhDOQpUzA+G5yVjdDQ6MStVi/pDM0khQmKKpy8NS68q6nw9qIlRvrCj6LBl0ZMpbcf/SQYKbqorrdUUQBwdhfSsHAFRgJXEhUWk0pqq5ecef+vALY3O3JBh46jCQVRxv7rafI2ddITOKHL1qf+DXZ9OjephAdu9T2Y70U9sU61d4RaX69n05KJwtdDzCc8faB8p1qjM44vqRFmIiHVm2mPhaQmYkYBvKrwj41flZdnakJHCrBMAH4ieLzSANAOArtBSSANGKGWdMwT1YAl88MjkUiuQViz1kWWCXTAyPLRH2PhFLLhk3T5g5gN6qr4kdlq9iqSbaadtHjZR8g/WeDduzEiYbDkisyZFyYoOIcB9mAikLrAa5t9GISOQ2oQNVpGzcTiT7IztnERl+tMbhY6xaQOzu5rI5PI45yhp1yuNK/xDyaK9KCxLVyLwgVPxmgQSq3ev3SUTUFn/0fQCsytCmZbECBj/+7Bk7AEFRl5LQ09McHoKCYtoyH5VjXstjL0xwfUrpnmjIlgaKxx0YhqYBAjkn0sKWQfR52FrMAQRTqvDCy5PypBTr9xo0Q3PBk4IoEzOUHjUbCt4K6RdBs8sX7Gx2PUgVFprPSqcJk3+uh/436n9R0UNl6719W0HRVjQ6edX2USvVCl8SzaFfNx/cxbfmXtLXzTSYlZD/ZUGJVAACsAODIUECUjC0AzAiq0FKepjELBhk7HWxn+GGo3g8zdQqKpk4LuU0zMTlUz3Q08oDExISjIA+XqcjQnaBpDXRekZvSTVzQ2HwtvcqcmyESC+UTTChM7q/ZlYp2UlJBDh8I94TPVTrxl2Vii3q71CDivBfIrWFK8S2NKNQx4iInjvy8E5S0FM7rpTkvcmnZAyfxoOoqxRtb3l8JCFLZffy+A+bbGc9eQaLxwtLfBgr1cLhFXjQjtrnTZWW2ZcTgdAoA6LXprd8+qXoCvHuoEQIEGiFHUYUmNEF8l7hATmcoXUdeVvxSzK1JdWqR4e/UegoKW5/MPdfPcCrxlivrS3OP+aiCBT944S+6BCfEaVjDtO+vduuVui6lqDDpUz0MDacveylR3ROdPbmkYzZSKVUgxISuUEYkPgCe0ARapOVOQvW8xKlJh4HkdEUCiu6EpYampI7rpv2qfCgi7kvbUty6WNVdN1quKvbW6SxRxXjFNFrNIhuEjSR1h+5ufYS4Ncc6UDe+FDj1SKBnZm48fGsZzN6XMB7vEKk/eG+eG2x4/iajuTn4Zhqb5eR54pxOSWlYG+3SbIo3Pq0tc5iNeJoS/U5DyM0//ZyycpGSYlgifE+ouF5//7smTsgwZuX0nDeHgwa6tZnGUCjhZ1dysMPTXBma1oPYSWCQIx2seBoW1I51OmIIgcCbFf//TpBXk5dbU4W5GDRGx1oBDFIBka3LYY+W3eZg8GE7zKPLwWIxpE0TIKekx+3O4ofl1Oud1o2ltn3ic4Ys6ol2EXMzyeomGMiERqP1O7pZKGJehGpbt//p//WTSnlQgOc5yCJOx6HOz/qgAk6kEAIz0owDBIDFHRoSyEaFAWnvpCGJp9JEDmbgoTKjayCZ+iD5aPZPYu2fle95bXo/bP0nZinrWipYvq1yg4PGI36CWlFzIWo1W7hs+LZP8sbe5qDOZEQhES9GCKd6Fq9nhPNQses68hiad0njy+Q5zjuh76U54Z6SQiCN2WOzen2mI5K6Z8qHjir2ddzQoa7Y2xsdME0hf3OvgKyK3quO8fxmx4yZY0LNghj9sdMy2rIarYGxYZGtkguc1PiJAnprFIEwUP1GC5Pl39ZBijcBQEt4XhRrLwJjhUAEWXODgvOwFLRjbzP6+q01On3f+GHVJzViR64wZJPJULvMfE1KgXOPSgwza5XWDE1JmgoSJECACycbgmjadcfddv4SZIWtoBqX0/HU77Mbt0xc2BJlzfXfxW48G45E4rNvYGNyR45L1BEJ28Yi4Kg9DgcT2RVFY3n+Ss811VmePW5SGQdCUOeLEUiRVb1Ps68xx2V3R/2RCDrViwyG4WBPwjoV7Uhg7CtWCfnXZ4r0+l3rebh4P1fHZ9VxV5WbFMZ3ED7sEUN43rXYBIirCGSQsEgAgKCecQvgJYjYwWkVTQpCmT5DiQrJqq1XsWks+ZsLiZ2xRkLv/7skTqABZzZsxbDHtw2QzZm2Evihc5iT3nvTHKl6+ofYYmOSKd0rlc4+Pnxtab4iugXrHeUxrFr67U6mcttjIyG9Gbm6K2TR3JwqtqEmAvGa7S9PxkpHb0hBerFtqplV1FpJGMUQzNYUIMeSpIQeRj4lRNn8VSHaBtpoTOUgXJTAuQ4Roi8oEabZ8VxlcwBDiMs5EqSko6uRoBCFgudG8BluyOMEa4eRo/HNxrEj7xyiQ0VcwptHCkWy9UMigkan/QCFzHLGguamoxRh75P24liTwzBEnS1k6iPWz4P6QIy0+opdlE7jpbstcXc7A0d9azXc0ofiiYPV5u/sLRedeWlI5OjIzDy2LWTi/zVR6+1pqKanUUKelkPjSkagypTeCpmJV8ZJnjqKKMmuaBV1oVYooM6vWTaSlK+IUCOD9iz0UUc0QSLyIIjrfZn5KLKtau8VI6qRoFV2p3ZVzQAAAArXXUMNgRoa5XSR+edZ7aqKqoNym5yHG4PnXZQ9Ml7QyqV8m5uWvLSylTVtpmlzHjAwOZBl2dNqrtLu5clfVFTUAjCW18+THnqOi6POokGtkw5NDOUcQguLNH6txWXkpFOKl1Jq7WEvF1T7NFn3JL78Lj1fs9Fbimtfl6NdjD6nmLQ0qeCc9NlsMbF7/qcZPuvRHDxRq54q2BP3fUStETUOi1oEAAAFxim+T0gD8Jedpdh8iamgQZFmNBjFm+PR23scVskaIZKomgWfLRIDqI7X4hfmYuCBS8aDwN45x93OkgJVfxzAca2OVJrUsweVZKJBYyfEPe6NcTbVe1DLizx0jGvRRexhZ3Dc92vj4l9RSss//7smSOAQUvWk/7CWXCgIs6HzzIhBWleTfMvYqKAy6ofYSiIG9JUyUIzdQpPVUAKM8s6oTAHMQkQ4CjJegtRKguGAm0pVyJajlGaxqBRj+UzEWi2T41rJIj3ibN2hyPv84d6anb82IsG77EeVhb7avKquEcprAmAzB0B9s4PKT2fIamcMGa39KWXuMeycYOcKsK3uhIswQCSB3lbT1KrQBcufMxecnyDliYPJ1tjpdZ4ok/tYPFVFWVUPnJ27UvGZ9QUhCd5BulKicPLNokBZ8GWSbc1QwjKi3Cv7CHjb6YZJIiSAUp8GeoztZu2XqB4ApJnJc5LNvJVCvlbdmtWn3RpwHE3xz2m6sellXd9WIxNZC/PHfVLkpjXShCASH8VHNX0KlD+EmaFlmoj94kTN12lKqu+LlajJuGeuImtofeq9b4K65iORgjXvFTKHePj7EWuBxszHfYqcFZWmoMu22NwgAB/+F0Vrgo9G9Ll1kjVNkO0JRmTfrSKrCYZguaeeBgoSJkQgDE3oGGxniJ+Rcx+gErK9O3BkHT3lX2pTdSU1/E3lXeoTxevLLUp0JZmwGW6ueFloYtlp5EP2N1r0MMdsKyraJXj/zsMkaDdlchZVcPbjDa9ll0wQ7ajLWNl+OrrKkuxMPnPMsnS79U87sQiuyd+dR4Vi7NrWZ2qtd1pilmurB3i4a4hZqykAmUbe0ucSpdingJrJCVhe5gNyCHpIykjKZTnfJfTGH5TUtxvqOGtY0iQEkKOUQRFUxE7iZbFiZysIrmoniI1zjdxjLTfDHfmIxNj6gvv/0KdL5mP+3kx82g9y9ov8N2/yHMuAqxR//7smSLAwU8YMzjKWRQdEdaD2HoSFV9eyyNsfPBqB9nPPQKoah0VL9vxALlZRJk06zqCS2AqBMuVMOBosSpWNBfuCVOYPvUTTot1yJNPybLIxLTNn+eolQ11GzooVUQRxJX1O+zVnZr0dkkV7ediRGFhm/96RtbEVTupfEta7RAI3VSMLejaYyWSUo5jSu6xApnYFparGwg4TpHNis3BZY8TbMrZu9V8T3cMU6MitEOCzU8Hdv8yQZcRV1PEXbVqCwI6bbUqseFHj33SNnOoVUE5Den/0AjM0SiIuTKAAAcY12BGEkMSoOI2CSF1FdBdo5Q47hhi0oWXXbmM4qQX5rKeQs1yqmy0MjzNLPcV3UroLHgwPdyu3yU8pHKyt5WzzT2G7K3RSpM7AMCc8kHUicuJt/0Vo/7eKjEf9wkF67VCUDcCJhE4LCqeCtAXBy1672REQTMvyna+VC1mLJz0dJyXPSo2eOcZ+q2r1je7sysk9Xh/ttGZHSZyzudO/V0TUKdu3zcUjrEWFNBbHcbTapHsXvy8yPFKGXFjyKRQy1ZKZj87a3pCdxY5RfSzT1NoXC7WrrdWhLJSKjRxHzZFMUVSBbp6feXGR+oq1DHN6XrBkDyHUsU9pCQs3oXJXh5LuvQ0r9MmsXZPRvEEs1bv/VhzUSQq06Mqdwo5qaOFKVymQegEUI7j7TYmjKaKRUF6PnVDvZkZ6SsNNeA1xMsoZ7EJcBBjSCitPZ0OGZVGik/0SxnVHNvXvays6M/bOhmvQUheXolHWvShSv671JuWb13Ryl2DBRSSXQG63Z0KBP9UrEBpANALcFlFBxAUFh2URpkCP/7smSZgAWTYMojb2RwZstZzmXiLhNJcS1spNXBlJQm/ZeYeIzLk7IJkA0A7C5UTXGb6xO4Rqi122zpAKnZVFMmhcWlCSzuqTkuXZTMRGXan/NBd9OEGLskYZD4ONySVImdgHkGnFN3qlPRRJHnT11bqLwfeeEj2axC0zOxoogzKVurGB+ObMeK++IqSY6dYIZXvVcgfvg0Ezp3EbEmyYcviD/9JOjJEQ6Io2iQEc8RRyBQk5D2JqZEc3OcJdCNocmW4ySGkksyISjdwo5g9yCn/WlvUP3nmH7VIS7Ib90/H3WaFB+Mnd6Gf2UgKAGCbhDCT4OjGzjqCT4tqVBOjOI/RQ2hRCC89EzlCUSk8IvdCBqsQCEAIAtF+BAMDg8SlTdEHGdIOwIqstcsQ+zHENLg2opXJhR7fsLjuyRzNiRxi56db92pH38q6TxWr63MyOf2sUwuId7ywoleuHNxurTV1iSGdurwV5ypStP8P8U8CP85dM97vXu+wPqNVVQ40g2xvx4cSh+KSbXki+BNu+Zbe8+b7lpN6R3nzIoIP1ie2I7NWkrZreMxxcslOU/q//tBJt7lpd7ao0lBFC9Kk1hyZQsyvBNaA3lfJpbCoKiVzsMAGm1gbHnVDIUjSXgRGdZq73nI1UL2ua1iNXfc/18dNPH75eyueb1meu4UBMmb3LEs/0yonWjaW6k9vXDDcqhQUGkJUACIIiJDIyFCCwAAABA7U5MVAjxzwyEfCNcRAB2CMZGWGIPxgSmY8FGuAw8DrBs0eV4UHEvjgBIZhb9BA1hiM8rUAQrX8nOC7qCIZFQBc0usxFq7tF4F1qvUXB03Rf/7smS0gAU6XEqlaeAAZEWJ76ysACU9lyXZvAAD8DHlOzeAAJcom3J71lyyLtCdIF3XoXLeVR+kvp6UFembanFBSOIQQkXFWTBy3HY02qTcYg9W6GaRRBgjYoEgNqEudAT4mcDkKtgN+JdL70GX56kfpxFKa/b0lrytwWsLwac4j8Lbtu+yJYk+6y8Hlhqs98cf2pb0sVuEtifJ6KWKldLhZzkRVmEGwpuLzpnw48Smzsw0++DSX3gaM09ihucht3piCHLnmzyyRyvX617M3ln3AfiSLcahRvxcwm8wTUgc0UE38vHFA5D/8oGQiXDxMoABDKzNDqxiaA54ggAAeGTLfNOMCIBPUE2bGDIxmoCZmTIBjXiQ6pKR7MPBQCACIbBwmJIAhoEuRMLxvmnaFxrJaHMvc6jWxL6IjzTV6EKaMrlTCXLb5gJdOpMWs8JQ/LY3I4JbbxOucdOlfaPotTkYeedZcp+nkj90T7prv/HtvfFbMkm6eLyy5PTFXNyBqiv0xEuLcszpK1agn84Al2duks5X7EqmLNBAj8SWXw28DLOSC5njzVuvzeVuxhcqZ4VMsGgQfLL9FnFozA694cq0kst3+VM+X///+muSzC1RfrGUd/fPo5iZvO5aonU+8cB9PUj//d/KDDiT8upAMCAQCAQCAMBAQBgQBVA0EUWLRQEDnsRVyW4YvBs+lfPuC6mMsAzj1M5lJ5hA0AbByqAyVIrFLM5NZxiaItpiVU8WPDA2BghKyFnOtKFQPX+2VqptbUhkMhxHSu3sVqhMMOzFRtmHGd6ScVhscHrLCn2/g4pa9tQYb9XqlnViqOhvrfcK8P/7skRDAAXHWFhuYeACxWxLH8w8AFGheWH9hAAKQSzre7CQAG1XsOLXGbWkypXJkZK+7UdDM21p4GdXz64+Ke/+f8I+Rkh3gQ3rn3C/j73CO9grjerXsSBSYwhKZKpMQtloFCIJq1lQhoM0cIOSpELVQCUAcxc6RSdTD54uwmG+zNnA/wqxvk7PBHj/XAEIAdIWJ84lhVFYTIpykXS7YWGCr5GTsmQ1itFoKtHwUY3sznuJfuDeqE+rGNQq1qmrK3tcdn3T/llAQ5Pu5HCCxWjYlp/qlbx8any/dvWy7nDnj2vX5o9pr//53Hwrla8YY88JSq5iYo9qzT2tS9axKU9M7zf3xrXQl6h80N7ZWo+zBJFeworFjXkfHQ0HbADJ2UiEkAgBQWwCCwSiM2PJd6s6oJUtRcxeVwmYreoYwDYGwJhII4gMKg2CI5lIPFjbPKNDkULs8QhWj0ejRtOw81FpVNm1MiyWdbowWOQ9IeEe9Jict7GtoyxH7I1P6QlRNx8r6T3dy3FfVdOPHVLTVdWkU0RVU8DrcQJIFJPLbip5QgEkwtNUjwjjpEUBDMBAAABLgHQYiODqNxL5IeIJELX6c5oCndprDXHGjImTGgWNisRGw6KyXIyMniszLmyETJIdRCa9xlERkPUgaJNbi44+P4u00xOk9ijQNQZ2U11zb63GHer1R3KbKCUcpJAhn4a32HXSkI9O31NH7uUZ5DPPc/yGVsLh5+7nPa+1CHnvXbq8tc3LigIeypFlF0VBBRAHD3JIrJasIhrGV+XdU9LHhQxS8qKnsxVhKRkDQjAszCBL5UfeswTp09VHFmBGDhsIl//7skQcgBS3ZtfzCTPClqva7GEmelHlfV2MMM0CBK9sMPMOsN9bLAgAKJgiI84FjtZO+Rxfo90sswqHeL1d4Ba6TUqocrTahPEzsuEF9bPTk2zn3ZRlfOrfqc/dgqCzGQnFkDT2tOEJP7YRy/JIaF2amEbtbmHlKtTZr1l2V9+9cinNytiQRAAkf1fUgclPQBiSsGAKEv5AipkcHgXRC5SzHlwZeBaJJIMrM2fmquLnYKNrx1kjNBZMhQyWaWTgQIJjFpp0DI9UEZ0UWdh5h9ScSABhjYnqGoMiXlHrbmGsBk3jpnlvBWVSo8g86UfsMIoPcK12TzoJNLltK6k9935KSHhmkqqlAjoXZSjL7ZhUMrZ1RGfU1p6M/JW2TgAAhwZSo6iiKia8w1QUmK05odEx6v0IByLCwrD0DQSnvOyTS1Wz8r2dTvW6Op3yKDJ87DkFV9BeVYMcMVI828NO5ubjDdRKopIzKlEtbmKyzYcwMdR0fKePRYSS4o6JSKYzPFwiWSGDjrq6bGyzTNLpe+OX5Z5eu2PbNWlXMq8vH741dLCIiKLvpGa+32MvQAYEQHAYIDMOseoHMQ1RpUgYOZXDGJukE5FUrIiFU91HVL3T+COAqBXIxitQqQneuj3jFOUtFmWSdLcJ7syXpcf4q0spkfu866Nu3tt8NJdTjt7nAOJ0xM60uecNUFi5EWzPzEOdMsmuq+dumvkag3XMHYfbQcMdIGbZySZ1VmN4QxkAAwvlYJCC9PMECnwJgwSrcyEA1SZk8LbHIkiOgHGiyRgMSt5CyZmJ6Yi2FSAiOsdBvvZJGIxK/JEo+++KrRuLvLo4mv/7skQlAAR4Zddx6TOAjEu67mHmGlB9L1vMGHHKJCdreYYZ2R1ldPDL3ZQyvz80Ryk0m2OjW4yRzvaN4Ueaajj29XaJR2Qymbqto7v2bNSn/f7Od67sXmIoEpGo37bot7+o7W7v7fmslodoVEcRHQACCo26iOBgGB3D8RAOALs7FUK+TGGo08PUvuwoVLljAZynTCgtyRImnnXYQWcjPQ+GSLTTUZjFkSzq+2RSsldO2FHOnq75iZkwij9KrslhRrslk1hBeb5PrRMII9RI83sZpKmLKfc8O/Q372hTPrtMy8vDP529uzQmDaRzH1sSsKYv+zjcON2Q3VRHAABFlprwQxVeJcJ2ltKvcaibkLDZSw1XzxQHm7zoxsmfIwGW8oAThOmQx2Y6RqJSbdJjbIpHbq2d8NJuZxtmSg5IyqsExZkgF7Hu5SEy8oo0E5KMKFpYKJhy872xsEzh2U5UoddyUEzBa14PU00HBk3/ZvYAFKObliV+mv/40zuamqEWCACAADz2eF6wodaakF3qfgdrSyF7UtxXsw/8RVC09aSLmT9+DTwtMH61C3DJzCDwXHKuT7MRKWSvNyU0TVwtN1JytyOJ11BAKBFuTKOjkWiUSR0HoHCafUutnrGvLaG9UWjrvbbDpFs7YifjSl0/SNNrm5OIif5P0CSmk3stA9Re337VuDdWVlI4CSACwDGLeiMUqjQrfaEJAWMSVsqmaKsw6LQnOn6CU4wuHpdWl9BSIHKNKURCZmdcj00ySb231ilHoKLrK1B4ln2KtZV1BOIkJhZYpmAV1GMZG0ExlOdFctk5lDP3sfok/I/KEYyXv540Kf/7skQ4AAQGSdd7RhzSh4u63D0mclD5bV3ssMtKHCwrOYSZ2eW/j7si2jiXywdQ/+x1S//zNW12IsoA4DsusiroUygCrCMQUMEEJDVEI09ks0RAeoGkLh4tP2ihmygxLCKZgOgWoamyWre7TPKSogz4RNkzuX2tMuIgF6mfEbQpRSSCUOhKbLlkyC9VHQReMrI/7Nub0iU3kJ/7uY++1jr35s5e4xJ423iX/7tBWr9nbk+WrrqJE/lLFNf/JVEJlZDKEoAp0ExuLTEx73KDP4tpTikakzkAJHoQFccjs+OjFUxilO9jeHJs2aRxPOesITLHsjBskClKPg8hrDIyGfIrT1P4xnvVUX5+1mRaOW2+ab+ap6vpM9PDXiCPm5iUGOwRLaxUyxuvVb8+T91rr1POzxvb5x5UrVblJTBKM2sVT9cXupdSN1RSHRALDIuQWFgEymQkt118KReJlKRaskPzTX4jUaAVCGTceQl8jbkDI0ZkzUwl+QOOknRVnm/Uhol8GW49K3nexuFqzwx0FJDJpGWiHm2mO7bD1vbG2m6XaP+zqj/TtpDvqGXONjFXaObtJbJm56g2zs8d9zs+2ukGwE5rpszjrf8rO6zBJIBqADgSDmiAtmwdohoJAxISiLoZ7AkzEVB3K5kP9yHbeOFthHQsIK8qK2uYMnUUtOTSOuYGkMPYpEo57UqYtUpommFs94Sp8uzbQfV4XjpCAn6Fd2Ovn6iGQXDVNoVp31quiuRlKsMtn4iEZGRU8ydywxhhhIBhl2O5v9zz6Hcc1OFZTEySQCFAimYzxDRgAeCTBSD+CVo8swx8OBtok9kczvnxtv/7skRUAAQSWNXh5hxygqvK3z0jgk/xRVNnpNAJ9yhqsYMOMVLQ+Sppik5Q0J4/ARCSA0qhCIKCDCZoAGEUE4UVqSOtBBgTkhDGpE+zRVToqFASt0ElFUqq+J7Tit53fsbmb7S8rqZQzLJDOE5tTJCcjCglCkaU3hRhoyw3LXNtyUJxuMgAw+ZW4O0Pp4b4filJrIQYaCGtxeUOR6NVidkG0UWyKVHDAPiJ2P6vFIakSwPYlADNmQI2BaMnj0XckjlIqWVWuwgmmgg+TXzbPNKRb9M1J6zL2pidaLgv5UnToj5cThz7PpKp7/Duv5Kjc7f1zNJBaW55DHB8pj/1S/91uHOQhgAGGiwe1VWRGZM1rRKBoU4zZLhSqHZG40QkVSC4NsEgvlESWASikmTd6SJGkgpzphx2HYJOhKgl4GzyFu0jsLK1mnK9BCEiMDZj/AhnYqBV4lQhHu5SIoezuhIMSOse1dSYSvEB39js/qwYdVco5PYCH9MhPQ93/74qtFg4ZUEW0QAVDDxC3BVAl3gQCTLgYssi077TlzpWpxQ24pCBPAYh+RrSpW0ypbEiNcfvt0JDlvjfS4cccHwFIVkh09lQyvSBnKQT/UfHio3E67F0/ia+7P5eNO1n5bq+f47rx7fWdWfpZ4+7/ZDOTzHEKv0173zPD5/3/yEW3MbcnMtDfc3nWnWfbJ24JsxsyIKiRBLp6+rm65+TriwIBZKzLN6a8obI1C1T26j+cwgshZTqgifM9I5JEjp8JJzBp37zUWxj+UFP0S3ytntDx7HJqYmVLKXQ+QEPs1GV5golfqozr6Br5tEoUjtDNPtg2kKz0P/7smR6AARjYNX7TDNQdYta32DCjBJFZ01svSfBwSurPYMN2Lg1GadsGsTvv5E604ovhCQwAIANH0oAgErOMkgvBYW2Bij7M8R5hZf0y0vl03peaqefbkdtpwUh3dz94u3cegxQRrQlAZ8CwoKv+Av5sPMXJIa2kka+Gypro3omEichnoeI2LdiGeJiWPJYXmwaThY0liRPscYXfJTVtTlF1IoZ1Gos1BmdpLwldtbNL+5tx9RzLg6vOddNGeA71gSJo6uzRARFIiiIAAUNICqhuqF2D6vDb7vFmrv8mHck1TRRkLmz0SBnOxNDZQULKCkFgmAUCrEvtSKtAbThFx/gpfKvKZfEyFIXp5jw8uQNPnfbPtvnfJP5OczffoJeBD/pI0PsEeYYQIyyzrBh4TiMAb6aKrKpr2zQADh2F6HuBAEEJc8JmFYqyUl2GSdZ9HWsJfelUfqmZ8xPFxtvhKqDu9YGkSSTJm8rKmNr/yjsUNxmUW4kpoy2nZp3gJQmJQRw0WKS5swKEdsFmveKbcgqxvOmedHubdh6EEqKr11KYCacakSnigISIbcE3VzMKDCQ4leKU5uNroAAQNQIeDuJ6QIqS6kZC4VakGCJ6/ik8N4kb2geBfu5LaHdLxJZ12Kjj40+nKKTh0lv30pu0LN2UZtpMd31gJzzkWQdEtjyq32o6vOnc67OdJXpPUvbvS0s2AarqsjPW4WlHauzU3tts69yLdsOtBvj4+62yqH1znruDgyK2WZwNkEEqCxK5IiUIELCdo9YQQsTwoh6JGxnkNJxyo29i3Zjate+3z1+yrm2qeWAuXzD4QboOjhq6pMoT//7skSfAAQHXdVh5h2wfys6iz0mfBBFcVWnjNmKCK0qcYMWsIZQjuAmgQUdDErPfmSOaPCKFi4/OsrKKMSH45CchJVUI/OKnGaW8oREOR3MHek5upI9NcrOKGIJEwOq0uhSjJS7V0D9ddXzRrgQCWm5UBCTggxbrNzUDFnQSlY1SHJlwH8aVQS2CKGM2rsvfCLf9MSO4LoSSqPaRhFRRisp4eUz49Ld6Zk0gdnM+EEMLOMWUuMhi1W7I5Pn69oxnbJdqR6Jex5xYUdBqFYpjOaZ1me+feyXIR9HPnOtNFQMYgiJo8TG0DNV5qpjORZlNCSQABMQktN0nS7hEBDMEDaDXd1VFmbKI437SYnbq1o7B1mpZD2xEgkVCVlzY1y6DooPDqKgEDxDLmDNnUKgXBCjFsbwS9x6aoJ877EMTkFI6Rcz9NisVr5VT768UT5U6in7tcyyBTnSsxv4UFqLu8ATLoY0BrZyPwoCf22UM9ybKZk2gACYrUrSqqAiK2mYxFVDdSDCZpuSS7qPa/j4tjofgSIjYULWLcSCA4kvChncYkSRdUnGIrLopKzYih1VFqgsCPElMkoWtZ1oJ5v0JSpYUlbpLv0jY5pW6WZ6RVbdZm5y7HD/0Thz6N0iqSEHQ3gw4JPE9KB6ZFnOYe4t8ktJkASAATQDsyxprob4XLiOwYqOUQcYriyr0FZIMZ+nKW1GiiQSlSbIxVk492Qyln4gQNeUfqgyopBySU2URhZ3CmbFQwA0vgumMHaiZOTft6RHdDWHKOUrM84NoZQpOpDUlW0u//LeLKU6bBBAUgoOiYwGSYyBcw0SbsZx7XT380I6QP/7skTEAAQNXtT7BhyygUvKn2DDiE/pf0+nmHEJ+a1p8YSN8BwpFtoKGiovoWtNRoeYiE2VsCxKkUbV5W6JkANMgTbSIPrXLTwrWeTOuE1rVRRZRps9ZumpoF0ENJyRpNHWtuS1RARZJCRjzj4tiBI6kF2PKUurofC2bp3qRacIntu0aGj5iCktMmYvNZT18q1Yo+oWNA04euOUvoqAN6BEAAAQUA9DMAMwgeiQ6gwBHJM/q3F1sEeZ+MlwRBwVAGvaoAWa3PVop+KkZe1WRS7hEvkkRNVMtEEZTXMJgE25HDYCyuA0yuoeWbQiBh6yBGx0QFkOTiQamrGeohxH0xAj2rie6SpnMgzFMdGSW9Jc6a6TvFPMl5/dP7UGP/U+ln25zf4bf9JZ2S+a1Fb1SJula3eljrDp3z5o2bNAgAXAfJ3nahQ5h+tY4AsjhfhScfIM8BoH+XkoIJRLYTteaKki/Hdcp/my2/ko5s+7IohiWxUliVijTbYYkZ4VX2JtFWLurNmzkqyZsXFDk6GqMsjla8gnVIS4s7iC85Kkid0GOyzQyUSOqZ+dLviLuOa/p80VVBww/xzSoxyO3FTfvp5tFAcvZAMIE6UOhdUhDAMMFrjQprGayj0NPRe9ZpLumtB5Ij/QDhc19xkscwuKqqRwMX5u8z0FB1ikcjOtz1QX+Tr0Dthx2BLGr6qmCOsIrhXYsCpSDzfIU3FAmkqAMtrkSGNJxx955NOLPps2SSbyVQ6BfvUqpiE4HpHKnXEnV2XHH3vdow8dSLPH2zyfScmPFob4U+pRAAAMFQlgbD+u4sEX0doHxl4V+iIEBAqPqhb2cv/7smTrAwTdYFFjDEsyiMuqTD2IeFI9fUSMMQ/CK6uosZMiMH4jNv9MhSAGBlgxIUndnTcZboBSJOWoWfhFrYUkcKgaWnBHyEgEhplviqoqyRENi5rCfHoaPgwWFEHLnKpg0eaQbsc6Q5r7Kk1rUNZRwx6of3UTd2pbmZqV7mUlp1Pp8dFSY42KJkph70EUVUIHIgAAJCd9SEw+MEwFYPCg0SDR/fdNJ+1YlBJ6OO5F+v3WcSL6h4EBLVD0XSXRpKRFEJWEo2kqcfvpCuEiBVkSKYVRpLml8wHe9CQRkFhJUtzhmS3tSl42aZUoK941MlEMJXJHGWLm9LRv0jS0t7KFlq0Ju3XnlyWCoRz8QBo3LTXO/zj6Glj7QYs8WInaH1sptNF10NPolZ3M+bHNiPddq18Zt/zGpOQgAABQzPKm7jwS6zWFaagc1+WxdI9PZ+ktBIGP1nl3g/NZbXStORZJeLZhC7tISaaGokj8bQlZIVcciaEyDMljy0NsyohDMuaZqHkYjnZ6LNhSTvMvR9TtW5VW6Xr/M1mhqKud2UrjP6zNp5el4jnRtvn12as+N61TL0E/4VY7QLFJQA6t2oaAziHCVqjZuYPTirhISUJMbgV9YfY4+kzUVQfyRTc2+MMT83BkZnaCLX4ryRMVouSh1W1RwLyadwl4fZxMVgdslBoCqtk7AUjcaPCpdpDAwa9cyJmDYKjLRRpcxELqHcQk78UTFS6hCEEGyRCkgucWt6zbrTQs2WQonQEj32S5HoiWo4mfxK7h+3WXJee4vL+S0eVy+ovf7dnJfqdGfV/H4NSqxxEAwKhlBCQKgdIEwTUAaP/7sGTxgyUwXM/bDETyggraLGUmfFUdZzyMMTiJ6SCosPMOOfOYOkNAbJzDAK9zPxOsqvNkKktEESKSOIIrAJHa87lQ7FKpephuZUE5oKA3xuziYddp7ZhWlU9c0gjVqNet5ypVKwCcyc6VNArSMmffZBzkqHksCfqDuh3Do7/+SyiYXdwuJpfSv//5qsQAAIiozAIJaEQTH44gUNlpnvK8Shi1HlsvyodM4LtcZpuuOaikve2y1zTlpAMot2X7EYyH4dIbGTa8vIFsY2U0o0jFKXSHlxKhRYPbTlc7jgeZYVefqonOVRGnARY+y5d2n2Ry0YJYTuw8kZGaIoo+gLhhXdKAsEYiwfCO7h9nCBRSBEDYnZWRkbVCoM++hJukRz6QaPoqqLOJ0iNXaBnyX+Usxfm1/FT7sZw/6BYWrocoh2V9uKwJBQAGQWUjdAZXpdVLVarNHcYcg0m46ESG+WicPCSTlA4pcwnIYO4SRCU+udRSUuixZsEulGiSV1jwnl++jLKKdHpVaSVuptMaGnGKRK3dbFPpWtC2bl3BYVt1UG2gi17zjiAI9v1a1GuGU+BQv9sEUv/zaBLnhACD87DhVFSeV4pcCFkhy+7SS6gaHALE3+jCnd3Jhz1MThdx87DtcrRmh+5FHYymYi2Dt9/5x8LVRyWS6xfV+5/E4qs9RUD4KtmBLqwMg+0sGQIK9kFhJhUAwolFNtpNIQpsLBuBLBkgVt4RhcQoOKqF2ofojM+N8zpsCI2MttSmiHTXzn8keGPoOVHPERtj4tltH+uhcpU+GBDRO75tYgJPa4MbilXIadRIUkKBrvI2SBHeEsyi//uyZPKDBatezisvTVB2ZzosYYZiVSVzOoyk2wIKJefRgw54NuQpujS1hNdOKleaQ0k5EYTR8iADIuDtINeHqljbwiJHogYgccSMNnAcmYKtjXMDdEgWmkaTs+lEAkx6ZDEtRpE1wAQFwyYNZkGMWaTW7anF3a3d4DcWCEGQjliNdENFnGRfBGZdx4MMg44iB0PFYQH99URTlUMwGQAGLWy5RYLrNTAIZ1grIUAbbOOwpJlj8XIYmB71Aah08q4uiw26MmooEMxh3FBOSbgEGroujjWwjaEyNek0peB+Da8p+1zTpITSGi/r2OGM8WRJlOafcU6mUQvx8pbsyBX08zJdIkYthv9XVMjcJehtrNahBPTcswvk1NjaixI1+dPnspdyZQFFeWBhaE10C3kefnYDCicVmrJdJpFKoDqCIFhRBbwRAZS9pBEuOxCELx0MRzCETwu+8I9hQ+mS1RrW9WZBMDb8zyWbep9XNQWRTTE9lKwsIYNhytMkEjyySw/Gqkii/FbE00S/cXULcK9jqtWqpk7zEGxKUlo6RWscGVI13qrrhCbjBWe7yPgkYfSQDgULMEOBHyj4zxQZwcGFhi+awQXSIBxqJ19VM86fOBAQJBmlFWR/YfC2TAaoMDQEmlDQnF8WU6VTkdFvY0ZbtzknOYSXf+jMy40r3ID452JEbLjx2u48ufgeB0mxGAvXO8JC49jMKLYhoamcbJi7Vywv1ZfZpsV0U4YKeYKg5OSmc30pqcfAlJ2Ycr39dYgrp1G9zbL+MUtdMfF1nGm77Aykc1SY2fgVXmfd3YT2Dp11e39FBsaRBiRzAAJHtMVYIIOt//uyZO4ABPhgUXMMSzCMC+pMYYhMFD15QIzhgUoDLqk5hg2goBnto3vnLGcJAKLspTpGyF1aspT3bqysTao2mmHvYv1TcKFJ1ABdohQECNyEVUyzB4DKSv67QgGYJSBgj0EukNAccPQDoozjXJiK9AVBlwm4VEwzWfqJLCuWDATIgIzhY8x/yFHsjmwlzQxJajsFHXdKuKWSACVbjDoxHIv6j/tDkDurkRw5zVLxlxWTBL/gmRfWB7CTBJ0XhFHwHdUNYJcd1zLm3VGlXHVUFLle0phkFMfrieiOVo7H7RXHc7yhdVH36kO6NlMg0sditE+cCp5S03GumgXhtU5j29DE2fm5JH7pV3UpivdFi87g9kqnGtJ0e63SL4Gz5fKxPfGYIonoHlUFhwvJAWN41DRyUIXvWOrnU718lm4ZTEh6GYp059+WtQAIxLWcvsiVDzGokVRiMTwwwos1ugXIny8EB+dSJkWhwgRSc5TEbC7WioLMocHLAvTTY/etL1Vb4YN8vA/yrXOeOrhLe5nmPiVHtbsy+s+INVfTHTMt/d9Xcztxm3jr4iHmXI+eH9bzovQQFTE5l3f7ClBkLTkhjPKAEAgQt0SJgydb8Fjqg6zO5YjyX+VBG2RwSJJnFaiFvjYMFwQx8hhczVneI1X5qxKqB29bLZAaly+ZWqKiK5SZikm210OZyhtUGA0wFRxdoqHCPk41GlcHWvUE1zLGVciq0ZO8bk4xy6u2Z7Eyhmx66yVT/rsCKpZbavHA/V71RTRawz8sGS5dh3XvaZddUQsI8bdmyFGnRNsKHqyufdcV5Obe0uuXmsJ6HYp0okKSIzEL//uyZO6BBWleT8MPYlB7y7pMYSh2FcmBOww9jcHkrOi5gw5oCACMMacKJHDJog1q9AAdptaDrjTJU/itbu09PEXQft5cuz2zjc8yrSTR6VtjC2OK7TSSMRYH3ZWY8HMLU07C8+R+6giBHL52PmoMtciarl/cMZwMZFQdKWlIpKxl558rcMuhV8ts2Ztp7icgZjRrBo0r5OoAYQAAc5M6SLBiIhRnBQ8vupo0xQxWh16F4XQV1xglGuBnrcZcCSGLGN5SsmVcq1fJCmTyzQnpMS8OnjalYbUuzlSmENUYVsVcnOb7EkS4wo6xcTy4dNLhgEOPnIKwDwB88Q15aIyq5hYP+ViNkWHQTMY6PovW2oKIsbk1qo6J/gMoKirNWOaPVCqpVMjzoH1sTRlVf5gqz55fxlZIj+StvNXvVl0tVuYezVsumP1mtZahOvIl3RemqB5xGMqAAZr3B0lQhV4iMtIxEQpeuVqr/TP8+cxOu9J4U9bq2a8tgHupJix9cJd9DJmScCOoEQPLNQqzSQrK0eYgxfg5Bn4G10cvuVby8a+w8pdkqaLtT5D/5u/3mdogL9+n/Nf7Lxsmvm55sD/LLb9u1kPWku4WuHZMRTgpMvfzvhRAtxUABpU2eDDEhKoSDF0ZwMWlmWVJnRCB6ZnDIkrLbjw5rLkSKML2MndgmGm8ppely5Z6MRhyUgkAolkyw00qJFr7D/hdMnPcyT4kRDpTFntJKjJnxkj8U7uOHBGxgiNS1VIn+rJNdM7hwCE3rUkHQ5uvTyxAdsQKXDiRvl+uqlDPaJwAc6IU8r8DEijuqZg2K6lnMywSS5QfRdcYfRkq//uyZO2CBcReTUMPY3CCK2n8YMOuUf15PYwkc8G5rOk9gw4J/9NiBxUDGtuqMiEsiMLfRJtHUlcBzQxCrBgDJdv7CjsDgTMoBlGv5ajfHO+SdIs0hw0h5nc6shr5t32OllyHTt63aCqqYpVKkRTL5HI2PL4fmeRwy+89OSTBifPuuccWAAAAhyhA4kOH7UvQ5UILYg6iNTnpSuYNASyskIoy4s7GaN53k4us8BDFLBGFFpGIehV2I3UOUU64LsPlLqtCDTQTWbA9kBs5y2pR+uhaTrf1YUqhullBJKWEzlNGsilWWOaCMVUzSI08oMXaPv5s2f2VTpjgociZXK6rnZuwpdWz1UsSnB0FTSggClC6vDFCeYGkn5YuelA3ZOTT8nOMiB3kOiZow/1BOyzZyPMwoeAySh2eG3euOh2MkAAAQ89XAyYn4JmTQlKgRcNpjH0kGArUWeJwOJDxOsDQ/Fi04gpv0apdKZsNtmSKNMwxi8gNLqnxuig83cqd0U2uhLaIdyjdWAErQE4aWCo8mYGYlDtqFJuRLVU2gzfm14z5SPpyJIr+cxq74el4DDlwbU0IwyXPjiqY4YEXj0MCR+lHVQCGgADZmzQEQuOPyPMXVMuAWKUGDSh0alCwcFUrdVVW5GloP5ksCx5CGdmEAg6PZuy1Cay0oD6VRdxNFQiWM4iGQR2DyJkOuOTUkWG0covx+XhnonJ10uyWpa6FHMg08QV6iVw3iEmQhcE8iQDs0pDBFqb0gfhbENbX6WbXJqSaWV0Kgr6ka1hWuWYadLEy7b1bt8ywIijCWpPcGgOBg6OI6b0kgMl3PIJ/XC6fLWdZ//uyZPiCBcZdTMsvRPCH6Jm8YYZuGi2LLI09lYG4FeexhhlZirZu9UjS6+4W8865qs5vY2q69KZ0G9fsZydz+l9n91PvgCGcQCAg2VCtfmnfrO82dnzfcfpOMAorUhiSla/ViCbv0W9PC7mGKKNjJLaDJg8xeSm9YXjbe+tnUUAMpKrwmn0xFJ5e1pdMWFLPXjSvPdqgJR8q6TZuYza/e8x0tZ7hOodvWU5ANvlNlHs/f/3AUKAAAAAACmCnApOoeW2KplFlvCYKTL3FhpVJ5S9bGLsZZs4x8k9MZpkwfQxHB8ZbHp+yvXc8RRQYGlIzR3+GB21v157Rlqcu3zgooL91iaznVunhLSsVd4rMhcZfR8zzDjHjYuq3LUF/PrXjQa4xu2dyUrhWfctb79myN90vvGc79mb+v+83x9fG641T53n6z7/V64/+X09orNETsnu/kpHjwMU3WFff8+9FqnZYI0gAADiF6R6M4PMXVYo2iHAeW12qsphCYz3vpGS1yTVdyUo6vXSgI54zIXFiqdVMEJ490eNmCE/WoqfhZuttmbxmpt1AULBErVkltG1aHWOhDT7q5D63R7+zU1xXKHVnc93hze1Hzrt2IOq23Xb55el3tZsxnmfHpB9L332pi+pdf7rGt87vn4p5I2cfxP8X184tLmk1PI93P4ZwTjw0Wue87oAFAuAAAAAAAZLA6JMpELmWFBrAQZKviAOL2kQEzozVJOCRhkIQbAQbQmQCg0SkQKhiChQcZgyEwu0oQogjy56FKUJ0lmmW/sNq1obqBLPaa1tSZvmqLvoo2+axXIWc6q5mAMnZw4qMiBhgquDF//uyROAABXNjze1p4AKkK3m5rDwAIt2XLTm8gARnsyYzN5AA2KQGtp3H0flez9MpXFfL1oZsYUsGhWVqHMBZS61Slfp6UObC2XRSOw+tRFNlcUgFsk65MAyuCYo7cqnas07cDxWG4GrPRbV5BLtqD7hyimoIlsqjViUSG1Q3+3co/KKCpSSKHqavLIcoXakEVlNq3HYvapnoi8vx3F5y5O/l3DKdkDbOHL5x3aKik9vHGxyWxGmpJmq70vrWLuu3jdVK/8q59P/LPa8LqWAAAEWhgAAAAAAhyYWMgwQJSEUBj4Ck7tJISIWCjChUxIEMCRzMj0RAQwAmHDo4FjoyaGOg0Fg6J6kwdsMFmOIN2J8K1kz6mhoRBIwl+5MiacleyBpEEy4oxA6oOXS7m2krpTRcaWuoyBY7KjBPN0UzhiayD3baw7ccYBQPZLIm9Kp3QNVcLEs2MIZEteENS25Az6U+oi7Npe8urxVW9bKA9YAiPAAgQREXTlF6ficXosdRmfx3A9HA0QRMcxS9ob+NYeBkrU8JdKpBXp6K/V3Zg/uUfrY502NSdbM8cMfEL0rhW5HLIejUd5DUvi8O8fy9nl9t/4RFY3JKB5JTVt5XrNTVK1yQTMopJRY5T0WHL+D//41jcd/lJRWARyp0qEkBgEEkxGo6oRwJggoSByY4ZNvwqqFhEuUoERASYSZAoFsqa/LpgcQgxjK1mfAtwXwZy0m1TLluMJhELR8AyT5MzTMyuBUiNFzOZjsf5MIMzCySbwklBCXLbCYW6HJGjQJ3r/FdQLsipYmFxjx3ucxZLY8OSxutjM3O3TCmH8WNGlkpbVd///uyREWABhNiU+5t4ALJDHp9zLwAUuV5RZ20gAJYLyivtMAA/W4k01WVmYKOG9RGKL7/1vq+cazffgUz7+nVjnEeOD6FqlNfPviW8iv3E3SP9Z7hGb6YniRn36AI7dE83CASkk22lEvGYaS1D1pTLNLqqCjDBCagzcmLSRCwK6UwRoRbDOivVEaivLgLw/0ouj9Pdxc3qrOUR4g6RVy6Qp9h69Il+IWgWh6ntuLWiVS8YZ2JPJ9VqnelJNSsFsmRUa7WhlVeyPICklYXGSRY21w26qnhRI7y8CBaOxUzrPkj+eaFDi0wxRWx5NWsGNvUTcObFceHXW9S+d/NEeR6SQW+HuPCiLg+p9Qa0ez3w5uR+dsc1H52TOseqqc1qBHkk8eOS4E4fGiKUQUx+5MHFBUGRym0/BoHa2p7BAKr2nUtYa+U5JVIAIPjsWoryWZMpqslRSoitgmgaNkxKZFkLMUTakTt7skRDGXJ9OEW7Pl6vUNwWEYqubSS7eSQoJKJxj7uozxf5CfjVKfbdJ+I0NJZ/JlVqEVfD7U2agnras2IXNtmNJIzCNLY3vxvdRJnor0nGs3ZzVkGHPkwZH/mgSJ1d54l4IAlBEtm1FGZVNdklbiXpS7WqvJraxJKODY0IJEZUmLd4W6TlmWaN/Xvhqvu8c27110Vvfn59bk2fYbV9e2t59av1Wno7eu2ifJcWon2na0ntilv3uzH+tMFM2rNXWHulrMll2Fy0TNb0/star1IasXpW3XvO1XL6/M/lttHVSolZi2KbXjt0rnJPW6VAcEsJJx5OhkbQMcwmOEnQBSoWDGGPJ2I3yxljoO0lSDF//uyZBCBBSlezyOYYGB8yzo+bwgOU4F5O24xL8HYq2g5pI34gvgg2bl4lgADHySQDzqSi11hSq1mD3WCdTpMCuax1WrY7unKukaEzcmGjtm1iKPry+2nHHf59TGywfIEbSmsymFCvlq8pxQL1iuaDij7XkeYPxi79m782SW+xtuCY3n5gJBor/+Wy1zvO5BHCsHj/5rX4G2X8KW7VMsS9OZWcicjFA9KgCu8uiIAtAEYpBKalYmLDJkTgclAOyVljfAo8Sahm8ucxnboXhDkwgRhBSearxik8IT4+d0aTepQeYwxzsGplkA8DXa4RbeJGA7A7+Imz6jadvzdfjhl/G/7Kk3pzDe8N/fVpwt18J7l/VrcW9wq32Mc5RgeWI1gIvF9C/gBbbpAgcj2RicJRstvLizTJmHQ2j605vkuHzcpujNlDDW5PRiQfPHfNQaY+5Abn0FlRtSqJDV29wlxwMNuTipy1VC6baYJvYBj/1n38dEVhqYpZyhlTVWh0zKkU5UoQC9nMftdhq6oluS+b2QRhNhqowNazydI3GWfsMmf2FY6q1jmllH2tNrSITdqsYjNYDVWxOX2HUtJthE5MyIIVKhuJFJAAHrnhcKWdEAJrS6xUWhKcKYi0w4PY862Tf3EyM6mkrAg1aSBZUeSa9OZWV91WK7csjLIouqfSR+sgsWf8293yylvJCO4CKU9z/4FL5llGkMDTalYzL5KV1SLS4xHA3eOfSYomhwKvOeCFUOFWJJLAcLAABvNmZiMA7FjAADl9IssCSGMIJ6uQtdf2bRlmCy6k3iz9vpmPtIo1/4SWGSeiOIViUplYSBapL4F//uyZB4CBcVezCO4YXB3Brn+aYhqVmF5MW4w2UG+rKgxkw5QThYvCgQvTIQ9LXQnWHB5C6UYt8plXg5WTWAelS7DIsM0UD+opywgUfoRA9cbTwe0fLy1dMhZGyvOHcKZy7iW6zUgJnx/uKWazczUwlVcf6wpVRYPJ+u0+gv97IfJaJo5Sla0cCuP23Rpe845ClewO39A1XmYGXkpVzGq30gJMUwRqeqqEe48RP3BUi6aYzFTAB3dzecQkhkCmktw2guvobwic5cgBwWLyfvunbmftkU43Cq4VItkVOVqZRhw67QIoiZGKcgxmQk68ZacRJDDnWiIS6M7Jy3zibPpx/8mqDeTNyPTWt7A7V8q/hfkTwGT3ine0AoEGAAnS+8AmsBgaYDBIGEJgwCBwEBQpMUAJM6HVSqPv3NwK15NDC2vldjc3uiMJZ20ztmxD1qml0ch648Eam9Tj+q5QGUkqLgkciy48k4vreNRwbQhsuK6NUS2XOHMZG0umTD5SFjziEOY496UfE2/A72SSqXsboH3bZvaSQUY/1Ri8hGZY87finmltM1Y1j870prRcDI38t+3No61ZSyS+7Hd7VE4tLGO39wkOIfMUzNgsu+9aoVbzzCTHK3HHXyhHBQjBLqJWrOYStRk8LQ2dha0PRGVs/czCeoCSHPCDc0wK5Z2nL0Ds6ocuiroTFuN9O0mYq+/+WSUpOstLpZlfObdv99Fyo0DHOHnm+jw/q+Z1Ky5neM2QZhXcs7s1omFFQIACZ0z4OBJc8MEZgsHFn3QHBAYkCcE9IQEWwizoRynLPWY2yZD4DyeD0kAYZJYSdax6nBTksO6//uyZBwCBZ5aSyuPTHBZxdn8YQJ8FemLLy49EcFhEKe1gw2oO4r4Qp+/Q4hLclGgkS0lGFTHch+YRf5MXjhqYjYfyrRVj8Ux+4hLRfWmiIJfpaO5CFS9jsirrCb1iHPBZrLXQEM5mpCrbbcpOTYY1eUHMiXr4mmnV87ciEkj51bvFXIoJKUlc8StOdUtXxvP8R5ygrPRL0ugMQferC9MUBRKcRMKDWGoXmha3KXL/zfecwncYAiEfsVmMoocYc3IuCl5YtCpk4X8cijbTkwY6sKTDutbHJKJe61L0f1m2pGklDo02pdTChAWJNESq8XW8aYrXXovQpzY0AIQACNgSIw2GDAQPRmBwTIgnLAuFhoSQ01Np0JU/UibRHJhc+zlyhKuD4sYcjpyPYgqkcVIN8p0A3HKW1HL8c6SWsiiFpY2XRuqtCo65eoPC7keLS4iOkIcVE2RK9vTVsQy2vXJ4NYv3oyLimGXbZ4EZx3TAGE7gaIUdEg2mTcvxzyUPC5CEkj6sPDh+WX6Fqax8Lyk7zFxUYzOXzxtZ9XYjnS8yKzFLWNtf/zJ66hNDIaQACAS4WaRPDSmZAiItptl0wDK7cQgJrlgJciQBdCEF06wj8rO04zx9zNGeFz0CJq2VGO2B3CFy8MrHrJNnRdwpWI7GIPlcLX1W+Qu1oorwKKk2n+SCAVAAACP1TyEVCoKTAIhBCIOcQRBxcGDZeo+nMuaIQzMrDCaKZYZzpcJTkej/U74WNCFQpTsOpD+dxlObGZqPZHuDmQ1/Ye6XzCVB0qmPBelic5ELSqlisDm13mUrG2SJxWKuZ82PNQ5ENj6bob32bpP//uyZDkABWpcTE1t4ABiyJn9p6AAHomVN7m3gApXH6h/MvAA+wPM5vE1md7Ty5eeHW/hyKS9Kxsa19/v1f/vGfnOPm9f5cV95v5NY3uznbP+/iZwn3BUG6eTZMJBpObDtDkbDABTigugAdG6H2X8B8DOORHZjOR6JiZwof4aNMFQ7csFRT9jSVWhPeh9/0uXXGtXdT9R8993fxPKRfjI60jGJXmV40ifiH+6b4/uJIi5iL4kq9xtxqRbev29Cje0u6ogS3+JxpFtowFJJONSw6c6Jg044uARKN/IKLDGzAmWjJR0ysAFScRgwOTAuTGSpJgQOYQMFtzAAaxoDNAOG4dAAnYVWTsLBDiujnOkiHkzEAP8XpCAX47GEB0BUEsIYTssTA+G8zk2V0YdY+1Y4jZMUyiRE+OJqVDjnaWdF4ZpIrY1nKR6cheCxIaYyeVkyWZGiI3xaMZy9tlmpKrGFv7EwszgwOCf23JVXmOe6XiRS5GClny7grNrzsqAiucdjcHGPqSOtxlG/Z5Z3kOPKhbnDUj521WniV1jRrsCFIg/HhnIUr4mM3pRlg2NBvbjtZIVfEhQQAFaIcXRVVEM65Y2ok4lI41dWZYYbLlgIfZMnkIY2ArlYQTBsQr0wjClTjUhQvnr1REw6jvVBH+6Zj4k1pO7arQmF+hba+boeZZFe9RDHV1lkW30a+GB823dw7Q771nUWNWutU9aZet7/dI0TWN4/9vvGNZ+f4mNx4E0jBMIibTa0RyMEBgIhhSBMscjiMHGkV6VjwXviX18Xr1ji6VIjDIYDQB5W+IjwOJnS2Yy7jDJIRIeaMxO1dk0vEAP//uyRBOABL1g1O5hYACWjFrfzCQAU3F9W/2GAAoyr2q7sIAARuqqbiO9o9nSYdUOw7Xe58n2njkGQ2iUtQlih9ftOaQYchrnoV8LmjKQtzKhklEpwkdqmNtAmUyOO2MZwnDkIPn2rsbDzVMrYzhlM/6hmznZN0yLbDn3J/l98v//+jt8EyKiu/z+gcEYbBA8/////0II0aQyXCOhsaWusdCgQjEDTYGcty1PrqZCpQ/d1g024bYYGpZyPhciBNVUmLwbiw6ladNR+TnqFeTBxdthc52XzhmpsxUJMq9geZ3Nwnr2RtN3EjUjlz2mEEoen5BJGhUSbJH+Ff+F2n/+0xHDGVPyZq3d2ynUNhVVmznPZRhKkZI+7SjNHPJ5P/z2md3PD/9zzspTfQI7RU3Toi6RVhKGIjPUErgo+r1ZyxlzHYjjXYLdOanYFlsw67W32W0ZdxFC0qq/s9MdsWXpn9uVnum+9sf5+NBMF5NMaLUyyi0zFJgIKQdGeWLnLTfjO1D2Z7qZs2nsv/UnMybdp55nRtxyYaOJoq0WfTlto1H3X2p8sflm2vpU8fftS+Lntu3Q4Mzhr4h9vlHq2uhV10rYrX/K69I9MsxBoV4IAFlLuTnFRGMiCKBWeudCaJw3Tl9K/cUlovAlRVGnrfBURZyW90aOthMhRDKjmpcM1cv6oYSbrLMksSWYUCsHHkWgVPulCy0IvEIKOVBRFO5UPRCTnDWEag/NgSJcOYUfAgGD3QVmhaXGUKWRLsxUKkCw4RxlrnXDi8WHpEeJrltURjXuWtWYzIqrl2lpIASNMMvyskBQFCQeSjik6lA3zHGApHrV//uyZA+ABFla1nspQ/BxS/rPYQWMEb19Vewwz8HALur89ApogS3BKgoBkYXNiU+qKYsUoLMZFSMriQ7GKIX1LDF2xiv8ry0n5XVXs1ebUc391QUV/YY12XfpH2IZ2VzU0S/j3+GuRhPx/JrXFmXxxUuLztBMkuK0xIxxjCS8XOGGZ81AhBUyRlFWWWkOqRMVw1RNbro0eJAAVEwfJ7kyw4qwMIV69rdHnQCMvZQt9UT/XLstvRHzCM/U9R/PWSKueeOOJHqX83azYi3jiwg++/jmRI36EdHc3oh2aXoXjX6mZH6UeQjyGeeRJ3eVVahNkH1LzH2K4u4KHDHR8pEoN1UutdOXMwtkSJAQpp1IML8hiRJbL0OSlMRdkgAYgLDPZKo40sCyVDEg4LTY3pHKwuxd76Laa9tbYi8pLWpmTP5ru9PsxfKqzYki7pyOt9gPcvpHfwPfdTuc3MYsFbHye9JV2IhPyYd5R1prfNL3749bOSpc/aztPyYbWKXXlJsb+oOAc6iNI07s12gV0JmaUSLepyYWSNAgJIMVsl+ExB8qAllFAYZutqNLEjUynx6VKjWyLBWBaiuHlOxy98qpTKfjhe9vTavPh4DpwUmRVNxaXQqbu+b3f0HKbO1DHwyHuz0Oz7rqtXtWzUtRS1BP01QKysuHCO8Cd1dGggZLOhVWaImIaEliRABM/WIEonKUBEjNSQ8SCVsWc04kI0h7KN0FpkrjAeBNWDiclU+igK+9yA/9niaiwpEIIucAjF0sgvtr71Il8lq3BB0a5CacxIzlla7b39CVyd/+fCPuZ+N/yl5RWQ1h161Z+7PrlIovOK7k//uyZDmABGdc03sMM8B0axqvYQOaUel5RewxC4HOLOi89A6hIhzZ++XxmO36VuP/6xEjhnN9kiOPOJIJyNLVmzeZFJfrGQU7bTYAXQ+ikBIw6UMDCcn7JAN0dV92WvRm/tDg4Msm5gZNXxCxscPk4acgKZKPxpTsWs9mleaNVEMAAmwgxYeat8dKQPKts6ofz4Sfb/+CFfzT4fM+U17S9J7HeM3dPJJaX1UOKNeBjrX7j0UJIdoUzrRJADDiPmsIJKvLMp1HE4IttRcMgzDMkA4RjPgPiQ/0CZk7qykLVUyZNE2rTXxj+uxkLMUdwwpyNZsfAtAl0bMOeGFTaGCpuwTpW40VtCCNcbdiuX3t8IJ9ZHUoMKLd2V7M+Po3GmxdTRuIR/unzDtNDipgifID4cwjiK1mWUbYhmPSCMQkSxDicXR3qIVUiZIAAM0k65J2NEUpMAnQLJhHCLsGWmFpQotnspVPtjlcFHBUtJ2yYk2x9xzvlU0mOqh6cV8Q3LrTOOCKuxka52tKUZm/+Gue+S9yad/io5KRBQQGMmZPwnTTbXGalV85nz7fMSN+3zDHGElJR1kERttkcCA1m4zYOGQwRRZuSEF3Xle5kCAFndHGofaHD910X1LDrdlY+MrjNdWVRm5yGVm4HI63+8LFTgG7tcdWZN3WZnHXDvkU6hQZkD8OFwZNdLzceOnvTh/01SCTJ1a5LRnsKMY45CRQWwS4KnHsMEL2UW8H6jBx0MPpXNmuW79yqflp32w1uhY6y0ukyPz9Sh4O7Z+eB3tmuZd9I2yDZJ3TESsohwCbKjdrE1N00sOmiR6kFIzR4UVEsm4e//uyZF8ABLhezlssNHBpC2qPPEOvEd2NPYwwscGXHug48xYgRlglMxyPYSuHWcvS1dmVmsVsxKXsmZXZnqKQzqxMzmkftnc9mKg9nfL1sy+zeqfLf345n0vnDjwSrEGVqJnHv57vDVcucMzgELlf9ENKx0mXtXEDFPLGnFDkbpCuZ9EvUHYaqw/D5ki5AUnNUNGm7k7a2UqnfXu1VMp0KuKn3/1eJ3Wlr8W9C4SQ+HHW31tdTkwnX0ZVnXkmzuIM9F80tGILdB93VkYtR4s0u4mACY0M0Z1M3Z3rbfGuLYmccPnDwZBjJKNEnQURIwqu7NnGkioEqolKplewhGyrGpCAkJTGoJAgIT9tKomIQ6K4F0ReXi7JpcGEH/wnrSvfWa9wQ7ScqLHxtT0pR2Vw06qtnVA46F9T7s07eQz5aHRcisw8dYo3sF5iPSafx1KnFxasKBYqcH63v1oEUxtAgoAQG+gmZCRIaUtaHyqwmTUTpRh8l3NU7D9Q3oQwRC2cTIhJzoBV2NJkfmQmqtVgklN2s8qdc0yHmnW2Torac+SI3W2prudANNorCe2djloI/ZNO2vBPSyBp3ZbU/V/wjzTiAUC1P8pxdhugXCH+zKb0Vz6U8qELlk75ddmsKk+1cU9wy9zio0Z+Uw3aTQ7Qrkfy3iCVyWGMzMFgBSHEht1DDkI3LvKPKaw/BCs6lbJnMxrysi02MgwwkhCxFs2WvW7/63pzb87nkpJx+Y7fc9p72khSghuW7K6zWIAcQmlG/fMpXsfmTnowZqI9CgyY33UjGRnTm07LqvmxTvYUlIiZdAAMi4WIOZIikCJS9DiEIiJD//uwZIwABMZeTmMPSiJra0nuYSJ+E1FxOoyxLcGRkej9hg3oxo/sDnG0aSvJYFwYOtL1MZICgAg7y0DQSERfEsRxEWiPATCQiU3+jYfmbyw0jvSh52jmZtwqonLO0h6iBnYKI0EVELGyHF9o2TpvaRz81EKLpKXlrTjfOz8O3s3oT1l8z8JstcqT7crQ+im7a3j53XqKvxdqUCsWLyiDelHPIdZ365xRrETBG7mbwanEySAE7gEIdnIGXhQ7F2UTzK1TuuvB7lV17q2LxEQ87CaTCw6sBuf4wcHlWzsJDzfSCQ7fvcvc7J+KMOwM4lN3QQVNxLg4GqgQApiQYsH1g+o435g3FP931/XdeTz96jBAoSg8AAH/JrCikY6J5y53HAU9BkDRhd8JlWmbRy/NDE3GRK7ZvRmbdQdQ21dnIFc9RAd4bBzubGrTIpKhwalFR5vD13rz1hM2TniVDiqIood0KrR+iB4WfFtkFdWsytUh9XeNAep20roLbIOnRNb52nIvZauQiIuQOCh3cfW9b025a1cgAGANGG0Ar65EmghM9TH4ZhLBpzT8Eqdw3Nkj4UsYgrpuiK+FAZlcvPmsSYlplNhKgvwmUGTI6jlxUqU4p+WAeNtwnuty6Yo2pAAXaOHGydXY3LU1yoY7hsti3WyT/voMWWh0oh8hOcI9Evp2ZdnloXwnQqVA3KLlAwI8QA6pLuiKPQguAYsU0aimAaFsOMaV8qeR6T1T5jtymdIo7ASDkyBy/ZUQSIAv5gexA02jqDklnVX4aOBlfCmYcWNrHfsWZiADRfZK5Qd0Z/iGvrHoKf5XAyLGlgrOkcRWgoL/+7JksYAEDVpR4w8rcIBKmjlp424RjXlNzWEBgd6wKn2BIngaUgnTUQJrMSJLMqkIhyYqRpYjtuMHm3amsJQuTYggIUpBLVITsaCWJbHDxlnR3dVRJkIlVS8H1MSyz82o4rVPdtO1BMmlUuissr0OPblupZ3KIQdS9XeZkdyiYKrKjL6uZNHE/0JOk9w7TvgkMtC9Ue26v1ZiZ9U8T8JyPfm/lWM5dk5ae6H1yIxiS9aqdwwSgmpgkQVtB10MLYdjh9KP3QhTBaiJmIZk4EgQgewUHl6UeBJA0h1YRUhFqtJ0t2Zy5V0BSlukZpGXP0K7OAmBVTIg3nm5D+kS/qphWli5L/qCHmY9zK9j8Q4Xko65oRTXFgGt8QqMKCNvM3jRAM3pq3Lfxj+rWMFBx9DFioEQk2MbXJkqowdUrvxU72msmTUx85VMUFHuRVasbTZIe0tzysXrGJq826dXI0SQyGFtjRDYIkSjYkgCU9RfksJ6e6pHEL9FH8nifltaHOmXkWEnqayuj0fJU1UWUfqx0OgJiIWDOj2qt1AcPPZ6q92Y31NSrLZeU/aqL9HV71M+zavlLzPsVt21tMdKC4ciQrrO5x7p9/GowAAAfvcnEAgayEzlMHBQ6L8zlycsEoAXLuxZmISHIlASBFYhKkPGaFpjuSYibOn2vsqKmnEN4Nuer5mYJlnK3la74dET5hpsyhL9iSVf9Lqs0kIibehlvSRHtV1N1Icl7Oi09tipExRvvRXloou1EhTt9ovgmHUOqwvrpzgouk1FUXb4faTy+1GSQZliphFnu47qPLXg0fQDrL4cuqSMAAAG1QBgi4ZbtIn/+7Jk1gAEgF7TeylEQG0LOp9l5SxTpXtDrTEvwhEuqL2WGVCmfdRtC2SOcxe94ycVUg1AJHFKFLA0kQ1oRs0sxFKjChSZieC0+m+u+T3zO89ucDjLZvmtl14zf878UplTG/65aCL5Jb5SX3BVIVRzJVidZMrZzl9oeO8EVPG7sZXdY3fMzjnpK6y55iNJaUvtXzsfFK2qDNVtIMAgAbghaw6hyND8rxf8GARDVm9ArIvVSEOxhy2Gq9Mg4idyAXqaunqsEhMgP9ISZMo8RwWRMxgNERSST8q0jhvUY60dA2KQO2NvfTQNIoLCrYYgFcL0gRPLLV9WJkbTyZNmi4Vjzpa2xCm6oBQNKciPS8txixooGl8e/lRXa3ETTWsvLoTswtuUgJ4FyFCZUmFBU0FASNOIxtE/02pKSRzI3pR3PhATydK6mtrTIAJxxpwM1dIRCrICCVeOp7WFLqO39d4oyVGYXlGVudnes2MvQlaleYuLGblRgsdMbsalxyfmrO2gutl6zxiBSNrm3pvZ+i3ggKGDE0xBYSiB806J/l/kPCA6Z0lTpdXGpENDq5IRbOnDUqD+q63PWNTNmNAYgUzlSxRpb+QDdtjqUgACdLuCSchMX+ODaQyBMEiDpF6pI55ekiBlux5rbKFuOjHWwN5VqwW1GX4x6PG6eSrE0cXMWUQhK5kc4TuKGGocdcw5C3LkCYMFldoVIr9D4pgVJ8ug3Gp6WCWQ1eovRfYIzrr6X9jZpqlme8EUp3ND9ufRl1FWN17oYLWhJq6OApuTM/u0999JWr9EpxPNMJ3oDtqGJ1aYvTJ/XpUxcqswvD4Ia0hRCHH/+7Jk7gAFTV5OY4xLooSrmh9lg34U9X03jaWVgfWup/2WISCySAEBzHaIjSJVvW8e1mAgDDJC700cXgOGsZkEGQ6ll9h0JTIoRmNc52gYHbWNYmUIXoo8cVHfe19480VPnmbixzbDZRV64QQpjiqe5ax08Mt1zUXV1bD2Nv1erklY5nqGpde+7+JX1qJmH/bV2DpZGE1MxeppymoERB9EGadJeAlAC9zwolI1I9INTEpeN9UNo+nNPsFkkVd1RSB7GDDB6RTp7a6ZovPUOxnFNS1+IbY/WrQ6ESVsDHScDjfbmBrBb9vByRdvHbNSCGRHm+KGoTlMurQ5j/Eo0mtnDsq/lUm5ZIPHVcWxdEmfq7DWxR9ZgZSvVEG/hYzey5YJ2pll1uSFNZsfVjNVl6Xx62i43NfbxCIucscWJmFGiIO8I9Iyc27ZoAADijQuCaAje0hQGUDoRUbloXPQsZdr5NOXEigTrvBwnRJj4wS7aEnRIVHw4uJJxJMKfI+dQKVVVD2lKMam6hMajl5m7f32laRsSggPwJMsvFLasl7mtMkChgobDIhqPTEgDBpgyUQ5RKoWOKFHljZUtLAYGAWcv6gMIJVQSDAACNUtBIjHhQHDQKAUNkXUhWDp3qMp0JBrEIgeovGBIpJp1YJWrtNKg2XfATRKRwODmqpAePcmaWcysWMzrpzSs90tHtpcW2sCkx/l63lMI90RGAJiCY00/4QNUoNN/FyC6GlV3+Rc/KCRHD0jrniZrEaVZgoZd5pb+ipuap60moS8qvlo/pM7LkKaBmtbJlRUI5WwTEjNpZv2LcvPP4MspcTDDmjhNSHJmaL/+7Jk64AVP1xMI2x88H3o+axpI34VEYszzbEzQd6r5rGWIagRmBIAHIjPEOkoYI20NskfZ9lx4PUZfJQoF/XOU1L2XvfG0h/ZcfovJbiDEcPRAhBri4rccy5JbjjV4j6ltRn8jX+x4fW5S/i7Xw1ad/I1oYdsSK11fSmED6GVPHG2fcVdfNxcd2n/M1GNnOZwzzEQtt4gHKpYGMTJQcOJi+wQXL0TpHiMt48yMik0zFClVGfqkP9kdKoxo7fCSThtuQ9pvvbW/gKaPuiuQnMZtVm97a0K+dw2/tbDFWMeDDkamS0b1vbwz4fsqlHT6wZGV/erUm5m5Tz5ww1crMcXW6PnJq1/CpqeB4KLk1WA5Zmo9xEgYWZKebO9MMHfh0ibzefd9WpAixIfXcB/vcRx1K9S8LLa5xvnV/7zI7u7rAldJZQM5WAQUkBzYvgzQiAGPFl34JUtb9NwYDsMZvD9qCpXcjWF7UkF4AdgNBQPTCpRiwLvJQ0iT2MQYUDU2km64GV4sMGGHrcnE8sHQvwOf6v5n/n4SvQb9038cK/jRl9tVajH2v9u5s+I6TiKqqivLjxvPZ2JiSmuyoA5UApFxCGgAAAABxcbCoHNgHQECU80RQuHjDxQMJCQaBQGExlgXGXh0TIEwKCCYACgGMJg9H4AxCIpMZIAHDLAh4JmhlqjbCMkRuhorgb8xiIYjS9oJp01S9SJaoSZxd6+mtJ8MkXe0Z9pQIAXVVw56xEz1ttaRRbgn5nNtHg2CEXnslLwloGCEgE8mHtv1UWxwe3SWX3LUyeN52Xs5hagSSFK98FwxnI467zKaRrD2v08rq0nN2v/+7Jk8AAFZl5MJW3gAHtqyb6tIAAlAZ0pmcyAA6qw5fs3sAAm6oTZ1TKu6sENjht/l8TMbeZZCeEBX4pRSF/5TOJ0NgWbF26wc6drOafJWOXS2igmlbennYm9b6tMjVC5DXJHTymz23zjT4be2vcaC68vjVqk7Yw3FYfZJK5ZCaCtD8/3H8uX9IiymH//Y1rf43tIgAUrUzOATaoh90IgAaCAXEYYZ+EFoy6kBGmpJ0AgZIPAAFMtLghmMLHQcRlqICBQk7hgYK9F+v8qBRm4sJNsgwdYFAuQCSmyoHigFvkj32hxrK8omwx/28WFW6+76QI2CQOJJYyyJiq/5iGXduyhb1LQxaDIeVrryXGGIegaamZa1+N0kC50/H0uy19rlp9JbKLVPOT0v3Wt6/CCL07qxSVr+5+W87v+6qSHHdBWsYcorvce2KWavY/X5jfxvRbLV+pU+7qp2lciDZDI6bGcv44Yd+rVwpLFHKL96tn/f+azq5Yz4iJ/////oQBQiSgEAAAAAFGKjdgpNbjs2G7DGQiP75cwaRTIL3NjOMIHhiUVGJAcJKYGgkxuATAQjQhEADDgqGggafDH4KEQApWaSEGYgdrHliCdCxP5ZJIDKDppgIsPQ3CCZhi5oYBoUoiImHEFUoZkQXXAScyAgSOJ9jWFYM1rkOao0FqRGIZMkCsUxotBlNYBCEzmuL4C4YtOmuWRcuBWkOm8raNxWmm61NuBETLUIUI4Rxe6ljySxMhpqXrNXgj1JaUsU8pu1+bZY3B1WVv8xCma47rJrEXpoafmAc4Kp5yh24sn+FRCWyaX1p+URZxHxd2Zo4blEFv/+7JkegAJjGRN5nNAAG5sek3HnABS8YFHnbSAAcOvqPOYgADxceSJTcmoZu9LZmKYPlAj809mQvjAmc/S0+VrjvV+UNFHo9dyq1c5f3UQl9HelDW5izTUddDUf/3uV/84kANKgAIBAAAgEBNpyW5GwkitFMysb5SzNVI9/n/sYu+5prU+n2b+dr/0faNH//pnFz5s5NzTCzq6z0Y4ies5zXOJpaxtdKrMRWVz4uo5A8bDouYk7kWNGVRm+OlCBinntd2bA0VlibgGGCWJy4WuA5I4yUAAcVmzgzYxUOaehoXLRmQRJUwVCWsyBdTWoPcJ4UyAgFJNR6Ss1mWF4IkDbMIMF0KFCV6EhQqqqqe7ZjVpySjFp0l0k/k/lwO+ZxAxt7OPvUeKv+fVr/bhmUp/6aznIZOVT7F/22Udi5JnqLfmvH0k7PNSWa7KnaNnzWJH7GWqAYEgvNILtRXkYhRwcfnYONJ7xIAEICQABAcCBiVDaz5Nl6WFe925nLbx8rH+l/3C3P8///HHF/fsEoRDqd74eYkkafaun/SxY7hOYh6ul+J8anMyMWDEG1jIqUeriqtRe4mRt3Zdy+M/BQYiMZlBy1zUg3HuwenQhSWw4i4OBFZC9QkkVQNFWXhzN+QBN0iAwbJiV2FYEzltzqF0GKJFm1ZFryFa76N8u2A5bJLMKoYLFxTTW08rZUHlGmEZGJJFrf2NQS8aSunG5eJgm0gh7pJqNaZ2hCEN45FWSFSxq/kKOhJKrY9/GE309UKA9GMXuaGLCx6HWsF1UWk6NTz6DTSm169hWYPC8y4fH0sVfkkEWmQBpiImoRWIoAJLRfr/+7JkTQAEbl5Sc2lEYHBLGm88ZZgSIXdH7eEhga6uqPz0CjAzHESAaJ1G7dyULM7QaNTypV5cjCL3h4zqV/88nmHw4zR9UVDjZwukggtRArIvZDOYKEAZTirIdiKHo8voiHqyZDZE6iKr6IjKyamXKWqOaxloVmvbbnXYWFiQ+GoaKhQDBijqB1h5eIRE4EAAjuUZCakmPRGCNumsqwHCftdTIk6mUT869LOxKbEoMhIxBMZisXIP5EFGKgEmy83ayUipCUKUUhVfrLb6my0IUctrH7aiPvhJ+eKW1yrt9R/0Yf5e8u3NfplPmyunqO851tlazxfP/a+s27+EvU92N/LiX/Ot1mS85FUTOMG2HfJ51QceOWIqqQB3SFuFNuEAAEfKPvY1BETM880WaSeGZJchbS+Hyoi/ixZi8q0bVbRSRq7CrlnoORrefio+hVcooL333/MQ6v6KANMdi80Zkcs1D8dtyoGVaTXyO9le5SVBPpbgdUlJuysXIxywQDMl6CJvQgVIandmLtUBPYmxIbKCNm4qBQUXqRxRFdhfwXA0t2FvfBl9z5A6zzv6WHi4bKLbZIiznic7CiTqTbHDBR6UO8hQ2ivzZFwg9CgkCIqY+8oPr6DpuRIfe41Zua9YEbpHqdfcctTM+YHI6Y6tnq4clNlmYUfHTNzTs0PUw3zxxnmMSDVKUYKcTxqbaxNSANUXTqSYIEgALBXK9IsdClvyGTBFb0n2nLRaA3ObmY8LOPEG7GZB17pJrByG75qK21H6E4xIr7/WvgoH+FiOprR0TQxMjF7p/PL/Y/NZhQjfGyoVeWlMptf1I10fqnwMxU//+7JkdwAEX17Q82lEQG3q2h9hA34UCXs3jmEjyaoqZ1DzFhkugKrRs8MKiR8ylKwXJZUkAIBHP5EULIvGHAJKwRiEiMLQksHRPchZr321cM6bjAVqAZLO3m4S8gh2G1YQlg0QohWwfIVnEqyh5KJUAm0eUj8mjza7oA0ntKoFJdk2YmjVv2ba3dXCNxYy4qmYa3l4kql+rd+M2NOAeRsZCKXWs4a9xzqIXb21o2ROz3FbVYq5cyGti6OyiQOSEJvcnZKf1NVDBInZaiZCnRb7Fbm+hIwULGMGmEYTrkdyOeEGOlTlwUEyHHCxRlEix+n2afvzsz+ra73dDG2cWIKralbmRjqOEiNRNhqVMaYtkM1CMuIoiKbMWnjilpIDqdrurHnFVc5WcYJzWs/oZdBGhBU8qCXNjiVjX9oDBtkgHTXYwMkwfFk4gcWJ4Q6EDrhq+YA5yo4JPxyBxIgh+3ElQjsX7PvnYlrVCqKSuEZQRCePRw9tEuszgAZNiypd6yaU0R4+vwFSYmvjG0jC+MA+TJ9GsRZabZ5qBB+2kKlZK9WOyf9iyRVOLOyA1aPrkWRmTUfpEdZ8rqMxpI0naGH60fOpPmtiKWoVa8UMaWqfieAxUFUnnEIr1f+sCe7uZRDhaZSUJEXHXhhlpclEYFEGzGPCljernkEDRtpUULJPtZwgSkluHZI7p8WfV5k4QtfItes1H76KzDQFDC0YhSHF9WZtvbW6bOX7fQ27iilKarM9i6Jyt3NSXrtvY35bKWV4sGYwAtuIAAEZF7GED4GAwMKBBypsHBgWAA4JL3F11+Ecdo4HB8T48lXl+1Rz9bFJuDL/+7JknAIE/lnMI2xLUGkLWg9hJXoUXXkxjb0rwZKe6TmEjdVIroEJNrGYx/kMYW+i0vqzMBUnpdqVbJuRGSm5DZOepEe9zM1JNI/5rpsRKoG9sPJ14NIWmdMRY2b8QyuF+Lf0sne7e2Sln7Hb51TWvE//6zfhM+3a/xjny73yb3pyu/uMSTBGcYTRxx+1+wbLJUH7Kf//aCTcXeub8/V6q8Cuc9giIztONv0+uvGvpr7B2er5gdxUCCIH3mUXFMUc6VWghieOKlyY54c6kk5Dzp3JjzLOoUK3tb5frlvEQzufDPwvfLqgjq72mgte6L1KIdK+2MhmPPo+X+9qBlLiJQAAEbDlk0qBQARgYYXjwmAQtExBd8FBmazKmUhsBAHg0TmCcslxCMg+Xn2D+veocrwvxCKKeIenzQ1rEiIRaWIioXD/r2xiihuV78DbSFomPTGkQ6xwRj2jsiySoPlwaV2kUWdYeNamjR3pxxxVnjZ+xeradniD3uufNnepHx/HXDyz1Yi+IbwXzdHDnrmXArEb317wJnmJg1QAskpUgqCLcwgIhaGWELFuuZZ5EIjn2b5wGm61vNMIDfzEl/yrcxEiHvYoQUORCLMG6uQiFZaN1daL2Obd/2dESfS+htb5iqQ/ZVhylyq9ivandFTmVpZqyMosYegQDa7q0UkDJkADMiTQmQgkEh4JJTLcLTpLreXyuN0lEoRI4wmo5cJgWIP6GVAWJwOh++vYULmBwOgwD0zEI0DZGJwlm6dFKM6H4DVEp1NY/jHa+0JimRDsopt69l96/Gb+Sij2LUyitoJ2pPvdHXWmZfSdUa0xE4WOYnT/+7JkuwIExFvM42xbcGiLyi88YosUCX8xLjFxyZUvJvGjFljeHyvDh+j3xvQf8db4jt9cPJcapId90vZJUPwuG5Mc5MyRc89K1K/I+BbuhGo+40AQJmEiLwaGLQh4FNTy+1qPFDdtHtszU4pLW6zNWw4cMVX+mUkey985MxpyxIJk67tVnqTQPdsektUUEGYluwcI86UVFZSn021v6r2/sJ5+JnXV/0e3//TWZudSJsy5HyDqCTdxJCAAECddsKawKFS3zXk1kyWcqrLPfRdysEgF5iJoJyyDUYwHxutcrr3PrCqvJ7dnTAaHCSAt5mx6nbSKr2Vs27d9/GUM+kBEoP9S10cdoMH1Eiw6YnOcbdR2cJ+CI+SK9xkoe1OHcXCpXh89vjFm1vib8b3osZbxEyZest+wyTQ4FKFxCfVTDIQw0oMQ5P2ACPDshGmASJZhrKzN77UHNOYZDqAFmY9C0Vr0Q4N5SdhR3Z5mzlmicigRJSeMZXc12yGRnqOQverMSBkQt34MpydL+ibfr7bul1bggh5TndaoRkQhHPpb6rITrejN91RQ53jzww+nedYCSkbLAAVxBNJDJMgIDL7DoCut/i/L5WFUVpMFft42B0TfQ0/rvuJRRKNJzsHqxtx9brwPqP3QS8yuIKo6eb+WKti/zo/WV7BwYXcjHxauESEn2vazl0MQzOt0Iwqn9P8wqh0sXRHl/4EpRk4EhY/aFms3XhGpfAg24SDQcg8YKpBbxDHsC5vC0e3bTDgDByxYXPUKY/1swXThYoPmPPF4lh5juBIREJOS0YpCECmDNejkEw2/U5fy9stiZjrZHCGhdZv/+7Jk3wAEk15NY2xDcGiLSf9hgkxaHZ03jbH3wvc0KDWGPnhUY40fxMb0r4BzSz7frDv20jyTSbiwclgCDbQkf0SCzY9BobI3eb93aWJ00qxlVPLpz6TVVYWRmaEy3v2svdzFlGfo7/K4em++xXbwV6BXlikah2rqvcc3HF7nEgnq19ioPlN67iYxHdZRYs1CZgZXpD1RKxYo6hdLTi9lyXMPU7OSeBRdszJEZ1HBg7fqiG5p92z5zE3rGN+G/T9+1lvc4EbN6saQWN0V4n4h5/qAmBLSX5ULFI6PxCGJUMS3Bt4Kjj0b608jJDkvDmoGSLaWQymABgu9NQeg1NTl9pQpiYEgm7pt4udyHFlOoFARADGiFJAUo7g1OrjVSqFrtY5NtzzWJHvL7zlX6LS0fr9zazlGtpAG1fFVBOvRvry2vqy+qUp7ii30pH20v54KnUtlQtycqgS/wVdclmo9mSPzgzay14ULkE4TVZu5IGFB4P1iQSY/X2XKkTOTvon+r2QJkl4YwKQABBVEsMplKpLoSqwkQSw80ReOlUudLwrCi9HOVsrshLMw52Vd32tz0s2cUBa3/8XNaLBa8PjQ8YRfVdqbwdG1m68Pnic+aFWWbj52Oxh8O2tOuRVrmVfxJvCK956kuXW94+NaJLXqd7G5mVJKO/h081ku6LUySACFPKCnowUKCov+tpIwhCTBZ8FhOcwN1V1RSBIOsv/JZ2xH8IxPZxyUjybqCjXtJKhYaKhdl7glR1S+uJI7O0RsIzdffv0P5o5f5p0VJEPj23yQy1zUehLePGfd8ixK7TfIq/ysfa8lFf342ruOagsQ6p7/+7JkwYAEll9RcwZL8nUrei48RnxRNWtH7BkVQdusqP2EDjBmJiKqQuPUjF7QAZjibqN3qap3ZI0SQATEFCWDvSxYrE0JBMdMCDWIpLsEXUtiQUuo/G79kksPBNMpESPLqwymVbGslPe0SiTXFtxivkFBD99f6SJj9j6CDjS4lO5wUTdK8f65fgqNfTu3vD3p8sLCGfL8idMmS4QqKctwdSjBSpmYOrOzNRR6ZqiERlxogMKzY2TbZ2IwhBA44KOkG5DqM7SoFgJlPDFGRHAGSGpPeScaGuuLl15XRwx2Ym1/gewtv9ecxDyCk0qvtdKiOrl8IXP3p/GYLW4Ev6I3s9Ds5uP+eh3ucZk87Ikch5/w3Pm/+tz2Vf1m74hXrK7f7MvjS081T5/ycHiE0mDk+0UZpgcpQEUSarcrRdVVsh1uEIFG+hjoTLT6LTz6dSWgRlW59GdvFH3WhLTneAhyyE57b7uw7pljlV+x+PprTRPlvTXST8onjOUJBTpXZF0VtGzMmzfFnK1F3R3ETirGdsxvLy7L1Ztm2LQ11e9TWV1xFMhh6WtxboT7ngQM8ijEhUmTwCCCKCVICaBFiQkJ6Ww0d4FyJirqZOuUOYm6BNczPCcqmNxjG6ldtXAXUhiOMBIMll9bpIjmvOszeBDbdh1Z1Qlce7F6y0p9gpA30sxo9oylLWsuTMTjxzKXYXLNUmUzy921FF+Bm9HNFrfUw7im1Hvk8vNTQsv1Lr+S1Zj010qKWiq66hxVdgjEr6GOY88VUKLcXfOuVeiVAAgCVBAAAAAnAHJJhvxDFMgHAVqSmhiHGwPv16oZecyrfJPUI2v/+7Jk5IAEiV7Rewwz8G4LOj9gxXxUfXsyjeGDQiSuZnmDLfFW9Z4WiZ5Bi1lIzuoJdY01U+fVw7mc0DttpqVz3yogvourRbWbtlnkWc4fL63MZTeHGpalTjqZg0+fjVhE6iUJo0oiyWm7HsOlN1NOtJUsvPlEIKwz0VrVtY3tJJTSu7zWFi0qTADAmiAe7AmsCzJhIpLrpbxEtH6pEqWVISmmM2fR21ae0ziMXLrRMJQTh7rK8zM06Jk6SmKsCAjh6JLBJdJKwewpLpYH9MRYE3NOuxLjEkG9hyTq9YfRLWazb0MDhY1k8+sqzvXYboWSgybaWaEbKuVkeIUVwskejAIVCMkYuzvHmYSHyAm6rN3AnTHqWJs8nQvHJKquJ0bLgrCaRUMyoLPS1D1I4cNf2hk5O7KAL3OMCIDbsNMBHJUoMDfAwSmbscEI6fbTDo+qFgflUqmBKWTzbzcDVcpfncOEbKapVbjjc1UxXXErMz7NCFruKkhwGxpy2ikiuTbIt4r10RbcXlSkskSs314y3NqloISBCOGXB2P2e6mLthKjQzrKTH1HKz2SpvHftVdjL0M9VAONjgAAgEckRGDChEUoxgoAg1lACEUDHDdJJJQVPFYFKpxllobSiH2sqOBa7pNtxUu5lTEnkZOPigkh6FRATI0q5aRx55ebWl5zM52v/BIORnD7CldSUqtigggwLqShupD5mK3D0Q8hxE/TvoQK+LJqDVmxpdQNUaOlU/tWhFuBGm+dd+LnGzuRpFwfhKC7lxFUfEV9jyYgxfkQpFrGACCBGGrjVpVz3BxpYBZV+miqZTasYrrCM5b+VOnyNzT/+7Jk9QAFY17Ko2xMcH9rGYtliF5TWXkvjbERgc2r5jGjDjh2SmXH2Zej+lgERwWbQELfSKZAkQQRztvZOs1tfVz/bb5Qy5Txtm3bOFPztbpuZazufuiNk24Krc22SGo0O+5P+f/OP6OZfzLjkQ8g0NcqKwEkQAE8UgBSGYSQpJlgFLypisudEuKXdT3Z+mCsEnrPvYjkayR+3ItAExPeduVDMqmAtqoUhei5jfR6FsxDyXLhWxUicykgFOaBRIXfb2RzQDOplXBw4HFLp3AQ+l+uy+Qm8/Bwu93ZWSWlLHXVnap7woaRcMqZWR/mG4s2O+T1tRGbTUqlqviw49F2jI2NN7fXGHuqWq6x5c61nUasHOrNeJt3Y3jFXyS4zAcJ9zRGuzZvNO14i/G9/MAWrjftft0bhDA2GAYVeF5RInTxbMw1wHgkLW37VompHqtrEJMSpfE+WYyicNTrDyNTy2PkoXSmbGhRHcXi8Q1pmiSJwkjJ2akmmtnUs85cdnUXXdzM4joqzBa9NlopPomB+pdq76L3da3WX0N06aBxSlod96bdXZJD1O10FtoPN7ibO7///9BA1tvxaUKDEAAgCgEWmAk6EDCE+QyBAsZM5GZk5mYYIkI0kHLASFwAGoQWBTEAIFPhrIgYSOvD6FSWJgcMsQqTrg+XKZHSj4HoqgTdU3EZm6JiAhCN7LofSORlbGX3XdFIMUWLtDji7NGTUW85RcfrvRJGhypbnNszch4ZdQK/g1dzSF+Mjay4z/zld/4pQRuUyt9oLydMFPVsqKgkVSBIZnobp5BCZDJ6V9JI8kvgGfcZx5Xel7zfJYWoZez/+7Jk/4AGEmJJxW3gAH+q+WSttAAi2ZcnmbwABD2ypHM5gACqx2BJXJKWt9Pl2mZ65spt5RGn5LmuQyxt35RMwi3DFJRTjwtmpKV5IzhL6K9r89QzBLkR63IWvUFNje/m9wqKN7SVp+AZmfpL37sNW69ot/THKDrD3/qPqLAB5V2NhIEIMAAAAA7Gg4bmjTyYBAxxM3GDQ6VAk/pEcTExGMEhEFHcugYBGghAoNCRjQFGAwSWtUzSPhxH1a0GRenFgL7W0NUCABEWfv2+CScQdqXpi0y8ZQzBPaUJyt7CmwQApZFaQaQnOjWLfXo+sCLKppRBLSp5lzjsNm2JthaU/iai84rL3i+auZPZFKtuWS/NXYO+mBZS4dOpPQbAs/csxqW9lVJesZasy+RRuDXnbeIU9HKNWrkos0sEwLSUlnDsBZybOcppm5VqNMdty2XxCglk1LMsI52/dq0sty53/yy+VVqSU1NZ2ua/9/qpOR2WWJDD8rsSik1YAd7QOIwCc/t3BYQHf6Y0ugAOMQUS4AoAUAYAwGAwGAwHJGAholhAMEINHYGjTnGh5W8qnwIfSQPoGEIZczQ7cnNpw5nnJVI1mFQGbgzSXfbV9JLH6JzwUIlKBk27zNqrE5ZNzphthDRsEJXNxdV+oLdml3D16Zsxp8EAkMgkULgQbKZDQw/JKW1PUXJcawxCUJCgZNcK8F6RaR2Z6jl9Luvd1qzVpZcxB4mCcZQ0yV3r9+lsU2p6S1a1bHVi9rNbak2IOtIJe/jDJ1OhfeOHK9jPCapt67qp293+Y/gkm1xLxtJA1uaR/i8beR937pY3bnsed5bq3gf/+7JEcwAHiVvXfmsgAPRsas/MYAAQXWlf3YQACgus7DOwgAGCYQFTJENMO5D/9UgCmGqmEDICiEIYBQqERkINMcBq3nHqVZWdDcMGZ5DVji+GRFhJATmekGRZPUykOARQCvYORBZejnBgAUamMvbgx1lsUqP5OTa1Ifg6SMtlEMQ7A8OQ5LEpWTKBuXWpGzsigvLk5T9jc1IIDmKkhf5ukmkMEQdDUshyvbt69BGtlrrFnegB5Iaf2huSaS2cMOY5Syct/PSy87sPSl/ZJel1iXzFNTWaKI1MaeX6w1h23k4zqx6OXL1WRsskEBUduxNWsb1D+XLFjedvLCxvuf//tq/D6xaxGpK+9JKH8uRScjdLGq2fa8tpaUBgoDH/+l2//i6IAiI0MhAAADXsChS4oU4KKUbUXS6ifvWo1NvQ9s1aAVBSHAlDowWLAYw9pGHnDr3NoPoOhw+OMdGE7K1CwvS0pJs2aQg1RehnjyTZR5ip0/ovFy7Ufw6b1XNmsnUzL7xF8rEpSXf3XH3f6X6d6V1FX/7vHl0WfBhFVtMAE0mvuYI8A3kFrYkABVdRNNURDIQNyZNpRUvA3VduKxJWzt34FdIIYAKHIWONEcQhObUwaYpw4iRh8lMNFa7tSmqhsL3KjLXgRzxcgweQxSCc1zqVmxyVwlIk5A5ioHs/cluVXMpNv0gysubi3Ss7m2i+r9u55/v5l7j/RE8hHi2IAOI+CFP/5YBnFYNDZDMiEAAGOcBBDZIMigwjLEfFqJ8eLAccQuE8ZFdjZVeKJ0IUfXHbSB5bPN9qgBnWkV2aWdTmJQenpsfufemM9Sg0+Dz7So3/+7BEJIEEFlnYceYccnqruy48w5gP4XVj7BhzSgIvbHmEjfDwVuGLemonImIQ+MggLpvJuZBxaUg9eAvkBcIaZE6uym54ZA+juiFeqjDSBWEbIHEc0WD2Nz+WdaSeCQiZ0IxmQByRCjRINUToh6VJSarkriQj1KVPrD4/u2Tv2do1AIlO6TzY9zWfUizIAxMCiUyijh12cRtNdEleIRuPvo5Vqoe1Qv2cW/X7FdKZ4ySa5Q+OOXHOYKHydy81rbEaTF0uEppyVf44ZhCUws5MQgYmThisfYL2kM7qgkURJB1VE1G2Wg5yOcdSpZYyFYrlJgyy038MxvPHkliuVueB2OcsmLow/3YqkULFJdDm3i01FAyclWZQxWE+tpT5iT10sSu/uVV4yEWF7gBpwmsfUEOrLOksCFk5CSdHicud0DB9ikMmDqqVa0ikX2hxmYfaP7Y0p0sLkKrLCKRlqgBFnFbnYL4q6znhANAk7rEGcL5irir8eN05IlwfDDbhEXq11WjknLIc63lciaPdFRSbVvoiTq9LWa3F3dEXI/MUgxxhzpECII7vaC8lKNB+6MYY2JQ0yK1s4ZBI5/N5fJ8jKyFSVfO2kufMgTCvDQkzPPMVHNFCL4pQdls1VzMYAAAAy5B/AVR4CvhoA0S6DxXCnIcXZuQ9ebDGgxklQOQGhP/kmTEKTSJR80o+NULt4RhFFqHzUKEd/udCQkiKFEPiCwhhWmQhG8OWwk9VW7ZHVCswYWiweh1KuTVZvDp/mlftLj1r/7mUMioQ8UYkCHrHkGpeZiTXYbEj5V2aWVZYTjAAAKAE4vCoAohtilE6DEART//7skRNABQSYNf55hwwfaubDz0jeBAhY13MJG9J+6Xr/PYNoeRghBGpFYf4uJOhUZBjz2aEsqou2TE8UTS5eLC4yaMJim3/FBuXeUBoZoziDIXmjnQsQkmDhPRK9jcbMSQp1hGZH5waGNbqCe8hszLRtq/MX1VJn7NKq1ahFelpGFOyn+RAy9zfL0cypsikWoAECJISKRoCwifyDrfKlcO+z1BVxnadWO0GgyjEKNt50PZOJ5SzLaydo45yOCKJiPZi9hpaNSR6Sh7AoimIgK0sgMxgYEOFwVNJFqiRrAElDGJMsBOk/lrkR0md2U2pqvreqoaK2FLRN990pfzL9XoUSmx8GSJXpjaPiRMS7uqmUIIASSXgDgTkLwnoHwHYBjENVYXwBaXI5wZJ1j5kC0b7NDNqPNUHzB/V5qGTUOIHj9jBsKDAWYenVdQo8Z3PBV2MlzDihIpQ3MwvMYVIAxhA4jurwjpeUY2Z1O2x4Rq29ZDprRBBB6CYKPETV/kmTM1Rl7qsnuXt7sKWeWhWU0iRQJcFjLzbArShMUvRtQAJnwwuxkqq0/BQRCLlT5cEQzGiYHGky8WZRiwhVTz9bXMKsUxdMYw7DK85pcBzDhKgcOItEHX3VBKxg1XpGIh+gqxfQTu2q/km3XsDxUMzn03MYW82EkpFwp5bIWpC4syib9lnUP9rPF9qHlnaGVGm2EnXGQ2boRLQ4MnS8XSq6Co2vtYCeeOHm6vleltA/sMRaZmFB41HM2YqzY7o7CwqHl1RG0yDFINbkS3GQ0ls1sfbg898dose1N9UelrCnVbXudD3uu2lQt7NT6Pbc3x9UIqVu//7skR0gAPyS9h7CRtig2s7L2DImFBhZ1/sJHHKEalrOYMOqXE65T1djepnv3G0bVE0HdYTTVE9SVXY/+06orOyGlJIJTqt4slhwSNYw0uFrLXI3KQLBKowL1v5Q+tJO2YDZnRV4maIyAhHhsSLIY1VfvqVqW+2pThJlL2xvd8zb2r3tfZ+6hA35O9wqoZNnJw8slsepUxNhQjZsGVdUUJDICZ83SUETZJ7YW/HmymxWedOCKyDgTGIyRL2L9X/LBm5qiGZyIhYcYXY9acS7nvlZf5PiNtRXayucqtMiV3Ge2+9BlVj9fstsyAgicGhtRKuOm5rEMN5lIF4RLyFLcOS18vVxnHVjybZqAWkQ3WTRSxzDUI5yCl6jktxveTRtDzBGYjUwjclbqIdIsoYmEUKmxKE8OzkECz+jmq0Pqbcdrwa2s2j7GRCADgGgsRsALBVAnW8TsrFsyVEGoQs/DHUalVMq6ToyiXgezkemQhpis7i3+EkckxSBxI61PZAo0o5yxtUKAlDQOliGJLU+ikNhRA0swhiegtLxPynK0FKW0K3AVeaDOyHvWMgUhmSEhGRkRP2KMeDIKS85drVrr/h2y89TokqalAR0O7Xmxt7KkyCY8VajnRNgZRnLmrQE+shpKKOgQsMmJCy3BUqk4yHKV2LI1pBNji/NEWWrDDNiSndLJdnKw801DbYcEcM+BIqiNRQYRmIHuHsWHGaGaPwE7ed6WPTPyts/SleN5IxwnPI/hQgQeBg8JjJcs4OgLql8/3Joj4SNsXGgtESvHFFrEU0X0gYlxhLI45Qts7r8CaaMBUZmykJ0WcN4cQvUcw0rf/7skSXgAP9WVXh5hxSfqsazGDDjA/BRVmMJG/J/q2q8YYNoatoYx7ut1vLaP+bsm+N9GSwsgdrcbyy6AQLdjdcmNwoQTPBqaZcOm5laitDlCPAhFUKMmWdvzNcum7vUm2EM2zS/l8szGO9U1S+/2f+pHZrWjoADpiwewtE6PoQNsoILNV076CZN96oECkhkxawkIJVXQHC061JVIqSL3ajmwTARNhwYyFCgEgwZyCKuAPwILIKHMxfr0DM3eGNsjOGJ26ahXYjuZoh2ubZLU/GJH2r/SZ2PrzK5Ge3NYTzhHVjEmTqicC3CqBdztdm56lyRmhVIhbQBBdAuhntYPcbgQ0Oo4A0SjLuoDqMlchOR+WitM8zSs4ayaFkeRbXtokU6HGIWnzPRMu12iUhKFolcJU2U0O4lwlMnESrSt1a05LSM5nP2Oln/qV8y2T5k90dsBHhMgvO0qIVCQ3fNgSqZxnMMoZaZ38xcgPMyo9DrnlsIKIABUQKgcRnX+aoXCLIEJKPF8UJ+E1MxoZke7e6VKGYnbsmHAikl7kCEHq5OucNMpIjLvC3ZkN2spmMx+yrvzaVRHvUHZ3ZqrvBerL22nGbX31LGxH81QdUetzw37s97UM7F37z3vvOU2Pr/952up7vH0vTp3s759XQLNhGKwjuZuhmMKJADgYIaIrOqhEAwDOVUFL56fYUnu3zlxueeo8hIxGJEejU0knxBjYtNtxVnCq25ph5dFS5r73W769RerYwaBq5lQqAi4SuTERQcQxValQrDXzVb28ynQ9/h07ynnkvcUESAWIFBkEC4aWinYiOkfBkU7lcvqJLwODHSv/7skTBAAP1YNZ56RtggkwavWHmHBAtgVfsJG+CBSzqsYSOKCr+6OlUCA5cuBGjjUB0LMi7SDQddg0SLiony6JSy82SzmuV9RZ1ICKarYhHITSPt6uhvFtNS1iKsdajcbO36XtLJxug6koSBgEEJoypHEVbjpXyN6hQoTcQNCCw7dyrw9mK6wx/JiQ5is3FK5SGifN1pq5v7mii4Ew8ocF0LB6pmbWK0eZAYCOnUOQ7tAUAWiKgYWx7qCBz0lKR5mCReBYaHhOGWoxIzG6RrCaJ9t01ix9e2VsOyi1ajM/JEhYxYM5SR5mxiRHaQ0RtGlBzQM4spN57JaW14ibR1UaZmQ6pO/ajkMZJVvDtGvB+3h8Yi028P7LS676bIdmQ8MzOzql3LYp2YM6tzYlHJ+LNai0AUAAkrKd2ESU0AFlyVzsWzftRZfWqYCYpECImgCmSLWm7paynqWX48YZQNZSRF1l2Zfkj3KJTenBLliFIMuiPltPVwNJAmmxzvKv+YccvKS9TNGFpXmMb+3ZXdG02Thsx0LhvcVdY1xbs+srfcpbXSiPcF+kr+YHAmnA35ReXh5iRlzb5Jia3AAADMUYyRmBxiwtQVYRtC34n4Xa2vuFUNcqsEBYrpzDA7c+iQrnlYqqzmjEEy2RIz9URWgYJ0SAwsKkCjBHATxlNkciikOs0h1UhFCJYsokixHTjboswZOBtMldMstItJolYRHKhAtcLALuRMjlKJpMyS0i0UHkxLb3cOWicehZ+kkiccoufEo4WiXaTHP61Wy6KzV9RL+snaxtoACDTQytIimlGXSTfUfS1Q3dVnjO2hzT/y9/ZTP/7skTmgARPWdPbCTPiiUvKjGGGaBM9eUkHpNPCaK/pbYSaOTUVkh4gP0CBB8SktsVmZKyUYTbInh9dt8SJc+vjSDYhpZV9UJ0Ql1Uel105JJl6EI4jtWPQtsxMntmz7YBkyRmJlsIKkKckcjY2PQoFSY9lc1Vy6tNVE5mAS8y2RNIyUVW3EIHxXNyNk3cOI9Ewq4l1GU6MlTZ+OyP0KjM1eHQyGgADBI2vQGEBS1Vw0IlKj6XAcRLhHFNN9W8cKOIIASMOnE6NN0VJGjihrUNFVNUWQkT7xa4g1JcVBGXZR6itwOOmzSaS4QWzHq4Hs7jaQpByShhzStxbLy+bkPcMVDy98vatpUdmT7DmhKilqlaJ40qIS15oaLiQL0KiwrBmrjj8MIsda3hjgfibaykgMBIaw44YFAI6kR1bQYdQVrVO2Vmkbno3BkFRKo/bWjDjqY0R86KCMhTgcSmmpDXqoqOrtY/DvsUsZc9xVCjQlJBIwXY6MhxeilEJSCaRAkTtAifFkE4f8YPGnozbMpylsRxmA7U2aZqXaPOtirbEGmmRReG+xk0XvnuhDkkK13zqKC8SkjL938dOVJliTKjQxEoAAICA5o6dYxYOw1s6J6rLswuRS/J/IFxgmciT3O9CFFhk0sLlCWEtC5BSM60s1EpFtGWqRppdtAbQUwjZclN5oZkyxJpE2HtZVfBCF4qtEzTGkcBKXaXEshUsSKvFa5Sa1dA87d/5hRhZTa16hMCsTLe/DuN3Lec+tUUbzn8dVS9+eu7Y0RBkXNAQJN2L0gA0IggGCk8NkySqeVwhuAoFnNmC171acmPh+olBEG3YwP/7skTqABRxXdPzCUPCkqvaW2EmjBJFY0dsJNHCXS9okYSZuFxUqs04nRPJopzOieNF0kRIs1aFBXYEIqFGozYsKkxXPQEAQnJDIjwdVnnlkwfEFCkjiGoKEBAWE4CvSZtoBDQUFamihh7QQqAisYgQVenEELASCR1VZ8WG9Hzmpa2HHEcc+WvZip2ZQ+4VSZDs9o5WFCj9mWTVAEEhAAAjUpfXAxAZFXytKQCYMvXVCy0LluasPAKfZSUg/RYUwD3kmqSblIj8fb8vra5KSRVWqa6T6LWCowXnNBgu9opGZNNsqPMWJ0TLkQLo3RFZFNchGugKsCRpdXL3QQJdVJiT3DT/TRE2/X+hlcrGiVn2mq7wdvuWblGMuRPvSg3631c2761x9zlK1kD8Zsl93GX2H/S7htMWx1QmlUQAAAwg8WBh5PqFM0WSkYC0WPxMvG3drSjgRnisPxipFLBMHp0coi3juuUs+fuW9s8vV6h3C/enbeNftvdy0CxrSWEou2wmsUS3MrEmmLs48e6akonDVaJOa338sC9Xr47xtFJ5WY8YxZtZM/lu7v6fMxu/r9t9Mbn/+azMmmbUufFOopW2cV2p/my1oOXdggBjJuOL4DOihUk1BBEFTgBWo0/zHBMNIC60qRyfrtUZ0yhHIm7Paacw8l+6YPOyJahY3cdo5ElMuYoevxe872wwRWUxnNZyruQDxAtotMVTMpYscyvuELWsMCKzlh2MfU0ypHNpB2ojvEiDIryxI6FR+Fjkl+SDvtouyxalsttEi9Rqysj7sfFdqvy/F/8z9v4xgv/NAiAAwrOpfKJNLXLhovwNWiwCsf/7smTsAgTpYNDbDEtwjwvKPGWGblK1m0WMMRHCD6uo8ZSOOCmojGTsRaWdL5BGrMCzI6mbmhFSI4bncsT229UOh5z4qqKbJhTDLmDjSZeeIfElJVut6f43cEKIwojQoOt51mLIIRibqFUQ+8RRKHoLhll3BlGNhw11M61QiI0COZkS+RIZZepflgyHaADqtLjSBSkAARWyxyVzHwTRY0CFYR7MpnE32kthafZoY3DGMYmGZyKovIPB3eEwcxDYaJIiNMoac/uT37mhfJATlGx0Xa8USOGLqGGBGvQcCcvoXhOV/h7x/hCkswpl5MTQCWsvdUrJEkp46T6jhzYgPqLXfH69cHzPx2noADmxpN4sgijo5W+DxusysLNJVspkf5vHSRG4cVlakUGso5vF32MPjy7/v9Zm/5iUVpVqOoAAAGNTEsoBGpiiQjqJkjdiTRtQBd8ZWDDDQRDM5SRSVBmyEWs/RRx7jxgaqLMLg6ePVsJMimtuKTCiGZUJlxzavyvWipmZBOi9GI+kzYUlaS1kqhVJgakQlys7pJsCpM6PvJ0zJeQkYX0GcrDbWnHxXiN8/k5gt//+lkAIQxR8TSBxh0hSh8RSg016HnwR2tRaGoYXG/sobVxDzkg6KdCY3PxWuLU+Vji1JM0JJT3jEudVeKJcSOJruUra4nXEycBVw6t5Bp4jCrEOrfkUzbtKz5Xk9dllfN0fcI8Ie2FnjUpYTM7xNLFUKhPCFDuLKnNvSESrliFE7AxP4II+RcttSSPdN771flv+ju8X/SycMYauaMpD3V+8W+2hdC7a3quWB5r6ku9IqSA4Kk6ihpfI0LRqbv/7smTwiiVHZM9DDDTwfWnKLGDDjlVhiT0sPTHB6K0osYMOcYUCVqa6p0iskY6LR2rWInKJS8jiwdrXmIRRyCKwnm34067iy9lWGA8l/pGlkib43Oma5+TKJ7wXPnTlL2i3kqnKRkkR0HPREhwqw2SOLOfshnpy0sn/zcE94R7buf/6a5lUIFjwUUlqKMtVaQWIQAAgiwBauMAphJAOJzJBBEWChQhJJV023gbKLMhuWkk27NTq1WEswe61Dr2kmjA7CVHdWYjGEu0OXU6GbJThcp/YFRZP8gDhdJC5+YyytpQvpY2R6OREucDgHt4Ei1dZOOpIerA5HyRpfhVO3P1sgqrIyk/XoVlYMlByQ8fOhf7ClNyzDeWQQ5YTmby/7mq7mIc63n362COdiJDtbP/CuFyFq3RLESSxAABAEOKKriSF0YFZy09d0ijLwqVwHIWrXcamRoxzq8RQzD9mDaZhDBeS/Lyw+yyscpNjpSWG3G6VjBty9UmZrHJwvDTSBEMUw+4jVQbJhSIql7qDe1we413o5rpvWd0pamnG9IHDFgZPhUFSNoKmH0ImhfGHlhbQjeSieUAELkBzLAoVm5gA/AopShhi1l5IayCKOy/6i1Ni8r0jfpEwEKamSocy4SDZlgdmMJpsQ42xKBl1kZMWWMKRoNLncsvqDyYSKeq17Racu8Uy3OB6n+ihRS5xVZSxbopgQSuAyZwMDuzBpArOiSlicuc8EJkQRGFtxODlVsup31Cn8GVZY9OB7DKi5d0L9pF/KumX5fHXEFDMiQWUdiAXUZ8tQLrksNy2Hi5KD7CS6CobTyy61FolDNymnItX5f/7smTyAjU/X09bLDVgfIh6C2kmfBL9YTyMMRHKDqwn0YMOsT4SDWzKhJk9KO0oCBxppFztlLkYTh3MV1GENB4IuovUwq2RQT5hTnE9ogYDw1ktOzEYOQyZxC4x1NmY9wAQeI4rI6MOLLjnVNoRPNCpbEhaZoh5ko2sXPK5ny/mBkVRAEABQLqMIXyoIEAT0Lxj3XuWYkehKdWWPhBrf2sXneODZBQxcMS9q4Gq5gmobDUjUIsGH4yD2NsqEh6Fac8mXEMwR4JZ41pwP55dDjXKnCwTWGTokn1Uh38ZSQ0/Q2iDavuvK+OUODj8WJ36mJy7VhOZUsOC902TrejrcLGScaMZMEHXMBEb+eMzorCU8aR6z7iosGDXKGQTQQ1BvC4D1ioF+OpMw5Q9rjA0HXl5XdbMtzbzKlAkEBRH9PdHQugsIRFayLZRz27CyG3lUcW9EmQ4XLkEOr9I292tVu7IMVhz2/bvqU7SG4VqCyJplR806aWWHj3tbE40EAJjzjdh9mBRaKTPbO5bcpu0YvctG9+EMhUWzxkX3+94vC09pRBD0Qf4uR1WAO3OeN64mPQ2YXHoNjCaCTJA6SSHt0sY3J3+Md2IoJyiCgKgBQRSNI/BRYdGsnONUaILNYiTEWxIZqB3RzzeGzKINlMfdeQ/nbVOR0PXOWL1uLTApo7kp5ybnVaHb51k3XQ7yxU8hU+cXeiq6NR952IiizVytfYlb/Dw1OYhtL9T0WRwdB+fArmYY+6g1PSmi32awO4yt7Ui78tc2uE4hpxpym3bFJAptFMuegOX0hU4fm+Y3fRphDmhmqxUaCeEUUyAATYB4k7iAv/7smT5gQWhXs9bDEzwkgvqTWDJrlPdeUPMMNXB6qupOYSN2KEgLBLBlblfTelKk6HCSuaFHbRomNETc/QoACq0ULKNepeZojGTAYiRxQEJjIJck/NQQxFESwM1pgRHijMmNFqR0vV2IFqR2ZlNrg3NJlOFRDLcy829k9nTsc4WPwc/CIS1RgmDDiMTEQYdd0UFgVFEQAKZddHtCoSqXnp0GRsDfP6jwhspKs5ORPklVxFqYNkjhHDPi8Jgd1Q2h7rNkVIIIS1G+86ze0DkuicD8zYd3Tl0dl7xjeY8KjzPY2s2iQpVwrFZbDYrHzqa8b1WAEsesZY+xWWuTQyIluKSa8BaISiXz+D2STAiw9TtzRUumFYpY5tpybolPNWjegsPF/TGExwu//Nhg7xzhi7I0EM39XPO+tiKCZFESlAAD+ZPmGycbtLGBTiyRMfjop+upL33caPyTmGojM4KQIFKGmYfAlbsgSueA5osItFbmXSJUVEzO4UIQRukkU2NUrD0imuJmLa5V4nZYEY8mrG+rR4dXdSXLTNR935l3/POcjHjuZn3QyYnifMuOPcuLxzjHPDFKBoQJAMBATwaOjQiiTDg4mKgyzr8wenso3bsS+negIfHAey040IYBRhAeBGGMawWK4oD45ry4VgfLaGUj0+ZeHXLFYJQUihUlJdCmquaEwPiU5d42hskE1XaISdGyMCVcGhdFBWBM60QmHcWPynPtfrDsklkZJ5CQZMJxWm84Tw9I2EVPYvVxSqrE4qh8G1uy2w+k0OzZEsWk26Txa4NTJIetipJUy8XPR8XY5k0dTUFFAEKZjyzPQUsWdOqUf/7smTxAQU6Wk/bD2MSfSsqLmDIfBVVeTqNMS/B5SyouZMOaGVAhyzpTt8U2WssrY7D0xnnMvg+8Ipl5HXjaeZVpn49y+YGssvvqKj/Kx/tpnC4oUfVHGpGtLXnJlMK3Vz4+ZKmwvZ6e3+olv2qqDUp0oW0OmeuXcvZerWnns0OHfVrwhxYrBp7etVbeAQAO/EIth5MEGmFuEmxACiO7j5rTVMiTELosyo0dFD5PFo8EtpSq4mS5ZMvrxt7XENwyfCiR7S3tS1I1nMTJUYlRBAXFtaz/bEidMLMTxfTwoYcwk6yxUJlR7ICG8wNiYxZleUefJUxQkpXFhgFi3IcHvtpQ3tCyTeQhLsprWYJXOlKOkw/MMT0bJy9TinFvQcu5p5iOaHUM5b+yAkvSf2atRCXTaa9OP11C1DCRgKYQF9wUNhJEVIxTl2W0XZCaVWDdWMtRm5FDs5LGZAUVXBUFzigxfX2Bm+uHozMFyebxGjKLLRQFtEjC9TEyBhI7MgFQfMjEkJNVjCcJHHPWTOmnXCVHGZMEbSjYZWNSH7+nCv0WP8m25een7c6d7+Ts/3zP/c5n62/yf/hXYwyJwoVpfTUBtGABHi7M6NJ4QnK5I1IOmMBMFbqdqEmL2LLtsxf+MtAWjDMhoWwP9IafF8ZLfmLDrRvG1deTcMQQ6c5FHQc+zMvYva/WsPjVuDE42Vhu3NS8U2KlwWxSST4h+ckwfGbLhxc54nu1Q9hryYOY2Iz1V0DJQ7mU7mLiVFQwMByJ9ypVDyD4QVWUl2cPyBXF6vGU9IMeoJdeBbrOOHyoqYiCUZW+u5Q6Irkb8vStEbozqxISP/7smT0AgVvXs3DL2NwiAsZ22EmihVxeTcsMRrJ/S2ofaGasCAFKdS+blFLYSySL0bXSgQ9DpK6CocuMKAG9iLL2t0k5Vn+YV7zs0sbti4QELPMZ1WhzOrF2PMGGbAyqZIQVSuzFSOlEQtJVRrdm7xvPhdKFJsWlxpZs1Uz9n+sjtvjZRjHVptTTV51uqtRm4re+WvlL7HYaDVNv0oAYQABGrbcwsEOgEMEXIhDfFvrbJUzVkKxqF2rqt7ytOtZxQYChSIhSASj9Kh3K2jEPMr02ozoPJjypkyTw8FQeZoH1AIKnSx5N52aLmVBOUtBip1KI2WGV55ISp7McWqJaCWTpgZ6XcsEzQyE8U6jt2WDCj3Rkg74SxYTqyWDBbh0Ohac1We7J+Fj1eLh5J3WFHJdepKRJFLCmb3Liydpq6fbec+lOxCd+bwQ7zR+gcxHb9e0UoXOfS/pvBNTGFQxAAAHCsr7jA+DbCkEVIBRI9DVHN8Vds0fdub/xegdlnrjW8qJh1/EoXFHK9J6tOKvYG7Z1kgbdItGc3M1qzKcN+M8q1HNS6wIVbBFWE8MmF1QsdOKWoJczKkOfuEnqRRKpBRKXQ281eNgIDnxxXF0iYBuBMsLvpr6gAEoAAAZzUMUGDjTdFJTpDpxEkdwaAO2VQEaFaUQPpV52coeU0cORZMtSLSKmWEvy8EmlztvhUlsSfe1Vvtq6MCdeZ9as07zCIXSnpMKlCEbBL/qlx/GLSiix0TAHFiA9Vj352JQsXY0VTOS+2Z2xDNl2NCk2vYkKs0hGLXUjrF8Sy9b0bw4JCjlqyv4yu6fmlvtaXRZvi/n9a8E2//7smTrAgXgW8xDT2RyfUh53mEjmhaRizOMsNsBXZLo9YeMOA5yefyO5C0yh9iVuSRCv7V5M3GFyetLIhNu/wBAJJUoii9GF25KtrEmTTxgIKLcbxrGMhqshQG/xpofTvsxcQjthykZoRcGQ6Zsa6krfIM4BmAIAQF0ptefOHLar4nG1uuQqpIqnGRGKY7Ecq++xNUAToy8BBLvHQlwIIzQxZLgwJsMECTBAJCsGh7OBIRU1ja7gckuM4khDBwEQ7S+C2RYhEtWsrODl3RdVKtXb+r/gBIxOdDTOBJkuy3j1LEYW7jdC9AcKlddkTCEc3NWwpSqlBLpuqziQv8kew5pzNaZAtFYmFgxuSPIOMlj4BBC6G1wTOb+AtJlsHZNFGxsj3LKCAlXQLTsPnaWflUMxunqQ6pXb5ElxRC1NuQ0xvqz3QBAd+DJXMy+2zNOOGc5h7rWFmtEb2fZDNfSRGW29w9X7M2IxT8mHxqW+ZfYwtuLnLbrvcsXJqTWfv1Kt69ym/VaVd/9VEGRgOyrlt7eikgNxQAAAM5Kxv6Vdi2XzU3XgWvcSxHIAeJ12sRZuRbuJQamQeSKOrvwFRBUsphrirqcOF3o56fF7GzoIzj0F6p9pPXax+qlI7sTFVylLj+ly2hr+j5tnPjnGI9laOdZfVQo5st8Bzke2fDfcfhrTooqQ4P6lOY2wiwg5FSA5E5C0EQwGg0dGJAzINCVCdcqWH4hkmMEGuJC1RF0LoAEWFTZESAQUMVl8jEjgAcaEpGGZBpf8CEg5MKigoNBABvEEDgBDEvilcKjl88AwtiJfYtSg9F3USHX/KGD0wwGLLApcv/7smTvgAfyZUmNbyAAdqiZ3KwgAGWt1VP5rIACqiqoPzNAAEEUgl8q9hTstAyfvuTO55X8MKTXJdX8ttzoMao4kugRq6wjaMEnOo/o7ShesGv/LH3hl/KWFOTN2KSw/lWfh+1efqcaWzdyWQQ2x6xD02/UrjONWWOzafy8/FW3lSckENqDQW8rYY/TUjjqwMRgSFQ1K39ltJKIj2VRqB2vwPg79aWSeHL0YvW5/1XNDTQn5Q4UgSqaBMtu9b6Uj9teWLN38Ym0m9BVqU0updS///////////////////hcPsGvd/gYuhwBQBgDgCACACgIBAUCAUAFyH8c/zAG5MtHak+n6iTo2XSQS5Sm7sD6ywMdtTJ5AyACABvQIipHoonUzcjQwMGliZOZmynRNlDcEKkYOwbaJqopU5fPzQumDFA/SmKbKQM2TUUykTRcMTx9zBA8jctuyCTplghxFCID2oopPXqWpNNFJSkE1HEzFA2m580KymsjTRXsnpVqUm6CbsRhoeUV2W5u7CZwd9CVIcAAQAACEwWNgROdIQICpjRAwAIBwOklxkNnNSHcRpjippMicqCUIJpLN84FZuMCSSqzrN1On6buztgrQml0EBpQcdd+XMV615wKR7n9aMubjx07QV7wiEQ88yj7ZpVbn2gyFnMSZY/bZLTvUixnBktaMWXsgSUQqN3/iOT6Rtt5XXkjQI00rrzUEalO9QE5DOYfzqRaX5xWTUOUxHJ2clcrn7EPuvQxuWxShnpBHX3m6e1T3qSgllPjWm9S/mV+5hT6nKWnsfnndmr25i9U723r7OHLnK92vn3Lmv1+Pc9VKf/7smRwg3c9ZdKnawACPGHKVOeMAB1Vq0sMvZPQ9BEpkPCI+DTpD+dH9LvgAAAARwyC2ADSs1Dqqtaz9eudF01+gop5QJchTUkotVKSBO7PD6zeCztJP4kw/Ta5dcH32cpEA10Qn+vABADVBMINch2DsMASTdBURRBPiQpzAgGHl/pNQ+yv2eLpYmgPaBOwASk9lekyCKIrj7HArS/JlsQxGnYY5KAHAW08iFGMqT9OFCWBnJeXMxCLQglhiG6K6hV1ETtLI5rH2fhptKGGO8UbwvqWjxDqYiiT0UuhK1QO1KHarksdKfkWE4fqOTpOz/TD+GSM00moU8sLpCuMFAXk/oVgE85sQC2UR/dJt2jxCTnBfSUJXD0XHjgqGQhDoTBIKBPZUr20NPKYurRtRvzApFKpbJTEr7ynXsrHWugi/6Uc6PZpeOO/0nKuidIo6hNUAAIA7iN20Q88NYx7lwARyeFb9PTW/9PtqGYy06sFHlRt55OXE6stuaHRd0sMC25B5JhTZ6RcQcl6iU47UmEjEAA6inKdk2QgZOicY0SBz2ypfiql7JdEOUD2I1vSAk+a3RMiRtTfBOVxUqtTKdUUaEd9Fe4PEehFSsQ1EIhD0KR8IHRsGRilBgBWANjV4KBJLZOHISJHgjHjK4HiYnQhJBEiHiwzXF8Qy2WdXrIQWSIZVYMXwbdEVTqMzOUAaQIEk6CQ3Q17hSKpdVOoTxOLRdBNWOhe1O6RLFw3Oy0SU6AbMF1hoi8SD7DjjhCggegXPK34kiZaxbfrHDalHll3D22c279Ms9H+9lmb5eBR89ugbgoAAAIAcjintV4CiooHOv/7sGRyAVakaVOjD2NgQeRaW2RlLBktmU9sPYvBHhGpOaYIUJWz78hFIf2b6ndqE65/Rd0QujhnqEydYZOluA7ILSzknBs42Iza6krNbVvmq3jLqz7d2L6JIBgaLPAkslqu8uYvwv4TGlDzoJxlqVMmKeyCjMhdEUr2eGW1EPYreoVaonJwitSktHZEgf6HVZocFR1vKnioVAeG4rslE4CRgQRxjw9KxiYDmeRmB2fnZdCRfpbILJKUqiwQjJMRhGEI7RickZfD1aTjY9QD6o4K3F+LS+fIwdEg0ElUIpCJ4noCEVDdM2gFtIRmkqEgZrK0tlNDq6mLcMBwcKVdrYxR87i5CdYpJpaq8ybabXTvtdRzI/Y7vndtk7H2FUymNkhQAAA668DBY60IgGIvAk/l51yZ3EpUHpbdndfclXMzsTdSb3TmBbc0LMLs4HoRWmhYKNLE56YlZx60FUxyw0MOUG0UnZvkasrHE4BAAeJkNAlGFgsqRob4iMqJwlqpzO7DixYixe2zt/oij6xmQkdLCCWB5SOHh6hsqqtGZ8clY91DaXCccF9BTojly0VnlKNdCjGCBcjrCElTnzx6SzI3JxgH4irirMnBo4fOnKwfjhwAqgqBEmJWhNAnSKkyiSNyOlFuiLEYZPnSc25KJOsbQ8gLWfFKEjTI1GSguUpySy7dJzlOFXcq602/tpYADIjEYgLkCakOBMW/RWQAAABcqhyiqJLwPfUiEqzzzEOys0qUIiiHVK3H/Lia5av80tHA19hhes1u5Lrd2cu7G/1Yy8Bkp8MjaWKYwyaULmWKTocsXZFTSDq2iNKlzVqGaFQg//uyZIUBBZ1ZVFsMTHBVBWoUYMNeGQmNSow9M8kGBumw8JkIEGEARncKARZ+KTSnl3o4QbDjCC+75MwWunQ48ShyVrtZ9Co7ACkSysPZqpLNCb1bANJbpyfP1E0m2hi5evWiI8eLByNqtVqHyvHxzIpmOuA3LzHGap7I9mZieKKZCVKxqA8xxKdUK4up8KOKbrxGHOpFWwtRznotu1hsyhCBesDg+VKGY2CxBolREIuGgfeOEomMoVThnozJGiRhjT2oyZo4zDkIZLPng1cqxrpK6dQnoQOs7XlccM015y35ro0hIj9SW/dn14AwBFgBArARn1ZV5WuDUfb52Bo9HOiwcsLKAjI4STxlojSLKvxSxL1H9Zh9qn0d620o9TRi4pX9CGDmU0pdrap9daQjMzEAEAABMEjiZDiOOXMUTL1hQQKKnZC2PpeSeXNCqxTtPIYLnr24mvLURgTLn8St9mh8X4n/K7OmxgpOaEgypEpQSFj5HcwoKaWgWxn5WywfHTjiAnMjMaWoivvaYHR7UrqybJw01jFC1euIoKK1nG1GGIskrQwQnqZSRwBMJ4ChNy5gGi4CWRlGHxlkW2cTrCNsf2bWdmZCU0/iysFrKDyC62vq4UAIAAAhPWX4RBhQsuVOQFy3y8XynguVPGg+H7YrV82ydW6OfEicvZBe/7ibsgbPdWPf5iqygKBWGWCN7XJxyUBDaLRSXUtXVqGbnKd/q9HAABIAAERfp4y+rcE1UKiwAr6jkbR13xR0Yu3dukqh6HJSOzqA+SQNtrj+i821OlOEv0Sl8fi2+OCVolFNuhKGkeS1DqcS3RDMiuoIR7Sx//uyZKMDBTha0/MMNPJP5Po7YMg6FoV7SoyxMcknFGm5gYk4mrUic4TyqtGB3hm4Erl3HGEMtoixyEpUIKIk0sLBJtUiIEYmXZVczPCVhUjRFlWu551oNWdDAiPGFHipQgSR+HUTgXnCTbW7SkdUYxTNRyUbcsdkNfH7iC5RVfwUY6s6IY63P32FQwMiAAQAGjj5QSVspZk6kij1TiCCRgTAZJCL6ozZoZtI+RzdXcJykfIy26WJbcn2FsDt35Qc5ZCxocUweJZK6pbagOlj6+7uuck1ZEAgADKpL2VTBohGRWAMMkcLGYqw5JFExhLT4IlDlQ7VquCRiaBBEVEbIbGUwXFT4GcZmrA0ksvZ58RcRENGSoaojEzSITnoWREsHEeyJ/isBtpGxqUWD8oNoUGiQ8akWPREpFTUjKcmTUYU0g85JZURwylJlxqHlrIoPyvKWBnwykn1NjqcmVffxNriI/PQQlzE+6MvtOxik2JpTwXcBgRYAAmTlaxG1IaTac91yABw8GSF2CScniYJyonEjUoScfQ1HuLL2CsmSB6JWQQHqC6UqIOIA+qGKS2C1L3JUIBGoyVGBqnU5bT1Vt2z9+CRKQAAEDdNO40dkIiCMY0K2mshvBiiiTCLJWWxYGWyt6fTJ5Qm084z+OjiAF4jvHS7gXooHTXDRCc2u12iW6NOX+DGEAsGAxI4TskqbQyI0ZwCFWVnEZOQDI2KCg6QqlCQnpdiiZNdH8YKtg2MwNGW+qrCTOqjR9U3a6PyWHxxipKTLiFdiqtYkgqssykhb1d2N7BL4m3OmfvSzZrxdaPY7TeR7tUks6GBWsHhdCtT//uyZNAABQVgU+MJNHJPhBpEPMM2FfF1S2w9K8HVkmnxlhnhAG0yo4AAxQg4sBYSbeJTR5X/eNhZkmgYdocufhHdlxbw2cXx+Fo5DbXJ25uSDFWTC8WGzMzMzszO5JpxEQQh+xt+zkBCGP80+kzs2y7MgeARGXk2khnoz8P48u8zgnDYj/99v5fn9H/r+f/6X3whJPnA95n7gDLNcLIAOSQhvDAIAISLCyCfjzhYQOAReWaVRC9CuUmzSANWMwnl0UiwBa1WJekgbOIhG6IVuLDM/coJC4CZp4LGQpXPDgbLYTkvKo0M3hRY2xBDAWfiPFL7kzBmLzg92V3XYX2a7Fsbi076265Zxl+k/R9mZyOKB92tGV6Ozl7bajf7Vzvuw5Wsx7mMa/S7n2dmW7Hir3GEUfcvdTmYrg04Tx91VaHQuKXqS8/+ZfJ37TeCdEI5h1YzTQACmALE6Z0wQ8zYFIJygxDgaU4JYjSXg7oZceKFh1GLIxCEQIrJW0tVEu64cbgWNy6rypyP01Smp35l1mo5MHU8tpaKVdlUuq5TcPGpo09lCCXKivkRYtX1f61avVX/V9U8k9Uj188o6pmw2o5dIGMtdeWyFGUkgBDeXPso10EbOAqa2G0CCA2DwImuiIzeMEap+jcHbUZ+T/nYmS0SMyySa5RZB4H1USJlmZa8ELEiBkLTGhtjMYzMAiA1+ujTEsMQLJFdiCJJ6eslY39QcnjsCHRi+tXlP7Df1g2B1+3clN6SZtdI1/QY8yp3IkC/tiE7Ioi9+zSPf5uputtJmKq7GodYzjgfZyEncoqNNNTPSVdP/OosNX47pyEdCFrD//uyZO0ABaRm1WN5YPKjrMrfaEnWUSV7XYwxD4HAK+shkxYR5+LtOC06+sDkQAQHYTIfLACN0NF/0TQUfQsoAxKtcRf9mT66a3FcW2sliVgWiLrCKe9oDhqrqJDEt2dJ32kEVIotr0exSgUWKqVI7HEnFy1WzIeNuarZE0QPIiG5SuhyupXbM9SO9FTcmcBWx7513KKrOp12yH6VAzEgVkCBlpfVoAGoP1EDCiQIWYkuinMmUFpq7Z+o5AyFzywVD6etgZGYrGCRBsA0/oPVnnk6gYN9AlSqymnfeqxi7Fj0MXOsbxJPWHStHiuCi9mmHqVj0P8yj9NiPlOVvF/0Ica5r96tVXO5qy1JvkKFA97d7ZiabW///vbmjaPtvSks0psO72wJN+9IJz+chwbVdcfKXYZ9wPm+N8rtbAyIYBAXCGFIQcBMFqEEzZbqJTQQNFiJxNmi46ReMgm2pWtwzB9BWldP2euxxOEmcRK1Cs1/IM3V5BUjnEQRpr68PHtKqoJ1nt1QWfZNSczcp0WjG/yZa/U5380+yQ3u779PT70bmsxmdU72cxOSAK2rzPJ54edLkVOtqAgAAEFCMIkJWWfMCMTACIoSUkm3JBxkacD6snLACl8sKtsvM9uCp1UsbF943ciMslzE60bIBnUzhdO/hOaVhTt4fMqeWPvEnolH6yD565SnHH9iFnEjkHsNymxFRRGX4Ero0ovy6buggzOzb+S2elDfHZ1lx7rfpKmeO+N3zcPj1+5qMa3xZpg4xLnRslNLHkbitQ6dvSEKiBFY2R4w8hHRhoqSYgikvVwysek2XATKSCX5Di5WKKLsqd3j//uyZOuABP5a1Us4YVJ7C6rJYKasEtV7Uy2k1QICLOoJoyKRgs0uWIw+OdIDOQdQ4XNQlLAaN6USLp6NioS9FiLkJQaDs1I+2uRxa8THNM+5ipc0cceP4Zf23GhwPiZW+htfR1yy1nbcQ/wYusLcrSzctsdXjo8ab3CD+9uDekwATd98DQQ4gipUdsFmlDj0F6THy1HYIEWBECyY6QDQgNETGTRBx81oqBAERia/W1TtQBhLDCWQtDscCiPFkRC2JZOQIy4UpsoRTerxuNtsPJ2SQTpjRScbFjK0maF2ySdTiiRWrJk8ujbNezB3JmViY6m1jKzVrxYembdF5NaZMxOnMdtZAhdMQt5lmFoaROvvjGEpRiribHgivxdL+JNFg0ykRSKgZnihQmnzTO7m+PZkiaiShlAI6kzH5MO0XwLviQYwEIgYyn6g4gMBozko6LtfRnatLCUBskoH1a6+NkwLjwpFTBDg0kAqIwiQq3AppPSc+i2UH1C+5qoV2iHJRl43D5XhmlPt6xVSoIsjnmnltqpS9EaF928F/ZOhKULn/8PzK5vPjd1TwgJ4BmGv3ALAkgpOk4EBi1ogKIccKoqhSmMCiqoAwe4JZAmduuqBBgmKyJ42iImRaW32f35e+2mKt5en3rmJ/K6/VrDk/SBRZeqvwabqyrQC8K5zClGy+u9Gm8+zDxik9JPTrfiXzG1aEYaImv1GSxs+ZlVCH7U1U5K93FVqriqo6TxXfW5La44FFJoupWVNJCERZDglCWOKPI1pDFgm3y/F6gAgGYbIGJpJgZIIy1b4EH15mUMnm7g26xMlFBxIWFfClVEUARIa//uyZPmExapi0gtvTKR7qypyZSOaE4lzUU0ZGQnWFGlJvKC4wbnp9U1GGRaUyxqTlhcUQQJMA4w0aQtKH108Y6q2rKqB0JFQMCKchJP+IzxelkolongAbsiI8bUdaxI9JIcyyb2T6HxLqCh8TEy5oGwVd1UQAAAAKgRpJfNROVSTV0wAlJfNtzCzpY4kPMqGhcxUVJAALgpCFA4qUnK1CAwDf514Ea7DdK6EYTiDFSIIki9BKY4i2G+LWl0S8tQ8XTyYD4jJJdq/q1qkyh8eWdSGkDkNUXAFZ2rYtkDKhOipOSL5i/uzH2dbezpp5Ym0Xhsh21p1pyejcmHRNVl/oNCkMx8v4oo5MqmLStppWy8M10bnnO6szuYSABBzGy83dMEVaFjwiPTFA4FvTWpB2ABStQRzUEBbyiKeojEPZFBJcsAjE0LNS2cVqibjnOyAiKBc8BpQjyFlF7GEiOBowoRWcohWWIpRxsCX7rY3tsd071xClEq1QhidLUr9vz/HUxXd32t8/LtHd3rP91P1z381z3zDf/b1Y+Wp49dm1YTayxMyC4ECwyMQjmAiMWhYaDw0HTJZXSdAwobUx8hjCY6AgZEaChx7yEzSig9CNeqMlBVKSkL9aFA6YIqQuuMMiJAmfwh/GJKIQJ2bsUsWiz0RWe7WmKSMkAwS4sPoGj4jCNTCqJjqOhaNJFIpcSpIhJF+5CKTtCZijJtu4chmelBNwqZTPyhjb6WLHSPPGM0H+zYP+W4tlQrZ5Uqj7uM4Qxl+5rO/7BJdViEjNJeKsmV1vexlBhRScPDrAm2NH3vFRyBIZasYiETUROW4LPF2w8DA//uyZP+G5TBkUrtsNTKFKvoybwguF4WFQi5lLZIRG2hFrBmqjcmViUUHPUVMTCJo7YMOwd7V9eIRtBfclhEk3WIxe2+sYpm535FHpDO/UTBB5AKs689J2UQEzpSLzOoIU9v7VlYzRiDRvflz3Q8+XdnP3rD4CTKqARW8XlA9UYWMYSuhVZEmZqYGCQs1Zll+tQBQAAAAAACYbbLGjAgwXGPh5jqaZqVGNAip0cB4NHmWYHP8IwCsMIZeQukgeo4ouYIDjsmkjD4dcVt3EGgV11XjZU8lFNPAwepdtxakoMiw8fDluJIJFh2edMCgcmn+WMdhHOIGWzFjxZg851c+tS6iM6WsdzHTNy0sk1VBki8VgxVdjh5yqZMrcdEu6P1ERPL3FtAm3WIQVEI6RSw7W4tx6lB3OYlmRvydAEAjTZkER5rZydaLBx8YiQkxwho10hGwsJJ4mDDgGIyAjBIEy0wIaJglrwY3LglqOhECCIDeZ5CoEKINDeyXxr32qA8yOJkyfLIgL7LDDJtWpPYqBU40xPbVHI0dh4qOShGkHQ8YuYIPTMbhCF2lz/WSm0se0pD5EVSxSVUmGNCaOFzYYECQA6sAONRoKIubb2Yw6FEQXYCd405NLFh5nUCayP8lDiJjDZQEFiaso8OKAz1KvEQMl6cejdevh8wAJcj4zAMtcXuhpXOc2530Danc4MV9BzBq0vfuVtZYyvrc5y7vL9llUp7MT9l1PNdKI3QO4h6tDD+2o5JcZ7t8KLSE9vkSf+ZmNtNrlJ9yLfvbeJx31d6+bbSfr6CBGckbAME5g3Q/+TAIAYC0nMRnIcDzgIMARSND//uyZPEExVBdUmt5QnKMqIoSbSO2E2FrSk080UnLrClJowrRlrK0N4UVH6EIB0C2zwxQcBS1o4cHeakbgwdmEPT0SY7DkSzxkkf2AqUaJzZQA3u2+Vcq2INusmmIrpofKqNVe6q3eI3ns1mSVee2ldW0o0+fSqp6aPX9NUa92izZ2Dy5Yy+lEAAADgneNBEQcRHKOJuAIY8YgoPLemLpbSxbJjRvtHcwZaZiHCh6hg0E0kyxB1pb953hxR3M0d3bhx8JW77DV33qrA2gR21OSSnNIDJpQ0uZahsP3c+eQa6eILacclpUWxrLMOGAl4uPwyLa1g7Jd27ocfoRrLH1Pz3zvorQ0Zi6MuRzEYPRpNHRZUTinfOWRK5JB/aF5Qg82ZKshL7ytVzC6Ux4xVhoREKN9oPEGz4kPl8NwsJNxODknHMY8Lzu4XhmqjbOOzGGnenc32aNZWCAEgEIwzqQ2SgycgFS1qggglGWCMrSkKgFRBNxmAkEQumiABFltsAiNSCHCblSSl42rTLrYUmcp2AzkyhTPjo+c/OTZHC279tZjEwhvin+u/snsei0oZtcmXSeFtvZtlvv/hvMd+YErPHwNjAQqBQY60bRjTQtBX2VZTE/sEG+gHbXevWLHUFTmiAxhgbJRemCBnsn9MORqZ+xc6z7TpdCmAZ+yakIISpqTBtlZoDiWYyASRUpLiIehZKoog0qi2oYhULbi4Y6FW3boYRNGR+og1I/KvTsuy4sYtM2tVCRjB5O/SNsixD5A4nkRUeRUhZlmSZvwOsxQiaN3eNZ3GZQrxznmMZThOrYhtyZ92i2ZGQ59l5cWxrESuWk//uyZPYEBoNnUTN5YnCgDLpnaMm8Uz1pTK09MMnHq6plhAqo9u8qV9nwtKnb6lFJpH8uMPdP22DOzombZEuiHa/5gHEAGRAR4glNZBwYiUCTI+yZgUuJptSTnZirE1i40SRwCuCSVJp33Ts0zVZ2RgyZI0ZjVOxqVRgkRJ6xyRrdLkIvJJ/Pxe3wocm9XcT09uY1VqiHoy/kTkMjKyUpSXq2UuW0z9Sd3RbbsyqwkcC9MGW3KgGAI3QooxECk2g454UxA5IBnwFkv4eKwhngokaCHOfRE1k0Fq8LgSOeh9u8OXIEeZPtvJygcKGNrGG1lFF1IlZN1HTkMSXUheLQL0kQkgnRRnOHyMQ0+V+NdAtqSXPWozKUExretsvkib10KVZUPeI7tW61ObpWszn868oynWVlynu3tbUkGYqjSy/tRGhW1pZc87KHlOXDvJH7AgAAEgBMG0NDBNKwNMlboYc2jaPGp1RVN5WlOmWkoJwXaWkt9sBWAg2pF0mmAwuSoFy9+XX5vCmxEh5kjoiUFxVW3yrXmZt4NqcQwwJreK65WA+Mj/qgA2sRihHRinb9J/Fl3NVhue1aNSKTeGox4Dn2p9HTXY7Q5YmluZNihPJ/RcS7BvGAspkCZ++p1ZhmpIcILAg1bsRggULVnMHXBwwSZmaAPwj2pOCDCAQEfjdqozSVMTYE1svIw2BIDWzEItJXfSym+3LETkFiEmY3GKjdH4VxgPtFlxxUH2WI5Wq5NExpZcL7AZXxBFyoY9E9AKaHdHJmqtPG4dFHk7mKDxRd5DqOWVZHeUdW6lM4by6qTH/3I1I7e+vLHXkCiGtsT6Se//uyZN8MBNha0xNYSfKES6ppaQO2FBF7RA0k2IHHK2t1hIo1JqADKAkQ3JWSGg2pcFrrya6pSlcKxT1ZyoxF4Cj0VgyLOM974U8YpG8FNgVPpittEkX70mcWzs46PMs5bNZWZGb4Uv6CpES0tk5sqqoPzozhbIktC2rUt3qT5VIlilMm9FbfrfUr0fXob7+0q4Ut6hXm4aoATUjhNZCYYFgqiDtCKMtFkOIwWGAQXDAQVMhgISAxHoeLxgYGW+QHH4GHXEgwKQDuRIdyHvHVEFVGiVB2ihkRgy6MCoaE+Nx1RtY1FXhhlEJIh+JBYeOXyGe2SJBtmPD6csgmIzD9FqtfG8gsMGIX1SWPHlZxA880+pE9PsF7H11x44jef2Ux9TmezXOKdWx6HlHbeXKjnHHJgffvZbtJRpcw5vPTqq0K3J/DJFFzEFoIxJtCSom6rltY3pWWvVTjTj8QBCGQ0NwAKOcACkISYcvDo8CgAIEVZAzZuAyULFA6yPqV4SYW+i4exprvkkuRfAoGaSJdhWtf0si8bvvJNgNAg4sBq4NiwwNd5JEUeSJxQYNMsfRDuUNAi1u9m2ipbJY0kdMtEPfcV0sizxFpE1aTrtxeJuToqdR8DCupiNnXj3Sd5hm9Spp0n27qlHduMkWd5LYAMMP7A6kMIXDIAMwpjMjVhIXfgxtaLRmGBAQGa+qaU6Y4WBTgjOCBW76cxMmMeGalEXGUGQ1jKejJBZGUC4vAypI3IZIxEoAUFNKpp6iyPayFvnI1jZ1wyhxpZCgPK6aohhdbZlU1Zg4eOCg9SS1Hu9k/d/Yfaf611i+lNWOV/Mp1JnT2//uyZO2OBhxezwuZYuKSazoBbwg+VpF9QG3picnQrOrphg18CLWf3WItyaQZNIZrMMO51Jvlsnu3Of7u9b0U5bEsI/P3chtlW3b/V1j8i2JV+vhhaIAlWmXMCSloQbUNmupBovoltalyWT9qwhPTMrriMnBl2FNYNe8Qkaw4jYToWsPo/Yzq2FRV/MXRtWYKVyStCkc/yMoa+ykVn5hWOAsjmX//Mvs/hXYt6ilDM0b51eCp/lFelIpkFjHymP5qwMSYmAU8vooQAAAJShmsaYKOg1KNlHD90A10GEiFlAJQUiA71SoDolF41MEeioB/ntLfNCMGFuvA8Ood4ZaYwZargJrS6ZZE3DbguCU8SmIYQFTAjdA9Fjzx4+UQeNHnizWw+DB9objISbKHFlmlh9l6iwxyPgYIL0zXzBZiRBMPdYw4OKZalFxRrLMvOYZMljqgR9UI5j79xn9v3yuwU6skS0NJKSd0vrpEAiii3MHenYKcGQqVDow27IEJjas6ezkEJ7MkOMFPuzVT62XmnrjpxGEyLJNqmuNes7nKO7rvMbd7X4xP991hyvuIRoF/EbGQmp7u/zWW5GRmlA6KxywEZZBgM9KeUyygmzdbD/9oIlNIxAAAQCocVdGvg6V51COdchGVnaVIhGDIBQFAAGC3cMbNjGQYSCCg/MBDSKHZInqGARCEMnbOxdmrN5a7q/AICmdFXqLE5+m8M+tH8WdWHZiSlIcz+LIE7AZxCP4KsY55ScPO6YGS1Ovpn6VXPz1mUdfK/vbS3vbbnzG2EO8RuPm6ki/29pmVHxt7X8vv++/JaK1udRZ6GIBkMmeGoUff//uyZNWERRJbUTt5QmBrKupnZCLaFB1rQm281InpK6ldpgrI3Pr6wiIi05TLwDNDgKiBpcDDAEFBoVEQiBM9JlDYUxS6bfsL0mKqJoqFj+2nDZQndQTK2nscJqU5JrkzizEilnZg0ICOZrGOOFy1Bqmmdg5EKN5Xal3UwpFe6OxGIbdW2a2ytpr0IlFoj0olK+7TqpWQ6PW1Hrf2jBwuI6aKAABjqrTMwkIxGSzRIQN/OEmEg8VlUDI4mTzMbgIv2bgKCj4iamQRCGCNeWogQOClIqbS3j6dA4eDAUCiIa/gOTpINRaSSCU0Z1oy6VLqS1E6J8KkjiTTaXCPPpLphZCbZQmEQ6bUEs2CAeKKxGB5BAR9GnpMhhpIiwhSXyPQt644w2dQQWluNLbeKNJ3sGSOY77IMinc5S7MoZe+4SnCMkCjMlPO4vukt1OSv/fCCgmjCRVLch6z4kZGsFna0AAEAGGOknjBGE8GlpINhWMBRZjxisZUEAQOksQhA4WNBCZW3IkDquhkmMuBH3/EjLZ1+QEu5GFYiXcs1TPx5k+jaGFakwDxek6glr3XkfnSnVy2rjHJO+zljlNxVq0Le+dKGto78u5rHtXojZm/R7f0/qeqP6IUNQAWlUkU9ATnAzMWgwUUJhBJHT0CYGNQiBS0DBA1CgFCAgpwYjKwkFDBIAAAVbmZYD7xWBISIBFrslgFM+Am4Jlt1LkF+aR+HUea9TOWxCT0t2ZfpCjiJ0SiQyTLljaJNdZk0fDpPKTA8dKNJvHIJIwYihakR8yeQ1AjYRZ31WEZGVNvLH/CQji7JAcOvYo9oRNQjPVk3MCl3jI0//uyZOiOBe9ezpOaSvB+SvoDaSW2FYlnPC4lGMnZrOo1hg2lia53cY1/u106fYiDbsWvJXHTVCHP/7YABUAEglFoo0gwbznEAb0aMkkJELviOCXyUddbDpSqkAOoI0AFTrWIhprcpoC8n422m8Iw+HLwF3I845JDLpTvhEI81ziGQm7Pc56P2Gfcz4yEc+9O/9FIACFfhdc37lncvzhFkiFyafUz/sUWZB6sXAAGTtz+bggAgLZ1a0a8ChgyVXEkaIcBQgMABcBEwiEX4HT9kiJI8HIrCERTgUSW4zeq5thPVs7X2Izzivzhm1R6rZfKQGVeNvHdCQcI3/efWxFTJe6YGENDdSqzNUiq37tPO0GdXluOzZm/7tXjtqAwyu2LB/jjpnH0sLPmSf1zk+5PGSX7Donu1MTBYzjemv2JkUbbOQlQ0yPlpwwXVd2H2CQUdo+EiBResnb1sd7Zo9hwanhzpyNzcaH28K/Os5gTa8+KUfgh/0ANggC2k5OY+apjCRelKwqgluGsJrqHl3pY1q6xp25I0eUM8e6nqQw9tmfzgmdppuLey1hV5yRDOpOZbJWFF0ez4YgHxOOYx49H7HChiOXFz3kOKd8XfA20act28k6mqC0wob+zHTsb7S7dsG4FHsmZ/E3bEfM8JWU946r12onDp/DeTafn4992QfA/GRNsxiGXKwpxkuu1GkVuqHv43g21mTe6ZgQQtsEJr0GNKBUCjVRM3gRMKI5hEUMBVlIVrqRsa9G08bS32avQCQWGUPRpooYjyPbU2JMg7RCyhSKkBPFqEkEgssgbig16+qDU9G7T2Bs5AUXXyE89HTEw//uyZOCGBh1m0LNsffCnrMp6ZQ+sVJl7Rq29MIKAMuklrCS5PBBZLNGmbxUmtJDnxc+3qBab6WOwyQwzfaJsUaALPllpZQ7EzbYqauRKxGkTL+1B2rrRnurQOqCdXYqu+sHeuLBi4pH2NvHR5ZHBwGl3aADAABBAzWCDMLjKiTgADDA1wA94GwgBWiwS02F7HYiUSQfjD/KAvdMNulg3aoqg1WvBww02TdChmxYgz1qRuWXDJ5nuHrw84vihjdXfpdnrEQNEu6Sxigt1NuJJavGsUWvVLrITZ9qRz2mSwqTVZflNNS68ZsbaEz6TuHSXrIIZ/paZhT99wW9ECIU2qCaprVEbuUM1KTd58Z8ZZ/aZWuQMAQgCYzYLCCIOMKNDIQNpya6DiCBk4sFOiDSNN9si56VPFmlpO5yl9XgeLY2TKwEAy+wOuzJ49sFqSJpzc14ytrKqEWVEcbYLkEfjNS3dTf2+hYycJMSgVhfYv+Iya+pLbaZycqXLZ8hfIdfc73Jnch1kp+Hj9UPP9QrxrdUqp2ogvV19hcNvTgtHDmI3kjzwzpCdlgAGoIBLbBxLYZUcqB9jSlFirVnJdZORElPiqecjFZULdShDq1ZyGbiGa9Wo6Ug6Mg41BKuWxQhs0NUQ/pNQhvqUCdzT3NfUEmVKq6jBDEzSZvccxdR3MfX719rFxFRzxzFV/8abDeuZfiF+tbiIqTm8gSIPUgRbJrvc9kgrGyqAGN6ZnYeCToEK5sJ4YiQI3kgAQXclBR2x6iSUCNOUUAUV+tjEtshefktgZ9XffSJP471mZYtLsW1yWTaJsq3MMtvTNBREyW2cbn2p//uyZLAEBKlaUjNsTCB+y7qMYehYE8V5Qi3hJ8IsrKjll5pJEEMRAsEpRkaazUz1VEq6cUXysjD1U81aaLVfXtd0vAySuhBnO8siumpYrcMtAuYlrVbiFnMVavFsnKeqbZY1mlYWzc3qWkJoeDa/q9nk0LYZjABwARlQg2g5mwYoIWgQMLBmJqVjsDegAhrXYAqvLasZXS5jcRQmzEaYaNbrUWZ4mzunmkT9rCoD8Ba8v2z34bpKtDDDDVFOcUTX1//t5am+tcd0sZmXu++cO/x5r/19NWRztsN3zu055rHO+/urWbdeazsSS3x89Wip2f8kRy2CHgJXihpJ332dz/3VARAzVrgOx2nmEjgs6hxUBAVcZklZL8rkNbQM5rxflPQOexRuY2FeV+HKFVOHk6I1pWKEWaiuI9gONCpq3iAcQUMyRos46w8gVLOGyNYXnBsdSMK8XKXboVbLoQNFViH6gizdahIlubmValtw8W+qnV2/ut4+CR8MMrr6tLj5GVjZ/swc4dYyB4NSB3Lxcj1e74/oAwACAgRwcSVRCYMmxMwBEZkWAGzDFwLQkja4gKVao28kCuix2gMIOh92XYJhEYkSqrxSJxA2wQqTpslJlwignA0HHjU7SyZCNqsShjjN67N4VDBPbV1djOmhaGfUp/tFUsuKCRS7O4Vm7Jc0PNi75sa9S+b/qu2Yg6EDKGM6FF2S/IBEJJQ9fUEhgaFO8PCGIgLsJdJFtW5Ae/YQVAxtrj/wyUGlQxBDs9dNRZPI05c8xebxit26//ORLV3LVz+aRHBKLkSMJYRA+7o5KMEnV2bWycdooRO+SV5zehR+//uwZLiMRJVeUJN4QfKCq1oZaSOiUYFfRG0YuUHhLOhZowrhW38W+4dHuUO7JRNb4BzEtLef2zHzX853pbssvZJlK6OxcRTd6hEFGhMESpGFabG6gwDoszD89YYGUDJvAMjQ4FigPKkt2trobHKUjFz0cZh5cEoBIN5aVrhWMeLFYZu1aFQP8xJvwF4hQtn9s+q+Xuem+Vv+/SQTjxCZUvhG795W58vJTzHdncEM4gion0U5SXjv3Q3pt6t0SdjdH0VkO1L7OYxYnI5hZQAgABTTbmPATBRAkNhKI0o0OIMqZsYYS2ocSfcMBKTaW7CyVpPlEEJsUfjuCw9BJEwXwhjouvjdCijrkDbDvvfK27fF6sB9Ve7E2dXgMdIPVJp1JWw6Hy5QhpCiDVxZ0I2ccu/T2g67pZyntmjxt9Zt+P4nefUVUkTI++vHERonMdd0mEgcjlPMUft8zT1p/jIDAAjE1ICWwLRmXPHSRteFSQrWBxRCa/JWEaMudo7mwNDqYjVoMTYeaQt0IgMrqMlkk5Kk1kworgZy4FZhulMdbQXu5LW3bZZuYOCS000dIfKtbGaX9IqG12JSXgKly/h4lLzIOUvz7Sjf+5GxUsuscFWPCvNMqQJ4JtAypWjqACEIABLQJJp9xDaIWBJyAKkMCCgjbhQpsoY4sUuiBhnWfluLTHsjis1G3zw58S0dTYfI2wpY4upbXYXWWtpGS1rS5UZbRAtNjQYiWigXhjVno76UrfoUzHt27yS83hbyQQszT8/Kr5p16h8LyUf/v8/PUf/PlXOOVLd/WP+5T0/P9a2VLAMcbsYfsJb9KWwVeIQd40H/+7Jk0oBEimNR00xEUH7Kuhdow6gSiXlJrLDRIdOrp6W0ipAIABWMl0RoQEYiaSDBA6MA5gI8aYGCMUa8TB62QYBrRbGpc0hIBqMSMbAGU3U7h4kbDAahcuhDqhjYroH4aN2rJhKOzQyq13xZjLlVXdisqEo+5Ds6+VXTnWmGPCIh6Ir1XM9kGVV9r513RM3//k6fxkrHdKoAEAEw46jNeIS1BwMSbMVGFioIBAwMDCsHAwYEoeGAqhMhjwamEmaZIAKwRMyEPREhUIjKWr7sOhyBVLWHX6Vi0uulklhhRCfgq06Wll6pp32PNPxX8S51G85c0zwdbkCQ4cOcGtKKH1cFvoc03B10rb1MtqXUvdUUeEaSXd1nt5ApXULUyk8IlDEjnmhiw9kmVEanMYEl2gER45hqDBQKT9Tr0gAAAmHAFhuSMYyyngFAKFTHiUxt/NUBTCRltwHJUxYYFSJVM+hwKgb1bZgyvqMlRQnV6YfFkRWMMTZZ7/OjT4vhF4VPUfKmwgIUOhGIdwxxdtsOh0O3J+UaeiGoWdNBpn7Zfz81P5nr8OEW2WZMSN55Eaw9jL0v+WdP5T9sM4csGrsoKsnRFwQBEcxjJAcJhQcGNlQYSCpgkZhUAs1EQlXINAtLJmpVB6D7cgsBBokSBeaIiSUoaDK1gGXui2GHF3rekzvOpOyI4RClHazAbaTQxUst6xLV6Weh2IpRJWigpTC0C8LYYPvyOJrmL/j82qvzRPJJcRlvbSSLK/XY4udeORa22EXjZPn4G7rzUJbxm3VjVinyGUTrCMFxTkbT1A4VmGhvi4AAsIABJbSVNWADPpjk5uT/+7Jk7QQFH1zOm2xFoIcrecNvA04T5Xk6ziUXAeAtKHWjFpDosOSIHarGU8GGmcDDQUVDI9GAAYR9PblKVQUFzKiihFJm48zZlSMuK3AZEyWdritvNgpuNb1S7lQIq2VtGFXclEerIIDlRm6MujSOnNoynGn2bVv1sfzNp6v1kfZfewsc9h0RQbb2dtUAMgAUUknAJdBpMQmAAlOGILLCjMDOyoUjgcBVCKKErHKXIOhkwq8fbK2kSXIuFmUmdx/67sxfHmu9n5NXqUudWyGOtBHjQykYCA36OOlB5ywAQQU2PaYGmLTCEcYWTJtTrAd2W2ey3ZE1NNDIstjsPeU+Cc2DiCGn2WVBhEjuJlDHTLxJB1rLTPJyKU5dEEUFyTuz7u9TMaBYvP1522/RxvTNe/O/2U379PzMt/mAJwOicOTGFpRjmKJobVzKUo1AfXimKZ5RfkU8ABjAmWlgo2R4q44Noh1iQ4aLHMCgVe7/11ftCuSl8ae1TQtj89NZ2plRFZs59QWIr0ci1pTlSppmPaswEhRuxr7OD2T3ywvQ+9s7fdeo0dKRzJ9r0hHONkllczef5ylPaHN6p6rZEslp1bgIMWWQmaNWd6pXvOFQ8JCg7q5Zi7SSkOaS499xQeHbXGYhj+s5PUrn4OEU8HsD76Nw4QHrQmbT7avgecTnPSPd/eAAPIACtoCAnRM2+AGeDnHGXyTJiIGLJpuIgPV6x+5WUuv5stcipafaKwkAacDvSgTZs74+BzRSVrotzdos6qM162jBUR8bZaZXywcl1GgHQDF/GMkt+7DREhNTW0NXFl32egjvRvXuQoGpOl7Rd4f/+7JE8wAFcWdQU0ZmYsiMGbFvLE5VZX1LjJmTInWvaWmXpOgF7Bk9y31hWdhhLMbb59xyqOchXLHqKIGHEhzW9xCPIY4F/Hx8qyCM7JhbTp4SxfHHvYaZR+8GoeE+OFAgoBUiRKTDsCYOqSxGQEQkNwKzg2mMZpYiFkgU61DHVSVUIFmazdTbMDHHT2rESkFO1TZK8PRYIW8peqU6uz5ztssyYOiHJJRjOE3F0mhGQbNaSOobJD24VUoML2vNfcgvkaSheIkaaBGKCbZmvJNZY3BwpqFk0kSasXxKSYb8HIZ/cEKBNaLNvxDpycQ0G5FLKba1bG4H4LNlS9TVKgCjgAB+ohHfiy5CecH5vJzrQBYVP2wDlYFZYxxd0ARNmFyMPxGopL8pmxYrz9dqFrdeg8Hjw8F2RwNNsJardB1XKNBU3GKh3Ix5q2uexZ0UOa+FeqIu149hciRzFXDCAvi4vUU0QKlVzCcjiri5v97xqvxHzV6x1KFXl3FT09MZRNuRsotLG1BpbhqKdIBBiABjQBACGFhviWziHELdVsmTQDZLQoEaI7qkWck8+FyNCjABAgTIAlLxboqHAlxno5j3Sjyui+P6GY91m5yviuEgy9WDVf1/1h1XtctIuOUjuprTOomm57T8m/tkPmuOKiYSuJ6pJfiB96xGql83G61FaNUsVQ6UEiFo3Q1V5GPmr5KsBNgBhAEDxQEAGCJi1RzSIEAs+QqQgibF3mBQtYiCBW9XRfmXQwyvBbVzCyeE5oj4TP29v9w1em0SSF49jnnlz7fRZ/12ZijnRpSXvVi1eQ1G9JNVj4uFKjya8aDUTZURxSv/+7JkuoAEaVrSYyhN8IWr6j1hiGoSYXlDLTETQhsu6HGhmtBECptzS+LCc1466Fjh8uUvVNdjz4uyp1lnZ+pGCCPpQ+GXOiuSCNvQiirT1OhbSzJkACAEAYhAJUDCVcsAiCs0pN6PmBZiS5ANDTEWBtkia6ofZVB9l+pdTr8xfAqg4xhlDMq7aeC7V1Qqe6hDBIdUyn/hmWyHMGe9n+W/NBrd+Yy1S+HJft2euzvG4+T9O6f5bZMJK8ec/3PDP2P+MSaPFv2Ix3do8lEVdT/gRedkRsv2/hLHttkqBAUCAnziA8C6hvpxySAYIcYKDQMOZvDy0TBDUjWAoVN+PDoahULg9fUtxiUCQlrELeBSCgQNxLyJ2pqxC7oBpyPa6TPsjXv4YBUvhnmPp2fq1rD5jyR3JFP7zP7Mnwzf7W87cpsQ8DJx8pu1Ot8iqb331L+X+tp3nm471uP6ptJpXaR2443IoN0pzX7AiWMBAGC1hI4IYD21voNEnghGv66KmRf1BPDqnGTewqI13pnSYBelyepWAlk9KhZZHRVi4IbDpFFQGwiisKQcXL99S0zwggmw03Vdc55lklrdr6MLXNAqtLVE03QV2ZXU/Q6oeujup1a6rR+x2q+VvLoOjGqgLeEBZO/QCQJSJRh0OICQkAA7bg7A4dBQgIGAVHLFCRgAkEl41NIBStQJ+3zVigpnzr8bnOrWeLK6M+gCLq6lKK+97v98N5lhcz6cwjc6N2aOtrhoWRosRqTxolXG01sOuJYW6uPy71yKrWvo/43KBuSSxaulnsfUGPjGmsRFMgo/41+ambVlzJ4ejyQ9Fo2JsddmxqL/+7Jky4SEYlrPs0k1IntrWgZpAqpSeXs/TTEUwegs51mkFtksvTHdUJSQIHUDWEDDnTcyTLBQuDcgyvoySycjwoBbarEUK3SgFqUBtYbgxgmGTsdayTDI1xjUsk0082GxUHBBKGHWTf7UOGLM1vMfTFHWE0maztFmog1GSzqQpra1zmM6lX8t9jAyke6o7y2l9X5y7k/YrVK3R6uUsaOwKPF1AAFAAABBRShjOom8kIVDQ4oRWyXVCoAYEFOmuYoZgJoDkkEj2HhIjF29btI1Vko9sJcNxVZqJu7F+x12JzFANChFeMrSQkdG5SeUiuhV+Qkytequmwnpx0k+shgwkDaKSpeqTm+dc7GGS8bneZ4LZ8SzyhWxLKE3t24nHN6+1/LykiXd2vf/rf6knaD+9TjW3tog542akOAbTYem1unaAIEkAQIyW28JEitEYIuZyCAhKxpSYtiDBKGTREGn5LLQObj4x2mMoUWNAxWmBMNWSZWPa+DvcB2TeWjJag5iQ6GGcaT25Muw787l8bm5XI+QyXPThuXl8z6x8LCjKZKy84qgynPOFCI/+Hp6ea//nW4OqqsomGyzl54AEVAABONyTGJqiRtI4wFEHJyAGlWk6UGm2Fh6+RUMKjUq3uUeQGwM7rQIh1cduwdrjAiryN7onwfGnFttj6N+hxZ2J5wxeTvL32Ehk/xXssUdTDYZVVUSqANo5BPXQvjI5eBOKPJKNWipciP9RNjSL5RJGjlmRp/1dVIgHr0w/lfiNlFx/jXW/U+aDY+WoOrgxPzk+7vclyGoBgSIjGZFBrBuKlpksSaCYmCESMxqSyQFpf0sqFD/+7Jk6AAE+lpO63lJ8HnLag1p42oTQYtBrTETAjqvZlm2CqBMLDRh4iBAAGA8BrcedaCtCvCUKS763B9CIpuwIpePK9Q7HAVCGFUNBGSrlTQ8GDiJfVydrbd3r9FMflaDVrV7fFlImpStHIazr3eoU0pkaxmeh2IZlw17NM0s5OWTCZnWW6uu5yFnOj8shGxDLWmIu1oCMAAQCSlDaoYaijAwcEvpl6oYUBCxUYAQAw1RYXoYEBDoeLAiFSA0lCgULj6JelUcO8UpCBoKcdI3yaEMORbWnJP3im5DhssRm1iRqvPWuWSeK4Zja1l/d5R5PSaSnpS1Iiqrp64UrBonr0jdmxF+sfva5rnWP4MfO86+p5vLCjue4cb4kzneWNX739Q901a/xH1rWPq1N+keBvLfLE95dY25t1aNrk99oE1saiAU+4U/6/IBTJTQDC4cHgWqOpHY+YUIEtsY2nIVqnEYYtIQAYKAwMVNgDBkcQuQLNh74IAB9CNxEgCGBeBkxmSCkkfTGaLyJeNB4MESYZMxLMgpmbnjVJAxOHEVozBRgiYHjFrqVTdandaCqjUurpuuupbTLQUkzOyTq6kebLUs67U0VnlomK9KyziUbOuJDlwrUDUP1+4AAXzBAUAA02Pk3yMI03HU1iDQ4tM4z4FMwFMRAaY8DgYZgqYOE0YwgCYog8YJBEYvBuYhheODgYYhOE3mYCaj5tZJ4BQMzzlbVpwSZAwtsZyUgMgAS5a4ok3wkW70Sh8OhY6y9QJHlLKKF526KVq2iw7AW1Q/rMkUAka6kkYBRxUuS+eqHZevxpL/OTALyIkRhkURUDlsIYb/+7Jk7oAFoF5N1W3gApAJCYGtyAAjVZUq2dyABBmyJSs5oAA/eT8tibHfgqTUDMk1GZzFI/tWB69iMX6aldCXLIl+5qNxqQOVHou6k5XfetZgSJaft94VKKaRS+VbtTj5R+j79u7vdeWO/Xe+TSunllmct34bilLZvRWks9t85vsBzdLuW4Regsa7/f+Iya7TRmw/lvlnDVgyb7H/7dyT7v7oUWlAAGAADNgoAAIAAABxOAG/S6eKVhjwEmhDAbuFRq2WkJKHpyYIPZs8qmHBcZLMRlIDAIqmTiGYaCxj4Jg48Zo4WkVrGkoUVgU4NMTGAjGSk5C6pkzSXzZHNWDGgDVpbA5MFeZFIuVKm3EhCXwOMtKJQYOLpqIJUHBYOvyDm/Ym/1IlSBBSPJbDKaru1DFJ2BH47NS+Cc43KrUtz62812iwv+96sbdIdlGOcZjcsnJil9sMzOYU/Ka/nY7SX789Zpr/ZdZjFW5a/LlTueEzvOk1u1XvfXnrGVNq1VldHUxlO6TWOu54f//9NQ1dYWavO2ef//ajcOVIxfxxznr6X68V/9Bt9n/nK2RiPREMjaHBYFBoLBsUbgNNvS87MgqhL2CQ77AE7yYqwL6CQTmNtlrwVbgVkTlL+gB/a6vBIEDtNbxzfqTcPvY3RPVVZskhpqGjvT8vqErC3qiSTy7JPAruv7FLE5X7TUr8qPuU1xMJhsESacmI9Vtz+Gef+DBCMTPUxHodBtJTPWZ2zN1cN52+Z8+/P2IYdJ3XnjS6IxlSTlWzV79f927/571YsdZs1GD4elt+0yiCWmtkv54Z2dZ5ay+xY3+t27/P7/99oLD/+7JEY4AHE2JXbmMAAOJMSqXMvAASyXdbnYWAAlcva7OwwAFFcRuXQ7ADImmQ44nXciUgxv67y5fHhs6O//0AQCQSSIoCAIGBG1iFlDWhRUW8KRhFDgKatpYQmos3VcoYkQE4MUCWCkHGIA1gLaqJ4GehZJVshBoKgzxAWlPIecjgbwKQeBcxiMgsRWixE2PFkLiTNnQlkj0yZB3lSdpqnadBzmitGmyl+SIc5cRc1tnUioH6ShDzFZlWrW5siKBoVLi81dPqNniq+6osmmJnVL1XF/TSOnYrs796xn+de1HPR+f6FoxP3gOLe7iQ4Pnmn+p7Uw+3iIq3DdLPNKyJfV47yjmr1bqt3l3t31f92vjPmuoHVAEu+7/xYKNWw7/uXgGJGAAAAcs+IgpOmURjE/612tIxMtWoztobJHQZZC2kg6cJykdJYSWAgEp+8ghAkw0Jx1I4Sh9lMmkglH9qziageTkyN1otpQfReVdouOTnUcmnmGVuWWQ1pp2nsfLDI8eqZa5mcYq/SioteGbnU99xtYct7mS98zf0qnva/vjuqm7ZLZ6cyT7GNmU06ZXovYYyofeF1sBqVoAAAHLzJyLyJnl/mJLAKVF43peNXAyFkrO3ngHMHCUIKVEc9GTD37XoUVSx+JLiZfR3lprE/SFlyjzmuI73qylRbd2O7MFaf3ssLqL1lObs5F96c/q9v6vzbcvs3ymruvafm9t+Zn29ytIqT1bVyt6Umk0o3bMrnzlbb8/m9t73j6Yn2KdfX5vP5BSjbDv/k8DMfejXpElEgDiIo9FN0SSjTBaQq00W2DzahjA15RoGZyCIbENMeEX/+7JEEoAEuWTX4wwzYpEL6vw9JnhRoWFfjCTOykosK3GEmjCGFxUuu2fNNwk9pb8VJgf4qISsqnry6NHBCTJiAcsmHJAynhc7yzpfVM0pnGZTEog8zSjTVVN3O05Rhmasm7un/P29OzZv4xXUgyeNjOY9cvmntE0Ug0RicRj07JvlwgJTPPUI8p+sph6yNfYqGiOjeQhCWtIikQAYKC3ygaQN1RNQkwbwtZOiTEFQocawqSYgSCjQCDkpqCo7UxMjJkB1eEahKaqQkIjCIlplM8wsnIrk182PCjtslaHjbOeOQMQ3UPBXlItJl4XPfDkLq1lTdlZKOYhZTux77dNaXSx9rlxsFMgmq2owm8RaK0Jay3rNu7RDtCZJ/P2+UTTbT79HMo1taNvRtKQABEQlPNZMAQux+HZSpc9WJdbjITGLsuaHEKgLsyEQARNxADalrkJMBSJRFF+HxPFApWro8vZSg1BPC5IdexIGnRxknT/JG9YsihEZ1GGLsuXOaXtoNfKx3lQmFOmixhqPLrGbUTCGXN/FcrXPxlxO/c7TNO8+8xmu812Rft5mGsyuyvJf/t3NKgmokGAAAQYiyDZFNHbKVNKX9Fl0QC3J7px8qaKPnfjcaGTODQ+2oudB8h0492UTYxsG1dN60gbuE/Am9PDFMGXCsRTWSTtqMLwl3ICUEb3KD4QJGY9gu/kC+RWs2DWqgUYlJMFPSDEWENiNmhjCdETTMdXLz6iVkWqNnSaOIc8vY2e6i8iNRwaJyMVEamCKKdVSdClVRRE5AAIkOsLTgKIhu66PSVoMElez9icDrxdMGC8IR+fLpyw9AdmqpxP/+7JEFgAEuV9W8wwzQpOLKtxhJowRrWNZzDDMykos6zmEjnnCjGbLzzM7IYQLHFIo4g2ljUFILPXNgrikmBjwgtA2EaQgwGsekmXK1E0he9SKFcpuDoGajROWlatrMTkQT0cxNBM/Kb62mFtFtH3YRZm0unZlIFzM/5qDRjYLaSJAAwqm/e874oj36yjQvtgjcjBgAAgTNm0sQQiobj2pzr4lEMNVX21VpkXqs0cCccmSobshFKBaJGdBiDUmkv7mYac0igz7TZOtrTm6VxQJz2awai41N0l21lkbHPP0jBOAJHEGOpz308JtSLmVy/uNS1YiSVbklizcm8O2Ti51Fn39BPszFW/e2vtf9mw11WCjZIyFJiINDQqLhsClm3TWe0K4wRogkMAACMKbccUiGOw2n2OgYg0x+VDWAK8mAGmA+AwRTJgZnrxxVjCyFigvpg1E22k1kXQoqcI0OJWqV3synMplEMoOhowzys5sMQCxtBBb2s+KkMFMcE6eBG1KuSh0sbptr9/SyO5ZdWyGGO0HWnjKJFXpdS+fze5nh5+038kaY58aShYH/1+21fJWGSRDERQAAQNBIJVQRbAiIZOAwRVYRRiFKyLGc143Ggyu2t+PXJytajaBmojpAJTz5HbO7tEjUdN5R+SCaxKrkT2bfQo05FVnL02meXn3iiLaIlKIoGPUXosxkldeiX0fMqdroo03CEoqbJ0GscOwgc6OiNQQYdGgV3EmwlKWDUDzSlPbymGkZkEuYmCVvTOOVypiNzlVQymQBw31Eex6ALYiKFh2GOL1UBKAwzQHxU2F2SncE6lTCc0YCEjDuRGabBL/+7JEGAAEF1nXceYc4oKLuv9gw4hRUXdZrCRxyhir6zjzDuE2azQZ08ANlUUHDugoycMV9ci9s1N3xBsziWVk2VqeLk52Z0MdLMQHIrdFqE6D/+1iim3OEfpmfmY+fkxkVWGhmp5X5ZBxR0CtuTNIcCetOJ7/+MZujLBmkSJAKg1JvbSZgtN5X9LVNFXC+isjC3oeOBmDRFv6S9NFmkQQQNJljARGRZA3VnZCSNJnJ9PymmeYSuYizS4myuSACDogsmKo5D0aBnXUZ0i2sDJyLcVwsz76lOvYDihi9yOEmaSaGen3h/SypctZRTRxJcaqQ+tu2OvSx/0ZppyFEkkEBQEFeayECEwQlvFtpnMFizSnlZnMOPRae7CaoDlY0WbxxhgIyYyUYTZuk7LTXkigms2gcfRQSm+Z9F7hetrakqnu6tSxdjEzTVo7WqCBVhRvOUvFk4FMWtlrVjUzMEZhKRjjkZylHdGHqqphUykpipWkzyrBzZULw1YgdAV3Q3e+uD4UcCgqpoRSAB4MVACNCChEjXH+KeOtOjNF3PAh59Kh8dhBnfLsyM92dSRp7vO0tbyBpkks9oyXhOlMr6fumbiKXV89/Vzhk0ghUOeWESZVdDEmdaMXuSKueNH3x03d+MOLLNYoLuBtkqHxRwGbxoOLCkUA4YEJYP1yILCosQtqLTSZj2b/5zFTFThEQgaRAJUT2qNjJBD1m7MpLBWF4RJRVw5DK3mssqdCZf+YMSOqxP30ywQZ6X/dBeyZeKPIoVpTSXVajiS0mIpXxyJ3RoUYWSKQVDyqkb0RqOyUPF2IzjlcrmO0KDzI7QZQWFO+0BT/+7JENIAEFFpW+wkcUIJrurw9g25PlRlVjDBvyfQoqvGDDmlf6C2yhtox/XojNzgfBgFCpgoRHsLGj0mulEMyNEoAI4hU2ASQA+eGUCHDrUajGmEPPU0xYSADC1cykUSwvSZ2rbG7GQZm02mPR/Dl7Qvv166O/4sgZaeqyRm6HhA+EFo7x12RAwY2gogcBtQQVICcI5R37GHFq6bc5FCko1z3ZLlpCY1clQiKEZPCSknG6EMMa5VtEBcJ7feznAkYQcYQkAAi1MM0oUCAk0tVZLQXnwaOkg4znQ1NNuLc9500xZ+NrMHiUl7uP8z7sCqmu7HzfOR3dWqsSPdx5eWkkPUh6rtvtbDzESBQirozhs2tDotOVhxiNyziJPiPcSSGR57bUabgDv5rfLUB2w7vIskGl1euG7rf/ur9eUQ2pkKCBZZGG5AMrLc35Ug3Pqfb9WxYBm7YrN973LyiENRyz94lcCpFhyg2XmTFJJHUc6Xm1HZVkrpWLWi/FqY07ZN3KcQTcoUZZoxhQBZwL2KxkhEinEo6euRogxVEbT9VQ+5Dpw4bUikmCBm1JqXOCYh4bd1GqV/68316iOntUBSIBLrPqR4wUtJRpjNW1RJTqgFYBV6vnBkgnovaQkgBcsO350bxceXf9MjvuuY3RiyaGql69gicBMJYcUR/ENR4iVkElbdPJ6kYysoo4LUdDOiYWpiQRekYxyLh2BoX1kJX4DAhGCVb70gUlO8hGoUKxoEaEwlXzR/zHegM3NgrVWnpJIGyQQnSVzr4hgyRT2MXlaGi7nUZ9LVjRA8IIIAyPSsIhTPaG8bv68Op+7S62E77ss3/+7JEXIAEJWDWawwbYoBsGs1hg2oQLYNbrDBxSgkuqrGGGaFj8xRkKZTGQbRRhiQErsNytTKYqWpQVh1xNsp2jj4xH9hXmW1eTIIo1lNKDL/b8OSwWSg1szftEEiZ12lHYUm9iIOg5E3fMXKWRYAJrUk2dbbSILoyOcVTeQVK8MNJLI8rcfJfStDquTffN5Gh2rUkcRvhzZ9LJy4Wz/P2WVPtfy2nGcC63LJ+Fu8WWfq043yg6DlWmHDAxUMUHsJvrFbSa2ZzPK99rObE7kd4VyPvy5l4xEoxoUExCzzMi88jMtHah3e2dPQug20n+FdTUrxsYIRUCwbFiDlm1I6sOI0RymQvkv1OtByTRjjkAgM71gL77EVUnP6oJlXtz4pCX/wp6mWGVJZNotqIFsehy52fvYxZ6T5S4eDmnpZWRLt2xFdtuvpzZTTaHey7fMpt+53n677V1CN242i2rMpC8L6aOz7Tq7f3fZCWrxnVealp7+VCNUhUUjiZRALTAXm/pekoJbfJVYtexGA2nv/FmWw5Ts8LnOs87WIKnsp+Xw7S40LVaanl9++xSSuWV0Wc8yXP8I0fLsEu5ilA1A0nFIwZK4hiU462xZKTN0luj+dnb07rS+fPy8jt8ybiwvRMmOYU0zyM2KMwMbhgRwmy8RBn9agpbRJoAAUwGdPSuUCBlLwDgmVue37KWRtgordSAmCVYzSQHlynp6/b9eINmvX+2C0iRFlHfSoqadJn3axziONQyWMPm9g0/HaYFZmyx6baVltMyvaYVlakctDv2WxxOQaSm0LQTCzPDHC8vMjNecdMvP5lRhG+K8pT0ju5s+//+7JEf4AEAV7WewYdoHvrOpxgw7hPkWlXrDByQfguKnGBmvh2REoApolTSlScYVc2u3OYe66dSVamMN0tBOK3Ik2aegS2g6alhNgWOOheFFzBMTAoWuxDB8NBiNYNECRVDM5cMwJQQtbinChARM5dsPJPPLeU3JczctdEPMziP5xdWuVMukfCvELaxN8/OlH4nsuG0HDqLLCqbHN5nUY6pQyAA4RtZpANbIjRRIfJuNfW+psqRmrwwdVygdYWgnK0DPfjehmk3n7Yodz19C9wiihAc4hejCbgvYCZDD48G1bcOfQhHr++aGhmRFCwY6Gd1cTm4wN3zzjeDnwzzMsvPv+hOpFnXM2cOVL7U8YQiigoteuU4gAUKS7plUUIAhICAAACMoFFksCmEoDP2XmGovJrRQFCHwXdZvwM9KJosPa3gqbCV1oIodTcsWNw4opsHZhpx+nGEe3JK8qS30W/C8MqmP/ICkvgKfvHEMc8Kryc2mOrOwEvJqu8tDoUFbPOsgeyi2hSD1EA8tT7FFnjXbPdX0GkbDyPudBYGRh4GWpkKkPJxV1V4v7MyxSdGdDRG0CUTC8BFZ9GXNckS6XoX9D6lLiH8OZaQhuVZoysmbIGE6lYd4ukSlg61H1m93G+quCuUa7J13UrzMLMxnVB/DLkBtl3dXqa5TLRHehyplf6pqift6dUen1/+XgxRi51wpARpJHqZHDZIEAICpam+n4OfIHAJYzby8zdFYXiUgn81+diTDBGFyi05UgqzoJE1LIB0nIkZOhrcTlEkR7sGfauZpGcm/tBmHRvR6i62yrEfSWY1Yp9plDGsJCvSRkvgz7/+7Jkq4EEfl7TcyYtYmtK6s9h4k4SDXlJjKRzwZisqrmGCPj/tb+zLqnrWdVCoIACCMQAKb0IdgaGoUuBBfQUPZoeG+OvqqHmxKADfhRvIR7A7CSjsxCViuEgbqBBSAvrzjDS1g2TTxN0eO+qOnBeBsLDEzVkb+wuoqfC9eKXAhyaF8+QdTggYpJjMMrO5FtdXqYl9aDo7oTZy0tYm0K9mf+zupNk7potnTdE0TsFEJkUwVFdCv1o/utQa2vYlawxUxWEAQColxEkOL+kLWP3kiXQbRurJmfQHNNvLmnq08l91w1abTdyyASGRSpH00gbWREyCkaEzFO8EUWdKXCs5s4QxKhYUMMBEARtCMNiGykFWlziJh8u1OL3+QdgGaz1Coej0jPzHPvdfOnnu9hknNVId1oqClaKEc8eU8km2OrFEgAEgAEja0NF11jbNjz8IAkwDUU5WkqJku3sIesK3Cjb0k49/tnjReUJTUePy+mMewfoNPuM6JEBbRIEh0BA0IQ4cv2XYxTxq0HCW4oORcRGaSIW1mRuQp8CGlVME8KbHcTEta61y8yrQ1+32PjNhmRHWncXSJwSPvFw0kZY5dBgDDBCAgIABoTrb+iUJ1RLeDFRQtOIeZhpClFdUu4VJVppD5SygYTCZuDQdBq6PhQfSlZJEVlFEbBab8mSw0TIdYJkZzEBa8lOChp0WF5NN+cBWqidrblv4ZOrXstmxSJfDYr5DJTqF1O4urmDmDNch7kMSPoZFI0qqXCM3nTvcoXIa5DECQ9V4fJZzF6Pz8bEICwCEAAMQNOfFR6k+lE1woGlAqmREvdElO2AuHSR1pb/+7JE2gAEDF1T6wkcoIFpWlxh6D4SCWNHzKRzyi+zaPGTDug0fPYT85RZR+Zv6xqMhrYW/mVg50mL0XZRAbOWGk+kgLVnS5s0pyHIx1y2HkydpnJIH4FbqjqKQFad6DNZR+4tjkr2zYyYldbQuubKRoyo+/Ei60zjDJHbI3/n8SNGGKFZtl6tYf+VIzXwamRDCQEAABAVeLAyUEKFT6h4FFgxhkaUoOKlmEMKFISNQc0dMQwYKMuvBbA4OwZ4CJ+pAoQRraxEVDKg8iSpxa4eIKESyQaStNr3Lg9GPcPpOniouhlovHk6cHBpJTUqrQ2O3WVxzHi46UeVrNQyNCt4HKH06CplyF/ehV8GpApVLO7Gjt+OTBape+LX5oX4J62Qd/V9ILQ4rONT6U5eVFbQsphZmroadoUgABYDiwaCqMlXC0XSf6ZiBi+0+HARmXS60+/6Z/aHVOPChphmd69Ztypm+Vufny3atT6KMYFuyLLNzS08xBtPbKiIKqbqH9zLQYRz+jsKg4lCEe54ZlXYEHN8rQhiV7/g8j65GXsbZmRYakSIqGVlLPyQ8PN4Y5OCamuMK+hgQIkAGsKGNFgqFnlutpUwObUFDL04YeEYa8GCNVgtlBSi7r6Q2tm7GJppUZpZiSOi+UxYhy3NS15rVyJRaGaPKnh2O5xuBJ35mUu1ZrSZkd3Guzrbhzh+5VCOd51pZQuspj656w/hUGyONlX9JTK3LpjdfMEB+efeyOa+6tjrIuUCnZgJPYldOgfLyWvlDENzqrWcm/w9/5Lbkp8YTf0e3rZpvKMO6WlclDcIISAhAJgXQuuLoJBkkxXehpD/+7Bk8gMlKl7QY0xE4IHLOjxgw7gVXYU+jLDcgf8t6PWEDuD5Pwyp/2vuy9nwYz6lsXE3km8Yfr5Z1rlCx7e+14llMH5amcjqYMUgsPgZEHkWe1Wbdj2Iga9SfWZGIujjkmlsZTGRIpZyLZJKIzaTpLIYwUoPmJsXMukUeO7ZfdcvO5GXwQYMIehmM5YLCjTPSrhRWA0AAHmGwPGgV40XhD4NCM6Bq4OFDDhId7FysLcPsZWHWzfcCGX0W/fWDTwo+xF+BCEEid8/MlQciNIoKJHll7Td4yGdpZBLlsnhdO/IoIp0don92FkVD6YqQ8vhLpoV0PaooSLjhqfC3z8jLdbVL1O+Hi4d5GHmkqrnW5MnSogV453k0XXtvUWWlKR/gdgdnDsRegqQAFAAHMpNcgEOMiFHVxWDlzC1bow8vFAxdLBnNy2NE7i8qfaXVc6Z1a2U8yFcVihqQ49v0ztNYa1kvIHhJHEiUlFFW2LmJpPB+OyTETDZL8oYVzv6tkC6pN2KGTgnVfLYEZ2VUVbfgZs6Kb3IKSD02FPo4fZtFcWYcwZLGZP8jU+R2gBBGAASBbHHoCo8YZUjQCgMCpWCBhCoWFmDmFgDSxoGikMlxQxCcZSmkSsjW2cAMFlyUTYRa2cNG1Doc61GhasQEISQM/xIfrKdq8cvH811QeeJ6gkbU+O1TDJUUc0BpM7ZVkVnExhRot0UpFTcKcEpzXUPm1F33szpN+RKP7QcjZU0i9WaM/Yw9MsfYNZ4Hb6dZ6f0s+98NUzxgww6bEDlPKo6asAnEQSAJxsgtGhZRElry4wQgxLWGViHToCiqKNPLTLJEv/7smTwAgSpX1FjKUVAhOlqHGTDuFShYTyNsTOCGScoLYMO4Dz03SsCeTCQvUy7UpmFO4RZ1yNYsySBVghIoqjUexDCjpJT6OTnAI1JCJSICiemkSiBu6xx9UpFtmTogQTIzsZbMpCr2GTmMUDIZdZSd7mfyOwJLbL8ELHqOgqKE6RwuRMJA3O7qkIBGBABKQAKMghMyPgaQYwbnIEbU1kaFFEqUdYlZa1IHQDcViIkNxZlTyqGQWB0RSMqoSbmxIjxQZEzoI0eVIml1j5C/o3V1EaDIzrfJRHRcaZ9wZyxc3O5LGfUWp1H+BdEx4IltkukztlWvSpO30Mv0zcmKlcfjZJnahCA0ejujDcCG5pqIiQ/FQKEI9JWVUCACT6wAMlCCOPIMg7uzLvP/6zrT1iB1kkEADAAIIyXME+HtYKAW4ti2qzceCZkAONSDsEyhwpUPWMRs1fORRhscV+GPPqJr9bsm1k833hWHL/TDBbbiDTlpHpkz3jlx2pshka+X3e79Rj3X+xuVzFbGbbczIL3Nd72aIIQ+nvtX+9p53AadvDuUfG+BBZ6hYom9m3kHlp0UZ4R13SLGqBAsQHQBROXBmCzZpqpMJ7DOJe8aRY50FDMRa/TtIcsMRqOPGbHLr4t87Ekd+HydY/jU12pjbIDc8RLCTFHvRfV9k4tqGdQ7xxH66C2VWnr0rhrLPEASzPtOz1VVObm3DwunMSoJ3jLaF22h7aoZ5NVee2nYR+hKdulv6m8BZ2Yz1F7NCkWHMXzKQm09TAkgDNYIrlkgWWkXWmShtPTMKTnGzP+VVXmr/IK5QQAxoUIbq2Y2FaSp2KiAf/7smT0gAUnZtFzL0siiivqPD1mklTFi0NssNXCCKvpMYQO4PQV57xEhVZnLqqffRdy4LPNJlqRqPZLalixLKZcOW/zkcPSprGXBw9mRK0lk0HGLZgTGTwnnLSZgEbR1YSFsckkEnWsPLA9ybKeTrpAgow0alIgwNGXiz+9IXNGuYz8XFSGfmpRGHxCbh1Jwc766mAlYAADgD2tseHEzG/gAKGgK5GVJhyApWXBUYlksWmJBvnD8oTuVE8YBHRCLhLjZhOVOO2fllYcuUdetSJx/UpEF8VKltacxFr3x8LCybvHvW2Jfmvr42UQ8Pun9D6qZ+OOrAej966LehKeRzdST98xdehLxAtLx/T2TGNRVYignnVssL1TP2ce1qH5gtd6Dy5/vuMXq1t7cM7WXURxpCKgxfIMLsYOsIhEdwgCIpw7K0IFFtqqkJgxKmCRSl6y1sO3Kr6aa+7UOXxp66c7HG3LROH20uwWuuWsR6UNlc+vdUObZnm0jxX2GBKfljEGxELQs9pUzqIVtCZ31Qxrqln4XvV/i1N6qNpfmPiIrhl1Mb408g3j2mIIqDVrQh6g8gC3AueI7cARDGoDmi0nUsDeoka3WEAMQFyIlG3DDjhiQ7pzl5OQHBobgeWGQy2ci2mQwTEWgHLB0MzyFK9zuIShULDc3xmX0PuNpcJspJsK1WRoMKj6x7P3OkFrYXmX52OFaJBM/g4fuKATE0rkidM42guBiMYqof4i+zwPVsGR6l41PVkfjSpQ/1TSUICpEikhIkXVaRNJvZfSYpamQiVQ+paNBqeTZURo/dQyU2Twueg70qwwjwgACAGBYp8VdP/7smTwBxUnWtAiOWBwgSsqTmGIiBW9eTyNPTGB5a5ouZSOMPGsUPX4nyBAU0hol2RACLkD25deTRF2VRX+3T77QKFr2Ywjvo6z5ux0m8ktyU0/D1W1s7vPskjSc7Thv+bGqxEto103M+NjsxlLr+RgYUtVOlkUfPVh9Z+1+Z+MfIfLtwy53wzTpjMWZGEBpfrq4iAAAAUlFyT/Aw4aiSPS1jl4CYYVmyIWwEQgQwFAz9KqJoAbwy1fqxjoeZPUWcd6mOx0dEbbYvP4Lk9ctuR+QE1I1rMGQuJ6nHpDk4RWpYqfbEiZNoPZxXOeKQuO0t8E2xAJJ0oovUu4drzqj5K2JDHIeznbG46RsNlSPP8sVPni12BkSK1W3Ymyg6vAdHp/M2diaOubuVumZ9CmB6iqcMn76sgs1GcVxT7NYYei7LWmVQvVPTvoWNuaKMQAJJZZe+K9QkCIzEGQLAg6SMKFj5H8n2JYeIgUiI/qnlusePB7zKQD2rmBQLvG53TzESIrhCRc1OCVKmK2Og8c7DBKTw4bOspkcz6EQdWhFU3Pjn+K8l6E0InN86FjUv1BF6sT5faJL27HnxjbZz6ZAi/IZqdKCaABVEiko+gkC/wVEU3MYYGyETYYZKRCYEOXo7jSBKY7WGk+Jq6r1JHAE9QNaG0XCoW096lmBluEJH0EOwweKRLCgdlq59x1oDJpsuFtfc4HpAI2D+OSOErFUeOVDuO/wCodus2rLLqHVl2q4dTeRSanuf4ujs0w3riiPtQDN6da2uJ6bNVjU2cp9FDa6FiHJYef6mP92705/dLrNZTOP/dpYmYsBrDFe0VlGWSAEP/7smTwggW4Xk3DT2RSequqLWHjThVVZzcM4YjBzCBoMYeZaQBOG0JhEJzl8Pe11AoztVvdFgxaIbmUsmoiJFhw+ypneIbK3UvZdijyqm/7asmdrGbVy8pPAc73as++Xm99lv78fOs9bz3jG+et+Wz027XyGZnfu/ZhNl01G47xO61YGzjv/n3FsJf97rUqQYm8aoMAAAAxMIWQAwHGUiQZGh5gcLAoUGEwEEAIHFRbibQiDQhAq2YMVnFQUZzASGzwQwy1i8rR4a2CQHF1wlQAHgjG4GOS88j/Iwbpw1ICaIv0e5E0Lma8cWokackLYLcadCAEHUT+p0nggG8lSvL+8qmhUUnRRDxjuj1JI2OK+So4W6Ek3TjpW1hbhqc/sNRundFaKO1zC2rS5skdiRCX2AWBjMTCiCIjbV2JU97Rh9KkZt6TiEjnVGkHbXROkkgh6PT2n5D02L6uzhdx8ZLJ7ra7KqQnyAAAANgfywT+rQI+XY2w9nA1NHsEAZ9PvhI8JSnlbtZig12eM1OA2Erh6rE3tRaW8jkNSkVnVEaKSxQQlrclMEHQlfiqKd3HzhvIxoe3R3rcfyRpp+yTNVs/IhI8TzPKhSW94mQZH5Ttr6rNWt359oRAEokPDBCBCITLEUYOLomgICBxATGJQAqVqPQ4vZ0nTMIGjHAxyIWwNYaTzLpsGSOhto8HMwsyq260ajEqqyPCCYtAVPYkL7XLsUYDM02NzEXicBWnnzz7YkFpCbQh+DmNtMsLnUKAlxIaGTz7EM9T5AnVPSmIpHajjU1YIcEM3618vf9YurlgkOctgmZTonZddrWrIoTgTXoIsP/7smTwBgaQWkvDj01gcelJ/GEjiFZZizUtsHsBbYxoZYYsuLWOwP9J57KoGBE82gMQaHjkVQywqHtEE/TSAraIMtuKdA5UuFzA6CV5LPQEjiXko4DgyaGJwspiQ6vfAXOa5m2bSpRkP9RwJGzQZEAfPiUoSQ4LSjxSppV6g+hpEMXWnmjckvXI61hEYx5uyxPQ+liK6KI1EAAAJVQ+HgJAKBQMEQQwuGE4eBxCfa+ous5eDyPLKV3g7vGDMIj87jBTK47Q14fgN5Ls5d3u5LcvtXYluzqYu9noXYxuU0Wsam627vOc1vK7U+kj9qvQy6L5/D8un69jC9hXww53PuX1r9r88ebzxsY55SjmFikvd3O1cvtYV/1Z5nuZpcO9x5vv63++3u9z3nvLuG9/j3V61z/+V7pb1Jn2K296vXecsC0OTgqrf8NmASAAARRVYqqxmhmjaRMF3wCSBjF3PcsLIkelLGzTYOLMC5Gk0whprUsqiM7nvvPQeyhi8vceLyunlUWb7GPx2Gq99/6bt5+3njOGMph7kQlcU3Py2ITFqM012dqxBpda9ZiTT9TsXjeczUrTvInZlGE3K71i5TQ/WylNum5hrKtjalFTeFJlz6Sht7t1rfaC9zecfju/ys4/lu1q5U7zW8c9dy3/NVO9+93ff5r+Wd5cvHwAD6mKGQpvAGoRF5bEgZBIJCYdMrg0KtRlQIaC4mV8ZmgkFTMzc0Kw9CQY2ImogqkQSXl1waZmWj6OQs9KARqzxkrRkxK90oGnllSYQrEFyIwTfsChKtOW9S2M6HUMa4UGAuIAxEhHByhE9r7IGZtcceNq7CADZv/7skTugAWYXc7VawACugs5mKzgACLhlTm5vQAMZbKm8zeQACwYCGKAEHM4Cg+BPct+7rhrrhTWJI/g0CBwUIHKeQlNJgKzFp12ZTahtTiNepfDz8Py58CrScRQJdL6VKsr1JqK1TyaMQ/FL7jtPgWpKFow1I4y0ppUy1+URqnl9mnqUkrppliD4vO/0eqOc1uGHcZyztgkPthgKrMP3ejUgl8afyWUfzco1P4Z/zkHwxOwxDT+M4r01SL53N4yp5XGs3t356I9x+6iAAAaGQIAAQAQkq+MfDTIQI2JtN5HThy47mHBAajIneGJRrJGIi0yIOCiiOjRnxmZ6LmSk5orH6AjyMrkxpiismWeKBFCQKODnwgBK9irLFYHJh4EEmcmZaa6jHLHFTQPM0JrbZXSUKXYrMRKEwxfZ9wVsBCDqMCEUg5pnFFG4zHwuGSgqDIaFoJSX6Dgks4kwZFCYbagcRxZ2YehRSOsDUvVUXArtnUFxFvoouR5GwUdezah184DREcOAJdQvm57DKFpDx4u/fiMBxeCLMuksjtWaSUSi9Zflt3cmKG/D0YhuXxyXNM46UxS07j2JRhuHrGuT8vuZzNjK33jquZK4hfvvBIqlNO56z7NPxS55fS973l64HGf/21VAAAJVMJiMsdMCRA0wxgYHQSI8XHMoCRsCD4XEt4KBQKICAYAMmhCBfQQqF8wMQZYUuRIJ8OcLmFESECEwQUQkFdImVRunQ/UeTYVqOaLlIMmPRAR5ODlDPFQyNxgkAXKRkW0B0jNEcXpqXTVR08iip1OtSGklrZBlIIosspuashdSKClVGrqL/N0jZzN6f/7smRHBAYbZ1IfaiAAuixKSuzMAFMde1etMXFCCa2rdbYhaTppptPpVrN100bHTelZc4y2TZAv5gTiKk0zxcHMIORBRXMDVAwKBBDeX1GrLL6LMginutpgwAAYAAAEnGKqhJPfoWkBW4W2PFsssRLjKQGlBSQ4WtIzxUBjnlkQsmCyEDXoEAS+SgjQTcWkx3HCTMiuVSaKQxxXJEnBdIFkgpdGdIGTpRIsRYixmQ0iRTNjIwc6x42IYfWXEETIyMUUWSQnzybTE1PK1ooqZddBAzRpoItquswWtSSz7syKVExWykFuzM6kDA063a2uzzhMMtnd3LjZuQ8g5iViLjkFQyLxRRcxJsoHjiCPL74icSxJUgYEBuWW0UlFyktwsHAU0DMAwmYAiIRL8saawKj0yGcrshlLhzI7Fl7vEbS+drT+RurdVuIV62IzU9DvISV1bnp0UslgtU1Cfe8HH/pWubUO3opraInW2plFQnY7dBXqGM2M0OaXrtynC0VBLIA9qLRSsOM3pFV6ZsvdJMfBq4/b0lq21aaBjG5SLfBpUPLW1k2+2VWqWTNykIhAAABT2u2MXmwKrp2o1RpOodEkVJE/yk3FWD+EIReK0BKLVGuosccXdEt6LfoD9VjPxSYzPnycmLlnoOqJgZSrX2M6geDcdRA1aSoxjDR/PTPF3FXc68vF9qJm1FV+GHDHKTUtqgWJ8056o6KYSNGQcIrMbXMNUOgjXJffIx8C2lE2/OTaIGMLoE2qYDwaTNABgBCkEA8zUNx4IkyMFQyZMA4CfZWJwBWgoQgllUPx50reU5WM8Awegu5CWigoCEDC4ZAAbP/7smQiBIXpWs+DmUtwhauql2UomFOJeUkt5QnB2a6q6YSWYGHaack8udE6NxSHXkzhc0xp54tnUmaf5KuGZ7hUjcgqs2iE7EVvRUgOl6umJrzRm2pRkxKYw3ItHMt6II9FBLPIlP/AyR5UWfYkWZ6U54dHHtqoECe/GukQEhvXvl1Z711efTQB6WqMQYTglkDg/PGkDGJLFTdUzTWAgFqRt41FxbI/zhNSMkposAtpymMixQsFOOmrK0iNqNuZKEsZX2HGKdQHyBjsyyxvVTUSs9+wKSYRypCni/pLZ7rjuUSEFd72z7wHMmcW5MCiSllPxxLWM5p9p/W/1KmVv5747n+uYq4S/aZ6qOO6n65a6yyRdlGBxZR6xjXqEm6V6f9vZAgAKazrJ43EDAQyY8pkMMZQbp6pmGOpgGDkHU7DjXMutAkAmi+58iUUYMgAISn1mNNUVVidFhrsFwYXPLYka0cLVKqyU1sI5dOGsProMn40FohXHC4cpBIZIuWZ/wapFodciQ+mQQr2a/k03l1qKq/aN4atjl6iMYw+4pTOpXRTW4puFi6juWJO2Far6LhgFomjRk75cKLMnIFkqQdBbksnAwy5hmOXjXa4iTZAGuzFNRqKHRpC6nHvuK1ZTpkMxMKqN1ZnkQs40tK/UhFTdJStMruRSzUq6bWqb+6oeLAg5SsbXczNW2Zu/orPzWzIgleUj1ZH5cyHm9Hea2zYiKsm2xnVlwiHjlQMFX1aweD1tikqAKckmN9KQgUAIwCpM4QKKDVPJWYAl7PBobCwW080TvEmEjRjj6M4igKC8z5SJ6WnVGv2kR4YvuG0WxZCcP/7smQehATKXlMbeEJibOeqzWECjBR1eUdN6QnBwKzrKYQKbBAFpDmFh6PkSih2geNjThe2iBOMc1cIV9RszBVTmDYqnLnKGF08x40TTBJa0zEeNVOqeBow1OFmoKG8FGjveOBr3jb/or0i9WbhK4sWtBNQzGhMLj9VaGEVpt3VQBSAQAA7vtuGIO3S3qHJm6UzBS2EiehFmLtfkC1GvRp3XtiT9UaBgSCmUwmo7aBmPW4/1PW5/uy4oh1Ya5bughjqGXPGjRjHLVjzXGZS2Ntd9k6TGV7xhc9KuDgVU8olZ+6Aq1lGLOtG0lcOTIGAACbk5wG6ZYbGGCBlUccKdmblBgwcTEZmQQYIDhiZHox94FigqCAS9NE7Qh31gEdwaWa1A7yPKrE77XX3ToRErPxIWHS+US5WONYZ0MwcUKEmcD3yxEc6IHJAS6WJzBjNiZNyothxe4oLVIhHM8XVcH3zR/H/iR/m9AFSCdzh3Excw6zE9ZT1zH3HXzEdR1dcSS0A2RFYee2NHdlHkEPWZ5OwHJCUk7XdxJRPU4vS1deVlCRI3G5Fx3cS1dFtoTTTzZslarNZu0ldI0sMiYSgkofuNNDJ5g0y9w+Spb7Xm0GeePk2+QmeWuJqOOjGllXuSqsuy2/62S6M6lQlH5WnZWsjZlLRk5WmR2Mj/uyGVRrX1QAE3LzL5AFYo4sGYUZ17oayJjQQFAQyFGQfDnGUmoMYspFQKnFUwW0KK2DCQ5Ku66JUPpLT9dmLTkkUmJxmyHkPz0Si7NpXvlymsDwcC43sgTY0IWvKU3Dw/zLaSTVHdCPVkBAHhiixmsJft3oKGauv6//7smQ5DsTkW1GbeUJwcYh6U2kipBRle0Rt4Q1Bo5FpTawguF8jPm9h8nSrryNrmJv6iuVrFrvnh4sbMRF5VX9jHk0IxMpZzjsP2GSmdoAAUmvNUoEjwhvAdsBmhgC5QDITMhXOGWlrio1mwXGLvgYuMPAUOarn+lDhEwJQ+HYwm/LXfDaGB0ZRkSjMSzEFXkTEGf7h2dwlByQyTFyZefUrOrHepi6lpluhCf3WrpQo5T3x5kBMKQjRXusanXi675LOZVcmYGoCGjOzYJ4TJTNC8hGDDVsDBACMSQCANMY4QDRuA0jNjW4HCUrHrCnF1qxRpL9/X2WkuIatH5a4LrLFlkTYa1yQ6vWpKYHgg6Y0G8S5/wiD6ASeUEOpYZA1dg5WxAEofmueJV5sIK4HXBDjkDAgzGWKXK2TxFdKKTEvNDQw15ApeSyTD1Ws/HXGvHfkIl9K0i0TLnpU1D+OWtYo/TUASnXuEajvmzKngNwQniQwaMNMeYqFAQH5QsDHByS/DxjoluDgV2NJ+ao1KYXK0yYu4oGyiCRwbK4wm4IDsJSXEbzH75ikY3684UHtaqbAIgA0jRJLFWCz3CrWVU/6nWR4crXS01C9fU0AFOS8U2nPHRc3QGJGEkGFY0QjChYiCRoTbGYaLmDAhYCCIjQFIZI5sLWgWndOMQCiDG5SphDaVDE+PQsuGLNm6v2UWtYyhRIii/lG3A6NjvAdrmYYSSdDNSPDBrKoJrGXBI9Rb0BXRCklOaRCQShTX9kfAP5Wzvor0XBXejHSUhYUYdwoRnzHTH7AJVmvNktPO7NgaMuVBTICpCzJeaEOwLWW7AlIoP/7smRThIRSWlIbZhYSeOhqQ2kjpBJVc01NMHVJzJdpnaYaCODiZaGCSQYni6IYpeixLRoGopA0tXiuKAyV4lOESEH20WkFaRWHp5DPTOJZEBM/EuMvTz7w8IKNpvdRb5iCMyMvt+mX/nl4MHvCPyokwQyK2OdZUoXax9RN4w9MgQgJ3WXmdyg6MCTprwpPCHTCJAiEGJCL3EgUwXoMAJLihgR/hIGUA46wRESB4rFlkXoxEphTEM/L5NH5+AlGc1mn9CSF70zkerRhvVaW0xM5nJYG9o7fMeV50S05ck+Me/4VnzSfzCiNjfJCKutgI5wIz+V4LhcJNNz7u8iV/SmdNHlBT6dphHHCEAiy8Z+v6kduAJVskokvMcUPGGMIKScAwdCaIRcHp+Inu6yBKFdrH65AAoY4gZG1gpDoCxgmIAZkokdFgZaEqNJteoFR7+lM0V2k6tc9/geZ8F5MU02Xbs2fc9JLBAaUcPBEeTEDRPLvIAcgyJ4fe6QnwiXqE+92JAG/HAAC5LTgMh7sBDYkdGvhhhKoEdhVfGULINMSXHghEWGAK8yIsqKHEVU+p6nnHubzTSqRSYfeSAuK+YeBlDno2+2z3TZZaaOz8zWvJ4XIRDLZ/fbz/lQmUc8/c6TBhyTiJOjJBYLEwGwfBwQFAeqHo9/CY2SLlFOp7K40JoQ32I6FyIed8lE+7MwvDAn2qLCVhyFgY3xOCFtUAkBCE6r7kLgNYwzbmUisYE0wq9XGgIYXBhNNbV66JwFOCvikHFvJPBgIsnbVQ/2dRxJDoj68qvf6ziHHgKx5oQADNv+4gGW0L2rFYKxuRQxP7Y9PT//7smR2hka8Z9KbTH1Qnawq12DsiloVn09MpfNKeq+pgZSy8MoeGc4+F+SV8EKlRW0KFyBKeq0t9nVU3V77aH6CIeUWOfTmHNfbjPOvdCUTOw2OFDkzzbq/IsgSFVdjnq+oHAGKOLzgDhIiebBBdL7DhfMxDXL7KS2dlsuDon56Kt1iRFRvlUWNjmW7lRw8bJYEx3t3FcnlI9OBAPOMOYcPztXNOm/QGAFv6fgAkk5DxnDEYULTm0WbA7N3SDBL6argF0U5l+JrNzTwe6Iew2R0dOwkxFwlCAY5MTGc5dbfHbiUjX86vF7SqI23KoyWsEDRFKZld/NnQIwc6HITSGaKucMRlOb0jAWHFoFkswRMobDaXkc/NUiHomPkvqGOBgnuEkQ1vOEvDPdFnwhxERjnFLRmGknZLYhyM5loW3lAaJ1uacUJisjxRND4XRYELOqIqDmFxLyxKQjSXXh/hqEhk/Qcl4z9DXy7syCNo+G3MMDUuKT1zNDxeNGrAJLD+nR4M0AoKHAm6JHNyXytBro4G3dtlTyZQyFwUq+/UdOGnRkdMwqpPvNja1WxuVwU9KRQr3724dbahaUNYasjEYAYStFddGWtoMjAQhMi6qOcJE6xo/04QiuUSopBWE4klpo9c9HAG2FzJ8ruFVDwzSBSL0b/wsStUhPnPkzh/FxN7KjEt42uZ2rMHNsHJ9e2xOzLXS4xDTXQzNKx1QBQyASHCQAUcGhAGUCMwtdQBGIQKR6cZINw1/tbbiGNQRfaI4hI+ohWaLoAqYxMvDwaFCmWgCz0TB7Nq1Mxlb9DLK1Ch6OEvct/wzkEJLv9nY123ZKFX//7smQrgASMXdXrDEsQbos6/WGFdhJFeVEssW8Jra7q5YMWEE2UfT6W1Zff0afvY5Ss3dK59Mx8tzefdz+aPfkc60GvDYPWkWnkPc7cha0aQoLmy3+riXSWo0ss9VaEzE7UE1kiSWy8yDJXpw9fZuSy43xPGLL4mV6KxP4uRBhG7M3iSfKaJ43r+Zpby5yhQ9xjkOMJ2SriryBEGe1r9QorVbU7MeZ/QVd5m2Xt5GOqVpRVLarNkJR3zdSrsjqrHeqaCavBQ5JHUkpLcisCMAKgAEx8h6AqjAQ0zTFAlaFgiwfIEroILuxNlyx+q7COERgtb7Sli9vx+Jrq4eUfwGBNnFt0+g51RVL8cfDVrguNrEYpjll+orEycX8orhpSW1Cq349Efi3V3fwdQtjl4cSietFuXuj3MMan0x2iZL1b043uizzbPQobr0VKo3NUhBKGbbNS01+5nYih1aKp8wE/QTyAQgQW2EJEc3saPADLJ+PMzZpA7Ro1FXYpHvgv6b3hJUUGUFl5ZvIrU2QaPkV1V51ZZVM8wWHR+7aXiJvXIXLfqjOtUShj4kjbpKZX3XKzoyak4l5DZTOiJq7Oj8SDHxYtCnxolHbZFSIgADRASq3BBFE5AEcAUARrKV7mKDJioGO6W+WMrCvKAWANeeGHmeNIaRoSgVTAgvOYgG/aQNzu+swNCZR8tRN997FZ34NSUgJK8Yu88EjOaSv62w0JhHOue/DnfEtx8f85Mzekm8DM9Uj29GayySWwhO8IiOZ/3orxpy/dLkxKcmgumg0j3JhGMdqPdI6p/knCVxIkADxRSsX3CgkfYi2FNqGrSroHOf/7smRUBASGXlLLSTRCbSZ6h2WFXlKVe0ktJROBnS1q9PYVMS+FxHWDMNy6DAuzo+Ca7JfRPnqCTCDAzS0VI+l9+7/6ffjEoe7OwqtlKAAstXpV3nSgw2XcrPmPF59//XKvmP18I/BNyVIQ9u8U3l5CHa3lXGnwnjf4BGDULmcyFEdL82AIyiMIBjwsv4Y8Qw4OCuEDBKebnoKssEjNeIrhdvK3Ot1EbyM0QhJtwiYyLQmqriliSWX+79dAXnLUq59g1ElbXum8/RJs4kZhKJA3/ThTkEksVlN20riPgg/RbsoF5IiXBxUW7Qy2dlMzU9DoFjb6dYaLaaNOo49OHMdgbK1jCTDMg9GGjjZZ/pAEsKSEcOibwB6BbDUEpfmcJOPtTiKhoGALwrBIWhugsC1izRyo/UOWjR5KsakqHlozsY3V1/+oIETKKqdziKKVmZMvqpvL2TK37W3h6JeR3md6+Zko5tl5t+pU/IPEHQwKrCxeIu5RAGEAIAUdrkxrzoYiHQZlwIaeEII2qENBFV1AwcPlUDN3oTzWwwlScqaA/BmZnyRZ1Bcah+uEzmYFgw973nHj1UZgcdxD15lp/KdsKEe7hE1bCh57hVbdSEDk2bmNKF7a9K+mtruf0ncvfySnvhp+tNiFWbOnl0TqOWhVztzq/lvDJqjWPtNSTU+bJomfNmzr7ru318o1KSQHAAFOSNPLqAyAg6A5CKFJ8LALuqsVm3JZdLhKVTCZwzO1lAerjLxQAGIZZAY8E+YEcrrI8ruq4lrUMyWvKz2Syku7YSjqybMWqP9XUzOijVQzWus10/6Pf1TPeWXrUzqqFjQsvP/7smR+gAS/Y1NrWFlQZ2taemEiZhK1jUVNPRBBqSurNPMK3Fn6xMAgBSaSUPgjBUICCapwjyWhagueYxAwVK6w6885JfCDAx+iMk8zlgzHRUCdPFwrH5NQeQkDTmKIAiSsOaFQ5D9q5KVUvH0XnQlmoDglEDjOjsPQ+sYAeqgaHfwSVyO+bW8aSb9Ud2Wvnx5ope/2IcGpkHReN7ZesqV475qsux8QMs4d0aXIdXFti9jT5nkTt9Vx0PtcELvA65btI3QSILQpAOJiJEXABmAtjKDNFODuEbZYWXq02JbTemENT7q8F2+VVHeYOCrK5+bGHkfDZTfNKfPFsvMgXjY0VGti2b0JspbtrMVqGZpHwUzlfmqvNV9327keb+v2bn5mi6jllCoY9WptyXStvBolmiJAsUDlUpSpFgIE4GShuDFFYE1oZbCt6BZQx6Mk5hcmFCoWkIyUwkKEcRkEowliiTKwfJHe133aaF/2ZJZG1PznPPGrsuNNyiJp+ktnS6Ml7RpjebMyS0vLsz5ucxqGno+21qalYSH/sZyLT8Vdv9T1iHNdDD3mJypDlh1EheYok9LHXQ8G/y+gGowGAnUBACA2BUviYYFir8S6Wyng2ArLiaBCVvS8mbc5FfZvlMoLg7CCh8PB11nYZPGch51hWh+PnPJXP3fd0IDuziXiQsx0Wou+qDFp/VHaV+iVM2cRPYj7RbH0OQRKaE4Bmz9wsbKG3kK/YBkAAt02ciOZ4AYA8ZFEb8Wk6Ci74AwS8jC2thUSpo2iunZDBM9HWbJoK4gWajNNHLDwRdIam4umE3ozhI29SC6PUxWbmvjW/Ip2MP/7sGSmAAScXNVrCUR6bSiKXGUliRJBcUctJRMBqBTo5ZeY8GFMgeRDnMZiY8UWCR9yclai4N3sX/swXuXGfFr8u8lJUEB1fP8C8XjBErqPxl+9DOonjXpx70QIw+vlIImuwgET1HvYToigAgQCGyY9GABQM6WYD1gA4CiE8AWT4FgGAVRCEPMst6Jaj9OYKtmORk03EvRUJZTICIaCAAk8kQNJxD6TTu/bd9//8R4IkiBBOmiIMMizSbQ+XNicXCwfJsF1OrJ2CR7P+//vfYJpt1xUdQx84TGb7I06GqFKG4JiTIS4SE9h7E5fmqQltVsRXJ3Muj2PHSuTxdnltWzJiFiCqWFhbUkgk61JJPqkyENOoqzkI9Dk3ZLDSL0FJyUfVqY6p243XEWUaHAFXqZsKUO7J036VwWSydgIsvkmddf+/OEv/voV4ikWeRbWEACNhN5Aou9yxqkEjWZ9tzMRhsxh0hso+n46rKkCaasbn29bd24tK3+FSQnKBdP8oTVxljKdlpMVCeG6AdCeQDk/EtcySCsYksJB7WrckimDjGIih5tlQJ0sheYkQL8Y6ZgS7muNMKnF9T2lXbX8q3goYAe7b2puOPLW63/8dZJ8kc+3BAfr+MGfsAAGMfVMWVaCt4BKQEQYBHVPT6drqoZx+LR9xGHyDb5F93Vo6aaki3P5TQTm3wDV53mFVQq/yjmXOHEiwGGsufkjlAgRDCO/zXYbyyiXzkS/DXfwmQhKnCQhydPNDCIm7gzN+k4pOi1F2mYwoSTqHHFKwUFxkewEMVBy32ENZziBgSNqoAyWDXSiMNkoFGivGt1XPbaYuy0R//uyRM6AxBpY12nmHpiBRmpSYYakT4V5TE0YdEH+LylBlI6IhtrSYzDd2a59vyIJ7KiMXhLcKYPgwHgVGGCrbgmVyIIGA1LjuZxxAWhBsxLuZkB5CPMxmeMDN4R5oGlciHIAEmJTrsFHNxL+MKCmkQnPjvUqWAIsDOEYDtvoHZ7RU7Kdggz2qhgjAAB1DAGe5gI6AA5Upp5KjYQAwKEAQAMcb40BS7UbdIvC1tOGMKAmFGJFxS68QoGnLYjLjRrK9M48Z7AkvrbyfeVlovF9TmN2nKY3HpWWQzaNPQiXgnFuZOnrul8Br9Jbq1LpmP0b078uFF7nLuPMrkGOdMkv5Za4yPY0qJarB0I+RKrupnpOnke7Aid3LqfS/at2KPpU5Ub/19egZPXZSEWG6GcrPliOLZhd/6TMyw8UrIWYL2tIJQg1MdceVX4mejy2sIxkBKCzdggQjSMsp5rXzneZUUE5NSKjDEMthlrYbTJWNf1+YUfNq4kRmQ8tgR44gfq3MYzqEwM6o7oYrIjDDV5609eT3VF12JQWQtCtYiVce1DOylI0oiKqg/jCOhRMCnQPhxklLGHGVE83ZI3gCcgACoABOXTgNVDoiCQsWBjKAhiSKQFIzGAllriJnK1Q67CYaFM/JMBECFA1O07PzPBLqOZwQ7UJgmmqR0kPwUJft4k3nigPX8zbtZ9pxSWFcs9T+dI3PKUf+pJ/jb96u/rCF2Sxb9Uld7KqbuPuMC+3JL+KbpZFFXhtbEmMs91Q8Khkd7VxFbfgjg/3i/LB+WEKTUuQuhLvaOdsgLggAPAAIY8buTGgETEIQ1aQMHp0HQWmTOJ2//uyZPWABZ5i0LN5YnB/q+qaZeVeE41rR429MoooLujxp6FwlAoKAxF0ycSAQDxzkllfRDnGyq9OWDOeattFHeucvcasrj7mb1BsRxz6tEFWC6ue/mYxiR9vGHMpb1fH2I7RfE3B3aC03qTJtP1Sq8MPW5ePaFHYxnnhfFC6iVWkgS8Dhl6iHRVlPRN940qgUdxWA0ADpgAPQjTaQgUGRoKAwCZeLkwOiIECyI632nl5UD52G0JiIruSpmwjCCZTyqPbGkWYtYeN++Q7InomZ5m0tp+0u17Zit2mPkO+96qZio99YvaBUdYZ/97Eaq1GFMcZDkDi+N7wKJIhp5hS6KLhH4MI6wTNqFOBw4nVcwYeyDqWxSGoQyjGzATHYpMCAhRAwoH5laomdIAhAAASThAAM35OtINwMLfGOFmkUu4VQSVCumYkReVtd1mwFfsJrwNDduW0UEUpKEpLtS22CRTH40yqUi7c3+PL5PnImWAipcRLynX5eBsOGMlC0umWGpyTuKaD7MYw/55l9q/GPxK/DPer60q5tSh+2WZN0S3ycWrYx53JGHfEXd+mQBABakM7mUNKB1Vi+pjRIaMaJ7l5wUFtLcZxCBYaD49wNAa2izbbZTs5TInKEyosQHSWzLozqaudvzMAqQta+vJhyCUcZJIpT4fEn4w2pJLagBizOQ9V9RGBqii6LhAdwg0PlSy7Wxc7dBna1+SddjbuAittB77OKvFNXa/Iq163/+TN3EqPtB/a4sOGBEMLHEHHqsB41jBO7mU9KQ0gGej8dj+LCkRyIsZesYYG4gyHYkOjwEOWkvRtnMIQy/2rQbSRiRw7//uyZPAERLle0MtsHiCDKtotaWPEU4V7QY3lCcIqrufZpiKYnTRp2igr8tX2CKrv6Dgsd7cfmIpPuu6c/YHjulc21tvi80KCa+EqYVtiSemf56HpceTcTR3rzHrVd7a1AvUws0utzxxwVz001161PrUdHVXr3ahg8aMEWGES6tjnJXoCSACAASmmzMkrNABwdDwFAxgAViSDGgqKgkKhUaDqQENIC0JT9Oq3Muk7sFuUwE+fHn3mdxtSo3jgZ1WS0cGwTK+zFVmMi3b5WZpTzn56tY/7Hiw/EgjyTKBVRMIqNLz40tZIAMNxhx65wrN5N3cIH02jDpxl7CEHS1MM4VJEXbflnbHxGrvMDSLgU/Gq9SxNDMq8uVuWe4MCizIlGWt0GuXdlQCAAMMATlU4+qxMCGwsBAYjAFyBjcAgwCTC2JCAgZ4GIuQrlnYhAITKER9ki5+TLqQHI4kD8s2ceflbKbG8YAWGQuQgrR+jgHm+22vKAMJuUgud4Y8Qzh+NLQoeTb/13X3Yn8pONm1uI/f+aWe2NKqRiRefaHFrGFHZcf/34UaX/LCKHJkhH8vkIgBBagCAGAPRggDgYHmHlhhSyChssBI6HQ+yXIECiZz6PSn6tCSPCwV8RggKAKq11+2ThYIjENyC08H3cJVOrzbe7HZZgHRZPHe3FJY/1b30KTKjolt4S2PkVK2enah+/E+GdvxO72ynjtKb5649CyssdUyd+1xT/zE8RksNnLcTghzHTj+pe6qe/TlfjddR8cSiu1Omm5fFIaNBPbSNFHn+Itm7uxIQA9Fw9KgmjGsSi1A7Ew0oZfxiTyt5CAMKzJAH//uyZPcARRBaz8uYQvCJCDnJbwhcVMFpQS2xOOn7ISbJpo8JGHtAeIMAL9jykVITuT8yaBm4GbJKwSCY68aUExjNuMpSgZOXLc1alat50vBYlOoxTRJhRNTAm989XPVluwIImRJXBL8Jy6X5n/T3PIMe2eVgI2e0fco/C/yc8aZZ42688mohFJEw0/NApqShAQVooCI2ElpuokLEQE5cbNEwQAtlc5AsDAJYQcPAKrAjIirmEOFpixf4oAa1Fvd+ZklnWOlqbpZPqSNrOU9vOkq3b1rblJKHrxjJhkWzP8dCxQuSiESF8kuiYx6Yq6wrffhSG0DSrPYpB/BrwTb9FnV2JfLJVcqBr+pzvFY77n/VZiXrKZy9w2xnm39BUeSslAtfakxHnIs1rBSusCAAE1fOniIgEhkUDAENGEHwY4CCKZgsdhAMHgaBCsjcKAehLzvwYXADyraZSWah+o+jMIu5IqT0KV+uRp+Vvz/e0z6IK3se4T+dBd/6GY1qttmWvqXOd1apjigIahBZrDBdoE1Fm4qKy14E+cNmKmgbDDOgYBzIzKJQaJtcjwbu9Z2VTvo2HI1DJKNEgeUEukIgkpQ2boNLGwUXmXDBE8mHuBfgRh4XB3LV84pgMhYv9s0VFkYvpLVOx2hG+AIMcTMLrZLSxqKRmLzztvNOOa2WijcN9NbN4UVJzZATlECvtGo4ow3KBHFA4ki/Jl5KRYEr4YsxFdxdZnUmEb0bezSgnOp47+dz8txclRXCEMtJeefRVc8X30ve1msVWR/y8plNeVn2//U+oBOSmKif3ByWEQ3fGQ+CsBG0LZzcGJBoKLC3ZqI2//uyZPaMhTRezpt5SvCQysmVcKLiFL11Pm3hKcISK+cJtIsZDlR7zBgxbjZQKVoSB4AetiSqZc6WTTzwi5qMyS484MESILe6petNQwu15fC087XLWOqkkcxVWEFJAO7dnsZQTRliW/UPf7CDCxKWQRUWxGKOOXrE13lbrq7daK+DI/kj9zVtsy8tGa+k5idzNSqhRb6X9fzVa2gTk9pNepUak5o9gm10iaJIphoLmDRuZNAwBAxgYNAQGmVwGWULgjwDWMXxMRgVKoBABgpgELFBqQvLkg4BP0CEsqUEBzYjBeMuQqkNMAKszQjELNNQZtJajoENkdKcoeDARY5a4tIDTzZUOQ4KFAqNBwhXFglhWijWykQqAIFyoNQypUOajLFXmXa06BIi6TTHTh1/FqwQu+o3ifbJX9QxXc6DWV0KbK2v6qaJP03WHm6QXJY1TOGx9+KV6maRODHffRr6qxMw5oZGFesTqMaYizLE37ezrUUNrub3/KtmrazK9/ZQtGj3kqlvUrIwZ9Lu/+BWNsglCIhUm6zGoGGIBAjOrUZAQLBgoYMoEMw6LoSVfSuEiFQLsYKHHdZT0Qkrj1WmKoKjzh+vUgeL0SNi3LQIExxick2/q/3ca+CGAbgqFiSU4GRAcoEaRZaARzY8xBTR/Y1Dg9iUpXQBUy/W1cSOqn7FeKmKSSevGopJyJesottFrVYCYdomjxPGyfoUVVTHdksOXjyKJxzRVQPtSKEIHHS9tlAIDUMqALMYYTbraL4MqazFzkPBZSAsuGobOoHrwND5YpSmDBstVgY67TXnjNxvSQKFowjcAWTnwsCElCWifFGh//uyZO0AB6VazpOZTPKpaCoDawxuFHmdW6wxEWKLMOrplDNsyYn7xDLZyc1OoUJ0mNACI7Lz2L215xjDzKf+xwhweMMik/m1apa6XLqYIl1up0GH1i86KXcL/l3WMF/y2qy1mFS7Qsc4yqh6PHRYuJx1WYPEA0QQSkJg00UNDZchwWOHZiVLp8V1A9AwWEksbJWT9BZoXFLbqpF0S16AFo7TeJuv6yFBIYYL4Q+9663m0+jjwdR08bdLWauGzw00mXwW0p+aJ44Q/FB3GB2zZJ+NYbTKtTCDIDR5aYhQOtw8EPZoTx5cWT28qP74sXUeZwnDdWkXXD+rJHEsk5/jEQaPp6m3h7SJqo4FOIQdewChiMXcDRCVLuOYV2bjLJb547f51ehv2Ypv7HDUmLFFNAE2204a3SFxcQ9fDDETnQXAhIFCHrl7hj5EA2qZywa0FNY7ONPbAGw7YyAAhGlDhvfIxAwBuaNyVxkxB6cQZy3iPQBkxK/PDuf/jaPhhWoKBavwLLdIIuWv7GRLxVwhz+w7ih12Wt4xfm3HSy/K81PWTSbq8QkINHHdb/0PHwJwtMwH08PpjDluqBMtqJcVjrT8vTKBBXDgtrAwBeqpYGkA75nalCc6xrcuVDbcZPkku9ow8ptJbQCmid8o0cwkBDpmQKMfZmsJJt+5hgSH4s6kWdDmL5zqSnzaWohkRP2VLbPlLmR5lTNqlqs2RKjVGMgDqZlIaYc0QJneTCZazcxAKpMAoNXcOMXBBRHstIqqoXCgfATSz4WAMBbAPTgdlrXlE25z1Io2sJKJe8kxBEv3HIpWEIqA5skSpQYDTEuPT0kB//uyZKIEBFZe1TspREByC6stYSV3Ea1rTk1hB8HeLOsphIo0vEdzqkihlc335/cFX8TXTVzFeNHiLrxewrHJLf8SQMH7OlqKvU46PodcGyZ3FcpVPxU0JaojlpW7QSh4bQw8QuZUGODNdQESANSNElkBwH82rZ2zJL5FB2Iux9+xAde7XnaUQx1AMZbS/3poIipVhoFh2JdpdD7Cj/m0gfa+NfImVBWo/1iFnrJEs/V5/XhS96aoHVSOxfLdWddH4dmzKJQjEpPVGa9qSVDaqr5zVaVFUG8c2cPLDCYfrD89WgGkI5K2MgFDRzw6cLMwEAMEDQIZGKGBQCwCJBmYSCAsTBpyTrqm0SliCF2FMk228hZKFGyUFUNZuD4Rq0loxScizuy6UW8qGloQxFMos4hKCdgKHyjXmLFA4o2KVfxYfoI3oWZURAmVJ55kV7dPh63yaVG+xaJrra4rqJ6/iR/pK8etVFcHUhRz88DYkGqVQ+JFpFpOtzAoBJQbl8jeABAD9KVc0AsDTRft9ZOqBIZCsIQzfdfIgsdbaSTL9afrNIfYKj9GOfp6BLC3HPcGiow1FtUJEBlOyodxWzkTU39u9WtUqcupl1Z+1PZ8tuzqrdy1KWu1UffsLZxS2UV9AkAlLHHRKsYoMvgx8Mxw0EBW5Izl4xIo5IMCCQOOpjKz0rmlMSwgA6DWJaUxOiE9UXNQJLwbQF0jmZlQpvxatc3JWxxRnVzm2z87BF1Q7pWtvl2UOyK41Z4NNpFDgnSviijurTmU8bKrGPoaC4g20UZlQLGwMa/HitZ5VUXXwxNXM1LmpUD+qYOWxe+nEoe6gaWD//uyZMiABLFZ0ZN4QuBoSxsNYYVPEpFrVO0xD+HfLKqphYpoNtIBCEBSbXbivgJQ3GKzLsjKGawIwwMHDgEC1x7Eay0FvJuj+LVn4PfyPyLHefNHms8ruJZw4O87VXas4tdTdh2bSvd9XNAnL2on372RItasrqV7b5aqxdnt7M1ZxEIXdWVQqWStnY0hQX6GqQLRSaKF7GYpASjEQ00ABuJ4yyzAhSX9Bn2bKSAacMhCgwVMcIAVkqXGFqpthF5hrkYrgkteLBorCyoKWChMHypnKHZE2WKTUMcuIzAyCVgVIIchw4njP35yAkHnwkiXQawk+Ta0fPBwXhEHj/ctELE6cWTw7M2Re4wkxypKxilfRAjVWV4eq1tH7pXMXxfOMi8aO/WPruWq+Ya9h9wQY8qKDR+MObkcaU66fmQCZHVAuwM92NrjHIIUTjuRd6AYoDBUICjJqRQQ8EZQYPGLXq+tLIMuGIgzLJakhIKl5dyh7YtgRLrpCQVo4l905Tvu5Ceo+ZWX67tyaFVz3DfJIGV2PYvMNn0G02+3faUWpPxtiXfxNz8tqfphjCdqNROoLvPpL8t6cmt21fa/WCo8SpJgARxzmCv5lKaZS/mtnh4YWYsYI/GGDRo4yApFawrgJIpuB3g34hCEeS4AgFckUWZotx1RRaAkRbC3mwMvkUiKiXN1DUbkch69ep1iSMKHSopXaaQPfNuW3XwLy9qaTTRfKTU41pdUQbsbLVE4V2VEMq0mxWxt8pGsOOs4Pqzy6dV3frf9355/DK4u+eb7Tvq2fv2Gw8y2jtrJLVdSFkr7vqABdt3MGpMpHBpkjqFmQqUA//uyZOqMxPZeURt5QuCEqQojaYukFCVxRG3haco0KKjNpI6gwwHIjEBg4QGBxKSNHS3Zii5uVTfpQLXBxYShv2xtOBqTq0CKRABf6KmRXELPGgoGpECo5F9rS1Rh0O9XkRTf/4f6Db+zP76vM4VViAgvFuT1OvwYpbwc81NDdmgEFytq/XoIqbQ3so+Pl1Cq01hBAdIkpgFA6OXYdSB7/tUAJuW8yJfM5KjH0UyPYMdcggnMKCWfGRKYwBqkMhUXNRtFAgYyiGEWPQX4KBkokeSYuUINI4LAJTTMGBRck1wEwKAoGzjR4V1YdCiKKHnyLhCPWZHPNOodHukRV8kLDh5cci67CI9wnvbK0jm/HJ427t3uDaukurkdF40V+u/Fm/i+a+bqoPFPgf11LxQnGuhBVQt1cD5FWDhNVWAFXLeYO/miJ5k5icgIg53McRRwKIREEgRWFBwEZSANbCgCNFYRgKkclaIsClA1E2ftBf9w32SHVVSjjJCM2Wf8tEW1Ft6x4vr5S+rXSqwrsdN56Zy4HH8Pon7ZN7X41FmZttW3ZSz208z0J2I8h7K15ENut2K7Mqvtfq7bOXrmK+GKTa6iPUAA22+SXxq5wZw9nt9BvAyZC7jA6YOQpRB0u9JiZUKhZKDGCBIqZioEAo0xgRvEvgQChpTaH2MA6CAVRyq6BfiN32VNWjFiK2nerxOV3jhh7s4fiQwoo4posZypiOEJ9rBHVtHIoKzdWal5BzjIudKSZ35Yebwk+Q1wxf3/FJzIi/9bo/zUcc8R8OXXn1/ajCREPgoJzLLxGaswa4W8obXfYgAFtx4xxVMHbjnP85yK//uyZOkMxNte0Zt5QlCHC9ozbYKoFD17Qm3hDwpLLSgNtIsQCBw0oTMpAAw4AIyZUIjxIZ8DixkMDxiBUZ+ToJhYbXiZQQhUMVRZy10v0665lb2qEQcy1hTs8hyfchu7l3YDoZZzM4hnREbr44ISZROn2O7bYB96ar73ygxDRKjspDzoXU2TR2WVfVq7JOZlTcGeaZnSeyG/+3omrq/dWSyiAgw0aWz2aAQAp3bbmKCDhEyS0DmwGxGs6Z7cxUKJY0B7EBZW0MeBCoVAUie8il6ZCK7AksrDS0+FWSp7VtJMX7qy3VhBcJxmWdve8YrpG3CUmkTgViK5z+hV7BUcJpduuB1ZRzdBy0TUFH/ESzG40sa8oKV3lLaLaCR7hRicCO4+sttNKjv1hd2vmeJkZPev6LColWLG+w97aK6AQpZbxCDN+iNLPBbQvwIVCZ4wCetVgOYJbXYuIUCa6OGn0zolGHEdRu8Nu3LH2ZEi4887K390+kbjZRgqcUErmAS12XBziAkSWhKDRYXVEb1KcSRUOjdypQntTRv0k8o06nPe/evf/QiJ+tdTNtZhCpzo/YjRbWIAU5JcFHULI0xiNTK8VMlkEzeWgsLDAowJWhfJBIIkQO8iGEUBSEaKI2kOLY2XloEZCIKTjhK3E+NNdcomJkFccTaW/LsuDe47ScBZwyz4/eruLDT0N9NnXcqzwHlVwpHm6TUvtjV96sDqH6M7VNWHZMxkyaePeQ/It36fV8aa7Hf7hHPjCqWHbGf8qr5f2uXtavZ1uB1rFHicdVniM0e7ZDhSw2K9zDntZkfq9OQeh4t6bX3zyNeGJwYsUoA1//uyZOUExKRc0ztMRZB269pTawU+Gs2fRO5l58MLM6jNpL9pCpcHh+Hg5aYjkezZVddUkiw9ePneXzJQBBSV8zyg680wscVLmcOgUUYQWDg4oDUCL6mQDiSgRERYcDmLY2sOiNIjNCXZkqu2kMAbEu4gFWYhBsdwbtAL5u1N77jhZ+hb6z2b1njnfhtQz+G/8BAI9Q2fhGTrUFZuK4jN79SgAhc+g6BBqNBajFn1fBh3owG5uWQkRYoJEImlAuaQCAMErSlnEaMgJGCe4oI7KDupBrOXBNum2GKYEY/C1QizTT6EHYUiHsTAh7HGU5zqSaAwRcfDPvETV/4c815lAEAIBATdztxQWaRQqGOclRNA40GEDgsM+zQUV3QgJStbbT6CNtmShjZOPmS7Uip0Q1k2fMSfVDVeqotqefA/2zjbdqWZ7Ek/OwxySbQZZc5HsRfY8HAti5pcT1lUR6JUldh5rzbh5zX3zU30lD9ljYIwME1qGagXWRC83gldTDS00lmnWMNMeC79uUsKFyJXxm/KcNsWGgTWxIbYpZLY9cITu93P1PFZMAQAAABOSy3FjTdzUIHhcILDbqIUwG1JV67moOA+TLrcVgtuT6WyQvnCAHYYBGCXi1EYP2ajGW5BT5aLEc7wu01Wq19+zf1LaBjQ7dF3v7qc4r/1jGvka31t/Z99YEwV0Tf2pRUpQ+On+aN1zGnlEX1yaMueNHTK39J+2gFGcvcS143mIHfFGLLpACAAEpYmlCpSDnQoydhB3hnQWscAOmCEJCRsoFEhLS7hkjzUKaUCKKozljCZfoFJvSBp2O1FAhcGIiHk+mtSuMAc//uyZLoABURjVOssTHCKC+q9YQaKEj1rUUy9DUHjLKx1hY38HnTkjgspcIpAsIJ62JBEcLCP1qsdiN0wdX8EzMF1y8fSCeiGi5oO08tq/80r4e+TGuUj7t+RjV1F8daR1Dja5vmO6xKJx6iRCaLAZZuqZp0FWi5qNz/6SZbRdRWQHBQ3GqlxlUPl7dkFZGlU46oNY4JgEbUxyRj6CJ8hbo3m2nzc7cx1sBKX84x3SWU61wua+kPIOGNqH9z1JMM9V4DxzchKf2CdeP0h/wf5UE+p/c7I5cbIjQqEI+z9wfcjmx8Ew9KQ1GEgTA70qgCowUzEZ0RlZgbmCJYwkLBXAWXMKAkVRZhSyBR2NBLujwiQg4cDjwHDqXSL6RrLESKFvWDoOrLe8qAO+0FZ3VIt5Tx6sikVx3zViF9L7HO6zSXUVl4ciUqpk9XENRb5FqvPrUolPFa+GH8RH916r3t7HL1/DXeg2Oq9RxjblTvFUPeKhRY3gPoH/YxBoVdkHss6vElMScmiAWkjVLf7ZOthyBnAaBvHwfC6OxRESQo1zNRQx404gJQSaIAkkGFCgPjsyyPnHHyI3bSJqPQUbKVbnQQQlD6xEAQxZjVvJ90xF6Wb0VkeV+S8TTZ0UqPy5ke7NR21pK5qoLOufOKsjJnBWoYeYVQVIq1RSAclbahmNhmQBzAkxrXGkQoCW6TSIjXsABCOdxHMwxcy2NRTClE6NYbUAjCfLg1uSJYqQxd0LnXzK0sPj3TjI8RqvcodmeTzktEZOmjeZGQCEwnXKNznolZZv7Sr7zUP8/gq25XK7Y+erN5q1tYARQajX8Mak3eZh0sl//uyZMKIBLxeUhtsRUBzCzsNPSV5EmVpUOy8zanpnWnpowrcSN/P++F5lznaZ722v0EeezbsBT4roL3u6AQAAKjbIQhXmIbglkAwhMGBSNcKIMcLmPGAgrUmSKUiEBR3nSQfTPjEQypaGIVFUZmvGqXcekEvJEC8IMj+A1cxNI9mMbZItt7lPQBV9aWr/HYEtAa0ur34CM4phDyLlo5BRx44Jia06kYuPKPALdTWsheRUVeIjxOWBCtkeECYaqRGLOoFhSLgMrFxoZMJKworrZSxMWcjGi6OgiHSiFxG0YapuXppCYmVohNxrs4U5ghm05Tw6qOXw69kZfu5Ka9jEnHlWOocoTynVQrSOHiBVSg8fIqbeEotEsH3xRImqcZXxXKkRcN80d2t1QgwNprX3a8c67Hfn4+Cr/74n5p17i/a6YYPGWaPuMs3th4rrJ8yChACcv9dxImDSIIkQWADTqytBhqEriVG6iizbrNqVZ912aVxpyxdYqCp9c+S2mOLob1mpR9hl/LNujLF78Wfe/byxEzDJVd5GF90mYbOwGDkhxvG3s5D/a2f49OnE5zklWKbYVagLUSIaUdJqUACikqZYpxmEWmnJGaex5m1SHG1aYlGhjogBUuA6jnGeBPBfJII6jQvycvR1OqSN5cwmjlKGLRbmQpyAw0HeiihcoQODTbFHXGJh5bTDE+6jn31M5bmwEIdhY08GIhnVjczDhHcog3qXVRCF0Jn69PccIp1H1XblZZUo3FNXc4ltqp3H/UOcq1Tidu8+3VXbGeTv4moZVw9k8d1DIueWaN1c+zHsenymWqtaq3pjFrIbmi0RABW//uyZN4MBMdeUZt5QnBth7q6YSONFnF9OG5lacIirWiNtA7Q23hQXNTgBYPNSITBBUVCguNiog2EwwBBgAJKI8SiMNMABn8d5JMuCJBCMDXFZlutLlDhLtbKozty4jff2WWxED4WPaiawHdbWnJ2JXTuonxEVkCJncYrhY1BJLuAex65JfMukyYOQr6giFbZyDsWw9TW+/w8vvt5Oc+/5QzFTUEaBazhl6aKABclvMJehZpMLFTsDk38lNVFBJiMTFgaViTcikICEiFHnKwcsAINAh4mBoDqACCB4AB+NhkIQHkTADcUAKYZZ4xB6JIqcehIEos6TEkCKao1HDrpoMO5SL6nao61lodZpWeKCT0nVdNJnU7vRein6L7vqRrRNHVW7HUOgglpsyrVKSeq1ba7azc7rSRmhq7sgasma9I81MWDPaADLZeZhwekuZVAYt6IzZA2KwAYbYCrSJLSJUnyhq6YOLoA0SxSIDHADyjJiMBGoyhABqBZIIwDKkOGXL7oGhTIAWlmS0Eal6atc1oJ9lK5lYl04JXQsQQdCQ6HIpC4ch5ApYyu65GS8bsFJxQsDwIlQvMxGAAAABAArTTKAY2QN5gHmRGYiNyZPRzhgKD4GnAKOYbIi5gFAgGCETEY2oGhi0CsGNCE8YMQIpggCDGGQE8DQPDCWBOMKcI84EIOEVTFEQ82KBDceC1marJlRQCAcahTdkc1ECMhaTRj4FMhh5ODQsCD6VpgYUFwdEdHsdAzFBNoICKi9j90DD0uUV2nM3TSjrQE4oBlL3NyUzbhT1azE262GsUVBTq2ReIvfk+Lr2aN0ZucmM4tGKV4//uyZOQABNNeUZ1toAB0RGozrUwAJImJLzntgAQqMGWnPbAA486bb343RvpJ4Gj1ihidJNRuJQ7E8nduyiBX1t16fsGU9uy3GX34ZoKeamLMP52eX598KO7q/KMLtBqQs8llPQ0lTOrd5jPZ1LFjPDfPx/6tWN1ecn9c7zn/9q7LrlW/LAUDVvrd//u/u9QAAAAEAAxkCABiDkgmTGEgYiaqBgbCImQESMYnITxhDBtmBWIyYmQDBhTCcGHYJqYUQYRiMhMGIeB+YqYj5gphjGFWE6KAkG41AcHm8jpvyqYxKmTJhjASY47ApuM5DjY2lNAww+NEWDMiE0klHiAxAXVgGgQFAybaEAFDFYYZSxdtN+Qs2XeVQBTRslLB4hB2JwlrcUleVDRbxiEOTsgkVJDzXXGby9BFLnJd8/JpsSnbFd5pt/JDGpyWSXeUGS/tJcksfmLVu1j/Msb3NfrXLM3hqU0Xbspnc69rn9or/4/e3lhnVwv8ra//+5nzKvjjvv/zv/lfz/LW8d/zv//ZfhXNHz35b////VUAAAAABgYhoRiMaDQbAIEBLZMcajAxsZRCwBdIDJtoZhya621wtcGgKVMxiPEKGYAMsdjpYSqfEqY4bZdDJYEoxnjANdDC3lEwMb5UXgUwB3DCF4TRSGqZRjl+YIkTcSayLGSV7aIWfh6JpwSJ1xWRUR4mvwBOAkhqhKE0Nw8E8rFdHur2GlokTO59R1OryFjvMoWA/llOQZaRnK0Jac77o4bxr6m2JYUgnZhs2WQmYV6LHI7l3K+vAxXFqTfWsU1///xtDwEcNVEqJrGYtuBYGNgPNgrDg63L//uwRGyAByxjVm5l4ADrTMq5zTwAENDtWz2GAAopr6w3sIAAEs+EwTF//8B+7/W2oAjABCBCCSSDowxEKkTBAwkQJQzxBFpPSh6IQAXOJyQUhKbsRC1bRoMVahFlCbFcAXRhmCnSQgaRUCKnkhEBOSIREFQysLc9XjDCRjjW7tRBS9ihMKRaOIwFNcyEPV9j8FsPc9UopE0dBoqo/1UuT8FgF+Twfhe2BkDSHerDhZEuqWu7dCVLKyPJo5oIYqDrZ9qBlxDUDO/Sh1qBvVsHUDbbBNM01W4Xu8YIjGh88KK1Sz0a0NhRZ4LXJHvK9t6IWsp9VwWePT31Dj062d8TdqKdIKuKxRH0N7ed3Aq5SeWHWlsQkf/1ncd/3lgCMAAAAhGFhSXw9YMIERVjRuU8xys5rU2HpxMDwho5hDo+Iap8sHqQtOL2FJwXD6X3EM8gdXL23Jejk3S1aghj5h7Uj7N2nYXW7uQ7S51W6Osxvtxv/1o19HN2iJ5fzte3utLGZXfmIzuWx9nCRYQgKO+AxV+D1MyzvzaRj4FD/6Hjnf/cw9INPpEAAkAKEK1V2JCJaBJYVVghAUFTUgdWplKgxdh7IefYcHgjnBOGxUUEEOSXLQePEAearWIo3soePpxkDRtSwqMPH40QR29D8xjDxt0MPFZMe7iLfuJuT3uj9++Ot0W0WeErSZ9550Sqrp4rfvd4qof7GLHfbTu/C+cOLd4tLRb0dz5IaVg+oIIBXUAQAIgemWpsAFuAjgpNpxfpRCEq+TucBtEhHA0wLSqUi+RtkfkS9b93avJqr6c7aq8Q30RWPonaMatIMNDzaQMKU7D/+7JEIoAEzV9WywwzYpBrywxhhlxRLWdhjCRxSgkvrLmEjfk8JQNshjpOekQBT6MszfXWYeahSJZ77SAWmW2DSDHMQ7LVAcwEzUT/hR0qMs/vSbE4R5T6Zj3BDtEOnEQ987J3OmIUYZol6Mfk+WtOZUjQBJQnT3/aIraShZAC16AkhUCOjbAs0vA+znIkqcvYA5kMBrLZlEZjshDmhKDIjQ1fjeeWUt1FSzmVicnUskc9JRmp8uLJ65seDDmxOa+zy2dru2Ou5iy6Lpk2f69E2i4k/xE7uxksQt8t9vWy3P/9415ZdkzLKnUVsQQsimZjO6Q+tdBRJEsmgEtqcuk3HhyyxoicrgPlgbTiZNgAMngLHgQAJf1qcVQ7MPhOaCsflCpWmw3IY83VlkQDcmmTZMdVIT5xERLUjgMyZaXFC+OjVZjo2hWiqySfdg4KLFO2HQ7AxFhg2cNlYhT1aGnXbJSVmjGGUXAgNVeyxZMTiBlh2t0sI4MgZhHtDAjsWqV4zdZScCbBNwmSpiTJjfmU/59AKEcqhCXSgOthr0NlkUvxQTMGiJ6w6X8V+yttVXOfJYiTjxokJrigNH4IyptPBEkzCCeNTslSxiLl1GHPTQwl+YphmC6JjZO6ebWrZ8UZoh5oTJ9U+nX7w2yUM5YY+LeQi1JMyr5nw8jzePd6a42945ziGZqKM5C8lUycTJYW6H/lTRLFBAAAkPEEy9C/AZ4vukhrh7UKqFqSi+qnJ8gWZ2oEVJvCeSL9cw6p29vBm61BBu0SpOZAkxaz2Liea4pJgYsUbw14Xt2CmDEUDqEXRiwpJFFVcqNFkuRMpFKSsXn/+7JELwAEd1rWyw8xcoxL+vxhJnRQpXNdjBhxyicu62WDDrE0m1mhVHdNFZPKbC0XJQlSn/zLWW/7qeioy5mf2LjwVvMC+cTAXtGV0xgKCXuCm9w2UI42SqUAdDsIgl1AVQu00MvA3yz2TsdVCsR6pU3GNPY0uaCw03RwZNDTc04jWPSdahIMEpKNdL6U5IwZRim1iBb1Ry5i3XcY5pBPaK6clTMt2O1z74tT+q3OZ815jXLVaTlJHvk3jf7/LeP+mQbv8p+Xka1X+5tNmvxZDSVBMSil9qL7yvTXoasabd0AmVEQYEAYgJD6mQwxM9i6ukeX1aHKC/CI7wQA2r/P3djUOy0gk4gjDphkjifJpa+zhBzunL1qbmGEjTUL8kU5lOkEIZzVly0u/k8gXy3m6TynUlmAOosYWwrCvCPcjaqS7BT6Da6Ey8pEdHAQbZjPeBq5kXFq2kVDBtQs2uVMYPUsvq1swgehkQAnCIgChjdRHMAjkqqr4rejbIkfX7cl14epaR1Ydh2IYfEozLpi9FBhoZLZNQSa9I4wburC+Rt0WRnX5EmelK0HT7kjGZEnSCKQLGnlQWsl8lGHsNpwnF5PLZ4t816jVVCkYc0N94G91EmtDIg/B1c7Vcjiof8fyC2qJMV57KgOS6Zh/w/WIcT6bacRCLpPhCRBgYQBgNhWAuGQ23QjRzA2hZy9s59tZoK9mUT2ylkyAo5Bth7I0npROFcGguQNFV57qS50TvS5C3C8w1NjJTa9R0mROQzWCR8puzGLip37HlZo5mI18izyGEGpFSqFqhozKekNalgwkoAtl+uMhSE5hzJi3/2B13X/+7JEQYAEAF3Y6eYcsn+LOz1hI3pQsUdbrBh1Sfgh6yWDDnGN1VtJzDIxQjMlSIKR5StKhsC42hqGuY2VpytMNNusdCISANSquEe9Qd1lZBKVb7Q+cJknMKPYQSRRzBDWYS5WI7OcVzEMTTZ2ZVg96M6a+65HNF6dSc3dUavWpoKIiUyu+Vr9NrmtXMuly50kB4laCFXwKRjNu3MSGDff0gKJEpEkAgKMjCCCAw0sDFhxGlW9gaCzzrceZ8Y+6EXll+WyeTPtuxJJqHpjUsMxZBHcSLb2QoSQKlG3IudpxTUmvrr+M2b11RmYa8gUzqKnxMqoMNgxrnVakWgW6NIvuRuecMwVTA7qUQ6iVRszpCyNZ3FNny1QLYGTjBZHko91KH98LfoAWFgAAcsHSPHUBDS5IyB9VNmgSeUKrMXdh2HTn4PlUanHsfaKX8yAMHIEEVmmIcpZ8thnKSISnhOULRSy4lLqzLtvZWFomp3NsUKPSNuWc2tdaMHvSmbStoaaG8s1zMs1itgzCoKIPZDv0acpnYY39+fAHidnKxxMFm/2/pIBkuAIJEgEuEoWeJ+A16rBEtTVpKD2L9JVslhL8NrPSEwKxMaFSB+8TpamiSxN2qK76LMoOxsmo5BCtzE/W0wylGnJmsBuxkIN5hqpFhaZ1DUdph3EdBTdObzUi7TLI+hSa0ihh69ifgJpqpscY4VoVEPocIYIXAxpd3Ii4Sx3d/O3wBEGoESgI6HqM6MhmiX5gh/Ey05nUgVdscUGWis5r9aKzF+eo4TM4lBUybCZAsY2opQ0KVhTxh0IaRNZPSkGeqkvaq9c21Seq4RQzWf/+7JEZ4AEFFlW6wkb4n3LKsxgw5pPvUlZjBhywgKtqymEjeGxO0YgcU6YkV4V4PYm1xKWFSPKRVJZCt7zPeuu/VL/Iyf4XFdyjkFIqMc6WS6/f+/GgASYkFSAljiUjwSAVWXbVgupLNsoxBzMI4jo5TfvnD8dYnDrkVrNWSj8BggHk4CA5abRPodmsS1ViOLK9BgpBXgD7AhOCBFxSLovP2U9TjwzboOBCUyxhR6H5UGu0r1yKcOTPpGX7so3noS8aoIoKEhh6kFzooDjAVTF31M0IBeC0ACA4poDVOABDiw0NWBJoMXUYlaa1dgLzw65bmHSQLoEZ5IbFQ2qcD5HcAyena8ZYhcnrBOYwdSVRDgpmOJuDh4c9M1waBD3VBWY0ZQBW4uuTlmZuxWxAeVl0QipRr/7GvMxDnSIZDmzTBAydZuRXbVo8IE/AqFiyuxjF76FADkCkALNQQsdgsQkwHQvghZKCIMWCKSUZuMR5o529SivR7haJHQrGHbxeZrxsPZOnW6GvIk6loVDOoykppJbW73DYae+wWmltVUam011MduO3XhUmPvnpXu6Yvp8049mmPMb6vMSsMew87NdWGIhTqzMMgBVUNJmVOV/3/yr+rgFKSJGRMkqYDoTYP4ey8EoDmEeKIPJLgbIqDgMl0a5wtsjQJk4RX6I3ObZkjHULLsXFc9na8/GKiPCBRAOAqMMUDI7pdHhNSGps8IXY+t/Ow3qTIpedaqhkSMQRyvX1C/3qehtQhGy6cP6IQk7JkQlQFzjLg0CtCjZ5i+cYW8Dl0Q7fkknI2UpknEqmsgkAO+mu7AEijKrSjW/yk2etbn/+7JEj4AD/VVVSeYt0oDMGu09I3hQfYNfrCRvwgSr6vGDDth0XcgiCIlKDbPfRPFhCJLaW7kDKkrQ0WtoMJoYanJSUknQWaiswd+RtmUlpqsJpM4SxEOSVCd7xdtzlzBYJiVihmRyL3hUyMlL814Y7uGFpDVUtzzMo87PiPXNNmO9hleg2i6WZkAAZogXMhZCILFJIGuSUSZUvQQqPt6oorKw9lUHu68zYHYl8WgB8ZBhhUnt26WAYG5ljThRDunpm0WQmu4PL+jt2joL5aPaRMR71NRAjZqINrm4cMHYta0aJSMqCILdc8+5oXtD3zMv50riogIyMTvcj6TrSaRyKGgd4fD0sgvD8aoAuw1RAoqEL8DgAHY/EAIWthYQFAtpWh1NanLkiglQZJqToxJp9Z8cwCmetD9zWsu9PrHFodj/AvYvnATcsivHYTnKQQ9GndzzjPQOdR5+5qm3vDdl53Y2f73PV/9m+rb91I/Gzu2b9jfRT+4t+YTtoYzek3Kgxu8Jy7RrnGfJCIztv5SqvVWgBomnY4m2pF8DxxGWDI5LH+jz8NQcpc/Xgo16XJ0gJJUspcwPZEI5YHCc/un4m1IyFAQQMoomme6IS9T1Y2VvZJDBsNg593povsKPkvSuUC+ahi4nlP4SzzhX+pxL+Gf7T4JHpt5K/agiw6q0yj3gDSgoCJr+IiASoeO4sO4aG6SQySqKIBgLWnSU9IE6mVsHcZ1mlKs4YVHy8RAE1F01KVJPPr6gcVTftLxbqDpzTLIr6eL5EtPQgfAlnFQHStRPsKLzJvsalvC+YLXCHPRHKSKh+OyxiamWPl6jiOVGXG3/+7JktAAEOV5VSw8x8G9K6v1hI3YRvZNRLKURQcorahWFjmFxwxPN2kRMdI17ZxJodzSSanInXKOq9KvlL3GbxYACMQC2RD9USjoWInUzFhjNW0VA7kLaQ0uXPPDsWgf7UhtWESlVDUBpdjpRbtl1zzTrp22l7qm1arIywFo4xdEpJVCiOiEpo+pORbyggpyRfop6DpKshA+t0hihqVbzyXwy++eTvK0PqF9fuIFxpZe+WgATmAQqIBDKdMElIGhShQuAgznkAtAwSLhzMfHFpXeZPLmhKSd6koWAhk2cFQIUXbAQTjkAdlqSJHdwmo601vdCg1S037dSn28LMGQ+HNRRy4wgjlJuVESuBiZFjvkHu0b8p53c3vTlS/xb6mLnH1w7cQOjaZ7u+/qMisuJ+O5oNryIsVxF8jG30L0mQM0shGRsSJJiNxgBAgFq7sZrTeRB9MwMBA6zkkALSVLonWJz5/ZjuQtFddN88/VRNPezqlr7mvtT7LfP/U7nSJQ/kJ3Huhm0nOVi/P2vuOlQdeERd2oJgSWnVci1T45L/+Q3mqfS+pc8+7Fnnu1LIVxac6gEdAlVBwQnW+hgZM4dlkGBgYAEBoJMNil49FEgdGl4yAt+sElCzVkzBqZv7qqbCIepaZ6n5bNNRmB6dEFDg5dmoHski9LSaiiPCt9HArDk7aOSOjXsqwx15t4qMrSshZXmgHE9SJxL6Vjew1H/zW3jDGqy39us7mPs57vKvd6W35MW9IWf45dqrL508+KoflQfPEacPIui/Wg+4pwYe5Z+f5DugBqZZH6YHbKn4jLdyT9Qzd5ss6vcSRFAYIt/FPX/+7Jk4AAEW15UY0lEUHRrKw9lI38UbXtLLWEnygIrazGDDuT48KxYGh2C4TWpq8vx5xutJPVrM0Zh1FGc8pF3lGrq+VF4qVnr813fpRpw18lweWTKW+POokFshgnqRzJP8WMQILy5men4Wo5odv9pfQQfkXwYVeEfRlXk6ozhAwWaKxzOJ6d9AERDoGcjER84XiM8eyVNCwIRERkgJACIgcJpUxhiLOEDx4MT3XzDgsEoACgD4iCQACx4o/cQW7B0wwhxn4bbYerxo8gVOVMWjmjKkJX2BW0JJ09YvGZwfy2tV+eIDUPhO3EoEwbdyIbWboPNybK5iapop1jwn31GWKtIq8TOcLHGoYrn6ozu2+Pt0dyj2cidvXmx+1P3rbsTdX9Me0Dn45Uzvktl16/SQ0vdE9IADO8K0LPY45O3dqr5y2c2n2vpv0f2JC04WFSLMdSDIZhLisklae63ZTUJbTRKkIkfLRVA1RKJa1FMSyBxUzyiqL3c8MMJKSZWlO2Egk0BOfgXUwxg3CEefwOS5MRyOUCgjX8YoampMvSWyo0JoZnr9/v0/ZlOAgavksYUdmzYaIbqAGMaLg5jMLSzjZY5akEnFS8xQTMZQgg0XKX8Z4j0vZkQsBCQCRCyl8UQulKLVPbTed5sEvuLUzlEDUEtiLYfvVX3gcurD6fKg/uw1NkkaQel/bsBw+cIkltWwPzgkJD2lUj6T00fttI/dIU2qdkV2jBU39fhU9rFu951tDIzwNIj+HNW7XDTUeyz+4COb5iOexHmj9/b497uamHTDqIxW1kX6ocg8SAEgASRATo4mnK/guaJHFnl8P+vlj7/+7Jk9Y4FZ2BQi2xNsIJrqx9hI5UUxWFCTbDXSfssqemUjfGzBoykUPqPLKl/ioXBmIjQwcqCTWzQAxKoKl8hi6y6fggqMWdiQszhhl3xbcrWmJ9UV0MG/5NSp6g7lSnSKI5/KesLxwhMiH2k8pERqZkUKiQZV7pTT6/1e3LqhmPgEhwfpESBNa//2tIqFgASACqKPn5MQ5PH7MZPMESL4gAwQhyZhC0l4aTnYpBSvn2VxImuq8HIMmQvCYkDxJbYNuE9pehInKUY4/RJzA7Rz55kqTxX7ByddJUadc+0P1k95RKXZEpeoWzQVmnVT8ir/SF/vW/of5W/BZCO+Tz9n9Hc/oveyu8POVi/zcx0oV3N+eTT3QJFcCt8PJghPKgbXfp9/XYubI7o9CQACVQoAaORtKhvoiHMcEwgEPVDkImmoXxxaqkigN/2XN2U2ilcg2llklHD9RoIrz525C3a5xXbBpiIosKo4euzZTfL9M0juWmyvgXsCTQoxJA59Z7EtBhC9yMGdP/8GcbL611VciMz28lpGVO+dufoOSOQwU7oP62cB7tO99IAUAAAAAqEokMPAowAYTNsDMWDoIBxhgCmEQugGDh6pUpItYpigHVSSSvoQuI5CV6pJFWfhQ6W0kooiAJUArT3kQbjXJUGKwJluILultKWWTC8c4FRxlcrKkxI7ynPnaC5Fl5yEpaWnradLPxub3DJ/JQ+teMUdbwC1kkEeydP6VUUUG7jz2aMN1nJu+XPdUr0/NegRuWvZzl9q5Hu6WujudsbOVgQAAAssGDUiTM1TqFDCgCVDLAYCVuXUJcVAzAQxkgsEmMwpSb/+7Jk8oAE3WTSO0w0UoBLKldlg4ZUoZ1FTiTVAfwr6NmnjTkFPFU7M4qt+S9srFNhynk2nlNI/pPTFAhkw46ALgxjCrDHTc0cSpBbDhNBBwXAw6Vlx0cwRHfhHl87eghf0zOkX5LzgL7z/M1lZEPY31yTNbF9zHIEfnwc5/33AwAAAADMAgMrIRikwmJU+cjG4WGZhQNmOjKYBIZZ9PlQVZiWilSqgQJHko3DCaYWIsJDnkqFAFQwRDMMyuLVG6PPPiEMLBJJkUpm6VPkMMIn1bm4UiFpURe8D75TnyFhcgXDE4pmNeutHjQmJZJwYbg1z0yyk9tYvVPWV+0jzW1rTU1uOqw9lXx/xvLgx7Wal+t/04/2lXt1f1l2ynl6LS3YXWep+drZvPizOIAiIAABAAAMESwx0c0bUDtBGlMoEBjExZwBJChSw5CudR7g5ALKGktbVav+7TUlHeuzMaq9iDU7W7k2xGDQK4AsucVXBuQTLo64Yq2i8rEuYRgzTbOPYMGQVvsEM5xFNS0nA5Sitj2OoZyb3VbfYzyTpZGBHU1SR8rOmeazXgO5bbkjVHD9sK5URBO+3AAR0AAEUUm6OnUxS+45yDC7ZEEwqSiI8TOAESO+USqKMYeROo6HEjMJopGORGQnl2unSXu8Z2W/V8SMPsgRqxK9yfyO2OtZMI5YocimLMF3khUc0ufMSUKefA6FPjIf0ocOmDf2p8UGNWHsyofXWaHd2sH1LflpXJ/6Vxd9axUTDuVIvxZvwPqsgfWSSL+NtAgAABAFcbiIbgaaYIaA0FlhkAoyVYYRDUoAMAaqBBa6gwdF1PliFlJlKcj/+7Jk+gAFYWFQS5hKYozrui1ow7ZR+YFNrT0JwgacaFmnmdiw3sqIH9OnYp/kVuWZrEjtm7RTw0+Tk/N/PZneiVzhyNoNDpWhrJF2cgp0Kyk8jXk6GjLpved5ltRYDBMGAkCQipMEizIusmxFTicVerJAq1YCuIZWzWoCAIAMBCKTAswgKTAcyMPmIwKKCEAx3Rg8beXEnE1pRdM9OxTcaOJjarT0pEtITflMEMVm4EujJgy2JUSTZFfiKFTZdAQT6ZmKapQP5b0NWojQMMRizqNpi0A21nTRdNBDakiT+xlOvV9gnl5qoY2pjWY27YTRzorL+zbcPSPa503+505qn9zchBOO3DWG48oSN3i+JgmAdjMBOWTXRT+NmEGBdlkSIBKSRLKNJFcJODiGqUp6pEarpD0YaIacIMRtPBfOQ2i5uMGE4QrQqeDxBxAlW4Q3+t823/OpTGthx3r/tzl/ngA95jXivMQQMZ2qb9f4018fz/dF3DNPfC43GcnXvdblZD62597OTt2gr5O5+687gNbyZnoit4aoEEDw8CpalkexVPl5yIGPvfl938W6K7YABgYCjSCJEKZBTRzBGiRbjJioKgkfDxakQCEKl6bSDCqRd9VoNAbasAWFVNCeXlAGINlm4eoXkzYzY1cRVD2rz0jPQkq9Mg/JMInfhQ0Ju9CpfTe3ZutXxkUE64HgoFIxJAVUwjPibhRFUtZBtmhjS8YrwaqRYj8CQzryMBW9OEvmqfIzyZZaVFT5uK00LSaB78VRMzm3OZx4ZzVWGJUuQMJuFEcXRG883Z0jUZiWdaoEWvpO5yJEFKyoEQCZB1kjoqP/+7Jk/AgFMV5RM5lJcI5sys08yb9WMXtAjjE2we8rqzWDDuXA0Bc2RPcvRkqMTY4G08sdl0C18ZDnWrMHpcbinboUeqtOYz1Gbvt0VIKdy+5eZqChk6QOMv7581t9Mdnb5ms32C6+MZBJR6dNn80bubScv5FW0Th+pccZcGT8AcpcVJ5bueaiaxjsfkvqAAAgAEqACYcODSMYjBmQ9ZvycBRMFA5UPhbwOIv0i0DCAXgMCnc1MmYLKcWEqDU27bc2CNNem49SgRVHD5kQj76TtspNYeZd3o87QKgtmEJ9Cq4TVMkYhnLya9NIL6FnOdKyguQy0s/djIKC/nK/SBvPTyD42nlmFH+TdbFlHC1lK86rbYZlmL34Nv3Lva05ul506tyFpBGMULaDEAsoMXwLKgBQA8SBDqKaoJ+O4EIeIBkfkC3tUm14DRuqQCu4gZAEGt++ksqXZ3Ca1Vt1c7Lydzs5iUUPMF1cOmLFTBRjzmiLn2vJ+6AjbKNUi1kqw9RLuIhw8HFMlt7UZkdE1S1yNhnKlkpWrslfKkwdvXRaPRURGVvkHUQDAT5N4ifaukAGADkhyMDLsyRozManMMBAw2DTDotNDwX00BrREWAGzRGTILZK0BykbYYPCogvnH2sy5JiUwOy5lnMEnJrSgRUfZcLrH7OMtVMkjZULCHpKi0rlSKbRKV1KCBuoCN8uRkrqiTS6rUpT7WWwq17d6qSL+RlnLVR+2wtKbq3Vp6zFh7Nwje9DGPfHPOHlPVdqyVqarqyoY+KRNUl1EH+SXyU0uLnpKKAAgQgAwVSXSa+B0YAO1SkyTnHCAW5pZuYJIMiMAz/+7Jk8okFF1rRY3hJ4H2rKlllArgU3X1AjmUnweks6TGVjjFCcW7iw0EyCHHftpKwTSQHpM+fUCEqvkdqZoqxBw23KtXUOp/Vfb5mt8FS+eOrLt/p2aD281JGcz4ZOesP5/0AY5rDjZR/ta0qXqn5zhzjNzz+qVKeDE/EHV9oPN0ADAAAAQjAqdBioYhPnTTpyqwYETJBmKEJloaJOLvgqzTzQMaQhknUGPL6q+UzDDAkbUrjPHLcx6HamXEve6TqaIgvBHyEFXPOwf7NkLHgmCW1k4JkvjcUFVSzjFeZTlxMzOZonvG0ynmRXFOSt2uH3x8JuuNT+VLUw8w3cdS8lGjNSUzpT+2h2uzKvfdsfW+CLdt2bdmopkyhZqsIX3FE1qqJOVRq/BrZ+BwDMAABFwo8dqocce0BrhGaagjHAhh4BTP6LVstAIijpkgOmy5SEPvNddiLy21AV6rcl8kfLLDWgAUDZ8UxwGdNSMFBdV9iY7Wd4KMWRk5UlRtpUi5uIQcnkSjM38cUt7hiESeeqlNVFqgnzT0feVrpVF9Nyk0uXxJadMAAMMhUzIAzGqPNndA8qZTEA5BgeMApA9rTyJasYxpphipwCDChhMG5YuczqEjTJASxbNpTgpQtwoGftNn8GFurHiWcLEdm3S3Q9KhH5DHILSbDUtqatFU1vLB+38EZUX+yfxQIbCeYjwwYZOS9ey2h7WGta62YP3iPorswE2LmYYMbQ5/TlXBONX6YZd27Xzt9678B7krqzDbJ2XupXc/Ia/vZlTl1zuU/aem06tPlHXSSyJQZoNZrP6aN4qMNTEDk0I0MBg0QuIPDj8r/+7Jk+QolVmNQU3hKYHprqilkZbgWgXk7LmWHwgCjp4WsmPjXyUlK0nUYaX5Fl1L0ao+yBT8w/0oYfSQNF3Sm8JdVtEhq+0dHT5wxKmCO4pl3xuevDpJafCsXFr63UxCnfYnNx63s/UlGNsNtv67bU5g8qzmY3I2tp/mf8s6AQCh+sqhjqEpHkXvkVQQAAglOGB5TmEgAmBIAGTkuGdQzGBA3kgIGGYlmPSUbovLyTzcdYJKQoDaMZRSNJeoOXESNNGGcMxQVaVMRhnMDesmNxdKXzVZKQnDrTfWKKjoNTnlVYPzjAMylflqw8u06evMeWvyFEWPIQ9nPYSC3v1NXJW1a+FKugw8Lbr17JryuMF/Ms5koQ47mnCzU71P1Ip2dluaLdr5tBTLwHv2fa76JKZdZu8taf6TZAqcRn8sTpSToW+u+F0AALMvcOhoN5MMuKNI8M0wMqALntIEnLSh7E7qlikhIPac1YyxWSzDSmhQDEYCahAUSrwEnnhrDQf0xEylifZLzxNd+ZgLYcTUUMJa5nwUADxk61EklhMh8jC0uadJn6IuYdbbw4pZqt/fgTzLK5wN79JqKisXdiJv/gNUD0KK7+jQSiSVMY00hiGZ4LGbQBxTUmIoMZYchQnDm9h6b7FWUrgGQBZ4KFw4ZaytEu4uei0yJqCYkSxhkdcXAoMlxCFyRfLBfbjOjYcUuE8RiYw8vZlo+LvfH9Wy9Z7bFU8vkLSf9NkK+Y0szlu5MMcb6ALbnx7ED27POY1x0KHfABmKqNekd9JbVU44sAiczUN1xLJFmE5wSqF+taFMkyZiKJRqQT9JfJM3GUKJ80QD/+7Jk84QF0ltOu7lh8oHq+eJpI7IVMYs+bbDVQdOvKnWHjeQFconG0y70d07AxiV6WrsOhKpc9r2l6cRCBpAMRku4eKBODqRmbHBubpIF4w2/eezD49n9JNcDrSJV3HbfF9WzlIsjyrl220TStyKOeXPbP/5+f/lDUqXV/ZvL5JA4LKuftk2e30m88xycpEdDyjUZTkv5lQBMPCbGm3MSgxNNM3OrkXM5RSMVgFEJxGIo3BDBI/GaVBAxCQBmYWPGfThw4BnxIGCAxjWYwKWauVBOCA6AVjS6VK3dnZkQgmOy1Bikn4XuEpC2EDWkkpF3CjnCJopZoqZMyPol6Mb4atXCkjoQ0oaqqocPQY8JeP0QDTs4DxUEJDVhlpZAIRMxru+O+b1FhWWvSVmd5xEXbP29Ow4skNP6ozNzPuFFp9PD6hdtkk+bS4zLiHW9p/em/BpAz+wRtfXr3ytrF2l4G9w57YAfcmBruz/akAAAEwRsYIfTW4o289MgMAIpgAEgQQCZQCOyfbTghG1kFDplelw6BXNBF5RB7cmRNdjEcpYbTyqyzVV9q9m1yvlm9F0cYLiWJAzuFlVgYWXKmzjIhcIQAohmWRKUxzshEDsyhz9vj80nCXV/0PtOlKciFmsc7+dpeRl+IjcYl8JzY/vu7AAqGPDAZRBBlETnEP2a5PRk0ImJg2Y1KpEVQMUmwDwXb5Oot4OgAuWYeAyaUUdURBJmF60OAFCaoBKXkYS0RIxWOrJfJepvHIqGksF7b8hjWeecNh3943rypPzvkyN3sOUF7F/w5xZQ3dwt2pdatmle/5SeUT+fHb6mZ+S78CzsREL/+7Jk7YoGpFzMC7p6ZoQq2eNvA05VSXk67jDVSeytafWWDay/r7C8f/H7WQxypjxOK8xPgsz5OvEHptYOYoWIJvN8n9TNjGcN8S8iAGhQCW0i0piUl1DFsDC0SkBK70oG4t/J1MXmR9L9hc0ai4fp07cmyFeWKg+WnaWYfYU7uzpKOqYKfL+Zd0hkeR0pu/tRxJuBGgIIXcd/ivfNnKFEautN65/d3PpnUvD/UO6Kaj0gU9WJD4M9VrmoLwWPQIMOB1YnF5rpAAAzATgAoMZ0d6PJyl6lQBlkTHw3MOmYHDwuKNAweBUdQmjgILrAYkgogrcjY4Dy4TQ5W3FGdCawtxZisrTHSqAY7fWjQSizVo1JPPDMoRtj37aykASIMJ6pPVg0oRMWvFg46TAjOYlhTSwrM68YLG8goJEQnEiF+i9KbdXmItgR32UqC55URSvbKp/Jnaswr7RwMtMS4XDSkrI63YUVpZtZxx1a3ow3aXCoos5R+xlzcCnycionzDbGF9pIGg2zZUddaxEl1jNZ+/RyH0gBlwFSJxtp+QFqjExoUONiWLSwC88qQTQQo45Dq3KN8qaT50N61SVHyp6TBu72TljLIuo7u7pL+Lau7unuYPaXDgFFXX1FTFH1CcSv3JcJNu8ChMUtwfHM1A06paCI0WL5tESu7aZssf3W5sUe9eab+kKHW5tu0axJ9kCgIKGSAbJ+eNr0Ro2LggjX7e4U8zpWKheMiAEyEJjdVyNKqoxwLgoFDAZsAQFDFIp5Zw8E2sojIzAYBF1y1cNK2AEAAOCWof45wjhVoWhkUpbmiecp6JxoW9r6dZ4sF3d3lsX/+7Jk1g4GbWbOE4x98JFsSq1hCb1YZYs6Dj2RwiwvKKWGGhBzVWG5uVMpBVakjtbls6ZsOG0+3S9dRHfcxYH9o9FS54lfInqRrrqxwUl80PbRQNHv7VxnW1qL0VxYTtYLNKJ1xKN2zsfncWL1FXlr7Gqz3OacW1gqtuXyoVU0/VTWr5k+2iJzX2D6L8XKm5sav7tv6Zgdob/0AAQiKIDECD7MqEOcDmIFKCOrDxJPJ5QoGcVPTlEpeq9usCtSrDm7VCOCQ2hKSCG0W1qYuYRrajBNPc42vEtt71Z0Tz4lyqaLzXDAn20qaLjxVr/bNw6OX8xnp2ic7MbBXNn9qUytZ8i9ciV8WjHPMjwglrGDg1aqu6kWeCQThwh/2R3oSVpgxDvAlaoAJBODV2ClkKmRjHwYUlmPEBawy40tCNkv0+9aQKsUSX8hcXqe9bxelosKp35THYPKZ+UAYJVAeSiuKg2W1UPIoTALskkLZk/AiLZDkcqmRHuPvm6zzn/X0pFCxmLln0qgN0tcc8yNjqxO5SaJ35MU9tPpIhRbiU9xNBJ9027dlfTRk5iOOQ2uwie9Wz6ZANS/Q3LEaF9phBjXTI/6lXvW6oDrqAJgTJpTGGDAHI2wVUYR4NJRgeJTJg0dSOaw4TjFsSbwWJOyS1rAZ2yaDqsUULhJuiE93Qo47uNS0tr1FSRIIgI1UIzZDgEx0KyGEBcc7OY6GootNLJVOPbZyC6F6zlRFal6K5J29NEptVSbrwkMOYaE5SWuPHFjs5bxwMHxMBHkxkBjC7OMBAA6UYjGgtWSGIExSYTCwPlxEAFYFDC3aOitaSwcBF1rBhD/+7BkpoAFHl7QQ3lJcHqrqkll5VoYBY04rj2VAcCuaFWnjPkiXs81lGRMdvdtvMoZD2rmV2bpSopNa0/VcV68UjpsQqGoIW2tVxV5XvYL5rYLta5GNWksaNH+ifI+DxXHWJokmVGnRGVRQGT80Tl0oWqU7/D+VyVpz0DeXxcJVccipyZp57zBDPtylvbxUt6rcXxbeN2jce2JKqiUiwxZMUTdARZx42XzLDt6JzjK99JnI+QmgCKAmBNGUTIggtOCBA8AVkFQgjhYDXLq6CWHCVLeMQQhElbBkq2ttz1XLnFRCNcLVq6s8rMR7E6ZU2BkZFYZEFARs9z56qwr9y2L6/f62XOeV6FdM1aVUPup5t7kX0i1z53hrz06jef4J9qOPzng1eUADQERRMCFsSB5iJTGBpaWsHhiChOYDJw0JRIZr8RiL2tbR0Q7K7Lppm0rCBIApqwimYEQxmSiiPYmB/qXT44J8S+WRpR0WtllbL5aZihjZvB8H6ytduk2enI2pS2Y9tJ35KvusfG9b3zZJHG8N2o0uMYz83FMEBJkMKyuMU73eUHH6iAlZUdsyW3F8s3NLUZbOH0CWigdCalgk3gVOQq7svtiMTfw2hXOTHRwzMQPEEQhG3FGgFu0Sgdi0aEQJQPCClRQZClMrqhwYyWbY5h7NrRPNcJAh8O9D8P25zxDf1XzJuNtglGX6H3rl7WBQORDQUnpeLnee/1KPLUlzvx4GFG0eeuScO5U1n3C3y+k/W3/SAAJmICSZFBphJYGlKOCSWYTDRh8ImKTqVBuLK5bw+ROJsaaqHQuGHTHnsFQLEjF73MlLdnVgBulC//7smSmCAUTX09LjETicEUp4G3mdlPxezhOYQnBuCzq9YYWFHF6mr14Np7VZ/J97t/DMoUQH2kowxwwH6MzCIwwRGIvDgZMh2Ix+gcrUiCMQYJTfGCe7la5YSv4dLzM14hxfNdB+YXWdXuzzRdbxc42uZX44/tIum6Jr6ZVBruxKJUMT3AjV70ylZIldkn02ujvVTS1XeLPiEERlCl1mSwnT9L5gBsdqdWvEJuux8p04fDwT0ANAZqUrOjGNzmoHgp1QxDFqZZxsVdCGKj3nVlWUVuY5biIkMVFZdlMMfsx9Nm3NKzfq2/RdSsm/a0ydl+5cqCQ+WqNKgACcxgYDGYAMrsY1QJjmK8MagYmHQOShg0SByzL5nEUPM4JlohBU5oIFxLpSIBwFUkmJRPrdIhMwn2qioXLgYI2ycuqiTwgOMLHUDdiRRvVpTyhoTspVNFSbM4Xyr4ojzeQBtHczk5XWt9OX3KUzGItb7S2spX38hq0UVxnfuaCse0172MoJS/dVf/Nvbz1U/KHr5cKWPPlRkXiroQ+36CIAACXKIlYMLG1JC5sSnmELppkCxbLEIBfe+tBn5iQEuYgXhID9KSXqpS0PpcrGuDNFS6wgpzwEO5osLWTOybI0hr2TKj7LmeyrqQ91LTyn6fZNKspneZFdLOPOX2ZfQuEQp6k77V5UE3KBkX9LAEhFOmAjoAQUYFQgBgBkc7mHReYHBRhk6GWAFAyxAKzRujBE0I2TpEq1adFdGFVu2i14bgKBGfxOnmmUWKxUEthHRkcYEIFINpp7WREyHqORvSpVHSub/3SuI1LCMLDT4sn4+SmeL4b8IXZM//7smS9DAT8Wc2TmEpSbmiJ92mCdlPpdzpuYSfBqqun6ZYKEB9+I8qVS/hONsmJ+a++1o56RZ4XdTh9qSV+/ufcyq2v2JX9zajOoMMJ7UWd6QJqrCj+1YAEAABEkyvKdMB2HHWgvRGkHBmWaNAtnT6fKMK3SQesdCG0zYHV9mS3lwo0/TLXCuGamD/ClHeVWNDWoY0ILWhwjq4NLmXRrzsykOyr1Q1Vb9yn7deWlE/7f+5XdPo6X1rorVMxBBxYUmZGACAAFFKOccQDpE0Qo1egwTgGhFBhhaFAyZjBC60MsLdRV7lJ7gnYWY7xiD+UHGsmkoblhLiblpqPZjxwkZnMSeaTMou0zoprMEqjNnmbGrplnWdSpsUEzUlUHWmaI01H9SqmHu7F00QrdjecYuppsbuyZmqpVTMtpcNm/UvUi9n0HVQr1GiL9aRkXjzGQ7TdhoMHgunMXxwEQEm07wKEM4aMdMNi+NceQTt2MKDMgMCDDTFoS1pTM0FICRxCsEgQIfB1D6gIqQJ1Ex6RauPTmKFuflFXWgpNEIaqdhiBt2qhuJ50yXLkHclcqTLjlnTWHSqZTyw23mzvl88siu4nim7577Tjt0dNi4Qc37+OudaWUfdUP2KMPW2TI7DaXUebLmTCoxPLSYHa3Oe10E/btgAAAAAECAcAgFBgtEFGVFMZxholnjs6YNvcM3KIjJS2MDjMBTswoHjWg2NPBkoCoOKRgkRxcZFJlALAu5Fk41jHHMIAwU0OIyuzkSPV010yIleC1JC6X8XcmOgsytYN3wo8dCZ58lDSYaR6GyZYoe8iQjXC7jLE/TbJMgU3S3Ytw//7skTYgAS/WlBVaaAAmAuZ960sAGN5mTO5zIAEJrLnNzeAALLnyjkGssVgm7kNxMdTMNWQhAZMmrh/X2vZ0sXopGmvgn2l3K3fWCHQnpFBEEAJBCgUUi+49NX4as00j529cpJB3IQBKdq4ZLknusKqo3WictsGq01cnZVrKQ2JROZdnsbdvj5MQdt2FqSh0qJ9K0P7rc/95Yf////T01ipv5Z3ndf/+yywu+jhDprXp6krvRizhK/s///8Lbh4AADAQDBcGocLYiEQbBpDQZzOgV+OrYjKPY5VAMwIGQmvnhgAkaIemUBZiQ0PB5ggQKhNmIHGhbhyxEEFPJTEzF8tEcp0kzUuBcQWAoOwxulGshOlYWUIDDmFfSAxZLA2tQGz1lDOlzK6WaoUwSkZxORmU08fuQCzh7LTbPpLHte90XfYhNxmJSx+4DqYxiIPo0KWT/tbTolMXQ0ks9RS+EQxTfWj1HPT9iy/9HK3fo2SYsTabDkEQ+sSRUUNwRn2gppbf12bjdHNw3ah+fwr5qwRSAH3uRqBYCzhN+vWr41bNNc3znO/9e/hLMZZFLlJjlhz9w+2kiq145Q13/t4S/C3////5dhC++oCAAAAdwosGgGa0GOD1ohFBT65mvoTFbQwOH4fV24jpswYGh6xKRkaIMJx3Vnhtl8QX7iqWhrmiKpHPmLc7DREIc/YmKNa98YkznOXOFEi+tda3CeRXeMYxR1r71qBp/ut76pExEkx643ffxDt5bRXNqdTuR/y5fwGBOKh6+ljxnB5DtpgaW1QLtyXKLfqRD2dKrVF2h9FQX9OIQp0uHAVjPO2F8LgLupF0f/7skRVAAY3aFQ/ZeAA40zqaey8AFJBeVUspNOCOq8q5ZYaIAh4/UagORGMy4M8y2BgetU8JWQIrHXE1X8J0/vMADADby2JBkshzFmUUTKMHOIQCBIHmUOepIZSYZSt7BWtI/qOLBBwbYjSZlLVghukPPg/29DJVE8VJxEhEwDmJuJidQt5czgRxFiCGmOAC0DlGChGJfNIxZYWFxjjxCPq5Wl6RaZZcxGknCAJIXw6FYnWdQKiLBVywQTmiaatgPLqRhhwlYu58UtApqjSrYa5ZnynZkIVDIlYeXjcnHjPJJH9ZHijjzNzNiMvuT5WXXmeiQpRsXKqQxNrtbV57HKon8j8u5LyVngwl+H5ChM7UlGBr0o3F6xuV7z4gxt7pXEsSOuCYgjSoCaL5zAjsAEffkoFVJDq6bBWixpfahi9GxNLguKzDewmfiTeQ80XN2TAWZhFmIbHe6VSChSWd1CuUc2qzr53Y0oVEMKStOusqkm4KCuPfR18JyIbRu997M5jGeqRfKKh81KQkwTLFKaYWVNGI1DkqOXmmUX7U+sZTO4KVLbMzHg2NGjDb4Vn2PLykYMbNgGASNIgIFxAgpUFMZdtRgNQRK9O1TgOJQu9Yrd3ZdNx4ZhlOyMGcIyJFlyhMjHZy5V6i1+BvaSVE8O1bktWinw2yL6adpIlEG78tteTt0BArujAGY80fBdPvw+fsYt9NiuVO/TmOYDnlZ6KwpbnEfcJbKOVPRcrY8TEeDkpfe+W7Fu6AR0KSzzGWzJBs/hmAgARcUCAGUz4ZC8wBQWXDABa5ERfZRMmCqUyBK5/VmPPF4U8UXtikaJQplGSov/7skQXAASEXNVLSTRijstKqWUmiBHBdVVMsM/CSS6qHZYaMXJ0eTxUHctRLJJm085+YaRsv/rLjmoe5eIdb93P7dOiKuSqq3DyCYi/LRvYRePlfucj+WlmZjnHvXZ6wwlH2c379h7shuvLNuYV3x2Kqj7tK82DhEyMGWnf3TiiBLddXL/7sIgINlAE3lxGSCGTxmEJiFiFytKDEPvYlAsoUEWuzBPtocoY2sLKRChkWqBULAmDqN4hRRQH5szyRVgvs2kxxe99NsyRslwxIwST1unfZg0owVv9zRbgS83c/OMHWbyqeTr/LEbvxuCnv9ttolFzkt32vB6Rv+y9X+f/LUI3yneS22eUN2xXJPjQYMLiw7tB4BSEyEgIYINmo1XTgDEgi2aBIqCLLLkAwBdyyyUdgzAFzvASDgDd9WKyx7adDPwQNnRwPWa916TKFrOdap7T+xptm3WP8QtuVQ1D6OjLtX6rrwmNHb8NrztbmTn7HLzH+W+fYwj5zM3xW52+5lNbS+Y7bW/tLbvZ5l8fZp5p+/0UawUZGrLZ99ogmxWBUAAmJAAgOI1KzGDEAIs2SsERq6AqKwhRQePT1IQ0oEDC57MtP4hZ0knqg6eOkZKH8GNMQtgxiqba+dUctWrSHR6WLI2um6ZtMtbQi4DK1cpWO1naWMBkm0JS26JJcmaquxQ7dvPj5r9WKb487nf/NnH3ZKX6l3xKq2pnl9qaaxnnaSStX9q1grpqTfxfOoLty7m6BAAjJ0nMXhMyOPRbjGCw8KDcKEMGgUxwgIHG3ImoDDAQygxQgywoiVj8B/NAotDaE9zb7Sp9ssLddLtAyv/7smQejAVQYNGTmknwbYtK/WECmxPxeUIt5QnR2q2qDaSKoV5I4F8vxOXvIAfweyjawvC2arfcXxtTz0VGr6U3S6Syf1Wd+c82ixPaufzaKqdn5lR39NCnGTCe0HE2/UZVcXSUImJWoqltkTriX3dTi15Wm6sRP2M4xg8kZsaMnGmwFHXUmqS2qkrKpPkpFpUCVogwGWxEmIZBcyb6dBIEsyBAquYM8hcl45xgTWM5ZR2a79ZUkQYtK9BcmxauOQkuVK4JEzXrBt0+lMdzEREFgwtRLQyV1JtU05fmSafRf2L3Q6Ius1HLorO5DtYqU6lTstFXKWa7YIFDDIdQkATIS48cPMkCTUng2RVCoqGBQyAhysFyc12zBpBr5tzGu8YiBruGsylfD4FBCgRc2DpXHJt1FhGJo9DQDU6dMmeycFv4ter81A4iB+ZkDRYIij4ku7gzVnGYLSnuHWPW8aPjQORXxm98DrqSFzsfUjF+SA+6Z8YDMFW49azbuHQ7Ye0YrncpfTTzxe6UzK1xysiCKwptTOIJtamhyYn+BCnJEXTDMDKlhBLEli8BwkXKakvFEwwoRczMka09WLRV782M4zeUAMfo/o3Tlc2orAs6xGxA4tkhogIvNFBu/V7CjVwj77SxdjI5uXDZVpXc+R9Ago7IVdnNVU/y7zTOndrM/6PzrmXRmlc0M6d3sYUioAqglToVATbRVMEQx6/MoSjsV0x0SMVPBoNAwcYUTtYG6HGBiUBenixKw8wFltaSrSKLJsbkU9LItRsgiamSpywEH6CgTOJXDQQVCqporEgNMpQU8o2mnPtGHhuf2Voo+pNYDv/7smQvDEUBYFGbeEpQc6ial2UCnBHZe1BssRGB5Kup6ZSKoPvrKTzVCgoyi9b7e+1MR55VD7Wekp/0lnnv6XS/3L/r59g/teH/r3tbWMb4tQhUmIUQaeZ0zBpfdl7Ry3pmFC8tEooAndpbhHUBQjHzO0FHphwsBA7wN3M0lYrSE71dPPAsWno6lxOROce/BDAahew9H8jsFNTcVi5o1MdIjl9Y3KP/pZXCZWYeXW9TdI28Pw9xyr3abWt/Wz5VEnEspannTGmwCCQ2eeNnUPaIUSxsa0sp66+sJXW2cyAg9YgcMfZHZAMQlL/IEoGCEEcUM2creLrKSQ2hMRijFC+R7HS6g5JS8L3ZITlBOSrX62sneydtiVD6JyrdvQ+j5bjfg0RvfrL3zo8vxKDCcHLc7ivYpVad7pd8rPUxdkRlpZmkxlF1MCUTfQ+LoyvJ546/+FvxrNWlm4d0rmEHWoyn1HygCQIetpAgBe1tdHLB0NxhYoMtIE2UyBPdR8zEmvCoQoAiq3zg34RACBtqAZbCqXF9oEdbAEZeOcw/E7jcyHyifTFDE5uVssJtQ71oXIQmlk3L7L0Q7IpCFODdrukjJ3vKRkMpclTChcphKSnfcHoISzFWdf9/161bbGaVDj9CEAGpJJeTHibGOqjLSTTDAoLLsBwAynU6CPJnFnBlSaQCUGCUtp4DYips5Dn/KspqGodmWL29Ruc0HQC4MCXywrb2q4jjt0hu1Ec7zCLFzlvUf5rRliovyWnudN8m8djtRgy8lR/jfx/0Liwi89cnuPxBD2+3O4ieS7fe3pIq7HDHsSh0ZHCtYcCy7AIl1oIiSv/7smRIhgS6XtO7WEHwdAiKqmUijxHBc1TssQ+h561q9YYJtFDXOoPrcgAC0C7LklR1JSB7RGWOrWoKOgMsh2RJkw6sAnMqeUqw4xtjD2ykHxmTfTBwmSJWcUznWjSk9wcJQsxyBIWRJNetS2db57Wn0Hht3mf5REC84JrL3mTf7lWbaqrVb+uhkanYytiZhKjC9WkXn23h0+VGTMPnJqSoBoAW0xkDVGKSlCHPuIhS1kLgqgXWl+y0vE0JEszLweAqVEHcfX8enKr5E1fKxUa2tCyjvl9elQ7Nmuj/sW371K84UCCI0JjFg6mkAYVjRQX6hg0JzBUXbqD+Xv/f6ipMFKzZHSWKVyO+Sz7mJP5GP+xnFffuNs9rNXHF2MaTiA8qBOY8Uo8oD8nFOoAKAAA1OpEmkBEqD8gVcutDsDQq5BxgMZftMz5VWZRGJo0QA/QjkqxWusC5IwIXrRyIqgcV7dobsbcz/IbPQTFQoIcLSQUEYrXv7IxHXZu6Mtt6E1Of9zo6vO9G6bIR5Gt2IzXRlaf8jKRXRrkUdCi0GwYB8QDjgfX01YZsWEksieUyCRI3kZWXqPLtQLVujqsDO0wF0o9tKd+BqmEjeAHndQQGCqFAYzxfzg6stSrhVIp5Z21KybFb72H59SMBagt9K/Ol1BUWbVM/c4OOn1hhMCBP7xBPqpHF8X0yk4QEPqGSLm2q9KxuZ32Oq3SZ47t11z2bL/dkMV6X+9LGC6dTqkVaIcUJSDhnS8HlqQr1jE2LEdJcpMzC+1JkBgAS3JCVSoBuAjEViTAeZVVzI3DxfqRbdSlfKcouuRrwF2LtMUh5QtW/Yv/7smRmAAUGYtfTCWRYjwvq6mGIf1INeUwtYQfBxa6qmYSWIMUKrO1plfY/rXfndgmbWnpe6WhNMu618nnzur5PFx6WHAq88SPGofA2/jq5uJdkqaKqpcfWYhPkQko6NXUPBlbnzrdRCE34Kz5cafA0QBfhgcCkmCGgj2x8XYoRoPEdEe/x1lCAMM0IsZoV52SgjLBgdAOIgwFemgjCWSHlovK3jKhGFIh+ZRH1fo6NR5GlkYPXQv4pCxpnlN5wDofgobQfoi5FVMxF5B6zIoPzEnhGuGEM2iAs3KDzboYtDI/cQIUpC+XJTk8zgwV0EAG0ZVdjRyXAci163crDTlW1F58RDOMOJnvnhSKkcK3Yw6fep5FSCMyxwdpDKkhoBdYWMIglhKVKczIGeoAXNbslo87SXcitFBbQ7qwFiRmYcmJMNO6eUQH7/ntzQVcexO38lWIRqkEaLWVuKgC1NRlVLHGtRRNSWelOnqWvpRlLfTlLldql5n2ul/d5iHMgdO84q0o8UCjpjpUVgAFIgljMEjNBiDLIjKgwAYsQYAA3gVBBhkMENnMIHCgpm49Bac9KOSgKHZqONAvh9X3huWsdxxi05pcPivJMk6TkMJQ5c39rYfoi3uE0MhkVtdKb5ezVy6PP9VzXFtyo79RDCtDUr1Dp+VOr7lizK3eLUQYfs73o3iTn0edYqriLhhAnIMeGmqxgjtlUVrbC3SQANiEAssJAJECHg9Fdymi9lj9cQu5F2FrAsAhD+Q+TxHAIQMAaGhd5MBLLGyd54QLYSSdmy5n2+jX/+v9vwbBJ0dr1xnYH50+YO8qX+/ROXr9DKv32d//7smR0gESTWtMTSUXAa4sqp2VifhB1eVmsLHHh3atqHZWKqK9LPZ/PnCfXK8yPQIuOINvgwYH6FAIQIEAOyMgQcsn0RAMKwK5Ujjp3lA5An25yBNOUvWuySSn678tyBYy0CASzcsTmSBblA6CGQi6QooefNeCl9dfyhcKWxIiCZ1uPTfKx1u2bzU0vgwdxunjifOH1T6LUlI+xV5lm9POlwi40m/89S0P1+NS8hVMELEhB0PV21EHwmem5EJNyVkIdQNB0E0mjSRBDgyZrO5WtAQpxCSqMQC7sgZtUpF03clYnluX4FZ/yUgyfcynIEM/QfZq4k3nThdfX3Upw1ivEAfMomGROsxNpvbE1Hul9ysgf6aqlszZfdjgV0R2ytRWohdFbl06PqUvvmd6JqJtOtIrWEAHbZJKQ0aMpYBxl4UCkOSFCnb1l8V+LhYwyRMB9qiBUBBsYPZQwjUNmAbl0O2RCub+wWGzALRR10MTUeveUk6W0+FGiZXeqznVXQ+iVkqYSHzGbGOPlo9DPoVmOjoBR4pMVN6RGSQ5aCxXkfRCs50egesjrVhZ1EHVXDoddYOqJdBLcbSqDRrpZhSIjYFuS84oMEYBwmkg0hEyqDWUXCWfee6UwQlBjdU2e2crNcXzI7LZpFybvXAYvJok5WGbiaKBB/2au/pu9IiEcdt7PfrggftKt4ptlglgNLyz/uREeUH3L/U5qXreMpe14f/Prddi9crmJK2FjWZiky4QlsnEDVIhMOqtNEQhoKoIlUHyQwV2v5u8rU0fCfm5pwZaid+NEQ09AEpYHtsjMor82kBKH2LjT4bcU4v6T3+m8tf/7smSfhkQRWtU7CSvwewuqY2jDtk+deVNMpLGB+CzpXaSOnDJbauf2pWqCLQOipFQg3E04dzKmgq1EPZmcwMIjavyFa9burxq6GfL150KxSX9Sh5XqJmsPZDCxxVXpBBUJITVvN5TNQQcIOLBYeWDzarRjokDYs4LA0aWDODFrK2km5JXbtLfgKKuy58sHD+gfFIeDEqSJfAwHs6jppx3Msmw7UVMY+JLM/+Z85/flEHz7I22CjmU+kZn2tRKt0iPJSpferxgQIiY6ei7KOMp3zikGYNYDGonCtw/qALYRu2xuYdk6sUIjG0K2Wnplt3TSSzWQumQr6YA6TltLFgOEftJY+W8QWN40ZxVxjPVl3nXsNdUihJC5H9ve50qKnnX23oI3kiItwg6dEFOCL+iPGTf/X2Ovn8yh/M/KxUof8yty47gmo+J0j9xl95kfY/IDTw8gIUgnxVCkbISM5hJMaMjkWwmHQQWAZjM2HVbwwDEoAaGBCOoTyILTXYa6rj1i8bO2AlxHHg9fS9GeJRQAzai1e5cC50zJI1JG4V58zIfLjNa8jsLnkci4NndROVN6dC0RvT/bRG8GA76yN3f0dW5XetpcyvS7tqqxDsDo2kp6wDKmEVJfdbeMCbVeZkgXObgmAlAzsZCvZxVNoIcCayaEewBWSyD840rQokMGEOifFtENTaZxH6R7PlNLuELR0FCjcmjJEKK4eeIK8YAqdwdNaFDuLn06yyXrLh71Ouy6ibFr7fsmdYQf899KOiIevi9v+n1S7+XTHiPFIOKGPkD86nfUEAIzA1dO4IjxUY1o9NoQDG0Aw47MoIgE4wgJ/v/7smTLAEPiV9XTCUPYegr6Am0itBB1aVusMQ9h/CFnmbwc+DTwwBlQSBB6kBLkMAayfVOJGg+A8O0otAZIpZ0qSiin00szG5IbKYGEMGpE9hUxVCxZsxt7auurrmnE3qbqd0TROQ6GPP7ufRms4+qjQm8osugLFRSTcJaxuxKjTo4BQeJanwgACKwh5jeiM2krMrODXDQEJAhIjG0YwgQQkHF6Vum5GjGKkGygCXVzN4qqg0RGBWWFRaYhQ0tByrXhFhXUp14wfdet4opT7j191ROIRRg5AIiqQ2lQVfNCYlzBFD/7nkXVLKE7ci8p1BvJNx3BUjYEOsVk6Z2mjDaxgSCNu1XvbwULG94766xne0zrQ25Zn0FyIh0TJDpUoIaNh9wjNIbfyQQASocCu5xTEfSwGbxYJNzATswJjKw9NQwMUBBKuwtuUExeEIEFwjwZZKoOXFa1HhIsJgqHVtLpKoNQTa37+27yahBsQLzYjILmAo5DyyHV4+qpvi6JJS3gx/iuLC1XIsdTQj91fUDSDcx5TPVhtloCR//V+XRyMyOmzdevHbnZBY71QMomQpPUAQHfVgj0eI2ASJ17wvIEBMaKjp8EBAcOASBSgCgEbVTAYcwtUDrui/ycxVDxbUSnEbRaBQwuKo5+OeVLAca3lhq5aV8Rprgk7KzzWq1J3eUDcRrCYPbmDJrDkPxyKEaVjnSbPCG0i31FVmoHdOfcIjTDTUiUQKijPynHvYm/xSsh32VPh7Sp4aU2R6hCeWEQkfBxoIiRk0oxQAChismb9EG2gRnROAmcww3MBIzExNwE9zLzB9zMgwhISwCqQeTJ4//7smT2BEURWk6zeUJwiMtZ5m0CuBM5aUMtPRLCGK1nibwVaGAgN1Z4UNRKhto0NKHM0huA94vDZoTipjRQwvBjoJGUo598/ohF3v1NYa+rFzOLqrH7MRnUTO9znOYjMLupyZT1stCaMc9ZCM/3d9EknOPb2iYfHsJuPOBAfHOe0P+tBJRSUC5QNbJiAAbJImJgpgQmAQEWDED1GA4qSLL+oNMFL5MPV69VCpao6tl7tX6Ni0N0UAU93CArGlkKpZtoqfFA/bUTD3N+zOsMZurIlxYToNMOKdI5rqPnavpgPJ6fdM5TGE02SEgXfusivJgeTiQv/ocLZSFQvDowYlO+Iacc0bdx8rqwQEDYzt3OlZfvevczdbpGwYD/sZ2Dd5s4WM8h+EjUGEUPQqYuWtD3XPcubyJdV11nv8bxN4+XzzQ0iQpGlhmMxHEJagg8GkY9SYUNNJUxza9Go04kQm88ndpIlGZFfGHMCGDGYtbn8tf9GuhXQXxAxBNVCf072HUJ2M0SIspJ/e30s6uPL3vfNgljm8+b/n+4f/D9nK3+5/kw27X/6/26+LHJyW7TVuZyjHTAYRXrlJod2mblQ8iNlYkNwKD9/kIwu5ZXuTr981uI3bEFamZlVb/ZW3WoUEghYU4kSiBnByH1ENAnSLLedV0MWYDAwZd+C/TcuuO3D4ooKnPlC8KbL66n1M32OfstsPufGp6jR2EoKrtoEraKHkkE/yWmWNeoQXrxhnevKCc2CqjkcNiKFa0OS6angtYpFu5mMaQL1dd1DnXBoiTUE1EXd6nGEvk+0ExGC4yiEyp0LOh0VEuFOZJx1njWIvSMAf/7smT4AAX3Z9EbbH3wkqxKd2SsmFDBeWXnmRSh/i8qKYYhWAJxZKFA3oVILsEt7ogsyxE9vROR3KXF3Uykc1E0nVeLiQjieOmXgWCMTTItcPvYsg4fzP2sUNteteWntIOmZ/9vH1PaT8m8Eu2WZNyeOrIHiLAxV4dbmQ6Ee1DvH3m+NPJUgYuY+ioKi4ACKgwWgGhR8iRuyBixSqoVHsCXioKxlMWHGmwRDQ8Nb6aZXC2QQfqZFY/pfFIHp8T9y5i3XPjIRgmMMk3CjLG+P20KF+aohsSGP7zN86ya5WP+43Gj57aYv9IFG8yyuVpI3+dP5b31xMQs+U9xcUr5S68PrTfogMN+eR62M5Hyfagxu5LzSnFug9dslkBXPVR9OdUoHpXeFBgCrpALATUGfSDg4kJhQAsK8rRjHhWflmnJQTMgqtw3Pr3xn132LGn6fGxfFEoJs9VV/xu0TRZupbXq66UpSS0M10AiDPluO+3WUFYO/yqTaN3LEU/XyYlwhyEoQWJa9B+e1gMCmPXMYtjq5OEmp9yaCLONXj4UZtngN2R1GyqB9MCSK3sq0pMCNiPnhCbYs6gNqZ1iAEALMZxgMBgIChRkYiYiOiJACqieQiAQQMJBNaQ7osEIlb43LnmYaWCMXygtVdg1WHmIiN0nMcepC1TO07ix3Zw7OqzCum3Y29e5ousmBjF+ra3xkfdslJtpwq57LS1TbF17ZAUkGWv+PKOvTikxq0vz6KRJ5tE9leXRu1P2FdbUvri12ZUIbvsvViXLmI9TXXeVh+xVbnGbtBVBsWvV+ksaw/aUylX5QAYCYIcJoxhG8SdBw0tKDv/7smT0AFTPXtGzTEyglYvqFWkmrBUdeT6t4YXJ+iyosaMiYA6hAQGAINPZQZTSEqaPxSNrP5uNqA3flmUuC0cnjl9xLhPZtCXjW2ced3nLdjicNlCEDw+K5/vg5a0of4qPnsffzsK13Ep9tFsLp5dTs1b0aj6pBMjuGpoK5xj3jabhNLYlcZMeQI3wZQUFoFc3rQCAAAEGok0wEjBI5IaYIT8YcE5dIKjIKBB2ZwxBhIWFU6TQFiWHD1TqOGgCUWKpiTe2iozrHrO0xCQ383iyyOPdXTmSGWEUK1EdZu2YdJiDM7jWDJlFtGz1eTmNilCql/OtPVKcPKSq1nFrfdpfpmVaV1jFATbbvGV/DUbNxpu4HmsSGTcpv/3aTxWiz+qRS2ny83A/LRRiXRoANTikoSFg2szOqyIGsAFNAYiwgbmHaTOsS/goKXIsIjK+5eAMIl2lWoJnW078Qfg8ZNi0ipRC00Tx6u04iSqlaJqnPtNGowz/592vngwDWzxX1KqlKgFlMIyNs4I4fgvMi+n/zRjz6KI3+yrUdeUjsQ82nDyKOWV7K/s3kBAL1GEgx7uAnMteqEAIBGJS4t0GJghtDCbc3mXDwQXgEdCAkCBIjEURkeiEDcQaAYDIkpOmAUiVUSoIFYDqGVg25RJwlVFQyfLXNAMACi/mq6bWhwkUl2pLPSOeCluAi+zWjr4QizEZxhMt9h+2P/lK7+dZy8/KH9jVbg8NHbj1vOWO6buLqDnqRKOv7+LmIsdTMVfwVq4i1NS1ZXWpocvlOAwGCSoQATAG04dlEiEITTFScw0GHgVjYUEBUGMICysHQpDgBuyOT//7sGTwBEUvXE7DmUnwfMuaGWkjflLleTrNmRdCAKynqbMW2BiwlRPax1/X3gRvbOojqfjcP2v1hows+Gpxna+hgJd7OF+oi8zCxIAH2kCklF4RtfRaxZONFRVl1iZL5ql9lJtDBgk6Oj3mPR79vXdf3TEjGrbKxjKoqwKW3ACSiVDBc81oPABcfCohloMiytJaEuAo8PDo0AJ+yYRgij5ICl6FXUSvIIFQBFu5ko7AcMPVElqyP/lvjIDsZZGu+aG3z6IUOY7EcujLOvVSaW/SjXVp0dXG4SINUQmIpE+vI7r98Ph2hfG3ujTbZzaW1774VOq+a3PqdaKNNNIZxbuOajUdnXt5amtkgnlrU1Eapv71QuIJUL0yNqAIEF0ychl5iIGmGRGYPDBikfrdDgKHFm2OaaMUGRHSBeIxYAgFgKg7VoiCqHS4t4oRYjrmtKhtac5J+OHSzQwLB7bJIXggw4ug5IOu4rtEhIY5wlGN7pztdnDpWrWBsyCMRcXHRlSTdx2O6GsM6q6LFFqaZpOIaxpvcrOrNSpLcVUjPdOfWauOqQRT5lh6DToGj1JQZ60CMTTcxgETRxqOPSEySeTAY9KCSKiA8qWmSHOIUGFbkHgeNo84XoVsYpBi2iJXIbJBp0QA0RsI7xy8xJllA7wTUlSAKh2j8ZJk9zyosqWnT1NG8kNo8aDpkZIlMpHbvaWLlxEAbRuCdDmSQI2aKdew87ThTnKl+rv3P1Fyd9T8mV7Hmf6tNcm2tNZ/G244lSV/10al6x/I5Ol73oyod41VzfPwqBIATCmk/X7AKCYC+GTggABVLw4EMCAwQGoojAOI//uyZPoOxOFeTptpXaCWq1mSc0g+FIF5NE5hZ4oHrOaJthZYAVaiCEIEkqAcYw+qk36y1kJqNRjeaKCuQyYr4V29MkI2Wakioo2bLsjOp67PY+4mQXHgrnQTvOAg+ce+JvunXodqqJ5EXZVUo66h8m75BhI0j1YrWM1P6t1JlOz1MVFWsXf3P10AQBswEIDPyMOMwEx2oioTQEmzA4hMGEsaHBgAgGBwkSGmOIZhR3hgAUb5aso8YqpCCOhqbXWujCsNq3I6PeJHOJnDr+3/JSCpqIA5H6sRvRH/GIecqnTvmy7BHvk8ybGJrmSh/2EArL6MBG1LJLo3jjZ45p9fJaOyhtfv02Srs0vsd5VvdDNBAdnV29ky5h2Fccx2fq2zTpQ6xy3fvvWPilzUf2I+X3I89aYfZ0RLTOXhvXJim8zMx7lewEDICSOZuc0OOWZmVAWYIIBzzsVBkCxD8OMUpHOXmGCDSmAGKC6qvi17kJHQ5FZfTstiTcbwAAUkGp+HQqQJooYysba4wPh1EoMtnSPZ5l/3eqkprGgqIxohOssCg/bNnqr9rvt/2T2v0h5+6ssZe8+lR3MXVq3y3fE7kzu6V6cD3k2l9QlCEYN5hEWYONHgeh0aQYAUIJAgYAg05wDHGvUqCqWDSwiNBQOIkb/I9MyTtWZUn1DYdeBgC6mhRTCaq442Zui7QULxGiGWSkXs/w+k2xbOPpxEO4GhtOfQbWkRXvmzedhr/l/m1XqxhP0or/FXf2DefX710DunH/CaGXEX99T70/+zB39b7/yWN1sKT2vjpkTdQkNmv1niMvuE4IzQIyGYPDHNmolXEx+D//uyZPUMxdxiy4uZYtCEqvmBcyguk7FxNk3lKcH/rubJvBT4iZBIBC8BAYFKmkb3iTRQad5bFORhoPVK3tSKe9JxtpHY1EIs+se1Jux6x7iI10IIGIIi50xMc6WerNdyOEAY7qil41AmGDlE7PMMDTkMTqlLmZqNmY5zIQwy5219XpXvNVz6W0rJq5H0RxMYp6iGrY17ONVcEBMSTR8mNBJBUdMUK34AAJjkEC6mZa0PHc8LDJVy8iEF0U6lUxYdyWewxInxgGXSF8l/kkzSMHCNwoq3uPKAJVp0aAWGzc3N1ieNuW36sP4lLwkGF18eznTNk754tyGCCm4/iEYLNztrSkMcHQV1yW8LxgeUOFF17jdcXovbf5iI7TNc3N7Vfhp6xijsFGGPMKbD7lTiKlFjmd7EXDgRGzM/ZWdP01icf9hx9mQ8uuAABgShEQSDkQmTjAgwUHF5lwAqDl7DDgkWD2HuysQuGwCGxIDZA8zwJoo00MGr5icBwQrG7DLJTIr9OjVt/iiI9gWT1fTLpms45VO/KxhPCDcEy38y5NKr37lgz9I4kMN+rdxIWksztlPcP4Dg4MFObRyli8tP/Kil4kFSF+xMieWVeKhYcaR0iXnZbaiO+o+hHl4dsxRqK8DjlIn42BINF941Yd5OyAIShC5ON+32Y1pwcFGtsGILnFq/tDf1xTDzT8Puy/0NwtglFnBv4JSFUg1tIUlGW8gJIiUqkfJxYJG1mqKCmQGffllkpRfTzna9hlDgyCH0J5lJMzfmLKdI1ldH8XhVbL8YYtz27kywYbubnobzVHddsdiMAKcojqI+WIjQawdLQQAX//uyRO2MBYNfTZN5YXLHDNnCbY++GKWHQGy9lkrGr2jplibZDgm8KC0DQmOMmAOyRQx9mlGmIrXQ5+6+tqQZbrrGR6YIJ86VmudXprkRYkMkVERwfFNo5pz5xVejhXvuKq3hHImOnbzq5aeoHOQnwtKJ2nTlynpnYm6rzRxdeLchok7EUVAXBpuJkFIgvLLmQKF0g7YuySAoMgxFHV2E6I9IGJu3UROEYErlMdFR0LJVQvqwV7qBl44gWVe2miTwny5t0Zs2SEC6n4kx6zMaFa/fSOOLnkiImXOYWn1lXiSNZwfg+Jo+cSS55RPa7G1+t5KenXF8I0kp52xJdAB/kiReSZMWZesKrnNRpE2rFGqiZkZiubRoYygCpAKUTKRFTRMwSsEKgNolLFWUnF0pHUDCHfnH96sqAEDIABABY3NLCS9ZkCedxZgIjMuD0yEA4vO0gEnytWZXyxURE9gkh+YAhwgJbffaVe778a2qorDhlZms7vcdnaTo5JrE9bWV/Gh/1AdGZhNmD6Qu2XWmgEIAZbi5EovSEO6rm5y4ChOB9UQxiUEi/gD4HztrZqhKA9k4INOhSDuYg7WWW+mNuP2yyz1HwejyRmJIRXiiVyUSJmYlSSbhuIrzqqYxMxbg5+v5sAQpoRJwpEBjLhCoWU5DPHaCqkbVV2orVlMwjPBLQIw56xr/PHDD0pHjkyGrjgsCTcs76+538O3nSBI12wq4iY91+45ewgSh7ri+o6kbjq3NROcM3MXPMmNgQXBZH8EXxBlktSXnCNas7P9/iH8t2ad52xz3I9wgYqEAiIl8EKPlH3rdZFyQMgCh6fL/G1j5//uyZJ2BBVxbz9t5SfKFS6pdYWO4FJF5PE2ld8oGLuj1hZbYr/kABAEhSlwiGxaWRyRUaIxpEVB1NQw8DCwi8SGrzJ6kwXvdMwR4Ze/Sbyo793kfUi/F1Yo2WhLKKbEUGsxj0rjnUNIkZgG4el89zCPjEw16Qq4msWNQ5DmeyIJYVVvfBompJxbUFtZxSAh/GWvqksipQy1202bmfbRbNdB2lkMnSUy1gFnwWI1XVT1ZNQc72nW126GSejZa7oURrgBlxEgBEDgvAnsdALOia7ikiXq0UfmbLvCOhejyS1QYrNFMdqdT3eUSIVetSOAPVsfk/pnDHBBblUGF7OGxxJ2rw6rYu18JJjbcRF8TF5qYuc9hosjuZ/Q/RV/EkLoqyp5cpXnV6HZkN7JuKsqySnZ1dMobMgdBWQp8THHXrkYQDDIEMmgUwsHjLgdCtbQ+AgSCgbMU+FpwUQqUvCFx8DIBTABVawOaYEqZZLWCZNnehtWN9WnqBKBFBbsxnZJpOhdaTKpSzfAtHjy0rkn2aLEyLAWar2ow11GVvz7fWRE3v4J82McuzbHXye0tXpZWGyt9TDaWZiyXUaKTpEvHNRyxXmtgUzeq5nZwTcnE/OKR9CynEY90iRbEqg9bKPk47dCVQGGEBKVIhFiQYQLel6SsSlHCQYFClao69jZBGAo9JoFU1Tnyo6QlEbNnVkN2tqimFhpjJ6PvvmXfGusb+n+t/TVv6tmtIN9VdFLPekKbw5ZsQYYdKTFI7vhnzPFDFDbCIVIGw/fY4E60BcNLCeoWXrbPFgYAQlNmo2gATIwVNFhAwsNDKYvMkcQtiEAsxICD//uyZJmMBRteTguaSfB5pmoqZeKaFEVrNC5pB8HELKm1hArcPzDWHjIDg408RMgDhRIBMQHMEkOQkShLzp6EJQiRZTD4qWQAqdMJIsmPWoKvPAViAJjdBWQ9tNAXLciZY889mZxGoDXXGjueBpKjKi4GiNXeLPERqUKzpA055L/FC+htUoFDz6cu0sXFmZ3TJdZsTEpAsberndavNknjnOS5oVtQUikWxo5EHiwPdPQCAKwK05YyTCwBVRADDazrkByt4XzQSJh4QGyjtJRK+7nkncRF/uni1TXk7kz8s/jQU7GgIbNAVjyWe7EtvD08rsWOEen2TqDu8tjGdk5laeWkpaGf9kXcoyBWSqI8zmmqyhWzOj/rlK0qp1zs6wqXyNUAUMAAAWSyTDCQy4BjwwYPLzDBoFBlgQ00rRAkE4FtD5djhtRCAJZ246UjYxTf2rPRyJw23ORbr/kxrz3l+ba0ioIymOdLOfT/poxZasL2K4EJUwqPm1KJEmVG1+RW1cKHnajrbSldKIe9tY7TFso1dJrpXaCzf/cbJrQ+Gb9/M9qomj6lsOlik5EJttzyUvdUfd/ry8sxQJxcAqMulbeJBM4TNkChsXMQ1K2YS4v6QorS5TxFUPCtoJfwyZqwlLjEz4O3f6Ti2xIX33v8l2zUbcCd+87Ey9MqewUUJTQGuFL2KIq63lYjCzRUEh5k42txBibStm6icAoKljt6hAU2knBkGCEpK8w4WPOQgcPCoaFg9hQYyrwTxfkKgbRU606FSiy086wb+r6ahvsdirZIJeFR91ORG/H9BCH/vPFNnMhPA2aqoHb5PzD3fC3nfVR3//uyZKiEBLtg0OtGXbBl5Gp9YeZPEblvPO2Zdsmonak1hJbMB2qzyVRKr9kXfCtwopN8MnmX/z6Sd/fzVXwc/jrQPt0rb1cT9xJunHB9L4i5khl5dBvatn9I+vxR+wgnskEDZGyoj0NBFyQOh0hu6w5AEvhaiPMajJbhzodc9I2xLY5BePPuPBWuaeNV3f3Sm47wK90oL/MLTfswt17bIsDi+raoIIizanbTVHrEHkKuprzLcTxvGxWlEMJapCqVOkqVMghY0VeqAEAABADkbbpjhsAj4RhpMvncljckNTAiACk67y+6x3fAgOrpibEECjAgalVJAFxAlfs0NJBj60TXVaOXr+L1v76T1nOXjaEzsTaxl2GmzV6pUC5+7iuz+hBJmjRCnzwyZmCWrh4+SG7GXfBZ3NFTktjDXbdruB0XEA0X5H8d/FXdzXF348q+B4/ysmWFFQVBvOpJ4TWDFJFlNIQYcCaaujTVayXhDiIyDI50hA1d3WavOzaVuAu+RS1oI163CJ9VFod77kB6qYEqWJZ1NqoH7pocq8iBu5tWolFh+P9zExDDqSDPqF9MvmNyf751JpT9NWBEWeWNPBS+FvajXNtyLCy3nJaAACaSSpgbQCj8Ai5jwUeRRmelKAcrBQsKgpbQZiD8jA0k6xNii7gNQBNBlyJhuw8BMFMbolE+K1FaCfA0kwIYmUHPG9NTGqRTWm6y8XjI2POs8oyL7LNSiggP5JGuitlHCbSYyILVLik1qRJx3Xeould0m9FtZutaV1mZd0TzzhfUfqKqFZmtbmyT3oWbqupRm9AvOypuZmZfKjIFkmCcWcKKSrnz//uyZNUABNFcT2tpRbBp58pNYWK1FX17OvW6AAHjLycKsyAAJxiWYmgiFbJgHY5pTCWHhDEoKhCUjuiEYiFW4s2Nv1KGXKAJeAeIKALgyIroXHTMiUEcIEMIGDVwGsHAXDAaQ8Injg40k1kMG2b3MTVbyjutB3QzFybLSVdHOpGi6OtFNujo9uzq3buupN9SettaXt1dv9v9XTX68zegpHV5pQAACAAAQ45AmGwiEwADJh/OB3wx+4DfHJMeC85vzB04mlx8Y7IZmchmLByYJDxhMWmBxWLFUxCkzKotMRFE7AEoEnECmDIGREgEOhuKCxHFUirEBksZTGADxBwHTJWuc25NIEdJFUEjsZkglKaUuDQETbC16ZXrRN2eGKiyNeoYPGh72y14IBhN+63SLSWUUkZU3CA6tjFGuryhqIPhEXmeGfa/RwE8s3DtMDgiNENLUm5qKR7KjlOq1M8M9SXO2qCWUtuXTt2WOpLopLJTJ78SicJiErjdLQW7lp0XTqy64/cC00/PtTkzE1fwxK4vMRiR0VJnu7hlN9/n8xx/u/1W3b5ha///5916mofrXqek5f5btp///kv6Xn403fPI05v4BgCZkcWa0GGcJ5UYEheakkIYJi4aakKYkiYZ9i0JFeMHKDhsMKDPByhGOAbGfipij2cWDGTHh8IUAs4sBJjouQMwyOAodMdRwQTGWApqy6oaHDaomrAY9DgZN9ppjYUkIQALX1BdSGfohIGoGmP9Mp8Ps1hsdqC2ASaZl9O3KBpe81JQtqz2V408ddqHWNP6/0M4LvhUaqzcJmoehMdlcbprMSg2fqyim3DF+DoA//uyROgACN5ly+5zQAEcrIkgzuwAG8mBX7mMAAtvsew/MPAB3TvFAkph+3IonIKaAnkhMRtwfKq8VpqeLx/srvSLC/RUENwNRVY7J56XVZDDT+zGpqHbrwWpTBMtp3ZlPZZnzHf01HSRKksSOW1L/d8u/DcauwBR2pi7zttE1bEDD39CEuFxv+enHqOoBAFNkQlgwCgUCk0rJS4xJS2NdHJCPgYbHUTJhN5qSwjNHScGTRpaTOaFWGCYeL9gZ7wQezZ+5PHJJMqWPG3CMw7UqxWch+ZKhEFWLM2xkUCyZ2cb87EKthQBvmHtfStTG3A1HNzMqlny23Wpl6hxUki/DTG4NpDUSpsca9WpWqY3+TMrru+qeCqV+V1027Msr5U17KPU8tq52+VbuDXGVvo9UV7bZAvR1HL1a5qlwr/lurXp5R2r/MccMX0d9l8YvQ/Ua5hSPxnSSKMYS3ePcblNa3ljve96tVR21ILaCEETEZCJkcqDaqMZyOZ8Q08LnUPAUk9Sqs2IAChJL+gyC9kUXeTvcZl7AEu8IAThDE+yFgVhBSjXYLEl5rClsIQAOg3CEE6E9Q5h0/YEMmUDwNYpBKiPqZQnArlGrojxkuZa8uS4NrAqlVFZXzcpGpULZyKh5EoIeJ0kC4s7csP4sDD5tgVvdRtSoRm/Hf2XEj1waH7OzvMY1rxmhXs7G551DZ29nQ1wYornHhJlSODBEliYnhWi3kxRXs9ler51Hfs+KRO5raknonFY1M8ZskgyxH0V5fG84pO9RUbDoyQAADxdXKwJd4LibVAmnYrRAEPoBHLbRv3IlT1AwHIoIYcCWhYHRU2k//uyRBYAJFpeV+dhAAKRy9rs7CQAEkF7XYekz4pLrKtthhmpKHDSD6k1RaTrEInPS0FSzXxYXjly46HjSEY1GrOUdSjDFcoc/DwqDXsa2jTFW8IXnotTN25VVPo82ZV3NXUGXukvYxZdE3ifPlER4dVbiReBdZH37K5JcCiOHvPHob74SerBAAAEwxgbDR6iIqPTxIfJIsgR+WOq5SDS27xhhwlSFIywQFSQSmEWsHXoiiJyV0L9zTyaO5GSM7kLWQ+U03Ql7Qaw+GrQlAmcmlNhl0dbl4w9vf1MxBOsyf+a9iF3WNNyvGWrxjyyqY+sz2CktyvDFI+oVkJXWKtwjPK37CpnCWUpSN36+VUZKDiUcICb6WjHZEQiABF4KwSMF6BNqFSASgZJJRnlOHCOsmAvWs5hSRhnhg/Nc1CNEsCdESrqXFfwWXERVQlO5N6ii6ByhNiPTqTOUBTEkrUxsFO1InmKk6dJlsDJG6xyJWE+HPAnJX1E2Q8Nm+TjHfoU57zdM3b67pfszxWVB01CmfJ3/uuIw6Shp5RNn/1410Xw3PngvUeTaKWjSASQltNAOCnPDT/F9m2XCwNQ5Hd1k1wiXlYojwRjkmLWYRKS2gW1cUNtM227zcS8tg0gpGithypsGEkydAUj8ctBsBSjeYnCbFuXBKincgmimNEo0THFPTyTOZWppEDFDblS19IRrUQtspSlLbS92jiFNM8ydrA8Qgg/c33es7qyzjAxRbwXLjlDH4I093+odTeGVDIagAt0hpjKxopdiVLFTQL8roUWflPZ92zDSoGsI1q0cxJdocCrliqW4rcezErxwCgYnxSI//uyRByABF5e2HMMMyKTrBrsYYZuUVV1XYeYd0ojLWx9hg25EQkgx1u1DS83UOZ6nnb/ZKUtRjPG5E3ZURsx2fv9rGb7hyc6bN6p3PrUtd4uLrN9f0+yYkfCV9RRNHCN6VnNW/m8mULqMs4qoftvSQVHI7v/su9EppEDoABLwZaOCdpKCH4aTSSvkTU1rKYNvIRQIIFT4yXj2avTEdWxhMto0Kky2dSXp91Mfo7N3coifgMmbQ8WGveu0YtkiuVcfSUOxE1UNrWTss+8uL7kHLzo7l5jirJSBoNHeisq8xEwha6Qy9epl0T9PZHPBqHgzMKb1u+9wgdr6ntkj3x2cr3u6ck3Ip8W019WLy2yHRACMUFYpwJUJUhp5hLAmy/lAEBFfOhkNdCiVLiMiFK/ZX7C91qzyybjQdxjPiRg4JTg5jduuKw+RbVrEQIUzaXODtQiol1JRh+n4VJaX+b8PQsEaFpad+fjbPIsxgEQsSIgSHAaNqUcmy4YloWDBpyuh9IiRfU45DwwSicdSsClYdp+8X+OdVl4dVM60iQVAYxuLCFDS0y7JYkuRGWPPpVsrZTIQYmA7Fji6QbUgRmOXgYcFqJv4W60fTnC2ztZcnmNfjerL/fqEzT1qC1QBQkp0KEtMHQywYFkOcPh1Fco1+/k0Ig1Niaoh0y4KE6mVnmIemaAv0QZ/0J78WOGEBjFghxh22FFCjE83JL6f/a++25o6oA75oiITmUmgbTmXUK/n2nVZkjnAzc2Ouk3s7csImUHE9tHAM0pMkfac44WaopNukxrkSRyUoZv1yBhbLh6tjXzMTfFomHMezsga7yijwcs//uyRCqBBAtd12MGHHKESzr/YSNoUBV5W6ewbUodrOsxhJmxTiiOx7LkU5noeSOCM6are1WZgYMEZExonVdWrH/3JMKL0tIH2tQrR+BxvrUsZwpuyIURIBBYXEkTHWXoIZO7IwOAk+oy2FBI2j+AbCp8uKge1cQoSjDF0asiZbJyKMJZQAKGBzj0PRICJZh3lUMCgioiGkXYydjFILEsD4hK0USGYhY0AxAvShkYbs4vT6jFEU3hOrZ0rwhWKINQUuVebnf6047ESpjM0yBCZRcybedD78ujLhAAfJeABEAmhzEWF0EBEMLGLmQACuaLOEIkDiI6pWamLrLiUstMNp1LK84Zhhr+rbL3FPTmiIpjKYh1EBZt6OSKHSmAhXtRnAgw+okqowoSjSAxMsXdK5xV7767QzU1TM0PpRTGI9yKTerZWLvfmaYy4CvE+GJ0R/8aXVkzUmaaKoAGBABFVluGsE1JorJiIDjuGsRe8sogkZFgkhESoEpNCVYzsZtS9yatCx6IYRcOt0+eu7a+gxiL1q2YuYK7xBye6IJYibaCZK1HWQSh0DV9J3WjUS/1P3eLvs8vlTUYz2U+1t/H3H1K//vZ/k5X/b//ez2WiNxlo0/6PIkC+JWkb9zdjE0UZMAAMpsTFT3LbFUcal5AwRHTBWsr9oHa1M0h/Wtdf2Fjk7FQKQWoNrHg+IEHtxxr4QVmEazHIyExUiXcSVNfZ7nGW2IAWbPUvGhKHA6XWMo1exUx8p1djqqaPppMvGxPWPH+jZIfSuIRz6FG4ws83hvbFeqofqK3jbj4nxhhYtNSr47Fn+X/8c1PPGVIgNq5XlBC//uyZEsABFhX1WMJRFJ2qxrcYMOKEO1zV6wkcYHjJisw8w6xdbetISsVmBSUT3VU7btk1xrNXGHpbjcm3tyKKGwRUupmvG/Zmsw2JbkOxWuG7k0tspmpFk7myjaYg/FmUCOWYI+s3KI8KX2F2w8I54IVDhkL8z6FpQ2mS5PfsEntS8y+mZQQGzQOqbPyru1dSZ9QKhJAITBSUWW6qMFQzPX4Q+WdICqJDihG2kazrwps3KlUGGo8sEKUEU2VCEgUxJ29IyexOU/UEF0cmew4SKWmysleyb2lmHxTPTymFKz6YhbCBsYwIYx+FHGkQm8U/CB/negJFaLng/yNK4C2gIUeV8jEdYj2ETBAZFqGLKDLcPS8UiuflafnSWqCWA9nUGAbIlhnoSZgqHhCkAzxSZHGUZbojersSuoEdvaJb8ciOjmtvYstt0IWxydUdUK92g60q7B97wvycdexMbV/e8z7pP9G2wDKT9Hxvx++PmWrlq3vedE3LLiv9hZBi6E9rOjv0ZMVZL915eezr/+/UcrVa4RAAFiJLdLJQcu7G7iVCZ0ZgNKhXiu3Ye6dvtju15TJMcrK0HE6CWDjLbMp8RV0qxdlhjzd0oO9IQcIpmQJbKW4fLvmhlOLxszoMGGGniqzm5KiIVKuEoLNcHKHM10Zkz2Zl7kGcURUndSBNGWNqhNDTF2ym5uF4df6X9yUc5NpKrIyZBAZQYm6sdHQVA3rMEekSmatqX1VoZPLXUdmPAOUIF0MOmKkMi6VOIB11v2TEpsyjCzWJYXhiJZeBRrzOte0Z7Vk3WvLVYFz7lJSFNmqAQisVDUdFcmMYkn7jhJ8//uyRHGAFBFbVWMGHNKAaSqsYSN+UEVpVYeYd0H8K+pQ8w7ozkHNkhq/6w1voDNvCPXheWvVBn0QFyNooHud77e/v7KSdiICoIuNluGCBaB8HULaBjA5LgkA0mdTC6F8UMM1rucRhOvcaFfU7aiosOmYOiAjO/LPTrCTGqynSbPFzOWfXWh63LjXhEkG8Wgm+GYVk5La6kJo7cy2tc30ktx9EijmmXXYIZ8UIkDotCFxiPM/lNzMiKZylTWkMZCUwhL7bpBxZCjaQHaYgmaQGIQc2C2FBYR9MD/Vxd0PLHDPLK4RheDkZGKNuHMwofjVKUYQhv25QrSieOg0uUnyki4S9zM3G5pnPY14QUW8Yn15yVHNN46o6BnbdZSts43LVokKiT634KH3ftcugHQfHNDtot0WMEK5nBAVQIAIaKxtNZ9koqUNoURyAAASX5Uk7KTKD9PExQ6IxdVcqDYtCdRA67rxkPUXY3SHd775ilWJMVB3F0jqOQfP4SLgCQgkLoN7aprYSVCjLoq5WnqlpFPDiLRyfZFi0VcySXZavYbbVrPjqltiOq6R1uNqhJ+IW1vkY96tXkpOoscxyIEoa3+7al680i1ERRABbXEKX0ARIYcLCwKZt4LFc2PKrLUkr+rs5DTeXHRiAwEl3abDjh+MFrrlOMet48/ep/kCoQblUuvfhErfSRQxspzerKqQMFQBI4bo8nKZfm9Ul7lg4frnSjLDUot+lM27LS4RefczYizjoc2+W1iE2wXEowYTebq7rEY4YlCAAAWXLL9qWpmlQjlSgLUUQfV5YJa20hebRqvUacIca0kq/X26kj57UVGX//uyRJcAA/RQVWsPQtJ/yzrNZSO0EFF5U6wYdoHsrSsxhg5YrqReXyaxBQ7aPIiQbGmNb9qmHOP6PTSkU3NFDcIth1OlZymrESkYFEYHTvwfSbEq0WXkRyCuuVLn8zUSlmrOycNzUjWU92ULB1HuHIjIvFLVv7cWt+830KrpOsMgxual1PRgIqJ6Q6tLWWTqkiDMZbk113Wit0bIoz2NMGU2A4MziY4F2IED/NXw4Iiy9PgzdaLdg5NXNQChp9DlLMF6spse5yQjmGPw8Uu42ECZEWQtVLr3bTzKNl7RD343VM84arwvlPgYyJDBrtJtFN+lg/RsZAEklii4avqKNCgCoIXJIQYtRrSDsJxjTqoiqTtXogo2uL5ZBffyVmtPPfUWeiGdw3/9xppagQMQzlym9rjHJV7OWrEwzLxyc+gPe4LnfRM97rIlHHcVv/V3TxF4HtjxTxQ2MXsfJHzO2VXsckxUq5umYqslUYwGMhh4stR6VHMY1VYdY5Ans2Q24yQFXNXXVVhCCoAarA3t03JORebbvCy2xnA9mYwYS5mOqd1S6VQ3o7L3HbRF4c+1WlaRVfQMdtDEpnFDZwQvNyJati3NnicKHBZI9Uo5ehp7UdjIf8fzzzM++dGnsGFSit/zKUzt/ozvWFIxWcAYonI4DTmwvrXHGSSlAQsvW8RexBIpCqI0r9eYoWlYWafdpa8GeLES++AVpLbebOs7NStHEWlmz1TGpgWQIVZxMMQsxGIYYHmwvidQ3ISy+q/hk4YQqojzBj4KjegXNmnaILpr+P7v8AVzJjhCT5fRR+Cu6iV6f7CS6d+oRCFUpgR5sLUL//uyZMCABEBeVOsGLkB5a7r/YWOXEKVzVawYdkHyrOt9hY5tQg5DEvmUVhXJFlCJEgAx/nfZ0MjVgYLmkSjWzsCvQ3VBL1b3Oz5D2cIvKOkwKW3/qDvL1EVS3X5a500DNWshR2YdfEW5Br6SeTtUto02oXcwhR0P1PsNCIWNhTclpfVX6zgrn8iafZzKkWs8j5lrqI2VbJS9G98Vqo3212+nO28hbirUfFIUAAC10F05OmsgGVDOGrxQJ11H2PMFa/QpITl1blyp1WdLC7KZde+Wod1kyKWxB8XUoVYWsXI2xQEJgl2XYztTBemUeZZZb5xpuy7fa1NNXWpSrvmKKv1rGshtqnAjaLNp4TRoFRlK6M8r57guAly5lGFZCVpL57PmKNcc8/OGKFrMVlbJCwbZwn87a3WzLjWOiQSFIivpWxPQWFFgW7mJKNHIPrrVUXy3NAMvfCNscnHU2scmKsxmY3cuqyuOyBoUrgZ99M4UdavupRvvTb8ala85e6ZDcu53KPDaBhYcn8gIMrjqQMxY8BBBYlQZszJi88aB8hDwYLxpM3yrybLc4c4PDGKZnCwzpU1i+f6oY8SpxsvFSnuE3XOxloIAIQKoAEx4OO9BMgRDHgw0daImNYa5OMKqPQvF+HzU7lEplkFlAeUbTIvGJ9Yq/7NyAIu/PD82ypfcfLgZITTlmzo8X3smzCzB8RzQvZnMzBqO0EZ37K1QpgpBCyz38hR9Wt/RRua49Wl5P+l6P5v/KgJiFCsEVWxatKFMfhEfCfh3uhS3M/NoMeJBDsLD3JUFaLlGkRhRAiABEAMCsgT5ECoO0coGdIrWHNVe//uwROYABHtZ0tMMHcKPavp9ZYO0UsVpR4wwd0JNLijlkw9Y0q4rem9OvtKY1NypPdb3cIIo7c85izsuxCs/GdBjLb+4pdemkvyLuEdvyikBGKVoSkdYLA8JxwNKbSIkeDrQJkA1lUD5qzQQXN9MqiJ6Zik/31WzWturbYIZQ3bDg5C4zEvufwSfofmcvCuuZW9GEHBaC7GFBIN1WARbtNXiBZEAYgAAqGR6daa2hGWKGoSHJMVcSAQsReVgY0wkkMZWEprMy2YKAy/w+8AEIEOOFdFvwaO3BGb+dvTSoCc4of2UNvKFJ9tm5XkdqdTcAFPcdVOdvbM5hTsxiX/MfGhq7tXif3qcY6a7Wb2mN+VHZmdkqj/t6uO+GT51s8dG2I7tsJyYp2Hx/5yzGZsQCgLKAgCAAOCiDrmtLYESw6hDJibjS7lqIqDBGz2M8CWY5ziqjYRdAnYGJGGsqowmoMj2e8DwI7yHeENaHfUGmIDzEClkybF79JBR7XDbsu6B8o4BHE+/UnRVGRk+vkJt4u9z3bJt8ra/rfkPNI7N++07ve9U7xk9s7s///39/y8Djha1P3V0OfrKT/2yQBCSQAAcsqNfUaBwxK7BGvnoZR5esEyRWSAV+Pg9tMpZZhqWqHkTNw61uWUsMpdJ48xltBaiL6b1aZOqJDoUPXyTO2Ti2UJVocZVWmrpj2wgnyhFWzsvG0E3dW1sRJSn2n/lSCcfC3ezDvromQCiec6alihvzftHPn+wDwKhVMf/PNhD0X1MIVogekLMrceTvg3zq3OCiCAAABECRBMCRJp1xiQ5kGMDGCrFBOVsRUCajP3iITL/+7Jk6IAEa1rS6y8y4ozK6j5l5l5SnZNFjCR3QjAgqHGmGpDZQ4kYikGJKJm1cZdzCUNG2q1W+iUL7L3VVVpDCJRHWNacwQnw4ED1L3lwVWQfJM9PWg4iFMwvUomvpI0FMUS75nmykju2Iu2I2j/v5b/51FxIH0T1ZgDDRcHhFUtKWgE202BSyyB4JP/qaAGQIEAAABaDCTTgiIxryy1VBXRPJxWmoAmtsVZ05TZmTpq2Y3yGygGpUpJ7GhLCbkxySKeYJLkhKBELiJTMjE2UdnFZ+4E+UZJ462KYzmjThGQNtdaMrgiLNVcWMLolci3uQVanXMq+qfGsx3q4HDYVFDXMEXhFXMoRU+B3I6Ybiv5hJ+TYJutBWosNwPZof43ongB4ugHEBQAJDkhwEApfBMxqjUAe8NQNIbEX9VjZyroDL2nFfnHkwQCQLc7T3a+EjltyrqLQzK4KvX7lHYpWMsQoqa19G/tfSUEhIGYAmTeiNHTCkCEqB+hqII0WPQ8kDXHL5yJs4WcarGP27L3+hr+ReRTPglRc4tEyxbuRONacOecTzM87mfZgsQnCawfQZ10oEBwAEAACGQaTSwYJXEpxbzWzOyWYqSLzM5kSWjFn2cVxVR08ekrpFAX4eVtcyMv0mqlFut9/vXvxlvymM5kyyxmE2SJvCzRltJYhjEUrQgeDr+sxJuI0yDLZw4LwjGXiQuEWVrlrYZliyBH6icP7M4vdLwmYV4J16oSQI7dE/AanAIfPU/VSxwp9LLWwxgos1NXvsSaeoRyHXCCCAsggICVDQwMkIIFpADAJGcy3sCgXhLLqDSZuiCMdDdkrzWv/+7Jk8oAEtFpRaykd0o7rCglkw9YTdYNBjSR5AkynZ+2nmmE40VBDz37sGBbYa7iposFeiwi+2Z6scV8qRU4a1221V2Vduy/FjzSxY7ZuBOIJHHrPhfLcJgs10I06CubyiiJi6Sq88I7h6T4s5rOos09+bbzbZv1U63lnq+ZDxc7vs/u+TB9Rg5AIjaV5Oh7fX66qEYGYAGAAWyRqQ6kY0agr0ixyShGpe77T0embXI1OOI7WMOxF4Fw7vTdfeiQCxpfXhdaFuQBvouhVLIhLc1dYYql8lD9k6gxYEp1pw64+ikjMYne+zQvIC2n8g7lTd31r9EJ10UssQCISTFN3XSqKWvxCfZAxK1jEd9xbSQOouiJGtgQDhuaiZ5cTg+iiHhJKSiBd3XQXtJ7lDVC1rlCmLSibJSmWRCGJF3Q67yyoEKVFXYK0Z8GLvInzy/Wzk9xfTn9r2M8uRGFW8a1Je1Pf/Md34w4tJa1lU3d4bqJFoaR9xAc1np8M3Du2HfyuQIHNxWsBOajnMkzQWjZBNzcFeaAxxDpnmQMfptHPZIJ0ogMPtM4yujYuywhNXTZeyjZoSiddtNejjimKptv/QQq3X0cFwFo7qgBMOZtXLdggCaqCOhI5WIfqUPdWv1MoH41KRYI7APNj4R7jviPCUS9ZW99Shmt6CK6Iujyu6PiqQbZOZ3qkCPt7PKSj7ibvqA2jzyLZWITPi1u9VvNIGl9hzW/zU/aJsw4+OKx/uFutFT/jTdSrz7VR2otV4fIrI79y+1aVW0GlbWJsnKDTXTJWtk/ffUaqqkgOAoVIAAQZIFkCsECOHDhzIkhDCaTtuYr/+7Jk74AE42BR4wZN4JXMin1gadhSbYtJLL0pgi0saPGEmnAazhV+diTarTC8ks69yX1QHDUkTEoozM8bTFawPAXb8WacQI4qwSUUimxKzCSm+c6tTbdiESyxWWzU7tWivUP75Ak/y3d4r5s/XkFkuzZvKOwsp4bs7RRL4RtuYlHdJu9gqm61/nvu2RVnPE0OrCizf77Ag4gMQgABmBgN66WAQSG6NUx10aXQLXOs2JiECRCBH/fealcdbhDNmA5ZJ9YMLTVhVWU0Us4N5ewCDSCAHN5mRRawJB5GpU4PBoIInsjsZgJdXgDniC0KIGhqFJ5vODgvr6jtJEsPapuPXj0kZWNQpnpkOwy3V7nLEyJJu6hX2LsTnbukIP13KRrfCKY4ziWy3y8fF+qQPFa4QEmADAAAFrE4WkByJTJZz7jkUGA4hI4m05RR91cYztvuqB0lvfYSlqCo/B7c5Z9Csf/bHYY3hew/Del9nLVdjpT0fUaWEWGz//3Zjcrn4el27rRX6ktvMf1uUiicslWZiXbhOY3A2Cva3fpaznKR5c1jynjI7n0tscHSh2Lm2YRjqmvZcXyhvLfP4Vi3biewUgQAAABGLRb6Cy0pmGnE9J+KPmVyivRo2vu1l0n4Z4hdTPvcj0H9lbTIE1QpurtZM8a1n9cmVCJjvePKnkMeU8zp9C8F8XMmULWGJ5tQ9c+xW5bl3lG2RafuxDklEOY37W5aY9rLUt9zZzTUbSQS2cRLdc9HOaSzmMQ3LL66zt7LVZCsjared/8yElryYcT4wHyTEBtfxk4g1CcT9WxvA3LL5G4NaATCAEAEOiaiMFMYgAn/+7Jk7oAEzF7RYyZNwI9ruhxphpwUhYVBTDE2yfysaPWDFuBgFABiBVBIVMlmj3RZPRsOrdrWOPGr7nqfPtdmbo1LMxGd8go5KpBE10nh17W7kY0bvz2wimMuP37eaLRMNKMLJJEdPLU/Jd9bE5aGFysrO1EflyuqtbLKiT1YtSlW6mdDNsmERW7ihQYHhMDZRXRV0CQAAADISheqBDGFgNSbRmQXsFlmrJCPc1hEOHn0eR9EkKsNQ0cBHI1HyPngoFzlypziwvP5MCwUWSTWQpMCiO8EQUyiUlsoJJs+MV5WXb+sB+d7AmaSQHJd5ChjGCzufWlJdX/x8/bkOakxKhS+dJazfVlHokFdRXd7Fy1a8/6/TmrlRWv3X/t+4JzxNz4hM5LEFwSZk6Ypk/L5aACiAxAAAgG0INTlayMAQ23Qy5BZhdi/FfRF62toRRd+sO0MwrGVm8d2OzVAyBcYQC5Xndj8wqdFBTVoqIkLnNm4brccq40WeyCxJkjYtgwHGpkUkDKMZHmUMBIaTU77yLYL3aHDCm6yF1Taj/WI8ssm/En486bamUeoGU5Z2tCAaAAWFDpUwAkSNpdWlEU5dQj1LhWYtyw9VK7EG0Eg0UZuXKdq2p5f0bm8nI/COGxdUnj1yZZAoYjWeUcWmrcDx4RGlrAO1mLnE0de0REE1UxS2PU6wxti0ncXJ52xi+rk0Myzke8Dy2wXTN3I4j+z3JA1eUWjLVY1l5ufZSyUW9TShnLEoi9tX6kSss0mhl0sl2SWUWZecZsLBJsRfI/z/kpAVoEEQIITgAgBgxFAaVQ1psZ6X9nASJQygUodNcE3Ws7/+7Jk74QE4l7Py0xMIn+rKfxlI5gUNXE7LLEzCgSsqHWGDpgXtLDkUrkqmu7rs8JwxocEyDFyS7ETyTTVil92mW1ZRvroUO1a6o/wEaWjTcSJCq1rTopYKax7UQp7/1MszYIoKKIMid9pKWDLHkHmeVpOc1N5uJ8yKNKZUBFwmkk9PHpALAAAAMLHndXwDEwp4AQFGc00sLiQcLQQjoQQgi5yjqdiVKm48fp1YH4SnZNTwDTzVJUUwHwWrBAVndR3VEVroScfDuKwheuFQajqu0PGo4A9Jv4tJkHXMBgJWTDm8qNNwsGQ2/C4PT6R1LncTjygTUsPCZA+R0NH+yjS5wHv7seh6uElyr7piKvQ73Uojrsyn5QXyHa9VWZ/OfVkf6ITuZnitTQqy6RSLIj/PrMsr4FoEAmGiAoSwYYAo4U/zrnIITTrzFQUUS3iZzPBCS8yltvkPWFV1a8aSGX6yqLyX59yngGpjqJV2LThMLUJcnovse7UxXWq8gfeO7P3VPy4v1Ey6/dmJervaOHk1rravPKqfAxK67l2f1l74oOo8t3ws5AZ4I65hoIucsZrV8jLqlfO//9pGKHJ4cI0ogFAAIiEgMQioMY4Pjr2Ag0KghhEcCREMNh4LVGrwdB5apQiqXYEQJLIQ1oR3FB+GMPt4zAEZBEApFky2lDyEGk0xzYO4elVmO8Lmlm0nhAHHKuqhLszDTTnjMyjdxUOQlcyNrIjXuj1OE8Zoq8vTXOxC3uYC1NSLHs/kFjyOIwF3VT0xJTQYexJaG0gKq1yeelWK+xMbUJo9TOvdyZartVF5t1qSu/92b9M1ZCoZLkHOED/+7Jk94IFfV7Ny0xNMo0rCbhlg7oXNWEzDb0xygErZ7GUjpjrPfYT9vN/miGDIRhAVzCdOJUyXADsCq2w1DDmNkcttHqZgUBu64UWidP2ZoUp1GbUvocstrLT1wet9tm4TlnLCsYksq8mipqJWc2U4+LSTghq2MLUjEMiAgwIh0YzraMPQrjCnZf2MqDMiUU92r5tnzuWvlWzy/55X/z/NGyp0GwcCyaBh/ilIAMgBCAABBiTyOLAh65oIlVDJvyDmLBIAkcGZKoP22tLExaWzSdC1j8iLR2LM7cLqWOVyaSxSUgSzbkpEjx4kLMsN9A1lkefD67zGtQs/OM4fWiYexo0Te3/v5Js0hZ3uXf/Z4l6w772x1r/7fEsPebSW+3+vjWP8Tb/+/jPznFafF/9fHxr5+Jv/nW8sGqWww216alqLsaF9S8DYAAABwgCE1soLeIVIYOYZxF7EvlgoZ04zE2dQ63EGiuHBWlyQNGcwGV/Yg71wxqM+mZ1fJWSHGT8R7A3uCzRL4hSUan0Gu4uaTakhZ75ziUrI7v8Q4uYzdEzJCdfNcYx2fOtQdZpLNf4+dX3vP3JbeH+fS2PX637b38XtW9PrxN/7zrdtSf5m///8laYkg2+YEHsR/sYgABAQYAADmaMZyceZeEnaOgVBzsSU7YUERWeDOG0iRuWuJRIyHGAj6W4CCw5KCoeDjCDMAhitAkWOpCMIz3SWot+iWTyg4kwUhlNaoUMWSjwny3BM5jbXkFKeMrOYm8kPK9e1YqZawCpigNdrPkx13LMUzdyypBdjL2lLahpv1LHmbRfUCNdasrCz5pb+tKcmswZ6HT/+7JE44AE1lzPbWHgAJdredmsPABiqY8tGbyABHIyZe85oACjjgSxzkDEGXedtKteN9ukJqRy/FIPg2EuC7NqLtLkTU5I/sblkMOJLXajmcMymfp5bWu0csllajhUmeOdnblJJ5il1YgaU7r08htU0lqP5DWEvllLP1K05lb53T1S52bs7dkG/r81h/dZWJ29af6VVo0DrT51VyUf8vIf8u7Q80AAAiaAAEAAAOYdLZhsxrfMjHA4Q2jRwWMUB0wIBTDpCFgcYYN5owoCgCMAFNRcwcFSUamCRmcZsd9GBQKhqE1EJmoFDgoQ86RQc1SfQcNOLLxs8UguJSxtkc1UXVN+VGRQOUSulgJrzvIp4LrlC1gaBMCXMmBCCjX2Zyl+G1li6FxPW8UNOcvRg7G2fKkMWBm1+y1abwwM8LuLijzM3cc2M3LAYMYA+rmJyF+G7QVWiUJkL9RmWPDVno7JYhIpHLS9cBWXUeSLOQrhvH4tTcTjGHxi7S0cbxm4tN3tTcsndXMo+48bhucl9p/7tNIspXas2qD9YZ1MPp7N2hqyiKZ/Q7y3h9l96eZh2anpFlTS/gCA8Yqwb//f/Wc3VCAAUjUACAAAAACikzYyUiZYgUOgw8U4jEFQEEb0IGq3BkRTMoEKapeDIRFhznGN3Ca5rqpyuFCayl6nffKQuu3ZcMBrDr2ilppbRke47KG1f5pbzNcgeLUT/KyubQPHEH6js7AsEUkXkFaBuzk7QTVvczPU1T5PUkMPUFFVk28r28LFqZppiIdiVzOz2xXo6XLnbWpBRY0N2P1t6jNXsz2g1Y5u9nu/36XO7c3RTG/r4XP/+7JkWQAG6mRSbmsAAt3Mal3NYABSoXlR/aaAAkKuq7+w0AS2JX9jedJ3LdNUyr7tZ7qYWM+9paSpK3O7bp6/2M8crd+LX8IxI6+VFXQQAAgpAmACAAACiS2nFqzUEgKZBLYQJxFfJEoc+AxRtxQARGhCMMGILdr6IgTmTDSQqkaCYny4kUpJOh9kLk/85QFgTT/vyzFk7cVry9UUVwdC/cdPJrl5RidfpoM9Zdp0r2c1FaGP43ZfPxigkU5Yi7xbyrS+v2Pciko3HZi5ewj0WkU3rOlrymdmak/PTepiP1Lu8a+V6xuWZ8paTKc7T40XaTff+vy3uvXq01rPsrqdv2K9jHWeFeauv3S0udBfndY1e56wvTkfzpIjT9pJzVfvc5BSvjybp6LK5AVaBAIzgVAoiSQlDB0wUCARKAY0Qh3fU3L04UC7Urnul/JYs0B4JcnDcLIONJTGom5gSQcJ01HEcTUkmOs6amJsiitFFEydaKZmtaD5ki6J5uvrnqBLo1JJvZI3qWjqVrWm9auvpJ1oEi9Eu6zYyXOmLWNakZ5dBJqC03VRrUikpZizKYzQUUi6dRRKB9aKanmRiH2vkOoEU4SkNG2sbSdXYJKBwnWlQ1BC6RoUySVI9lsXVf2W5XXdzIFEBOmqlk4CDAmSskSaSpKGyJYmSQsyiiYjOspnkUWWkyKLGiTPeiqZnWWut6CVA+Z1WoLWzHnTf1oUGZ1dHTV1H2UktHU7TRb0lNUZJ6CS6jVdjF3UcKRRrQS1smggXTJ0TNJFlJtWdARIxPdtDAS6YHKgEckhEy2EBqQRbV7CYGR5VbCmbl0i+gqBJ+T/+7JkEAAElVrR42ZGIIlLOl9p6KISUXlJrb0Jwi2u6H2ljxA0tAvGqnF7sOL6KArv3MXhkbhr1tV2Ewumu7i7LMaGhidDkIxihUadARuAweXSpsC5zHKn9hvtoKvZX0HD9q/LCU7X7lBLfqT8fAvB3E3UkDLhz/pUqEMv++Ki4lblCr3mbjuuwZPoXHCBYhMQbQMgi1FYSCQNggHG0ySWI7Q8RLZJmysqplBkJJjQMF7LOOki6sFbvz0swrWEXFw6+lf0Lj08Xbf2o5qVmfYnJNp9mKIIwSUSOuFPrCapay1TOB0AzM2k0suMAVtf7iS5hbt/i4Pomov9/gj+4Vo+ed10r7X7juCLvmPuE4u6lVSoJq+ho1FgSYfHqCjD1VAgFGDBrSRKEONZIGQBApALlCo0+yTwGBajwekr0eb8kEGsF1dZQ8+Ae+dO3I/EsTEl7xcA+FQ/ppEE9re1SQ6D5rgUHGZKh1UCsmO4rVhwCVzUsO2WmgWPuC2boo6mv+ZjZr+2rx5V0q30MH1KpQzsfOx+91Qy6buJ5ieaf8m8lLv7KIcDmkcJhzQjDNxMgiyFoqBgFAwGAUogAAmz7mWHs9IgYwCCGRQoT2BAszYW6YMCW4j0NYU+FnKVQ0VSS3e4zE2OD3XnE45RFYOrz+N26zTfcMw+hw3NHMOnnRTh7Wz7FWVMmpT/LYifc5e7sZidPP8uDkXrm20jBH4+spD55HKZa0+wzjSamfgR86moKlB54cbJBIm2Z7iUU22lBA44gGgCGcGgqdaPRgcHgQHgoTDwcAoJBQbS92XWGpixS5UNLRBREHFQFrGCP8Uz3ST/ECr/+7JkGoAE5GDP45hCcIaK2fxpA8RT6V85jiUYgg6tp3WkCxmj6KDwm4hnGZ6/nMqir1a9ONQYfcMIJqywZoYqjdxUdANjjPJHVsIQjXktbKlY0cI8w/yZZuKDexlG+NHNjEThU/l+Lx8kxfN1w93rPzC8XFz3dTUc0YK5aiE9CEHNW0E+edUY6Wa6sAPjggcQoR1NhFCWOjIW7BPcGB1LwNoJq8BGKDBxMLAlhZXTwiRbl2BUPRWvX7aUsJgzwP1SyS/Qz3M5hqsxSyrOQrRNzDLSkhDY0UJpDDxdxFuLVqr28a8qqamgdQt0d6xL6L9OBW0peLhT7kUB+0uUTPtf8rDThv5J7MfFEjtXEHRQ36PxAAogQAAAMcJggYckMTAAYFBIYCNIKAIsHEjkKm4lyS6jdVcNKV4Bg6kKz6C2UPiRFa7F5NFWXLhUOpJNgwSe3Zj0nS4sx2Py+IlMIoURgM+5qGXre2vIaSxycqpc8z1VjGsFBmh5dQNVcnn2Fz8fBEbRcuQTw1XYLjmyGnWx9zKXjVuJg9sOjq0m/iKx9Cy0KxUwPHWHQnOBVpQ9Bm36QgMKABSAQCGcsG10mfkQhIA1wMexl1RAHDBUZMiL0XtWnLrdWxuzSFhQt/t2NwEQKGDR9C2pEGDsVZ3nKZ1Y1PymtDAhNSpKMlmxJzQq9PmI9WlFjO7NmWtYuxk8ZVr1LGIsx7mR/Ih7FOEcLI1yPLZKVpaZ169M2ys3K1IljhRGJY1ECAJoQBACJSpxu7srFAg8ElQwwUFxGWBxyGmJF4hCJSZa/HH0L5pNu07zD0/SY9nTORRp3vzI20g6q3/KPLP/+7JkHwQEq2FPa0YuMIMrWm9h46US+X0/rT0J4guvZvWUitB9HJ+vZokEW+aUGR4mAZfiN4Xi1A4hdlCFI8QR7fAfNA59GmFfSo+IOrh7M6PjRCjGlHCpYx9R7PZErysNWPderJtOIbpaRhSFhwcxx5yXdJWbYfUcj4KhALRwzEvlbcj6gklOOAuWBirIBGGBHbwDRSg4CesBui0CXvFGa0ojxCBqet1aUEuIkLzbFdooGFXVnelZW7/TcrWFd1hx4W7TBFdq2VJVzT0yP84SS9ij8UsUosfivu5kWGWuKjYCcNlkzdVdibyRyyhlyfDL06pffL9u1SoYKKAZLoBApYAAAMMpkbsXFIlRgDQFWPaX3CCzqsYhIY4fA4WA/RhE8mRx0gM4Oq7WyXJiryjMk+lKYh6nHlj0Y15cWDyRCk2QkHHajT+BCD9ctlVVbxUJpk4PRHvFQ8MGiztF4rq9XJAZhRBJu9ieB0E1MxbY3uOq0Mqade6i5PP/hoGOP75xkn1yYtew6BQVnZRJUHzPEjNMTHuEAgCKAAgAASoVijJZEew81Bz9OG8CsUvwlxPGuG+TPEQoz2GIG1DdKMxEz8alEqhIVXHiX4aFjTuPE6/QjAJ9EjSLWgItvULfabK54ztTq0R3RjChdkZyuVnOqpBHRqidyDyi0oD9i86ncq/Vgecn30GpPu1vUxby+h3s8S+ZlIopkYpVECRoaDSZbc556mCBTsPLrpdhyDABCt8tsCV2yucmIy3onEmSJk2CeJyKJqbHCYImRUZMzNiwXSxKhuTiJsXSdlYkTqEwNTCsneapKW5ot1u70HesySmUzPX/+7JkLIAEclxRbWIAAn0G+cytTAAXmYlBOaeACuswZ3M3MAEieqRfUZLrPl5FaLegyrJWdq3fUgzWbUZr1q0UulZa0LWqpPOmhrqd5mV1zpeNHVN640vu1oIAmgAIISaTwOQCytOQDBgZ1DgIiHoS2oPEDkgsCTZf2aiUgPJFAZwGkALfFlm5BBzwHVGbHKJJaJECufWxRIMxo5oZEXKJmbLRJovTpcJioumh9JBLRMlbvUk6FSaKVFBtbV2pKWkzTZmUmayUdFIhkj6z/f/7tY1wiYLbgMBkMe+2t6v/zohjFFzFEDAoQnIYoaat0Ci4VJo0lrmwtore6qT8JStRgQU0ANyfC1q8uwYSQHyQywagnKFLgv+0S2nwuTRUoTM57MCLhuDFEWIMzOnku8VbK3K/ELUBFqeDK/Z6trYumONEUsRrtOtVgxK2qrWJlqwM0Rwz921lty5f5p87rEga01T4lzmHZ9mXcetNbbL/w65pjWHutz1rFtbN9xbQ9vc7r9f+H6Yj2j03f//1rmlqRLmdQMAKQASLb/BxpqqcIyyNLuDwIPEIoIHYpRi5QaaAx0SSiUHL8Q0LDiVKmrGxjga2IKAKUZUG1RJANmhthaaA2MT+HvAaBkOHEcE4ibxwmQo4ngZIuDAHMIGOAcwdxWEKjQGbKYsQlMkDYqkOc+ieZReMWPKpoGJumiRUwMj5RTLj1opIWWpRw5NVOhPLTbNzNkTdE6kcUkqktN0l2RfsmY0k0FJXUkmpNabMin0E9Vn+pbbLsr7uarGTdSQCspSMhbbrW6zEMBmRER3LQcA6gWR56OSOGPMjkUo1sQlCxMz/+7JEEoAEbGJWbj2gApNsSs3MLABT2XlTPYeAClkvKvee8AAihfJYkB7l8E+TTIJxEbUWlqZIGRdKYl6QQI8jjG1Y7C6mShiSRs493dS0UVzMvvmCZ9JlLM1XzB1VpqzNNN0E91bakGdaCbLpPZNToKoLdPemu2ymVP1LUzqqZBr7/7O1TP/2QabqkwYFAqkAQFatcQpDAgFQGwpHzjEWTLxeN0ku7DPrcMSCjlhdWIyA5Ig6LLHkkh5Gg8m1Y8uo19GxkQjRfZoWbj5UcPrmbqslqXNz1ow9/TDQ5qJooWy7bzbejh+bVha2UfZNRURfDKa91VwiuxNrqWew0m4m5Zv38TxMREPdqwfmKYgyX3f/C03Dc5V9/tklrsXPoSyBRAylATIH6fZr2amQgNA7td3I6zRsK1mYiYL9Vrct5ekns44rePG3r+sE+96vrWL/X3n1xn73XdN7hn6d0Zrmmnr4y6uqFk72d5tfk1jWtpyRXNflxuXMPNpd3o88TVpYPpH2wQpo+G3W5b2bZ4+WTOtQqtld73fM1Im9z0h6/cJ7w4dJYT7OaZU7EyQobCuKVb4V9wW+JmB8LSPeghJoaGpLNAgAETg/jSIWeJfAk6BM09mJNSGZZRKx465IW1cuNYMxXKXdmVuRRA1+JnFTtV26s/tJrW9b+fbP+dff3GbnevW1/TUbDqdrVevS2b/7cPSL/m8udYt9axE3vEmMYxHxPR7GzWbeMxsxNUcN52+8GB731fWZ873euM7fRJd03B18fVaObhTGWLXpbNMS2DIV2dR8d5tII0+ZAACHUpMl/zAQCqQTl0UEjBF1pMA1kwv/+7JkDwAT/FrW+w8a4n0LKr9l5U4QIXtX7L0Jwdgu6r2EliCZ9IclS61xEwk9+q4CCMMZtjxMxoUHTxtFNXFqpzgYizOTZTwaFMYaCTvqX4kkpH8BNSCFtPyBCMFheVz8GvrDooMf/g0Us09Svu567dyOzOQNclyjMVQWlDiQ5cbxFet6ddUMllBErgAACeD2IAOp7RxEqkMEMskSXCoAiM5QxY8emeYPgILywDqO9xhTaqQ2BW33k+74fHKceMdGUW0dnVRV4wQA+/luoSFRWj3s6syP1USYc5HWU+gh3O5LKtMtz5OQiUGO1UsYx6UHrM2MV5jh14KIAC4BHybr77KlYguSUkPSAggFO6dgEDANLUVldcFqgZYlwLmUT1nbIKDj4ctHe09zU4n+J5VXNs6Z7ePGPUhmrO6IPI9RQmJ/+K4Zhgjh5PEp4w/mRn7/MtXzXjGE1zPwqrwgdXebMipHsl9Stcsn03Jo+OqfTnh5uBg19zG4u12CJbVGrqI89bqZlQtScEKyABViTbIS6ifYYldSFhesDNWxFvqZ341O7yap6QSTdQMiHV8VB4Vyab+isJekMCr21MvXZo+pTakAL364i7dLCIsrFZ9qkmpfMfeShVVSHTcuhmV1fQ2Hr1OXOOoZNjiWO4QCyliwdYzJmDp1HYTgWlZwqyUDPKNEgoZNkbBQhAxGgAFG8RNtyUqzKG2EIWnidJR/F6LW65VgLJutp+4tTm838eYrc5iULC1y5IckDOI+x74sLTAZCGLmCJ8WjV65WvkYlx/KSfevfM+VKKunnr+vxfWqr3d+lcFNPCrz1fd3ya19DDmkkV3/+7JkPIAEE11U+y9C4n2rKn9lA8RQPXNLrD0LigCtqX2XoTlEoy+aH4QZx/su7BsCYKesSIAKHNCxuAAPDkBA0F2Q40xkj4BFRBJj5q9W7f/1g/4912rXW/HJPZt0lCUD5VccrbdYxb070TB5gjMtvXxOgq9angGpoiuofuQ87V8zWUSer+WnJP/3Aaexz6vGPuItVfKMfV/ZjlMpEb3n0FuGHfgE4Xk8X5R0jdUERJFAhmRDvu6LKXOMipG5SRLl5EEcACWKxFHCTWarNkq0vb3CCya1NNKcUGf52Zg8a03XFNupsIL1xHU7C+VXzVRw60UKHeLh58jDqoqK9m1juYj8he2jUJBYnRitpWpih3R37qOxqf7ftHSn1K3zRN4PHxZQ0VHq5jsE/yfXMEEsDAg9NJEGF0TNNHQC2Kwznjns2PLPSGGPOKx5YWdUawEM2pkHSHQ5ElSRBZE5CSTuOvhcnh/WYg5rY83hr12iasVkKzDRW01qqeSqcTOTF7ybecz6XP/uOdNaU2TLn0u5mq4idiriWZv0719rXVh//0XYisUPCjjT6AjxOIptjwVo6SWNKkT5A4ak0RV5u5F0RVcRFsHqJ5zVE5eObXbbRXzz3ijFb5nIZyOupYv49rKoO/hrucpvjwk+MQzWBbeE7tUPhbpXnJXAENnXNn/SS/05m1xsXAxyZ/GNUbwHbh+5uWv+mfMslvafOl5fJ+UtBi2cnywpQE9bpHkpELrBHREyAWjsq5h1AslEMEZG5DRG7Bc6KMcUpg+mrPZ3aY/MHvrSy+yGjk2dF2dJiyDD9gRnvxChlKDnGvrxliv4+UD6akb/+7JkYwAD9FxT6wYeMH+LWl1hA7cPwWtDjBhYyfSkZ2WjDxCpo0lrR5FPLciGv3btrZf/9MlboYW4ogy0mPZaMvKjG5KGIlXpMIOvnYc0wVcs7FCooIKKOofo6AABAQBhKBjRKztqVlziB8eYLBMvZUOhny2jnSyWu1FtNiyT/hWOD0A6Epzqz1nUM0tJ+PKBcf5az3n8XLocLU+ststD7CeOXP7FpMBC67mGP8cZ9R+1QsiPymwZdHzA99wZy5+rs6La7J/1c+zFfOKgCkcMGBtajMC9ThB3JYDhAiEABEFXd7VFoMQM1gP6FIii6kCKl99ZE9DM0485kZwJPyls/34ggctudj9Ji1RpPf73jcHlq/nbChdViEF+p3+U/UNAQZcvO5XNTKJb7v9MzZT70jIGrOimWCjGE9ASb5+eCMqMVbh7BHnnjUvmQAUADyAu8eUGLqd1VVoFwwBCmECortXwwFLgZig5FmAcb9PYLIVgCkeC0jRaHCiRiEZt9s4SeS0NBx15YUk3f7V4qt7vSrpAy0nDoPa1as+l1T/r3GXZAWnnOjiJqzk/74ifuK/v4XiBcfx99dSX/VTy381VR16dFyk8B4kS0LIhjKpQXnSxQHWCPx59uhIPgAFUQCf9d+LPBgTGSoUugUBBAusOaUZEz1571a292OAtXIKr59xtFBjkwurrlpV1vP8sGwQ/qtUwiNOazmTo93OoEMzsFdyoGFMcWuJbdmcre2CKR50/qbI+VnyAj1G9WsR9mzvb5WoxOeol3kKDlx6jfSQhYygSQYImLVbAXwSKBKHxp0BLIptMenISwLRugr2rlHq7P7H/+7BkjYQEB1vR6w9C4nWLWexvIk4P1XlHrAjbQeSvKLWjCxCFWWIhXNVo9hqLQ5G869uAXmzz5rCzT287fKKwfyEaghIIodSKXKYjOg+FbIItD0nMMxCLqnZ7l1Blf6FM0GP5sj6z3XXZji1oVnzw0H4x4IU0nIxrpm0oj+wWjRQEYoIACMoYAYIMnyiyMhgLGM0GDE7WXISaurxfuLuwpZlihbaj8WxtzbrwBqYbomIyVeE8X/l9e/Hnnn8syCBR4DJ7qIRfz/xGxEIEE7JoSvWiMgPeiJkoy6EOeTTb6vtwen019/vX//0ZG4zKCrMISr7iHc70qmWNXSj77I1IZQq0qOJloBG9u4F4F0RRckkitG+j7OP/zdSC6LPDbBdbmnLxrMSj0BXHda0vmBHkZXKLkPOiyiSTDSUBy3JAykS12gzGJERuhk1NkVWn2mJ7FittqOdpVmGQfqdnp+oImdfez/yP76I1JLWzyJYlrolqGIRTsNW8dSAcoGcAMtgVTFUh8FqZUBDhxblvodZwkVdWRDYgiaYWN+HVOxvk7PleaprHMqnhWwBeo+BR8eqmiQRiHOrHBZIcci4HON2ln7JG1d6po82RYBhWBpml2N5slyWkYPNGHbKv/3351lCO3fJz3///O72YEd8YwfRme1SgAE4j/rWANUCUAHHdg6yIBfJdriXmZQ8+cFVxx2TsTPCffVGNorTiqvWA47r4EXFILegLT4VRorxEokXFa3+OjLi/T9LMqXjlE/c/gz/Gf1ddzfp+a9qwy4LT5sj0tPLjROeHvxl0M3xri69Eiy3JA+RGCabJAntRZiZB5kHNnP/7smS9AEQLWlXrCRagfuZKSWXjbk9VeU8sPQnCAa8ppZYhaDJhkIAWX/Nro3DjaDdJRAK3hgLjtiYFMqR/ZB89N1jwAN4ep8pW+vCtiW6uuu2moh0GNOVbTztcwnyOE9TV18zLsMrWK7/Jln7j5eLn9Jjmau6xfhJb2qoHNzdVFkfMlzoKTyQJrxofCIMQUeBoeiNzLBBI4YKinJbbEl2LkJle+moEje4NOVIkFHzQlAGAIgmgaoJRDYFCjhaDoOQJCYo7alrXLPK9eDWO6zjwkSZqyvevpZrmUqm3gShs3Ie1QPstV0dpTu8ooan8bQ8tl+3uytVZ4SgjPoy9yOtr7xglL7gusYV+PN5trgYHSfxjai9lrq4+Daxa2xlVaJbkyV3C/LSPUwPZctUvcdcDBajPW0AEN2CBKAEAImFNrYLEpYruYwIL0RmIUSAtYSHgQDALAJO7Xbyt3jJN6wTK+L5SF6ZVn7PZKdWWYi9hJEW+WqaozyBIJq7n4aLkJxGNpzammH0LOQ2vwZIzW23LXoiL24rhpvVB0Ksfa/DeVf3NXE1cKKmrHfjXqSRweuwuYa9RGSVlQcmUJrAaZEBUaAAAJ80JxirsAIiVhhIGggZykEu2ke6uVAOL0U7u2/kF54WOasNzMKJtyuGXmnMWnxiX7mqNNxluGUzrA5G45Lan/PRy9eCXAIXvds38PecRX6cqexKP5u/cgN2Tr9h6JuQ5FumN8QaM4IvUOYvgVnnNyRYRR3DzvM28SdNA/5QpY7aWUQgA7UKh8IN6zXBj88XybAEDLIUgQAAAEEUCTo0YrGh0DApi4EJCI01kyE0i+v/7smTmgAR9XlPrCUYghuu6XWUoiBMVjUetGRjCPS5otbwY+bS6RDtL37lrZvtIy9lN/edMPVjMigqteglxrV+MhlZ4c8pV29bOd912lKm0EAe9nzvvjlR//D0FJalWb2eiot8b1uV9g+bejjll9BHzh+sbGMY+9jrVxVZ3tvzwrG2ZaDENdZec9OW043Jn/lC1jf4/lQIahQjCkiAAcRahQNeNSAOBUM27AwIRAJQeB29pAoAQqONo0SXcp8W7os4U7iDoRlfdBqU5E3WpK2ONhozN7W5qOA+rT09dxhXDuatexDcvADgVU+kTna/9O3t3I2qTTyMxTd5Ul9W+8rc7h1RVNv0S75Nen+vBAl6zKLLlmLzPOv4lS8OSrYzy3TnNJayy4XQnd9vZAQ5aCBrAAatadSEdRqAka6QIXMVwBWMyBEHU0/IRIlb3Ifl0ndq0hKKwemthubXvNX7TLkScW3IIxNjpLzVBY+la+9utTVVFbXlEbgzXKLVN6WRWYqw30DKtGPsU/eBhR5MCOaM+HAAy9IRVimavI0BxwccwIUNXED+KC4JlwVq6cFLCOgK0gYgd0NvNhShWkAIpUgQkIR91ZhQpIXFooqCEQEFE2bwSik/L5t2MqGUQfuPPc1DBlsbgtT29S4BEYhp0oEvYtRz7vLcEKI2sNtfI/ORVlRyukv6xN6QJ0b1I1qVFTgpgm/I83mRom4ubihxtIWSPiTZ4p6VOhoMEJoPfaRg+YW9HXkPTpkh/9rtdoUVtylvbFakFRDjhCBsDY3Gi61J12RF0AERAAKxAGNDRxACckqhiUh685geEY0KEwsnqSjTCrv/7smTugBSoWFDrbDYikIu5/GljqBMVez+NJRiCMayndbwZOPren77U7t0VnZgufw25BICCrkrdWdVkATXQkNutG24KToZ2XNmDbRUQ03+m93H1i6Cm/fY8W3o2brxj5oG31s5HtlI99nY/mZm8nnWbSLxN9FhVFY/+8rXeKn/e9US7OqoMuN7VpWSgm7IDkSSFAALEIGIIEaRumYko6UtsYSOAIMBIOIg8LgKXati+GNiAZfeMKyKAunNLqtS9oNzKhIkJ+rLC1w9kkMzNPuZvwCpLVmf3Ep0xZBazBVcCNeS9TDPxWsDXqQkD4RMaHI5kQsVbJa5KEKa3i/74FhH7u1QRxk4sr9j8fisv3/A0IdBS8aHVpAs20DQtYmom0hgJ8j+iXak8kAAQIA0hAEzOHNsSTwA8DM6CQqhRmLgcEHJXtELUNlqvpNMMWOhwppowAapn3nt0zvGEBc1LVUbfx5V9Xd7KGw3+6+6olKb3jStQtDVA2X4liQChpVxaahlZ4t+KvrGkeVW3K5yfCzfyrMl1QnUb1UXDxTIjRaWUzKss39myKJsWMa+pmrhL8QV3qf0AAgKBMkGOiVMCzMCCMaZMEOQ6lUcSBkiWTxOVFnEo4g+ir3mpmAvvUfLKNswM8AxsLAlrSM5s+7x0YGuiIMrnfMV3WykfPobamoYXGUHSa2RHP96La0S+aNgdr+SDy6mfbdlS98Fb4MKSvk+6+R9nevVlT62XdKn4XzzHeirWityaz7orRdNKNVX0qZO9VsFAgrlJd7zkmcLuhwCGgAAadOnWb56yMb6EA0gAwAaDxnnGakk2wbAh4+hcJPmRUP/7smTwgAS1Xk7jaB5Qi2j5vG2IslNpaTcNPXSCTavmGbyhOSfNFOGzG7LPcs6KGQxqhoqC1FFZwdFGopRUkjaWyaM1qj9B42NDypOaa4NeSA8MQP3+ONxu8jxv9jZ8cENSMXmxQTXjD77e/giZFHuxUSHQzayIxZllCKNXqWKs910vlbdZ2ZPi+qiCKkdDkLGndTIAIgMQAMzexDF8HAaORgBSMgKJgYHJ/JOYMsboSsqRCJqVM02w6CZls12Uwoxrp7y8CgXwWn1GYxqki7xpwY02WWIBrWEgiH28rjBhA6KS5gR69IfkNSo0FV+QNfoaIlwL35V1vRXqOM/v0HamiPxUPUmzcliL/etErfFvzP1acLfYw0ffAyxgPihEh4eKw8n34jJbaOsg6AASsAHABoteZkZZkYkGBwQl8u0GQUFEFMJJEGpfVrIzuKtVUuNo92zcKnZDhytNJQSnOITk5EVQXqtuHYmwFkkampe8KruSC6dsvmEeYsfNw/l/qh/JEet/bevPyXfKLek18Xy7LoI6uQnSjhKZJXfQr07Dx8qP7hPu6nyTUvNfYXrEU4d4mNqStlMWABYSEkAgo1gQXMXiUHJBy6aygqKsK8LiMDf8tekA/kAvIRVYnkvi5RRCcIoLkCWJwnBFBaCuNcTEcBPuZl4iAaCxRP1lwvJMYGqSmWXqjh9NSj6CZZJdJq3eZnFIHSo+ZmStM0oLe6B5NZmyTVKRzrOi5o6i2aPSXoIpvMS7rW1SaLqMKVk0qVJkjxiyRgtFq0c0ICyTkSJAMfPPOVbrCoQATSZs4iZMkPBoQUfTjNAiSbXWymkz1lsYLP/7smTvgIS9Xk5LeEJwjGs5rHMIThPRZztVmIACMaumprcgAMJJvE/4sJE+VwLuQgd0kGSFniKkTNxviqQIYIKkwkXkioNUPMXyqTzoy0gzFxanPmh9jhPKZi4aJlMuK3VqQQZItPU63rMka0H00D/Vupt0e1IsGO/YvrRsjq7Gq7VPuvqd0lLqWirUnOnnl4Vkm9tRjnCRRAMAAEhs2Q2g0DOxOBJ3MOCkIyRmaMpemPAUFQQYnFpjkYEAtMHCsxKHwMBjFAJMbhkxQPAV4ZJ5bIegBfSSRcIS9QBmY2JUIQmESpYhusQ0w13CQCEk0xzNYNoYElCwJcwQHrDhUUBJiRD/l1xkRFAITYkhclcCF2lRSGnHiD+Bh67y+KDzRFTMQf5GpDB5nbkMip2CQ5nFH0fiQQU2i0WdMOhmo8YyLCGv1musXuXqTGRv5JrzAnahT7y2O1vjsFS6kmIlTflKoPfqy/c3K38paTft2jb9PxMVIrYleTwQ7BMF0teS2Jddqy1vWbPdEniwZw/8Syjdvm8GbLyj8FQ9QUcWprVemoLeLit2i0F/qH9v5RUlIG//+fpCB3/ktIGAGAAAAAGAJIIsJ/wiFDs1NwEQsdzInuJR+MsKmh7BAaSkg1hNAYm5XQsHGPBwXcjOwwwzMt2JKlMDhLmiwGt6iTXLcOQZAcEV3UgaSReEKgexecNhxNa7DJfuWW8NNMhh8pbY7DqZKZ6DWdPN44+7CKbN67J2trKHiSWynTnpcPOsyDKZ0pG3z/pEPK/avGuTEMKMBYnFWOM5gmn7hLKsvryu7Rxd26R7JZPw5RyqLT8sjMfpY3GrWv/7smTvgAkpZM/WcyABIo8Zus3oABCFeVj9hoACDCzrN7KAAf5c1ez/eTMHVi67IEk0rwhb71r7utrbkz8zVyUSytJXokL+NLhyMRjCXa5Uz9YdR505O/bkyi5BEggWnta5A0AxHCzH+fbz33fMv////z/n///////////+/vZc5c7fCxT+VEQcULnQMIAIlxqZL0/iR+JWGrwVMpsreX0j0tYLPLBQnOndsYMhEw2JVM4TSVUxdJpLoKLxQonFomKkDZIzRRrNmTdJeowNa6SFBamZY7Xpzy0DWiSIUk1RVQdzTstK7odN9Set7qU11dNNt3qQ/r9rHepk2us3UpadNx7nmYk0msbrpGhsR5yuZAMCJAIjTlczMxCWDI0+F3gjYqKAZOLwBYEg3lWXeZtGcQIAtD84HAgBqaYBohGQNEc7HqDLsWHBj4hlVl0Zjlq/qYgdUyKLd12Wqfbq2xIKjmaeJGfpxJbU9J8v6tURRlfp6dTccfWiV8z/Ff3XE2kPepxnoHAeKwwm8g/CrGO/D9f1Qf9kec118kwMkhf1LwdqiI5rBUyVtK/QelKM9fBsr7Pnaym2YLjlPIhG/TR63jtNDD2t13y3fLdp/oH17WdLMUV89/6xSV0nHogJZtQlK1Bto/9Q57keqoyqTjG3SUQDzRvVho5XM8hrqV2qUlTNrcxSJTZUKyjgS0PPS6VFTX1AAUIACfdDRfIKAuiNStEBJAKIV8HBJgKAtmkzJLyrK8pg9zsuNkdTHpwtJ1CMLaemIJR50D62kBpm1nGayk9uCUJWllulLfe+O3H0oHn+Bcdx8KghtBt/lB18PmZv/P/7smRvgAQDXtprCSzof0oazGUjnU/pe1RspRKCBazqaaWWIMiNLbVz2hVrPhex/DPNfi/wMdaniGKBcZRkTnR6/6//4GlGk6e4ZuAJuErp7FI5PaypIxgLrF3cyyD9WVH2vKQhFWIKPNS/xlNeJxQzaEdrFJFUtYgzm7ybJ1MP6Wl52MkSR3CA2HbnSyDPGWt9mnen6ljuOfS68a31XA9a6iuVeuI/u/c6u+uru0++RD8iJuY+wwKuo4XEnxC6n2qPENABiABpJpOoMgBaFSJkiSN5i6YCIpoL7UWSSceFJfMwVXm5A1Jk0L6FQaD84qECSltEcVuUl9iOCiUvSNvOrzF5thNUOrKYoZ7jOyD2fQEQ4cIkk/zOWWtU4mzasZVdd3q7NVdUWUQeqz0QbRUMRVGuiq0OBBhYoYFkNmEHRp3cTqpVAMAgKSeyUbqd3LDA/ossGbHjrZasgDdpCVUXVAq1oN6wV5KTFkT3PfpUmayiBGhU5BxLMR3xSqq3nl0JdrXNGiR/inHdh1l8GNOmvMCdMioD7nONTxsxi909Bjbe1pl6BTVNclsMr566Us/hsflSOFszT18mFZ3MMsAow8lFBVYAEACAFkutuJ0A3sCncomcIUixPImNKXDD1QVE6gUl0nhKXVT5eVRShoofgeVytiogrlFwCNoj8xfwgit1cRf5xScSx0OLRnfxM+c35vg8fbz9a4+z/aOfHdn3/YzGZt+Ef8z+tb43Rbe85VNbPObjzLTr527a/b3G0FWsEJZBRK//7YAEAAABc11vAzRKOVQDmVVAYUwsOyVHp11EAILGSQmOqglMZau+WdJE4P/7skSWgAP/WdXTCxzgg0sKzWGGalAha1WsoHVB9a1pzaWKOPg/VeK8naAWnDsyVTGiI1QTPQrA4aOzh/i0NumbC2V+KHs5Cy6zLgG++h+35Lg8JKfF+hVWd4HMz+ZEas2XCNLCKn+XDWQzi6Q/hgiMIoJgTgOMFQSVywRL0bppUAMgOeXwFkoJsoKQG0ZfTK2UN1AqlmpMCYW5gsKV/AL+E4GA4oC65XBEBsQSgfyEQcVLPXgtJNnPtpyS2H36ve7is5/OYXUw3fG4PooHGq1k5jVmZiOa9WVOoN5r0CmRr5r12oyLNev9EuVy3TpRoZpzKAuoElHelQSm5JyJYRUhCCOzMPCoGTzxFukjC6iB5iRy3ghwTCod8SMLYbdwHHIQsIo7jc5yZrvgq+D67I5ZnilAo1horr3NiSQalXOmytsxlZKqblo9VNN9p/0QGeNj5qOame6bSvXV+xfq7qx3OO6izvtq0sn5/67lVvzVcXPPbvSuuZtqKzNFA7el8weO3yfNAAQEhJJzZ2eVGFkVBhrVjplzExCRTWEyk8QqBLBGA5C54Kdd1q8Z5AKJbbfMRn5y45EXzlGdC67UBpRz3HuFTi81mtdFbW2Yc9EEu/iUrPtq9HuzEWLXC2fulacaj/3fXXQ4AxEK0Yju5mcqO8E6XOtUfvuXVH72mFClBCx5OJbwCUpJxCXGaB6IYxIGdD5g5i4owEv4JDokHGAC7ADDUhXDzsIKwIOAaaH3EKgXO51WwwXM1JUrXLqGGdW2Wh1XJHm778px9S8bnWpUtkrSzwyH/Gc9xy4+wwBH3n7XsxBNFdK8w7Z5R3o9R52o7f/7smS9DARhXlKbRl2ggGsqrWViuRD9YUhtpLbB8yupTaWKqKGZTGeJWrzVZTrpZkciIEA+OCQs64UQrMRloJcvu5YCnTrjrI5SEWJGV7jRkKiZ9HoFFzEGXHEY9xUAUSZc3JGJ4NcSDe7lA2l+ExxAJQsq0nssiAk3baJtPg6zW0u9a409WYm/5211xzGqNsbp0r5pigxYGYwMEilSkSYl3VgqPM/NPcyV6Ncv3eZ7tRVy8zuMthnTv/YqAAKUcJDJ84xAVPHBM0aNExGmZghAVGmOEhhAwpIMCmdviRmmScEIFBOvxWFa4wJnZiqmS2SvM0IvUcAVtd1PaKPoEP1eist2yNxDq5wsay46LNdaOslBMBClCnBMQcNoVqqNrMz3VtXezKYPnZHQVcRBDDlGDKI6Kwgmpff2V2SSrUdkF3aAA4h0BdSCMcu7ymxRwqpGSkwNATKoM0EAMMEHKWORERiJQggACLWC9gocB9GMULAvFzieEnO4txhh7hOTabj6vXBpRt4hw4l7MMSV1grYkR4hV4SuxmHK0h8jlQ483ave2s+6stHWZ9w/SzdHodqorTiulb6baKWx2u4q6DhvEJO/w+990CCAKLbeBLMcMljiqbKvmnHJjUsqYtkOArLw4lBwqskzwrFjNzFFhYiHgpXq0lcDocZFID5GO3q6KVhtNguqTnvBZFwtWZVJt/P4r+VUpa96Uu9bVY+vK8cO81j/b7Xxj5itE9Y4jdayXljbpCzW4RruyPUqfZL2jGwKXlT3A4YuMDy/x/CX5df1HPfNqnAjx/VsaIh9CwC5lrGWdG2sxwAF1twYFjxakCOhiP/7smTbgMRfV9CbTC0ggAs6M23lXlPtc0DtvRHKAKvoDbMLGAwQjRnE4bKJF+izBcEwgcMMTXAGDZnSNa23TS1JhFTSXzSVrucmlw2W8rsjgLN/sIIxt1okzHn2nXmgWq3ZS76BupyeFv2tvPK6sV/CJNwIeDFlclDWIyEu979G0ZUUtiFe3VUeRv5mavot/Indn+ceg4upNQAFGnTJkM19eJGE2zJM1HjQSQrTBCFuAYqBBAeLCQCEjAYhFKNrKLvITF3qdqnHAhT1jAZYniRWSoDwYthvoeoJ2NlUiFPWRs21+k8OPBkvCrnEm4O/WWtHzLa1Oi73tSlG60PR8hmRc4vM261iJCXDkTYwhamDL8k6rpPGinw1cCMRxY7+J9uKHRVVNIn1DGXQw6am2OURhggDnCYVmBlmQWEIMSLE7AjHHZkAZvigVDw4UdIgwx2KKEAwQjjaMIKESoSSYmA1CFBGitq5SCsDzEBpqtr9JzGWwbE4RuSUmFFQdjSgFvt1DaRTro9xW+xxZMB4gqdYkiJjr41spruQTH1c2vpXrrrervRqccITHd0cx0RnWqbIp+d87952Od76vVA5+Fs4/GWdgAElKGHsxpzmF1UQihpZOYnbgYtFAZ6xIfEhIFBDpmUlJMS08bBxOLFqTS2k/iEGVbKuM7BQHBMjVkkEtoYvIpYasLMWnikquMv61Joiip9dm5X+ZXwMVJa+e+OJ7l8fVWUX/QYw/LFSfKczyd33MYWHjm4+/NkJLHJfVRLCpRtsS42Z1oqOXSoE+vOx/XxnFr3Qjy7GM316L8pd96rxwJDtnIn6nOsdjLWRQMECjP/7smTtDMVAXc+bb0TggysaI20CxlgJmz5tsffK7bMnzbQy0WtRNqxUP7w3PWvWBE/panYBABDaZphwEf2lmGFRw40lAabPm8CJUQJeWcKgqATFuoWM40lPZVYg8W3h2OoFoWpwcqIa9hx6ZAoTVlkOVyREgkHSB+HRaHnnLJ319w8H8lrh4ULz9Qw3x+kUwlQlvnE8LNvzMbpPTHnLKWZV8dt3ojn6RbpIZ+CFcpWr7qRwjnVdZcLkS/ErzBgJBYX7zHey2/95MOlOS38byl/JBYvZokHicfCAATlxsTDB0qDgQ0FkRHaS1ubaPp2VlWkC4TUXCgS1kjMkXTxoDWDClEo+Xsh1giV90QDi+DY3va/Wp7rSntu18IldyoHuk92Uyqv0LlmK6DF34rSvYnt5fcaW7Zkj6C43cEWdUvDQOBlL+Q5PW1yS12JV8V+JZB1SY30kp8pvJoAPyaElqCZMNRxUEfc1GtULY5q53O9hRzNbckTn1bwNf+vrn4UwvXdQSbzDWL5Ql8ftNINWxwAMABAHrF2vBtFMZ4bPwZmomgDUNc9QZYBUAg3F0CiINz7APceq0tdZIeqoXLeqO/anHJZB88zPULuWu/iDohysu7mlcHg6BA/1xVJZBDZiqJgz7jvXS+r/Mqty9luXxNdIpq70nuswrOWzhlPJdtJljV0oZpzMtMdPxSTZuLEaTg2EYJzgf9tZ11wWJGJ5r4DtAFiAAblbSSi2jCXWSSjJGkEBCQWpGRF+L1TMqDgUiomSGE2aHkBjz8vWOsd8azThUs17C6OUy0pcff6RLVRLawpc/UzGTzN9H59rsxLPyzm+0v/7smTBAATxX1RTCWXokeuqjGWJVRC5a1GsvM0B+azpaaYh6Lz/+UKG+5LzuuPyz/8zOm+9n3uY3a3/zNzlVHzJ7/e/bGuc8N29ytwONkVCGFQCkuh0EaACARciSIKYgEt03TaiEkjJIhosXZWmXfpkJ9ZKqQr8iFkJSQQakFca9cYs9oHCv6M1TLzqAvgyabQ0NbFl3WruxzxzG5PnEgk7XP/1IpY+VSJIIpelTroalla8ct+Td9xMR887rpXz/MJzFf8dK/Ndw1zctNcMlSOMsRygpZUqAAiSKTkrRIcAjqmihwC9iGytFA4SgkDselqmzFIeDEDC15kNSPTmTa8cI/RwHyDfXFmVs6li03+2Obl2rW/bpVN4VsMAcH63xV40RYu3rlr/kdcr/0bazPM0sRVXKLGoodHVVH3LlTzK1Q5Pl66luLTjFqylqo6SSQWzdYzjaJs2llQDojpSxtqMqDPpVBryiANgAgAFRDKE4kKS7nFtywUlI/kYJrOFZyWxktNJaI3vusf3QofflCGQrCaik0m5S1F6OJJDkJTopamVZq4bhBfxZeo4++TGlIdPVNisfdXUxJo/eqvV6x1j/ivJ74leCR3PvtLXPPiQmmhruYm9iUULzseiN+rLXt7ZHlUAse2AGp2lQaHecR8R9SCCES9VGdkUkW+y175bWjK4sbmcSq2qEhjgJPhgx61krgZQX5Sch5IrzGlPueR+DaI4k+eOOTY5CA6eIHRNfDjjsbzyv9qjdL5ceyzxCD5WGiz0+l4GV8W3NdfVXFzxls7s12IR9xbXqPZSKQqFeyIMCjkRogLQFfJYneyHmBVVKP/7smTOAAQXXlTrDEN4gUu6ammIahBde1msGRTiBaFoGbyseUuFAQGTvpIMfGgpct90nJd/1OnQieCocOlqgzCUok0w4WD6AVdyqqzUuTR9q1qJMg1PSkqbjoXUil0TlMY+Em8Qbcx8W780Zo2fqFZfM8WoTp2NleKZfPVQq3yXYA9S9n6fMZk/oI/cgUMFfjUAdQQlG23TFoTEQlzGWIgk4ZAALQ1DV5McCAA8WXUWVTjfhTpCFGJm0uqvA0Kxs2AWlVkMiV0ub3x+tMz5hdGwf4y01csWcPo3CcYkGjFkVG9xkxql4lPrQFKVKDL/TqWSosbxEX6H+Vd2CoWFpIhfc4fMJfV/n4+M2+0r9bx0Gtj6v2eQ9GRaCdx/RUoENNHWAZAICTTZgBBjmEEKo4AEhADmERZiICDigOVDxMoBMZOZQM/UsjqsTvKFRi4tpdEivthbDTzlZt57CM0XUtBBCftcbeRcFMyLHMm2beOgMjuKcSxFpPOyqN+O1r7gfTnUO9uon5NS+5URILWli0vpzYXVVx1/Dfcfz6/wzfx9NMxBpld7zaAEBjLgcELRMJGY74EwybgidGEQAKA4KAdGEFDTBGSyhgrQYScUhNKoo4JcLxcheTXos3GDC2V1tnRY7LppYk7DlLLoSymXSRxW5mCQthIoOCQRQ+HsTkgeUsjyROwFqHp6CiiJjCTUCU4dYYCi6nI8yIL6ZY6ki77n8YZwl3IijTdrrke142//pVMHwsJ8pcz3cC6Wi7RI3kWEUrNNG5pT9/gAQpg4eHX2YDUWYaUoJABmYXGoQmYPEyhgCALYTFIjqCIRukAgasCzpP/7smTxAASHXNDTTESwhasp+m8IPlRVXzJOaQnKVa3mScYO2JEskwaOq3CQUJgHcbqmU3djj7snlk1H4RGTFYtcAAXRnKEhn0UKoxbbmvZ1dyrUeVx11n6XKmTjvSoXtAP8l1Y8oVT0Pl8gbPYcwrowaxozqQMpUikp1mLP55fnxj+efnilKahhWOJg4ObKKoUAAgpQ2a063wCbjPrjBmjuzR7oCjRaRCAiDFQU2pjVgscZehODr4QFTNvYqHqwPTGAaGpUQYBmGaYKlCVapMz+NgsOKVz8Mbx2SFZYjemWEM7+CzMLG32inCLwKMqhB4hAHMf8i4i+8qaGDJ/dOZfvIxgsL1dropxNSND+eWiYEMxoK53qePotDPGOVe8n5IjC0DiRNUnnxjHGfY+5H27O3KACAACJSSUBqceE5glLAgMBhcwOaYOOEI4BstHggwwIlqtjXkWmxt4oKkg13CA1mtX0SxpIJ6X1oxkllhOj+gSOwpaMVepH6vqYjEiErFMpImt0ILNQQeRFkAr6FPKj5hMVoVeVNHZke7lOx71rnJ3bn3Vu6v6K9rtysQiliYWVGsd0AgAptvNFLB0gRGUpGDOG8/prkgEKgRoGyYuWpeYVKVgqZW9H4QIhbG5B9jwkqqAe+1puJul35xVvRrq+VWqMEbF48HcPDnFtne9yxPvDbTt+qXtAb8+lr7rBpV+PLMTMekuqS/dsZgesn+cwIPzWn1Crq9Y02sZ1TzVvl+r/vNbazv0+K/FKfVvvw/B12qPP85+Nu2DUTZyQt9vnlva2p+UmZxzACWMztPPJ0jGBUNhCIyNVOzYhwKjilbsRg//7smTxBEUOYs0bTETCgms5ym2FlhSNfTr1p4ACESJmirbQAA8JlZcZ1WfRFAaCCAkRBBnBpGKG8PcO4bw0j0IwyR0My+NhibmZQEEHKTy6bMTTJFjE4TDdZ1lU0HZTOimdUp0TJFdSLrUzrcbn2fWnrZta2ev7a2rQVoI1LY6qidwsOOu1fn9QtASBJnetAAAAAkkEJEEAOBhmNhqzNV3wDEeNeCRMbChNOQlMExJNIw9MBSYNCwXMQySMLg/MFAvMzSAMIg8MZCnLNBNc0B9cwIHGpWmTTlpw5WEAho2HJkHCzy1i84sxh8Aqi6q06Qs2WhRcTOS3fJTZKdCh4WZ11UlkKlicBuJRtyjc6/q856ncrOG0q1fww15mzhwTAy7ItZZcoDJ3q/bTlKRgQ06HHhl1t9WHSKncG/F53cqmKaUwbOrl7Us7e/GM0squWJBhHrj70s/AbxxalxnbMuz7C30eOFWaekl8rpc5c8OEKm5irLqtW3UmHnw+xT0+W88N6+GJqepKuNNvPWv/n5VotEp3OC4cnLNsDmBLYUU1/8OrVsf/IkC0MMeAAAAgRRooRIAYz6BGnDUwrNY04471jfq0NklIrBJuccmJweYPKhhULmUgkMAIzGCgSIjJQvHRGBjBECs0FKIzGGMZAwecMEEgBb4eMAwy8wyNWaUNJYWnOpYrUwuCnUVjGgEomEzDkv0ue4zmQzoQhXvK/a5FHZd+D5prz82nXb+diUiDg37amlm3eckTAcJVluQSGHJFQztwMDbC2zgKwYPxa3eufaxgm6xGUds8o6Kku4vfxh8uoXUhuxffF94GhmlilDPVef/7sETyAAjhZEnOd0ABI5BZac5kAB09jVv5h4ADpjErJzOAAJQFN5VNctZU9yTw7D8DxOepIMfhal2k5PY48p88rOet/8c7v6tjLG3T/+u/ahcUtO3XlMIvRik1n+X///z//8P///////////+f////3/7//////////egnOhhYgBCBkECCkDCHIxEI5DQ8RcYYAtQtuawnIbbrsS0buNPR/dCDDABL9MRPcLgl4RkfysBNIYOBlHOArnahZJ1Uh8Z4qEQWqTThIttycRg3xxmeSIU0mwx0UrISDSSJVAxA4CwhzjEin+ShZVaFKl6rVpdqqZnXzrw5wIguBPVEZaqbFREUzkzRG2i80KMdCvfo9WRJ9K9PwXbEu37NDjQ9RXN3CiP9x6a9NOEM0WBpUzyaquRqGvIsGSfVaw/Z85qOEyPHlIkPbPSJTmOdZ1KmMd7OX1bkTkjphdvorfvUBs1BcABX//CHv/6RNMMIEMMMMMMEyy1RikmrIaQQNHeUxTTWEME8Yfhk2x1nll1BwYEz9Oh/V3IZrGai4AdNwH4bO68cvQVXZZIWdu4vWRZuRKLEUFTobBhGAOQ3rzO/yKVYej8FxRTR3o7KlMGe9ZtA8BO5NvJecSerR1+kD1SOG1B4Hkay4NSFUcblM3etX5qlktWNz66I6/cdo/paeTyqrS3YrKI7hVwwl8i/Fljx0cD/nUpWdt7A9S1Ym6l+pQZZTONf7VJnrv1LsYkcN0dNGM4/F85yv2nt3rFb+WrvLmeWO+f9y5OV8b4joV3/+LM1/+kSAAAMtsLHLNl7E9lJp0qlSRa/iwR2Frvq/mUGh/gG//uyRA+ABBFZ17dhAAKDK0td56wAUD1lYyeYc4oSLqy1hiGZFgajjhFAeHtZoh2JxIyi1CwcyLZIexVsSQVjZMF6Q4tTDqG0yDR5harYrcI48e820XRi9eQOxltx+yU7s0xV9ONuJTmklr0q7uoMn8sfMPzpcZ9InbLI8fzZkpFGbPH+AJD+oObSyJpMlp1JC6FoMZAA0ztGmKgfZLBMiaGsvlidnsA6JB0nECdKaHuznSRYSzB9IwbGbOpPWceyzynDWGb7t6Z6qPdxbLn2972Tcb4/p+++Xajm8QybZLJc6Ir40+ap++Oqpk77qrnmKXiq53TG0/Fe7ZT5hE2k6rJyNJzIiAr9tcZS/pqpUHA7hfhDgKI3Aa8oQUH6GmLQK02BcT2MnKhdK2KyK1brdMiSKAzRgznTaBxKTiASCwKJTKMtROzCc+CkU42JyENQzVdB0qKiOaW+RiSJqNWcLpq9/ot3f6Rmkf0P6RI39XU1wSTyRoMiFaq5Xi0shIUVTAI+nIIv7w+87XV9grMtRFJEAAySIUAxLzKVK/UHc9wV/sciquUeXXMUQ4CyAtgEDksUT+q/GUGlCiUoy7zzAHlHnFWlE3RIuSMPPQaUbXY6qdYqLlNWGS/L8OsXN7VdXHTJKdpvfNVUxV/V8vUtx9VxPM207tCOyVHa9p9ze7iGFoljWsfEUWhms34eY/hYQiFkpDFKijlUYUGxdYFMhgz1KMsUb5ThvEr1bGSMXgJ4IRO3IlQyeVSkEJFQc6jgaK3pZf0dPVJkXV1MJ8tAMVSV6CbrZlzCvFFBq75BlwbuTw7suBerdPCsWKC2mfNn1WIT//uyRDEAA/JdWWMGHMB+ixsZYSN+EJFrY6wkbcoDrqvlgw6h05P+R0JkeQuNplJM87cWLEjKEPJN6QciPhWBusHpY5VAbItYXRSdlKgTbig4ol0y1eTW3osQNPvQwElgSbZ7JBM+gWW7QigzlIqQQtZ9sdXY69mlmvaxKnkpqKq5rHTZheENRhwdCyV3NCQwqXSAmIp0yMKIPa85bmPnUp1U0ue2Gcg1T6eUUzBFYfxcEM6EDDQaQgRG6jzKdqCDYZUY2SCCoSHJAtIRtDltefKDVAEGqFp6qbB39EQHggECc6eSlFEIxWQqLSBlWDkDvjKAfUZal5/bkcgxNfYy1RWHVgvxGRoUYP+0Q0VBKnw+NYtY1JsF+ZEdIVxQTkh1ypOlIm3yIXlrcXQSBCPyTtPZDIHhSGBo4AuTL2mJ5l/dx38A2CVgADpQUBN1aot5dy43YbAsZPtirXnvb1plmOR2aemKTtPlEuyKl1w4efCrJMyawWseXr5FInru1NR0lFdsCexb7r3TJKcwRCqhsyoTeDJwRQzSlo2h1hNCk4qiUCIcWTrVWuP0hyrl62Pk36FoeRmUWkDYUox5kY1Nemm388lVOeblkbSYJChVOQHctMhOViy4EqGxLoSjRUb/NX4vJwODYNzMtkgwwxE1tfp9HZY0zBi+ZXr6Xg2sNLQUhfZpV7c2qaDHLxC6kLZFIYGAD0eRKF4okCZApMrKY/enzONqnSYohHciT7nOmtGyHLKNXm58n5E+FHhasZwGAD1FzHGyYgioMkJpAHmzMJQUcAMhfsrOsMlotRqTnK3JeqvGlgpB+aJj8uZjTptDGbq7//uyRFcAFA9W2OsMG3J/C7r8YYNsT9l3X6wYc0Htq+ulgwqoprde6H8rGcXMrL+p15YfOWENmx1EUELZHoNM9hENDCrRVeFV1EibFGWCrrmks/RpySZI4Lfci9OVVBJZ0aUrVNWrP/c8zDI7xuZ0jcIX4HG8/VAAibJSKRIBMJBpKkxVEi6UVfpL6WIWprI/o8LubZ+NPFHa16OQ25uWIOR5eDl380jLQpCzEgqJVuRHwych7rV9peeZMx1TgudmS4zFBQzTRXh2OCMymSemjd6/MMRAszGPyM4XCEkWe0ItVb9i+ZZSDijqCl/jY5IWCdgWHEtQEIAyrHTEJLsVMDQR9ONSmGEgZpQFvH0aEv63BTbSa9HolhdiOb9zHzYW4PYQVtNiQN0ECKERPx5WY90jcqNbpRzHbSELiQo6IKdtR6VURnyrRiO8YM7OlnRGuP1etEd2djNmbc5mFn0bJVSlS5HX5aRTw60lEKBHseLLHAAAFkhwstQgvobE0iZ8BLlWK2jBHobi5DEarRKjmb7MyGpBnIllnfDpF9VvGyuE8LoqS2MSyVWdlD9Yye25ir1gmd3YkwUj2Rlvnx4Nj85tfEMQMoHXlfNcyyNaKqY7Ix1rUCD6koxCgqGpOKUTYDM09K1qCBAfGstMIvZUKkjFJRNIkAAygAYD7DtB81EmBMHSPEMAmASOYQB55WHodxeepkUDF3KcV46u+oyBjglgPbCUUDDR6KoQ0CtQ5noaKxYmIhkbAgbAyvA2iOpPBWrIpUUZATx0I3yW6PkGPHoPA2vQcagiakWbG9IlZapkhy+SEDFkBjF4USBoN7Fdf+kq//uyRIEAA/dZVjMGHVCDaxsdPYNNUHVpZ6wwa6oNryupgw4pmDbGZrI0Sg6VAlxU1VyjgoESCehfa12gs7GsWGgz8pB4JJOLydw2HNxDa4gGatCOUVJxyq1D32ADZgdgYKDFKUNKqtRjaWB4kMeEm1LfDSKqdFAhsEMOaslFKtYalv9pXPmvHC75J2sViDjPUgtjOIRxMcrvh8GId8UvlqhkZZfmv/GABtSKbJCLq8CziEZK0QKZynCjspjL2grgZ+2FLl2ZRE23hUsiQtEsCKCksceGChIazNGJnHnnSSNMNMLPIHUu9KV92KOMpm4NgegrFGTNq/TTMypOEggUtcnxzz7GzsWr525ZFduJWQyOxiQyVC3tLSmZcWCrRApM1kXFvRrXX8QnV4kVAFbSIkaKTUqyUKS3ggOOJayyIZA1tBZ+UAi71FmVt01BgnCZLajcQ+TAmw2CgrdhC4gnC4LGfdN92xesryUVIKjg21DhDYIRCPMwgyZbPIZHhiNuilD84ozG7+cEKW2D5DNkjkdbh7T3BQqSkGPOMe8uplGdWfYqLAB1AVoWTfbobR/UFnrlIq2mSqh0CAJzpSg0Lsr9a2z1e0jBzkciqJM96rqyXP1XxKmyQLwWZK5Jy6rpuhBwfamzKNDcOoCqktSspuUI1uYl6P3M3teB9mbmWfEtJmmIs3t1+s+7v2NqC1y+fvj2nxcKJvoL/pZnrtuo4SO/qnoysgBCp78lL5uWO9kCgAAkAcqhi4puDgKkGfJUyFc7TlAqNIeuhmy5S2TN0XE6zzQ0RB1oAj6bcwFz0E8WlLYnfija6YfIJll0O5DFJNI2//uyRKOABBxZV+sJG9KAiAs9YSaHUD0pVSykcUoKsGv1hg2wGqmxVDnMOyI4II9HkrystZmNalxwaGR60xyJTWOc9UGPI/gbPpo5xOggN4zurVtyWdKCi3xI4k57f7f/Zf60AKm4QkokyrkXFiJdq5HER1Vi3IbRKe8uqmkxNPoV+KUxFLh8nR+lSE9lg5JzrULsV75Rincxu2Pdabiu5IsZ6W9ZA7XIVRZRxSixTggqaiFS2FO8jmv9QjQi4/l9hple0j572o7UBFwK2ys2Yau4tiLNAdYcW7GdBk1N3v5i8Ok5GXUgTRlltyIgOlSGQEYDQAvzk0JCJYnh9nAUChOgJyUJQYEjCT7RGRUtpYnEs7yLoqwKLTnKZAmrGbWTVXmeqRxAwuc2HkZy9BBwIVayU1tjoVvvRiRcs0Mva+Z7wF5990+nlCY/Fc0BmNBLOvCYQKcjGcQ0QIgQ2DpGMylUcBi7HMXrA2BRRFEFwgYRIM5zAYzjdZ5FNmvM2b98+LRkEW98XklsMyCRolULQazhrk5eOyVZHQHdfmnKMqtL+51k+tGWJS+PVqG+qaL04O8oIwt4Yg0NalUnT8od+MVXpMjSrruh5HDyu+P9kEsakSsoYggYjNYP6uwAahRRERksQctKuWQAAsERmJ/5Ab4jxGoFuDQJoRRR/EcS775sra4zx1XorS513NdeNU2GpuMSupqCMIRVm90/KJSA6RtZ7Rfs2+qgNWQDyc6dtGV9fI34+ApmOzoneNcqvlNWfmZWFB/XpmfAWVLtn7LmX9L0s1yNTP2ZV8yyJmju7EJM1PY5okXRGFqxJEmofPK65ewM//uyRMaABBBeWWnpG3iAK9raYSOMD41nYcwYdynxLyy1hI41Q8zVkt2FOuxdrrkuA8sI5H2nve/0jWgsWIDTGQab5faVe02JJxY5VtmVuT97ssnJv3k9s/kvdxXy3fwMSNVG2NrMlWigSRWv7jZvq3c2M7xNo3qRFn2OZ2Gzk0p/kvmeZ7FRIGCUOqfq3AyxbvEYAAAEnofwAWGE1Dv1QHBxrDS+Bhhp9DhSQq1k1078HTDll/rcW40pThsayXec+V5OlTReLSmmqlm0wEILAtAwcfsirQfBESWcFbYNQiSPJO94OvBEbQ5TsQiWkpv+jkoH5qRBVZgWOxccZb2N4DkisQFrpfls2JmOjhkS6XY6DNZKXyPk+LmWMaQiNoQatqll8w+5MyoOSdgAhAIAEAAh1WCBxxmhgSAY3h4aGtumiqKXjwjy3L7tMli8nGcFpVVjMvmoOdt15/s0/j+/Tax//tvJM/zZVqdxtUgr4jO+s1MhdWhmGQW/ZNTPOfZPzcQuMLXO2BNryj3LRqBWtfkMyQT6qZKoxlG/XNiLCSxCUn+delr+CBOJxA9ndxV6n8O4AKSAASUVcQDAKWF4GNGZxhClsXVJTo4LBiSHLSrVnIhI/XbrywMydnbltReB/JPMz9R9lC54OnSKIC5DxIa1ky0zIZNxUy7mCoGkY2hAOMbIKb3fGqNHwQK8ZZ1jJHLJAr1Zq0mI91CNyhH3NdCtbQVchwUP8yt2EXkyG2e8v6vN/uL+DsXFYtxBG1kgoKB6CVFlZ5JgDQAMc7ORYhWOFhDEaCiJc2lXErUUFDoJeyKqspXqIgkm1qzTP3zqqLUr//uyZPCABMdeUzMmRcCICzp8aMPIUqFvUY3hBcIfLmmZkw8gPL26B2Kf9We0/KHBd1zORmCZzgTC9h8kvZ09IxwXQmzHs1kouXbHazt1qV9tWzaF1I1u85nuY+z6xh+p0t35ksXnahe6+bHw+yTM6Wv4MSEcMJTJW6OWGP6GoS1KJABi850FBqFxmE5/2BnAS4kQF4I0FY5AYjEX6BwQaO3njWO7TSmSJk4yNczDHehFPTShqdNn+VHlVj7AbdWWJIppSC+kUD0ovDANE9GINC9v10GDwuepVLwclsJtBUJjcCsx3JU8OoS0XHtzB5UxbkrsxNJOk5KJMhRq7eoCVR0ZZsfld1JjJRRHMVjai+Hy7+kDAABURsVeGGJhz46xU6ZgzwB6y7LVkNCIyxYs8yVpitNRhbUVmq8cS66rvsgLwBHXWDtS0lRw9nryEmdg91THUbqxJA87AYebKcIGEWX5xR6vhvORShd0ZzzkRZx6LN9praX77z5dJ8e8xHp1Sf1iZ022H3Mu19WbcY3pq2k3lJpzUq+beYhgjIA6C4egJuIc0lAgoguq004cMJSiYYM4oQgYHgIeBn+BxIjSBQVDkgjThBRPL1ZWDokMFYfSWoqst2HTkeVBDr5y65PRz5qvLnw+1rMCYjEES/MFPAPRx5GD0RWwswqTiWEMTMWnBG1mt8y5fPDACegl/IyYtS4lFIKWM5tg5ohmvDJSToemufTsumvnZIRDjlUColmHH34/43neaoBMoAKJKTo4qTfbMbhIaCSLBJGg5KS5C20faMgAEQWV06j5UPwbh2KT8sDkICTrNRmr+qj1Jj8Jskgx//uyRPkEBJBaUpNGHjKS6vppaYaUElFpSs2YeMozrqopphnZ+o24+DzogpKiNeDWOinm9Qt3wz1Tj3rr834jcd30MfBYEXu/BmtMt2x2O7VV725bv+318/xV2tNsbPmbvd27Pjf156YeGSLM9fEqF7wx1r39vuoQDIKJLg4JGcDRgwwKmhncsUEgsBozp7iwIn2jgBgBBwu2QgUytlLprrfvAvjkaf12t1uWE5bd20/UZMvQQFbsSy8RbhCpSxpNLFFJ5HxTJS/ROrZ7NQTq91S2O5tMQq8OZLCUELro7tidFJ7kcAJaCWXfNCIjiuZ2qatw2KsadoQpm52MZA0BV044DtQ/i9C1hABAAAMEasKjphakbBIGT1AkMoHK3CMDS4JitJtCa7am6uI63GVpZsaaNCWLPmstfDUKmEehp1bkre7mUrjFmQ0HMtLPS2iOajnM1I4fZK51k8OHd2r2TTopjtKWRyTvLGFW3Fd8NqaVd3/yMO6iMJeBqczIzRjJiyI6yze7DJuIj8Lz/MEGahkIQbDxVf9yY1nvTLbxC5JJALo6CGlCBhq8Y2bGE0pa1VwoADgShuTCyNYkApKJjBBbYT/U2V+tRmKHLGIr4blEK+7DLW91WhcvLAxnDLJZz2NWsluKAjhOwaY0luugQeZyIgcLVmztYVehoBBou36urS4oo5lTp16bQ5vPxZGqUssZfSKpORBYSpj4MfLEoLBGAEOKBgcZlkCtAt3hV9XyO4AgthZiMbDwYNGaMRklSh1IhJLoqtNYxcxfEuy3MM8ChyqEpQN2SFWi4C42GqUtOVtf2rAEBPvR5PNaQlXFu0MG//uyRP4ERIlX0ztpHcCXDNpHbMPIUml3Sm2YdoperSjJvCD4igNzzHEsjxOMNMIDkSUwOzEGE1qPQTSNFVirGMqjIirSemPl7lyRObO1Wcg+7hLqhql/bWZNbRUt1WUlRM2x05cw45phb5P6qqKpk0fGwKIwXe8nZG1LAgAAElEp0gSAMaEiERExrnMNBZMTt+nqZSArGGABRULgYcEFAnPLZFgGgQvVMqg+bPllNYWhF69o4dOkBqaIhC0tmTE2bBpSkzXsqhRYWOm468zh7Hip2gIrRMLySINU11uKH8n3USdMSYl+OabHn6lL49A+jEJ9mq8QljJOvuDMa0F9mdwv1cNl3D4+UGSeK9jHUmWnrjmjr5i/i/GUBAJBKO4gWflCtQX4KAZaeNS8o4ixaAFMO9EBhzmyVxFHbSG6ep+Ig5symgxxvHCid3GD42Z1PQhr49uq+ppCeIl1dlIqGH900L1lUx1GqdUUuUp92w0RJuD7v7+Tt2n1dLnuIs9zINPuka7qal7pLY1JWCNUunvH0zFu6AAAwuqgUiDDbEMLs863X2XoZAIWioUAyzG1FMw1ZPk6izgMg4hbEYIsYdDQZ64C4hkNnachaVaj0ICC2jS6BpEaYnKJS/ryYySVTrmUKJMoKhTkcSEL1mgqyqJThiQgImpzDwi9AfwaJA+C5BN7bkXGR0Y/kw1iBTYHWHPmtM9FQhIq1RPZ7b6Tbv+LG0yi/uoxtRjEyV2e/LemzlPVuKt5V1auNESB1hkg3U2BR1KY3xUY/jXtWTQAADkCE9BwKLD2kmsixwvQDBrmpRJzCWwM940NzmiWDhXRRsHR//uyZPwMhPdnUtNpRTB762qHYeguVw2TPk5lKcIQoeiJrCD5SZTO64RfWPs/juEOsAVDZpali6JYIVft3QQXxWTzIsq6Wxw6astmyBqLZyEmpBVHPzLrVvBkr3d2sLxNStd/Hfvbf+9wVZP16MaVTHlfvAk6xF1hiPIk6J6VvL78/X8qAQIQpEkJQRLkLAusMCtOd4LmoWDgQROR8KUQAhsOEHhplydZLZIdEjsubDKHAjMaeyrpfSMMP1ZI0qXH2gvCBAaK6I0Rr6TIIVD3trJT6W/Ck24Qxl/jP4VinJO731GWcnqPuo/sf+DDvk9zr/acihbZFX7a/2LWXqhj2+88W/n6+qQyk5MPv0QR+oHqGAcZ5UNxzrm19OEm7S6IRhh4RAUJIBc8bad6j4YgDUQcecQgkOxBHSLO8JiJU7DSYXCKe9UAO2qRnlbG525WbDCs3N7IKgyZXkLKdc3tAterimauKa+ykjGiAOublmey6gyDKmUpYiS+WjX/qY554vn/gziqSdIpbj6pJ0rlEqpF+qxW5kYaXJA6bDwXSXkXLMQRxRBgvdGDYtS3ew77QSoAoCABUbSadGRZtAuOGBgBGDLBgoMTWZ4GBjBV9q2LXFgJtr+S3Iu0B7GxyaX4SpvZdufTxl8YjkBWLUrkNPZtQuQaQIGU8l7QUsivpEW8iC9Po1/rO1INywAV+aq/khOOlu9E8xzkTF7RHPyj3zCGvAC/Nf96Lz2l3+RszMdW3jeoaKw0499NtW1ltpTCqVJnnwpfVPRDLye+QtmgMEAFRSCKWiGiAgM1U1FhLZyAEM16gRbS7MIChaAlh1hcERlK//uyZPeABP5gU1NYSfCOK/q9ZehOU5WBU62ZOYIKrGnplKIYaV6LkAPDAHQw4UF53YQxiBoDKBAJsFXSY7JGx/UdGVJhw+aduoGwPOFg+NlJRFl6hhdISPjThY/X6j2QfLysvRUDlOlnWxz+bWyTzHuMu5cVHRF3+1zRwnvIIXJCF9UQCABQuTRhEuGf0UcKKotDxocF4GMhMgamDBDUBGMQdgUSw6+4KZTCS+Eg0QUCTHVsMEQ0aZRFUcWFmcHgUeeQyHyWklBEAryNbcvWv06BSpuJaW4jqKKobyRluUiN0cGRR6MiKNoGiWjj8l1gEb6uHKtcVN7SIUb6uWExUzWJM9MlbyvTfUq9UIU2IZOfS1nH+ndYQbpdHUNjOdSBtrTusYhazdDxC6gprzPoQ7dQaWZUYO2kqfqXS7R2AKgjJEH8IezB3joFrGGyPFtjP9WF7cdvmgpoENfQLREjMi1Hw6wWvQ6j72kySEdBeaoeSECRaL2mkCv1Os071FzHJFWalrK93UTnGa9qk+/u+t0vS/sZfdfHXNDP5p4iKlm96czJE9FHnBMOCWUJLf1BFHgukYKnHTjB/NgbCJEwiOihgPoIw1JFMs6BBgiEFDx9xV0tQBoJbyIL9a80J7BombrkqLqy15WtNIcxcFRqkQgnJpRRmM7Of8SD7sVIl1qJWIlRLuWvGvBC+qFJV2ojUbOSg7f2vIw10kfj8Za+Gf7K36YCt1M98prcspcK2VelX521K33XirWd8Zarl5eyZ2ZxHqNhS7hsZJmL9TYfS7j+sAxEFzDPaQCuSjBASXoYCxoeEDV0ONGHK1kzwwtFCQOX//uyZPgGxTVa0KuZSfCFy0pSZehOFFmDQi3lJ9oaLGhFpg6YhL1IwSNRaBoQqiyJ4ZfynAKFRPbIIU9ONk9uglwAaWrGF79WepsM2sjmzm+JABAazrGl+G7wawGOH4jevQETXcmzNjthnH6eZ+a/TImxRRibBmnM+hV72GziSqQsEKhELXYoO9diEAAxGZB4RGIQsbBYJx7CmGw0EAlBcLunqiXSBChE+BeDdJEZETQYQGJMmYYXXERUPpokhbnoQsu2IDUmorBDMnYcw6TpYfLzI5vr2Ne1eh/KRWMImKmNWDxt2WYlt552lXylTKa7Fp3s2XXd6tLdr51b+jjpmWpORvbOL5w/a+bZFv1brs503YyZvas1/P/H+vteyrUzv9O8tzFK534l2x9Bj0wKh5giplSBRdO47Ag4qsgoGeim2BQ6k1IAQELdiwAFL0M3ZeSIsJRZTgCBV4vFgdgICNG9w1gRMD1kTyzvO1BSFao4st81rrv0dp4sWM34arBwESGO77qQQUHOFwyVXONDhPDbv81q+VFV3zhEVJmPk7JKS0v+rPMrx/7ShR2ZwYquhpAAAEFQwMchojA4NGkWialmRpAXI9hYDw+A1yIAAmgpYw4TbAATLkDghWU/ZpslUQVCXGocXEWeRANrVYaUDV2UwY/DqoZEdQEQibeoaaqyw1vRKD/SYSZrYu8lKhyyKNz031CfG5qGmty0+mirLqTEqQNu3FHV1Yfyls1ps0cdLYz7vSt3H3tyhlZs/kodP/a7s9oYftSulp5J7E6opW2tqvNA2lNsNgADYgCjagQxKzMSQjTDgStGckg2DgFkI9BG//uyZPSMxU5d0BOZYfB+SyoiaYOIFN19QG5lJ8IuLOgJtI7YLhoyEJpEQCGCD3QWTFA8EmMBcAtKVockZAlyJuUVOp3DK/JVSx+Wz2TgfihT4qXndtbS8DLoJ2pueVc56fuq1cGvRijM1nijJQUHWykZmX8y4cpaGMWtGy3pmhl8O21PK5fkWU5DL8s7zaCsmKrQlWK1AAABMBqCJjuCj2abNJgzPm9AUUA4lAQgUKExcBAYgmMyE2hA7eAAogHJkwZoPEgZYAVrZmIWFil0HHnhAMkE87kNgb2cN0uxZANFcmNC8cHQSa6U8ishQvhFAxWKrXS5M+6I3dZ6CCaZLUZNu6cbjzi+ct35FJPPKF/EO6mhWd5eEp22zf3OlK9terpue9St8bltev7//gu6cUT9h3xqvngpMaGKt4lQWAAABMEJo+wgMtmwGhhUO8z5hARiAIVIiAUJLTPEkQl4GCAww8CBidZnSkaT9TYeJKtaCw/MVZR2DY7SkFCVS5Ukbu6Sd51qln5YcNdBLMWrB0U5RJa2lK0RyO5lSj0Mkq2VE9e7WdHKZUeZDtf51sqfX7a7behRAViX3r5iPsMAIpPBQoBxDMBhUyqVjD0sHliVgMvGDCIgE+BkosURSB5S0FAQGU0kgFSjc1uBnIEI2ArVgC+WDPcxZ4WaMlkWiFzNcrCCZimLNXziR+4HM2qvWAYwMkzINpRIK3bN7EUvlrzz230QPdZG9fUlvhNt7b/It/qf02Gx8Zu0Z2/3qnf9z/frTr8/a3vVcGklFduzqQ50La/GH2mjgFUKDBsgIYXim6FYUYB0PFgYGhgQQkwWVpg0//uyZO6M5UZez5uZSfB+6voDaYKkU1F3RG5gx8pNr2fNtI7ZLBxyCAkeGxKDnRwCJgQoGjHhuHV8uK0cUBWnLpmcmwqXW45ybhpBhV4NFYs4RJzxhlBsqUp03a7ufaRbz3UStZHfKgxJIg2p24JjKUqaJL62kgbxBIZP5N9496xVuEh8PkIzU+nb+afwxKjiiRCdOIRmLz/noG+6ZQAAcwKfjL4XMkkc3aoDGN7Mpl8MIxhAElRY0NgIqZkRuGgFI7xyBFuAVYMYsoJMKAxDUjWropmMqFwQglTVlAhiQplTFaSBX6MDS4mWRkCZINhoh2iIgJ+x++gsuxpi6yhZ8aLhU3ayZn+JadKGLvFo7qcpVIvK4MP9qNV/UNhL/UEJdJGz0vWdaF/IfzSuVZKexl/dxlWLT22MqvP4jK3GyZ396+pYo4HamXglIpPEJ44QAYHAdINhiikUDRfdowiQImRAJO014zQiVpOCQXoMprTcXnfRQwtEx+VgfDdHc/jW/R0SW4aUMVtfnstOVxyGXvyPG7X2e2rXfMUeGiazwoJ1B94Xhu8uTi4rcbmxLU9NU0bUsjYPbdg4DLTzjblULVTVQADDCgsDKsGTDM+TVMMDjSbDX0UQ4ZgoLxgaChisFhkeCo0JTEwa1O+ONSMZIBRgOzL9ERczIgwJtPNGgLREqw4AjHNDoQaWsEUMfdjrfRdo0RoJfjRxlSuFiHE0amJ10aYRn2h/JqO0RThrGJLKqSkQS1Up1DLyvCpPIFSNVdson0woe9lB2Sz+f+vK4sO3mJqgV7l+VmkKB0vudMK3ptH0zRvpTbBbGW/ux8730+F2//uyZOsOBV1czpOZSfB6BRojawwsGUGdNm7pi4HZq+nphg3s0/1Jk8V/MjoT3Msqi71E7toK71rTP0naMWASACiiEm6gQFsGvJ8c6xNpUSaCunSUKWejW5TTEhbjYh9DEAHikUXysSBwg8gKwihesnya8Xpmslq+5F822MfaWZRuf8+0/yEojm9755t2vxm9GQ5FhQPEYiWj/BfcYRnFztckQ/nmX3wR5FeF20QCZl8upYBoAERrQ0GDzGrFNKsc4/yQ0RjQqKwiWrPEnPmQAgQ045aJwBxRhagIQyAoWFgYkGNS/rTkwisaYIavRKiZEIMmOsUU7ct1ZEeND2YsDzGbRHhSbtglDlDq4wHF6EzTMJl6w4qKxLT/QVmz+skN1yqlLE2ZpIrw3OJKhYd/LKPu3VW/euRTV0S54S11HCocUuT4+tKYqON4yjnWOnEivZZ+vyk3Gfpt+7vqvEtXzatZ2ieGdxwERxynsV9x1+8KvpmuUmc/taDHSBiGESLRJxIQSwXEPSgxacbHy2zWnNdBNVh0D8Uleao/zspjS65PXoLwjvOR5nMPQ1nTQatOeB/pmD1o936Wu7uu+XcpBq045DxgeKDdBw8dBBiPOhivb1LxtBCxM2/qe6PZcvdCl8vL8fpdpX1DxoMrSBfxgcVKeiDRfpsoCBAyFCENrLYgsgICNpMkdD1/9f+hyNaAEIRnMLmJ3CY7RZ6I7GcRANCkBCUyLc6D8yg4CmwaCLAQDjTHhVYwuEARdNYiGDSu0vRASKJR0e3VrNEOoUzHMToUPhyuzsT66EydcedJsdbGLT5DoQo0M9T747E0n1LmQ3tF//uwZN+NBjVmzguaYfSUbIp6YQm/WUl/Oi5ph8o2LyldlCbwP6XEMoohzAg/qU5fOKrZGeFJWt/XjZReTI6f44JezEXHMoenSKM8AupuOJJpSEjF5TQ8D2OXyUufXSW7YV+X3ZfQY2mq+X0hNXUSrXs9gmdQPSEhShCWsy6lTBJSJ70ddsg5mK3ZgEJEFJOEpARIJjhqJhBtHjKH7zLgbVMct4/rN34mUXoaZvN2HiwnorfgWv2s7sIldSmvH8YOY4ymfuo37//uqihBJrRf2XkwMDlxqkvyhuPb2SRhJeMovR2nGd7yLPlONbGXQ0xS2t4rEEy+ji/INz9l47SQ8ekms+pPJskuRI8WKY1tlvrbasj5ievrrYAAELEwzuIzA6hABkPMr0IhBMRSoKACPTAYXIk4NBAMJUgc6IyVMtMHhlqBAYdIFgEYFFgIEFwXbXHiSHjQz5t+o2/UieKTtVqEXnIrmb8fkk93jAsntNLw7M7G/lCqscyX4v66DjhyQTm3uFPWWB5fomd3uIJNKMl4rGX548V2VS6mOuu8bHNso3/aXGKNPxW7cX+2vM+772xh895j2bQrGr8d3yt1loqJAxURnDxzFXawzbrzXrdtHXC0ojoQaDF6yEE0HAJQxAE0Yx4tCw/ZS9ksPqJuPtqGw0HH7kTkmN+mBaHphaRpUG0KBKUS8tlDJyzUtv+av7WBPa3vrbqFiptH1uivf0W23J19lImtZy2Z62se07ZlXdt7VbsmcIGFmChXCS7CCYLIKZZUIiBAAlGdQ2YXWZhpzHfD6Dp6UF0wWHTBwnDHsDpWPg5FAgfIwChYri4aZpf/+7JkrQwF8mLPE5li0G+r6so9In8WzXk8TmWJiewuaqmGIaTwxwSUBOFqohASlXc4lVlJQU1d0XjoJ5IXkIdThMfHWLz286rTPRI6JuSElaeNryr1gubrXHU9pq1NWybB0J1FEyhNKqprW2bLi1uztLVZtMqTHn/vTFqh7vZpzXdfV6asu7swxPrepW3PTLl6r775Jj5afNR7nod0hLrA8bHzsv2gvY9N3a8bLX9Q3hZ2xtExD5JAziBTVzuahY0qKxNnSGy87DmB44UheaEbvigfiJDkoZgpjYseLJ5wBXMHUxh8XajIYy73qbvGklj41Tfe1JKWJpIsVZLX/5GXTcpXPPNFt0yvFrffV6z6RPD1XX8pHIw6/05Zaiv1EZuThGiKnxgkU3rVBAikkioVAQz0PCzKBH48+0CNgeBQIDjgAa2FCTy8mYNOBuEx4fmR5UjQ6omNwzfRDuoq60A+joPDX83B4cZGSaGrlipVRoNB0ngufsRHNIcVLWQdMYR3GJLCd+RBCo7FhUdJYi94eiMsX+KY6SjGpx4t4y6xvPn3fy/FRcrUcd0qJV22sjiai6ucfdDdm7KahTEFLwiHxbHanNUZvNQFIsBImFG/3ON4gYnjdVYl9ONWY3DttvIEZvb0sudeo+UmslfoUsnMzCUi2/FhQxstrgSWVWFIhzlYaycZ1dkJmm3bID6Zk2quaI3i9Si5WXFg4cHKhUGBG+eRuWBZFaHA0wS1HSJ9ePWFDIiY2vYgChg4AGmR6YDapkYBHvr2WUFg4IR4YAQRk0cAqeCh4c6MMFOQPMgEacvlHRIMwooEl061np1o4DosBB3/+7JkpIQE/2FQu3hCYG1E+s1hhnkVUWc4TmkpgZ6jqvWEjeRfaHUEddJubXWJUzQJilJCcFQvNIJEuXIlU1AZnOW+VNIksjPHUQv+rKm8QhtD0yhbdwUlcOp3tLY3qrEsjcWJQXRZ2G/M4irwq/nlvWhnqUbqcI2rn9+v/Wfb3O6eebLUDpmfiiAw0GwCCLyU11kDAsABSfWSZDtAgJYiI1WjHmBwMaB1XLWNFm3ba/kfbHun69O/uY+tVMmIvwZ8HQ5XPd8dgLUZWDKggwpBbBL3EiitYV0i7OZ0lI4j6UvL/v5niYa5Zy+/ll4MySc4zVZErtYCHEb7VQAAAVDAoDDIsLTBw3TKAnzVWggELQOA8wJC0wYHwyEBQoxpgGDECkI0okvKJEAaHC4tuxjhY5CBhEmDrUCoAvql8rydEIpGl7Fqs5aVZemCvkFBWjzvNxMEUeheT4RDiJpKbMqFapPi6JK5tsQ6629LlIY3H+zyXuofeWa16NnLu89JJ57+xcrHpf/vlt7e/y/p6lW7JffPK2v11Nydxj9qfKE797I0TbmGXiB3YMAFNq28csyEe2NVN0CpKWg0UhXkPCFil2KspQMl+atTnNRjJVltYjKXlIwUH/FlYIbEp4ehgQBs6jO0Gz8hdshvZHkvT1ejNZoIkIDoEaSExQsWuBkRNB0q5VFZxove33yhIUZoS/QAAQmsgYZrEYWPZsY1mh/yLcsaMZhoAiADGwg6JPGKGNIFlwf8BnkB4jHHxmKByyf5ZlSTZyUFO9T7W51+kLV+QRff6Q0qvaWiz5J597yFgOrJl5eLB19HDUdb24xuoRcVY6H/+7JkvAwFbVnOG7pKcGeGmkdhIoYVGY06bmUpwYYZaZ2XjTwiPVT171lv+/fue7FQSz3XyzV1KvbRbDWfSyN3lkM/hBWK+/KjlOd7u4/yr14ern+nsf/2rbWYpXSvTvwym1s7937roGvUAQJJJt4dIZmYOg4SXlZ236+6Fxw92FSrTIIK1NbGoD7jIjU3iqD7gPyZRLVirp7u7/FL8FkAtuebTy70slkmS/Th05lIXDLOr3BHxRoA4aFiK1bROk4ze931kN9416VKrYoEolOYqAEyCGTCBbNSGgybZjFIYHiGMjIkF5lwRnYCFAcUAZMQEDU6mjq2NdThAT01cHdSEaWVhtV1ttBg6O0k1ZoH9nOau6izmg2NKyhg7AcHIQWgqXjR9DNR7eMNVoEE3WxCujRS+rT2m/EaHxa/l7ndYyLrQdWhlV1XvN/v5wrHKtcc3MGyM2vEqmfFLKCK0lCY7Ubc+kD0OULcqIAEyOW8kQFRzzKCkoKkMdIWbQgbZB9LUtYoeyi+k1FXxaG0Gc4LrJyDAOnMqTCk66WJDmGnPfdoP9uyyk4wqICtDCyrTK0ZzscurdvXy/zyDH0meVhCIYOYT7j1C99tGwGhwlais71gAJFKCQZMRgEwcGTOBMNlyseAQkUBQTC9NUsrkWHQfICBbmJl6Fyuq2d3zGHanAb3JZo7t82koUpA5EVB6JAll4qAEJg4A0Th/Cfp8PXxQBypgYNmb+iGJZ/CWyebtHqZIoODASFC95af3aPDhxtXDf7tlc/bOz+NYf9f52fleZv52LNt5xEdiWfwpFBw5LB4YOMRPexEdn/7aVlW//FkU6v/+7Jk04wE7V9Pm5hCcGfGmjdlY4YYKYFAbmWFygas67T2IX3P/zfbcxYeOT3T+lwREp+w1RZTTg8pRY5Rt8RYuZA9GQLIIAInpJJyyRYkUrOeIjwfB3JAJSTcf7PnxbSvX2cX3velOygU0iXnHPy2Zv0o/ScOFFW7GYBz4RIFKBwGg6pGwiC5737u9VJ98ECh9kCgoZJYNxEl9/hLhP3jot+OXYXhO3d/kXeE493jd70IFK/93fiv+XFz5Fz8y0cfHAPdbOoJApuYyIE2cMu8DkB3JQsPVhBhVsnETDR6qZzfx9mTpKow02dnTKiU7wV2wpFHBqzaOfTUtuMYzirJUc4NEhATQzR6jyUq0UySLaYQnowEwtXYHfcGyAxq2JklYsa2zLD5ilq/PxkaEedDKp5j/cmaPjaFE8U5b1y4sbEcpd2xTnWh6Hsyj21Ts20QfplxxuHLCPBwVxcH4h8aCn10hiwsH5FYnBkQ8v4/zrWy+I96cilMtkXpEmnJQq2m0NvgRT9S6bnPcC+PNOIQXsPwAeBaxMEOAFgBwS0lqFjfKdKOJ5pxCSENByOdjoepxWPH7uHAViTV795oDAAAQEW7iAAyqjKDAypvSGIOJDJyKojS1Ve8RZk7d+WQXHbM0/0ZV/KYLcLYCPK5+vWsriSUiMvKiocTVpSkePqtPLSy6zerl2HNr/Ng4HpbE67BhW6weiYpHQuGsdWS2+9uPVXHJPZx5DOd0wL6Htyy47TjJV4nDnVmCQTRUkrFU6eGbTsEiGEoPBng2xZlJ+gk4jF5CoJpwy9qFnWD5JwhhSH3ZSEzNZQEvWVfoGGJ8WE7DgX/+7JE1owHtmjSG1h5YN/tGnplj5waTZtKTTH1iqWxqiWXsLi2NcC3huIaLkAKENTa5H2Wpvq4WcvStOdPqJznQ9jTjbNVzhOoytc6R9AAN5i/IODmCCGCGm9Omofr/YRBCRTFisWxBlK9nVuKX2aBiLMCoDVowdDKTpKze1RtV7ZuzxLtWIwZama9eHKss2vWCK6Kqs6WFS7OtLon2Iy4nUA4Y0YMWS45vND/Vs1yWliAvWktse0axIU6mrx0VGX7HL4dUo4kNVL1CYCdPRhTpNF86yxMq7W3BnTBjOKjJg4GIhTCSZuZFSTFncozoB8ncS03jJSiKMpRxEPQajG8ixtG6b7YWNYaj9h6VymPkvDXEirNLQYtnkS+LvY8hscBAZYgAY0bwNq/ppKnGCHCDyJUrAIxNxiLaTIpnSxHsjihpMH4JZueQrC7JTI/xXK0Pduqa9R1x3djehZ7M1P82i9/31lzK80m1cuykefNh97XrpG8f8tUT5uzAiOM66+KzTdLSmcy9G9OXBygtA71oEBhnE5l8DfXqtq8er0jx26v6E+gs04Si0WaI3mo1kC0yRnoxDDDBCSqLtL5WMl08u/vd8612gQi1QA4nCFLQgACB+Bk1HBgI2hvUY2tqkVApchaqBujkOu9cRnJx+ofaK2bdM4fjqMlhHEPyajtBVKIUUFz87UO89XMWM8zequToSDwd0vA79DVAWor9bTHKPpaj2YRbS+4sYvkl83cEjFW0lqGHqlRdNVRTu6V20zTMkdTDN1EKjrYwYfJgoxaooUbz9rEwA0bUW1CAAEZmYsEsUyBQwQcGUsSXHs5F7HGIUn/+7JEVIAEYlpVawxEspGrSq1l6D5ScXVPTLDYgkur6eWnmfnRJGosJOHUM/kPSIrbqZ5GHObSkS6Io2zzX4btMWEg0aTs1Gs8k3JJMNZh6hAZVdV8Ds1CP6ZRg8VOm7qOxCEWismtyD/JFq7tYFkHUzxduiszT9JoWct0/EpbtETDFNBCUPae5CQseNBsgueoP2G1mojbP/oDCqVpkAAH/wEFrsAwJygAxJXDAZakS+yV0E22axa+pbLKrXYym2jBZbvy+xieoIHnIUz63zn4s11W5IdcUd7nrr/tEipml19kKi5MHRv17X2dgj1adXfSnwkjS8yc+FmjfTU/+VuZJ5l/ckjh05EPOTqBZzS84m2m+m1WdyS7aHsjSgZZWlfIWwU0Zu9vykhMK7VAQLItcAAGcMgFyFD0FNjAiSIivRkSsMZZJFI8oS+U6s3C2bqEidgj4CngM42brzvFV75pSVkr8PcMcSXz6Zrarhs1iksC9pob0gCGwbSwaPLMTnJCbcaQEbiN2OtMiqubk5kbT/Nn4RIVfalGomq+bL5Usehan9clR3uDtK5ZqMmYxZFKinZb5BaLALNGekxBDvpVAEmCNIkAIzyRZyIgwORAE4mNiaMKizqoqqgclc8MrD9dJHsiDyEmcwo4k6y+WjsfGw5vFgU95I+cpDvtWiOtLJTfaquvetppKzvZdSTsH1zyMLXIKG7jp1qHolQ+1HfI0cP22uZjxppvNmeEY/4WOVGXJLr5465Kpcm/hkuHmogedYxmaaEFrDg0Yx5odUsCx0Qbag7LSQAAQyAAB9HG2aCTAVGv0z1CtKWu6RBsWJoFvzP/+7JkWYAEuV7S029D4INLKjll6KJSjXFHTT0JygEsqjWGFxBpvIEfWUPe/fvgTQ0kxG8hCEkxTqEoqzbxfGSmtrEGBE+L6apsj7moqCKAWOt8dpz04txRfE/D7fjzoG5nCvf7Yxr+hoyTx974/skqNyrxkubjhV+au2s3VDXlDPyjqjZfGFKr+CHAwBAANJMgCGtiEx4wRwBLDUjCEfNrBtJQiCxFePttA9XeiNHD0SNAKCYjIO5SJswnA+BtPGIbjjHrZhH9ekszXT+JHfkOg7poHQNXD5wkEelEooPhmPH3IjndiEdXlk1jDL9k10uOfxg/ZauRQk3u5+vmnX7iMmB8FHfdfrV77XJXUwLPQnF0U24NxAD5YL76mQP7PjCgkY+X7tWk6awAEKOpjAiMKtGitydRZ/qFruiSvHd3D72p9MsdpniMOpqIyIRlWbffVfb8PNuaw5VXpZ+taLgxenqOW33eRuNZRf/YqXk2bTtJs1Ha3l0l6pM9LbstE/lUm0VZEJVzto1FbR/0KnTKY0yC1bNEWDyLBRggaJQ77QNJwRRaJVMFN6DFxjh56Gph2kSKxENFwkSBVLAhgOSYtoFh4ao9AD2B1A8PiRnY8NNNPheyKUn9ceAuyGavXLnEvfYjGb0beMlZItKAQKI1OFZyDDkEENvjeOnIrkQ/m1WC5TxkV8JraciuPnuaGKd6S3Kt3YwfAvI/mPlO4Uy+BrzNFjkERhMaHYeQPRkq7sy4LqogiJJawDEAuYZACAzQzakwwI1KwcQmaug52pSVECpAwaBoqkI3DKtTZ4faDFK9IVCBE9vPHGWtjCNe9V/TDDX/+7JkaYAEwmNRU09CcI4LOfpo49ITZXk8TSUYghGs6B2kixBdwL15ICaOlIMG67utye5o0b12vVpJVzTwrzpvKsWLGFRM0lKqQTRn7zwJ7nt8zzvwvzmRSC0pd9+gyg+U4TFTYf85wVyn0vufSkG7WFLco0GX5SlUCOQsLNGSkGQbnbhBaMROQSQQwAAQmDhcUXYZUTLaR3krU4JWoPD46NIqjoqCv01kcDy+lVDEIg3spq37jdk5793tNOl5r0XKa3M2Azu/z+azwSdmVOq+g6m4QQaRyDUPl7KC2wpHsytDr6Jeq3+uQ5TdTGwrjpEg/5i7Ucl/dczf18Gv5Divux8CdZdbEOxgvpjTHJMCMK1RoVUS4EQgaSMudCxMzpAAqBjYGKmCiEADjCAUMXJwuypOSSGQSmEwRLioOJjNd4Y8/xegoLQzQNItU2NnVunXt9N3BIJpV61J3KyQPuK6s5LeYVTKwjIzFyQzUmvkbalurqUrGd0COXBFY6jXUXMr6Op8X53uvp2RvXse+5UKvFhEsMU3qfVkc4q+NGCdDRk73cxTNIkZAxUmEIxrJlrgrDzMqFhTBZErhiJUAlD2OLaPZgOU2zvNFOMxHwJtKJCQb0OIo51izYskRqeDQHjtbH72VKzdRd+JaSRDDS3AcJUOKTNSbX0MyhpPuSd5d9kr2QDS//k9vEhVfKcRPw3ppzD3aDIxgN7nl+TRaYwYPrLPLVz6+gR9vnAAQgAGswEuYwKUDITJhRErMjCFkCtzpAZIrsWOobrsYw3tLeiFurFSUYizYjkDSogOO9Xa5CtTlXHOmsrM3hh2wsw3mBFruAz/+7JkbgAEnFxQE09EongK+gxpBcIRvX1HLWFlwgIs6XWECyFXfC3LFFg3WRqSxgFPQTM9SjKu36IbO3k71a9G0ebN36Fa3oX9V7p0o4vOk1OUzrAMCCOoXAVx0AsaEAwytYDUSZbml9Rwr3L6d+yoVaf1jU7WYukM9ZWjbtzHWMT02sxECWmSomOGOo8scJ6fm6y7U5R5QJs+WVRuR69WKjSf0VPuFyz6NCk+xGb4fXDGfM37P4fyfMPTNK1VFLiDKoqenqX6kr83/d2rD4pzm3FVUuSNGKE9R8y45zasLfJsA0UIueuNgxPg+vTtL3kAgDdGl+y5KSLrI1KuZ8RA7bpnMv2rZYA9taVQzDwVUTErWXrpa271eTLaIRzMorWAnD6yC3VzYqReeUR+6od2lLU2QaUYQ33d/Ohj2n1W78InD3yPR5bQkhD+r37/kbvuhG/3Rr2OdEKLRA4HpYaMP/SA7MZIokWzhldARIKpGNeOEK+dpHEFFxBJVS+PuBWg8HB0SwdMwWNIqimPZwl2wQC1vB+sgfgOD9E6w678ubWXT/+xuabRWXEgBRcGD8mCd/RNEYWLmKGn6fnfystFGhGuXmo4P0Tr1k9jDkyXjH/E9/2CqW38PdmYTuzmQTObGorqYtZxcNYvuhFuiVfd9Y8cINVg4Ek2eZVWwGgSL9TAQU2YcP7yVHeclynYj/kynAAIoAFUoGlUBRwUKMhmy2aXJEnFWMrvdoMFVMvNW/U7KJbnvAsBSbGhvSsVFW7lbqS/9zu7Oa/qO5lSPxW6P25mJPy16KDmj6KqsigPlp1Z2Vx9lWI42J1oitRitjyDTxP/+7JkiIAFfmDS0y9jQq6sSixlicRR0YtTrKSzAgksafWGIojUUcNTXfkmYzmkxlqNwlBQc1A7kfspBg6fdOM9fFoKGHRmjvdXfdoyeHsAZuKqC5qEaDYsBQPrngfGiNNGVR4gEYfH1jiC9tqEFRsDY1CNG5U7aiSAwiFrCHieYWgL5DxgjLT4RbW40S/RrhrvEzZ1/a+pfHFENQUoLAHHSqKhGCJv2gEYWwujAbUjy9ddBGVbP9U3d9AugedKnbh8sKA75xUWa4NEDdQcPxqjMwm1RMQzjKjWeMbG7KJCrXKSVDNetJNbo4qr01MIlRgHMPEBEUOaPRBIHFWk8ZVXEDlZmXIQgAU7zKsv6z5CYKGQujjKS+cQSSai0lccjnG0zir7NbKiM8pb+aHWL6fQvpWXtqEDv0VwZFHszyO4GP30ZWOEgp8cdrXmAROUs2hg2B5BqGtUeib703UfTz1kHXEN8eOmGrZY/Xmn9Gnun4XOaLv9ahBYTxBoPQ6k4oMUddVgeGKpVtEAEp3qYJkA4MyawCSBkQE4qogIJqZ44CgM9qlFyIc5k8CUJAHjk/4kQjNZE2zPICvzRQsCKSg3QUGV6k80XcFFPNDRRwgESufrGtLQ9/JTy6j+Jv4FTrh5+SB/NC9dVGIUN28WorddLHFLw503CNs84xLaGEK7tEdWuboNtZyD7UKwxxVIOrWme4wEFTKG5ZFOxPsZUPAdOcwhCOLyr4dR2I1D0hldmIKdT+9VrSYCBOWIIpYdRRbcpDW6+tduoRr4dy1LbOfM5NelogCk/2sxTlMdoOzm+oJ9nflMZWlZ3MVcLbcrWZOfStH/+7JkeAAEUFrT6y9CYICLOo1hgqgRTXlRrDyvwfMuafWFixk6FdRDtSSwQajzKiBGQSFaQIdkFhHF0FQevrZBMqafzlaAa7E5E2kzjA5hKz27UyfDxqyOK1Uof8y1w87N7Gkg7IaNc2tDUuuHJXJct6Xj2ZIRL31GFq+Jp9fT638fG8xnk+JI8CEUTrPq4xInqsxamEjTiQvV3DXQz4ymx6nV6i7qQnmftR+qPZ+ZDSmetH71K8oqj7kdRU5SBMTqhGMcOsF319MYRWma2ksIKiIdsBNboLJCqx5NXOo6qDz9KmSgdXrEolA7/6LBGP1KfU0SGjWqSMye5ydprW0+sqt6FqIL7VHNumsl1yxVk+KREBpVyL010mMTRenTLWbB2XUwv6boZ3ej/Qwsut12p9HlTm6Xqz0Q1N3R21XDPrGTdoIK6gFYAsiRICGRqwiHhjQxy1pkDyETP1GyIKjE0drbotal8ea6+f1pI3RNio3bVRqk9NQmNStnEltYWYu3bPtmJ+hIc2YFps5hWP71jFzmYV2OeeembzuaxxN0w9QzVFlLNXVOhZmF2UNEGoqUFndBK9TcWK8ZaqmzI9BZ6slHEGgg86jRVmoQ1xYvLIAAQsFRkkgNYNDcwhRACGFGRyLBwBfdp90AKzk7WDufSuRJrToQ0k8q/uGeZc5KC3Y1Zr75qrLUgKTPOwUw+lNcqXvqZpWjktAs0RMXT3thlOWxupn5bRkdOsv/ax/TqaF50noXPJslBKWTJcv6v1u7z2Y4YEDKgzIMRXUTTp6mEWSPt+appHBISwBmACcPsWCG2QkUOg+nkthVEADseNwzyPj/+7JkloAET17R00YuIH/rui1lA8QSJXlRrD0L4fytajWHjlyxxFTsBHQy3xKEyWIQOlqQ4y0e4d/omva3kF+1M93260d9mB8d0IxwxlWzmXhr8aZ2JTFqyjrbsbWW3jQ4O1heRk1xrOddEhQ5vOrdqvSiujPUmbnmvv5/l4nQf11Q2LCaR8rMwUOecg0WSkN12wh9faK72NJ0hCTPVynKoCWcGpTLoJROenVCoFSyaxKGzO/pkbYSUBQupc1UMdA2ZY8lMuFIaSKPEuXJ8twN+7e4O9PQxd6hShRKkWztRtjWGWs/DLlC18te2MpfUq/MTLZ0kFUkNDpey8NuSlPh1qZAnEletbAwuAxlgk+8S+skUNmlSVtpOo5LokgRuEpBZsHagFBrIsHHkG3AZMzm9HXuadYXzA0MFYWDgxqkbm8t1vaSnjl385VXZvT1ateCxAJSiiWmxg7mT7iTqoUMX5/Gid8JTa5m2vY24FL98ahMxi5xDvnEy640p85Oy1OKY4x9dfOZ8r8mIAV4mJCRsxAIdTuuIBAgYKUMLJalIYKMIBGkhkWBgbAQoemGI26wGArNYUkRGbTzOttYCqsooJy+rMTYiOrP+zdmZXS3u2q7Js+3uaFAuKdEk37vnn9u+YAbh2KQlqBbgr/6D0RqKx0MDmwQyQUIq4IVjVHDpWtqIlaqIrFsvURIGi1lwuwE4y0JnIUVDYMtZaMoz8kqFQvbuygmshYtBoGiHuNKPE15S3IaTAHjCMy8FM36BZI6uRcSKcCfD8iq2AsvDIuIbzM4dVM4+BtD6AOadyKCJHIOH3hq/Xvxh3F/yKpBDCn5j3P/+7JksQAEKFpSayguMHlnqg1owsQQ9W9NrD0LoeqtJzGniohPWg/jGv79ryO5r+q6Ud8V7SOpI40m9lWOEmTgtdTnXm4P/5wAABCgEgCIyNC4IMamaVBaKbvGNiU5meLtT4MmSbi4yBJ+oNWVBkVL7gAUo0TSojRPtKiyBQWnMUgah1rBYQOEVvpBCjjg2ggM268tiEWHZKbQaD2ZqEK9L0ROYvD5vOD3dDg3eIPxJluRciZztZH7u3S+jO9dBZu43J0SKSMSSaIZexBOYkOcuUAFw8KYqqkyBOF45SyhiVWDFk0fXJf5DxGGll8YmHyc/GdnKelmcdTktcXCvfz2qluWlW/i87J6+IIogpQx++K9SVZT72QOv2dWc3fy7v05Wcs2v2r0lryhEW0uiWiIi+hdrbap61Qy0FBdVQrnCIcLKGKvSS1LABIoABSgCMh5g4ADhUxYoMGNhWvMdCWNOQiQngYYIqBKPlo5y8jA8+dND0pIj6XRbKVEhk6VnWvm+axiseX3+qenLGOp/QKnyuGowtqK0MKtDo1CkmA2orPY4qjPsV6et+TtKFBshue6SCaZEwpc31xDsSHYUU1YUCMIOJgAXEmbWHO/mpdCTQLghUIZwAsCIhDX0ih4hLb4QfczqgTEBw4TEZpRWJ6IAUWhmQczfa7ytujVfhVsy1CHj5PCoFnbHfv3fek7WAuokxNuswquzCQnlHSZj/Bgv/KraASPp95++sxju6OawMWuJhv1trYH34VH8XfPzf/nbzkUXHf5v9FOBDDVlFoaDQ8oAXEHT2sACYCAAIGDRkUVlDMJzBvTbZg0sXBdtirODXD/+7Jk2AAEKFpQu0YuQHcIicxswsATIWs6TSTYwk+s5uWsGTlP5LhC972yKZotvAyRO1ZZHaMuHi/BjITcfurK6W7u3UxoURpH2SU+oT9d4XEctob3mFfxOPEfvZ3kYTtjNK/e6z9ftqvaiM8f3dsg2oMYCF2TJk3t87Wn9Pv+H8IId73Pj3fxsbdKlu/eyYOBrws4kBgGQf5cf3/6KbKaOAJ0ypM178HbwtGKhASAM0htNtAEDiiRpdOC0gQhQGQ/ewjCWomI7GSNWsanjYi5yr3NTvWJkX0evrYVAhiljG4yqOpuCEF4Q9qOhvdnOdgORCEgkDpDdPGxC/ijIk50ozqT30hfYPIKQ3dEdyg9nTC3k7B5SyQ8XrD84hJ91j+H+RNr4rP0su7n6vwKH6ft7zae26zpYOHIq/dg4PIr3WrUgJiQWxUJB4UjwkCAZksrGCIwWm9XV7VV8V3m27HDgHAAAChLTapbkWDmWXAwkF0Q7DLXhYIlw86S4CXgT4xijIWRgRBAPDtGOSIxU+abO5CCKR0nzTVc15kILeEfBXuSVH2eagwEASFjCzpwqGBIPGGLtuLCQYIZgDSp+wsgYPCuVERR8+PKnZb+egqkZPjjkixWI7XHiSP7X6l6HByuoJbkA+HL6uAps0SHq87N0Jgt2yJsdyWbn7uMQx13umi6KYRLswf044PDNqFeYDwAQtiwwEN49UpDgmHxwV1y1nz+eWUhf+Y7OXScsBEKAMMlwBcCyci9GzkgAEvUGiBIQKBxZEMAUd39TGiqHZA2ffdPtcKYVeTtNbPL2407B5Df3z5+nGCa2MPnjhXRMdK+O6b/+7JE6wgGI2dRm09jcstM6kpp7FxTAXlNLTDUyl+vaymGIpwin71UKB/i2WX0j2pvH1nfNFh58y0fdR8X3+S7eisd9yf2bZZ0LEbPV2uDk6KO72VVTUOkX3S7YZWYxMILOlm9Lgg5gdE0/gHXO+RDjJjX2s7oAAN2REgBM/BHwSoicbWig0kq6hLKUFFmrZYHZgplS9aaOODCXalMsrLOmGVOgycYicP4VlZEFgMAMGsdDhBK4nH5qteXHbTqEyrcsmofSXlrykwVdIvKutGBufkZNywrKKvwORURLqjttiOFSDixAFmKN8aznSc1xJV8NV0tvTtQ1Vl1KJ7uItWMSDRFyMPeJqlckyTZuUoAQRhWeCswVcMiNRWMq4IQQgCDqgv8AAIkuBo0kJQ2h4yZLtvXfQTIBr8DS99lvzdDKGuAZrOrtJQ2NSijDhI1pfyntQsO1Fo8iuFkzx++P+zlPe+/m2Q8w7hk+5xl3u+Dq/op/VfoVna95at14h/8rsYgnu3XN3fc9bmCq5kRBcRkFD7yoQxJYqb6QBChYybw+yUSHgAUCVoiBOyvdCMOiFtFVEBREEf2VUVEw0aAyaZhbFnLopC9DO3fG4nLe8Kl5L2XNnmXDa4uFVnbPXNTtqKkJX9//muWZ9iEsNj/lY26V5fimfqy1TLufM/4XYRsh+1uRTmZXpdYy3rwoEHGovS6kETAo01lGETQZ4unTFLBisEJgAxtpKoQokLKhjQmGWbZCGiRRnMyhZIyMCHdiep2eJ5y6WMaV+nA6+ToWMYJhxb9vDkdoVDsODxnAh3QYBFOtRFsRLpwGkNw0/h7sSQP7En/+7JksogEWlrTK0s1YHhLKmFpY6gTeXlGLeENQZUs7LWEihTUSVfBV3jRURddahLv47eLrOE646PgofcJJnSrSLTXFNjFa6SbliTthXr8uGAWaVNGTvlxIsxJyBbaQJzBZE3XZGswhA4vwRCRzQAmFTDJq+wpu9eCa9M+Ufl99klrk4Tb+nF9OZ5+wJWEo+AgkYU1LLW3htSjdL7oYraNmbv9SP0Xc2Gm0dFZH5cyPMnS81tuUtPsZ1rhQJyoMM9qAb6qLMLAVOk/9t6wI8KAjGoIGo+ku7CpGmoXo1tybnIIMrNRzutcdK3bpngP2lQFDAWoAQMa4uJkNdW5oXyv0ptllxD6mgX4a/UGVLWCHo+qVs7Wz7z6U/2672q+fPzaj8tWbOp8sCUrtL9mLZjpz9NsYWnTl637ne4OX5SS5UftpLcDYVyxQ/e712R9EkAKAimAZd9bxyDKzExVBWAcMJnYDEnwIAzEOqWJ1QTt7qzMFLZanB9UgcyuZq3qJ9HoKCaxR6M4WKhwXLcFiNSACzGMvZDSnZc7GKgpa8zyubchOkYLK7Og5Vd6ytMyVR7kvv2vKaleRHlLVyCbqzsIspCRJWgAYmlDDhg6sIMLAzxC09FsAR4AQ9bRlpsDgoDSGEoYXB0+GmSSwBWA1yYAcpW0qHrxafmmUzZ8XebMjw1NzMV90vI5ZW5cy5BkNHA4IYiDNxCx7gQq+FOw8KkRAlo4fIoMM0IGPA6uRIdPDnX89JN1UC9V3XQw/uj+gU4r2PXge1668X+z/LfpPMWkWOa5euJFYw6VJiHbG08G2a/JiAACscdIMRBfOl6EKlH0OdH/+7Bk14AEW17Yawk0yHVrWs1hhYJTrXFEbeUJwfis6V2klmlCxki+GImZUQCreIQxEdrs5oJlRZTl4pthM0+uAcfFInBEx0ssUQbJkvy61/X7/mJksl3ft0UyLgbnw+RMbK53LBhZ4qr6EVVnLj2bL/aa7oLjRVCUdnQooZSK1hJsxy5U65kzI/7shlKGY7XKqgCW25REXh53GDimY3KJzQjmCA4wIwSARhMllRoUAAKhVEEwSIQoSChEYSRxaFVIMAIIBDckz8k/nKiSwbLCz5QBpLmwGB6phkIFpbqzMzC5OTIr3HwZ3jyhS/+BSJYwpo9BEIwu43HTDobY0CD0swswncC33GOybEOtZntRnSvLCML3M3MDaq8odHmRWNJXD5/dB3JaqMxl4w1uLGHyaFzaGtjia1GnnJXYsCAAAArU3hWYGUnIwSCICR1kVDfCaRRJQYW4qVafbxymEYRxSc3AcMyCV24kNDoOTdqkDjThVPWRn1/0Nyy687F6uQkPtRsTW9W4clnZKOgNGPpc+7a+vd2cNFa0uiOCY5bjYBfzqTlSViMABsXFXPKwy+haAAXG3gA3HChZmlCBeg19hMlDQIJGBgBmCEIQIcXNk4RwGNGbBJJgCRTnShpOweKMkV2EW5DDFPDaT7pi0aTculSOka63GGk45vdWAZzKR4IZeEUWnYKSa20kEZA+ZVjaSjZzdq+iUrnyCDFabJKtXC5C3JjHqPfsdN71F+ntrTraxZfqb1WWv0WfnomH1Wj1/ezq1O/QWUuGPiR3GybzdVBZOI+ziOcPiYM1VAFNpKFRQbK6Zk2fACaEUPEACTa2tP/7smTwDEVUWtCbj0WgdMh6imUCmxV1fUJt5WnB2qupTaMK3NkhrhTQGbogo8R1zGKyNgYcWjzCXZahNU76PU4kUjcL1E93QMiMNrOwWf4P9f6edQuHsZwV20FaDyt/K6t+xECF8eh13LpRlVH0VmZ7QXddLQStspbGb+ab16X7YtosF2a6Bil23IEgZfHCoUZndDAIuKgnoByYaHA40RASEsDlhEGJBCTqfK/BETEoNIr3l90TKfJqmptHM6kmUYzt7zFbtvDfeOvCe5c3Ir5MH4cvMD45/9CrgQBHH8GSm5UXLfwIp20FXjC48a3AgNAySR8N9IKS2oLK1k7dUrdvIp+JShJTXlG3HJCyIIiXaiBSyC002wACiTBBhHEeZ/tWa+OjTYYpWGPDxkIch6DBQ1lFXeYQABVSIRMUD1NEsEHAsPs1SPFQlM0oGVeey5ywwIW+mcyazIZfJWIto3rlfhXl5I+yZ0tEV1YLloG9e9YVDKIzmd2bVDUeebExelubRStR/3tnXRuWK/71TVOn9SrS/VmMJtILSKL4DP+nIATCkcOKlUwuej6qBPueQyQkjG4GMiEszlITHg1MEA0zGNTE6dMXHoxwChVLEApMiiIgLDBkBJzmnCWYPUn5LvszIAyvRo2SPQNgbLIRk+X5gJ2wsHLYNywjdZ25h32ctrT9pXgsyqkT4q45x2bebUnl1JkbRQw7CHLI8ejRQ9Imcy0im3L75mzHTXlC6jnogXqkvllET+v/1DbsrRb/Ir7if/QbL7cLn/CTl5Ylq2Xa96QG6rhkTwkqYT5NqCUKSYCvWDaA5iFMimTTnYy4WGlIyf/7smT2jMSIWlMbT0PSiYs542zFxFgVdTQuaS+SDx6nybwhOI8TXU7AxURHTCBMDyVI5YcHEZa6Yqk9CVgIVsAHkTkqXiM1Yo7CV0CXnorTLoQJG7139WQ6AcuHtK6GDQ/oQ7sYfknw5iIMj+fnf5j/3u//mT96nxqxXzD1M2OcJxa9wcm2EyN9poctURoUgeEaaUoZ2wE225QRqBxVPExgsEVxElLA1KAGLC65YIIBGgmCRuyh0YiPEJa7osUR5Yw155YfrTa+XHcodIvLscl10MGd38ohkJtd0tc6wWVlcq2xcwZlAHTKjX+RBhdqze2P/GECBn+eI8Y+5bZ75xBDk15FncsHVt6xesW+mY6/y4uGkx+5dHr5+xhit5NP/P0AAGPC1mNj5ZSCBC/c5Ae06CBAAquSYKDB/GZBoeBEag+KOC7KyBEwBgIMgoFMDFAbhkpJaIkURJhgJwGUHodaqJjhchTHuBpGK5XP13eHDI62PLDZYIkbHtKnJBFittNmCFOCZI9tuYr2LaSBMME8vaaP56g5dG3KENFAkmRo0bbrxiEiwYX4Joois6WMamStKQSYcsVPTnBcnbmvlLt5HdivMUO1Rh0iSdsis2owSP5GCiooIDkDxPTJtGIAwySKtig4QJPDxmhAEHATBzQuwbIhF0PbKKpbuEs6GgMCzFCepg1NozWHNl0Sd16hUPR1GGrD+Gh2rQXgkmyN/qNo3X6jbf9c3wlby6YWe27k/CvLtiwBcXqPPzEzX/9R3gcIt2c9vbVpBSl/rnTuzV+A5urcbYpPPxpfjbWxz7Nl6xnKQ36lcYxe186XjyKFthmi6P/7skTuhETjX1IbTDUyt2wKR2npeFQRg1LsrZFqYa8rKYSx/f19CoVTJfC2WqantHB6F1KXi3FpX6a6gJEo1ElBwA98rEmiDtqZpqts0K4oU7pYDBb9NimHNRFUwWA5OStFCxKGHsaCj9WFRDfqvAPRNT2CWZeeunv5R8kkWyq4faTThM5Bm7Rbp/ky6fVZUWtt19GW8z/btSs2zPd+sC8+PcTWn+RsqKwnOY4t2CNnm5X9d7IKMZuUSsKb5Zl1126/LoBs8xJt2Uej7mopjX2gf51aCvGxSkTBhoOCnBhQTP4eR7ABVAYmsHBmSorF+EXFAG5x2Al+JvhYecPcZmXGUMI64PUWDCgZiOHxYOREbgmmGmdPQ+ocTGoHMXUnW0UYqDTL+hBmLButTV1yQvUN+r+NX+qYwmttOWWpt72vqS0vXbmpqFhVMH+i1y68YUlBK5NKNpBq6X6gTQqEk5HIUtKkWQqROmHUlkOkBYTTMowuVrTLi3WoQAzjAa1ZAEHQANPO8bqmzXdhh39+pfbQoPK3dNQ8Kitqojsh3N+StW0bp5kW/Sdp1bNv0J3ROTZO/I7SkDx1QXKQ9pRzCp6H7KQAQICdgkWjAyZYsn7AgFMiEMLAEYoqEAyEEQOZQCimYhINExkcLcAZOZUncDhcCBxKCJmdUTe5krxKUl0iIH3myOBKxMC4qpTLENh9Ay7qlfljq2fY50DlqERnfaV+6JfFUgfvLJbUirs6HP0hVerVHLkaa9KCr+V/tFZVFr6kqy68Wy62OW/UXyO+KssVhXvimOrnpP94u5wJZ33jJ3Ort21jXxtQi3dgyCAVfNiokP/7smTPjAQ0WtOTTEQgaEurDWDFaxUVfUJNpZfJ/y6ppaQOqHjDDFgcyTGCCYACpup/MlMWTaW25ABKAObkxqVxYv1H3wiT3z3LSqUuewIeBlwOEYsnHwMMKSCPi671eMfTXiUo+ZmvamkVsd6JsHRvctflaIP7lxr7kmVkhkf5fIXMu6lD36d6CH9ZGSgRwr4cMzQBElP8E5wTdNUAkBMR9hbtMybzgaAzEhMREDFCYRCho4KtYSiQiHN6gyyzbgKsAtYJWKpxpaxojvOTGTbsvcyq2XhGrWpy/FO2X25XB6tElucwiAnEUBYR73mZl1qCc3EeIoCcB3KboooPK0PnGior7CGynLPKOdpdVSV7LCjW+hAYfDJHEoOyYjVEyaOmCmmirum2qVPW8cU0YqK0QLFWoqLXBYqL0Ot1ACEBEFS61t1J8Iwg+EQXEQBJFxibok7I08MobeIwDu5AL/1Ji5R3+WHqvWha6akCewsPgfDmg/m50DO5OQtrVFEPGjQwdut9zPMg22m1ItyBH78rX3v/DoD+RF8P8pUQ7cvIi6Sd/sQ6uUhzYyOKM4JF3G7x+/8CExhXDcwZAIhN2MU/aIxGfUdjCwZMnOEQDoHBYyYPgxDGjy4ZgEJLKNAGOWlBRYRgQWWKMpKXImjOlgWtBQOIRYsBGEYGIQPPIoKjoW7IdE5a1NLKldvmNQXKLH2I5bvwXGpX/btNzbYZFT4OG0Xp8n002zaRSX5SP9JjvyXzyOOyd90tf/FRnek/dBFRLynueMXfIT9ureejXIWP6zM9XO9ivXnuVRMxRUxW7jL41H5TTOGwbFALktaVIWQ0A//7smTrDAUBWs+TeULgdyrazWEDqVaJeTYuaS3B8KxqKZSO3awQaeRAhgANITmTREAaWquX2WMmJPxWGPj6mErbBx773I9HoFmHW7uh+gLkaBRJ9lUJK9Gtvp23LL27zsSVcFa3Ff04y8+bkqiTvAbOvTUz4K7lD/qGnkwuDlOyfouXNaXtG//56qWTH/PQgJ8KNju6ygBEcwLWjmwdM0qA6G0TplSHoyZHL4kWDAzsMSkkxqNRCQTLSsMejkaLxASDFAlGoGZgo4eHonaoK0jRLZ0lXeEQw62VBQE0GaN5TDrD+WVKpITbvthYicO2p57Xlr6po5PamYOpu93qfydCFcGbD+DF8gQzICYTPfRUSlDqouqlbqZGk1L16wM5QfeHzG8zPIjNXY9tZXgWENYNW9NP5xpKXw0mxzUCAE7VqtSrzqqeo/UFILxEAXGmqM/nwUAFzRcWCFaAuEwGH14C1gsEmigDT1cmHU2IcckvC9jPmWs2ouTNdjr8tth9LfmhUfHbU25tDC0mdn8y/U33B0CJmaQqS1RSHlXqUEVLJfO/5/rSKbT/ypcNgoYErNKkOisWYbeOJEc2Lu37lM/jfbnF6dVZhjY4e3QZABcadELgJyJhCQddrH+bJgR0KE6YRn5uYSEBWozVDtoUue0sPGBeaZiaSzQIQZSpJLKZFEp5lY4CzsHaFALeSx52zYz6laSUv5yzEHisek77e7iYqpkux3Tra81xPuPOggAR4qCaSV2xZlSkO95zmVbqWQ/e0190ed6+/3f0f/q/Yf4c2vr5m6l6t6iyP25bPjqPS5JWpSHCfh3wnYfs/oCl1t4N0v/7smTujMWvYU2TmUPggStqQ2UjtxQFaz5t5WnKBq8ozaSOoGsaG8EmOSgAuZMeACcscNFYe1EQghDN3TCddaC9X/TKFjEPLIUtbaL2Ygo+1Zr5OSICmyF0UZy9WbH4uJ35Xtdpb76znajRh1rfPVQhug21IIh2CXzQyXZS5P4/t9Q+lci/fhlWclmWaFPPuc/Y63Yhf8yl9pCfbouzZ6IQAKdll4MNDiAQRDhgxGeGQmNgAKIAMVgpBTtMEDw4hMUHC9kjKocYUClEBE3cLIiMUEAav+fiEVnIiyabj/Osbq3ZTGVeXc+XKZiADHh+JNQ3QoX95ZnRQzEHSYuqzg4rNws9RAgP3Ie9v+p19FzUwfHKN2KT7Dh3cX9RUoH7fx93xp1PervGcdOMMHcrbqOCi1QdnbCFx4+R2pcYHGgBAAAACpvf8OVwseCAwmaMuMMMVLsjQ6MJzoOuXxPa87rOH7rN0T7lsaYjlT6h9ROd0TRYWuqS8cl/HErlMoml/dgzXHhj6E5MLkHQipQ1Me+HXibEm36+XfL/L8+R1VGboMo+FedDst2el0sN/6dJY22VvBf/9AFy23gJPGxwzUpAUGYnOGTEYjBC9Zj44lYvAFEY0fvvECQGTcAxiIWEIg5IA2IBjQ0sxQGwJ2GUEHhjYTuW1EISZ0uDBEalxbJolQlCGmhoprTpME1UtMlkyLEigYEwX3Wv0C+gxuQjust0FKcnTdJd6yKGtk17ImvO3TsooJnp1dSi6bLqKya3nrl42zN3pWqZnUcKKK0ls65gbnThUyyRIyrKCzq0WPDES7USoBUtk5g/pISAtY4AYIOFUv/7smTphET2X1E7ZkYidyiKXWljpFWxe0R1uYACFS7ojrTQAEYkZjGVBx0kDigiJLXSZeeHEajUEsCrE6GOA6Q4BED4HNAVJJCejAgtY2E1A6SxHMtlKNjQvGw9fSX+qZstFZtc+zUU1NOnlOgZKepI3ZaKndSVF26m7oumzaKq1++639af7//qzjKfmy1maTKoWXzhN9CEaV1IeJKRKw2GM1hkVhw7M1QvAbyamRm3owyAG7E5jK2YKYjKSbMXBz4Ch0WFFCiILJQUIaTDAVOYDcM0V3mraOBNZOtpgzhuJsIIkJGNxTCTqTodwFAHzOWFAu+q5rTvJEIAGmNMnDB4FcAxYPb10kDAcJStvaiY7z1kHGmCw2FpRMDaOkRAMoiUwzuGPQANp7uSywUBQlxVbjlx55NtJ9msuicUt0+cTd+fZfP4U8vjirbbbQM4y5PtQLNVJVfkMMO/asQ/n+VjcOVU8lTTDLo1lFkM4SnCu2LwLWl8WuWrz/ZxqB4xDnxiMUWpZyX3LFJxsSYCZb+xBlbSxgS/ZEzCCGlug8tHDDhZVpQ4Mcn60WoqaZ5///////////////////3HVWf7SbHpEAEyhEMBMwUggEASDIQFjNAKDmpqDAqBN7WJlgsPCxU1KgzLg15sBBTEKTAKACJB0syCM5ZYUIZSKiFrBw1oyLBhASsDYnmaY4o8Sn2wlpjsqZvemONKMkSKRPdeH4CLxgYNe6u59iOS6mWP+kVQq7mYD2mA8lOmG48tfx9YAZu7zMFGGpNytRDqKbr9d+nto3FAaVzEmnSaD2N3r8hkD9QThhhUjF6HOZwxIIbfCP/7smTsgAlQdVVubwABGQzKn81kABHBaV2dhAABxJvst7CwABIFljmRNxIrWi1E/UxAL1Q5jblnPxt/D9a9CIpE+WKG5A8EQRVoqsA2J2rKo1MySBI3L/jcbt40/ZZdt59dVTdukik0sly6Y1Vel05VIJVBTFWnUdG6U/BTd4zAV6VT8E//4lOLX/8k540sUNIEAAg6S48hDBNMyzYgj0FSF+mcqWL7hbXnjaM0llYqHIYBUDUP6DYLjyCgbiFjxYPRGKoGwr0LHrLmmyIwlNaREEOlKEaVNdh0HmUolWoEpEKhLNByzk0KLRcpqJr3XqSxdpc6qzE7iFxh9eQ92zJol/8QRxv3y0X8vbczvfBENUCAQgnBEM8csH1MLHmeQBABKLjGU1mGDw37bdGgdGkM/qizuP5Dj8O7TUBqUhGmrGu81UPOssQpHZycifLbpsNZO7qrfWhbdWuNk9Og9Ws7t6d9e22LVSfxrxzNOhMwseTEC3HANWMUNtg8bCr5rQFnmJRonD54/OFwjVWqCTFSRAIAOSjm1N0mxaSFaSKlrL4qpWqZ+YfY+B4mh44icKiwf2cEmODHNlSM0Zbc6dFgFMDG2Wig5F7JIUggKMQ9orlz6QzFwhz1lvnOZn6jUuqlIxWYXXn5DyXb9tmns/Yd8zn9dtubV0bdeaKMzH1PvftfaozZW/z2kYWfo/0ZNIUUGR3N1n7vnVKvUUYZGmIkAs9wXgFwlADWKWDHCqH/EG4hhcRhl2OhWNCpG8UCAaWSCayWKXQwzbxqeLAYMoFI1DISceTKTwggaXF+jXs54y8YzWNPu2OjteXhbNaUN/lRD//7skRygARtZNfjDDMyisvbHD0mclBBY2WMIHMJ9SvscYMOoOI27v/YyLJx5+W575DVn7tWU1yshetpym16Ip1DxzY+vEHmFGaTb2+nu4xBNtBWmUuIr4itVbGakQccGyO+nGEQUoUrRtQIOuzSnX2xNgjJnghFNGmgr6f+DLMkNUMIKozHEumcZLMDY3YWQY8mDiSC2Kg1reBQERRFdPNz1EhjOdBK6RVrchJFUleqpIOcRZCnCWdKuZ22n59aCXOeS1mRaRQ6UessIKJ7sCpWoOkwuuV9oVthCVxlF0QCg1WAVEwtNRrLD2VI3NskOxFbbBl0upUlmVW5ATInV7LpTyP2ZaqX30noMEnamQTtdXqmRXyly6jepGFAeZhfPzfye5Sc0Tau617d+Z63l4zKxYa10S2KXWdEdZmfluV3lzJkZl6pUtamz0IJMCg1BYycLDq0O00ktrNmYkEAFg9RNxQgogWImQrELHWkB1RxNB/DRQhoT7i2Ggx1VFHqKbC3HApVCp3R0qmPD1WaFErBjQYsS0aFHb7EZvAQFAR6gAGyByGpvQQcWZAmCbmokjqzxOEWDoxNvltdNBZvo6CyOkXCvCv+gjvg59N2Va2YR5IeBSSTQCVpV7T3Gjrq8atg7+ECNtMnkADAfwJQIEGqC9EkDqO8PRzn8H8JoL5FCUpJ5NXrQ5Cws66w+QY6lmCyKqyd0mBgwSk/hXUIWSYyz9diXd6OPG06V+4jNJoYqOTy4Op9oqvq8EL1HN3N3NysxbmlYaxcUvMfJx2Ll2f/dh3d+29m7tVbXw6fdbwM5ichTjrS8OcFQjZoVP0/+whE2v/7skSOAQRlWdhp4zbSjGta/D2GaFBhaV+nmHcKFq8sdYeNMWlCSBORjmcEvAlhTQck4QWMdoaw7hfKCilMqc7kLPyAalXO+TvWIcRJdPRGWb62MxZyqZTHSYBLg5PMeVms9p3qWF6W2szanpAtleswr06Ca0dDCKLYfQqfctrDPI+6mnTS8vFgxqIzGXKqeREjlG2hUMKzDWiDWzkE5Jl4bPdcSTtqasSQJKiBFNRdA0UWEIQM0thzYcSYiokQK85V01nlAZVlMFk0WlXV2QxokRcvH0GRgMwVxIYKBGCei8BCgMCmZRgFzFwnpPWhbIu4YGkE3hExEJDGoolFCTJdXj/nnzaGu5gstNG3UrIrO2CdMoGNCOJL8tK4CZsK4eccYwmlVSd979ohMlKNVIA4a4CuDGLGagS0H8JgDOP8gR8jANPDEsiMLKyLHZRhEKNOMMcqZJFNqa0EgVhhQWYgOJ8rJGjbUowhVpuzjSknf/Zl525ExjtErDxZR9ZVxAz64gP5carcqn/KxVmBTxz/IiUzZyIiWNeGA5HEvb+lBlDxYz/KRijHGE7ztVgJKoiABkJWCISQaFMJBG1GNKOStCG0npal8xALJLtaUyteT8ztNytBE1LE/h6byWVLkWxEaTZd9UJsYqZt8gprqtL7XvVMh5XbadY4uKNMXDoGm7dgUiHPdpo4id0RlgOqYTMY+UyzTNn+mcL9SMop9y6SQdmgCT+RUKYkT9UqzKBgsrRIICjMS/aqw9keQVSMrVTQTxBeMeUWlWUngR3bU/Ln0oGoW6EQxwTaNMiuGx0ziFqaCqbV1vFFbS7a8VflNSqW/P/7skSkgAQdXtdh5h1SgMs62WDDqlDlX1tMJHOKEymrJYSZ2dW3nqyeypcybt+S72E8SSTyE9IcpDPgmgMoy2bFCTR6PDwhlS5dzAmWMasJMjzdhzhfnYSqNIOxRydDo2pCmucDtbAiUCQAbIF2SE5eAfCiChculB9/EcofSqcKvDkmWaswsFAOZYXVmcFDYnNIUS+mxCcYVXRvTL2UD8s6NDx0cy8ftOONnU1xM4Po3adA6XPaYd47vLN9fCL8ufD+StxBe8i0puViSWNGwcUfaM42t1ltve466cz3UItoCOk1VUPCZw3vvmaqRdSkkESSJTsQHjRFbxpGoMowk+tScbg5KqjuQ/HmIOvKYNlUDxJVkvp5gCpYMUo2Ztka5SLVszh8wRotJXLNzEWxleZeD3o03cjYE6kXIUbMnp8S9nF/OTXkTGuvuR2KdzB0peyKc9iXOHMkhmxvQlMZwqGhwmWcMM7hesn2lGSACVSqVkaCVFcteX0RzZjRK9htlCgDSXQmGkRGrlI4vDVmkzq9m7FHqnyr3elBI0QShA0tQhDhaOpUWTsawdVJDrpHFI+OTGyJTIlTrJYgsaRXRSuxUl1dgVmU1Q2DhTPwbnC5dcG6Q83UjyfrklctpGpEtzaxDmTC5hvJNHsDwIYISUSFtFFF2GE1jCMvAgsg2g2hNS2zYm1paV6DqjXF/WsYFnIk0G1cnRRp+UYMja09GEkXY3ps6zyvOJuXlag7Wed5LyYR8zCFO5lVYlJRzY4IcHtlRhzLLWuDLtidynOrzMjknEhfSY27MkU+Gdh9RQ0DEwGFUU0lb79vXtgCy6GgCCZBwP/7skTDgAPiWNhrBhzQgwuK2mBmvk/5ZV/sGHNKBKkraYSN2agaUIQYmGismCucEgbi3Ry1MnUg2IOw24mXE4QBI04wq0M4qhiRoKhCFpqJUkoogUdSjCpRRwcTsEMgYQyT44R6dNZ5GqMIreCNkU7i9kUz0EA7rYVcivLP8mPvoHCjVCYUq6wEYIBBZwdBFlytRkPwUF2yvLkNJ+pVAcUQAAYQEB3hY5Is0QBQUR24hZNtKxltKny49Rmk7CcYEdp/lmz1vHAuYFQoq4RXpZojjKyk1liIWWJjNJGFLLNlOBy2LnDKrDz3PsyBsINUNviWP5VZllTpqar14KlDMKxLp78mZVuepp1VP+PdPvoovfDzu+Nlmb42142DKymMpJaHNP76pvOL/t2e2XpAoYQMgAFQqLBx0ZAcE2MCq0+GlkB2tKUsQh1WBgTwUEan3EYyDKKFnoi0qQL1Z62jzg9Jl6r0UT6Qbz0KM+rlHKujCDzWWyFxoeoi9QTa4ZJqp3xlIFZm5jMu/iOvCfbZ3Q673Jtjv+/fu6eNaG7aL35jdtAx97O9Ziphvc7p8SueXn3dT/Nu2gHWwI9QKJAIcJCAoyLJxEE1GOJLKJJEOKkkj+wIuwrileVi9LBTg1Z6K5WM85Ld7B3/ux1MDCSWhNJ0eA203k6izwPbkQgcgauimTjtclK2vvMaFpO517tvFIFFvBjLzSsTnT4TalxUzay0Ju1M9/VpcqOphYLkEOMh3eWi3ZkUecg+r6SKQwwqJ6dbHpI0qtR71wpUBUgIgAsYWbQmeAuM+JMR0SoMWbVdBQ9oVK2r0NBYvE6SCSfgyyx95P/7skTqgAR6YVS7CTSyiwwaqmGGaFJRgVVMGRdKLq0qZYYZ6Q4yKC7FEUVWVKits9t0/egtcn8yWeWrHKwvm3jMdLbbltZ3QxG6w5sMNTV8m0+a7pXWZ8OabLZr83Ntts1t9fH+8zJ/xH4wfCcUpnJs5+eMqT9rMbmQzGEJZ+JmF5rkjON+usoBMAACIERiyQ8UVKBz5foSEOklk3ZBWQJvua3c8AKFTNALGRWEk4Pz9ICgzsoLDzTh7NGjS9F9X6wt/0wZi1Mt/NLdW4HGiCzBX+GHFGklhJJzpB5uMPOJp0YbJR40bcDpUwaKWozKs+DXD66FarS0u1NPlh6lDW3Ml+0SYNpcae1LD7WnJJxOxQvVFtaRJ8oRf6QCCUgAAkyTNhQuOMkKKQ4gPK+oFDmpiQdKRVVMFf0LZqxKWwZG3in04p+ZPySShseIiOcCU4roxQ5pZucTWfcvSLr803Si02ykaxxwM4i+sYZTjS4ThKFkCae0fdGPPaTEqNXCbWMMJ8svuknJ3Bm2Mbned7hLMd8NIJMZTp/GzzWzpVkn3S8yapM5MJ57Cc8HVL4PwDPcEvGCAIS0GGIBTDnbMsQK9jg8qUTgUxQH4XzZO6CLCjGZsH+d5/KVwjK5HBSPGMqtDlrO1wHq1mJggMGUaSkmBFCDqJG67gZENhEtAfMwNhggqLGLmOYuuT3SXVWOVCSMw2IGwRsRSof6xQbeBd3IXFb19bbjNjz91ytZojGr7NXFznyaeV4vDkJeJYt5kIEHJHx6cwrznMFTgUJFU+oLRoTLcZbTy1mIxeLbijM76WVHUgqozOEQ+TMYni0YmyJyrf/7skT1gRSWXtOzTENwmavaeWmGmBFlaUysvMsCTa3plZSiuZzSyTGU+L5uLQYZJYQkH4pzN9NT2QSuhRa6E9W3PGsbXcxG8nV05mpum0onGS4eOVDdqazP6J76aTjebkXS3PVSmfYxVVpIpNnJ4cuXnq8oNqQIAkNrGFmhWFmhP4P/+QQACICgMOgcJmMFx2wcYkSpJrwZOs1Ca84oHwqG7akUoHkutadR6ks6/AmjAcdAoJYkQnbVKjzEYHUtSIiXzxgXqZi41iWSFazUXNtx5xqN8nb1KLb7KltrlY5Bt3gaA0TUpTVDEVJhorTYpSo9eIV1MWZmFLx/MnTJCDfetlngkWrUxh+kxjA6ZGPbxjLoTqTZJZNIAEAAgARAwawJweCaKeRoGBh9cLgMTKgKY7B0wH3vPo5OMBwxRtkYq9tFVfhMptKVwpjlMViZrGdaOMNvZLag2RrGYe+Nrr86wzDySzeNP7uAtOw8kGxylNkH1lD8ixr9uhFGLRcjzozzlMXXf1MtX6H/eV67pq+fdfDqyrvPm9nn8oJR94Or598EixBJY2XGXUgCLBSiCQoKPDRxZ0EAHbyDBlJv+OGQMwScYQPB6rqgf15oNdtXayFObMcieT4y2KM7vy+GHIl0iwgAvg8guqG7IokOcmch+gA0eknOTqv5VHz5qZNUciEqax5Jih412aHOiywQrjsBnWvpXjjXtcsMk4G/gvw6zjMWFPjkWeR7CxTAwpYYEP2CPoI+FXRjRVt7CJAAjKGyKnISAJuIwIXzAwxBRgSLBxAWLkKWonLQfHBV8DyGLyBrSzGgP7FIJVvXDLiWQaaYcv/7smT3gASlXtKraUTgkguqWWUmphIte09MmHcKPKgo1aSOsHjYMSSghmclXK0be3JGspJshcRv7BCRsLUpckYsnKSRFnR4viTFYTlW6QSKMwTVbqOe6k4/4N1UJELookChWKnDyXWvnIPtpaEPKBRxYUIomVnZGIEP0/QqQAAwsrBAcYkTmwgp5a0YWeEQim+ECb+Bj1kjp11v1BqPi3eU6PjHRwBQPkeYPIX1hbX47hp6Ja+eq0462eM5MdhEPvsV6U1OA0xEJwlQ1YWYaqcFEDqxEQS06rWUiHEUOdKuermeCqPaG2/tSb2WIt8HeiEqxXfnpRLfUN8sz9p+3L//z/z19m75ueqr2iJnNLyQ7Uk1KX7OSStxxkF0TeICAAAdRo7HTLFOhYs8YY4cQzlJiNCBNENxlV24tTlqsVJK1CZ56muSGVz0GkoeVSvPfSymIyiDE0P0izSU3ZCHWfhZyQibTXqaiWzGJYJI6XhkjnHCKPZ0qGCQfNUXkES8W3sKHMM4m4GReLVctE1Ex0SsVDfQ5DYip+k5be4n/T2PM5URvs2tlOpkDnSbbnAcAxEcIZCobMfDs4MRCEig6yVGhWTCq0lmgJABokIYBCDFYn+kkfZ0IjCJK8zyROa9DhsGDauFdw+sVnBE28JemYCLbiagrbmR++ihPUGu1zHTN5LVp9NeCAdm1TZyaq4PMpxYz3IZCl/2Rda7Vm52FEu+i2D7PRTqt788+WzA2mvjtKZWOn9RCmFIuzqHVPqsRTVd9ZtbNn77NXIuTW0ll153t3oM4AIKTQAACjvmkWmjDmKHmGDgyCKhX1AoJgxIATIdWP/7sGT7DAUHYNGTeEpykOvKRmTIthS9Y0IuZYXKFS0paaSOiMvFK3BhiHWYPNEWlP5M0N+42q9n5NkywKKCpR0A0NrJ2VfFKA6ieviwpFDwoDNBc1SUxgyI2Mykiw+5XOAmdCcf3hbp/TMrZ9IuG9lzzpwcyN16xe9f+HwtFQdD4TgxAsmDryRrRzcAAHCisDhFDsaeQHJVJhxmLBVMSpBZ9EIFBKAdHtGN00fIfZLAS6VKSqHKFYLajE/GmkuYEXqkJO46XDYpgglrEBOgPUsYyaAVBnNCQohyjj24o/bejf9ADUteQPmgKvnMqj5RqTPUNZw8ofz69n0+vjU/AB3MGV2Nh8V/uJOVyok6VoXrJ7BocBZ6hQdDG5ALl4dlNWFGxYXc1KNQBDQMkokupvniogmBnI7AYCMcNDAYZL1rzJ8G0SHDYS1nWkm3LpcR9b49n12Z6+q0RGMYQEUjclA67A1F7Iuztv6/hoEa0NuivcUXa/QasSZfNuTJH+nDzIj/+u3ney68zcs4KImOPFuXl/+EaBAb5BpahHvUATAsUgUQTDwWMBDoJQwWEhEkqqa9aHIxBR5IAKIRJcNxVpFm17wU4ysxAEojcj0prNzmZsI10InxQFwSDtYZCzoLhkzTBqepoTcEydEz4Cd2olEWZEGGNtBnxEm6Eaf0b3ZN+11WJ9I/u2nLN1Ffkknv1ClSp2GajyrQT3JIN1NN/Te3D9lF/4f5kf5TzzzZkbcdaMX4TVluLPncWjqDuqb/QEAgAAAImCpsFcRC5MMNBQMEzhAAh8upGQcoWg8qp2BK5kCz6OAFLptRqJPNZ1BCqzQJ//uyZPOOBOVe0RNpHWB1Ssp6YeNaFFGDRG5lJco5rajpow8gBUtakmrMR+1drc1USne2SJLckmKp3ObNvMSZa9iioPP2C7kpPIuPFL5SnI0tyanmZooxukaPaimnDMthCm5UKV09/Lcq0aEvO5ScSmXmB4cIx4yB2nguJlmuLaUAxR+B16DUo1rNO81DF2QeGG6muBaWABcPoBX0ugVdRsxJD5ORURXT3FHEUpe2VwpEm6mGntL6LTiRmcgKPqRaZhVfmUosKiI+SHQ9PecrlMMJyKYqE6XZKji3nkhVcqqUD/pSHgW3j1HSSCgCXMPOJ5Zq/Kx5H+trUHXKG3Zi+ZiyciRXrDFvZi6Z1ZDPL77CavPV2H5pY5i2p1acbh3aRTPRTNF54HC8TvE3LVuBhCiCS6Qvg7AjyB95hDGeCJExxp8UUk2FBEqq4NmrKopAdPebtqD5datrLgS89jp8jcri12mOZ8pKztJo0DcCscLAahlaKdpOgMpUIKlIFBRbK5ZcQmz35A/z1K/Yx/mfV/6k9FvTIbcagPunb9p5SneK4clpnFYBlWi6XqwDDBADmSLHswmfDmQzMEDEwYAX+MJmYu2BToHnChN4to2UyFDAShyWvJ6NgKw27ECvc5DL0mHnx241JIGiQKjOEagjnIuDLchXHcX3T/YLeJC5qJwy6eLjjM5jjsEQ2u1b9hdIW95vEE1kEYQNfIJtGq+34PU/P264B+7Umznaad4yntKsb4Mb4Ju2VzyD4z82575tPrcvcqHyt+9P/GTCz9IgoAQcZimgHGjmGIUAkuYCylogUmK2AED1FHURkRSfWMpmRuKt//uyZPmOBXJZz4t4YnB9qvpXZMOyVEGBQE5hKYIJmGiZpJqJciY4Cl7H5JG4yMA3zrCMS4Sm1VpqC0LcvAEVT073jFQf90k84Tbp4+nWg9W0QnrkEq0Io+GkrMtXDvBYSJgR15kWr6Rsvrv/KT0ArTV+FE3v07kGOSr5w7tb/7rvVQEAgBgSxQODmklCTPBY5tNGR8vGOBg3FnyKkQRqbC0tqrQSI2dj78M3ghj9+Jyas0Tr7i/wD9jMtEXuKBlqCNOVqkuRkPkj6FB1jh4rWJdrfrULWFF9SlNtBK7yK3TR7dbKHRrIPqFXatrN6jHgqvvkl/0a+3bDqtd9enVCLDV6o+UDUqXaJDd8uiYqd9cnBdbCwIR89U/GDO/t0iGWhZEALIXpjmBlIAEHqzAI4cTMMZ47ZngsOSggJerztkXS+cbbyWpvO/Cp27I2cNSigzVkSEglhgjmnOUW72HQWif7r1G1K+lSwkqWsXDe5u213vhJWde9niNLxTyVVl7HKhk/ai+xnSc1GIMfVK+T8J/dq0be9GnLspMddGX2aZRldVRiBcaPS9EAYYe2gXqKjFptqv6OZ1/lfELAIi4kIAsyJuAIKmrjnX5GAHBAZH8xARKlL9+QAARSepjaGjM2+68r+pDlBqG2No4AsKWz+TiP3WTMXbkZ8aEKDctHl+JbaSY2eFELiuX7QqXbJNHBrWNtxVrwxnxRVvMCTOWWZjuQfyeU2mG/TwKuXu8ugNoE7PPy8opnZ5jukrszZJxubhc92NU6Ah+UWh36p51sTmhBQgAAzDGIQGDCEcGEiGEIwKrVSwWFBq/HhQSwNKYgmzLH//uyZPiABPpgUkt5SXCaK/oyawkuUq15SS0k04IorOjZoyKY0eG0oou+LaqaKoCglq6sjAJdWDGYzuexInb3y/DJ3WnjM1gyfFQlQTsqiKFDpzoIfLkxw/rR53JqC6m3Vrou7fgOrdFbzsdAnU+alq1b1Ht2KvUEPcuHI5hnPpFRGIs5cnDg8pz30dYUGADAWCpgwkjMgIj7BcVMAAFDgCZGGKVJMKnBQcqeIsJYoyhkk06jpKPqF6mXvd143FUirOgeETREyBBdOJ9FKXa3ZI6tMSAP9mgTTYFYoiPG92y9NeiFeEUSJ2qkjcZFk5LC9T6wWM5mTyik2LTMF4WTz1M4tnclHqmV/W798IauRDHt9YR3tkQ3GBhrLPdhsNvAaqikLtYCWh+BQACnxAAhzEwWAyMBwhFIQOZwMWgR4gIIydR5NR96dpaGzVn+lUrVmZfYo3cokAyLDHpVbl9PTZVLV+d/n2zoEO7DjszWHazufQEAGJ4UPx6BO5nEgVhwpHZOdE4Ul31b8j5A1E2m/7luWSQqamWhlbL6AHpSszLHMtAoxPDhmzn3unXs2Y2VEIAgBDBsO+AEAY8YY+yZU+TFExTFH6dGpQwDAEWmSNVUEZa7MFNalLGUW8njsQ8xm3PvZ3r7UWcUiUmnYXJ96PcuRiPQCcKe3hViL1tsZktC2WJ9I54sDSpkAp5Sz+5r+RF/zMf3PcOltFn60XMVKfqksdc187a8IV4Ln163JiPqO70j8/sp2DkJQPP5V6fzwkvRGGYyNAwAAACGqCox2FYKlmdHFS+CAQCZRekMyfCAiCNDBW51XJHgkDuIi1Sp3J1v//uyZPOABOpa0StpRXCGy/pJZGbMEtl9RM0k1sJHLGghpKKQlBFiUioletwihSrkxVaIn2FjtqFHpTPJRnMC1jaeT13JDkNOTJpy+XYrlEj1Gq5rW7TNyr5pkOgtwPpdBCkqYZXUkkfq9c2qQ6Pck6sVS6HFcStzclXBIrWdPQ8V7zBjDJBJXyL6AEAAAAAAGIiSHJgxALjOoSOLhQKEkyKMzBggKomTVCASlKYNCFVK9P1FSFz79K3sIQ/KAni3WDH1dmH3obTCZaPLdFSgbY5UZXfqZnLItYwiQHcqSTCY7N2xTuNCJljYEQr+hFp6OfKg69kp84lA7wTiex6//2ljvw9INtP3OvHNPv6k+9B975/5JenfO6W93ftpiuOGtz0QbPabW1xvzPyttYJgGAAgEcYxaCOObzHBwqipiwIZmDKNoZOcZpBF10BYpfF02wI+v0sd0YfWQpNjr8xWcGEs7du1LLUAU1ULmDGxa74jPFoacwSg0IjEa2aWNUWq14uJrraKs4qa1L+huJsnun/Gnw753akr345m7m62zuFXHndxi99FaV3RMQ2oP8F30TEOGnASH7/kAgECBJJKoodgJIMAIjUks5RSMSJh4ThkKhq8kjlzGDAiXSuGirMIg9v5tlTD2Eox73FqSORpqAZzQJhbufn9pdmSMc2JgRktpdqrEyu9Zv7Ny8qXJ3dknU67oQuLXuXa23R/ifdh1yHI2g3yqNTT7wwcsjPsvpXdJzRNmsYaylJR2bZHsqREIi5yA8sVTIJHMo6GlgMCAEIABcLLzkkRVCcFKOtgDCBgZpzrtJHiwkAEYdEUvUqXQIox//uyZPSABSRi0GOJNbCKaPn4bwY+UqV5RU2ktYICLKglp42oC4g4lAPYZxHKdqP4lBFoNFq2x/qit6LLjWla0YMYVIwBSHpIEvm0jEvRKGkLJsIIOlYzzHY/KmjGZ50plOMXBKiRJkpIxs/y0+nDPv5/p5ZyHPz+M/0SMITdProCAAAQCSlREuhx4ZKIC1McIfhQ4DCVNYCDiVYqElwTDSJSkuWo6iaXyaBVglwRkBKAqZzl0pmnSp4f+44GrzxLbXKBoMMsHpt0yHnawTFdLqMfqpSpCaNuropxVefxUVN7QwrXkal01VsyCRsDSlbNUzUaVRMtweLfaRjWerG98/bW9yQRUdtSwOuIT9oiLSWCQLj6LYWVPgn83yj3dhAAMISSSSqOKn76Daj/gMiUEggAJyW6vwbgKm66BgZA1QNZaiVuNpe24YV81G3hQKJV/FO1HOIGBWbtBFlyhxSXZkxAwBYCMVFgg0YiEsBAAszbJA1LpymU6zxYvR3Y9WbIE/qUxTH/3+Haf/zlL70+e/9+5fsY5A2Dx4UHtWhVhHWAJhZ9mGAmFRObOiR59ZmO0qY4AJhUBGRS+DA8OC4w2Fj24IYAQwSGmcyxcIHaanQpkICSt2BV0oPsFl6PSJyLVJNI7MtgRjOSrb2MEPW+sIlEMtylVx+mBSygJSguWHkWkcbPHyU1YEN1TdMF4MNgUiaTHYTQPI+qT0d3jKDmm0fyyP7FlbaLWykWbzY6u4y1DLK8mxednEfUR/29H0+897Jdjil1bmXyvNT1oN+s3tH2Ufi+6g9vb1/z8efBc/WHC/D2gQACDEMTr2T2bDgGR0IW//uyZPmEhPVZUFNpRcKBiuoaZSOkGIV5NC5li9oWrSeNoZcgHJixo0MaMpUac4mIDQ6GaXUy3hMhZsyxAJKW5JFN7OS2NT7ZoHlv9p72UxOQ9ST85zARghwSqAiYlJBBToCDHR4f0fJBI7xEqjXiacFmpJa4hTzNUsdUreqo+1c27s266MZld72o+71l7TgRTqwuKpjyyBVItxsAQIlIphgkKikrdwEiZGZ4wGEiZ5RecWsaOkehSBUEkV4t1TpIgHCpGctZWmnlhDVNW5Wb0JN4AcocIQWFIntIYEOf+NOJL6UALcuUIVZxqvLJMdIkbqeD/UMYxyWDr5+e6n+o0RAhxL6ZMPJ91uIK+ZV6FH+nXIjpzFfLG8jpq5+lvhWrGsZ8XuZFHKGnTG0ktzU3A6kh+wACERKCadWwD9kJBLYPOjYKrnp19yU8Pto0lvWxtUZzyGnboJcwazS2brRbsiKYsUceCoqRc3DY8Mr3k0UkXkWNmafPR9tK1BiCIVOklz6uqFZ2Q4eJAuI1gvbnlsvWMADDZEMPj23YZew/UUdIrIABCVMbDNTAwKSTEZ8OLC8hHAG+TBPPQRJBlhsluGRIpFJ7qYhwslZAqRjCCMeCpW5KPKpu8vpkY6D+OQYEsAh4JhgPYEyMOY/ycFgwMORkgDEGPpV8lgwfO22ixVui9thSjVetdx9IueWw+S782UTd/iYTNorfn6R7OrGPmKJb7aFO09IxRg/X/kcUUuNXzp7bp4slQ51O347o7fux5LOzSuvGTI/vL/TH7WSh0ruomtbaiNm+kQsDpIwAAjMKhA4oPvFsR50eSfhOJpiAcRkA//uyZOwAhMBhUmspRVpuxvo6YMKmFy2DPG5lhconq+jpliIRABTFeSk4YchQt8n4aHAwIAOHc7OyYMT8/H5Io49FYKxcOxYFhtmEEChBmmx6Ke5buWZN28dwLn11VIjn3Md1KcI7u48XLPPlZe+J5n54gxKRK93fn+X++NhhFPaWrv+WfLaDal3jD8eh6dcDq61jT7rbAABgNAFJQOphx1Vc/5081c4o9VoCRkYAzpQ3gomsEkQOUDwBc5jAodLRjlIqQEZDvl0oCgkOev+AkPk0Y+zSTtxhmNs7HVCHJehLcVUbAgYUicNg9DKJI6hMZFiljLJIpSbrsh3uIMW10Z8teTLyzMnF1l0JeVXORCVHw8sWeSHQks3KxKW/x6syFMn6CYyRPIizSVxecoqSfavKFEPRvZRpz3U6iZgRbSWG/T/adyyiZfh3M5ttsTBhQriWvvKw0v7Z+9eF+nTW3Tv78tjyQAABDASkxlcML+zTSQIGDDgM7MbMRUDARcw5NAswSn5ixKFRMwcEIhMdAy8DdQsQ6GLxJ9s7JgAI7EWjQ+gJRGTSL1NKceUGCYyYOJXBqjCUNIrEquiunU4sbRDVgaLDabhcpR+7KZW8tJZoXbWJT0zO3m28DJmWxqkm9VZfD04JxdkTBhWlSEjMHCElajwBWRoB4mbqRrekk+zWMzWaJ1aN0gtVDHU05xhi23N863w+3Odwrc1QUMXTLOKCjLlFUjI0QBw0GFRSPo3wsngdIMY1ZBuXkvC0wiGBAAAAi2CeYK5GeJGf0G/gDBUUFKyAFSmWY0WRXkXgINDB8cCCCQa9XAAw0kCLRZu8Sqyk//uyZO6ARnRm0VNYY+LarMnjbwl+VWmLSS0ZPQJkLyjZvCFw52PL4Z0nlDvuFUus/fVtrlLx6KPdh4YrIealVNeqxSV8+rTYaaNy7hTHXz4lkmR4gD/foZ2gK7X2+3DFOUptIdtPP7moerHjXNRzOO4ZhBmtBaOPQyXFT8s4xvT2LMCVxJQ5J1km0w0Np4mMfpS8PgvWxrcvr1VBAAAxhwsa7MmszYGNSgLLBULBj90wGODOFMKByFYMopECDYiiS1xIYjnAdJDI0Bf8scqKNbX8vmKw7Lbu2HPJ9WdllHMhOE6StsSJhwlc3HVAjUckErTTtFKzqeNH41m4R9c++I1tXsuq9F+Zr5MtYbvh+Ypeqfxh9YppZZUVYubPAfCZhpz+w9JQShRiRDs3g2+ChtB9F/HKEAAC0k4cxcHNCB0FpYtcMUGApw0CNePIhsBnBC0ciiYTpiQoQJGmZF7lb6Js9K3R1qWmUcVKBtqKadiERhRe8JuwcKTn6Wzri1+9kzyfKkYwtvMsNywl7awWyPTaYnJfMWnn8UDflibvi9e2M29n0yiufPuYtjqxi9lLPShJvjjNqzVdCSck2Gry5JQuaF650Gm3EbLW+W70gVKhtaKdJMiCMabkkbWZsAUhBx9RfFIILKUk19sTAoJeVTaNy6XU79vquOatXHlvYwquEiM14YqIz01dd4FsfBWrj+vktdmRtD5rG6vJf1X2iF3s1ZB0Wx01QS6OWSx+C7KYaZlrVlKj0Nox8nrqq7276O1HEiChgzHJ1K1QT6L5IAUDPZRTnCcyVkNBVjoEMwsghJhgQZulGbhoJAjCRUQppZEr//uyZJ8EBPtd0ztZSXB7K+r9YSKbFR19RE3lLUn3ruqdkxZwKEOIO4PuFYV0jHZLMJbrjok/FJRyPEoxkitNhHFs28ZRRLNltPjBemSdAbh9keaTBk1lyVboUrqpFCWXpZp9rE5iXRXlQby3oc6y2/0iP+04+5Tz3rXq6/ihr7HPJ2Rqdw/rfWul5zz1GWbd+7Q36NQz+CkzoYleGSGV/E9UTV+Rkyvav4IAJx6yYV7QbCpxeJoRCeg9efVn5iirma8i+6D61Y9MQG213GSTstw4FCwolTMzlzpVIsdAFuJZ37AaRdqfDaO8slvdt/bH7FxZUF5lpZkt5tlQvQ6PdEiKDrkO6GL95VeZm0Hv3oxakFnupEK4rUcuEg6VkFQUujIQWYc22ioAaLNrVEGC0wMUgdsDipPMFkcwEIV8kCBKBgb4OYEwOtzoNTYi0OZplJtVy0HREI4HE0EqcUwOglLoaYQnYLChYI/+S7IeoYDiTL45drw494uDoZEAXkXLEUUGieR0xTYuqIF7vVLaaFy6KE21MLzMh6Q7zGpAjnY0autW+TUrL3Ej+/mfkZ7LXpNw575FNcLddryp/WP+MQ2sXsWtSRNSEGxKc18oGAABKba3loBLQrYBXhhdhddCy034IQy1+GUNZyk8HbbqxTBsHoI6Lkh9GROyfsajCV500OR2Of/F0rTY3X6n+2D0pqYx96cqgALDTODzHqrwOUHzeV7/rQGZvEa/3YH1/hv0N5bVXlP7X2Z6uksY75QLYAAWfzwm7jhkZea7jnTchjAeYiVhBucNlGBKhjokbAXmF/pgSYYgkCIhNeQzWA0uKYRI//uyZKWMRS1a0JOaQnJyx1qqYSOMVrV7Ok3lD4F5kWpdl5S4KfHxUri/V4gIRHcdbQIGGhBbxIKYHTHNjCCFIMmTfOd63B6c3Qyf2Y3IXbvTsfbSNWcezcmycGm80RRo1rF7mjymskeRjBUZqND0VyaqtRTjIL5pr9hN71VBWxmjf98Q69o3kDzoKW+4VJyq7keOsY9xlPIoHzZwrQ7tfJEWXhO/cqoQAKuXdnRzlHTsFxEUCqcNIuhQj/BGUGLcJEEqUq6QMCQhkNdoc5u7xTsfM4w8tQHHMq8cu+mtitPke4CioNHh72Jrb82QO7KdASPUyz1UkVAY8RZSpI1tVIaKirqzNRBAANyXmYTpExmNs5qj4bEWGCDzKR4CP+QvuZ5o+UZioOmMI0hHBXIbIps2USMQ2fKNSqIRuDo+0gaKnH4xcOE0geAJg0DvYaYPFgcCNY4c8aGmqyRZ4CSpxcURxoih6+JRARxDHHu4hfU0lbNO59tMtfuu5NzMr2eUvDfwPu0q/7vl35qOZuppq9JobM/JbZ4eDqzhjSt2i3F+qfU6sABRy8CPDgiDf8D6DTGoS04iVXiOBEIRXMqRFEdNK1nmRSYO7bYAx2KP6upi9Ji6aqUOWBAqOMFEwxp6yc2uxSGHK/ibRlnS2l7Tx8AiRjVigUFUjhNEqaDfrU1QUAQjpRdpqm2vPC13HvOC7R51RTdUASVJeYguRrwZbMNDPPPSMMUSLRmM5jzwdPBCgwcU0acwoQlWeAAg8paIHNBg0/l6X4eyusZcEDGSbiuaqNNyDLqTEU78zHgugdnHYsQczn0vliMgdGn2M0v0vy1t//uyZLaAxPRaUbt5QfJxZFpDaysuEyl7RG1hDUG0EWkNpg5QAhHXw/rvzp+MOYSEteMVpoeO1HP0o+Jies9Yxhl6b3Vj6yoX4r4LWOWxp93zL5hc7QIw/oz5OpyYOumEAEpuXiNkAsQQVIlAGTEicQG13JFJ7HPAQGnUHBQwe02BiIE3hCCSCh6Vq+aFOtFkQggH0KUDl3QnqpG1PXTilC0XkChfqpx+lMYBB0koXeIUNHKJSWsVat3bX1NevucejXja2LU3IuEhXnHU9qoAFtycxWNNrETLj0XDzcVYwAlGRZAAY4+FgFABpgnm9IZpSRJIiHaG0IrcoctghQbkUA24DizRWqwGogi3B+DsQu/dYErmk+rTyt8Dotlpuxx027OWJakVZWohF4U8uvKK51qkbbT1y5Ri0o1+pX/YU8lv7tbPHW/P7qWChDfz/MvKbJN/ln6svUI30vfuvSUpf2jlVx6VNmk6Qk6sLSPSrIKFbNBZ9v8KBISdeHTwx0aMlgwdsCSCCgwQhidasIIAzGh1/xABjgQwhs6fblOHSID31nVftCh7KJO20GGgynhdlMb6083EKMlnJadbOdXXj+45q/3mOq3fTo3f1X/6cvKJouOyCNjPv+/nbCK326AACk5TMjsnLyQAM2YTrp0DFBiISgNNnFTHwISNASSAZSNRDC/Yzs7UMeUJKZRpyAdoBCcF9DqiEDprXbc6tTiwoCQUUlkYXkge3Bgk5nHOV26V6POrEbGUpezDmsM53Vuvb4QR5pZVUaqpinUUCWvGF+nfDF5Q+vdkmyKeauyKPFOesoTbvWi2iVJbOkyRT1T8ji2I//uyZNKMhUhe0Jt5SnJnyJozbSKkFTlzPm3hDcGkkWldp6FgEsoNhJfHGQomyCRQRHVjXiaUSY5SqABEkc44qNaMNvDM2PTBEJQkHFvHSaAIEjNDqLGHlQqtAtySBNF8SRxnmmIKgKlcnRYbcQz5B1zCQ/uM8qtbiO2bnT+fswChoiPkxIwLpUDsgWselRlSaVilnumcaO9TaOpyxBLjhc04vQACFJRmDNjAzCUQz86MOGDAxAlFQqEmNL6dBEZgYJMUHlMVvEoaTBIYXRCFICkJEDkwD1uMPEAJEGZuM3lmo48OVmyStm0cRhpLMxsJWepNYXbMKWOnNh5Ky0YCAek9+FfZzsLCxQvZj9IeUyfn8ODxZSi8cw/aPCCbUWMqr7heA4WGQAAoxi6wbJ43QImJnzmGcNN1ZPAb9NtOZQc7bT4chhiDD4Gm2Bs7efGqu+C6ylDedllSpOKkilK7SYimk5HIc2+7lgk6F9Kre4S6JduVrnl1AsI1x/IvEGuU9jOtDn6xyxzm3Ll/Qt/lAgAAFOTkNg3bIzTs1pQDXgCJEMciqiAGoSDH7/jgUcAu+zZT9FG0OpgRLKXoYnTwjimyi7/vKLlxTBtHikjuF8wrPNYzeObTk0fmr9/cfyw9gPssYpemtmZm+dqxAqw62W5zjjR7A+JaNtuFGRCgX3NuZDQU+csjlFbyDknhn+zFsBuQJUybCaexi/nWxnocFFiDgfCoORAM79Ppw/04pFYkz2aHkReP1L0UhZk3kLnOdejfAdwjaFuZ+CEJ0dhA1IZZK0cA+w00QgBD04PtRk7HArS5zIpCIqvOcyKREQdCgQxW//uyZOgMB2Jn0RtsxkDmjRonaY+qHXWjTmy/E8NINCs1h+K8PVBUIhpy8vKHzjJxkBA86XtJnwpEsG9qzi/TGm8Yy7q/pbEXHdeIvbrNRi2tjegTwxdc7wxK+Qsjhs23xTH1iBX6vmFrDVExjTmxvBPzRWIzefism5UF+IZk9w50Ouul9qm8E/DR66P3yw7mgzQrpUwtP04qXLDItnrq5Yi4YNJZ2Dju5QKpu7P5vun2xFV9I9A0N+KCEJ0LWopA97buXQp7sGfiQv47i/ItB72uXGk3GAMNU7i7X1kLfYLInmQltMSVEKhLKmFK1UTs1yTLYR5YIz22OgGsJ8Pc2Jy5JOUkvbvEdchFSTzkIgC3qoAAAICAUmk5SBAhIrAoO5i0SRME1qBfVaCJiXQmVtnw2yzVBK8Ofeq2+xtbee0De6qj/OINZ90zj1k3mXWb2dT0ilsDqmXUdme3ipxUsbcVh/wL0UCqa388fKcy0tOaq6O+XCoT2NuDc/aqIzMrCyuWrsgYawoS9GQS5yybqjZCqgoayK1bfpedcj0DjfRBhjcey1w1/SW3IlV1BqOxHA4qScPQhuL/VWUrFbtGIpHW2SgkUPNVdlvM6CBJFp/IahiB85FIZ7O5Ecvzvf9y7d32rioUJCVGCAAE0SMZcwXHMIpEWCHCDg1jM4TML4O6xMzzRJI+bTESq7PG6+5hpQoKCaJrOLNqHMhAphL9Tk5csked56unF253mMrWFOQWlO3/bpWEJEUYdcPq+UDWrJVnUJ0VHaRZckVflWJVW9YkId6uz1NrGpOnHyxuUptv3dVxKE8nCclljX2ct245GLIv//uyZEcABLdaVNMvS1B66+rdYYV4Eel5V6w9DwH+LupdlhWwC14ukmJkXTvYAjjbEpKigAyooVAo0gOYawBO1V6N6X664zQu0kDC3HVgO1oF7tQxPSd0P3bOsGNcnccG0VUjzBpmczCONnSUVeLBIM2/dQkBRWaZprkKR6VnvVtT9G2JOi1pVkMj1Q2hqJay603MPo7aoyFIVoKgqhjGuKpUYdh9LaYwRkFFkW1EAhqGC4jLMwCMB0IGwO2W5irwv2iUxFuD01HDQ2Ask6PmL4EY1dQW5j8IwHLa4eL6eB1wqLqUD4eZbhtpj65K2GXNA6G65b/E/MtX1PsUPvevw5qvn1NN4GHfLRAso+WHXcCtNsrzD1ciKPbqPfalueBhPknLUzTrICyj1Fgbcy42RpB8gwRAe2ojLrAAAJLESjBRBCxFNUyYhEVILqeEDKoOK1NamFrSYNop1FMCZIrOSyyuHe8uHyANBZdcLbt7Xo522tr5RZ1EQgLimrarh07bnQwDN2N0QXYtVXnxpXzIYymHUctB6uhLTILOgtWjGqMGtMZzEYTHKPVoiDlLcFHKa0o9hrboygSJwokAihgakmWFgRGq8y2nVFGrKX0eDlC8MEzVKQZiTBJSenbftjeKXZ6yoXTCbiYUz9BIsO21D9jSI55msVQ+C7z33d4MdLBK8xkXSazjPBediS/nQT8bOfhhudJ8bf+cR6ikX+EEtmXns5eckck8vrUh+1u2zW5skd7r9XzczUUeWCkfJEf3+qEoKyNO0EAwE3EgASGItAcBCJ6YhecQRJNXXiam2Z/20gR02VQ7u+rVWtkxGgRD02gZ//uyZF4ABHxc07svMvB+Syp6ZSOMUn19Rs09C4IHLWjJpiIYaTBKaxZaIPBuFKMK5PLzOxT5IZMJCFHfiiBczcbnV/c2wZ61ujFoYC2Tpwn+//mDK9UinS5M9zKTIqbH0Q3NSuC4yNxjLgPjH8FVKy4YbJb7cACSoBASUcUIWZDpxvRSY7Ly+BlxZb5RNXoDWA9iTDLNkIlQpAOosijW/CVgC41so/1VmVJwcs5+qAaJlWxLZUDk4e8shbmifDuCYE8+MOEaeh9bFPUUf+wffEQy3eU71c1+MEXsleAU0I9UxXqs72Pxpq1A80dIqP+tZWYSaV7oitmD4yQ4EfsWYafyPTgRh9z13MLqgRVdDS03Qs0QRDVqJg6gskqPuiipN+FwNPhmAkg5zJTWhGlYgNpQiDo9Egs2ZEhyBdRW0M924qoSCMU2HLcWjPV1KuYIwdVK96MuqlWsCx/McWl8unqqcs0/w8TfFsIzDeatG4Jn5VvGD22ia9/lfa60Fl4/80VgpxS7NPBobuJVITZRMCsY24IBAAN0CTDdxGNbmZg+CgpbRV5ggokFZStlaBEgdqnUHaW0l8+UEbLYx99ZQHEek1U3C6LRNCCbwR4XHfls/iYu0ueYaXveYvtNp1MX2ggtrLV6YVrgWitTI8eqzirMYNEGqQ59VvGZtQC5h2VNcnPeVX6zekmylVs1f9ea27xcWs0LnlFmE7QU9hmSiJuo6AgUQCFaRuIZpE5klIcGBCAIfAdQWibKYswjwFSqFLkKrtLQlR9sZhQ0cKtuRr+gtCKPqIzVgFxiSTyuSTK6s1yEBhqhmTL3+g9MwYCsOBpn//uwZHOIlLVb0RtMRUB+6zoGaeOGEq15Qs0lGInjHufJtgpQfS/N8/wd/340szX/yWLSlTBUlpNxyQdu5MO+TFw+cvbnxm/poFJrAoDCwKrDvqMHVLmKwCVodQB04AilDE7WbiOIpkWvTMQOEYphy20/Cz7WWll9ncsMfpLjeA402OnYa7mVx9M7dSPV7KtGfLTwdLrOtlltSucftRZpSaUzrzG+rv0NtSIAiPvFw7+ShXc34Rq3JquxqdkxcKbut1bT3Ifs8okcDOImVxrXxM8X82XeNcZXlGYmVLFikqUmcYapp2on1hKSnBpT6ZUXmPhQkdMqFY0zIBEYevUCBrVS2K7IfcGWslf6KmECMfTvfblR8Hz8MSUDJ9oR5vHdQNaq9GxTswZTyBmM7PBi0OzKCPol2UGOnvJuhqF9jaP1fMisdqhQrUqeIVJveILb1MQZEETuE4MhECklgDD7v1IEBBRIJgi1DT8RBgQeF182X8SKM+pLxhhQEgQgaX/TNZ6sQMHQ8+KgLrtIe67QuwTNH9ftoUOwitFrOfYAgd0Facd/SgaOT1prGiBfQcCayx9cPfjrTgPBOcIAWT55lEO85L41xsxXCV8X5cc2UBnx21qumAlf908cln73nt77N8Ldn4kne+XN48gpRgOFOeC2YxVibC8SfyeuAEAD81WIyBvJ5khpMlMEBKpkCcTCgS1D6hYo4whCxuBG72rON8lDXipOqeDAG8mWhArUaGdW8szIrSYjMg3e3uuFfErFe/TDg8gR0ywZE0b3YGBpUM+yg7E6vgwwPMTqroxaHBEqzzog0EK2d2jEPPTISVezNKX/+7JkiIQEz15QO0g2QoFrOhlp4ogT5X1JTLEYwimu6vWGCxw66YDdYCYECns6wAi3E0nTLqBRafBuMnAEj6vK0iKrxrwiAQFIcZ6ZoVXRXi9JCzC1hZgEunTU9LDd6vL4plGX3YuotBzuQiHDwkEhQlfK4JvI1DirEIQHT9schEvNDhRLZ+v+U8Czl6NukpMm6StOcbXx1Dtyn8kfkRpF1AhEjuL+BM9ZQa+J+kjgy16iu4alcXWxDNanyD3JPqBoBhHZBKPepQZptJVRgiHrrak2sTea+XtFtAZTqyVkKhZlQIwJ+tRdWG5Eyx5Wr5zCidyI35/84rM6u5v5KZiy1iTSuejC1H4qTBWCgkXBMP4C+qM1l0iyWG4xDHdpZdWpTn8JntKZTrwx45sP008i9hZFdgAHqfU9fs93R4ZtXsskzK8mR59ebf1QiKyvqc7iK6SI1gg3qghAgFJKGEWHMOEQoywQxplj46KKA7bp9K0iVQA8LacQIvHJgNhPJxfT9HAXR1DjXh6Vu21QxVa2K9hTr0PpiRuFEgERRxSvVeS5ks1VbT/9trTezy6P06vjLr+zI3/Gb479ovXb3YH/t/sk2d5+Zjdit/pt1nvvrdsjdfMx+7avCHJkRnNhhCpuogFxQgt5JEGSsqiUivdVd+090sC0TB1BUhzIDMU8diMnHO9dIhWQKMBobh7WpG1/twUShPFSGUS4/ZhUl2VxYyRKMkocQsYdQslZgwo6FCiAQtJQoD61wvQHJlElQICDwIw9bEEWZP5coZEyQir2E/TPKv/8+MXIec8O8TNp1irx0pmYsOJRCqCBOdHh9yn6QCD/+7JEjYAETFrSu08ycI/Lmq1h418UTYdJTKGZCn2vqUmjJykAIAJJUNPIALB0ppGobEqozRFG1Qdh5IOCmJ0r7zq7Z6mcOeVQKw6OU3FhU7sddzsTmfMefGnz7Vqkmqvu1r1fD8JSOEgNR5j0/TucOhxDPosR74nOJKHb+LjoeyN5LHx0SUhCccJU5/ePp+t/UQ7M233KfTd5CiqvmFj0t/hedXqIHYEpkig5geBECyGMsgfllZEfwvEN6Vcnk85DU+RLIEAtmTom+ehhIIBQeKBAuheVVFvFhkOixnhgB4oVDcfiD5SNFxM2Q3erJXy/c9fyysVsssrUbg/d2uCFn3bc7deS/y6e5Qoshss0/5BysFgNfMu978xuh2fCZG8XmxZOn2CzWFNwssHSgnG5ZMCVB83krRTIIZayh6CCabm0Dc0hCbOoV3nDplqUWRGTA4+aIB19bg2+IfF3wLOLBP8LkgCMEURJGiQWS7gawyj1j2C6heJjqczKLDFHpR9is7YaFlxsVx4lC8seP1Lp3cqy4za1/0umWs2r4UBoI2l3pL8E1kj3HWNFLO4qEuat1EoginNvV0lG6N+w0loItZrunlStQ+n29EyscNSZoTQ5SvWN64CoqFZoisyKDw9gtDzRQYzIdWjGB2W3OLXWRJYGaS8BKPUHMAdALpNxuPC7jTQkpZXydQVsLXI0mvfAYxPKliSWPIfUn8Qke2zLV+0L8p7vtGB0Z5HeY8YHQkuoiiOICrG3uKNIpHRiEzts+Vj1pUemUzurNKhS96vKSpncWR6VsZhMEERow4edhUg8VMUcYp21iZlUKAGQh+iAGdT/+7JEh4AEMV7UaygeMIHMWx08xZkRGWVJLJkYShctKXGHoLkfCJ4Iy1wRVAqCkQKVqfq8kI2tp6N/WaLA07KWHzceKA7eGmarblt6JTkzLd2as3cSPiHe1xQ0krf13FYCaxzJrLYmoQDvj/lpTQdepTihhw5Mto5KHUM5WIGjvoXqrsbJRUdJNKTZl21/Uw4w0Z/EVF5HtNDa3pLheIxH2NHO+frYAEBaASUQh8ccDTCyRpBUOBgBFBxgmyaCmEPMVPFsHOinTCvqMHclf7DxGhl6M4Et3kkApqu6Ea5/u5mhJezspLCzg8In6TyNOsmYr6traFXW/JDpramjKs3zQ++WiBaH0S9Faa2juulY0d3zKR0PSa4G1jbW5W6LGATokoRxX6BhUK/cUbUAKgBlRN1ABCkSIgVq4XA0/CEHfxpycaVTor1YSsSluTqFjnPCmg7CbShee5KiW8cpmzXVFBNkJpg7CCEnc8u3lpspzmbN5iloqNJIHjE8dkvM15RJpxZwqlAyG2EGImn1j8svb8f7b6NO3/nm65H9UvJj2LIovsKLq53QdXhlhBHwrwCsWoAIQjQUNkQAR3MchngI08skPGBnWWoTqNgKJjEkAbgNxiialHkqGmVnU539p1UQVOZabzhmPztoHZegoGcYPk0lqh2jnu4I9fjOAEPrxSrxt1LwOtAaGIZilIr1WpW9Ompn7n0fu+xF25mqRaUqVaV5WZPCiXCQeeJIDXSAIWANKuVfgP4NGMIAlRJCOVlGddzkJnovxuMPUlsCFw5Dbqu+0QoHX2TAIBydixFPFWcvE6OgtpT/9numx9XJVHNcuqr/+7Jko4AENF7S62sdQHuq2l1hIqgRWXlFLDETQggtqCWmDpnsNV8k3FPa69MwrGeIS+FO/g32+KSLtOtp+EWqurGBGTPw/0VXMVy3UipyyVX+uMbhFN8aR9ZY8aHCPQsLFRZBDciYjzHcABgEsIkZRmd6WJmDdgCaiIKIUZlYsqiXcIAAJGomPU+sb63Glji9rJYIqFUt2u8woGVFKz+JoeXvxsqAdIm1wuK0mzOfW0sn8TfO9ec5hY/683hms6tkaGNtC0KtW+HC+9IttWMAfKuZdE0+1QqNeaH/lU45cin+pLmAj2BDUeT2IAAagWAo22SGOWhC7R10jTSbjZIQLCK0oltMU7WjXuQEpdTzTmvxUU5/UwVQNRMzkFEsGSwIcSyaRNtst3VkiCUtKV7W9s7KiZuG3NLeurljCFB6IpRnFb1q8t8GMegUpuewEHPVY4QwLBAN90XDQuEnA86/9UuFlN29b7fXd6QQ+WxL0AYEZQILMrHNptNo4A0oFGx5oNGiiEBhEJBoUKDl3Much4ZhOq5PMxgIqFXOoqCmbgOlm0o8beot37E9BoQadWWzUWoFx5XN/ne5pR4O2jy/WdJQ+G1ueFZ0f/YRpZ5UlOut9Wd1Z3EK7rvrLO2tDVZebondPrMhkMZ3hThzkw2f1P4QG0CbTRJglUn8CTmlALCrt5KiqEiDwuRTRdjqbCFiBtCSYUKbwe+Iz06j2x7u9FzhTyLRlhqh5xo7+duz9ZNDkpLOmms72zFIKE259jfKwuix1fLbZy5qMxmWftUe/K7H/1D+KDfUdwhWnkPuWjRb0Ld/z7qVd7hm+7/nnyop3BP/+7Jkw4CEH1nTaykc6IJLOfdpAtJSDWlJTD0p6gqr5sm1jwiPr1r4OAp9ool2X+1rN3KnAAAyKfNcyRR+DAczEYFcQwBmDEcxUMLnNWMDJ6Jh6u2frDqbx2yYKANLID2BIcgyhXSHA5MU14Ee6hfyvlQQAzkwoKceB5W0lUZa3umba4RL/1YQghInPg/+avT6Uns/ov159Qu3+AizIiMLk0yxwZ6ipyVIb+8/n28NPypnaD8SldUA8kKtVM2jD3J9tYAyQuVfctWDdcuc97PU6ozWYe8RDOCVEqLEC2XzM+HNKQ8CAPZzMeCSc6UQuAikzylsirUSldx/PLlqaC0EkC8glqW+Sq2UMElWmrZI1ebvuxtNDdF6zU161XSpG5gyFB2WcVUcNl3ZrHUdStStfUzqpoI9FlG5QLjFxjjXLBLhUBBtD8ZdCaSWYVYZAKZACRNjPOC2gwP6kcDA0Yxfx4brWDIlRPJmCGYYwHYYFwR+DW4xCfdJOazAui+DkQ983Lp8pl44i9R96lk81b1JJrZ00LmS9Fj7Lfq9T/0W030VtqXst3Myg9kFstSz6jtdRuyKaj7xCwXG1wDE0TKBZwkb3AAgQAABDsUQSKCKmMYAEWs9kGTEQeOFGAxCWAEujIRfMch0CFwDMMyAGyKDGGwUZYGBhQJBhjMMB0FAxhh0HB5jZsAiERwJhoKYOEygy4NMlRkfTLyNswGNwcRGDkxniCNGTAVYgYcLKMMGgE3iEZMJAWzugpvOt47zKV30SUJhAAYUOGPAgMBEvXoX8wCL2nqswy3TtDaRXiMPKbhgBVdB0HldGBqWHuMxgi/BcDz/+7Jk3gAEXFnSTWGgCIFpGfatTAAlhZUzmc2ABA8ypec5sAD6lgYJsnTrMKAi7hfCcpsHepYlRNNhiA7cUjMplUIWnYEgdh663lt15qEds2JU59vDWet01V7ok51DG52N4XpuXyaHppyJbK7NHLKkzEYhHsnsgeg5Yz/uHw9RPLjWl78Y42su8/r+SWU5xCRQO+kxhP37hx2////8DvAiLwENAAKGIBCAAD/gmIX6blFhkpina2Ka6u4ZCDMwLNVloxeDTCqGMZnUePBhgPGVAiYGFIqITCojdwwxrMAKjCIAxoQGm8tMGTBMTsxM1OmSggGMedXeL+vkY2NBcCC4M2coJWurZayHC7uwnTCHqZK1uRJzx6A1lbtOW8zpQ7ClfxGCpbLLz55UGUucxvrOXJDVvwxvOH2v1ZG/cso5yjtYRm/L5dy9lu9akFE1nOZh+3OWYaeS12/LK+OUA49obU/lKaS3jXuZ3NT3MqLHV/s/Kc6O5YpsKm7sq+tM61dq/3v//4ZynlXmePe9//+j7erWaW5jjnX7eR9P/9H+PPgQARA9IDIiKIjkBRSTkjdt+/JgRQeNPdOpCEY404sy4EDGyUkSgyFEWUNaTNGDR2MWGTKV0NdQxSFEYHNLto5mBBehWpPdYUSGXpV23jhgMAKG5TuvoqaVyp2pYwxrq108HnhhgK6ZBTNcl8MSx6mSuFx1ndjLLnRWBjfce3mYtvcopO4r/wS+cWwo4HdV9abcA536tTWt38sXXvxazSzlSHq+8L/Lta7KuYTWtXrUakblSqV41pbd1aywy19XDDWW6OIyqWUl2ioaeR71XncZZVj/+7JEZwAHWmPTbmsAAt9Mmn3NPABTNWdMfaaACmMva7ewsAXkvq1PlW8sauqlvViA8MrO+9/GtUnKlePyuWZ2wIAQCgABpMElJKSuS2/8i3jIYsyZAsbP4ZI6BiAUJA44KgxwFOhBxK8uAmAh3gclhGBtFjA1QtaeBQkSC8C0KFdjnOyrwG4HOfyGqwW5Ql8OtuXCJLGWirOgvKNPqMvEqPZ+nzhN5OKY929BJ9XLKWmiuBATpzFUZwrttR6O1Dc1bFpK2rTO9ZIWIMePd3Z9Dli6TysYIj/0atQGaKxRsP/Ccl5jV8HcWHiNBamZ7EaZJIW+/ljzVjurRIUSBDYasEZgd6qr4+6UaWmFDbEOU9O47fQvWIq4m8PINWd/AiRAAESFDP0xkGZ/gbZwZpQNFggkZgGIz5Z1lohDLFEBgQBS9bM0fQMcAtAPEvibhyiCViZjiEkKiTEFEjJ5OGEEsUXjQdFoMxoSjLRKazyS0JkbqTao3NYhDi1MiymdRo7Mm6bv7OpD0HU1TtTd6kU6GmvoatbvarfatBbrTd1Tja3dBaaBoibqQTMC4bmhgaLTgAkMjDz9+Z/sgEighMlKNp4QjTxASWGEomcqCqvX256mKV7qsQb5s0AwgE8EMrPgogfKR+ExBjuJZuICTFiK7XGjqjolxW9OazrplJA/y61h2hqx517+V00ixSWv5Pv/0+0OpzRd8HH3HMVDFWSh0aNPn3rxv3p3WcZ1J/rjfK+yr3m9coHU1opA6utCB97C4tRKixKHuOKUUHXAB+uKbk7IAJFTXjkPezAwQmXDUF0MD2kgoVNU0Hz0AsKZ4AKqLsT/+7JkEAQE4F7Sk3lJ8HMq600847kThYtNTRkWgccu7HWECjTzdhqEbGSjQoRRctPGJsxZG1NuHZXDcHVWfwdcB8hcJzMpGuMi24mTXVIzN2UB5qV9YzU3fOrKNskZLjYMQ/spu1Fb0rn6b79VDfrP/lD/Z5IuQNWVa/TlNqmVXVaJuri/O7W+lHfd3NZCt81KpVFufiZ+UTZ7zL6TcJuXDUsl9udt8sxnhhA7Q9Ig9xispkICwfsIqSHm5GV4sxyKlnFPVLFSClGOuIKilbI0IbGOVHuhdsdLblGoNuzKhUSW+jrQoFloRaQPZC7EC9bkjfCnL9O+rgjk57Y0Fk9hHwMK+S9n5l+GMrn7mdJhx5qmCIEACLRJhu+RwzRgCh1oZBEMMNLjFU4YA+Rk2zlrzJgAQbUPc1rxECbguZsyfRCDY7YfGZS6eDl+Gp3Bn9FkCi1SWxybiiPw1TxBEa2gdhfeUSFAmH4+pPu90lqQd6nUyCCk5k+hIjXOMuVFl8k+u25FCo1RdTHvd6748sfXvPFVUzN8iWqikqJk+AKBeeocFiMP5kqLox/j7HNTSgASwJFl62pvLxLoBSSjLKYBLlJdrvxmU6pykijXcsosyZ57ASyuSB4FnpQiVHIg1YcBl+qcfjCze7niA4pHupckPtU699YPbWqoHYzsY/pY31bl9HLLPueh0enWeqXpJnPujoslWR8EcxRgGu845oljaACUE2TpN2CDFRY3oRMqIzHhpNYBE4yjAbmToAxUqDjSQANmXulWZ0MCoJZCGwcVGC7qz7P39LPwY+U+gKzoUp6XbkR+o4D9R6ggbAqp3D8lYDv/+7JkKQwE115RE3pCcGvLKrphYowTUXlIbWEnwd2hap2XjfkxNbDdcUIqgIiEclUj40IWxg2uRCqmydqa0xlnWrxUunMwsjHX7H8Xvs1++dNL9nN7U2t9NE30y0orH8VbAqu4Hjenl6s1rDkYBIAALWljqfwHyDzAFaWymCuF1Ltit1XKnDtNZf7N+K75qcz7UEsxEBRHZAc41Sm9IeJ/Mn8G8fqfBJ/+ceR8Mn3NdWedb0fdl9L89B6srPtaYDZprqUr/uqItu7VtRten0NVkwQqxEHrgqxoJMjbpk+QXFmMBm0bAmIo0twuKKuGUNhAtwfEiWD8QI9I8xd61CsJMtVFM+WQa7osqjhFxXUL2nbCq6IFTYiJyjzVppw2JSe0ZZvjXn9hF3Cys2Vm8l1iBD053/Obs66Cqf/Ktd1b+VG/00McvM6ZMzmTl/6X9x2d4vW2tl4nv3ZK5cK25IY52K94KfpJFRpEITLumnl9ozcp9RBgFfttmVBuYC4LLg1FiZMk3VuVDGy7UdXyupSNjgxR6SHMBQFoudr7cYDl6KnyfLFjT9jz/3e/lyi2/g/yUn1XHl3GE9cJYud/MKmrcWuCf6srGZ9QtHF/Lb/xj4WIPT5lqCL+emRuQrW+p4WMpgPbYyJ0WO/KagMAAAAdknKg8PPFhwFEB0jZg0oOEmJNCCAD3j6mEPGWIgReQBYbW0RHRI0sOVgS9CqhQKiUGy1a1DDlRv3z6mS1OZGVS4jWWJzerNfcFjm63m9NNr+puwUoNqHz/M/LE7Xws+O4SmcWj6V2fi2qWS/Eh/9XgtQ+kNb5lsf+18SOi4hr4e+Wmpj/+7JkRAZE8GdSU0lFwHAlypphjZcRZW1IbT0UQeyrqY2lCxC+qlb2K5OgjFR5k0INRCtfMN/z/PjKAgAAJCVp1DqAaH+ANADSLRDqKkT3hUOByVa1yQILTtQ/LUrWmTbRmrSjJOcBYoxg/xqJIfxVMQGL8r0P/DBfZ9XOfzgTY1Y2WmpbWdR4+k1GglOoCZl4MmmKY9dw0aJRsxXfGPi81ytp24Cljwqp1LknNAWNQiMMuAsElOA0GXrUNDm4vVfwSLgIOFkQGLVpcDiwOAFx2VF3yAMrU9L1xQmFQDLHeIOqpEaWstGdXsL/DuNjLiIF4R0htcd9XWAsJrqJ/17GCPPsnI8X9mrf2mN6+K+xT2+Dyvar5sbWTV/UezXA+fj+PqXn4W7ncdKBscrCpg/ypoSYUvqCKuu3igS9NZlOSUCE6CQxollyFDU4yDmSnLBgaBCgiJxYvkvkoKSh2k2ItyC1g4aat95j/e4Rx4foKBqdnK9HGqaTch4iVds10AGmOVdTpZDZh1c52OW5SSMzF+jJs2R0syGAkM6G0cFlVdkZGuj/a2mZbzclBLrGcx2VAAUluM6oOIVMR2KnM0V8w6asW4FI5vAr+mYx9AdwE+WmpulogW2bSxS8UOgaUNlboxNn9K0oUzhQbA1j0UlBsTFD5nRi9zLPUyF5nSur2trD7N8V8xXBuO65VRuomVq5ra+OIo/8TXtn4uGqVd2pNyVP4kv/u7ahF6M/f8fU3UbFqvlS9dYEDMOxH0N6wE5tdyU4c8eYGYd8YaoExIcBINohJxNSM0Tb0kDoMAZbYZY2IOJIQwzAbJYzuCWsP+1HCy3/+7JkYQxEaldSG1haUHPLCmNpYrYQVWdIbZhWwfSe6F28nXBLPLlYmPiw1Vjgfltg+3d5txJY5lRUr5HjhvcVVXmRSQSsk6ztd5n2JSdsyzn9O3o1U7c5ft/zN792RQ9bH5MAFtuUxo0NjEwDDGHCprqkKhBMCAYGAAODkNlRho6IwwKFYOG2/fkeGQUHpmFAAn+vtmkufF8FRMLhtpV+DrjS2/6BuDHDSkk5fv2WJ7xsaWajXmc4Nm+MlvBzdhDVIyTAxkI9Nz7K9UfMmq0YGaTxFqi+uhPfuuyVcrMgx+upXoFfUEAC044ARk+ckMfwz1S8WLwCUmXEaARLdULDDSUIe9AgAlIe4LTmsmoOOxLTacQhqTZ1MKJsOJQVGJC1lwq8Sk0Gyq9KbKt12txRO0oFxwoqjXKjYcyiK8BhZVOdyivMcs3n9M9JiWzW9vbnXHx85lTxd/PdekoxSXKUbkutBCl13AoMwogQvhRoZGSQl2KkIMEnyae+ZEIBwAwgBL62z5S1MZ/IdeokAubD8VcJl0RZW0obCNJLCaZA5Dk1Ynk5mpSlZ+bl7o2lBZfCq2U1PfXMX0Yx5jzyoNIZPqJFEDOH0z8nXd/Zz4accipH/b8/BcPh98oaUpc4SezQjAhEkfIVAEAACjrbsFj53EBzIh7SZiAJKjFzy2hRIGJF0maHpAl5gwOWinl3uGX4Hg8tbqrEWYe16XnTJnodlLNKupBBr/2cbi2a177Glc+oud9p75NZd/2cAjLZ7ZChnCTUwKitsq3XYt000fedUK/iFAFpF6HsNYLhk+MEBfaUc7EgnnagIAEpZtlBCMwqrCP/+7JkiAREIVpTm0sdQIBnulppYsQQNXtVTLxtAe4s6umHoWGgzvi9K4EiGKER2auwwleTBXU4zhAFctn6JzpGyrpzeOZeWquUQ0yyB4yizw6wagk+fsGv0flM8k/kyTuDFhC1fIOBwuu/Xc/z8EI8AU3BggmwEvAQAIoYf4HFuYTu+T1gkAC4ngcyA2VxaVwl3cz0U8OBmPNUgUAKW3XpuGwZSIWGg9KWxMxbdPC+CSIWd6UKzT46kJK53ASxV9rSZ8u8qDGNHJP2JBtcC2TV1/PMp8erg3PtIv5tJmK40T/y7RP9OEhFj+uYM3iR94/Dyenks99NqrIMfq44iv5vku+XvkXP6sgUoyBQzqduMy50D5vk2hABJRpuLBEoqAoeeFd0GFWITh0Jg14twh6Ohse8gqwGjcNwbAVsW2y8nE54C1H5Ex7F03y5cff2H9i2KD/lp5GiP80tB1BVWXFUNEMzYIG5z/2N5q/RJ5iL0X/j7q4cWNyV/HyOxgt6Cq9FaZdPfL3H5Ej67JWtDORwjN0Jn9rrUeGW7eoA1gEANxWtzO0HTQVYMwtpYZeHHZbXqtr3VK6GyQ4F0WHHglcVrfcAjRWKIrbBuS1brMi0z9/P/X5qXfDeOtLCUFD6Fqr3SkZlcrNo9UMqeO6l2rjEXG03fD420qqTuBZeWNbQXm6HHNyEInUYbHbtLOHQqZJaPwT5BEoznbCb5B9hj0MG66fliOSWKO6drQJ1cSNbgOJ2cWqyevJ35DDYUTA4RAswAUhDvLfo4JI1Aska0gkdj00Tq4N6UEjYWSkD2r+q/M0qa9CZqhS7X67LjRirhyq8kb7/+7JkroQEKF5VOyxDYH2Luv1hKGlQDWlUzKURIgQs6zWGFmzXcig2uv9lrpP9KgYxnMtAzi3WOHqPWX0askKQrUJBxE8IXEs52ghQugByOtERkJeYHnGRMwJCnQTpaT7jAVAsZYyPyuocpaVm8Izj04vX4T44QbkId8hcPLJcZBgXM+SreFe7HDk5M33tvWZuJxPxmudNaZXSojzOqKH2UlydGHsI3aQ5tBR+dCqla1ZVTS7uhK2zeibX5MqZxgyoYHHPvLgrI7k10Qw5TCDZt9JM0VSxHQ1awVXBcEtohwcmfThYMw6M8JhDaLKgtFykOoXZESgIm2Fh5zWnq6h3+0fof56X5FV+yx9RmyQHQIsmTXOEMO4lr2S4Up+SesaKjto/U39CrSYnsQfta2UcsZMd39DknpW7hdYjiBaMkddz2NmgazdDgWQEygX6AIaZQAr9rJPQDUQtd80CIYEvTHVspRZoyokJ/sUSTmmToZgRaeiGX7Gk/UxRm/IRjstDs05PlakB+ttR/B9bjomW+SABj52vRYali/0izfpr//OWLmPla4KIntbbaY+UvVb3lOY+SZnlG84muoebQ6ouPMDcNEK41k+hZK2rlXdIDqAJS22PMoEmo6C1inLKlvI7J5wBpOdRRVOHvbCIPGSIPg1IC7UiuF0eUTkAOKsaY9iJaZ/GX4t+mrfnRZsQQg+hp1i4i2bwl6aZbfKm+ow+Hn7GjBXGUlS93uaRZSpDlOP+Z9SKgqVmUHcUb7R80v036dzUc5TTDNeUK00JRBR7VgJuNFFig68zNnN+M5gARodQyZiaTJoHC/QtKg4FRQSBD7n/+7Jk1AAEGlnYayxDaIBrqv1hiHsQSWtZTDENogOeqM2XolFRYMoT5gtWdJkIgxawzwNyMTrMM65v831ReWxbUXE3g8JiighruhRMk/U1kuDwiHjeq+a7xYRbJeXZfRjm8Zap1zcf7O3FW0Gcd3VgP63QJdUepznoPwtCmjBGQ3n+MQTqcMMxo8WmE1gazkh7FwGGEMRD8wGQTGgpDCSnMPFky0Fh42EQFSAKsWaKCgqwYUNO1IeKhZHxQgRVGdgoJ0uhWmSCGjyVa8GPjbtLwde1XeWemKf79SfyEoikZCgxCWPeAhJKNkbS8I+ND/SSpuFKFriI1Yu+VhaSvkh+pHUoLVItEWerppeuTYjPi5JT97+J+oS6WK5NtQ5Mi4e69Y5NTp94BXstyYxu4EAZ8CiosTCo4Dp0ZAE/leUhAGvGXWVUHjyyyRZThJNypVF5C59NMqrLyahNxOtuDc4ZKVOJ8SKWPtJBOpr60lP8eQPoyieappMTCkSRxNxpXxz2UYLFLOi2mfKVfVkWUkTQPVZHIUok4tNd4y8pDbL2aXcSMtZc5B50grIOOSYIKkl5jBGZiMGBjB0cQfd0hBeVgpQIHWyEDSTWo9RCkgy7K3cAYQx5f5p5ZAsF6xbFPRuSy5kLLdh7druU9YEN1EcVASDqGDAyN4Iuz66LURb+h+HRzVu3xNZIbGclkecrPAlnRlvslaiL/YZ91sJxnxH0c18V//JpA/HK37/zxBdWwyK+HxIKnTJzshO0Gj96zEnDQACjTxgzOc06HAEgyRGAk5hIkaiWgEnXIRIqYIVWCKTAJaZIBG7ewJnIOMG0yfdjaYr/+7Jk+AzFHV5Pk5hDYIZLWkNtpbYSkXFEbeEHwmCrp428oakKXMWSevkRVCTOP8g2REUMOyO/Dd2NS9DnAFbsqFykgNWZQzpa1nuKoEh81BtY9p5NHSrEW1QxYyWctOLdEfuL46Hy1VW0LxMX89pzv9TzfXPztPHf/dTz9Y0JBDQm04Fwz9nPo+2lAJcjmMChM1YEDDQdN+g8xHmDDxfJiuYRJAyY1lt6YYDhjkjhUSgUBK1DqEQyaZcQbMYSkHUa4FjAWMEQQZb4QqkNDH19q0RaPQU7FJTQHDdkoFwLSLcNIRFiJyqGxDGiOWOHEUWYj4x2k0JiXcORc6WcdaodGh6KWXdajx0KST3T8q1VddQPpuDP6u4LMb1rS/mbp4GV4iTXVHSND47pRJjKqeTrbXpFeR+QAGOSYLHhxRWaiommLRhZgQHho4MEDiEY0AywqnICOksDFwU0MOgcSBxAUHjGpO8iANGPAYpAQkcqDUJdtsaLNmZo8bO/wXxLpy24eFz2HVK2PepWlHyUDpyjjH1dCj1foZs6JvzSZTzukzOd0PazHor8170VlpPsfmtnWonQ19jX58wybNda7yRzGtAAUkl5gQkDTcxtRNdgzPPMwgXM5AzASEHAgYPpdkQkDkODEVX9kaOQBoAboLwBAA6g5gtonwJIF1GFE6ACtJERZfJQlZ+cMDxdL62JrorQWtBZuaHnOKOsp0SlQM0kWPr5sm6y6vQQdA2QS17qZen0mT6tPVNF6+2pjT0P1tutrJ51kWzQ1qUy1qNEWOnDV1HGLIH+9sABtx0GIRzpiZobm1JhngeYC8G4jZjIUkaluED/+7Jk9AzFVl5Pm5hDUowr2gNvCngSrW9GdbaACkqh5863QAA5EBGKChAQMRNABlGF4AY8KAwxAxgQMEAQJAWNg6csWcEwoDzI2RfC6EonxnS+JAOosF8jxQY6SoqQ80OnTIrI0zJ85p3SaOJ0yofWmtSnUykOitbvZafak9SS2rQ/a+tFdkdalOoyONqOu13b1HMUAzxEeL72VgEAAAIOBgOBgMQ0DDwA06YNAYzC7s3FJN+TAUbmMlICiyzZgZAZeHl+gwJMcBAMOGGig8MAxbaDjoZMNDgZpTdl3BBBo6zyCwO6ODsv+yF+oyuRTBagBGprFnbhyUTTyUwCOW3TXUslIWOHHGuF+k6ZyajVqpx34On833TnWaGIRKVvUkg/hTUFNy7aRzATEUGmNvEIoiA26gC3maNXaDd/url7Ct2kwwf+Ny9rkOWHkflkywr/tBhxp6VFvlaznyzhevfapLD/xu3LKsPq4lj1r9cWJOXR2VgWWy9hX65//v/////lkiaw6l+ksLri/509unp40ziF2aWCbVx5pNDVJGrtJ///////////////////afP/z///v///////////WwptYatRBGwAyESkIBSGSiAhUEj4xG3MvQEBc8sMhTjZI2BAxIMMug0KCEA0eAUJRkUDlY1EtAcIgJAIciJBacLPEtAIiANkQ+FWSUF+IGUKdKUq1Qgv20lhDarGpmuQ2nXRp1w+VVp5lCxQDqtaS7hxqDQc2v0eENtfZMztVz+LpcdmbJnYehrr722n0Esww4GOGVI9KGtPepfjZYlJIerPDGLeHxZ3MZM5cvg+G4WtKEL0cFn/+7BE7AAJToXS1m8AAymuqp3NYAAQYWll/YQAAfkc6/OwkAGC5Hvd+OZy21RSamfu5LKSxzdyWQ5ZeZZz0w1AkmiLCl8x9jMWqUc/CZbLZ+k7TuPGILde61t+11xfrjxyKQJm3ZMRS11oi5DdJMpfDzSIAhmAYhG5XHM5+GnmfamlVPZpL1P//////////////////+6p5Q5x//OCRjFkQHCIYiAJJCTrkoGJkiwS8bD2vCEi2gUKNs2dRkLpPPAFsLBEHIkCIoPxgkGmHMVtYrjILIsZJgtFlWw4qkGKWs0cmsjYYuaiDrzHkfPVfd/SVUzLGimNWle6Qy+mqbr4aYIfjjeHu4i55+lLurj+aj+d7n+Zz+eFJGplVGRfNpHMbfACI0SAAEZVUfG0cqkAU2JL0WUq2OLuUpaxK1aHVgqAAbVBgiE2jpMFFkTkcJI3mWp1pm2sZJZZsooFtnTL8ypL55rO6dMbWystO2PWRt75bGDp7PVHdTa6V1ikF8g7W8ecOlQ5D8eR1v88fc/59/Htm0j0eDh5//AAH///9+2DeUAAAcXYDRT4KYB0HehoJoeovDkTREkoPF0+R9hQ4se2wRozSFypE3WzES4gEOwpbNrvzNMNqFARkbYh/E1jhGLwiAsPRJ7oQdoMYwyfCA3NzF7Qj7NBe/nSLBwyw9tGoJFzJab2AktNx8ziWZHDQBDggSgEJcnYEQkUr9fiISBiAUxwkAAA53hcGiHEEoOMRhBKQpHEuQrFQh6XVz+A4OMrM4VgVibrAt7TatUThhBAXDMtKymaikABgtSm6mY5DwjrkDDBEmjuhkwkGkcVMv/7skRogAQOX1hJ5hvif8vbHDxmvlA5h2enmHOB/yFsMYYZqbA76GO5Iiex6uZRcnoOnN+Emprxkc0rJa7xXaWWjty9gWWfJj4V83sqI2yHS+Vn0dSUusabZRQJkMGuH2EOA9MgWJ0BlhBWwXItwtyrPpfVypVijU7to02EwCBQC8ykyJuMD6Y9C68zb7T3oSso5Is7bYw5UVXN3PiGekyO/UqVnVEz18ymm0LZjciyNSo1hKmsMzf+fCkXOQvK2Mi0udjcwTmGFcpkKetEZ4pmMcOoj2ohJdjINAACrgvSsoSUnlMSJsjc2KwCsIyhnydQZuH6A6eldM7iEdsQupXDmsK1dey/l8WG2dUxCerg0iSloPdSLICU2afNd8IZrXKv9ZIvTXuba3hB7aZeJeZtHWUdRSKPfzl9I90Mfhs+DTCt42RVsVENqt4cvX7pqpbtf9v++rCrXYX0IDjgQaRTFI8OrAyeMFJxvk8iajE2xyqnvPIhBkGyQ66TZAJETHiq5Dk0/tF5JJIUmkccOwRPc6cgFIeFQBdBnZMo6CM11OIDVTNZ68GiyosQzy04HjDwjQyOlGaRjk/3FxqTFZSea7eCLKGdEBRDgQwkK97hq1ass/c0BUiyioABO0nGjOhPDCqdM6LvFzeuybkrb3stk2kSBCA+SJFEJNcgqqnIIbqjCZ01u79LYzFbeOxLu/otC8T68266Cepl8qysMRn61eksApuaovfm5uVeVaL2x6NLzH8zNZWb93Mtv/3Z+221Vtf6pu+aYnKFI9QzbT4RA2bYz8CSkpFFUUAAVISgqy0bQcaCVOKeZX/tW9Zk680X0//7skSOgAP8WdjjCRvSgEs6/GHmNlAdY1+sJG+J/axsNPSOKdZEdBYXJw0YWh4sA6UBzCYUEiSPWUJVhCnsbfbuhZIkMT+fqn1Uso77VHYytpIEDgRA7eobUQHXDxzEXXHOFyGpKtjKfcqmW3bDeUeM+EV6VC5ESI/51eBQHwvnavVa+xrV9Z0luPtKFIEAsbobQbIOMC1CNoU85w34Q6SLNlnHCcpp9HKpnJ2Wm4MXIQiQjQTPK6nL6jlNZPE4Uoo2TayhYrKaQzk3BG54J7ei2wgkUFoeRCAWiiQJkcoDR+bJp5lSjfsvThF5T/OWsuNq1vGZCOJr5wz2DEiicXdgwB6i5jt9ZNJZJEAAOIxAka+QiJgXHgwq9W1W9bbV+WRQ+foJ4DaAyFormMt0CSDalpl5f4Teyh32ktbbZ23XZ1FU1UUVlLO8UBH78SJycWuEzJq0DENXjqQStbui1Nl7Pf+LKwukioyNqffrWzJM1LdXj5maa0azZ3fZnapJ8wgvlLohpRDXp+FKB627braJJUuRIG94GKYY+zaRg10IC6L+SoMwW0gh0yqhnVIEOCQR4gUKLHyTBwDKSWSBJlDhww1HMrEEIuS03yCmXrV7rU31mVSsd1aVqjloJM6Ej49xYxxS0Xhx155NZarpumWhnC8hKQzJrNukZIR/c+XKrQLCslpdLJfi/JQAIQjQjNVUbj6JTtiQAKZeRhCXEVqSa42zEHbflWCXxguKB0RjVlmgXCs1GQmHdidAcLFqwgMQRsCQxwIUQUYoKaMZxxZhwIzhBaEFoyAI1fBlIHJOc1bp+DWgu1snhoSEj0XHMW+RUP/7skS2AAQdWlbjCTMigCsrDTzDjlAlN13MJG6J/SasNYMOKWjIQnH9rhYinDk8Ci2ZRfzJ6nV/z9Jv37OCdtjraSKRlTIBz09VZASaSNCWUyhAdF1iltGpNmbftmTzPH3HAImFnksM0WtFO5mj51icucZJcIHWhKRW3qujkbKZwqKYhBGzOACRYlYiVXRU7DK7VLDApQzSpMmOn65Pwg+WdO1BApuqq4sW2k2VKZ+8knLOUGNdQTOO//yJqkhVK3FImQlKZIHwfIYAPkwhAy9CbRXEKwE8P1SITc1EcqGWKonjGyrmJLI7FEkCO4XcaULgnLpVpldZSYQRVJFHAk5DUqm5rg0DZvqF/9U0YzKg3OoNqHphr4lbmMURlPXhodFgOXhI1hJaKGLUE9zY5ojFnMqSikAomkPpg4iH858/OV3LJFE0gk7BphEoe0QADdBfic6aT+Ua9mYMRbK+cfhqJUcMS2Grs7bLB/VY6Rp8xbQ5ep6QTY49NM481r0WfKZJeHWqS2eDV6YReKVLL2bKp1osCA26ElY5rz0OICHKlMgRmtJdE1p9iMTar+6keVpP5UIcAhInsVrEjDK9E+xlK8QRDSAAAJAgCkV8mAAIqFLU+3rQBL8spnwcj4yJl+pGSDQmB0XIQuQCNEqFy7OwQe2ospyIcqy0mLm4sywuIRNkR1E2SLwTOmsQJMrC6LUSKZPCDOYTSdkLgiHWSSKEFgs3bTqKOsuK1kpqqMMYvVFNUHv1+TnuTXe+t8rTPXeNxCbdmZqas7GubqbtLdGBggu/fUULxuGXEIAA5dUmADErFC0n7URLyF0laa5dFoyPkv/7skTbAAQaWVfp5h0ygsva/WDDmlKldVEspM/KNDBqZYSN+fe2WtaQpuB2Q8ICAjJmyENnWRGtqkIs7FnUpTgZ1WZxPUKEtpfdSNGakcVxVHsnxzwLoINENRTSUgIRW8CouDOTQZayolA2yC6Vw5KDzUMEhm1UU27gp9UZKpLw4JkaG6oxJAsDV+hpDyXNXFNXnq3t7FVAmUJAAeVC49OLIlh1IFFp4bCFu0KVTs6k0WiTf8lz3Zj+qExOdyAgIChCOIVe+ayyPEeWqQm1TK8HStlNVCfgTPldUgURQMZUOjmPWTNm002VbpvFZFsgHKspT4ss5Nemnhjf/n+DV59VUmNn3mRLY2FpZ3SvNbNkpm8UzcrNTRqXPzIPpcZrTvnF3wgwEAjgpxkgAOICL/f46NKk0dWvIInPRpsJzFq1DlpujBi4IvP0OLPqaRwsS2OeHAYoa1bRXp2vb2KmftWVn0Xu2gWrFmwxsqesv+hwihvRS2+5d1ARsvILT6SuSolUvDqZyBU0s/hkHpcJCYjIfbWu9yfW5/+1tSGzBO2Kd27xu2ox7zf3lqOTftUYdNmfLn/dTreBIOOAgmABVtLJJkGEOZVTVFMrgQJan0wkVWfu8FA+wBmfHYFT0kXMT+EhMEw1rjcT1iTNPArIi6AD5WHPBJM9FyIAQAkEQ6S+BpUSOBiY5QSrKB1k0yFMwWnVlmUQYayQ7JW4HYZLCBPyRRQ2xaUvR0fVoUBz3ZBJRSS9c1CbXiOxT9tdnjNdpx70+07bphZK1Zz6CABADAgMPFAySoLdELSjyhS3C+GLXCAEDoXgbBMfrj8tbB2QOkkdY//7skTuAASBYNRLKTRglEwaiWGGmhH9YUyssM0KN6vp7ZYZeHksQkCJnwuStQ4XoGp0kHB4zDXElf6VIZJBj3Baw1FPMxpQ1A10yS5MTR0somw0/zaZYSNGnqPdi1ll0YSRzZdiyd1NMmU1TiPdtg691e8uHMnzH3u+ZDbjM/x8s+FwytJhSw/V96ogEGAEYAAKyR8QqAAKg9X3GXMAQDKBX9YWYl+y9HqAW60tNFb0DpoNfuv2+9LWxRDUItzDuv7OcFCNTyQPcbSKbS4hnIuSkbkjoNZckD8ZeSTuLc/ETFJGiEdKElLcoLA5UHVTFg1vh4W0YH34ZeGDCuwGel97eh/V9IaxoHGMg+ctBmZks6M9orexaTv5xkEPho4/WlL89nFDFsZSAA1AQABfoa6mUdSpZqquiIvF+F6OWW9KoH+QTF+6JTh7pq7TypEmBa2QGS4nqxbDXljCn1TiFTA5A8dNLG7dDsdENtt5ur6yV8C3mte2sL7PWhT5JSdvRlmuMQnMWSRjSKJsSk2aIPzmsbmCIdlm/zks7dmiK/MIOxVbjGJ91NjtKcvP7ze8rT6aDUO20gGzFisjSASAABYpDqyM3ljicBobalh1OFFtNkeOQkUV/VeRjCjSckgFW8qjGKTgVQPTUrixJGexu45CyOYrIW91AflWINw4DrM9GUIti6aBukl2dTG0PGAbYlRz+5rylNNmVKm19bWr8jZlUF1dmzPE1Cr+tKV2253jte4/2k+VMud5InbWKYt2Z+V/atnJNi+4mQ/+bUeqyM93D+wQGCIADiAAMxQHpKGUaVKLqpgeMeA6kOF5n/RkUNFcbv/7smT0AQTnXlNjKTWwk8tKa2GGnBL9eUzsvSmKTKupcYelsGOIoc8qhKxbMyuhx04rnNaTbew7cvNePqhQks1Gy+g4jtbWpXR+V1UUlbTWPOqZM35LsiXYVPba8pSe07FoL0wG9qSq0pNkU9KSbqKmuzaYyKEzlw1DOWSy0q3zhvSzfDEr1JZre3u0vP1j2lgwAzKBVvzFQCMCAABGgyN9NADUGuKglbOYyQQMhe5YYSFwl4wIzlW5yc5dZc5lChVqZiUTqQEjYk1RSqzKbFjBP+iULrplRV4cB2aETzWrdJ8iM4bZESBHKLYhhUMYpNGwwlAWy0yrfi9m/IKn+w936rU4NoyLYdnxOLN+Bx/zF2OwLx9oI7BYN2NZvSa6ztjOS3gRC8alTQsxHmnF78zfz6lnjGtrMIZABgICAAESEHCIFxCqEGBJ7CwoMXUHp4bEA79vuzdkOLUnTPO2j2Ppq03rNcK6Aw1xaFtxta0moNSJmpuDiHusK2a5zRvfw8qVtVFtT5pmNb4xB1eBB7QZxSDwjF0FWC94dBk0FKDV1dQ0f1JaqHT/4GXgNDtpTMXFRjXxJ5w9EFCSRytylFCh38O0ACDGgFrQQEVADCHPJVUjIDFYaSk01xMKGE2G9oad5ORqUN68hMvBbOXrca5FC+yfNen+KUkCQIAZWE3G4udmUcKIL3yPR67RlEad3NTT9HLxAaSufUwWPKiBHCvZRQ/i16Gm1MaIyFcQzQ46/3rceO8mvsTTJVrrXspVY1X4nrpUtRWtxzRYuoR37LyqAkIUCsGPAUpinFQVIJV4EwRKg2Pocke2QsTQHTbsQNenNv/7smTtgQUEXtLLKTXgi2uqbGXjflGZZ0ssmRbCOStpIZSPWJ3RWtlEeRyfiMJo5dvX5z9bKvV7NN0WLS1cIlu5EM2VlKbeVcjf4IcpqbSlkI9KMbIdthxNsIpc+XfTEi0UrxvcvP1Xu66ledM83FFhaKIYzrvmwZv3EfLYgbVM/FM3J7DxAFRpogGmgOmz3gQIAARCUEmghwyFwG8pQkiIay9jNoPLkrbQwzs1azyVn/g+CUoqSJwHK9cT3XTTbrvzL9DUr+j6rRlUw6iB2Kp4NVZNlURcmQ+Cdt4liIPOARQzXgHOoiC4rTc/ZCeUQS3vKHk8jP2cYOWi1rxqKFf/Z/3/4r82/77fy+etzs8f+tY0tcwUFZ2JYkVUyPopgAIgACbAIKgEgByxQukmg3NHwBCSQdiDFlo0myoBqRClcn7ttLJbf6fRH2GPLleK4oS5nJhOxotIInQl1bbSsYaqRk8vCRCenunsk+M06x3bbKTbp5B0qzgib5JfYyPuT+6cy/nf2utKfX9X/2fZZ2dv3W6c+qam/tu994xn3NnE+xQ1mZ5Y5Mr4HASTs88wAiEAXlYCnBMgiHNDcKEuaCnAgaMR8vsVCWlzUF0zOXVnZVML7YtbgtwZFNylHVp9iu5MdgaZCb2ouTIkfDruKwwitk+cxchfd5KbE3u2yWLrsUqOgiRwjqW+CbsTKeesGpeiiW1CUf5X6qe6qzBgILyhhoIf0V6YMHwKpawb0EnWi8kLBgywwscyG/ON5ft+dvr+HcoABECESAA6A9LsRhwETMEFLmCoUQRQaHoo2hIvsreBHuDH7Yq9kNtfSkRL7QzMzf/7smTxgAR4XNIzKTWgj+vKbWHmXhKlm0jMpHdCQSzo8aMPUJpaDGVU1nOLfQ4VZBfpKa0s6tnO1pdc7K0T+ileYUvRKJLlI9zF6ViRr3hwXCasdqKfMk3VE2RFIxFNwgs12hU3Lr41hZGmTaYMQg8Z8jd87c9vyLRlq+PAoD2JlmTj+6MqTEFNRaqqqgCIAC6/DLIIDjCKOHpcr+A2YlBRZgxBlabjv3G4Kj6z43AEBocWz/DEhdd45kRCL2xq6idmIbMw1vWD4+Ym34o67JAVxMmMVyjJiBggJ5/OoC1qooIZgxT4zi3yDmphCE/nB4rTRrcpO1NqDUe+NhfPaYt64UqlhLgfDbU/lRePKbiE+IMgatbJHEGPznfMfH+NaiAAEBBAY2IQEEBDzPViCThjiGpILJPi4KAdQD4yYIErRqomct7EWYFA8SjDXKu36YzBsyKjqNuxK5SQGU7SbO1BR46bnr4XZYsiyZJi7xBlAhI+kQiBLIWswy4X61LBYsJBsMczJ2j0UltSyH2EKg/Jd5+dy01y23ErbTtvqMr4a2u1QmAi2NYg7gxscAqlJr6Gvd/6AJtRoEEp1spGAqKCghxKRkrBt1tMVjCZSVSlznTj/NSiFrbwKyz1Wt2VTeSwSWHOS2RztyBIHpatWXTdrgkv3W86yWG8VPgmrda+zjl/7vtE5+kXmdCcve3NrH41v2v5hGu06UDBRsKHhGLPwx3cdbIMUGS8KH6d0LnT1YoERqr5gyvKQrKh0tURkwQG2cUkyUnKtqBWVoPsnf1moFYREdqBkHHibA3qtMzDjtL/aQw+YVqz3Jq1POu0mFlFL//7smTzAASaZNGzKUWglMnaGWXmllFhfU1MGHkCC6up9YWOcNFHVBUGDurrl7FTtw6Wx1b9lutWZbL2RT1DllLubWpZ7tRZpHkD4Vq2+RiMqYoyZizEZg5WKU7pdiBOYhEPum+UhHlfJRBgmYMiYwReWv/RIAAAAAGBg4GERhsYgsZCQYUQxw0gMzZct+w0cFjAxhKvJK4bPFIzt2QlQCvzjlroVHddYLi1I9wh2pjgjwFvnVyZmic/Ut1MdpeIeb6YjS7QyyKzSmutl89fw5jIkoZ2R+xth3E4+o4m4qQ81idgRk62AwZkzxnwvZ1zYKkNsuMfsaOzvqGtCHKJoxWnVr0ap8ST5Sf7JeosP/ZIkCJ+LQWjbHKPECIAAABl30wzFMzMxkLhAFA1MxfUzwFrTtIXTz2tPCF9ZM3F9LsOzhMSgGvKmtSSvK5BAfbkdrZw9yznO35mlRYpeRC1i/tmWm1WlzBGhLIWqZa6q04DjZdxO0Fi9aVXYbbUk/PmUwwBMYEaOwgcnEYE8UmVxR+hyrt5AQuE5NIRiyCPDSMRmZdtyNDLMFAkJghm4nCtv0Ys1yqfoA4SRAglONyKLDJgUMgivOEA3AQlOJ5iESyGKzc3fhmJ2ndZc0tqMohyHH6qW1DS9c7K3/pqLcclPfpZ+kUiYOjBEY9/V+RG82L/GmYyNM2L3goNU4jv8Gn914ZLCnkTEbZs479F0EkreE8yMk27LLjiTORk8Q590Lzbi78Dxs3A9pg0tM14qRU6fHzyWboFd2/HbiGhBEAHBxq5mHBZougXgXwTmgZZn6mIIDL5sUVXQQUjT4OoIfeZTtLKav/7smT/gAUpWdBLTDXAnEtp+Wkj1FJte0lMGRjKC6LoZZYOWco0tLGt2evdj4pp9HmBUB1mL3cetayiyzDKJIDYI4SBRajkpV6UYHCDEriIoIsVojbqbM4kxJ9cuQa62fKzmuZCXPxX5S2ZItwKn575StWAx5AI/cV/Ne/igEQGxAAHQBmTpAeVKkOYua8ZESeJJURB1iQBRPgz9j+T9NNm1EIbeqHH7giGhgAq6zSZv9O8Rh6faA2RGCUkGGaSby0JwhekYFcMOFdjLX+cyG0hsA7HLuK84SoNnJUQaXI9j5rqQsN7mERF7pzeSd9sbKn7OLVdEZc3cz3+FIz96uUqaKQhJzQXZh+w0I2uXpDAGE5IK74IMjQuPPbNXwGAWgAIAGlUNACUSzQYBMwlYFkCwUwwBqCGysrjUwKAylg2FNIpQoqzaVWyqLncXpfhtFlI5ctSlxUFdET8C+54kpqc4J2QQ+oTYUS8JY9W2nJEihlhPW/Urg+KNS4xz9HtJ6+M9Y9JrZrlSdqGIGISU/U89vauaiBjOpKOyU9Tmj92o641lRNoLpcLgW88gI5RajetrHd1ucvc/f2f74UBkgIAAAQwG0iAg08xxLUOuGlBy2DnqDgArqdWv2ZDm6Uz1FDI6aCqlw1SB/DgirlRFP4tsv2NGEBGNL/elDsMoJUcdKbihLjMJf6930lloy9HSSTbF7qfVWrekOfJTXqoN16Ujf1rKRkjXTfvTatqnGc7CL7FONWtK9mlG/6gqsh86vY5pz09eva2/w8/T8vrYALQpNAAAADDQMHJCwGmilvDBjzjzqnCcxfWBFTv8kFNvw/Cev/7smT7AAUJYFALSUXgn0zKGWmJlhIVe0bsPSmCGyxo9ZSiSKxnLSdqSmyeM7IU2ICdAAgpUybObhgSc1Iva9ZP6s8TU7BKLrxPIzpmHh+bEpJLd0a59aWtlq49bqqZayFppLSCotvbHDBdBu0P5U/dVpcdGvMyHI5iqXjN91byEDTyBdWitOBWAETzIkRDgMawEDhLRnxgZhhRxZBWgVBhJ0OKdXs6cTu1S2H6JW7CnjfXjlQ8dOOxOTnQMteEnLwbgzCEVGOiEIndIiKKpsCMkYE6NL+3s+xEpeoYNqNA7WIhonpYeqcpGxzyaV/RmX0kJy305jMx0LV4pR6qDW6q68nvxQhVrIJLdW36kkpHpDUtg1N+N5mJi+6q2lDrAIZ0uUgNIBEIACQAAECMfnMgrEDQGCUvTIFxYO3dASMInArPYpCWPzXjc7Op+tmytni1LCpiKNNZWl9yOUyHw0hc5k8zG4Se5lK7vyaSfHNzc3qoFbMzGY8EoubNhu3LZeadWZU/Pc+XhKczb8OXLXVf9oc6UmJq/5d4xSv4fHbk9aTf7A7VppONvP9pvy5jZAzBIMRQQjSSRMBwABLiQ4BpQJFtLgMz9MyIAI4kKPYPwl0ZhsdIz3icJep84jOMloKRHjuO0sNygDkMhQcIa4pT8C92NBsFaGsJRysctEhEfwMOrGjdlD0WH4vF0Mt6tW4koPa6a+qbgcbSDVrcf7Te0Ne8X9dQ7rzHxD/x9rex3cRRaDQ9F4cZFq9XVirSIZjKqqAAQgAAAaBB3AyQ81wwyo9YRAEQVi6qnLeqZpUPE6iJ8cZO6+LqzSaKtFiMFMSPB//7smT2gATmWlDDT0rQjYv6LGkmlhJZeU3tPQmCSq7n5aSaaNAYWZAha1HXS2BY6YLuKpI2W59hTbMxijj7KgKYTREqiqn6mInRTGJpb4nT2d9mXtVUjRcdHa9gaaP5W05oL/N/fpGtIur87ambS5bZyiSS3ZytgjPKTf82vnTW7+85aMFfTQAqgAAgABlswdgKhgHRjLTC6oRLOgVNWRNoNQZJBoUFLHlrtwEmuM3uIgPjNmFIEJ2IoIFyUpJTtQnkV9IA9Hx67R6OikrTd1kZVhjKTjJrenWinlB8yauZCGPAnlCkE7q1kc4lE40hhK9Kk++ZTL9xi9lDsy2OrZX7knv+beRhnbllVH/yY1Lbzxal+/78e+ApRT1RGCMpKmSW8e6Gp6L10FABgAAoOECICrMi4yGi5w8wbqYG8Foi6QCATCa67ZbaG2vRqkhM1FUsbui6qSieHYfmCMkpzKq87t8rXai0vr8vBHihpe7TuUO2+JcWFVU5yxZXKXHSPNzVlCmZSjaPh7PJJMRJ4i+JWhnEWJrQ3ZLWqGKsxezjK7up5q7ax1yi8xv8RY3QdKDadkGu5+2QCQQAExwVMoCyEMMrCzU2Mw4MAQkYbDCAtGiVHgcFBwABwqoXDrXwwScSApUqu7qWdNOMqbRu8sYvHe5TMozwf+WQfTUkefzs5EHn+aibMpf1wTZYTBIRywsXYpUogH9HAJ6qIGCPQ8PgmnMDyDdWJxNKJ5nyQAPGJKGlutYNuiyyatQmjsRTZ/45/nCbVPWa6UpZdhBsIZ7w+AxjmkjBm+K8DMUoAvgxP0Ees+aAGhDBAqCTdF0REMgPZP/7smT2ABUJXs/jTEvgj2q56WWImFW5eTkNpHsB+yynpZMK6WouaXZFsTBMjBwaP4soukeJjLePK9FuWxBVvNw5GZL1pjrwzNOC+mfO3tpwUIGoyKLljyrAQNJRQ+oXRJjVc8wqlHvX2dsnCT2Y1ZaSW/sybZkZctr/XeULeLDlK7FYhqFVKJoys01//dEm/20FPFvyAHAAAAGMOKDN6DxS3PouAIpCkzckMopBK6QQhcGYwEuxfLc0xHpkLTlgGFMmmmAFYGAKmQBBFyIGhxQ7FB6dRvkkjn2j9BTx/FJbkvlwz9sPCx9z06eyEon66i4t9LXIHrhshfi0t9Zs+vMK1rsQuZxwzcvT7q5eTO3xt3gGwY+0jJYvk0dOkRUk9QHKj5coypMp4IS9LTg1rcQxAXIUMAc3D9lTLhVAW9UCAATBYAwBBUAUHCLUjV9BbguMUAN6rQVAUll/BAcYdGljzT5ppStNmwYGWrgmUvtH8XMLUVeb5chHaHDVp48XMmJ0BCmKmIsoxFAcGpL9UCaEmeU6zwsruRlyrnZw/NszzW5xDqU3P3K9/K+nX/+/n9JR1BANGz9w9xmqoAzJhcRhwBHTMRo61BMPMVcmQIY0tpZSVJYAjKXYcCtbiBelp0dkjNWUNmir1q7h9yVbnnA4eXDQoKNHkuJXWR9SKiuuCU9hLA6FpbY//kpNEaL0aU0WDjaBnTUPlGvDgW42HyXSA6QlmQnVpzUd8oJaq3nbWUE86pNVrUfxMQegii4OBL8JXnuf7eXY7U2JEm/yuzPTZ5+rfOyNOpAk0oCm/xH4Tf+PH5d9WS7AKAADpnnEGMDmo//7smTvBgU4Wc5LTETwf4r5+mWDlhWZizZNsNWKF6znGZYN+Gd6gWKcsHpARQaYdxLIsqifkwqIL+QS2HzoPC0rFYcA+IXIj34y+ax3LSo+hXwvvD+X1F3ml1o2zazlNYnT1k/xn3YsWGN3rtO0pmCYHSxpDgsdZFMwJjmTPONZsZERGsLsmXP//lcnq9TzI/M/pbZQhYIaGAbSrLR7NSoQwAAAAIiBhpsABCzc641CoqoII1IDEQQsREVERkJBIGps3WBwgCJJlCQ6ibFadbwaYHlDFGJOjYkBeRVoSqUivxETJ8RozJBZqu0eos5hodFwhiRveLvNEfZrkor4SAlisxSaJwmTI1EZlDhc0TzeV/xORiSjSfqDmKYYl1Be8hGe2yRD+9Bec6rLKR7/C2ul6v7u+99ZL7bcveVDJF8isTq0O5iyu4lb/6FAAWkAqWQmjXBTFRTCkF/mEtjpUIgP+jCr0vOt5K2pBD+SmF124SevJK8KjWDP21DoNveyJQyttagLmiPSeRzW1olD7CiISqxaTY9MSnr23tpqwS8iJe9bdUpoth2plaKwZCtqgQzjyKZSwulSSt5ZkhTDD1POKJXt6c3v/1Kpcx3vvhKAYUOTGQNB8ykJOLTjGApD8zljGgceJH7USL2AkWZK3WGWbsswnEAqHq3F5qHI+QYvCMlQRV/t13Cciv2Wyl+rDM4nJz8/FWbyYFj3DzyrZg0JGXIh2evmJSTu+TB1UwpkJfSE4OFzUJHj6FIq9lLTZeZismXt/l2+mM/VVxT1Zwfn9x8C44c+HyzHfLNwPu/+Ib5q2+56yzYNPqiQcD2IQTD5Q//7smTphgVTWc3Lb0vyhMkZtWkjqlWZlzZNsRkBkKwqtYCK/VpGjEXmv0H8KPDfXVyNNoueVteWHA4HCyR8NEi5Y9V4VXMKdJ0HekDuwJS3Ynfn6epSX7FJZp6fOxY6AkHczaJHxHwTyaaEmFnE8aTyzP3c3/Mv4Y0dcd8jAmO+jcBiiHzoWb1AW413aOUbY+YEgAGTiwaDCwMFZnEBm2FyBBsYgBZpI0HTlcZ4G4OPRgwDgQfBgzYfdISQDlAyIohF1SI3ApWTBo6EmjdhwhWWREYARCxhwIl9QvYGIbasfdqleJoEqQ5mCBjBnXiSOTiUtpbiOcXpIagoVAqWCmXrneuOMxau1puF0HakrwROlGztpznyuMMZyl0fQjxWG16tuRO3ZPDses+3B8cECvaYlkifmGvqQu8fKgjwVee5yJyjcXZ74CcWGikJCmzPKMx4cY3DjpAb0exTPm+WCn425Yc0Y6JYUInCUneJyzYqDPKedSGQ2Yzljn0r0LfR5X82r5j79M4/eBhdRivaXb1gBgogAAAY2gdBKwQAJXu2sYyHGgJ6lakhiFQ2KEiYr9OupYaLLwAtHiPVlWrydShCjny3LVV8DWd62HNIRufbZs1t1yyYX4xv32VZZDNe7n58jLv/vac/3uf388P/jNX2of59u7/3YaIh8a9y3f3zM2CGZUY+mEPcnsZIIMukyHY8HKQHYcM6ZwAvpwAUlhBAi4GPhYIVC4GLmnsIxpIGCUHT7Bipl4JUIMFyZPKRkAYcGuRoRcNERRuKyQR0AkAocj87wiFa+xGLdravPdSCMuDyKL1cAhD+6+3dmmJ0l4Hojv/7sGTxAAf7Zsurm3t0iyvKGmHmWlhliz+NPZRJrq0pIYGauXi0Llzkp1dJdXvSD4VOVQky1XbFohYmLfW1elpTj0729T/t5IkyTK/uHYdHskFmlMQSqaWeHZ2aKFz6SquOB0+WdAsQHGcvcvpCKvmhKtekJXPCkHIEEnpAKv8lVD9D48nx5ZmkfbMI9eWOtYmAABo/J6tCbIDCSRdxb9YOT0L/bh2W4YWb/8lG7XXrczLDmhsgCedInELmDnhvK+/kZFxAT/O8sMAYYiJohH3HPjHvJ559n8/gnpMfx+nEuhccY+ft9lf+kc7BSqfZeVI7HgP2hl/NwBreqoAAAYCBYKHJCGzAoGBiHC4VWwYvIZhqSgoUaQbLjl3IEcllYQakSZluyvk07LyAkoDS4LaKmtI5CIbeAAqmkQpjjV0MToTNhkZCU0d5Iwfzl3BCfRNr2iwwuI5SkWj487CXkyBq4ftWEECKuPUYmPPLh/NIi8vrtFAKE3imycx1gLDewCWZxUWLssLFqBd3o6UJxipZPPUS6ttVOdk+ZPnnpbcVdEuholcV15YmnGH3ooCEOp4+PDR5M9ZqaVina/2/AxdaOr3oBgQKNESZSehhrhvIUnGfTCkUMVXkr7eNFtkqwKhIDiuA9zegzXY+CZFlPdqqk4I5u3lgTDao6Es9l62c1HzNwr44XZa0X6ykPxZglPpREawLAJsqG005EAgKBhi8EkohMIiww8ujBoUCoBFBcZ2gRgIMrjLUCEJsrpacgAJhwDJBpWpiCAFMQV5KSywY6CoBmRU4wD5NYmwIDbE9Rx+US27LhoHTj5X2kxUcimni//uyZLsDBkBiziuPZSBXhzpFPKKSGT19Nq49mJltLKt9g4msyQV3Fa3SdesUdXobAyNXcSC2rMTsKEIN7EemUfCbBnnQku60Zf9ykPTdlqU+jgdYVY1Us/WqlvjIc1F1Z7FzxZNVNDwkqsjutqlQDc9nEJuVtWrrm4asthSzI9Ga1FBr71EwzrmPJpylYaMK2ZyERSP79PLpAHBMBHaOIqAUZqcMgBWVNImpSbBVsvyTtV08u5EoLwrxOq5vM1c5YmE6qhh0ixjvM3qa0EBNy6oilMVN2gTa/2tdl64afWlF/t1+2lt1yp5M7Ovh0fMOPZE1GAAYvCQVJoBAJj9pmAxggWYEKRwUIGTxUqAtWYCAYBBbkuSjoY2DafUvWanOSgArCjymDTaHREdATXI8zxa8m4CRA3lhGaVKvoTEL48ZzLVZkuMguhSOV4abn2uWBxjZYUJXWD5JO5Z2poj3D5OME8E491jQZ5u1MqER7Zxuxo+DVJCpFqySBjS0lFi0UHmFCFuVr3GKEoZSFSbeTbIIlRQYUmH040saLdXSG7iT3E4aQs64cJYIMIYNCIn31bvsHeu7qFo/TCEIhX4fhsgUxIpMbZ4Ygieuo1Yo9bTPLNfMZrg7uQFL61tcRtUUdtWHvQGJWrGUrtm3e7SOBqqoxhRoPhXVeGrWJ+ItFtE5XRS/rj66GXPFOwJgACiSgMKE0yySzZTiMGhAOBhgBCnDsmZuBKnIiCgYDC6yx2Fg0DDTLJgYkciIXdFQATEBWUwTBzNAPTSSRbsIAU6Ftuo6O6Sie9pb3ND63cMCDI3saDA1COI8T/5dELRTTBPlD4TU//uyZMAORi5hTIOPTcBShKooYeU+GXV5Li49OUE3Eahlh5S4dDvup2J8/zHVbqz1XstZE4i96OtCcSsyBYYj17NEw2ntJrSHLEaBWDXOmVL61SbeiYzMm6SVr3t4m+/paDLF/YzLPo18SqMJ4lnfaN0ybG7UPsLDyG+yab20l4SslSBW3w/P2wAEKBSYwSdJZI4uz1MGOCMM8d8MhVv8eKqqvk4w72iS1g6kgCrwUyocWsJgYOmVDY1n7Um2R3YHi5Su6eiru9X3PpLP7+1xIS+/Os6oqgAgAARMCASEzBI7ABpN0psxILwwfmBC4YN4hhsIsmEIVEYcBIEhiMiMHmGwwr1GybWgvImEiq4MdJhkFgoBgAAsSDgMX4qTgIFkAXntoI/F8eIwxUxSBOXGWQnH0nOlY6T3bPQLJ2mERTdODU+pw7B17Q8Dmb0ExETLNKFbVccUc3B8ONGjoNHHehhSIHQpcDLpg+ImCmvQ4R3GkHX3VVwQmzr/FzUXLo/M7aRUGhHdyaSZEfKfwbTf0bAEIIAkluJalvo0ImA1S8oZQyX/D07ZQ6NIy5iHoVrxT+QUDJubktT/C5h5PiM5yvBu87GxxqjQDCkzIdbY5SNpf22LEASFSMWUPsMSr4pZu+hTFcAAAAVAw8HyMwpJNCOjbiBzxozMfKDt/cxEaHgkQBhg4MKALtzihpQqutMFAEnc1pcLpmGLJpYKlWpi5Y6BtQnYmYGIvJOFpY8u06DMt2HkejjIQtKCj6lo8lszZYSWmO5WTz8pzq+WLh9FcNy/FNV1Zh//h+D/QCptADfuVLbl/vvc05DDLbOT6UFFZ9hv//uyZM6CBdFaTDOMRjJTw9oaYYJoFdWLNU2w1wFTkak1laEoUDbci6WPk/tvjl12Hnf7SmSQhiMhGMubd2z/d1nNfptCAgoEUZcl5CIHsAhZW9BLPMVa6pTJtwZBqEY32bAYNEfFy5zs1P1Aj8vd4wyzZIuLEr1VP/G3dXwO9izRslFTt2kBvIm0U47srZpTrrbE3xcnD/IV0CmAEgopYwBomAp9jgI37QvIl4EKQfNJrrGQqLLVjyBr1xRxSkTgTYe+JaL8qCeABAAMRjHj5FljlolQ8HyGiZZJUqpsPgW4iaBqRVNmJ02d1nHZZgYs5mkXllAg6bzFk5gYHpoWFoTxLGqbJmlA8rmiCkWVVOqqRQsmuqap0TX0HUYHGrX1IvWlZkt0NTvqNz+p7GBdSdIiikVGSYpBIcmXi0wsAAktRdwqECAFMOOiLDCgUicBhQ4RtHoV2S2anSpI1HEOi0RGg6xUiKDGDNi+BQSCMGKFHJE7h3SQJwtAoALpuUU002KAyR02OkNLiSyiTi0GMDdBkC7SIudIsxUoWMZmkgUkHOGBieSSKqK1rKtakmsggy0WqYx0jVCxtUgo8X1oIoNZZoo0NDWizsxsi1zZ2ZPWqpTm2p3rU9A8XcyLjukYG/PHExFtuAAIQEAMBgbM1DpQlmgJ2GDYymJSLgSLDVULTIlRDcEQDAolTe8PTBYEgsJBgaIIQF5hCDgVDcxELMDAgcBFxQuRqoGE7hFjKAGo25nxMJJpuQodYFGNCRiYrDjdB0CMWAkT4BWDTgLjP4istaVxZ0WCKdvErS+jKEhAEAOQAgiHGuw5L1/u8z6SxiHm//uyRO0ABSZcTtVqgACpC8mzrdAAIo2LKlndgARnMyb3N6AAvQ7gt57G2jLEINp2Eyu7FrF6QyduaMbAWmzsDtja+3zE837euN6h2pIaR4vm5m/co8ezVEweH4uzuZsRZyMcOQVO3bn5zW8ad/oCnKtNM939t9ITA7aO3InX38npK/IXW7at97r/1/zc7awns7lbv///9SWT8rkcrieYUEAQG91P/rVb/u3vCAAABkBAAACYkDhkMjbQcwmrCJlo2cSIHjJRxySY9wGwjZlM8ErRkSUe2CPOVB4ePzDyMyYWB2wtcusCQCE0eLCpUEYAx+5Bp2IWGCwkywMiIK5EgcQlUMCwh66dh4ObmhFllx4exeHV6zMOLgacw+idx/hkKVhx4us1t4xyHXaZU87JI20yJ0SI5ZtNeXoPtf90YnA8ckO70XgtGN/6lt51N4g7ACHortu+L4zsza5p2qr6wHMxq3dpM35QXcd2ER2cS1gbcmadnXqnN3K9Has3tO9BHak1L5bjP06wbbNo01CtYRNBfLfO0/srvT1zLtPWv2u81/0MV5UrY4XO1O87/xdrcakEQZQzTbv9ge7fp+////+GQwEEVEABAKR2c1IyMgiyEQiERkDWmThyAhWYYybcYYUkhKGtS5SJmkcRKjwFRBBL0xYz4MGDis0AKGCgCGVfQIY/72Bj4ouLBrqboTrSdtUx3kXXDSlJeEsDZNQdl5XUh5plrdG04eDb5+ojFo/KKBZjQW/h1xLeckhiCqaOWaz0R+vBmMM24EkLxzkqgeP34LmpBZpanJW/+4lhWsXJyHIjXl3OW49GYHiETjsATtJH//uyZFaACApj0/5rIACx7Gr/zDwAV5GLTb2ngAGurGv/nlABMZE78NyOhws0OVfKYzsS6vQZzExI5rCvSTlPYxjU5PzteV++kCurJ3iabI3klk9TRe5XtYxlw6PBocjlkZl8x97eEbsOxSyyWRygwkB8d//pjf/lkEXNWaJZ0MyIonEqw2mhWjlNAMFDO0ZXxIJSFBN1cV4FqxseGumXJ9KsHcHESZlkQ5HoBWtL1zXcKHdYV7IxqNSoyfEGiHneh7KwK6Ki4Vavm17ChPbMEXN52N/aDCjKG+tsE76A8aV5neRqyQ7Xmz8W1v0992ngS6tvMkGeBitL1iwZNZ9/TdMVk9/8+tK+St9T+s+PSlau6esnj71nX/tRgmvV5vETWP7vJWLUOeaW+AIRszAjAAAANH/TMdMHCRQa/r2JphQcYIQAjRCAp0r3acZOajPhmQxzZNyJ4XgFxXXpNZmR9RAlk9mLEadmRcXdcfwZt7jQKUwkIls7V76El3vtWI50kZkQ56cyGN1n0JF21EVqmy3ut/2YH8ZqopJtOCrmpuMwUwyqTvGM8FVl6oZqyHipYkBkOn5gJ2LFniu3mVN2TNLuWIOYURhVR9QqRrRcy2TmpI6Nl1IhtcQsblw+Vs+/Nrf8OuhvSBm5zFKYWNAkpFxA/CvEKOu48TiNxzZjHKhaJcZJ1H+ZhwshHEXMu8wo4iXMW4g3bq6Vfc4oyHGDKfZKkEFqjz92I1OQxJ2Xlz3yiqJKryo8ey3RqsapmaYVPOPHNQBRSrGyWnQWdRPficGG6ggxISAyAAH0Ck1dA0OIg0I3RjpawlPD1hK1cZVAI7Tm//uyZBABBYZe0uNPZPBkyys/POO7GBWLRW3h6UGELmu88ooxqz3NWqRWilGHWxjVCPyUf4x1xYuucT23iEe0DzZjezBPjO6zSPl387YE7DUFo0/dxq7krmE4PHVaQmV/BeG+sVYcPLdfIG3bX3sOLiEqGf8/T/xisX7B6SnqHF4NjIKHFja1rqSi+EzLZ5VxZ+FJ89idgTbrzz3Y7qxDxhxhMM33SswYxcu+DNjfWJXg5RU3tBot3uYiNqkQAhOHoxDKCUsZGC6iTpariJApl0t1YsWgQaYhKQ+zpZatX3eetHzFsXfRTc9NfPXMODLa9OJTdqK73a3oSY6raG81/Y+vfKNvD7flfpl9n9fypdVOsZb1+oIHZt6gARZGAg6/YLpRsKABgojxbohBDBxcSkRaiWINJOSGlUdaew96IHrR6iqlU5WIYRY5+9bZ7kYhYZLYgJpF4ysTT+Iu5sQtsMXN5Zp7LD65gjVxqj5ipluPLb2yRcd4TLdttjH642qoXUuZT1VG6t8HEKBZyzmFGnY2pyg5VRLrwO4uHYY+GXSjSDfR2roW37EtPdN7M26f7w4szMpMbU5cXKIiSStqzq0zHJGJVa7qCxVvuLDpDcK6zjO/mY8Ij930BLusVSkG0iCJYGdfKwCuAlC0msCMCkP6jeJUPSaMiRUEV7E3xjj+xUArgw58iwRRjpJo2yPiZkdBIJdW7VKnvlf/xVs3vhptnqVn9tdl62Ut90qxuuqGrXCgTshGdNoNXlUANAMAOFXdbMAAARGIg4EAdtSQGmBDyYcDJaJYeOIDZBnBasKZ1tt8JpzI+KjmoIA3IJ12nPUE//uyZBuBBjxhT0OPZUBaxGqNYYU2GTmLNy4x90FXrOs9hhTdvBpAH7i2tOeum8nylYaXhVnZo+IUCFvTnMrYdGx9oW0pYVZE6rr1mbl3opmiyBN6li7wchRjai8snohCS0taW9d5ZOjyEJMPlr5Hy4BB0PIHkNNRKtVKW4DxdZecHNi6QCwewDg67VKel+I5om5pIJaqt0RytKSMKo6IDJSeTj0DJHVkxU3xeu7LR+oHVGr5UVUK4gONIAAgLjV3bAo1KZZAReIQnvWgXGH0TC07My4ULAmNWQBoAk8XOLsmYtFeyKuU2wcA7EiJUXJE7O89PoA8LcGmpENi0rBM6yAyUbxGsxADCrmjYiGohUwFgCAOE1QyaDAEHTBAMMFhUgAC/zBAUSrNjh8SCSEBbkvIs91G4KaLEfdiT/NKeV4QsV3HMSiR2bby4Y1V7zqNBHwGQysSF4el3+78Tj4cZYgqfyJDWM3obYIw6q7IRVcPYHkE39od1XyHYHflt0xQLJDD7QF82sSqF92JKf9MI9HfL8P3TYO1dJ+KvMzDTsDjAhLbItdSpXV7n62OciKb9aiu94bob1ms/fodlxXbjHhNpw2ohzTStI1rdvVNNyM0Xf+v/I7Kf+snhAV3UAeriALFhQG/4cIz8VjpWNkPnXgXMlEaagtI66MfviMScqIHpzmz3SRv5+oiEl0PQ5kM5fN9f/9fqW/i0rNuuY+v3ykTr/M9WL3e7JVRVp2uLABM0OsMDK5DGA7HjyYCACDwBCRjNGnGwkuJoRKHS770QTGCYBpgvW9EVchp8DAgMgIjGQA+s2H3Or7hWoIAqdNhOI9k//uyZCIBBcpgTQuPZVBVxGoYYYVKFa15Oc3liYFgFCp88SHUknVGun1Ute0iyy4h1RW8Qk9Dy8g4cYbg3+zc503EcIVKEVn4jx6eVSp/NVP/DjlGTA4b+zlnZveCdMT+qYDxLy6x6tGjUl9eGCswN4j9cXEdlrTOW20tU/6MqL68eXxp86fk5YUup0l3ZW7/RHjuS2GhDiOIiA3ABEIggupSiEIwuHglQXsfk/AqNIlwqGy25kNYeqrLBU/sVUCoTau5ppE0Rtn6ZZlj3sfijzFa2XvLlb7psysWEwGbQklsIEwqi0WU2dfLEjCxa20AAAeCAAIE1SiWGEAIZUNgYmUAdYw0NNQPDVRAsFhCh4qn2OSUwM+7SkS6dqFNACWdVN8WnH1otQNBmN1mDStEE/DIQ91Ojk66P/lIdKWLnkHy0h3op00iC8PWJ1ZHvQDmyoTjtfsOmbTE6ZTZyZm9XK+xB2wNR3qy33X+U/GN7bWnXUR5xT3px3baip+JvtOZ39P60ihmYFB1ecda5de99XrelRN5g48owISUfWCoonNEAOy4olK5vMEG8AaIWlQzk2+pCAHgtQzjrO8nzXrg2XzciHQpFReaOJmxi8UXfVR6utdpISCAlwU8qgP0HF2/4TWAqjBh7mJqVEm9JP+lwgRl8/01BAEIAAgAEceokAOODQsoDIWhPZuYgCGT5xpg4YUDltgqGIDpqU6QgYFMNq/EMFYDDapAgWCFx/YaYfL8Lq7Ymh0aMxa0Hw0ToVTaB/EArTSaJhj/kkq3WoY5PbUba4XQsRGQwJMxdjeoz3Qs9l5iPqrLO6JNKvbdYQS+jYdq//uyZD8ABXxfzmNpZdJUBUpNYSV0FM2FP609MolmjWk1h6TYsav26/iLCGd/PYili2/kHOVv+z+v/GsazmB8/N5itCqmvjINIJlhQx1rNRyIYTnY2zEQCmIYbURIbVEkVFxpSAd0sVtqq/2qvBwp25DDUduVOdYPhYLR43xBhdRNaKImKqXiY5W32b5HBTMggZzJFaCmEbDiusXs2XCrblKeS/2/Z0n4+TCQEJABhJIAZ2p0MBUUFUxjRS1W2FQgCJi+AIMrXEQB0XtlboM9UImLsSiCn+kgpDwFuPGo+i9IbELNVDzadsatYzIKxXZfSQJPpKEs1QL3zYoJMlNr9JK8ZON5R9XaErc7lMVxpDc/sYe5r3Vp/9S9puEJEFm4WpnTFWx7IvvbSQZNLc+5fzN+f6nSdZttOTmunJg0gQHBCPsKLITfmSevb/HQuf2PJMBswI2iCC1YBpbXwqcWqy4OADuEGvWQvxRtaNeEZhjGW7nXof4GoMAnAl20/lm4+n/2umFWjDJxQFAz+wgxlytF2o4m04ci8R++7OSF1MeFl7RIcC8DiBTVE0YIYiAHY0mVDnV1X3IFAoKoFvmFKzA+paoqhKoiMsXu1E7X3y2uKuWSiZDc38R9RFPkpTYSCEijxoHVjT79/XfakY6JO5rHIcO10QFDk+cms5J2XixY4NTjmHEnS2vJfpD3Ng0yItzg4TxzdYi31REjuEjXauJmYU6TOrzu96xztjh2/JlU0lY9NITyX+27kdl9fbKimrxgrQgoAoW5jHg1vrRYg0hj+72KKTuwKfnEH0QvE5tptDS1YLnwe8SlY02PWdZToTaF//uyZGSABY9i0vsPY0JeKxp1PCh6Uz15SYw9K0F3q6r9gJXZmCL1yOvuPp64assHBFube+0iXFxp7+/9wjGn9fxFXF38V7TczJ+57j/iveONalCKrmf0qOBnyHd1UJuQ/eWL9DRmhGdnGfsxUaVAVAABkBfQ8HTo0P3KTQw1lS/TWL0A4QvEEwHKM8bc6Pqx4yvOie4rJE1ujGX6pEmatMkWWUZhzp/YR8M43V3zivL2n6WvLVRocB4hT8kiY99VItKIv/AqSc4pF9Ubv2H1qnRPiSIQs0oSx1UXXhhcNbakoSVg0zJNlBa+pvTTi2ceO1sVWfJk++nieW0GWPeOvxWJow9bEIp1EGIOUpkBLlJoCIbOGAzmJedgl1vnWYG8EZsPi/0q4vybh1RbCSTTmMyJrps0jh7XocrMHAILMos6jCkQWINNRFpanpz+revtdX7Zn0d9era3p82ri1Cr5XMzaY3hqCQYQQAAYqrVyEgdRLYoTS/ho+AhsbPRyW+QopL5bxdx/Jm/HpuipI2/CgWsZ9tsNj4tRTIPyITRrXUND1eZGjGTS2dNXywklSpOd8LROYlkmyCS/ChAnEmCKctJO/NhUX0qxS+yFLuUCLyec142kt+kuy1jQ3ZB42no8vTDcdOpxnNhLUXeilkktFgO0Km9Ysc1JmC/3dvSiiUJG3Ww7yKU8GEsTQJkoXKvtCYXWZA75sHIr+7qMrL4rXvNRrVKPtv77R5Lo5jq6u/uuvSbuOgg3fpQXX+YrOa7/b+nt7GdEt1zt+qLkfWvPvTvmNnBnGMLDOovuDwK/H+s2i0kAxImE4gELAjFxs9IVSBi//uyZIgBBQNeUesrNXBdCzrPYOKMUy17RayxFQF4Fup9ga3w+iBYXuImliJfpVr37GGms1oaKWx+i6qnIUKeWYBtb4biAvQ8njIlKU6aF9TLB3XLRO7iayr0zdoQdD1z/jenOUxVgOmqBpmVQgrwzeooJ5p0rZ7iR51s61J45nNHG2UUxqkFiIw+HqBZmzHXKQQaOYu4JCE55FixFmaWJBrK4q/EzawPhZOhYZjaWIAtjrQJJAIxlV6ggiLL2lDukOM/Ow0r1ib7bkkXSH/gufDYx0Cnb0wYbg920U50p7ynUQwbEpQ1iR7TRufbbs9RFKMNGCrMUFrHK9BbIylLix6mCo3EVrtYaclxoABwBrMCLLAqJAIOLwlqAwgBUAZ/HkBAMytEAAqZhG44xNf9pvYlK52qh7Qi0q+Gnm/UGVHnZaLyyAMrXTZuOScZyK+7dn96iOMRSZX92i3zkr10c+sopG4kJjEms9ruU7N1nTd/SKG3RnaBgqb9WlqxNKNlZwrTDX5MzO35sap2xU+9Zt744nGMArVIXziqkKsWJSoJ8jouBABCRAAyJ8IMIvl3S/jvx84bUNBBvoI7CVLfy5fdsaidqcxM4Ujcm0js9XIImSUrTp3+mpgi7eLPE0YyJ7ve5wdGR+B//Qp5lOH7qrhOW+JNrn/wr5btJ+Ir9/X7/lxjAQVBCAZgBK1oGFACoUvEhAF1RltAG8CwEvono97m35lH5nUchExTcmmUusRLaWwo5W/b10zutigmbgUFLhFtbfYRNwVVWnh1ZrpM5R1X6m75aZmWlzeeDbOZflnXlniPEvRJt5Ln89RMyfHNSIw8//uyZLUABMtaz9t4SfBgJGosaeU8U2V5Oy0k14FtqSjxhgkpt6lnm9bb71fF0oRIXSstH98f02vKbVRIjO+koKCgR9uDJ4nYZEJPiKtfR24lKiO8Zs5LFBptompPw6tcAZElqiXpgLfAweiI9/zqKWnDiZxsU47MqbI5FdpwzOxOgyoyLM/9uqd16C2o1lW5tqW6MjceZ7KyPd/6edXe/P7wX7aKsNTMSfwJQAAAACEpOilcgeApASSYBJn1mbmgHQFmruYQjjE5qGUBhQGOBA8nUyvwWvtfwcfyKiZe9mWbYKBgTmjxOkUDZITQRHtx6HaYXW2Vqx8jbFH4pSqS/50NN8FUcsqUYwuIX2iR/vS84lLR3aSyf65FlrZ+WDzslean038w3XWam5NdBKymx+1nnH1U29+Ik88puzC8umip5NcCXvFqUgkNXRDBJuopQQhCSZZ0JQfCYfYLSCAF5HVXypcBAYF+CGakirqeEFGDxX9c9A6xZ2yFIrKug3dkpejLKHFOyiosVhILUk/pSosohxiLK9YZRF1VHq0uXtWwWt1mBgfc99P1IgMyBJEgkBphsNiMEJ4BgHAADBDtOCCVKFlpe8wUBIeh1WQwQBwSBXSJgW5qAaT2WSBw+MfBaA5skBcH7JeogcNoqy+hI9WnKStQqJnhw3sBCoDJiF5USZs+mfKfgD5gsNZLX/bTId9vEMe5yfzO6kgsKOneM19QLkROmK2QTP6QCxuU1AqYxYWo6yJRaLCPHsImxNgLP2jkmXRFIQ1VWD9V0/ND6h0BC3IucIpwzZ4cAqWIzY3toi4qUgq8FTpdqk9LsOIMAFCU//uyZOSGBOpazds7SfBi5dovZSV0GFFvLq49NUGsq6bhkwqQ0mUGUEiPGGaBzwiiIgICbsnehpFuSps8t7IasifLOaV40Tm8K/FF0yl3yrrp+f2cLtWRpw7WRYhz73nYdyDJUOZrB1dEbcOZ8I0l9S15AREr1GjSH6qtz1R1pb6T6paYzR2Qc6EEAAHqGh2KopnlCo4FAacZWRlUmh+BkhGCDU3igeXLYAxYeEztFtnaSUnzIJg74Qv133V6t7nswoUlPPypMIagMHiFsyNULUjx7TLNchnp9HqkmDowZEd6krl0eFRiB+IGLcbdi6sxzS1SxdfjpVxy5VTNo/eQ2L809j6HWmoJbFu0Wb6ZJE5QeioizsVy06rkTvYxJWpLTpyZZ+aRrBCSVj1xD4ERwUiieQ9Q9uDaGwQss/9sAKAYAgJQkWXlDXEYGexkUTM+UaMN03RHTicNNbmj5KbXSzRqQI4YFGCTccU9zes91C7GidqjDKhFxPoqGMvGEew24kFo0UMynUjjGO1BBo2u7PoarvMZCxIuNvuLNo7s7NVuRqbZSVJ7VjHjRcQUCHAgFRgJMvBjCToBAzZDExcyOTPFBwywOaSlLrutKszWgHMYDhDK84PkgzJQYgdPz4gRFV4C7gB1o+Obc5HQkigyYH92SojX2laXX6KSvMnxfO1i0DZjuLHLynoesEDkf1Ene3kQ3cva2zYds5n0j93DVyjCxn5aNoqjqV1ObLE+S6IqeNu+Oh/HJwvvi1dDu2j9t6rqxctzTlDPovw8rqxysdCSun6uZt/dPByg+Xp/9RyodckhhQJDUtaYIxDkPCAoizg0//uyZPUHBaVeS6ssTeBuavm5ZeVMVmV7MK3hiVHOLWf1l5WwuEAqXNMvpZJeeQZU6YN5guyjQit4pphhfZscyzfZ3X///1F1PCW4V76V18vVJL5mcxHsW84g6kfWvKTvsr2yErPVZ11Cbsoue6oi29iNkbo3I3S9JP1URclBzXoN21dSSjoIh0ZbvY47yQLxAJZtIQlLfj5gRtpKeRcBdjarqiDWIFWJCY66bO13wu4sBLWG5bcdncj/KNwhYsYUe8q5o4OD73FxTi9t+sdIa7sKYvLR3VnDk3rbkIKFD/tUnNnpheMOSHGyxxJHfX06+1PhRTRIFE+eluJopEk/uI/19LGXEUnJYrd8lkd+T9QuYoftQxlskLCYqiWqlkR7ZESx3WF9CPIUBCDKHhCJWPWzO4Z/mWsZJ4XBvrDR9ZqYVkTXmgao6f7IGApbyxApBKHAkDQJEDuOcesub6zGh8+XicZMtWYZd3Z03pAeRKZgK8W+f5OHeF/8KdMkP3CAAzuidNKYgWe4cX/10V938oiU19E6wjNaCEL6jNx7hkDGP24h2QZvD/fn/P3mAisi77gPc+Hk3qykBOcGCpoMdIAEAYgAA4QCACgw6r0rAhalBYBrmgMm8ENCQsNQRPWbdmBYPrI+O9bv+n5DsWyuoujw09VjrwJwOG4hTLopIB5U5LhGn7Wxehbu2pyWyjyi+oVztkgHZ2lDYe161B3wgbt/RzZpql9tct/s5fokfTKBVq4ma6ZMWvnSuXhLOoyYvoGoeCs5rSjq6hLKFqsxhheFGiG8TFn3G93llX618QcKOCG+RudpIgpyREEXSvdHi5OS//uyZPeABipn1XsMffh26zo1PGa6FCF9SeytNwITLKo1k48YgrLunQkqZMaSIggwaXZ0MqEScKlU913YvA2PxxtqbmDGFdMStZ1XW1bh9QkeyPmLQys8tQiFxS1e5YkpQXhc5Jah7sxE48lwtNChw6i+88oPxrfhljU84Xhn9GvBNyUz4KGOw/qnEAWNQ+YLuFxESMT3J1gHIGEDJYgAAAHdLDL2MEolhBYBdkywwuAMAJ90yHSItrLLmdNpWurK795kzUWKZZo2lYd7OMQEq2LMnWV5IXEcskxV83/RVwLH14sRiPdctfwZTnC1+MNeqNE+yT40CxbNurlBBH+KiDx/ANyjoIe6GiAMaB4vFUqVAoKPezQVXbStyQVdONdxmPrw29PQyyqEm+AespAjBgAAOIAAAKgChBkKF5CUcTacdko0wDBgMjO0yiqTiIPc79whM7la1AVG9uGT0Sezquo1Lx5TcPbEwWGFCDfEt7ifim8nyT5sSR+e501NRzAeV/vPpwHlYtJNt9GLQE4db3B7MwJrZpxEkY/fu1zyE41zu2Z7oEXvkpto4gzJ6i5qJiEGqW2AZcScBMHx6gaYeqoLFCpAK7RAAIAAzaqJbYWAEbQoWKhBA4eSg4FPp9EQDON9Zs+WkKZ7Lu4S/KsdPcS0Ji2OEbuJ4QY8S6t0lZ+nAYB7dfxYWXphjXf+sqY06l3IgXbzTolQp3NJV8p07akvUJX8qxuh3wZ/KQ7rpp3iihdnVUo7dMwbxb6pR6xta6U6rmw1qb5sdq9Ek0ffrpMePTpaZLOiNTeZbgJIsUqCBQCFYQFRpX0CviHK0o2g0FRM//uwZO4AFKxa0nsvRYCUyzovZWa2E8V7Ra0xeEIULqi1h6IhCE1w812BGZlvrf1MxVeON7U7Og98+Im61DuUCxpQrlCnJlTfFQtwJVZBfWx+sTjWhSRBB24mV+e4Fiet2izf579Jgev6vcW0ZRD9vSwo47dR11N1BrtyQcdDaaj28Wfi9LUZI4YPGeWOmoNNmY73FbUqmEAQACrKZAZnuMsIRRCkSxAf1Ggt0FQBZ0iAvN3nM6C7LZXouNV13SjziLCY3ECCkt6k1terhxqxlYfAvAXTKC03TL9rWnb9Z2HukclVPgT2vMD0X83fciizFrqvbP22Zs3IaOIrxo5LKHDuDfhlniEuSWve62Le9f+F4+9bvlfmjBVA5oSWSHQKaspiSoPAIlLXViAAUAAgQATpGhxdgLjQo7OsElKR4WSiIKZcc/6UrdGuCT2KU9WJGMRS/l/qwjztpn7Pny/8ltRU442VDQmWTGhO9ze+vl3UI7WnyWMF3aJ6Wy2DzDBsDBqxZOiqb3n3JGt5E1XtJ2kwshcocRdk0bAwQxjsUtUURZ1EkjfdaGOZZVlyqikIxR1FSaL+swlNcmg7PSsY4QAAlRaIDMoGLUg0aDAphowFKjowwhklSjSAxDfFpMXtxGkaCv6Jgg9qlwwC5XNUTuYEqi/EvrMmWSLUvyp6sa8UpHmJB4gvmg5aUOPqUOSdhVAIicdAkPMHMMIKeR0MwfisRI9r1n2p7eSGmCvljbVouwXDB/DLw7cxtqsez8FD/3j0uoum6VuYZWB49JZPyB9edVP0ogAQAAQhAAEwIyaokYq6TD44xxBKYYHBYDCJRfj/+7Jk7gAEn1zRayxFwJQLmdxpaLYS6Xs/rWEJwjytZzWzD2CsbZUPgUfyLkK2Y+NzuNvAhBIHVjtbj7Vst6YUxWbtT0YVhjky9+maY//zeHbnx3ly6+SGIC8No0fBVB7r03rTmf8olr33R0xGkn+1Xz98Z/mXFiUcxtj+fLWzthW+M/vL/Pae4kT5F4I1ShRCwSNgynrqEAQABGAjoXABgLMIFTIXQ/8TFg4aEAIgqHj98elrjwp1o4lmpZNgHKEtFbSfMKm2BSJmkELQ85bwh14Y7H6ekr2nwjkbUBtCN4dCOH86G6MGxfcRQ/YToYOKp/EIYthkIBt7v08LWHV/GdtIkrmX3UW2GbKGjKlOcaHxFwNHzwXEySTMHrPFvzzUcPuVSTVRhkCRtSeUFD0SBkQYJVxKGABAADgQcORo1jI4uYAIx8hquEdhaUCTBlDPZE14UFmKIXsqSmNcKh+LjBbkqIRGyH2gd+U9i8RboawH3KpIEQZ9Z4unkPWrxntiLxdjBCN55+JXd0hpieaw39wzfDqr/Kfq8/V0HJaW0w0O6qNmL2hLi6gfFcVw/Np0tNC7LF2Ls6qa5TecAhZ6Y5+oATAwcBIDIQGYEBJgstnLQolmh2Bo7MihsxSsk3oanHtgkOKQhhkGawl63NmknF7mMK8t1dRRhf5B8Mv6uSTVkEonuNCUmXxKxse2tTtw8ZduYSIBMqa2XW9Nc+oBmKkqi6kqJeqrXrnWNTbNRay/SaNZx26U65fsVSZy4z/Zdse32Lu42avVqc3q0mtMpLZoaPeftKIP/qb9vzgiIQAI4AGJD4sfDgYXCMBkjKTFugv/+7Jk7gQE91pNM3lCcIzrmbxp6IgTdXk0LmVpmiSr5mW2DtgFmMGKZQK717KYOsh2CxHHIehN4ij4FjN70eIdVTucT1kOGqSGlc1ufWaXrTaQYXz5g7827HTGhH9HmVxyPq9q+UvXnD1BvqRYdvJ5m5doQc754dR/BQ4KXMMJvnfMHcGx+Z3Jht+/k06XTLNF9K1HriG6/qoDAAAQUMtMAAQsAIjDDC486cyFRMOCl2iXGLNj8l7orOvPBI0QjW2QwrqFnrmOiYc6WQaNMOyAax7WevRW4ua7Hp+9uNwdlk6Oc5u5MP/nhiqb4HHVci68B9t2XjW9VEbSB5onpdthullB4+ut66owT9DMh9OaMesN/k6HnZE+dKryBiD7SAvf8htq1nW1iM9h4bDlIP+FSR0/JXYkYlNNEIFGfKZOraz7n9/+OM7bpAGAoAYM3MOYkDjcYKgXlpRl8TBlYAlJipgz9PRbghATLRp+4VPys04Ra/Fc5gvcPDoyDVrTY797mc2rBaKJ2tdvoRw2/buzkPZ28tXdn6KOf73EDHMBz45WqJsu3OlTCWxuvYWSFCRKFzjhqVfutDoVGdtT6XnK1iMuLLGuETLq+sSAAACgSXtbUGGg51n6JQWBwqBhRUelQSnZ9nSUMhchpAcJROggzL955Epw7ZlmIlrBXGWwaOYwMZfa6nWrYAQOc2hTZEopIQGaQ/aXIOdONv2eM0gCRFzxNG7Le4FAbw+uBpFtgKilsQok/VIRvRkJeChieysx6Bwl3Is+AKiGsP7nGAd7XUJr1tGn4nc9kXXhCp0pkMRMF3wXJV6UgUfRg1KEQgr770v/+7Jk7QQle2LMy3lK8oHquYhthbQV4Xkuzeknwhkr5i23oljJgnqJ//qBAAgAEDJRImMQuDsPMNBz7QhWougYuRysrgk1F3lALDQOhZa8kDRAz8omqLDEdDRAQjPpIef3RjOWD23NJ1zWpNN3xmlPZJquIE27tAZW/bvXGsJRGuIquXDkRdWT0GDtNk4X9CbS04Fy54fqh8+o/qknm4vhU5jp+uZvnETH8zfJi3n7lKoMQAAAHAALIExjBA4wgkARyV5wsEBAKQECRBTujXjAG3pqJBq00BgdIoRFaAReGjg8dyuQdQjsYTkcqRoK17UxbCZ0u0iY5sszdO/ssLJ2WHXHKLDSkubfDgwicv8N20dvm8ZnGcLFlKQWcr8FKZkdZloSOkrmcyVDl/dP5m8EP4sizX4FHY63k7SlMWQc+5lJpx5zbZmvt0MVqB2P7pmrRxXYOIdXnb84sJKEFTifUCGBQABESkQhERgkLgU3xWSasE+osSLshYESB5GXvaYuYMT2qKxTmII15fsOrIuh8vm/39DRRpEassOoDVAN176wfXt6b7t9I50XIwBk67eT/mjbRtggekor9vW1Rxeb/c4UjlaZcXJPbD8uZB1DC4rO6wsJN6+9d6C2LRwjsmJ1rEPqb/Vih35dvKdWKCgkyD7XSVSKYk0gvUFIEFsI+CLH9D36UxkBIFMy7o6FJhDCQc0CloCzzMR6NAgE6SGK94GjT8t9AdUDDe4YkNhA6OAIMmqdOkoHr1q7KKTTIyuGpW1T0fWvrGpKb0+lviO6pjqtLvSDNzfFgIXeJKcy2UnHeHWqLPT+ex8xGYuFmw5bZsb/+7Jk4QAFfWBOY3hiYKRr6d1piYhZRZs5Db2XAuazKX2GPilhqlhsfJYqnAUPY4UrstFQR4x6DgmhlUJShHcrloHabEDA/hhDqqg8PzNehks06V76DpVYhsPCwa197DyhFqrJYWtj8FEGl0VOTU61iSGspHBtOm0FJn57ID3Z9KoECFGJmtpolMDJPpDaWySqSDlplrSp0YrRUKsctyXIs28biR31tg5RFiB5bHtv2OUvHxnC4o4WRsvORrWfZ7Mez1Si8oYZpBHaleK1ulfoUoGtXDxjoyNtFuMJ5NWquwtNOYOPjb+DmWPf21EzmWD9UuqNwpZL78HzZc5741SasFel3AiR3neIyTVU5Hi4oXlHvm1XuFmJia72nJGaDkzLtUnjGgn/q6vX2JxfwXCfNH+oeZ/8xIhMFmhwMwA+AAECo8OqgFjyTgqimMAASmxjYpQbSosFW1JV0HlHSiAYpNDDNWxC7wgXAOqtmtqZfCMc1sKYw92dvYf1HaA8kjWnjyQtt1SGMYxJcYQoJ5qQeWuIUPdZKo9kDhyZyyH0uTtfjZDtMy1UmB5vwnPTqBDGB9Bs0LF+lyd82cRcrOEk1ovWWFSeYz4UiIsmojUsuhTzUtvxQuUagdy9yMDAcEAKLAAACZpaMMnEZCd4+ArCNItHbCFBIBdKGyoIlP9ru07ef+4LaeufL3q3/8sk+auzAFYPVla3dLR2dSirxggB9/LdQkHRVkfs6lZH5xokw50dZT8QVbncllWmK3PouQiUGO1UsYx6UHrM2MO8xw68FEABcAj5N1/1DCFAACwgAAw04wpg0R0xL49YtS4MCgkaRAT/+7JknIEFC17QYy9K0H3LKj9kxaQVFXs9rSV3wgwu6LWRIoECFkkBP92mqTraVU4qWxZmBEOliVFLKiEoMAonTs/ReZ4hQE2TeifZxeWU6EenGO3D5JJERJBICJ+k4VRwnq1RBvtHWp2WydI3eyyII6vHzpVCZ8kAJa3Rm4hUYjNEgfrB0y6abRSp4ikqOi6WxcjxBiupI03rB4FUfIxIW1KT0dIDTbNUEjvUR2XtjKWKrmFg6Ew0AAARoOojw6JbAgIbJTMQBIAVIESMsXgvJO8ttTxT8knPqdm1ckRzZIzxnddgILaFCoxQ5woeeQkzVfF/KtfNA26+/5jFbr6iaJOmlpvrlNtu6hn4ukuFmZR49lvZql5v0aYFu+XXxc3ho7osrx34gCVTc4VoZUeUKugN8n6WEDAQADAGPho8GoLmJDwCDwl6HhYGBZVNQUhh/pGi43Oksyxi7TdDUZVenLxEZVqqc1YEaiZlupGYIncRbDeJRzFBV/cyE16Wl7lLesi3g6JYbNZK/ImU2OVKMVP1ShJqU79qa3vZ79TQ5yx1BFWcKmCZDC5IY+t7FoSElxp7cpCiGQIpTyUWZq25/0/OUWVnyZOIpJoUOqh8tvtzUIAZl+a/26SjBpIgaKTVklCpm2liIYrgt6gMAJ1pDIDS2XLQUDRJTNsc56wf/3BRwZAfh4Lr+xQntduX7NrHfbWHuv5pRVKySnVGpuBo6k5RaVlD7LeHfcGJWGZSiW1fq5fJ//RN+HPq8h9yv3yjH1Z7HynzT8/7N2HLwkx43r+CYQaEXp1+ACYCxZ7psrGMgRjAccCHmYHO6z4SAtpAjWX/+7JknoEFG1zOW3hKYnkK2j9hY5pVRXkwremJge8taP2EDj2vkQeCDJlHMpm8buFJrPzBiH/kIFAkVWT8a08SvFsBcH2xmuNmEGlPlDpa/Vp2UY6eYM9C487kNS6xexs7UpGFu0trNmFqeohQdnvQStpiquNTOFSv2TU5aFkCexwqazKlVxnLKciXfbI3UWF1R3fRd+Q2ghqTT+kJ7H9aEm1Cts+1q17vc3pdbrRgdQkgMjtEyA1Sr8cIRTHBCW0ahJBCMIePG66ysIQIaHal+9K2dq8LsD14qI/5CHCtWBIWFQ5cAAyQxZo4Z3Os6T2K4UXaKqJHXKkPakjOO82Lt3E7sKfQ9W9nKpqSiaIHpGh3pEUl2DHNmP/z18zLrD/+r4w8MbotAnwqUwQBgTJVAs82UxkKBmOaMdAANMTBQSFG3ixmQG6qhqNklfqZR8Z95gxO/ERkMSMSJisHMIB2s0IjRQ4hnqrwxBVkRBXnMxEqDx5hX7Lb/7lt6cWo5o+uu5F3Mr7btT9zC8MFt4VqW+Wat0v17UsVoeMKtoV+mOlTG2BaHAfQLDa3OLHUHNRsm6FPUCLL41bshlNGrvjBn44h8aC86VGqOyakX8BclcEBAABWmkSxHqIrKPQGUmJCE6tOJIyEKLgYJHUGYBMQMkFyn0AR13eCBsr+Cg9n5wegfIGxdFSWkaasrxut9/a3Fb8Ns2FxqBrXhwQkmQRpLMniFMaNPCwXeQQHY0baRer3L9VZ8aJAk/QRAAAqBIBYNHa9VeAovmGjicIBwOBI4AzChEFQ0aorWknWt0T8RSuizcAMFWHKrwGeoRChCVBHxF3/+7JkpIAFLVxMQ2xFwGqEWe1p6VQUlWszTmVpybqhKHWXlWyte5XlU0iTHYaeyYjEiX7Ci8zp1ZAks5c81JWddDbrKDh6pN6qFB3ucRBW5ypgYV2YEJyj+mp7ElP332qd/PNkuv7m7VXO1n1v3dww+2Dyzttsp3NK2m7o4ie83PQaG0SbGxqtBOzRe7hA3m3xqMglZIkSWZ87LU8zGiLCImMgeYYKHwUIGkZwoSjIwCFqqPw6N7dyCdQFF8FlitoogxhnUwmLDEVQAMlEI25H1FswowojV6VMha4123M6X0E0dlLkK+iPJ0Tvu4x4ekCKTiunnHHFBMmTUcZkPZUiDABUkCizFg5pSihhYqVR4D3KIgoDGDjhQ4B5oeiLB2zw/Vd9/6cknSQZlBJV/RKIX8hSY9uxvC4tzuELikstLngsaFKlcaFiYkod4rIiWec/QQTW7Xi4KB7QG35gbHAx9jq+hsZQy67KM/P8o3GB4H9yKM10IqjlB8Z8jp5Fv5T4qvpKLu54ESK2SssIDaNBedtCPyaZuq7QRUKAQO2QS0ah6LTcSEIlnEYxASIB0zhAgaIMHl2W4pHgIK/AvPHk70ONky2Q+vo7lj/CQU17niUaEZJw/op/BpmHXWiOG5hqjAd2WpeiG37e/+TRe/+U2R/5Efbv2Y92Z91bWwltiEx1gJ4q3Uph4IrbSToQzJhBfQECjGTjdHxJEmEliagCDiD8EgBdzrtwiK8BkjMJIOYM4UByAMEHeF7yyNYNsBUyLnzjDtKA1CJHjcY8ixMJH1mWcLqCCaZjnTRF5dTWQ4aCbIIXTIaWy4iZlw2WxRWnRUb/+7JkugBEzF5N03hCcG3quc1l4ogVgXk7VakAAa+rp/ay0ADsg7aZeNGUgvRZqkVu5jdZTLqd06jhMujKJW6CVjissze7JUbsimZmazhVRes3QQLh9pTLBYdE4eNHM00kcD0HBEGx1tOgGZlAKNBp5LSEsBAhdRyEbwhaUOoqknwiL2XmBcAxR5l92HCxDXkbYYhmXTJI6OiBZUVIMnpIdWn7ILHYmh0npFw0dZoqp7V0tH1/2W3R7aSLfvev3+619SP3rVUprdlnQwoCU3uVAAAhAAAHA5HAoDAoEIZqXSIAUw87MFHTXoZXCkS34GFzKw4AgC5nuSLGgMwYZBxVEpMl+reGImee60aeZ92owIaIQeKOAr6lN2QTDyOm08uGTSq5TVlNeet4GIEYQRfgvXPDpQQIX3BAkN3pRhFdXdw5GJxQRIRK0HCJ5qLqWKAa3hfpd+rAWjTDbeMRiWFuxQBX5dJkrrMc3/91395/rmUQljv2/iMcgFW6AGdy9XSwnab+9wz7r+2K8vdyWYX30fiX22ksddWCnE5KmHLRdpjX61n/3ef////hR0n16ftjP7ffl+o03B0Z25BUYbC+lFEpRPXJ7//////////////////+WOfvPv/////////////93Ozrf2t5faQgA5HhopEpBijWGgkMg2vGAixgXiH5rXJIPMCRXYZdiADhWJPm/KBRwQp0gQ6cBzwSOmWKpHqAA5CMgAMRacJDQiOEFB5UEiVLwPeDpm6Z9O6jxhUIUIEHCwVdPGw9ylqO/VcMl4JNNRFuq3ytji+WfQ3PuP3kLcBpTL0z2GJFOE8bJpJBjRH/+7JE0YAI4YfS7m8gARosyq/NYAAQjXdl/YQAAhOf7DuwwAHwijaQ3Py/XEKQsm0kGy56GaN2wl8akEE2MIxLHkn6R3I+/cWlkfYzFmJyhkjgP1uL9puZZv9F5iclmfd59v2I0t9xWExuTxpxU+1rL7jUFS9/eyqjgi7GY7L5uX25HAEmaZK78XqWOe8DsKCT8kd90180cw1ighEVi9tuONq9EYEiL62KelpKar//gk6+7/ewyKtkUgXhjICQSUnUKG7wYUFLCgi5KVMVWGHi/zEnRXWtt1GHvkBEOQeDsoRgbKHgublFUc5tWg0Ty9Hk9LWPQ5aPatWqlxrMru0VVnJA6Mfwv7aarLnGjKNpoaNx9brcW8zMXBE1FR1a7u8xxfbJUpX11F/NTNfpWttyxX1Xl2IB7axaASVEgCEyoZCoqtlqwYlZK0JpGphBfVVsXSHZIpw/cDP03GCSamMxSoPCq6PiEfSugebbWvQ+lYYW1aXXnutDX8gfY/egX1peynXfpudrCeln9mOO/Zl5cr+X1iKzXvZ83m80//r0/HlNm0seh2HqTobr+zorZ196jjPUkyMCCAl/0QP//+AZxezE0SAgADhi3wIRI3qLKTU2QeTNZs0NwnQ3Iw7Eg9niVl3w+llElsmBxCqnC/FtMRn8DU8+qpoRB31QEQQ2yE1yE291KHPt6KY+X0r2VStQQifpkw0SrEX2P512grPT5jmnbF5rfWPtvG2+M2EId7tf3WiaU2XCxRAstIHfk2dPGTxLNvZfxXW8DwRELGZiUwCWjal66Is3SeUJay0GeAoFoocLA2iOJhGag83eJ1Y6mDD/+7JEWQAET2VX4wkzUIkrux5hhkpQhXtl7DBtyf2hLL2GGaHkiBp066NFnnA1iSKRySWyZBpTRhttun+uWz9naNKNvy5r+WwqS4Z1tOTqru8VC7TP10b22Mxn+W8/ded/3Csrnyf1PeIpn3bESa6e5q3zfiwQoxjfuVhjFBwNsh9a/7L8lFVndVI4kSQCxJEOsyIhL/RqvJzJmYribuguparCER0+8PIbHZEZyhbbcgbWHXnbp7su3tVaohri5iCJ16zTbXS8va+84YzO7BL2Cz1CChipQK0Eprv9+s3W1Ughvuj11sqpq0bWTy79akq3zOkyKpeRHpk5UGJ9tyjlMULgru4e7zZdssMiMqkmJIIBTCrzwKlBM1oSdWVilC3llCe5rygZJ7TxWaMyyulYgrrxMhCPJJGkcT78jueQmuujz4mMYszlUFupFiErqm5T9tT+Ocdd35rILs+XK7+M9NubTVULh7xoeWfzn67PY7E546cHsr2ieZnRQuwkFMHSvNlK7p+h/8WmSKZkMhqQJIDJeehgAYwxTGN8MwAzMsYor5JdISYq+lagaCu7htn1So4RmEKi8ZNNxRo5ol0KCXSiSM3U8YtEXIrQVG5l2yc058jrl6MQ89WsmIk3GmZr0fCyldsfa2ZxEsl1c1DW0e//wk7XE8dcc7cxXzXIjlD0NHj6cpRwb2Imb7++O50zwiCdaSIJYiDIU9kBqnaXDQRRStq8qZXChj7OULkM15sOyrmYdmOQych6dPRRNQZ7TRovaIo4h8YiJsnBitgGtzeyIo2CMItOPJNDIKaai5RnPFdq+o+rmGds3NmPhV6l1kT/+7JEdQAEKVpY+elD0ofrKx9hhmoQFWNh7DBtyg8s7D2GDXmksz7j5pVVPjN2J/rvn/XcVW12LjxOZYylulgOtMF5oVXfmrRaRkZDOosAAtegYijauz8aAgDEJGPtAWKzRj8uvA+hCy52BXdYjNDjdoKzghOeYJHtfpaNfBk2lz35jbNV5zSX51UzA4TZKbDa6SG4MxqepmhyoHVAuoc0VNcz9+LKpMrF5XyJ5PJLjVW6O18KRESR+9XPga4b5c4BD19ytXtZNNDDIzMh0ogEFlijsoCC6dIs1JBCck23VmzIgFiMP4oTD5GXAGLlqdbRY7Ww0jAqrHDwq7T60YvEyx8G1ZumYDXGTjBXamILNGGjcEKVcQKrSZheEMKYIFjCRQ2eFeP1Hn9Ll6bEmeZcycoQaD7jPn7JnEMv5PUHXYViqjQMBH6XpYdrqpUnhmZjNhoAFQfWhbBqcS+ELYALzoIi/jQmRDQGPS9WRkUTwAQRjFVA4GBGyBaagWUzKfxapQSnjOZPL7Fw/V2mlFBCbhm+jPeRerZlhBF6xYy4cyuB/uMr4i/m9D/3luhvdkVUVXH99nHytRSkt7Da9I+u4iYmkOYSp1yjbTHSz4zHYz2/npta20kACYyaFPIgaJ0CTj+LypEeJwb+z8K5qu3NjtzSD9kcjBHLJY0hrGCxP40i0OCximkmpVtCjiDJYsV0Ia/a8bUQKjK3Ui4GxPC97Cj0V2Yi5lW6NvZHDixIPDMQK9I+RXys1zLsWqM920+gqyw1kVdWHSlfvwq4P/ejpqiQAABgE2s3UuADdIDYYBjEmXrxaWxKz8ToofsSu3AQYlb/+7Jkk4AELGJX+wxDIn1ryv09BZxRbX1VjCTRwc4v6/2DCikaItgWm/bNtM9qLV8wixc6/bIzJvNUU1Uwe/8JSXenvOI1bnqmKiBO4NXsbbZ1I65hztZ2Nam6CtYFd2394HP4lWyDxtC0d+lIbyadPlvlIpZ6L30nfpq/p5/VEXu58fXfFc86FJ2EJYmdFczOIoABUZXDcwPYj6nnUWqzOIrecqALlGrU5Mn7QyDn1os9FZYIEANqOtmvI2jazlvkMarDoZHwFJfq9grVZmmQ7MyvVn0d1b1Lo+CN0Rq2k6Kr2d8z0OtBStKyVTz5ZO1AqkucWyEBZ/gn6X59cmrNuyZspFAFOCM12CkqXDaoxVP5YFr6n26uDbbvCX4feQw3lQw5VppCeF8ocSqM2OWu3wOh4ReC5so0oanzFS4TSFpUboKBDCwk2FExnhUyDGZVa4d0OIyg54o/h20MLFd4YKwDImpPg8Gb9ADfchzLhzTxCKSTMEJcBmBapIhME26n6PmlCQ2aFMWiSEVDWFfj4qlU6cBmyiieLxtReCW21lUyiiDb8xWTymBLUlnDh7FJba/qLSuudSsTU8lR5OoMvS3eyS8OmK24oo2T6a4YY/9pFqdYEXBh7iyYyu0uxshY5UpSDHRAYkzPk/rkaFVIvUjyKpm5xywFhSmpWIhodAXVdDihqjEIxEEAJmZq9YHMLEy29gVCcqNXTJnFU2hh0XcfaBa8dmbZFcgVimC3hNQRuL5kFiA9MB9NjOiTurMaEatB2NNTw4peovhpGEDMkpoyxpRzZmDERLmxsZZZESHySdMp6U+1KRM3Eo0MjIvpGSH/+7JEugAEIljW6wYcwn9rGu9gw5oQYWVZ7BhxigSwavTzDmkDsQpSUV0NAxEMyQaco2/9Wt8zijl7RIAAAUEw5ngSSWHApgWBSlzR4kQjRBB8HmbY+Yx2VcnsSi6BvYGHP4slrZ+/Jbb5aWUoid7kZYtHTEkW05Hsfjuls2ZeOVjlmh0Mjt0UoM4TKTN03pxJnN3D/ekyf1Yq+gOmhtqapVjQZoclzK/KFNCMT4ppM1cU1cmiti5utRY2V1IW0CSnQgQs6HAFQkHAixGtKvfZ+F9LtcWQtmcl2mxUCmjkbW1PuIAcKDkRSUYvbMur2FhEKPKd5mvW6Ovyr6qxgz9MTJDetc3I+aukmUspH0ZYlKpiHiq9mg0f910VMe78Xc8CJW6NVQvMcaf71KlS0JzMUMjgG8U/+XcyvoLZaiEiAAFAQbpFg8RsjMIOK8CnK1CjDFAQlDnJtPKR2flA9Rzh8SgcBUtZgtSR7LA8mIYouhpR3ulSrSbVlz6MrjIW6sTnGlcRZaGYM3UB44M3KkWO/UBjMnkfcc8i3B//pa5NQiETRPLNxgXc5CN6FGhuV1HDE21yzHoUfpeXgAITQwA4AAYl9OcVqiYogDjrkpvqbPWyVtmwMSWWRVYEFK0nJkCKpdYPm2yELHcLtUfQJTCeCoTAffNG+4KKG4aMgpBSVHmjbcFk0YRSBtciZMjCLFGhbtrmaY4RSZ5anwRSU6fGbuF7R8a1HRHuJVjQfyNOirHOdMvDZggU7Nr2X4xR+bEdmwhDXLNsdm7l0kjRDTIxSaAlABy+rTnYEgjsUaEOTrr2XVMJur/rQYThFAYIoqfKjl7/+7JE3YAEDVxW+wlDooBsGr09A4wShYNPzLDNAmCwqfGGGbHmKlhs1gMF1CSitiY+R+t3n2T95Mu4xXQHGCq5qFn8iuwMiJOv5QdDSmQCQgo+AV7oLMRuJWmaNUQIwqkwLDKkWalYz0ZrmvbMm0bjx80vXVOKiDDSUXOyTShz8VRTs3m7xMwpuU3KiOVZemW9r1U7rlW1qqRE5WDAABAyFlsiFSBSeD7JGqYM8d1R1PmXK/X5JI1AMCu04DvYHYFSjSKAQWZZKfSKbF7lFml2zJdzjU5c8K9sUH0FJnf+TKONNsVJZG/FO7oFzcajlKgrMTc5Tob6Y9KHSca3Lz+PWYdUVLPB9c9o3zdtly/L3czxs47aWUfzjhLNFzcuhIFQpe0wkgOSEACRYI0SoFQDVJSK+J4Iy0F4B0nUgFtgYF+MwpxhcrG9WKsPYCAfSZiraNCTJufjlFkaBNEKq+kJSlDoiWcjSSwkI0oZE6X8iVVAF6XWVbJEEJPPFCk8REXaVmWMLpak5Qn+KaQ0YkQphndQ5KS0ZN9ImuPRe2DXK5mtTp1qMvZljs2YSSpGI6RfLwJqamWZzIvraADMIAkeDoLLPIViQY8ylE1XrpRtbUPxZ0H8Ye8cGzcYwprNO3sAY5wy57QnVQlWEknMuYdAVHscjMDh1UjtCgBcSxmHxSZKpW0YalJpgswcQB8KbS8UZ6McFuW7pGFgNZ4UkskfhNAFsULjAqsLIhbMCYeaCGs2cM6izM7ZMzS2PV1atcJPatnWS1qr4RX1wSDIUODw0RIWU68zypGRgABJGqLkIBAAK0UYQDmK6wqz6VpCPSxnZm7/+7JE7YAEZF7UYwk0IJWL2lQ9Jq4TWWdIjCTVQlmuabGEonhe7cMTyscStc+PgFQQolICQkPh9rrdNtphAwWRMZI6wzTyuyRHTOUH0JlJrVF/JGa1JBNdDDY/NZrwMw28ntkb1rpuMHGrkuRFsnLdFO5EKx8DzSLb2tWeIiaiLeGZbSK4dduGSKY0a4WUgSDBTWTJMAoYY8hLupVVsECVAEAACPFYNBQuEKHS7VSTDS5hc6z5fbow83CBWjRzcImK96pMjAhicLowylkzlHI1a+kDCRMrj4lHRPH2p1NhNsjkdLykxOFlD8KNttSyudRF8VTTVZTe6vbEzVR8p1Km3IR2k3v2NqYYI/YFOmDF9dqO4/WaejHGsMGKOKKohqe6gjQUFEssNuC9J7uvTCKkCCABW+q5bChojexNOcHBUEX1Fn/ZzlQ0cOxCaqzEci2NSQvRfwoJtpZpCyzSUWqQ7CJxYy9mRSOojdIjnWOKPREwwixNE2hWknImehcSrtnDh3FmV+9RvLiAw4a082DndFkQCRI4n+xJ1UVWSkXXSLM7p7Uyk8L1Hu1sduvGBXdh3nNo+GAqxRHHd5amWZIPl1D5fMQ6tAqAAaK6jIwBHVsBNKshgu1TldCNiaC9HKkcSdeA5ZDcGWuWqCNuthP8NWPNSnCklwXDwBJR51GYMRe9JjxtpaYpBl9yTFIm5mhyzklmErvMMP1YaiVVkZzNrpJYnsPzc6/g3LqsRUK/NHvDjBS9ySsZSn/Vy7AIUODVQIM+o8cJ9Nd4dOt9tRgpxEBNiUEJEkkBpMZzlhHbVpZKw9YKUuTIHgh+HZTNzg3zIhX/+7JE6wA0hVrS4wkc8JXrykthJqoRTWlLjBh1ijyoKNGGGjk/yBx/y3pWZ3wW1YsdXy7ZrbQPpC+Z4wlPn1lru6m5djB1GUz67K261e9ZxcfR008NDhhWt0SkkTL8EO0jrpGi9yYZshAxObO6DvhqbvjUUzb5V68zNZfc69QKdqCjLFAtifAZ+5tXs/+7wBKAQAAgCSf6HaAgTEnnDJeZu7xQ60tqsopSM+kEgqChaT3aE8dIWDInL13oZZNLvHJrG0y0erSs/69XGf0Qo4L+VDGB8ykSxCc4TPcOAiZ2UwHoXpIJTGEzSKIwOBqw1iBCMKQz8rpEikqybLcBJBj3HRWnHIa6ZWwt+9LnnNOt21n7buxjZ+7zlQdLJuAlSLVPy8ffL9bhEDSAGAl5phfCXjfjXjGB60p3LrrcVtZ7ZZrRxkTcES4dYTBMqKypMgFZmlwdBNB3BUkwMtsbh+aiFeaKU1TSZMzSAtgiMiV7OxNn9pEk0j4WFoERI4FMNQhOC4YVQAg8sQh4ZwtGIHT9SZgo4DK0dPKKOebsjlVb9JadLQb94wqVT2ZWt/+85NHRqIEWEgdHPUCnPaKBVJCAA5jC6rRiJaUI0ZYULCQmNvOp2KIKrMxf6iXdD+oLoKX+tFdGN41aCFTZOn+uRzWg1jlbMH4iAjksqoQXReo15HUGxSYjT/GZEqi3EkNKx2c7YSXKQthAOjEHpRlFQhDkqxEGCsYJlsG0JO+CKPAzg2Vd1U27aGDLNbMoHSoNAs2YCFT9s5/l3tc7SCG0gEAAYZKyVkQRtI0oFK1XPoi0rXF4YTbeCBZxh0Azl+NrROgKCpr/+7BE8oIEwlnRWwwzcpWLKithJn4RxWNHjCR1Sk+sKLGEojk2oNahioITWpitpVpEWxJIzkgWbihQoDjRcK1Nd31xjShvyZakcETa9qlKXoU5TpoVUzkn4OMUcWaRT2NMfUQlcm3tTYg4pYiWHPuyvEaIyQI03yKykIrbQvSVSoQyqOpG8542Y/J3ms5+JaAnWUAAABGNGTNPGETAXB/GVgA4vKFwnETch933rprcy/FEsDH3Tk/u4V0bxDKxHqtMj2BhCEpHK11WacP8Tk6Xr4dmJH9KkLOSJx6ooXlyjsULFEpgKuWebTXZP0JyiZfTlh885YlH/4Q06iaauWzB87XYownM92m4s5cPb8ahds71KLVxneJGvYo7uaraBHog66NL+kkfTyVVMnKPIPG0QIJohiAAAOcQGUP5bafuDkiHdk9FK24LDQUimtS1DcRiEYgBgCiE3TWbZuqIJHveAay2SlEL208SDMi6ZHF1D34jInD3XrPcKezCP7HFYeeROxqCVbrAonpC8jBrYQ5lf+u6/OLlSLO5mwnWEJIuv++XXwCqYF4D6RL6ZDKqIABoTBZJD9RQu8PmRwLCJZJ0JYVwFQNHBwz4tHrvu/qCZw43PYvMEw+x2qYxQxIKmw4F1yw9F8fIrnYHShJIFqLWCcIFSmeA4t9YK1GIdSq/6YrrZs5WUiMkrn3LqKGBEMYo472xafOSU0DexOeX94tO4y+k+lHhPEk4zQtLWHxmoG17NXrp5v1IjrsZ/iDfJzeY7mk9I0kCZlQSRyyJ1+SW/f/23eU5CYZURIAMQgsMABy2ah1EGg4bLi/KYi/ygMvRqf/7smTxgiUDX1BjLETye6mKPmjDjlVtmz+MsNPCQi3oMYSaKFDEJXDN9tYCOGKBJGKWSsU2paZEBaSbVviwlTVLPYASlBCwhU8SSnNL2YfaI1DWmUz9MLHlAw27MLw01mEImoOqFLajimKKbVmJvbovr+n9INptMK1mdv23NL7Xb3u/Pfxvj+M3+lzZCttmQo0OcwTufKGcKNcYAAAwsbRZIEIkgA0t2LdCdikKu44vqHmh0tEvOXVVBYZc/HBo6tLjU7tOMnro6lKZcA8d+ORulfqcGiCsdNkWnRyZ20SR7LNBGlyxmtXXdgAVjZSiG+lKoiYtWIn8OhJLTqeJhL7jVY156o6cKptdYkP5/jz9PlARo10Szj9ciRhik01STvuKWb2KbSynReUt+wdrPc+UYheXVKSfRG722SYAAcYBZI5YcsIQB81eJpotLTqUJYau6PrBK0U8V2aMso22DpQFGrGCUB3nCHI7VWtzmNy0vnfS9XTTpqrMyk7YdqE0XppzJCocNF1Jg2SlERj2TWhimeqbe6lPRurt8Hv0e2mQhgcwx8pmZfbksKag1oyxfDkevXvW4hAdO/bpmcKUg2uAElAEtEQoNNCFKoYxBVhrEOvQFQOmsUsPAkRitcpKlbLDck45NS2XBPTm4sORtpI3yJV+zZUcGzBVhdUbVBmp+uDPU+TwYmSMikPVcsJUssVPC4tFn2okeSIk0TmCl4q4Q32GH7i294YkR8x3/N1p/PCQXG3oQ7Z1COax6crUdY8P+xKeW2FM510z86fv9R9LWaZB20WUldTfo1+fft6fdgqcv+zscIESQAAu84IMabmIMP/7smTtAwT1V89DDDVgfgr6LGUjflYNezisPZHCFSDn7YeY8a4cdLdMn2XMZgr6NF2DrVTaXNTolQLblDRKKRdYUQOazrMZZ9OUWPVByULtEg5cizlZIo0jB4cpDSlBIFaxQcqCuipIibA9HcKLKnj7YzYylTeJYvKaNZWX2lyuxXCYraJ94zqQ+VURhxNHNduYlT0DIdt/3f+t/uqUEuNkIAARiIi0QLPfVgEK5aMoDFICORMANhvnCespbIjKBlJ6W1keHMPHHcGwhyBYaZ0bHlOoYXfInLtXq0qiSEfSibzEkKOZHFCzjBBOxAFH8gURZYnVrtLiTS5HOPTO7iBCj3qkOVz6DxRt+bV7pBDekum/ye+6tiHp0uq+P67GJ7VTfBv6kjfcGG/oDpZJAzmWvDnQ3CFozfLcxeEOZIYwcELKIBCifBZChHkIdLany0rUlXwuJMMbSINOoKe27jLnIp96iWcax1wOwUUEF7WJMasZpYgdXlpPQieMBzUjbkU6LoqmqTbKV0yIraejFzH6wnk5PRSNPBJXTyJ3P6+bnXn6zc/QOt2/qHT+eiAMMH0ZR1QRzqkA4Lq6Pz/hv7XRESIMAAAoi2gq2IKoJQHVRQBZiiI8LDBCzqVDCrS6vnxGkjFccFShSNtFSZhhCWI1PaUaOE4maSGVPWIdrrM1RZOU3HBLRhKutJCa+ANHAGMkjNowWZ6N6Ph9ElVyDBHA4W1uz56/Euf+JoO6gC7S5remPLC+g46VpCl1rHIR6GbdLMo53dQVRCWp0URUlE3PmRQn6FOVWv39E5z6360YYJUYwKEAARXhoE2LIwW/6K4N2v/7smTrAAT7YFDjD0nSgyuqX2BprlPpe0OMvSsCFaxo+YYZmEU77dqJaM6zsRSoGKOiIVLrS3CLTKy1IheGHzmOW5tvkEr6o522ezTqYbLoFA373rJxUyMAA7si58doInp543Lk7XM9VT1rPWxsgHCjkjv6dRRpymvoa5GP4q+50bhsy/BVbSs7X9fCVvh6blhcYij3VVEAUSgglTrbw9cChAgk4MiJgjSmXu2oohVZvRV0KTTL3ElU/K3FirF8IDbiJcUC8tr+iXsYzhYjeXo27x3VyUgrGpFg5FROnUDSsWH8VIoC4tz8E1ew5AXchgH8sNekI9ICNBf2xpWe9cpPaiJyLUMkGP0LMGlgFLGuVKR6EQJPVYZ+YyhbLgMWvbXTtdAlyhZKNpAsikQKQs4mm+QeHY4iQELqqTPSYYeUhbz3T/pJ7WzQAE0Bm4FzAkJ5RJ51lzlllYFOHxVat9l8AW4EikYbBFzDkigrNLlB/+fl9xcmSeqMSTWfJp8r8aT+Rq2/sePz8L2/nfaKme71hAx1wqdPwIwxnfs/CNnhYOk7lg1mP71zSwqEM+czYH5Ur7niUPwWOTBDZUGJKNZEiCBIpdSiQslhxQSdReSCXcoU+qp21hiaKuguXBZZS5SoaCaOkKGFg4y+H4840tPp5aoMEFgtq2M0rWovHQHXU6EZomVxaOXCEG6Hf1aHnJGvdTEYs9rQi0aUGy92616cXk8Y5q61ZejrOoy16GQk1bqzJ6p0yr9dBG9i1pbj6p59KeHj12nV11uLXLPJKevJqqTqNCj++RXaJyysTsG3pzGwXtKZSr67tqZQCGTiKwAlkP/7smTugRVtXs+jDE1ge+s6TGUjjBVNeT0MPYxJ8yyouYYguJVQL+LzRICARWA8ASaAKQ9DBh5SdCaBwt8wVGFExMaNYxq4qlsHWHBwcHQ0QhHRNR3BtUfXQ0QWpih6X75rHEPCNRy8190tSw+Ymr210GGPyrRck17x97yltUTVN1Wxs+UdfEt5rXCx4kH944cKCywK5u5awJLJQA/oebEkzjON5NpHozIElVrioE+e4iEEMdLiTljJK6uZ5B3GGXWI3bYZVzGq/kce5l9MVatDcZtqs3XOilbx9Ttu2yZtSsOBxEi1ZcEQaIVKAYC8I0BmMQyo3i8xPaEgTjRK2r0YUg1Bw3tUiRPg2jhwYMX5LR9kxXqESCH6k/jF7FV++SxL0tlnifa1KS0k2BD5pM17SJtGDSpWYmupARGRgQCSvb9siAVLxEhdoMgjSPMY/EGYsNTkZHEnSbVwXYeAfdxOjJ1RW2hSbZOn4ahflJLPSKQjSHIl0xM3DJGYrawiTYtQ/hhOGL1j6YkkunJmsmqkhxtIOziadOWkXfVfNgqCBJNDLjDPsRUg/wr+R8YB6i5In7HwmEnSNQZkwdfVTwEEyEQhCQWMMALaENNNKUlQrDAk0JgqBBBOzqlmmmLlmIu9UjXK9ksYi1KTSvsKM47kEwO8SpnW0ocmeMDmBiSmSgMiUwhsiS4nDgf2qpm3OWkoeFsKEJjyYui8w4glAqNJiUTbwVJ/21E7LRUGuO5AQTLGzoW/Z7zT1pg+7Q2bJvjL+up36/FfNysUpNvpXa8lS3q2dqTFbq1wvooWuRv1Jv1aLYkDkiVdDsNzClysmAAiEf/7smTtggUOWs6jD0twhOtZ62EjjhWZcTdtMTWB0qyoMYSV8Em+GPG+C+oBhIMRAr7q6c5mzwRxczYYQLlRkmP4qShkUHWMXVpCRL/XtbG2dxFqstjtaxWy01LNlKIsag9aGWzlmVqEZGcWFn0M7lZURFpZEc71BnUa44rCBilHPKkjjZne3b6b0v2yzajhr4wQrINjoxvrnsmEvIEjCAMgk8l2ipHqqqcwDeXQpqgCiy07aPDytEEQSfbNZat4rCa/Wh1NVtGJQW27EGbTK2WkIOrJqCVbYKlBiFiUEiFhyligIgDw49+XElRr6MA00JMZjUIeWJ8YKpKZxmDLJyqVyMNENsh7w3u0WpVMyIQdChZ4OGI7Gi82JRQk1HEf2DoQF9YRQOkXI4mrlVdWyU4cpeEup9QlytXIuO3L1PD27aha/BAs+WFtawwF+lHDe3QtftZ6k7G0SZdyVblfrsEDlYRAAACgXXD4jEMFbtIlMHQlLQ3ygFBC6LFU17rBTZMIAHKXQiQA7FbHatNOFdRiWNX6OJSTwjvSDtEFMVNLqRsokDaM3wwFbqsS9rOZWHFRfqTKW/bSLyPvychZflwp84WTV/y708iIoJgPh0q5kDuM52lAMFUgAGQkrBJlnqAiccILblQEtmgDHhmsqNp8yJ1GGs3cOXLsf8x42ynOoNJQEwH0fzJdYQG4ClZHDC+hS3hqyaT7C7KNW5ZZ5ayPTmcdu2GaAsKJmo2nci4+IJ7rEVdcPRXiSHlCrpT65+dOLj/YSbuxhefWFSeQXl5IH30ax/Enz/12/M32VnC0LN3CMthKcqv3/rO2nJNJEOks3v/7smTxAgZuXssDL2Ywdkr5/WEjehWZizeMvTGJjxpofYYNYNq5ccjBNuO+E6/Qu5cGkgAMUVCESCASVAUiN5PcydT8NPVDzjtWayCKMzHYqw2aVHrl7ks4MrdKkajPbakYuAhcVeFZE9PWi9XL+ERKd1txU7fPc18pBzc4k1rzGErmoSYTxASY4zDd8/SCwDHiPQKu3roCAAABWABQwhemSJhc4B8QcmCAp1W48ScpPRDkpa8dIjYGDUboZRLIAEdlzM0+QqRKwy8IJBBBAA2qijaPM28cmbAQ18zqYWdaVaqiI3bKjj609RIrkNIEsMPb9xc29gONRIaj5FCJOVzUojJCfsrBqD9fL5zJtNvD3ho+d8v+3eF6T3SHxlrVS251Z1fLiY0GLdFeo7ZVKeNe+WCHvDwvD/zuH+obRlMu134tOWo9tLEVdQnf8TjPcRdpUKS/SlPYYnl7rri1sSJIVsiAoAAAACEZCHNZwIKBCYmOuQBNuUgIKU+4oUIrFQynoAJyHoRYjYmaqOlaLAhDuCSgDIbSPb1YpZy+FQnRRCBjl6VIsiKpjkXdLt6yXyY8FFO/URXc0/am3NSLVNRrzJ3VOw4k+/+/Cv/QsMa8+e3tm+//qG2q/ub8NwBBoAAgqlrDWy1OQ5gaCCJL644Mf0WRCwRzkqE3l4R+FJ2CQ3GWUKS/Krv5riuV26Kkfuo/8id98VgfCtUWAbgfUFQdAOKX0pdaV0QxLtAsZf8QCYoxZUrq/KRM6dZv6ETDFuaGHsLyw5skwmM4f650rGJy9JnnIvpehPCKsZ9DkWbpvJ63s5xNNvuw/DvMQlAgx4YBHP/7smTuAiZXY0vDT03gewYZ3GXmTFQteUGtMHdCWx+oKZYbGasLBbB4sVQGJCt7gKfABKgjLNns4zQcQX0DBkkRGDGAiRvHzZk6zEGYqXocEyIzL/kq6l2UUeTDiF7J9EcYxYiCYcLllC7am7L5fKyYopQFwNlxKuEdp84PGFi94S1cGUpx3YzepRev1+32Xt+sdfYJ/1Oz/7nYW5RSFrc+ribt7TrxKd2WTv83xz4CndlFDFilvvlxWARTF11y0lwCMx+BmhMIBRERAAAWMOqjnFYv+ZOPGLtQQEBBuOAzCiYORDdtYCpQym2y8vHCnfgFrcjmHef29uakMmbPKolXd6q4TKnmvrlatKoTXdx06C62RCU508quHLkCQFN8UpppKHhE0qIQZZ6FAtqSLtUa2VEKFvYQzXUbNS73wXUTJXi9rI0VikKXpCeCYXcgxFLM5kcs7pT1zrYorIQk2eg0XCQKU581ufSMs2O/O+v2pMAAAAQ0FQ60EHSnBWmsUvirC4rjLBLWil1H0JMdVwEVYhYQgWI0lpSD8bH7oTo6Y92AV03lpSokJCgWkup8nTMzMp/I5hHMWEdg2hdcYkKuaXFMyEwy6UmcNqsE8cQNe8j8hadyTJd01UKr3u5n6++vSlfyhfhLd29n73+e17qHqGefUz0pmbmTmj35pAgTWC5P8KUljTZRjbxj0xGS3VzOgDCkAAJ6M6fErquIhUKyoGOSEIBo2ODiKCoy6L3oyyLKyswwsAgd/GGsZX/ugfx0pt9JeepDpTSbkL0exquGm5kW1mimtWVMHE3yPnNRYob6UtJOsqnCFuEs3UCpn6ugMv/7smTWgiVPXNDzaUaiokxKF2npXlitgTttvZXKOS+obbMi8NjALRzjvdnPfGUyfmISP1GlY1bLVrhVnpIsT4jrtc6kWXPDDkkDnRMw6UkV5+0ui0/Nl+ovM32LEWmalfG4lW8l5/SukKCfYHiy7AoJmlMqAfX82B5z7nsS+RPPDzGaDoyvzsIQRBIQgMltAUnK7TzQcT5EgFezXWrz8FyppkTkNWC0+6bH0/HKl8zaduh5XbIx/7NS4VskQr2bUGG0mj7kxU1TZxs6UBAKpl8Z7a2AaC90tH7rNuJr7btWdEFZPaH7RP7sFxppVfnXvH032/LqD5IgGkQhY20CTrYAwiHKebyKmSznBVCS3HcleqsucatVoghxYQRgBoC1iSPZYLBAxQYFaQUQTA4SLSFcBcidyVYkRAnlVUaHqSanlcGLi5IILa78xk8MqzsSW00iFJPloCLLAa8hgjNOQsLZrJRitJ0U3Wu7jxPLLM02cFTEpHGW0uiFsLNx/UGha0OjTSy5pTpiAg3VXYsQrOmr9xQXIYq8nrMhOUFCTOzFai0EW3V4q5HnQZb6QLZZVE3AvZHhUAFRIsNwe6khKYcxby1tbRJoBKt0TKNOV0zVFYsD5PNnZzBbGrkD1kECe1fc0QkdyXMYlz+c3rqiPfygqNFDVS5FD6re1tX+K+UxpQixsr23tQemHoZURxmsy9VSs3V+ZukWrda5ztUrST5GzfPvbMr1I9wRBigQ7MxcMKOsM0xLUEOGQGjBPmBISWWYjApl8QlrwgBmBwU9ZESB4CrmchBp3I2SBgKbSdrCC4DSYrF0O50kjrhlJWExK6qwtf/7smSuAQUzWs/bmEnweUu6z2ECtxVJezqOPY0KEC7osaSW0Gx9l91irt4D6j84ved08hq0+Znsik4r2RXvKYjlB6x+WZ1cefAwtRfAZfN2FJFswhWnPhd1nX+favmGRGRXjWxdGeqUWnlm8ry70ypQ9PLbc210cF6u62Pq3zoxhnc9m7IxtvzNZ/8pKrTmnTO4IMPqJPkQIbagIiEDTFBFBYStFu0GQeuhnC6Uh2oyCCniVbZwuMaYpTO02FU9S3DCj6F1qMVnnJUnGALuD1JxdaakahlJ5e7FqeSCQkOyk0VTGUWLkdxIVdbN6kfVDapURVLHSVDtVUeibX7vWeqGoNHVqRJ0ePTILtQOgrGKuJjjrTXTCEEIAJgD9gpklACMVAI0UKAwtOqCgIY6hEUDxU8tL/qQnpUoIA/P2zKAiQHMFpvE1+5EG5z6MONek6cOlhAlokvUKkQ7R2eXxed7Dt4ksemKI6oCJjWsC93pOT9voyZ01ZMMxNY0jg3Plpy8wNf0Ld3+ZxurOX1gsLell/a1WyiyE6VWy6/Gj9+8nTW12zF4eS9vL6zB9ehk6evd5depyhTlrLZtE7RKvsCFOKGXUnfaM5TOLskIRx2PU7SGoF+U6sXjv2bjP1d2q+TVSYRMqlibTMs4gxuMYXcoLoC1xGYPyvSaP2XWj3PO0kDiuw9mh9kIRjKuraSloUkV1Zqa6wqcBzPm7rsA6hfO+hHQXm3J/z/i0YIVBV3+z8gY4ZQAAMxPECYTJIqYmozMpQoOShwymTlJEmkJrtCINs8pqJ2AchtVoucspUFaBZptKWs+MkVDZr3I7GdDsztyCP/7smSuggVMXs2jmGHwcmZqC2jFslWJezWOZYfBzKyp9YYKXDCuPNzpSD6zA8n6h6sRvaAwtDQyOHnWHBtBMCLPStsVbKSHNis5dyvVp7Jl9cO2K79Mz3zz/mP7D/EptRitZqzFu49MH/MnEb2pYpmuz81pWf9vvfp26pjZEU6glGaqLVdt32baBoJzNiUVDDz/39OSIp0IC4peoS28eTnpOwQp58pW2BWyRU0+xBDa7SUCN72VG4OgmwoKZBDDps48w9i3stCuhZtrcNfQhztBYi44IOhlVVVmRq1Uhtjl7TVVDdpOj0vcUoJ33tcjz9L0dDbLWuzOzO/LnZSqFM18ilUxIAABMx5wEamKgJgQadF8iyqvQZEAE0hF8roUAk3BQGga5BgqFmECcoUGQLTrJg2PwPAqu5fSS5N58ph13+l1N1Q6B61iKxqBeIA5v6eDAbNUXvu6NJIM0yIsGNUj58wmsVUBkrhIouJqCX+qQ9YfayGbpMh3FppVxo96bxs7cxO+7nvyCI5jit8HJvLh5/3dp7votvbxuyVX1r8YZ/yr5wQYIhVKpumXlqkkJbINSVySNycBaVVL6g1TsZOyyGuxxWNImOKZRDvx4iJZuZN/xazzF26g2qbwxf6ozY1p2EARORDZrPNbwyKHMmv2S8Mzn9NOUuyXIuf/5fT6MrlLDK1vHiqT0ODVKRCCCOjHi9u24AEVkAAGdQiEScomYYMGe4g9GNJEIgACAykKMDBQaIFoCQIVZJ3+bwmY22aa2FOdq01DqgbIIVHXWWU48PyqNxirJJNzoqGweIioF4ltsFMUodD9McxN8WGEj0ar/v/7smS4AgVWV8xDbDZAZ8iKj2HjhxUxcTONsNcJmpEp/YeZpK/WzxXRaYnZi/UIBV9mzyd2h9+2c+6CpwDXmZwdnhZnZo9yCNyn+c+ltgfO+v51Jm18/f/G3tzd5XbPmLeR99I4Xpepk4l/Xgo+8+sHK1uYVHimLTmZjAY8JLhf0Jh4vKqjBKnSezSRxLoubgGeGfZ7tIu8SoS/vZUkwF7qPRXza3VcqTOPl5g0vkUm1wSSTnqP4pXk1ANBA6ZCRV2kKUdR4WFLoMZ5dCIxLE5O5uKEJDiqACQAAADN9gQwWCGlAoeksdMTAsWAYoDjBAiMJABnYXAasRIFYTfdwGAIB+VB2KMIelT0JgeRZ5P8fCsFXEHays+oCOnfJ6PCaHxzK7xi/mJbVWhRRIKsRdHxzsx1VXDK+vRWK6Je67c8QUTTVIDG/z+y/Ty1NR7fT1h/zuFn6tL/E1qu5XP+utfH34j/X/z9wbf+bHl+PinxJaf+TF/i2q3nfV8VX31WWcnjAXlhW9X9gwGmMoGMhpG4zOG/YUWpguvG0t0CYjOAZN3BQWXww+iVgKU9Qkgt0kSVPNMgJQHLLTNIdpvKaR9JRqnWaPc2drNs/SrclUVrZLM1mySSLMrezqoM2tmsq3/+6OdRqzidZvQSSjou/iuLwxSBBBAAEY2IIaUPkdtDoaQumcuDKagOEYhlgAgMJAqAx0FQNjJgADFAGDBceiIKgIGQhA8aAc3hY2go+goxYc+g8HCTGkioSMgCUQMUQBR4YYCwgFC1xLDlCcviCAaQqWk5IEs0c2QA4SxJFNCpfipFBU10uG5MfVOqqmOUA3lgCP/7smTOAAWJXEzNceACawiKHqw0ASQljya53QADvTHlLzegAINq76baKbQF3NTeKSobNISCTMeumhlBFNOc4EolkDO6jK8kjitSBH2SpWa0V/OM9eOegiSNeibRIfcB+nzht2KDKCoBbpUlUw4T8U1JfvyB9IGmJvGTUlXdtzpJamIjWwx3L7DqYXIrHZBL6S38rdiB7deEvpdnpVvC5lyJtMf595bFLMEy+WfZ3/wBWziMO2IatZX2A2ruR/+eOL/okoxjgAAABACBGqAAAkoMTVDXikwopNRPTUxosAhl4LBQYzCg+RDYgDhgwLAOOGg6FBciN6UFIg00HSYDGGOEMLXYM0GAtDMKnRWhoyxsOojTt9wjUAorKkeAaDASpNQZFExiVxVJZy6zsPm+8ZfpAVAyZjvuVAlK9U08dDHajSpl/L0/djUxPzl6JRCq/0kqVJmYk7cZbyvqk5Lo5KMrMC0d+j+hzi9BjcvdwqWpZ9J81uzlWsd1l3OvfuWc69TXzGsr1a7qtqtjfr/2va7hNU27GO9YY////Zqm1Yx5/LfP//zuS/mF+plyp/T/rt47/3b6EAUkZxNjRSlW8VhzWIwGgQBnK+RZmYkNFGqmqoUosoTYKxQiBFxBGBHQvrBCqZM16EgS66u30kjmI2LYipcZ94uyNiZQIaGBpuQ6zpurBzoOW78eh9kDJVJRmkxbs6kqt0sP0LzU8L3rCSy3KKW7VaYh+WUnZyrLZ2zlORSB4x979xeUWqtLOzs/qxvWqeCL9e5yvL6S1dt1MKHC7bo5dDGNqOUlaru33L86n2e4UnO0+U/TUtLL/p9U1eeqZf/7skRfAAcLY1H+ZwAA3wzKPcy8ABKteUy9hgACPq8qI56QANxqX5nn87zHfzluvfv1N2c79/fc8+y7LlWR2+WQaeb////9wAjVqkLi9lhaEYRDAaCspwhizYlYBsw8ZTAbEYERICQiGoIEJAQKGqm1SGQ0x4A1w6iuVKOUIa6Goe4JPJbhIz7ZhCx/SI1AQW1dH6exzlAyKYskPRiuQ19aiTZ7K9bxJGgtpL4+4zO6Ub+2mU0HHNdbX063PF5WzMTmp4RuGQsQGCIrHjyG/f5hMMFtfx0YoHBzbLQzoNJSH5l/HUDBEpLHZ36XgQ2SBiDBYIV0KeNUjWwKqDZMWnw8mtStb/01+1KKu9nPMzsGtR81vAZEWtt5pUVVIEL3mv//v//1uUGAIHNcJ/0iSJjJn+noZmb1XGvZxvTQufuutFrPvVt0L0cW3na5M2pbc2ZpX/ralq0mjnvxAsEq5W6sX/6JESjQsF8tv1fRbnZpfZaM55+Wq6tfdjYu3Zzm3U2pW7lTjA00+b9l8/KSJheWN15OuWlt6zEXv/Da98WR+0gPORMXuoMma56Q0Zgh0t7b6P37kZZMaWrSSk72jgB0H6W0RkXrepTtMNRvXsGO99m4KKSNSn4+pbiTmWK2si6vJBOC08uUZ5CUdpSsaxcuMkiJF5Kz3ShEyTiC34VSXf9sT0kh95AspGTyu70evgjTvEOwJ2QoqsXnKUF1Dc0xZv6Vo0Ye9GiUbmtObeIo7YWJDyc3TJYpQKadKIYJSFf6ctrVGw8Fbye5tWU4N4QTSJgAAA1wygJOweVOVBmyTaNrWUz1EWZsTEYbL9yl8HN5l//7smQTgQU0YtP7LExwgWvq32EljhRJfUvMJZHB/66qfYehaKuLyU8U9bJz5odSjjxpPtm0hXs0qUOc77XfGs/StW+XODrTaDemlrfZfmEoKu/mBOXU4lmz6E1OeQhFdlEzz7OB5T8lGMVbM4VC65jTr5yoGyzSc0pWsflJabzUkU2JHZpWpFeixYfSfs44lIhawqDVWvJBOMHq9JE183MrFH6rxcrcpmfbJoANPcTkSLRMXPGC1xNxK0OIpqHCfxbjHmnP+shwKtLidMRijMKXAD1K8ZxnFZ74kqUbm0ynqS39RrKVV3oy4UvJVHyWl1QWd6Tde2q6Epu37RB0tKTv386ovpPltlbd6I2Y1pWzGH0V8l5Q4LDoKcp2FSyC3EG0zlsYjDKWqIIRAYoRUdkc4mqbf3kBCvRbR3EAkLYXY51y48KaMi3LrYwvFFO1rdw8nP+X6sUE6E8WPpd/TjWxss+RxUUkIAA+36ZnHpiaosis98RLRgyQv9I2cxKQA3+9Tq0Njk9lohE9xzId5wS3OcU29o9XP8enzGRWMc8smx90C+nOY6+2xC60mJrnkA7aRtNc1JyQKx4qhezKNZRQ95AgwxPVW4TFxSoclAAAJgCSwYbCbM5BKpEBqUKXaPZ4lQo1YfhDhKsLDZfzXdY29VXaBnvihFYxmgPiQfoXxSjiV/r9Tr1kFo/4v56kVmv0lRVYZqb/GUPb47lX8Od/WVVzF2uvJrl4fhxa4eq314URvZmaEFbgdF5ZWu4i0t99mGyeRU0lCChHMBRAADSF/S6xnIDfOfEyoZgTrCSUVqVbVWNXEqBrUKwm47rEquh1l//7smQWAQU5XtFzD0xgfKraf2WDthWxdz3NJfPB+a6pfYKO6epu/jRvStPliZ54Se1Frhe3ilrY3NiN2J9FglEjr7y5w6YhxHnUIWcmFR3tKEZPmNs5AuiFV4ZW8UpfrCVHBEif5F2VYoUcdgqu+hCQhmGnkECxBS/GUMXImUDSWCHJJm0DzgmLGpsBtVkuFRTrkBHlSc3WvTSRpPWK9K6l28KhrVIyAAxh0xAYmqRBJQiSK7wlUGjQqu7UfpcbzxrPp+Z3e7w9+b17mK4KmtXa9P50u4c11wx6tLbWscGynX0+CgwNstjFXt6KPVfgb4e2wP+ljmXe/8OgTFIY58+NDkM7xs3M+ofVY5C9o0iZxwWQUScEQTOSpa6kBCihAAAlAxAFiT/kQIhqvEgiMlOHAA8MWmKkSqBJCLQOcdBMSq+83KZ3VR4qZ4hBaMVDhpBqBOJdAW2ijaU4Ks0k2jjZCmz38zoVa2k0Jm6QtfvDStRLGIakVJNktWLIQqGWRDBBayau+KwMRYYDW8ixL6krWA3Y7xujPpqOG25hrFhLStiSpBn3reH1r2mmvrMWOxM+NMLamvlUuetxm5mi+SJvygkBS0Rfs/rJxifhmZ68SgC094alyr1mSmHCQIiOErOKzYRPdPWiq07wICobu5ujC5RJKZUdjCtASob1u1q+5HDwwcYggLCgdUctaUrUYYNNNaqLKUSdjRR00EmdViTaPlb8zclEY43nJwE15Iaqc2JfJOxvYygRxHekyEDQMHBMGEPsYpbaAFFaAACIGZZTzRAwiDGmX6oYZWkTAzg8SFEAMgqx/4AYZBKEM7unie43Bf/7sGQVgATeZ0/jKUVgdYtaHWHiPhoBgTKOPTjBTA0o8YeZaC6KGu4bjkziMVnCdpXSf8bJ8QKZsGDZrZMlfcpS9toqeaa9pxz3CeDYcl7FNt7pVBLmkLOUWfb1ksu5b7VQ1s2mGgRUnKVPHpeNv5eYtBpsixTZKzzMeppVqaqzTlQHzjHME1j7LqOxUdXNX42viPKcA8toIRBEABOZ1wE6AaYv2RXgZMiSACAMAuCcLYhjgzFbWFlhJeriUMkVjQ9nH0iVe/bkPFkixwMGHAG5FvBLrQO4NzmsdlC3R2kXdk93+uUqKqd+zmZ1QqCVKqsZrCjsVaKZ9j/Wr69K9GV6KgUBMgURKMJ6QAjyAAY0ELYCqGjE54ObDkBBhshgUgGcFqasIpjgKGJU0BgmYkAScLdlbgw2CQjgeRLyWGXE5IBNwQiWMWwoKyQbM6p7Jg4aR18KUvuJBB+s1sEQcXMss4f7Wywi7heLdWJjRc7UiGF61Kk5FdhEQUtXLetfxC/q7D0Sl8wFhDMXtAOPL9Q76yhV9oCJW6kjMfSUijbyaKCQBGtKKzkcHwKqpk9/oWzCi6bNkrZL7qWKtbMu8P30RMF2rcJWaIULGtapto6r9uP7JkTieKX/+8oQxBNKyAEXXKB5AyZf2D2ztxVbCnjLulxkgwUNgp9ifdkPYBeBBnC0nKyjPP5a2om6LAm/kqRsibXNNPJ45odD1b5Nnu8VtppReIj3Xb7Efd9iKgBBQQAACBCRurp3CqaG7pI0FgQJAKIKbQOAzHQBZJIEowYZjgQYEGoLRd3IGnpHRDpUPPjAIGaYNULUZPGTed7aSaKo//uyZCICBcdizeN4TSBVS0pfPWI+Fi1vOo0lesFOl+r88qGY1adfAQleWdyczGx8RVDlek0Qv4qp2tCliiYVKw5dSNDAcFzQOCFbVhpFCkaMRJxDSDP8QcaUi/oMj9W38kX6JpaPZupIhM03ZUX309bJkWZ0nteFQzz2xu0Xs4a7sa0moLEGOKDitctBfKJthXjtu2t8j0/QIgpwYEAARNpqN5hKNaL4qnMmA/0qGJrbuTITP4uoIpw5qqQZ5J+r6FPMGPsKTY39msLXR22ep+DburW/oqaeurpWFWcr1dUqXsmyf13+Tv7UW+MltBAohAANA0STXGFz5+8iEaixiBpw+4yKMEDQXLAcuzEoxFxqUPFMJpwXHkVdLoakrQ6VARhyLj24mEAX6cuXqyt5LI+ztQ5s2VE3aBKWXvQlxCNisXIIWIwNj65tpey4FtOKAgKGLJzhJi4nTfYrXnRGBaUEJGu2pOK/68ttJA1fKQy2r2k0EqNB8xh4VLpRE31JrtQjyhiFLtfqUlt02QwdSa8balW/kjm86BRQAc+g9rMykHcDAAdJYBTcBSAaBqj1sA1Ar80DgH42Py/neBCdTjaY7P4lKm0TuzQbi5QCABBKWWDROqm0oUFK4nd/vhPq2/aEqKks8HC8H/qII////6N699VoYNggAgARmLwco2SYwoJCSh7i6RhogDmVH1TZvQuEoGNbjjc4ca3RQ79BfwUXHiF2qjpixVI+4JzXprGLtetTb0WYdnolQvPMVVFneYjuqfenAs9MKiFBZqYKqtCVORXuy648BW4ph/KSS3TbT18v+NvuvPJj7ogCQ9J/7b7z//uyZD+ABQ1d0GNpNoJdhFrfYYJfFRmdR80ld8FhLOq1hAj4G7fENYrf/589v4Zm9btbtRJxZdk2s9EK8wTTYwf0e61894GQQAsLARWaJKoVWDxqtwsWUUd3N7s7Y97/CVY9HO1369l/tu6uhp/FU99kEVlk5kJJodjoAUTUrFS9sKaBo9FmtLYh5aMbb3VAJaOm3n7ByjkQOLhRODAYC4Jj5MgBAoSYAADIJZpZ5qhNIIzRkUZfpeYwUMKoSiexgqHV6qT7iFrUvrTdTnEl1Q0lR4U1MdcbjU3MPkKKywFr1MFEc+trqp8/i7v2UBHZyMsuWb1yx6BGjR+jEM8oIOs77dCFF6YR/Yo5fcJd4XT3EnGLauf2ZHlLQh5EEdhC05JsS2BZHAP3XLziY2QrCiOaEjpweAFCHXIghvOm54fEIKhIeZmlV6rv5vTYAIA0k4QSUVBxNSBb9ydcXMX+94ujBPe8rkid0kIi4pHV09lv//5O4h1J91ujZPzKz1P5HulZNHo8O6vJ9Xav1PoRKM+cdqgmcx9xI+wQ7lOJHUDCQhAlVKoCCAUyMAVAADiaSaGuwKgThhlCzHCkEYFdtkRxb8qj1h3t00Qv2ri3Ptd/DyQS3t/GIIU1b2DMp/sbJ448mJcweUav7n2K/4Pzf8OqYKZzrnWJfW48UgCS/SRIZuk3hxqvy5FsXqJt4dFmM4jOZUj3rkY0u1Sn2dpuni1MYu61lcs07bDmsXwVyrbcMpbEbKyv60xnsX6f7exk/3ZFeZOSCMytoIrtTM6BU0CAEDFNnWK+SYLXW6Om1GiomtON0TQCIUD+VHY3v9sFWO0h//uyZGaABRteUXNJZdBYixqvYSJaU315R61hZ8FdFqo9h5S4+7l011/npVtwb/11BhWo9Sctn+qkp/v9NW6rmtr5tG0ft1K1WbVdDD0B3cKxa/Qgw7UAqYIABM76UykQENm6AM1bYVJHKDWQcpASOjZP3kNhwhouok0btjJD2/yzKka2+bNmjPFs3NH7ykOGzDcWtPvTJBZ1av0j3JsmwaobyfmoMVHrPMVr0mrTRUXVqu+iKWyjxcMLm+aG9XU8k1V8NWvYg9ktNW9WepUwLWb2M7mtkzUoGq1NN3LRdNciHazA3Urma2nwzYLGrLAMLA1VxKKAkAESm61+IulbEWY11PFzAjVrIlwyW97Pr+SNfMihUEZCd9kVFIZJKf0U2UaINr9olb1QTNABOl6q3TrlZuNvstNJdFoIx50XPtaUCLgZViABBwkyIxhSIAAMak0DX3HRQCGaOANBTBhIyEOQ2BQKDQQgBUrreDwkwan3unXnK53YwBsXf+cYWDgJs72XVAIGz46hpPRnF1WqSDOaUH/5Njc0kkwxUKRK24ptZqTTjbIz+JfOxyXyv2o8bmrbe52/E9fIrXJmdruvytzygkz/csjMuY85OxV0fnOHIwcFVjQ8WWR+QdG9+3lUXPXooUDVlKWtuhKh8G0JAJWLHQpha+9wYRcpU6b4TYP9LyS2sCF3wGyhM5OrRFVapjeLdH/4iI7u6gORQREuV7jYugusiXJwTf/x/6aae1zYo/1uh2JL0rrDCEIJFAAMlohoqEiExsRO7LnBL8BcDMYqxo8EmsmFBjzsNNUQdL5SudVgc+lmIQRLjPr5G6J8Pw5K//uyZJaBBONeUPtrNbBW5Rq/YegOFI1zOa3hKYFrmSj1hIoYfTSp+kYuxWkwvmBcWrrLsbed8Sso2xdzClkWpLmZ+YYK4cUncShLkIEQ/LZX5SNvxy5x9yb/WOIe1bWB8AjT9nBerQEbNQtv66VxBEmZijhubsvFbsKRc5jB+vPgNli0JuRJilrppsqJJ2kjgZUqNEIgEDWRKU89kOOdP3G0nb/GQOdN57gRY1Paj0vBY9+XBRQzMQGthJuUt1VpTPQd1vLlbkiW7/yBrGSpYIt7QVYIxZ2HbSojetM7VKvhLlZpSObCo9S6ASQCAAAMZfwMAqxCpOcM1AIZe4ZCjQqgxAHGgpeJc0MK6bCVExsUBnzrH4pnKkOSFzp06TgGGRHHsrxOM/RKWg+z2Bq6Nh58Q8n+1alvs9K4Dw9TLNuljMvf9lBKa/IclB6jWaXa+JoWs2ZF/098nqzjrVqBUqe7BDHyTie5e97MqqCNKPLq/pSfiT5MpaX+N3D9m5xeTzjiStdVyg72u1FCCGonktIkoSh1GIjhX25+VAZy1GgMV/mQnaA+pb63Ee58AtDcS7EjjqddG83nyfS9jfpmdu6Ax3ZHmVlR0974w5Ug5TwowW1LSYB5jUoSRMz6a2/rLKoUVnSYAYlQncbGVDEAMZbHokqDA4ORDT4gzLglj62NH5TpVFdjp4TCMs72OEgxUUYusCEqb1U/Wk0d+RCSGuVC6mKEEsSmF0pJsy2i8PdjmUNBFn3kto6OKyMBgd4Olz+ELa8wX4kwrKmOrg4t6JVw1lWPxNjht05d62kcj0lKhEyiDaG8fqN9Smt2ut/SESUk//uyZMSEBQVbzctvTSBbBdotPGW0Et1tN20ldsFiq+h09IoYq9dZh2MMH0uhsE0JPItsIAigSZciSJAUJYEYXQDu8cbIiL7ZNsWd+qkagZsDv+NAWWH8FH9l5sYykjed6EEN/9KkNwbUTb/76fP//+6O2ndD7L7X////44IozgaHuSoA9fRVFAgBtcIGFQGIAyYrEZ+cWAozF6BCGzSEjASsDgw2SmEh9K+wwHGEILacboCIFBAEYgvAKhAiBikJYShEwaFFV0R2ducpvYlu/XEQ6RYEN2wKFemkKM6nOB5W73P1mac6cLQC+pVhxlhniXbC2w3FFDWketTdDn25pI4/FQuP4g+yh5tAad2okvuKH4qQ6yCDO4bJG2bA0iPcZM74RhKw+h3rs/LTx2wnRwyfphUGy0raJ8iRBBBZASFsS1+9JmtRqqr/1a0HRGgALQVmscDo1YGNEJhOg0AhCAwjaqbw+xh3MODsCA7GCm60lk8ToDs/Xh8XgQHQz5yjN17/O2viy9/azMIMhiKc+oWMMfCu04kdp+vl/0fk1ty5iYQKarOyCgTyXw3IKeZl0d2ZVyXp41BYZuwXP+GAJwg0kEKhZlMeaTvGqEgGIIaENkZWVlx2+ZQAQVi8kQ4GCgh4LOg7i2yQJGG4jMTEM7lTcQ+VE0mGfWE0MivSiXUtWUQzFL9vkt7k9czSYao6PmFn7X2pfzlqBJz9Y3+bj1TDC7J5bvs/rLt7CX/jvv4Zz+Wd3mf/jWnv/mX9oO51o3Gsf5v/+WYY7gmh/8NX/+n/u6/LH7zz+7zDuV7DDmc9V5+PP/cNzmVSC7F+vX0LpEAH//uyZPYEBiZey6uPTcByawnsZYJsVslxNDW8gBnWHyeasRAA/OpJXVREcCywEGLVBqwwL1sTFlLtjNiCGsPNhDimgNgomieKYN7h7hgM8ZidS2bilAQQAkjOlomhrnVl8mxrHCiiiSRzQPnKll9J0zE9XNikgUDVelahZjM426Oo6ls+gtv1M+tXRu5g6qhjxLREqbfjqW3pdAAABiADCCCCCXoxEIzXzDMAGw0i3jcq5OEOUCncDMowgpTBoCMKFMxEHTCYKFScGEAwaGAgKgYtguiKMyLQYwcPeS4QXIhUoZo4CihiSQoMNCsC5wzK8WHN2TLfYygBH+y1ECjg4iZhwAgjXoYY63amcNOdBcIAO6YkiBRiCJW8v/OP7k1C5BCsZaB8oympSLCCEWomXBLhshkzXHRi9uXS6ngOpGH7bo6jG1FmlLRL5IpLAw7VszD0S2XOpKHugyQQPHtS+RXFgpjV6ablKdOlDz71aPteW0lj8IbgaH8punnKLUYyjr8RJ95LnMxmrSSuHXRl0rtdhXzU7vmeP6vTstlVI6M7jbp872/lMrmYzuhd6imKbKsCbf///+l1AAAFJACAgCAQDISKSjQGEplx1mFWuaphxjlfGfl2YdD41AhQkhw/AqHMFiYy2GjD4IJgADhYYeCpggijVFb4CSmAJp0ihQKjTIHjPQTLGAcUDki2AAIM6CM6FNYKRMQHsgMkJU3VtGQYqdMcdNQYXoygMAQppCSo0SKocoJKbp8iEqF1hMXa82jjsDiK9/EgZb5SlOxVJyWQIJUoVA1yssZbDj72V2RprD4I2sSZaAgqHJIVZ8DMCbLD//uyROwACPNkzU5zQAEr7Mm9zmgAD+mBVb2FgAn7rys/sLAFVE6i3NxikoLtuGMi6KgTcYPfyaVM0l4n9Y/lLYs/s5HJmjiNWTyqZj9ykxtOFD8AXIbkEVlE3KbFDMUz9RuXuRAO34uQ49MBT8vanA0tuUl3feYsHe+M5TzlO6/PKKWz+NnkVicjq3IcmNSygqWKSv36AhjaiAAAUneCME6UklBkTuOm0FqMnmmdKLQNMcznAJzWtGrK4msjpnrno1OtYbO9Jz4dKJqannf/NRzL326P/iI+qc6//nZXLeI/4v/9k/7Il+c+J4rdf3NvurqKuGVSrzl8vu4qnvUNJfL2OLEB2EiWvTPsOFZvFyfxPD3sdWBBs1UyEwSSQFS8gs8SDLU0o8w5X6PsOSOUs8jU526/AbOhLO0YsPdkfLJmtzpRb1B3RO/NU7rnq5+Xsm46r6tSoVmdlRX722z/ivf1Xx7Gu7bvuvj5/uIf8vhlbpfHT+ulK80Wll71Fl6k4gTCotRJQ7O2vPqvMS9Bn7i3ueGVAQcLVGAE4kk1DWpEWD3rLr0qwrGk9tK+RUU6dOd5g2gVJGZG0mr35nHX1bklnN6/FVFGSBQTrcsgamffhnkyKpWxi5TIELADdmB/1NH79ivQeUXLdoaoxEwTVal6LSOvSitvovCU62RUW7ZFfuc9PrvOT2tg5F7gfjTe7ptGHaQpaLXhWe3xIkwgg9RWMZmYStWX0SCEGWQ6hbyiR8W6Sbh0ay2sazKbO1TBmOhEI36a6RBTCoAgAzhwJLQEpZPCaHsJYF/5dU6DCgmnHLLE2L+VSWuUlTzTyI5AtKt+//uyRG8AA/5eVPsDNdB8KvrvYeM/T/lrV+zhAeoDrWr9hKIYPB60MjX1UyOSysVIrqJFZFSpnEgkBkhuC2nBO1/6EFq5SmgF9NAlkl8tJopWmhEHAEhjODTiwBILSRkSCVm3bjfKh/7hIjqGbnxFUNbxNw1j2dRDNDuSVaXqefa5vpxgL6Woqvx0C9CtLUU8D7HW3/AxevuNl9Rt/3AvDU6VZKRvST1Sbu6Vw3N9RM3ErW8za9OtidxxmNpbSiCb9NBRYsuqIkukicptqmwA/I9ArkHJgkSTWdAxC2mUeX3T/xm7WdY0A27h8210gyHm+/UsqXPUjeVY+tJIvi/2ZK1FqCqV6V+ipJNexLDaONujJ+Bl8c/MP6vX8QTN3KToM7rS/qunHjrriKu7LmalSVks94i0RCAjHuISF3WDxhlQmoUEBg1FAACiRACN+qG4l0RgIM/JVWyhI8HBIkKmPhiHcsAgiApdML7dseA7WcrOUGwai+LhOLZed2GN2UJF81THkpZN6ykLK6q6te2FmLEkcLAqKO/+s9Nz2cw5rgvtYJNaBa48gfxEX5l8s1vtPjG7u9vuEx0Tfuze7XTVF0pfoLG6tPHRcWD12gjvwkEOQPYROXSIMDBUiAMZY0kGb8NBZi3RE3CLs8X1hDUhR1TSdzx1kn9C+ToVOEQBGhjUaC8vaPnToRLNptKh5qZNVdXaHHY5nqqJdF1dJXW7v8rdU74ZTZbatve6OqXyu1evqX+5WvygWiDVrZa6EMGACAkQE7/HCDRfY6FmqDSV7SwYOGHlhdNCKWKyQFB31g4UAepdIQvEfAFJCaY6q4QIwkfk//uyZJgABJ1eUXtsRGBmStp/YWJsUqlzO429LsG5nSftsw7B7KSQW3LSBkxWLKQqIxXxZL3aDak2/n5ZqfbzpIGerLKWYhu5II0tPPu4i6X7/G/1SV0o7vSDk4+0s/lj6WZhU9Z1M5CNQv5kUX3L965np7eVpt/M9J7SEizEltWCNEqCOOAAawM0gSyKWRfYBC0gYqpiIw1iiCsWjsfx1NygiBrX1HwsZ3Z54+VlXtEVDyvaeLLugfNlBP0kATf+0isyjhh2PXmhNQaRi+Zmhw/BeZF9Mz/wwo+eHAdzVC1uLUjtE+u8lxN+f/LfNqj3+SUIIUAAACb1bBgaX5Gkw1VOTAIgIsBpgMeJNyfCtyiQWBc6qfxdsIcaKLLGTsc6SFgGZNGdPW3R6FC9K31LizwgS8p3MKFldiwIXS1DmVITwpyGGEpPfTjsqUUhw9e+jqCvNhjapf0y1qVql3OV+B6ntt04TKm2iWu+jxnDedrauTsXBgereyqVY46jFo1J2K2t82PKSdPuqDBf5Ohy+Y7hc5GTAFMtuNJUAzM7DAjOVAza9UcEHlmOKLcd67ez/oQdGvyoFRIzR0R18+BYn1pll3ZK41Gq/3F1Fxt74fbnDaWGhEcDEMyzZIAtWtz2dqqTzz6MyjTs+2S5oUUdFFrM+oQcZFzUR0HDoqAGKBhn1OTG4CECI7NGJAUnoPIUpvJAPnhEwcLmBgcDWXREibGMJc9VVpyG0FVchFpdYKX7hqutQZBeh58DHH1GMeB4tMnnPy4ieMJXB4+3iRHSCSBTgQjPhqy4Iv4ryxnzVKQKjc5LvtDsWiuHq8oWti98b1kv//uyZMCGBPxeTVtpXcBhxFo/ZetKEplpN429EMGjIim9hY18FS81jYRIlnkQQiHKPNo0EIP0YX4iKAw9YRIitrG1SRKgqIzEkYOMFBBFXSdStrgjgeiVB3gixsTMuLK/EpEGe/Rt152mtIJ5IN55NqcFgPZCVnZN6pYUWZgqsaHSaHrVmqfkW1P8i8JmV1UTSynemmGSImEEs67E7ZIVdDhJBAAJvychxiSgMRg82r1jEoEcMKBA1OzjM4UUppiwCDCQewhglAphwGGYQ8+70EAICoCKADSlgFKGKRn5CpWh+iNfUKf51W4gLExRjZFJPSzgiDgeXfOKrWVXCfRcGchTTllWGzJiKq+cwHGJVqRL9sfiJxt4P6b4hOBiTTZcdVdKZ5uC7UmMxXcX9xe17O9zOncWzZgrPoypY+9JTH1Nu0FgO3mBTeNeK34anX4tIdLcA04pR9qgSso3Iwu0dvKC1e7u/9QGDFLCCmDY0SkOlVXU5SuJtXrA6MLLe8kBgGaI24eGXsZ9vsEO42X8HZVdGnYbe9ds3X61kqEWfjYDgyJA5G/kmO7nE+Cpvnav2xPlvm8tNIHBVyztqA5DkxDjUUkihKOeDr29ksAkiG2D8n7gM0AAY7vCMBCYGMMBTdMkeIUBQjCwI5mTASSKgTjFkWKWn8MMAjHgJxarS9ESmC/H4Xq2EuWaMghwti6kRagWIy8weJAgQaXfIOSLCoZ5Bla4n0eEY+/0RPyuInxso6seTX3KGYJLbX1d3qccvXP/e1mIJdU+ad4/72FX3ASb87HhC/0th5ZLqbDqts3h1SG3i0bXIW8odbR5zzTR/9cG//uyZOiCBidfSquPNeBspXovYeZNE9FpMy29MQmsHun9hgpcDE2lWDU90bmaxGmXpTwDmNBIDiiG/VraCrKW3gnCOpeMYpbnCAbbzTXNTzo/F8XfbfpVj0UO0SII4oVUK5os5ZdGWyooMcrqDZVQ5MQSttCvk9unVvTRdATtBK6+IdyrklD0w8redErbqABAwAAeI85icMKBhUMGYF8PBwwUDTAIcMqNI0oHREAkiUOJi4Pq7qEoAMEgsyUK4g6KCgylVtAOhJop4SB4lY0QyYuJlBGJbLIZaPFZ5yr79vlFnwgyeswKqZ7LPZyexuxx2pz3RnX4tuI0OAOVIIk9S5UfrGWNkU9+gUl9y97tKCsm6GlQLL/LiEJN7MmaPWB0LuZAx9h1SqPE6zHFwGqWaRosyd7pTUmVTavqwotf7KwRsLbiea2iq+V6+sjQorDummvxsX58qLOE5CUr/1/vQCaoAACBNGTRoRXSsN1Yb/ZEFNGxKoBrMD5vNl70JciRm9nTTrV6rdvdDr0tMTbkmNbGO1f0nYR+BpR2aQj17Q2Md5DHhM6ZWbElq2tNHNYje1dGa86r3qJnVEIenu1ZF2UtJLrf9uS+RqignnLVgYQDEAAAKJKShqbDzl9TIiTliULI6eqCY4STFZ28ZZSBs67fjz7VLTUOeDMygWukkUQOUqIrLDpzlh0ZV2l75cf+3aW+UjNdbVL7FQ8UOevyZSHEUVKrOgYb/l+GDq9fnZiy9kixR2bBMwJhE6S2xzD5TlgcDKspKFN+AuopswcFjZY/ZQz9qmOp/ZfzKWiM7VP5hswsaWRHAjuhOBMltsc0orBZ//uyZPKABo1eSiOYZGBuivmraSWyFhmfPe1hhYKBsSh9haXxZ7MbvXxu/TS8ydv+DApXJCAEsxOKp8xNEclACWwMipDoclUKMbDhAA/gdLOJKnAbPbig9KkpvgfRFGFJzDuKh18OVmfQ7ZUUyrZ80K3PRo2JZAgYRl1oZO1yf/pYuoQMRtfNQKka6M077OPXRkGQmkJCSCBEeVkgXb2TEiemCdcnadO8b2E092FEe+ZG3rE7goFCS5ukKEA5IKCRkkRwilIkdNumPJiOB3Q9JtUyBwggAAFEAQttWi6xkA5GYZWDjAJOmSVx8OQLkaYuyUzKMAU6u4a6crnuyo2j5MvE11/xMMlU0WmAl4zb7TRJ0srWs4rxU18sIGAX05dqQDx/CWQw8kzAEblMuNL7VYS9ZIkc5hkcMJDkp824S+2x23viSkiTuAMQaF9e5Rg7HF65DHnMjLZZciK3sQJT5ZSxcYxM85hUbF6FRDgHZVVse1iEFINjLkoNJ9pSaxyXx0UUZ6/bZj8R0AS2KMgSAQgEw4UFYayEdJbeFVJELOBXkuUePLsacbHPhEdMHENQvxxf/zR3qe91RLO7//s76hgTuea6l24pDAtphYeSNGPybBodlXMn5uve7nXnd82+OyjSjt5z6ya9rb3uKvveX2Qb6TzfgSvNhf8TsOIH5Z+T+Y8ShUsatVkDQGCUUBKYAAXQjlVEYgFa03ckUVcItpeL0SXJE1W8nCEBYxIbUxWazPVArBsVlA5KK2YoWlShLDpyb3PBr1ks0hSZ+zP2o3H1LJVE9UEIC/fpZKclT/Vzc5cUieDapD+kIHfoWZ3NmNFx//uyZNEABdFizvNPYmJ+a2osYWaOEk1rQcw9LIHBrOj5lY34F+r/ig+rdzb3JNO6RTXdqW9PFXKXB6z1N6OVQpvcqgjCM2X6swspdAx0FBLEBjeIAkMtANDiMl3aJAWkSjvgog/6+HHx+q4gwb4fjJsLJ8njAaYPU3clFrsSv4ltoy75qOZV9VIcfc38cyYF/yxB2zOfnAEw3DuafAhF6KdL+9mblLlxO0OXrIVy8sfq/WvFJjowTJVB2GaaFWUqK5MRJWlEEIdAmuy1DkBEsfRgLPjJ2LFsU61HUfU8ux5Q9neX5oncZeetU8DhmslckyRaDjRDiGTZ5GfK/1xrfajAlInq/sYuNab7GzTtA/tf8o/nb+v4O09ox454WqZai6KqKi4aqXqJtZtB/ER3aK3UeWVAl7NNXn4NB4nRRW+OgEnpQEnGo5ICqMDHZu3JD0xpa8g62wPk1XMJHF80vAj4cQyHGW3xtUU1KPAgzyczEj33cPvqIvQqFk80QQGh89xc8sK2xJt9Ct/UD6Umq9juZ7iqa+Ba7u6thZaHrW6qs8PPDPQ5PiHpJaTa70OaYEaOPKJQQZfHEngMIi1OgBBAggAAlAAABM98oSBO/63UWWWUzBURdGCSwFLuStpQRFbxvTU72PT0n+huJPM3mpXK7OND8c+DCnkh6jGioRiNGvcbS6uVAOmjLinuUv0xT4zV90sfh3+b11h/pmpt+kbALpWXBpqjyOlzkloIGnUc0ZRJY2ErdqJLPiNFMZUagXyzSuMIqMo5J7IfOxusjLkKQoYOQAQgAAELGj1DKCjtMncdwhDmmEkQkKoL0NkaDNhJ//uyRNqABAVdUfsJRDCA60ocYYhYEmV7N8yg1sJcLSbxp6UphIA6oN4B2O7GYUxfqnupjokiMz+xT8NtDsmUDmjr3MeOUljS0a9zEhuG9hfOpsPEm9pSa2Nqn/bOdVhtiSstnLd/TZUaTe3JIWZYq515odZbIUpJsMLzhhm1Tu/KtqK3WfO1JTvZSm48zqUk7xMyiTJBgv3e7+IIEQAAGlooIAxkCAoUOZ6xH9UoM5sBYbSbcghAUR1wS+KAAAB0I9roS5kTQMUGlnKA9vLgIRHsAMWUSxMtItV4MRxRtL3GGHRAG0wrkPWjp6asoaiwlFw4+Bo2f4+gVSyd1xorudWpdx+CmdVpS7jDTiqGrM7CcHszyOdiHk1q3cF09zpkVrrMzyftz6FjrcKPLFadezybWMR4XdRGrPVks+WBVRMLtwxuFBpN6ws+FOe5/hjEUbAArygQLTH8Ev0VQYC6w++w6JER9ljFXCJCTCJzUfZUyydtcj+O4NtRD7lHAStfbv5TZVRSFnitLUSHgyr/iLaUHC1hMu0fMlROFaYwpk2DK15diie9uqWmeGUjnodmqQsuhgz5WK2nNvq5Rv7ATooxIjSZQGDAYVzODgUjLvkSYC7jTDjXCQQREMkMAIgoE18pv0DWGAJHoYqKFpFeOHLYKCwCBXCla+ErH1X/clrXGXisnOrrnyK1yMVk98uS5qLxf7g/zYjYeFiu9xJnUk6oDZ1Qxc6r+NmthIcyFFXxf7lay/IiDjogjyGsdUnN7fIqQ0xz/HHNRHWNmfqKgOCzpkPij7GJNXrP1SoEUAAhQlFjPJe9T4WEC7BpLG8EX8Ma//uyZOwEBaBeSyNsfWB2CynMaQK2Ev1pNY0lFsIdLWbpkxcQRAYiyYIaKzwtySEagzVcJcBLiG5ZLIw5NND+EobhAjF5/sEKDvPVr15XD9TRMBvl6dTs3d71SOQvMpi3OKSqCh7ughNVr3dFR6LIjqjZmyK1XRQKUezKjlKQ0Xc2UyHq67ffPd1a6dFYaylKyCI1TvXVEAoAIAAFkUklEZjCgp1QKMEkAHoh5QQZmMGHAyOICNGGq2qPNOYc6NsmDpkxcVLestvXAuCIQ53HqAoOHLC4oy3JCcTH8EO0nExODVMYdYfWbx3pq/nVtd3cnXjYETOaLPHD71/h2mQsvnQvON0Rrwo6AkZ6oWpRNnakj0ZGBC02F6LeHI8s366zNBnvmGuBGow7av6N2+TYAoFAAEIAjMFYkIzT1AzEZMnPjc286gpMoSzNQMKqRvhihgZKLAIhMJFTXTlXiaI0FGCgwAbR4eYCw2iBpWTwZLuCARyWymcgMRYJVApTzUc4lxD8suwyFhWdf2gh+d0rGcoIXRjxKCCsTCIjzB4uc0zH19qmPWOKyG/bOuebzimnNdM1OzvY97Itb29DVn086tVkGcO8HjDgQAAZIoExE9NcYGGqWACwYYyds2aMmUB2AF2a8KQlQxDt2HBWhBAWiLjTWsP+MEpOQ8GsQ00uLj6DtDHiA4fKVyoXBwCxpidjQ3SlBZuixilUs8nMkD6zA0bMnbSTculV3Wk6FlnKk1a1aaupFPUldB61G5+itt9ai/0mrr1vZlPWvOons6mrutjQ9Y6bmtE6IWtOVKHFIYAA6SabgGIi9hmYuACMxA6Fy808//uwZO6ABMVaTvtoFqKXSzmMbweIUtVvQ7WpgCI1oed2t0AArMHBjCB8GDhpYSmuwdwB0LMOFGsQ8NwmwIuhQgyBw0FtFvMVmYsoTiTBoQwGgQN4AsIFaiojMB2CcDGwdlQN7oppTcxP1IWrciVLIam11J9R9KtmUtBJVbI1rf9OrV/pNpdFFlXUuYn8o1lyo7rRTBp4iNiDPdQAAwCCFhB0BzBsNhUSCUfBsgqQ7Zo0z4+NHSyxNOugz4RIkkYH0AumDq2hBAQgGDoASa/whBHRjAKKzBsU0YyRULAJlpJIxDhSBNnhfCBx4RTZQFDGG5M9DmSJ3HEoSrGAmguWKlopt4s5L5vmXy9+5RYhyA0tFnl04LRHLiwWrFDzZW3aTF4Xel8v1wDZG7cZypAYIwBEALEMheF3YTAsBymk3bn+U8/etve1xFQQBNZTkTGZizyXO5O0kppaaFNai9JzPLDCrL4HsLkBw5fBbrOntd0CggwQu8Fwa0qxlEWu2Jm7Symnf+5LH4m6efsW5/D7eCRj9oFKwuGoI4BdoOAYgihTJ0Nkh3UM1efWp8auPcf7c//wdff/4wu0VGAAUQQaYCgYDAYCkMGMVEAaCmAn4BQyWaMCCUXxY1TQMHQQ6EUPHhJsIYCA0qAxyCPIXAiDmm2oECvVcoOI24CYmCglPzwKVRVFr403d11jzyw4bBkBjAVRxqFzVGXjLJp9v3NFT4KuaUIOpnR6em+fyKOQ1yKRNOcuCajJhqAFmU9e17fdz21Yy+EMv2riHJwxKKuS6qFiyWtKgwz5qtd+ko7efYEicXlcP23DgZtEOLY1UGxqUP7/+7JE64AI/WZU/mcgASow2jrN4ABQgV1hvYQACgusbP+wsAFfllmjuVb3MtYyB24vDmPbMN311xdMVcEAL5oaKAWcJJMiWxhbw1r7OP5f//+UPyuXxiWfDks5L9WNceZ0l+xanelw32czJ8IAlcqjv///////////////////b/n597/8///////////5ipP7u42sbYbvsNPQokAEEql305REkyqZElE1JZaIzkr0i6YzQGs07peFiQcDoRVHigNQ8D6yxY4aIZvT0J7Q4smu7U56TOMt6R5jcTKYWeYNVSxQ9a+kSqrbnSdBzHb8t6uelJd9VvMtx0rj+aip4SIr9kfauuql4Ra/3c/xDPJi45rkJYQjN2LDnc9qRMkVmQBSBKSdEMyQ8dSAIQKHtdVtVUcVpbTWuQI9Eyzhwxk4AE6TTq2TTZu4nMPH1DqrTROmnqQu3crKtt7lPbDabyvbO5VbDDr+/p8vO1udT2y156rayH7Zvq9kV1HU06EJqK6rqq65mf6u45fz1u72y3hlfoVSz7mdnGlG//5lLy2RRGRGQgaJJBcFEoXVUuYfRKgYUGtFXbZn1YHlP7k622qERxBOiMVR9GB6+SIcm9S8HHo8CSx0VT3w9vs5kbfiohlY/1NWFRLslH8adnVWfz/ZkY/S3tm/3naCH+5neTt/If0+40+mAjPyiy1u6euTXvuFqfJziQG+yDN9zUPx6/Xty2JshnYJUFVEhEEALHaAlC7lwJSIyGifCWsZpbEWxlPG/7e3625XrWHGznEae2bQN5rLTt4GhxRKeGSBhDFgw58OkomzdFPpvnb4dCBUKW78ifb/+7JkaoAENl7Zewkzsnhq6x48ZsoRfXtjzL0JSdiurX2BiuhewTdCPsSUuTrt7/1/33Kb/xuJnpv8pWWfnxFJLtg8qDo0UcfPslDlm4xSsiszEaYog5hRLqVkesKtgYCskqiyto7UkCJFKGMrkYck2GE2ELjWN1TKLtjE2SBpg7kU9mD6oNFdHOHYwIhEmA+CPpYGTY+Z7S9RErgQTR/RqyMIGzKy3M37zUKvEiGZUDCeTniJWrzovTTx/+QsLd8Z3JsTI1P4vmWW7IOsaT+hUxjxG9MbReX5ZOY3ZHhCPtJMhQcObYLJHiy1qKlKrFNrLn2mwSl+Shb6XcJS/H9vdwqY585VdGlvTeaddLSBqWEhdFt1g1gUSWRNmBd7U6BgUBiMrQhU3FlhJa8Ms28lLSmb+n3qp+386tlWzH1tZPtHBiqBxDIdHxTgxEdR7seqlCtGhEE6iQAjC3hBbIBbFQfRqGquymSBjHaQk8Gp3BgE6hRkEgVi2BBoMlDXeeyylSKbf0FCjMgnLKdqlLjZWcZD3u5U75KXzw5IdzKXI86dUfQKwCIFcQ5UCmDdKbZPbbzl1NPzzD+efDozIHQcV+Yx1sXYf8Kl/6hztFYxIoSCACy3cHEpk11E1PJ8qOLE0270KBSV/nnoJHj8MU1zt2glO6lypLKHCzW9OYIQVCoKetjgyRSnQUQ6A0IJcUQmmYIUEEMcYEVuK2FWSlg44a+bZnkSJQmSR2hlvs1fIit83HbXV580a7ZLNf2w0Ntw2u2ziRUiL6HQxEDhGhoY6wAwXW+6RhaFuiZpcxVR7YSp5urQIzLHxxl9HKU0byBZclX/+7JEkQADzF3ZeeYcMoArqx9gZr4QNWNfzCRxQgYu67mGDaFddLAwVplArFSPvHNUjinUpYSoWWkWwumiFtFlEIiUHNdxbGwIDLCXcwZRRhUgDuEeEWCSp/51dVBH02KbnZuuh0dQ4jBHEdaiV4j+q5FWSRRAFQomC75tmqFOVNCITQAAwYNSTlItSAapAYqhQNyE+mHL9jOZChR2aF6mrOMrKYsP1DVNo0abQIjvPFkEwgYK1GM5ssJMQomBzorD2rAwAHYFNzU9wAGqCXQYWbC8NonCLHYVkwMMVqLfJfim6UdoW6JGakkKT1uTKUA5FBjCWaMYpgeW5T1TsGaFKFZVRDiSQBcBSEoNgpwhDCLcD8GubgkpukmVEAsTzEkI3lMo0a3PYzrwGINH1BphWO8OWMsWSVmh0Hjy4a2RUGDCi1qCFmSTEgRSqVXbmryliNKeP0eu5+eK6jnp+6lVlEQfXb/X0obmfrfLuaXL5Db4bc8sclZoSdz0ymBPUjq1XdNd4VDRtoElxRaoo+jEn8RRLlH2KXZcFDRqoqJ8payWlrbqvLKDqKLYaj4nx2FSdrkUPRPVJi2W0ljNuSmqJZRgxSdprc+BLVJsw8IGCCPmTSG0HFrpaUOFmnM+JbGkLGJslLIiUND1EttLHkyYikz0q7koQ6fM1Egjjfkc3JgzizEA8gBZzjCSN1UTOlRsoEIagS+WzzRf2NRqbjMQpaV0aR5gQhIjDBcFoRigfnGlEkMZtA2CFJkiTBezSdTKlVjbtXvEVekHs5LQpx26t6EpEPaZTPcM22iKeam+RLIFj4gvKw6iGqzkwRk1JI5x+Qr/+7JEugAEElfYeeg1cn5rux9hI4hP9WFbzKBxwg6vazGHmOjM8cw+YHGQiScihWS1vatJMgAWXHcdja1BXSAFFYvcGIhhJTlB8xGVMHUjdSLTz7wkBRaNANCDx9N0zH18NOisMYw+WURymUpqpmd+pUcM1VZblHr3TkmVf+6fMmnd3Sl8U+novU7sv4mvvmLkv58j/LvKhEadrU7Wdls93Vlz+97keL1/Hz5e9qxSjRS1CifItuQkUEAEJiLq1ZtT00CrQlD1OGDWBOAyiMt3Yu8ciVPkJMvo+na/MMwhH8jHSNacPmJIwB2AgYUJSDWdKuBOQYTGawO4QMCtj4DDPpIdojUUyUOEuyug3MZaSuW9i9S7dRtvW2sXwHFZjJfuehESe706GUTovIl7ZLHf/dK95WMsKEJIACZkFSaWqn8HHQgXmrmAkK3CWVDrIAgO2j9wWl5Z6w/aVzQ7Jy5YsXMU6/7AevS+qyG1qrX6PvfBBNz2zjbbRCcG4kMLM1IZ1L3uQIcyVS655osS+pQ1M65Dt04YbmGJ9qSaFJKc2BmxZckwqEVrgiBgkFOD4UWgLgolz+ukICEAQAA6GgGG8JEokKBQKcMBWbF1uLTQEr/ctxKV/qm2ZzAaBHdaZEkTS+GoTyQ1zUfeudsypco9ZFeiCrUuLjoxZhLOsKlOVWG0UIUihOEjhZloWvIRncJHne0nkmoja2eloz2RgqFGvRxRd2LqS7uLnMxE5da72divjLLZseYo5Ws85FO+n0aUdBdmE3ftTepPS3Z841zksl2KxCWSBAAAquSIb4vInubRhwVcDxW5rOTuTlcdnTjwTDUAABShbW9vdgAAAGxtdmhkAAAAANZCocbWQqHGAACsRAAT5FsAAQAAAQAAAAAAAAAAAAAAAAEAAAAAAAAAAAAAAAAAAAABAAAAAAAAAAAAAAAAAABAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAgAAFC10cmFrAAAAXHRraGQAAAAP1kKhxtZCocYAAAABAAAAAAAT5FsAAAAAAAAAAAAAAAABAAAAAAEAAAAAAAAAAAAAAAAAAAABAAAAAAAAAAAAAAAAAABAAAAAAAAAAAAAAAAAAAAkZWR0cwAAABxlbHN0AAAAAAAAAAEAE+RbAAAAAAABAAAAABOlbWRpYQAAACBtZGhkAAAAANZCocbWQqHGAACsRAAT5gBVxAAAAAAAMWhkbHIAAAAAbWhscnNvdW5hcHBsAAAAAAAAAAAQQ29yZSBNZWRpYSBBdWRpbwAAE0xtaW5mAAAAEHNtaGQAAAAAAAAAAAAAADhoZGxyAAAAAGRobHJhbGlzYXBwbAAAAAAAAAAAF0NvcmUgTWVkaWEgRGF0YSBIYW5kbGVyAAAAJGRpbmYAAAAcZHJlZgAAAAAAAAABAAAADGFsaXMAAAABAAAS2HN0YmwAAABEc3RzZAAAAAAAAAABAAAANC5tcDMAAAAAAAAAAQABAAAAAAAAAAIAEP/+AACsRAAAAAAEgAAAAAEAAAACAAAAAgAAABhzdHRzAAAAAAAAAAEAAARsAAAEgAAAAChzdHNjAAAAAAAAAAIAAAABAAAAJgAAAAEAAAAeAAAAHgAAAAEAABHEc3RzegAAAAAAAAAAAAAEbAAAAnIAAAJzAAACcwAAAnMAAAJzAAACcwAAAnMAAAJzAAACcwAAAnMAAAJzAAACcwAAAnMAAAJzAAACcwAAAnMAAAJzAAACcgAAAnMAAAJzAAACcwAAAnMAAAJzAAACcwAAAnMAAAJzAAACcwAAAnMAAAJzAAACcwAAAnMAAAJzAAACcwAAAnIAAAJzAAACcwAAAnMAAAJzAAACcwAAAnMAAAJzAAACcwAAAnMAAAJzAAACcwAAAnMAAAJzAAACcwAAAnMAAAJyAAACcwAAAnMAAAJzAAACcwAAAnMAAAJzAAACcwAAAnMAAAJzAAACcwAAAnMAAAJzAAACcwAAAnMAAAJzAAACcwAAAnIAAAJzAAACcwAAAnMAAAJzAAACcwAAAnMAAAJzAAACcwAAAnMAAAJzAAACcwAAAnMAAAJzAAACcwAAAnMAAAJyAAACcwAAAnMAAAJzAAACcwAAAnMAAAJzAAACcwAAAnMAAAJzAAACcwAAAnMAAAJzAAACcwAAAnMAAAJzAAACcgAAAnMAAAJzAAACcwAAAnMAAAJzAAACcwAAAnMAAAJzAAACcwAAAnMAAAJzAAACcwAAAnMAAAJzAAACcwAAAnMAAAJyAAACcwAAAnMAAAJzAAACcwAAAnMAAAJzAAACcwAAAnMAAAJzAAACcwAAAnMAAAJzAAACcwAAAnMAAAJzAAACcgAAAnMAAAJzAAACcwAAAnMAAAJzAAACcwAAAnMAAAJzAAACcwAAAnMAAAJzAAACcwAAAnMAAAJzAAACcwAAAnIAAAJzAAACcwAAAnMAAAJzAAACcwAAAnMAAAJzAAACcwAAAnMAAAJzAAACcwAAAnMAAAJzAAACcwAAAnMAAAJzAAACcgAAAnMAAAJzAAACcwAAAnMAAAJzAAACcwAAAnMAAAJzAAACcwAAAnMAAAJzAAACcwAAAnMAAAJzAAACcwAAAnIAAAJzAAACcwAAAnMAAAJzAAACcwAAAnMAAAJzAAACcwAAAnMAAAJzAAACcwAAAnMAAAJzAAACcwAAAnMAAAJyAAACcwAAAnMAAAJzAAACcwAAAnMAAAJzAAACcwAAAnMAAAJzAAACcwAAAnMAAAJzAAACcwAAAnMAAAJzAAACcwAAAnIAAAJzAAACcwAAAnMAAAJzAAACcwAAAnMAAAJzAAACcwAAAnMAAAJzAAACcwAAAnMAAAJzAAACcwAAAnMAAAJyAAACcwAAAnMAAAJzAAACcwAAAnMAAAJzAAACcwAAAnMAAAJzAAACcwAAAnMAAAJzAAACcwAAAnMAAAJzAAACcgAAAnMAAAJzAAACcwAAAnMAAAJzAAACcwAAAnMAAAJzAAACcwAAAnMAAAJzAAACcwAAAnMAAAJzAAACcwAAAnMAAAJyAAACcwAAAnMAAAJzAAACcwAAAnMAAAJzAAACcwAAAnMAAAJzAAACcwAAAnMAAAJzAAACcwAAAnMAAAJzAAACcgAAAnMAAAJzAAACcwAAAnMAAAJzAAACcwAAAnMAAAJzAAACcwAAAnMAAAJzAAACcwAAAnMAAAJzAAACcwAAAnIAAAJzAAACcwAAAnMAAAJzAAACcwAAAnMAAAJzAAACcwAAAnMAAAJzAAACcwAAAnMAAAJzAAACcwAAAnMAAAJzAAACcgAAAnMAAAJzAAACcwAAAnMAAAJzAAACcwAAAnMAAAJzAAACcwAAAnMAAAJzAAACcwAAAnMAAAJzAAACcwAAAnIAAAJzAAACcwAAAnMAAAJzAAACcwAAAnMAAAJzAAACcwAAAnMAAAJzAAACcwAAAnMAAAJzAAACcwAAAnMAAAJyAAACcwAAAnMAAAJzAAACcwAAAnMAAAJzAAACcwAAAnMAAAJzAAACcwAAAnMAAAJzAAACcwAAAnMAAAJzAAACcwAAAnIAAAJzAAACcwAAAnMAAAJzAAACcwAAAnMAAAJzAAACcwAAAnMAAAJzAAACcwAAAnMAAAJzAAACcwAAAnMAAAJyAAACcwAAAnMAAAJzAAACcwAAAnMAAAJzAAACcwAAAnMAAAJzAAACcwAAAnMAAAJzAAACcwAAAnMAAAJzAAACcgAAAnMAAAJzAAACcwAAAnMAAAJzAAACcwAAAnMAAAJzAAACcwAAAnMAAAJzAAACcwAAAnMAAAJzAAACcwAAAnMAAAJyAAACcwAAAnMAAAJzAAACcwAAAnMAAAJzAAACcwAAAnMAAAJzAAACcwAAAnMAAAJzAAACcwAAAnMAAAJzAAACcgAAAnMAAAJzAAACcwAAAnMAAAJzAAACcwAAAnMAAAJzAAACcwAAAnMAAAJzAAACcwAAAnMAAAJzAAACcwAAAnIAAAJzAAACcwAAAnMAAAJzAAACcwAAAnMAAAJzAAACcwAAAnMAAAJzAAACcwAAAnMAAAJzAAACcwAAAnMAAAJzAAACcgAAAnMAAAJzAAACcwAAAnMAAAJzAAACcwAAAnMAAAJzAAACcwAAAnMAAAJzAAACcwAAAnMAAAJzAAACcwAAAnIAAAJzAAACcwAAAnMAAAJzAAACcwAAAnMAAAJzAAACcwAAAnMAAAJzAAACcwAAAnMAAAJzAAACcwAAAnMAAAJyAAACcwAAAnMAAAJzAAACcwAAAnMAAAJzAAACcwAAAnMAAAJzAAACcwAAAnMAAAJzAAACcwAAAnMAAAJzAAACcwAAAnIAAAJzAAACcwAAAnMAAAJzAAACcwAAAnMAAAJzAAACcwAAAnMAAAJzAAACcwAAAnMAAAJzAAACcwAAAnMAAAJyAAACcwAAAnMAAAJzAAACcwAAAnMAAAJzAAACcwAAAnMAAAJzAAACcwAAAnMAAAJzAAACcwAAAnMAAAJzAAACcgAAAnMAAAJzAAACcwAAAnMAAAJzAAACcwAAAnMAAAJzAAACcwAAAnMAAAJzAAACcwAAAnMAAAJzAAACcwAAAnMAAAJyAAACcwAAAnMAAAJzAAACcwAAAnMAAAJzAAACcwAAAnMAAAJzAAACcwAAAnMAAAJzAAACcwAAAnMAAAJzAAACcgAAAnMAAAJzAAACcwAAAnMAAAJzAAACcwAAAnMAAAJzAAACcwAAAnMAAAJzAAACcwAAAnMAAAJzAAACcwAAAnIAAAJzAAACcwAAAnMAAAJzAAACcwAAAnMAAAJzAAACcwAAAnMAAAJzAAACcwAAAnMAAAJzAAACcwAAAnMAAAJzAAACcgAAAnMAAAJzAAACcwAAAnMAAAJzAAACcwAAAnMAAAJzAAACcwAAAnMAAAJzAAACcwAAAnMAAAJzAAACcwAAAnIAAAJzAAACcwAAAnMAAAJzAAACcwAAAnMAAAJzAAACcwAAAnMAAAJzAAACcwAAAnMAAAJzAAACcwAAAnMAAAJyAAACcwAAAnMAAAJzAAACcwAAAnMAAAJzAAACcwAAAnMAAAJzAAACcwAAAnMAAAJzAAACcwAAAnMAAAJzAAACcwAAAnIAAAJzAAACcwAAAnMAAAJzAAACcwAAAnMAAAJzAAACcwAAAnMAAAJzAAACcwAAAnMAAAJzAAACcwAAAnMAAAJyAAACcwAAAnMAAAJzAAACcwAAAnMAAAJzAAACcwAAAnMAAAJzAAACcwAAAnMAAAJzAAACcwAAAnMAAAJzAAACcgAAAnMAAAJzAAACcwAAAnMAAAJzAAACcwAAAnMAAAJzAAACcwAAAnMAAAJzAAACcwAAAnMAAAJzAAACcwAAAnMAAAJyAAACcwAAAnMAAAJzAAACcwAAAnMAAAJzAAACcwAAAnMAAAJzAAACcwAAAnMAAAJzAAACcwAAAnMAAAJzAAACcgAAAnMAAAJzAAACcwAAAnMAAAJzAAACcwAAAnMAAAJzAAACcwAAAnMAAAJzAAACcwAAAnMAAAJzAAACcwAAAnIAAAJzAAACcwAAAnMAAAJzAAACcwAAAnMAAAJzAAACcwAAAnMAAAJzAAACcwAAAnMAAAJzAAACcwAAAnMAAAJzAAACcgAAAnMAAAJzAAACcwAAAnMAAAJzAAACcwAAAnMAAAJzAAACcwAAAnMAAAJzAAACcwAAAnMAAAJzAAACcwAAAnIAAAJzAAACcwAAAnMAAAJzAAACcwAAAnMAAAJzAAACcwAAAnMAAAJzAAACcwAAAnMAAAJzAAACcwAAAnMAAAJyAAACcwAAAnMAAAJzAAACcwAAAnMAAAJzAAACcwAAAnMAAAJzAAACcwAAAnMAAAJzAAACcwAAAnMAAAJzAAACcwAAAnIAAAJzAAACcwAAAnMAAAJzAAACcwAAAnMAAAJzAAACcwAAAnMAAAJzAAACcwAAAnMAAAJzAAACcwAAAnMAAAJyAAACcwAAAnMAAAJzAAACcwAAAnMAAAJzAAACcwAAAnMAAAJzAAACcwAAAnMAAAJzAAACcwAAAnMAAAJzAAACcgAAAnMAAAJzAAACcwAAAnMAAAJzAAACcwAAAnMAAAJzAAACcwAAAnMAAAJzAAACcwAAAnMAAAJzAAACcwAAAnMAAAJyAAACcwAAAnMAAAJzAAACcwAAAnMAAAJzAAACcwAAAnMAAAJzAAACcwAAAnMAAAJzAAACcwAAAnMAAAJzAAACcgAAAnMAAAJzAAACcwAAAnMAAAJzAAACcwAAAnMAAAJzAAACcwAAAnMAAAJzAAACcwAAAnMAAAJzAAACcwAAAnIAAAJzAAACcwAAAnMAAAJzAAACcwAAAnMAAAJzAAACcwAAAnMAAAJzAAACcwAAAnMAAAJzAAACcwAAAnMAAAJzAAACcgAAAnMAAAJzAAACcwAAAnMAAAJzAAACcwAAAnMAAAJzAAACcwAAAnMAAAJzAAACcwAAAnMAAAJzAAACcwAAAnIAAAJzAAACcwAAAnMAAAJzAAACcwAAAnMAAAJzAAACcwAAAnMAAAJzAAACcwAAAnMAAAJzAAACcwAAAnMAAAJyAAACcwAAAnMAAAJzAAACcwAAAnMAAAJzAAACcwAAAnMAAAJzAAACcwAAAnMAAAJzAAACcwAAAnMAAAJzAAACcwAAAnIAAAJzAAACcwAAAnMAAAJzAAACcwAAAnMAAAJzAAACcwAAAnMAAAJzAAACcwAAAnMAAAJzAAACcwAAAnMAAAJyAAACcwAAAnMAAAJzAAACcwAAAnMAAAJzAAACcwAAAnMAAAJzAAACcwAAAnMAAAJzAAACcwAAAnMAAAJzAAACcgAAAnMAAAJzAAACcwAAAnMAAAJzAAACcwAAAnMAAAJzAAACcwAAAnMAAAJzAAACcwAAAnMAAAJzAAACcwAAAnMAAAJyAAACcwAAAnMAAAJzAAACcwAAAnMAAAJzAAACcwAAAnMAAAJzAAACcwAAAnMAAAJzAAACcwAAAnMAAAJzAAACcgAAAnMAAAJzAAACcwAAAnMAAAJzAAACcwAAAnMAAAJzAAACcwAAAnMAAAJzAAACcwAAAnMAAAJzAAACcwAAAnIAAAJzAAACcwAAAnMAAAJzAAACcwAAAnMAAAJzAAACcwAAAnMAAAJzAAACcwAAAnMAAAJzAAACcwAAAnMAAAJzAAACcgAAAnMAAAJzAAACcwAAAnMAAAJzAAACcwAAAnMAAAJzAAACcwAAAnMAAAJzAAACcwAAAnMAAAJzAAACcwAAAnIAAAJzAAACcwAAAnMAAAJzAAACcwAAAnMAAAJzAAACcwAAAnMAAAJzAAACcwAAAnMAAAJzAAACcwAAAnMAAAJyAAACcwAAAnMAAAJzAAACcwAAAnMAAAJzAAACcwAAAnMAAAJzAAACcwAAAnMAAAJzAAACcwAAAnMAAAJzAAACcwAAAnIAAAJzAAACcwAAAnMAAAJzAAACcwAAAnMAAAJzAAACcwAAAnMAAAJzAAACcwAAAnMAAAJzAAACcwAAAnMAAAJyAAACcwAAAnMAAAJzAAACcwAAAnMAAAJzAAACcwAAAnMAAAJzAAACcwAAAnMAAAJzAAACcwAAAnMAAAJzAAACcgAAAnMAAAJzAAACcwAAAnMAAACIc3RjbwAAAAAAAAAeAAAAJAAAXTMAALpDAAEXUwABdGIAAdFyAAIuggACi5EAAuihAANFsQADosAAA//QAARc4AAEue8ABRb/AAV0DwAF0R4ABi4uAAaLPgAG6E0AB0VdAAeibQAH/3wACFyMAAi5nAAJFqsACXO7AAnQywAKLdoACorq&amp;quot;&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;type&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;audio/mpeg&amp;quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&amp;gt;&lt;/span&gt;
                &lt;span class=&quot;nt&quot;&gt;Your&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;browser&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;does&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;not&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;support&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;the&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;audio&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;element&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;
            &lt;span class=&quot;o&quot;&gt;&amp;lt;/&lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;audio&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;We have taken care of the preprocessing of the musical data to render it in terms of musical &quot;values.&quot; You can informally think of each &quot;value&quot; as a note, which comprises a pitch and a duration. For example, if you press down a specific piano key for 0.5 seconds, then you have just played a note. In music theory, a &quot;value&quot; is actually more complicated than this--specifically, it also captures the information needed to play multiple notes at the same time. For example, when playing a music piece, you might press down two piano keys at the same time (playng multiple notes at the same time generates what&#39;s called a &quot;chord&quot;). But we don&#39;t need to worry about the details of music theory for this assignment. For the purpose of this assignment, all you need to know is that we will obtain a dataset of values, and will learn an RNN model to generate sequences of values. &lt;/p&gt;
&lt;p&gt;Our music generation system will use 78 unique values. Run the following code to load the raw music data and preprocess it into values. This might take a few minutes.&lt;/p&gt;
&lt;div class=&quot;codehilite&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n_values&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;indices_values&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;load_music_utils&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;shape of X:&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;number of training examples:&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;Tx (length of sequence):&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;total # of unique values:&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n_values&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;Shape of Y:&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Y&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div class=&quot;codehilite&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;shape of X: (60, 30, 78)
number of training examples: 60
Tx (length of sequence): 30
total # of unique values: 78
Shape of Y: (30, 60, 78)
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;You have just loaded the following:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;X&lt;/code&gt;: This is an (m, $T_x$, 78) dimensional array. We have m training examples, each of which is a snippet of $T_x =30$ musical values. At each time step, the input is one of 78 different possible values, represented as a one-hot vector. Thus for example, X[i,t,:] is a one-hot vector representating the value of the i-th example at time t. &lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;Y&lt;/code&gt;: This is essentially the same as &lt;code&gt;X&lt;/code&gt;, but shifted one step to the left (to the past). Similar to the dinosaurus assignment, we&#39;re interested in the network using the previous values to predict the next value, so our sequence model will try to predict $y^{\langle t \rangle}$ given $x^{\langle 1\rangle}, \ldots, x^{\langle t \rangle}$. However, the data in &lt;code&gt;Y&lt;/code&gt; is reordered to be dimension $(T_y, m, 78)$, where $T_y = T_x$. This format makes it more convenient to feed to the LSTM later. &lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;n_values&lt;/code&gt;: The number of unique values in this dataset. This should be 78. &lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;indices_values&lt;/code&gt;: python dictionary mapping from 0-77 to musical values.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&quot;12-overview-of-our-model&quot;&gt;1.2 - Overview of our model&lt;/h3&gt;
&lt;p&gt;Here is the architecture of the model we will use. This is similar to the Dinosaurus model you had used in the previous notebook, except that in you will be implementing it in Keras. The architecture is as follows: &lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/karenyyy/Coursera_and_Udemy/master/deeplearningai_coursera/Sequence%20Models/images/music_generation.png&quot; style=&quot;width:600;height:400px;&quot;&gt;&lt;/p&gt;
&lt;!--
&lt;img src=&quot;https://raw.githubusercontent.com/karenyyy/Coursera_and_Udemy/master/deeplearningai_coursera/Sequence%20Models/images/djmodel.png&quot; style=&quot;width:600;height:400px;&quot;&gt;
&lt;br&gt;
&lt;caption&gt;&lt;center&gt; **Figure 1**: LSTM model. $X = (x^{\langle 1 \rangle}, x^{\langle 2 \rangle}, ..., x^{\langle T_x \rangle})$ is a window of size $T_x$ scanned over the musical corpus. Each $x^{\langle t \rangle}$ is an index corresponding to a value (ex: &quot;A,0.250,&lt; m2,P-4 &gt;&quot;) while $\hat{y}$ is the prediction for the next value  &lt;/center&gt;&lt;/caption&gt;
!--&gt;

&lt;p&gt;We will be training the model on random snippets of 30 values taken from a much longer piece of music. Thus, we won&#39;t bother to set the first input $x^{\langle 1 \rangle} = \vec{0}$, which we had done previously to denote the start of a dinosaur name, since now most of these snippets of audio start somewhere in the middle of a piece of music. We are setting each of the snippts to have the same length $T_x = 30$ to make vectorization easier. &lt;/p&gt;
&lt;h2 id=&quot;2-building-the-model&quot;&gt;2 - Building the model&lt;/h2&gt;
&lt;p&gt;In this part you will build and train a model that will learn musical patterns. To do so, you will need to build a model that takes in X of shape $(m, T_x, 78)$ and Y of shape $(T_y, m, 78)$. We will use an LSTM with 64 dimensional hidden states. Lets set &lt;code&gt;n_a = 64&lt;/code&gt;. &lt;/p&gt;
&lt;div class=&quot;codehilite&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n_a&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;64&lt;/span&gt; 
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Here&#39;s how you can create a Keras model with multiple inputs and outputs. If you&#39;re building an RNN where even at test time entire input sequence $x^{\langle 1 \rangle}, x^{\langle 2 \rangle}, \ldots, x^{\langle T_x \rangle}$ were &lt;em&gt;given in advance&lt;/em&gt;, for example if the inputs were words and the output was a label, then Keras has simple built-in functions to build the model. However, for sequence generation, at test time we don&#39;t know all the values of $x^{\langle t\rangle}$ in advance; instead we generate them one at a time using $x^{\langle t\rangle} = y^{\langle t-1 \rangle}$. So the code will be a bit more complicated, and you&#39;ll need to implement your own for-loop to iterate over the different time steps. &lt;/p&gt;
&lt;p&gt;The function &lt;code&gt;djmodel()&lt;/code&gt; will call the LSTM layer $T_x$ times using a for-loop, and it is important that all $T_x$ copies have the same weights. I.e., it should not re-initiaiize the weights every time---the $T_x$ steps should have shared weights. The key steps for implementing layers with shareable weights in Keras are: 
1. Define the layer objects (we will use global variables for this).
2. Call these objects when propagating the input.&lt;/p&gt;
&lt;p&gt;We have defined the layers objects you need as global variables. Please run the next cell to create them. Please check the Keras documentation to make sure you understand what these layers are: &lt;a href=&quot;https://keras.io/layers/core/#reshape&quot;&gt;Reshape()&lt;/a&gt;, &lt;a href=&quot;https://keras.io/layers/recurrent/#lstm&quot;&gt;LSTM()&lt;/a&gt;, &lt;a href=&quot;https://keras.io/layers/core/#dense&quot;&gt;Dense()&lt;/a&gt;.&lt;/p&gt;
&lt;div class=&quot;codehilite&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;reshapor&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Reshape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;((&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;78&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;                        &lt;span class=&quot;c1&quot;&gt;# Used in Step 2.B of djmodel(), below&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;LSTM_cell&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;LSTM&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n_a&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;return_state&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;         &lt;span class=&quot;c1&quot;&gt;# Used in Step 2.C&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;densor&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Dense&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n_values&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;activation&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;softmax&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;     &lt;span class=&quot;c1&quot;&gt;# Used in Step 2.D&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Each of &lt;code&gt;reshapor&lt;/code&gt;, &lt;code&gt;LSTM_cell&lt;/code&gt; and &lt;code&gt;densor&lt;/code&gt; are now layer objects, and you can use them to implement &lt;code&gt;djmodel()&lt;/code&gt;. In order to propagate a Keras tensor object X through one of these layers, use &lt;code&gt;layer_object(X)&lt;/code&gt; (or &lt;code&gt;layer_object([X,Y])&lt;/code&gt; if it requires multiple inputs.). For example, &lt;code&gt;reshapor(X)&lt;/code&gt; will propagate X through the &lt;code&gt;Reshape((1,78))&lt;/code&gt; layer defined above.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Exercise&lt;/strong&gt;: Implement &lt;code&gt;djmodel()&lt;/code&gt;. You will need to carry out 2 steps:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Create an empty list &quot;outputs&quot; to save the outputs of the LSTM Cell at every time step.&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Loop for $t \in 1, \ldots, T_x$:&lt;/p&gt;
&lt;p&gt;A. Select the &quot;t&quot;th time-step vector from X. The shape of this selection should be (78,). To do so, create a custom &lt;a href=&quot;https://keras.io/layers/core/#lambda&quot;&gt;Lambda&lt;/a&gt; layer in Keras by using this line of code:&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;div class=&quot;codehilite&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;           x = Lambda(lambda x: X[:,t,:])(X)
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Look over the Keras documentation to figure out what this does. It is creating a &quot;temporary&quot; or &quot;unnamed&quot; function (that&#39;s what Lambda functions are) that extracts out the appropriate one-hot vector, and making this function a Keras &lt;code&gt;Layer&lt;/code&gt; object to apply to &lt;code&gt;X&lt;/code&gt;. &lt;/p&gt;
&lt;div class=&quot;codehilite&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;B. Reshape x to be (1,78). You may find the `reshapor()` layer (defined below) helpful.

C. Run x through one step of LSTM_cell. Remember to initialize the LSTM_cell with the previous step&amp;#39;s hidden state $a$ and cell state $c$. Use the following formatting:
&lt;/pre&gt;&lt;/div&gt;


&lt;div class=&quot;codehilite&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;_&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;c&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;LSTM_cell&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;input_x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;initial_state&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;previous&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;hidden&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;state&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;previous&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cell&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;state&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div class=&quot;codehilite&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;D. Propagate the LSTM&amp;#39;s output activation value through a dense+softmax layer using `densor`.

E. Append the predicted value to the list of &amp;quot;outputs&amp;quot;
&lt;/pre&gt;&lt;/div&gt;


&lt;div class=&quot;codehilite&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;c1&quot;&gt;# GRADED FUNCTION: djmodel&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;djmodel&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Tx&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n_a&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n_values&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;sd&quot;&gt;&amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    Implement the model&lt;/span&gt;

&lt;span class=&quot;sd&quot;&gt;    Arguments:&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    Tx -- length of the sequence in a corpus&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    n_a -- the number of activations used in our model&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    n_values -- number of unique values in the music data &lt;/span&gt;

&lt;span class=&quot;sd&quot;&gt;    Returns:&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    model -- a keras model with the &lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    &amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;

    &lt;span class=&quot;c1&quot;&gt;# Define the input of your model with a shape &lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Input&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Tx&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n_values&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;

    &lt;span class=&quot;c1&quot;&gt;# Define s0, initial hidden state for the decoder LSTM&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;a0&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Input&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n_a&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;a0&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;c0&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Input&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n_a&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;c0&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;a&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;a0&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;c&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;c0&lt;/span&gt;


    &lt;span class=&quot;c1&quot;&gt;# Step 1: Create empty list to append the outputs while you iterate (≈1 line)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;outputs&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[]&lt;/span&gt;

    &lt;span class=&quot;c1&quot;&gt;# Step 2: Loop&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;t&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Tx&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;

        &lt;span class=&quot;c1&quot;&gt;# Step 2.A: select the &amp;quot;t&amp;quot;th time step vector from X. &lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Lambda&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;lambda&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[:,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,:])(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;c1&quot;&gt;# Step 2.B: Use reshapor to reshape x to be (1, n_values) (≈1 line)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;reshapor&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;c1&quot;&gt;# Step 2.C: Perform one step of the LSTM_cell&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;_&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;c&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;LSTM_cell&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;initial_state&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;c&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
        &lt;span class=&quot;c1&quot;&gt;# Step 2.D: Apply densor to the hidden state output of LSTM_Cell&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;out&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;densor&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;c1&quot;&gt;# Step 2.E: add the output to &amp;quot;outputs&amp;quot;&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;outputs&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;append&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;out&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

    &lt;span class=&quot;c1&quot;&gt;# Step 3: Create model instance&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;model&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;inputs&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;a0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;c0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;outputs&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;outputs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;



    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Run the following cell to define your model. We will use &lt;code&gt;Tx=30&lt;/code&gt;, &lt;code&gt;n_a=64&lt;/code&gt; (the dimension of the LSTM activations), and &lt;code&gt;n_values=78&lt;/code&gt;. This cell may take a few seconds to run. &lt;/p&gt;
&lt;div class=&quot;codehilite&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;djmodel&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Tx&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;30&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n_a&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;64&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n_values&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;78&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;You now need to compile your model to be trained. We will Adam and a categorical cross-entropy loss.&lt;/p&gt;
&lt;div class=&quot;codehilite&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;opt&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Adam&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;lr&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.01&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;beta_1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.9&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;beta_2&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.999&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;decay&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.01&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;compile&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;optimizer&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;opt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;loss&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;categorical_crossentropy&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;metrics&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;accuracy&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Finally, lets initialize &lt;code&gt;a0&lt;/code&gt; and &lt;code&gt;c0&lt;/code&gt; for the LSTM&#39;s initial state to be zero. &lt;/p&gt;
&lt;div class=&quot;codehilite&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;m&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;60&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;a0&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;zeros&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;((&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;m&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n_a&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;c0&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;zeros&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;((&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;m&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n_a&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Lets now fit the model! We will turn &lt;code&gt;Y&lt;/code&gt; to a list before doing so, since the cost function expects &lt;code&gt;Y&lt;/code&gt; to be provided in this format (one list item per time-step). So &lt;code&gt;list(Y)&lt;/code&gt; is a list with 30 items, where each of the list items is of shape (60,78). Lets train for 100 epochs. This will take a few minutes. &lt;/p&gt;
&lt;div class=&quot;codehilite&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fit&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;a0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;c0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;list&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;epochs&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;100&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div class=&quot;codehilite&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;Epoch 1/100
60/60 [==============================] - 5s - loss: 125.8482 - dense_1_loss_1: 4.3550 - dense_1_loss_2: 4.3467 - dense_1_loss_3: 4.3375 - dense_1_loss_4: 4.3449 - dense_1_loss_5: 4.3462 - dense_1_loss_6: 4.3409 - dense_1_loss_7: 4.3420 - dense_1_loss_8: 4.3378 - dense_1_loss_9: 4.3328 - dense_1_loss_10: 4.3407 - dense_1_loss_11: 4.3400 - dense_1_loss_12: 4.3416 - dense_1_loss_13: 4.3384 - dense_1_loss_14: 4.3359 - dense_1_loss_15: 4.3445 - dense_1_loss_16: 4.3375 - dense_1_loss_17: 4.3445 - dense_1_loss_18: 4.3381 - dense_1_loss_19: 4.3416 - dense_1_loss_20: 4.3377 - dense_1_loss_21: 4.3348 - dense_1_loss_22: 4.3374 - dense_1_loss_23: 4.3377 - dense_1_loss_24: 4.3309 - dense_1_loss_25: 4.3332 - dense_1_loss_26: 4.3331 - dense_1_loss_27: 4.3414 - dense_1_loss_28: 4.3366 - dense_1_loss_29: 4.3388 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0000e+00 - dense_1_acc_2: 0.0667 - dense_1_acc_3: 0.1167 - dense_1_acc_4: 0.0500 - dense_1_acc_5: 0.0500 - dense_1_acc_6: 0.0167 - dense_1_acc_7: 0.0500 - dense_1_acc_8: 0.0833 - dense_1_acc_9: 0.0667 - dense_1_acc_10: 0.0500 - dense_1_acc_11: 0.0500 - dense_1_acc_12: 0.0500 - dense_1_acc_13: 0.0667 - dense_1_acc_14: 0.0500 - dense_1_acc_15: 0.0167 - dense_1_acc_16: 0.0500 - dense_1_acc_17: 0.0500 - dense_1_acc_18: 0.0333 - dense_1_acc_19: 0.0833 - dense_1_acc_20: 0.0500 - dense_1_acc_21: 0.0500 - dense_1_acc_22: 0.0500 - dense_1_acc_23: 0.0167 - dense_1_acc_24: 0.0667 - dense_1_acc_25: 0.1000 - dense_1_acc_26: 0.0833 - dense_1_acc_27: 0.0000e+00 - dense_1_acc_28: 0.0833 - dense_1_acc_29: 0.0333 - dense_1_acc_30: 0.0000e+00                                                     
Epoch 2/100
60/60 [==============================] - 0s - loss: 122.5815 - dense_1_loss_1: 4.3327 - dense_1_loss_2: 4.3033 - dense_1_loss_3: 4.2750 - dense_1_loss_4: 4.2805 - dense_1_loss_5: 4.2683 - dense_1_loss_6: 4.2616 - dense_1_loss_7: 4.2467 - dense_1_loss_8: 4.2309 - dense_1_loss_9: 4.2306 - dense_1_loss_10: 4.2222 - dense_1_loss_11: 4.2159 - dense_1_loss_12: 4.2396 - dense_1_loss_13: 4.2136 - dense_1_loss_14: 4.2056 - dense_1_loss_15: 4.2119 - dense_1_loss_16: 4.1996 - dense_1_loss_17: 4.2205 - dense_1_loss_18: 4.2172 - dense_1_loss_19: 4.2046 - dense_1_loss_20: 4.2094 - dense_1_loss_21: 4.2107 - dense_1_loss_22: 4.1830 - dense_1_loss_23: 4.2017 - dense_1_loss_24: 4.1849 - dense_1_loss_25: 4.2274 - dense_1_loss_26: 4.1660 - dense_1_loss_27: 4.1823 - dense_1_loss_28: 4.1908 - dense_1_loss_29: 4.2451 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.1000 - dense_1_acc_2: 0.1833 - dense_1_acc_3: 0.2833 - dense_1_acc_4: 0.1333 - dense_1_acc_5: 0.1333 - dense_1_acc_6: 0.1000 - dense_1_acc_7: 0.1500 - dense_1_acc_8: 0.1333 - dense_1_acc_9: 0.1833 - dense_1_acc_10: 0.1333 - dense_1_acc_11: 0.1333 - dense_1_acc_12: 0.1167 - dense_1_acc_13: 0.2167 - dense_1_acc_14: 0.1500 - dense_1_acc_15: 0.0667 - dense_1_acc_16: 0.1333 - dense_1_acc_17: 0.1167 - dense_1_acc_18: 0.0833 - dense_1_acc_19: 0.1333 - dense_1_acc_20: 0.1167 - dense_1_acc_21: 0.1167 - dense_1_acc_22: 0.1000 - dense_1_acc_23: 0.0833 - dense_1_acc_24: 0.1167 - dense_1_acc_25: 0.0667 - dense_1_acc_26: 0.1833 - dense_1_acc_27: 0.0833 - dense_1_acc_28: 0.0833 - dense_1_acc_29: 0.0500 - dense_1_acc_30: 0.0000e+00         
Epoch 3/100
60/60 [==============================] - 0s - loss: 116.5917 - dense_1_loss_1: 4.3109 - dense_1_loss_2: 4.2527 - dense_1_loss_3: 4.1924 - dense_1_loss_4: 4.1842 - dense_1_loss_5: 4.1582 - dense_1_loss_6: 4.1571 - dense_1_loss_7: 4.0905 - dense_1_loss_8: 4.0318 - dense_1_loss_9: 3.9843 - dense_1_loss_10: 3.9231 - dense_1_loss_11: 3.8791 - dense_1_loss_12: 4.0587 - dense_1_loss_13: 3.9282 - dense_1_loss_14: 3.9412 - dense_1_loss_15: 4.0041 - dense_1_loss_16: 3.9797 - dense_1_loss_17: 4.0494 - dense_1_loss_18: 4.0533 - dense_1_loss_19: 3.8847 - dense_1_loss_20: 4.0046 - dense_1_loss_21: 3.9785 - dense_1_loss_22: 3.8670 - dense_1_loss_23: 3.8809 - dense_1_loss_24: 3.8403 - dense_1_loss_25: 4.2099 - dense_1_loss_26: 3.7872 - dense_1_loss_27: 3.8369 - dense_1_loss_28: 3.9038 - dense_1_loss_29: 4.2191 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.1000 - dense_1_acc_2: 0.1833 - dense_1_acc_3: 0.1500 - dense_1_acc_4: 0.2000 - dense_1_acc_5: 0.1333 - dense_1_acc_6: 0.0833 - dense_1_acc_7: 0.1333 - dense_1_acc_8: 0.1500 - dense_1_acc_9: 0.1500 - dense_1_acc_10: 0.1000 - dense_1_acc_11: 0.1333 - dense_1_acc_12: 0.1167 - dense_1_acc_13: 0.1500 - dense_1_acc_14: 0.1833 - dense_1_acc_15: 0.1167 - dense_1_acc_16: 0.1000 - dense_1_acc_17: 0.0833 - dense_1_acc_18: 0.1167 - dense_1_acc_19: 0.1500 - dense_1_acc_20: 0.0500 - dense_1_acc_21: 0.0833 - dense_1_acc_22: 0.1333 - dense_1_acc_23: 0.1167 - dense_1_acc_24: 0.1000 - dense_1_acc_25: 0.0667 - dense_1_acc_26: 0.1167 - dense_1_acc_27: 0.0833 - dense_1_acc_28: 0.0833 - dense_1_acc_29: 0.0333 - dense_1_acc_30: 0.0000e+00     
Epoch 4/100
60/60 [==============================] - 0s - loss: 112.9619 - dense_1_loss_1: 4.2890 - dense_1_loss_2: 4.2016 - dense_1_loss_3: 4.1004 - dense_1_loss_4: 4.0832 - dense_1_loss_5: 4.0032 - dense_1_loss_6: 4.0005 - dense_1_loss_7: 3.9329 - dense_1_loss_8: 3.7508 - dense_1_loss_9: 3.7841 - dense_1_loss_10: 3.6229 - dense_1_loss_11: 3.7585 - dense_1_loss_12: 4.0467 - dense_1_loss_13: 3.7883 - dense_1_loss_14: 3.8409 - dense_1_loss_15: 3.8299 - dense_1_loss_16: 3.8629 - dense_1_loss_17: 3.9154 - dense_1_loss_18: 3.8612 - dense_1_loss_19: 3.7641 - dense_1_loss_20: 3.9915 - dense_1_loss_21: 3.9526 - dense_1_loss_22: 3.8211 - dense_1_loss_23: 3.8139 - dense_1_loss_24: 3.5948 - dense_1_loss_25: 4.0516 - dense_1_loss_26: 3.6208 - dense_1_loss_27: 3.7090 - dense_1_loss_28: 3.9178 - dense_1_loss_29: 4.0522 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.1000 - dense_1_acc_2: 0.2167 - dense_1_acc_3: 0.1333 - dense_1_acc_4: 0.1667 - dense_1_acc_5: 0.1333 - dense_1_acc_6: 0.0500 - dense_1_acc_7: 0.0833 - dense_1_acc_8: 0.0667 - dense_1_acc_9: 0.1167 - dense_1_acc_10: 0.1000 - dense_1_acc_11: 0.0667 - dense_1_acc_12: 0.0167 - dense_1_acc_13: 0.0833 - dense_1_acc_14: 0.0833 - dense_1_acc_15: 0.0500 - dense_1_acc_16: 0.0833 - dense_1_acc_17: 0.1000 - dense_1_acc_18: 0.0167 - dense_1_acc_19: 0.1000 - dense_1_acc_20: 0.0667 - dense_1_acc_21: 0.0667 - dense_1_acc_22: 0.0500 - dense_1_acc_23: 0.0833 - dense_1_acc_24: 0.0833 - dense_1_acc_25: 0.0167 - dense_1_acc_26: 0.1167 - dense_1_acc_27: 0.0500 - dense_1_acc_28: 0.0667 - dense_1_acc_29: 0.0333 - dense_1_acc_30: 0.0000e+00             
Epoch 5/100
60/60 [==============================] - 0s - loss: 109.7424 - dense_1_loss_1: 4.2736 - dense_1_loss_2: 4.1584 - dense_1_loss_3: 4.0388 - dense_1_loss_4: 4.0095 - dense_1_loss_5: 3.8833 - dense_1_loss_6: 3.8840 - dense_1_loss_7: 3.8953 - dense_1_loss_8: 3.6539 - dense_1_loss_9: 3.7169 - dense_1_loss_10: 3.5004 - dense_1_loss_11: 3.6634 - dense_1_loss_12: 3.9162 - dense_1_loss_13: 3.6401 - dense_1_loss_14: 3.6207 - dense_1_loss_15: 3.7078 - dense_1_loss_16: 3.7199 - dense_1_loss_17: 3.7606 - dense_1_loss_18: 3.7380 - dense_1_loss_19: 3.6345 - dense_1_loss_20: 3.8921 - dense_1_loss_21: 3.8876 - dense_1_loss_22: 3.6699 - dense_1_loss_23: 3.6901 - dense_1_loss_24: 3.5543 - dense_1_loss_25: 3.8517 - dense_1_loss_26: 3.5988 - dense_1_loss_27: 3.5695 - dense_1_loss_28: 3.7622 - dense_1_loss_29: 3.8509 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.1000 - dense_1_acc_2: 0.2667 - dense_1_acc_3: 0.1667 - dense_1_acc_4: 0.1500 - dense_1_acc_5: 0.1500 - dense_1_acc_6: 0.0667 - dense_1_acc_7: 0.1000 - dense_1_acc_8: 0.1000 - dense_1_acc_9: 0.1333 - dense_1_acc_10: 0.1000 - dense_1_acc_11: 0.1333 - dense_1_acc_12: 0.0667 - dense_1_acc_13: 0.1833 - dense_1_acc_14: 0.1833 - dense_1_acc_15: 0.1833 - dense_1_acc_16: 0.1333 - dense_1_acc_17: 0.1167 - dense_1_acc_18: 0.1333 - dense_1_acc_19: 0.1833 - dense_1_acc_20: 0.0667 - dense_1_acc_21: 0.1167 - dense_1_acc_22: 0.1833 - dense_1_acc_23: 0.0833 - dense_1_acc_24: 0.1167 - dense_1_acc_25: 0.0667 - dense_1_acc_26: 0.1667 - dense_1_acc_27: 0.1500 - dense_1_acc_28: 0.1500 - dense_1_acc_29: 0.0667 - dense_1_acc_30: 0.0000e+00     
Epoch 6/100
60/60 [==============================] - 0s - loss: 107.4794 - dense_1_loss_1: 4.2596 - dense_1_loss_2: 4.1184 - dense_1_loss_3: 3.9666 - dense_1_loss_4: 3.9315 - dense_1_loss_5: 3.7843 - dense_1_loss_6: 3.7999 - dense_1_loss_7: 3.8353 - dense_1_loss_8: 3.5465 - dense_1_loss_9: 3.6362 - dense_1_loss_10: 3.3987 - dense_1_loss_11: 3.5823 - dense_1_loss_12: 3.7975 - dense_1_loss_13: 3.5239 - dense_1_loss_14: 3.4337 - dense_1_loss_15: 3.5453 - dense_1_loss_16: 3.5800 - dense_1_loss_17: 3.6270 - dense_1_loss_18: 3.6501 - dense_1_loss_19: 3.5647 - dense_1_loss_20: 3.8324 - dense_1_loss_21: 3.8064 - dense_1_loss_22: 3.6287 - dense_1_loss_23: 3.7189 - dense_1_loss_24: 3.6011 - dense_1_loss_25: 3.7717 - dense_1_loss_26: 3.5339 - dense_1_loss_27: 3.5834 - dense_1_loss_28: 3.6996 - dense_1_loss_29: 3.7219 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.1167 - dense_1_acc_2: 0.1500 - dense_1_acc_3: 0.1667 - dense_1_acc_4: 0.1500 - dense_1_acc_5: 0.2000 - dense_1_acc_6: 0.1167 - dense_1_acc_7: 0.1167 - dense_1_acc_8: 0.1333 - dense_1_acc_9: 0.1833 - dense_1_acc_10: 0.1500 - dense_1_acc_11: 0.1500 - dense_1_acc_12: 0.1333 - dense_1_acc_13: 0.1833 - dense_1_acc_14: 0.2167 - dense_1_acc_15: 0.2000 - dense_1_acc_16: 0.2000 - dense_1_acc_17: 0.1833 - dense_1_acc_18: 0.1500 - dense_1_acc_19: 0.1833 - dense_1_acc_20: 0.1833 - dense_1_acc_21: 0.1167 - dense_1_acc_22: 0.1833 - dense_1_acc_23: 0.1167 - dense_1_acc_24: 0.1333 - dense_1_acc_25: 0.1000 - dense_1_acc_26: 0.2500 - dense_1_acc_27: 0.0667 - dense_1_acc_28: 0.1333 - dense_1_acc_29: 0.1333 - dense_1_acc_30: 0.0000e+00     
Epoch 7/100
60/60 [==============================] - 0s - loss: 105.4369 - dense_1_loss_1: 4.2464 - dense_1_loss_2: 4.0815 - dense_1_loss_3: 3.8994 - dense_1_loss_4: 3.8578 - dense_1_loss_5: 3.6710 - dense_1_loss_6: 3.7394 - dense_1_loss_7: 3.7620 - dense_1_loss_8: 3.4043 - dense_1_loss_9: 3.5205 - dense_1_loss_10: 3.3301 - dense_1_loss_11: 3.5093 - dense_1_loss_12: 3.7560 - dense_1_loss_13: 3.4409 - dense_1_loss_14: 3.3113 - dense_1_loss_15: 3.4849 - dense_1_loss_16: 3.4962 - dense_1_loss_17: 3.5746 - dense_1_loss_18: 3.5761 - dense_1_loss_19: 3.4955 - dense_1_loss_20: 3.7821 - dense_1_loss_21: 3.7828 - dense_1_loss_22: 3.5663 - dense_1_loss_23: 3.5970 - dense_1_loss_24: 3.6191 - dense_1_loss_25: 3.7155 - dense_1_loss_26: 3.3698 - dense_1_loss_27: 3.5727 - dense_1_loss_28: 3.6350 - dense_1_loss_29: 3.6394 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0667 - dense_1_acc_2: 0.1333 - dense_1_acc_3: 0.1833 - dense_1_acc_4: 0.1500 - dense_1_acc_5: 0.2333 - dense_1_acc_6: 0.1333 - dense_1_acc_7: 0.1000 - dense_1_acc_8: 0.2000 - dense_1_acc_9: 0.1333 - dense_1_acc_10: 0.1667 - dense_1_acc_11: 0.1667 - dense_1_acc_12: 0.1667 - dense_1_acc_13: 0.1333 - dense_1_acc_14: 0.1833 - dense_1_acc_15: 0.1167 - dense_1_acc_16: 0.1167 - dense_1_acc_17: 0.1833 - dense_1_acc_18: 0.1333 - dense_1_acc_19: 0.0500 - dense_1_acc_20: 0.1500 - dense_1_acc_21: 0.1167 - dense_1_acc_22: 0.0667 - dense_1_acc_23: 0.0833 - dense_1_acc_24: 0.0667 - dense_1_acc_25: 0.0667 - dense_1_acc_26: 0.1833 - dense_1_acc_27: 0.0667 - dense_1_acc_28: 0.1000 - dense_1_acc_29: 0.1500 - dense_1_acc_30: 0.0000e+00     
Epoch 8/100
60/60 [==============================] - 0s - loss: 101.9258 - dense_1_loss_1: 4.2341 - dense_1_loss_2: 4.0441 - dense_1_loss_3: 3.8391 - dense_1_loss_4: 3.7897 - dense_1_loss_5: 3.5840 - dense_1_loss_6: 3.6718 - dense_1_loss_7: 3.6403 - dense_1_loss_8: 3.3127 - dense_1_loss_9: 3.4345 - dense_1_loss_10: 3.2065 - dense_1_loss_11: 3.3701 - dense_1_loss_12: 3.5745 - dense_1_loss_13: 3.3010 - dense_1_loss_14: 3.1700 - dense_1_loss_15: 3.3948 - dense_1_loss_16: 3.3908 - dense_1_loss_17: 3.4027 - dense_1_loss_18: 3.4766 - dense_1_loss_19: 3.3359 - dense_1_loss_20: 3.5664 - dense_1_loss_21: 3.6005 - dense_1_loss_22: 3.4448 - dense_1_loss_23: 3.4935 - dense_1_loss_24: 3.4713 - dense_1_loss_25: 3.5394 - dense_1_loss_26: 3.3488 - dense_1_loss_27: 3.4172 - dense_1_loss_28: 3.3527 - dense_1_loss_29: 3.5181 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0667 - dense_1_acc_2: 0.1500 - dense_1_acc_3: 0.2167 - dense_1_acc_4: 0.1667 - dense_1_acc_5: 0.2333 - dense_1_acc_6: 0.1500 - dense_1_acc_7: 0.1000 - dense_1_acc_8: 0.1833 - dense_1_acc_9: 0.1833 - dense_1_acc_10: 0.2167 - dense_1_acc_11: 0.1833 - dense_1_acc_12: 0.1333 - dense_1_acc_13: 0.2000 - dense_1_acc_14: 0.2500 - dense_1_acc_15: 0.1333 - dense_1_acc_16: 0.2333 - dense_1_acc_17: 0.2833 - dense_1_acc_18: 0.2000 - dense_1_acc_19: 0.1833 - dense_1_acc_20: 0.2000 - dense_1_acc_21: 0.0833 - dense_1_acc_22: 0.1333 - dense_1_acc_23: 0.1500 - dense_1_acc_24: 0.1333 - dense_1_acc_25: 0.0833 - dense_1_acc_26: 0.1667 - dense_1_acc_27: 0.1000 - dense_1_acc_28: 0.1500 - dense_1_acc_29: 0.1333 - dense_1_acc_30: 0.0000e+00         
Epoch 9/100
60/60 [==============================] - 0s - loss: 97.5397 - dense_1_loss_1: 4.2224 - dense_1_loss_2: 4.0074 - dense_1_loss_3: 3.7726 - dense_1_loss_4: 3.7188 - dense_1_loss_5: 3.4940 - dense_1_loss_6: 3.5790 - dense_1_loss_7: 3.5319 - dense_1_loss_8: 3.1729 - dense_1_loss_9: 3.2830 - dense_1_loss_10: 3.0899 - dense_1_loss_11: 3.2784 - dense_1_loss_12: 3.4122 - dense_1_loss_13: 3.0784 - dense_1_loss_14: 3.0281 - dense_1_loss_15: 3.2444 - dense_1_loss_16: 3.2328 - dense_1_loss_17: 3.2966 - dense_1_loss_18: 3.2335 - dense_1_loss_19: 3.1836 - dense_1_loss_20: 3.3985 - dense_1_loss_21: 3.3578 - dense_1_loss_22: 3.2382 - dense_1_loss_23: 3.2796 - dense_1_loss_24: 3.2682 - dense_1_loss_25: 3.3755 - dense_1_loss_26: 3.0391 - dense_1_loss_27: 3.1840 - dense_1_loss_28: 3.2072 - dense_1_loss_29: 3.3318 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0667 - dense_1_acc_2: 0.1500 - dense_1_acc_3: 0.2500 - dense_1_acc_4: 0.1667 - dense_1_acc_5: 0.2667 - dense_1_acc_6: 0.1333 - dense_1_acc_7: 0.1167 - dense_1_acc_8: 0.2167 - dense_1_acc_9: 0.1833 - dense_1_acc_10: 0.2000 - dense_1_acc_11: 0.2333 - dense_1_acc_12: 0.1833 - dense_1_acc_13: 0.2500 - dense_1_acc_14: 0.3167 - dense_1_acc_15: 0.2333 - dense_1_acc_16: 0.2000 - dense_1_acc_17: 0.2667 - dense_1_acc_18: 0.1833 - dense_1_acc_19: 0.2167 - dense_1_acc_20: 0.1833 - dense_1_acc_21: 0.1833 - dense_1_acc_22: 0.2500 - dense_1_acc_23: 0.1667 - dense_1_acc_24: 0.1667 - dense_1_acc_25: 0.1500 - dense_1_acc_26: 0.2667 - dense_1_acc_27: 0.1000 - dense_1_acc_28: 0.2167 - dense_1_acc_29: 0.1667 - dense_1_acc_30: 0.0000e+00     
Epoch 10/100
60/60 [==============================] - 0s - loss: 94.0498 - dense_1_loss_1: 4.2123 - dense_1_loss_2: 3.9718 - dense_1_loss_3: 3.7111 - dense_1_loss_4: 3.6433 - dense_1_loss_5: 3.4021 - dense_1_loss_6: 3.4689 - dense_1_loss_7: 3.4208 - dense_1_loss_8: 3.0681 - dense_1_loss_9: 3.1439 - dense_1_loss_10: 2.9460 - dense_1_loss_11: 3.1399 - dense_1_loss_12: 3.2173 - dense_1_loss_13: 2.8944 - dense_1_loss_14: 2.9221 - dense_1_loss_15: 3.0894 - dense_1_loss_16: 3.1183 - dense_1_loss_17: 3.1481 - dense_1_loss_18: 3.1005 - dense_1_loss_19: 2.9970 - dense_1_loss_20: 3.2726 - dense_1_loss_21: 3.2057 - dense_1_loss_22: 3.1046 - dense_1_loss_23: 3.1572 - dense_1_loss_24: 3.1024 - dense_1_loss_25: 3.2077 - dense_1_loss_26: 2.9859 - dense_1_loss_27: 3.0679 - dense_1_loss_28: 3.0849 - dense_1_loss_29: 3.2456 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0333 - dense_1_acc_2: 0.1500 - dense_1_acc_3: 0.2333 - dense_1_acc_4: 0.2000 - dense_1_acc_5: 0.3167 - dense_1_acc_6: 0.1667 - dense_1_acc_7: 0.1333 - dense_1_acc_8: 0.2500 - dense_1_acc_9: 0.1833 - dense_1_acc_10: 0.2667 - dense_1_acc_11: 0.2667 - dense_1_acc_12: 0.1667 - dense_1_acc_13: 0.3000 - dense_1_acc_14: 0.3667 - dense_1_acc_15: 0.2167 - dense_1_acc_16: 0.2167 - dense_1_acc_17: 0.2500 - dense_1_acc_18: 0.2000 - dense_1_acc_19: 0.2333 - dense_1_acc_20: 0.2333 - dense_1_acc_21: 0.2000 - dense_1_acc_22: 0.2333 - dense_1_acc_23: 0.2167 - dense_1_acc_24: 0.2167 - dense_1_acc_25: 0.1833 - dense_1_acc_26: 0.3333 - dense_1_acc_27: 0.1500 - dense_1_acc_28: 0.2333 - dense_1_acc_29: 0.2167 - dense_1_acc_30: 0.0000e+00     
Epoch 11/100
60/60 [==============================] - 0s - loss: 90.4433 - dense_1_loss_1: 4.2032 - dense_1_loss_2: 3.9378 - dense_1_loss_3: 3.6490 - dense_1_loss_4: 3.5666 - dense_1_loss_5: 3.3112 - dense_1_loss_6: 3.3359 - dense_1_loss_7: 3.2873 - dense_1_loss_8: 2.9282 - dense_1_loss_9: 3.0407 - dense_1_loss_10: 2.8309 - dense_1_loss_11: 3.0155 - dense_1_loss_12: 3.0760 - dense_1_loss_13: 2.7798 - dense_1_loss_14: 2.7797 - dense_1_loss_15: 3.0136 - dense_1_loss_16: 2.9562 - dense_1_loss_17: 2.9666 - dense_1_loss_18: 2.9588 - dense_1_loss_19: 2.8938 - dense_1_loss_20: 3.1198 - dense_1_loss_21: 3.0387 - dense_1_loss_22: 2.9232 - dense_1_loss_23: 3.0296 - dense_1_loss_24: 2.9524 - dense_1_loss_25: 3.0343 - dense_1_loss_26: 2.7661 - dense_1_loss_27: 2.9873 - dense_1_loss_28: 2.9684 - dense_1_loss_29: 3.0927 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0333 - dense_1_acc_2: 0.1667 - dense_1_acc_3: 0.2333 - dense_1_acc_4: 0.2500 - dense_1_acc_5: 0.3167 - dense_1_acc_6: 0.1833 - dense_1_acc_7: 0.1500 - dense_1_acc_8: 0.3333 - dense_1_acc_9: 0.1333 - dense_1_acc_10: 0.2000 - dense_1_acc_11: 0.2000 - dense_1_acc_12: 0.1500 - dense_1_acc_13: 0.3167 - dense_1_acc_14: 0.3667 - dense_1_acc_15: 0.2333 - dense_1_acc_16: 0.2500 - dense_1_acc_17: 0.2500 - dense_1_acc_18: 0.2167 - dense_1_acc_19: 0.2500 - dense_1_acc_20: 0.2667 - dense_1_acc_21: 0.1667 - dense_1_acc_22: 0.2500 - dense_1_acc_23: 0.2333 - dense_1_acc_24: 0.2000 - dense_1_acc_25: 0.1500 - dense_1_acc_26: 0.3000 - dense_1_acc_27: 0.1667 - dense_1_acc_28: 0.2000 - dense_1_acc_29: 0.2167 - dense_1_acc_30: 0.0000e+00     
Epoch 12/100
60/60 [==============================] - 0s - loss: 86.7520 - dense_1_loss_1: 4.1942 - dense_1_loss_2: 3.9015 - dense_1_loss_3: 3.5786 - dense_1_loss_4: 3.4803 - dense_1_loss_5: 3.2002 - dense_1_loss_6: 3.1740 - dense_1_loss_7: 3.1654 - dense_1_loss_8: 2.8111 - dense_1_loss_9: 2.8566 - dense_1_loss_10: 2.6948 - dense_1_loss_11: 2.9021 - dense_1_loss_12: 2.9080 - dense_1_loss_13: 2.6004 - dense_1_loss_14: 2.6577 - dense_1_loss_15: 2.8669 - dense_1_loss_16: 2.8388 - dense_1_loss_17: 2.8214 - dense_1_loss_18: 2.8333 - dense_1_loss_19: 2.7444 - dense_1_loss_20: 2.9425 - dense_1_loss_21: 2.8702 - dense_1_loss_22: 2.7715 - dense_1_loss_23: 2.9040 - dense_1_loss_24: 2.8200 - dense_1_loss_25: 2.8897 - dense_1_loss_26: 2.6141 - dense_1_loss_27: 2.9146 - dense_1_loss_28: 2.8326 - dense_1_loss_29: 2.9628 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0333 - dense_1_acc_2: 0.1333 - dense_1_acc_3: 0.2500 - dense_1_acc_4: 0.2500 - dense_1_acc_5: 0.2667 - dense_1_acc_6: 0.1667 - dense_1_acc_7: 0.1500 - dense_1_acc_8: 0.2667 - dense_1_acc_9: 0.2667 - dense_1_acc_10: 0.2500 - dense_1_acc_11: 0.2333 - dense_1_acc_12: 0.2000 - dense_1_acc_13: 0.3667 - dense_1_acc_14: 0.3333 - dense_1_acc_15: 0.2167 - dense_1_acc_16: 0.2667 - dense_1_acc_17: 0.2500 - dense_1_acc_18: 0.1833 - dense_1_acc_19: 0.2833 - dense_1_acc_20: 0.2667 - dense_1_acc_21: 0.1833 - dense_1_acc_22: 0.2333 - dense_1_acc_23: 0.2333 - dense_1_acc_24: 0.2333 - dense_1_acc_25: 0.2000 - dense_1_acc_26: 0.3500 - dense_1_acc_27: 0.1833 - dense_1_acc_28: 0.2333 - dense_1_acc_29: 0.1333 - dense_1_acc_30: 0.0000e+00     
Epoch 13/100
60/60 [==============================] - 0s - loss: 83.7251 - dense_1_loss_1: 4.1851 - dense_1_loss_2: 3.8665 - dense_1_loss_3: 3.5127 - dense_1_loss_4: 3.3867 - dense_1_loss_5: 3.0778 - dense_1_loss_6: 3.0074 - dense_1_loss_7: 3.0227 - dense_1_loss_8: 2.6785 - dense_1_loss_9: 2.7845 - dense_1_loss_10: 2.6258 - dense_1_loss_11: 2.7822 - dense_1_loss_12: 2.7713 - dense_1_loss_13: 2.4534 - dense_1_loss_14: 2.4543 - dense_1_loss_15: 2.8009 - dense_1_loss_16: 2.6527 - dense_1_loss_17: 2.7003 - dense_1_loss_18: 2.7220 - dense_1_loss_19: 2.6382 - dense_1_loss_20: 2.8010 - dense_1_loss_21: 2.7151 - dense_1_loss_22: 2.6806 - dense_1_loss_23: 2.8805 - dense_1_loss_24: 2.7527 - dense_1_loss_25: 2.8195 - dense_1_loss_26: 2.5173 - dense_1_loss_27: 2.8125 - dense_1_loss_28: 2.7547 - dense_1_loss_29: 2.8683 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0333 - dense_1_acc_2: 0.1500 - dense_1_acc_3: 0.2667 - dense_1_acc_4: 0.2667 - dense_1_acc_5: 0.3333 - dense_1_acc_6: 0.1833 - dense_1_acc_7: 0.2833 - dense_1_acc_8: 0.3000 - dense_1_acc_9: 0.2000 - dense_1_acc_10: 0.2500 - dense_1_acc_11: 0.2667 - dense_1_acc_12: 0.1833 - dense_1_acc_13: 0.3167 - dense_1_acc_14: 0.4167 - dense_1_acc_15: 0.2167 - dense_1_acc_16: 0.3000 - dense_1_acc_17: 0.2500 - dense_1_acc_18: 0.2167 - dense_1_acc_19: 0.2833 - dense_1_acc_20: 0.3000 - dense_1_acc_21: 0.2000 - dense_1_acc_22: 0.1833 - dense_1_acc_23: 0.2667 - dense_1_acc_24: 0.2167 - dense_1_acc_25: 0.1833 - dense_1_acc_26: 0.3333 - dense_1_acc_27: 0.1833 - dense_1_acc_28: 0.2667 - dense_1_acc_29: 0.2167 - dense_1_acc_30: 0.0000e+00         
Epoch 14/100
60/60 [==============================] - 0s - loss: 80.0885 - dense_1_loss_1: 4.1764 - dense_1_loss_2: 3.8270 - dense_1_loss_3: 3.4346 - dense_1_loss_4: 3.2869 - dense_1_loss_5: 2.9697 - dense_1_loss_6: 2.8713 - dense_1_loss_7: 2.9154 - dense_1_loss_8: 2.6057 - dense_1_loss_9: 2.6267 - dense_1_loss_10: 2.4907 - dense_1_loss_11: 2.7096 - dense_1_loss_12: 2.6947 - dense_1_loss_13: 2.3858 - dense_1_loss_14: 2.4002 - dense_1_loss_15: 2.6353 - dense_1_loss_16: 2.5205 - dense_1_loss_17: 2.5915 - dense_1_loss_18: 2.5955 - dense_1_loss_19: 2.4933 - dense_1_loss_20: 2.6285 - dense_1_loss_21: 2.5063 - dense_1_loss_22: 2.5610 - dense_1_loss_23: 2.6933 - dense_1_loss_24: 2.5691 - dense_1_loss_25: 2.6248 - dense_1_loss_26: 2.3545 - dense_1_loss_27: 2.6633 - dense_1_loss_28: 2.6532 - dense_1_loss_29: 2.6037 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0333 - dense_1_acc_2: 0.1667 - dense_1_acc_3: 0.3000 - dense_1_acc_4: 0.2500 - dense_1_acc_5: 0.2833 - dense_1_acc_6: 0.2000 - dense_1_acc_7: 0.2667 - dense_1_acc_8: 0.3000 - dense_1_acc_9: 0.2833 - dense_1_acc_10: 0.3333 - dense_1_acc_11: 0.2833 - dense_1_acc_12: 0.2500 - dense_1_acc_13: 0.3667 - dense_1_acc_14: 0.4833 - dense_1_acc_15: 0.2667 - dense_1_acc_16: 0.3333 - dense_1_acc_17: 0.2667 - dense_1_acc_18: 0.2667 - dense_1_acc_19: 0.3833 - dense_1_acc_20: 0.3000 - dense_1_acc_21: 0.2333 - dense_1_acc_22: 0.2500 - dense_1_acc_23: 0.2500 - dense_1_acc_24: 0.2167 - dense_1_acc_25: 0.2833 - dense_1_acc_26: 0.3833 - dense_1_acc_27: 0.1500 - dense_1_acc_28: 0.2667 - dense_1_acc_29: 0.2500 - dense_1_acc_30: 0.0000e+00         
Epoch 15/100
60/60 [==============================] - 0s - loss: 76.3000 - dense_1_loss_1: 4.1678 - dense_1_loss_2: 3.7853 - dense_1_loss_3: 3.3565 - dense_1_loss_4: 3.1934 - dense_1_loss_5: 2.8572 - dense_1_loss_6: 2.7488 - dense_1_loss_7: 2.7980 - dense_1_loss_8: 2.4660 - dense_1_loss_9: 2.5278 - dense_1_loss_10: 2.3507 - dense_1_loss_11: 2.5486 - dense_1_loss_12: 2.4981 - dense_1_loss_13: 2.2178 - dense_1_loss_14: 2.2171 - dense_1_loss_15: 2.4723 - dense_1_loss_16: 2.3932 - dense_1_loss_17: 2.4303 - dense_1_loss_18: 2.4306 - dense_1_loss_19: 2.3661 - dense_1_loss_20: 2.5173 - dense_1_loss_21: 2.3778 - dense_1_loss_22: 2.4141 - dense_1_loss_23: 2.5083 - dense_1_loss_24: 2.4410 - dense_1_loss_25: 2.4678 - dense_1_loss_26: 2.2971 - dense_1_loss_27: 2.5865 - dense_1_loss_28: 2.4312 - dense_1_loss_29: 2.4334 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0333 - dense_1_acc_2: 0.2000 - dense_1_acc_3: 0.3333 - dense_1_acc_4: 0.2667 - dense_1_acc_5: 0.2833 - dense_1_acc_6: 0.2667 - dense_1_acc_7: 0.3167 - dense_1_acc_8: 0.3833 - dense_1_acc_9: 0.2667 - dense_1_acc_10: 0.3500 - dense_1_acc_11: 0.3333 - dense_1_acc_12: 0.2167 - dense_1_acc_13: 0.3500 - dense_1_acc_14: 0.4667 - dense_1_acc_15: 0.3000 - dense_1_acc_16: 0.3333 - dense_1_acc_17: 0.2333 - dense_1_acc_18: 0.2167 - dense_1_acc_19: 0.3167 - dense_1_acc_20: 0.3333 - dense_1_acc_21: 0.2667 - dense_1_acc_22: 0.1833 - dense_1_acc_23: 0.2667 - dense_1_acc_24: 0.2500 - dense_1_acc_25: 0.2500 - dense_1_acc_26: 0.3333 - dense_1_acc_27: 0.2333 - dense_1_acc_28: 0.4000 - dense_1_acc_29: 0.3167 - dense_1_acc_30: 0.0000e+00         
Epoch 16/100
60/60 [==============================] - 0s - loss: 73.0323 - dense_1_loss_1: 4.1594 - dense_1_loss_2: 3.7470 - dense_1_loss_3: 3.2790 - dense_1_loss_4: 3.0920 - dense_1_loss_5: 2.7455 - dense_1_loss_6: 2.6302 - dense_1_loss_7: 2.6774 - dense_1_loss_8: 2.3535 - dense_1_loss_9: 2.4139 - dense_1_loss_10: 2.2482 - dense_1_loss_11: 2.4613 - dense_1_loss_12: 2.3677 - dense_1_loss_13: 2.1060 - dense_1_loss_14: 2.0593 - dense_1_loss_15: 2.3188 - dense_1_loss_16: 2.2564 - dense_1_loss_17: 2.3186 - dense_1_loss_18: 2.2824 - dense_1_loss_19: 2.2487 - dense_1_loss_20: 2.4113 - dense_1_loss_21: 2.2674 - dense_1_loss_22: 2.2173 - dense_1_loss_23: 2.3595 - dense_1_loss_24: 2.3342 - dense_1_loss_25: 2.3701 - dense_1_loss_26: 2.2122 - dense_1_loss_27: 2.4123 - dense_1_loss_28: 2.2990 - dense_1_loss_29: 2.3839 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0667 - dense_1_acc_2: 0.2000 - dense_1_acc_3: 0.3333 - dense_1_acc_4: 0.2667 - dense_1_acc_5: 0.2833 - dense_1_acc_6: 0.2667 - dense_1_acc_7: 0.3333 - dense_1_acc_8: 0.3500 - dense_1_acc_9: 0.2667 - dense_1_acc_10: 0.3000 - dense_1_acc_11: 0.3167 - dense_1_acc_12: 0.2333 - dense_1_acc_13: 0.3833 - dense_1_acc_14: 0.5000 - dense_1_acc_15: 0.3000 - dense_1_acc_16: 0.3333 - dense_1_acc_17: 0.2667 - dense_1_acc_18: 0.2500 - dense_1_acc_19: 0.3333 - dense_1_acc_20: 0.3500 - dense_1_acc_21: 0.3000 - dense_1_acc_22: 0.2667 - dense_1_acc_23: 0.3000 - dense_1_acc_24: 0.2500 - dense_1_acc_25: 0.2667 - dense_1_acc_26: 0.4167 - dense_1_acc_27: 0.2500 - dense_1_acc_28: 0.3500 - dense_1_acc_29: 0.3000 - dense_1_acc_30: 0.0000e+00     
Epoch 17/100
60/60 [==============================] - 0s - loss: 69.4759 - dense_1_loss_1: 4.1524 - dense_1_loss_2: 3.7050 - dense_1_loss_3: 3.1957 - dense_1_loss_4: 2.9943 - dense_1_loss_5: 2.6361 - dense_1_loss_6: 2.5053 - dense_1_loss_7: 2.5479 - dense_1_loss_8: 2.2498 - dense_1_loss_9: 2.3074 - dense_1_loss_10: 2.1006 - dense_1_loss_11: 2.3598 - dense_1_loss_12: 2.2248 - dense_1_loss_13: 1.9963 - dense_1_loss_14: 1.9827 - dense_1_loss_15: 2.1813 - dense_1_loss_16: 2.1791 - dense_1_loss_17: 2.1621 - dense_1_loss_18: 2.2242 - dense_1_loss_19: 2.1387 - dense_1_loss_20: 2.2267 - dense_1_loss_21: 2.1067 - dense_1_loss_22: 2.0793 - dense_1_loss_23: 2.1905 - dense_1_loss_24: 2.1433 - dense_1_loss_25: 2.2115 - dense_1_loss_26: 2.0629 - dense_1_loss_27: 2.2656 - dense_1_loss_28: 2.1405 - dense_1_loss_29: 2.2054 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0667 - dense_1_acc_2: 0.2167 - dense_1_acc_3: 0.3333 - dense_1_acc_4: 0.2667 - dense_1_acc_5: 0.3000 - dense_1_acc_6: 0.2833 - dense_1_acc_7: 0.3500 - dense_1_acc_8: 0.4000 - dense_1_acc_9: 0.2833 - dense_1_acc_10: 0.3333 - dense_1_acc_11: 0.3000 - dense_1_acc_12: 0.2500 - dense_1_acc_13: 0.4333 - dense_1_acc_14: 0.4500 - dense_1_acc_15: 0.3500 - dense_1_acc_16: 0.3500 - dense_1_acc_17: 0.4167 - dense_1_acc_18: 0.3500 - dense_1_acc_19: 0.3667 - dense_1_acc_20: 0.3333 - dense_1_acc_21: 0.3833 - dense_1_acc_22: 0.3333 - dense_1_acc_23: 0.3333 - dense_1_acc_24: 0.3000 - dense_1_acc_25: 0.3167 - dense_1_acc_26: 0.4000 - dense_1_acc_27: 0.3333 - dense_1_acc_28: 0.3667 - dense_1_acc_29: 0.3333 - dense_1_acc_30: 0.0000e+00     
Epoch 18/100
60/60 [==============================] - 0s - loss: 65.9726 - dense_1_loss_1: 4.1440 - dense_1_loss_2: 3.6600 - dense_1_loss_3: 3.1156 - dense_1_loss_4: 2.8759 - dense_1_loss_5: 2.5293 - dense_1_loss_6: 2.3704 - dense_1_loss_7: 2.4252 - dense_1_loss_8: 2.1443 - dense_1_loss_9: 2.1869 - dense_1_loss_10: 1.9732 - dense_1_loss_11: 2.2412 - dense_1_loss_12: 2.0710 - dense_1_loss_13: 1.8579 - dense_1_loss_14: 1.8664 - dense_1_loss_15: 2.0844 - dense_1_loss_16: 2.0677 - dense_1_loss_17: 2.0429 - dense_1_loss_18: 2.1007 - dense_1_loss_19: 1.9928 - dense_1_loss_20: 2.0520 - dense_1_loss_21: 1.9597 - dense_1_loss_22: 1.9512 - dense_1_loss_23: 2.0799 - dense_1_loss_24: 1.9929 - dense_1_loss_25: 2.0700 - dense_1_loss_26: 1.9091 - dense_1_loss_27: 2.1557 - dense_1_loss_28: 2.0115 - dense_1_loss_29: 2.0407 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0667 - dense_1_acc_2: 0.2833 - dense_1_acc_3: 0.3500 - dense_1_acc_4: 0.3333 - dense_1_acc_5: 0.3500 - dense_1_acc_6: 0.3333 - dense_1_acc_7: 0.3667 - dense_1_acc_8: 0.4500 - dense_1_acc_9: 0.3000 - dense_1_acc_10: 0.4167 - dense_1_acc_11: 0.3500 - dense_1_acc_12: 0.3000 - dense_1_acc_13: 0.5000 - dense_1_acc_14: 0.4667 - dense_1_acc_15: 0.3500 - dense_1_acc_16: 0.3833 - dense_1_acc_17: 0.4167 - dense_1_acc_18: 0.3833 - dense_1_acc_19: 0.4167 - dense_1_acc_20: 0.4000 - dense_1_acc_21: 0.3833 - dense_1_acc_22: 0.3833 - dense_1_acc_23: 0.3500 - dense_1_acc_24: 0.3333 - dense_1_acc_25: 0.3500 - dense_1_acc_26: 0.4500 - dense_1_acc_27: 0.4167 - dense_1_acc_28: 0.4000 - dense_1_acc_29: 0.4333 - dense_1_acc_30: 0.0000e+00     
Epoch 19/100
60/60 [==============================] - 0s - loss: 62.6909 - dense_1_loss_1: 4.1349 - dense_1_loss_2: 3.6135 - dense_1_loss_3: 3.0333 - dense_1_loss_4: 2.7570 - dense_1_loss_5: 2.4193 - dense_1_loss_6: 2.2440 - dense_1_loss_7: 2.3143 - dense_1_loss_8: 2.0281 - dense_1_loss_9: 2.0355 - dense_1_loss_10: 1.8696 - dense_1_loss_11: 2.1065 - dense_1_loss_12: 1.9666 - dense_1_loss_13: 1.7233 - dense_1_loss_14: 1.7666 - dense_1_loss_15: 1.9915 - dense_1_loss_16: 1.9269 - dense_1_loss_17: 1.9156 - dense_1_loss_18: 1.9449 - dense_1_loss_19: 1.7975 - dense_1_loss_20: 1.9085 - dense_1_loss_21: 1.8638 - dense_1_loss_22: 1.8645 - dense_1_loss_23: 1.9642 - dense_1_loss_24: 1.8688 - dense_1_loss_25: 1.9633 - dense_1_loss_26: 1.7898 - dense_1_loss_27: 2.0430 - dense_1_loss_28: 1.9241 - dense_1_loss_29: 1.9119 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0667 - dense_1_acc_2: 0.2833 - dense_1_acc_3: 0.3500 - dense_1_acc_4: 0.3833 - dense_1_acc_5: 0.3833 - dense_1_acc_6: 0.3000 - dense_1_acc_7: 0.4167 - dense_1_acc_8: 0.5500 - dense_1_acc_9: 0.4667 - dense_1_acc_10: 0.4833 - dense_1_acc_11: 0.4333 - dense_1_acc_12: 0.3167 - dense_1_acc_13: 0.5667 - dense_1_acc_14: 0.5167 - dense_1_acc_15: 0.3500 - dense_1_acc_16: 0.4333 - dense_1_acc_17: 0.4333 - dense_1_acc_18: 0.3667 - dense_1_acc_19: 0.6000 - dense_1_acc_20: 0.4667 - dense_1_acc_21: 0.4333 - dense_1_acc_22: 0.4500 - dense_1_acc_23: 0.4833 - dense_1_acc_24: 0.4500 - dense_1_acc_25: 0.4000 - dense_1_acc_26: 0.5333 - dense_1_acc_27: 0.4333 - dense_1_acc_28: 0.4333 - dense_1_acc_29: 0.4667 - dense_1_acc_30: 0.0000e+00     
Epoch 20/100
60/60 [==============================] - 0s - loss: 59.4294 - dense_1_loss_1: 4.1263 - dense_1_loss_2: 3.5646 - dense_1_loss_3: 2.9457 - dense_1_loss_4: 2.6493 - dense_1_loss_5: 2.3123 - dense_1_loss_6: 2.1407 - dense_1_loss_7: 2.2008 - dense_1_loss_8: 1.9522 - dense_1_loss_9: 1.8878 - dense_1_loss_10: 1.7751 - dense_1_loss_11: 1.9452 - dense_1_loss_12: 1.8496 - dense_1_loss_13: 1.6384 - dense_1_loss_14: 1.6571 - dense_1_loss_15: 1.8758 - dense_1_loss_16: 1.8282 - dense_1_loss_17: 1.7956 - dense_1_loss_18: 1.7778 - dense_1_loss_19: 1.6552 - dense_1_loss_20: 1.7680 - dense_1_loss_21: 1.7626 - dense_1_loss_22: 1.7142 - dense_1_loss_23: 1.8044 - dense_1_loss_24: 1.7505 - dense_1_loss_25: 1.8849 - dense_1_loss_26: 1.6697 - dense_1_loss_27: 1.9366 - dense_1_loss_28: 1.7748 - dense_1_loss_29: 1.7860 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0333 - dense_1_acc_2: 0.2667 - dense_1_acc_3: 0.4167 - dense_1_acc_4: 0.3833 - dense_1_acc_5: 0.3833 - dense_1_acc_6: 0.3667 - dense_1_acc_7: 0.4500 - dense_1_acc_8: 0.5000 - dense_1_acc_9: 0.4167 - dense_1_acc_10: 0.5000 - dense_1_acc_11: 0.5000 - dense_1_acc_12: 0.3667 - dense_1_acc_13: 0.6167 - dense_1_acc_14: 0.5500 - dense_1_acc_15: 0.3667 - dense_1_acc_16: 0.4833 - dense_1_acc_17: 0.4500 - dense_1_acc_18: 0.4667 - dense_1_acc_19: 0.6000 - dense_1_acc_20: 0.4667 - dense_1_acc_21: 0.4333 - dense_1_acc_22: 0.5167 - dense_1_acc_23: 0.4833 - dense_1_acc_24: 0.4333 - dense_1_acc_25: 0.3667 - dense_1_acc_26: 0.6000 - dense_1_acc_27: 0.4667 - dense_1_acc_28: 0.5333 - dense_1_acc_29: 0.5167 - dense_1_acc_30: 0.0000e+00     
Epoch 21/100
60/60 [==============================] - 0s - loss: 56.3204 - dense_1_loss_1: 4.1173 - dense_1_loss_2: 3.5151 - dense_1_loss_3: 2.8569 - dense_1_loss_4: 2.5381 - dense_1_loss_5: 2.2098 - dense_1_loss_6: 2.0119 - dense_1_loss_7: 2.0717 - dense_1_loss_8: 1.8554 - dense_1_loss_9: 1.7872 - dense_1_loss_10: 1.6853 - dense_1_loss_11: 1.8433 - dense_1_loss_12: 1.7077 - dense_1_loss_13: 1.5398 - dense_1_loss_14: 1.5232 - dense_1_loss_15: 1.7817 - dense_1_loss_16: 1.7155 - dense_1_loss_17: 1.6859 - dense_1_loss_18: 1.6611 - dense_1_loss_19: 1.5288 - dense_1_loss_20: 1.6523 - dense_1_loss_21: 1.6695 - dense_1_loss_22: 1.5854 - dense_1_loss_23: 1.6980 - dense_1_loss_24: 1.6312 - dense_1_loss_25: 1.7663 - dense_1_loss_26: 1.5452 - dense_1_loss_27: 1.8381 - dense_1_loss_28: 1.6438 - dense_1_loss_29: 1.6549 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0500 - dense_1_acc_2: 0.2833 - dense_1_acc_3: 0.4333 - dense_1_acc_4: 0.3833 - dense_1_acc_5: 0.3833 - dense_1_acc_6: 0.4000 - dense_1_acc_7: 0.4833 - dense_1_acc_8: 0.5500 - dense_1_acc_9: 0.5667 - dense_1_acc_10: 0.5833 - dense_1_acc_11: 0.5667 - dense_1_acc_12: 0.4167 - dense_1_acc_13: 0.6833 - dense_1_acc_14: 0.6667 - dense_1_acc_15: 0.3833 - dense_1_acc_16: 0.5667 - dense_1_acc_17: 0.4833 - dense_1_acc_18: 0.5167 - dense_1_acc_19: 0.6500 - dense_1_acc_20: 0.5000 - dense_1_acc_21: 0.4833 - dense_1_acc_22: 0.6167 - dense_1_acc_23: 0.5500 - dense_1_acc_24: 0.4667 - dense_1_acc_25: 0.4000 - dense_1_acc_26: 0.6333 - dense_1_acc_27: 0.4833 - dense_1_acc_28: 0.5833 - dense_1_acc_29: 0.5333 - dense_1_acc_30: 0.0000e+00     
Epoch 22/100
60/60 [==============================] - 0s - loss: 53.4685 - dense_1_loss_1: 4.1085 - dense_1_loss_2: 3.4626 - dense_1_loss_3: 2.7668 - dense_1_loss_4: 2.4326 - dense_1_loss_5: 2.1167 - dense_1_loss_6: 1.8992 - dense_1_loss_7: 1.9371 - dense_1_loss_8: 1.7622 - dense_1_loss_9: 1.6704 - dense_1_loss_10: 1.5753 - dense_1_loss_11: 1.7373 - dense_1_loss_12: 1.5829 - dense_1_loss_13: 1.4240 - dense_1_loss_14: 1.4348 - dense_1_loss_15: 1.6158 - dense_1_loss_16: 1.6283 - dense_1_loss_17: 1.5730 - dense_1_loss_18: 1.5585 - dense_1_loss_19: 1.4316 - dense_1_loss_20: 1.5616 - dense_1_loss_21: 1.5802 - dense_1_loss_22: 1.4950 - dense_1_loss_23: 1.5737 - dense_1_loss_24: 1.5281 - dense_1_loss_25: 1.6507 - dense_1_loss_26: 1.4775 - dense_1_loss_27: 1.7304 - dense_1_loss_28: 1.5815 - dense_1_loss_29: 1.5722 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0667 - dense_1_acc_2: 0.3000 - dense_1_acc_3: 0.4333 - dense_1_acc_4: 0.4000 - dense_1_acc_5: 0.4167 - dense_1_acc_6: 0.4333 - dense_1_acc_7: 0.4833 - dense_1_acc_8: 0.6000 - dense_1_acc_9: 0.6333 - dense_1_acc_10: 0.6167 - dense_1_acc_11: 0.6167 - dense_1_acc_12: 0.5333 - dense_1_acc_13: 0.7833 - dense_1_acc_14: 0.6833 - dense_1_acc_15: 0.5167 - dense_1_acc_16: 0.6167 - dense_1_acc_17: 0.5667 - dense_1_acc_18: 0.5667 - dense_1_acc_19: 0.6833 - dense_1_acc_20: 0.6167 - dense_1_acc_21: 0.6000 - dense_1_acc_22: 0.6667 - dense_1_acc_23: 0.5333 - dense_1_acc_24: 0.5167 - dense_1_acc_25: 0.4500 - dense_1_acc_26: 0.6500 - dense_1_acc_27: 0.5833 - dense_1_acc_28: 0.6333 - dense_1_acc_29: 0.6167 - dense_1_acc_30: 0.0167     
Epoch 23/100
60/60 [==============================] - 0s - loss: 50.5873 - dense_1_loss_1: 4.0989 - dense_1_loss_2: 3.4085 - dense_1_loss_3: 2.6755 - dense_1_loss_4: 2.3346 - dense_1_loss_5: 2.0253 - dense_1_loss_6: 1.8056 - dense_1_loss_7: 1.8110 - dense_1_loss_8: 1.6679 - dense_1_loss_9: 1.5486 - dense_1_loss_10: 1.4742 - dense_1_loss_11: 1.6158 - dense_1_loss_12: 1.4831 - dense_1_loss_13: 1.3308 - dense_1_loss_14: 1.3322 - dense_1_loss_15: 1.5146 - dense_1_loss_16: 1.5332 - dense_1_loss_17: 1.4608 - dense_1_loss_18: 1.4368 - dense_1_loss_19: 1.3655 - dense_1_loss_20: 1.4530 - dense_1_loss_21: 1.4696 - dense_1_loss_22: 1.3947 - dense_1_loss_23: 1.4381 - dense_1_loss_24: 1.4368 - dense_1_loss_25: 1.5236 - dense_1_loss_26: 1.4070 - dense_1_loss_27: 1.6220 - dense_1_loss_28: 1.4565 - dense_1_loss_29: 1.4634 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0667 - dense_1_acc_2: 0.3333 - dense_1_acc_3: 0.4333 - dense_1_acc_4: 0.4000 - dense_1_acc_5: 0.4333 - dense_1_acc_6: 0.4667 - dense_1_acc_7: 0.5000 - dense_1_acc_8: 0.6167 - dense_1_acc_9: 0.6500 - dense_1_acc_10: 0.6667 - dense_1_acc_11: 0.6167 - dense_1_acc_12: 0.6667 - dense_1_acc_13: 0.8000 - dense_1_acc_14: 0.7167 - dense_1_acc_15: 0.5500 - dense_1_acc_16: 0.6167 - dense_1_acc_17: 0.6000 - dense_1_acc_18: 0.6667 - dense_1_acc_19: 0.6667 - dense_1_acc_20: 0.7167 - dense_1_acc_21: 0.6667 - dense_1_acc_22: 0.6833 - dense_1_acc_23: 0.6667 - dense_1_acc_24: 0.6500 - dense_1_acc_25: 0.6167 - dense_1_acc_26: 0.7167 - dense_1_acc_27: 0.6333 - dense_1_acc_28: 0.7667 - dense_1_acc_29: 0.7333 - dense_1_acc_30: 0.0167     
Epoch 24/100
60/60 [==============================] - 0s - loss: 48.0124 - dense_1_loss_1: 4.0911 - dense_1_loss_2: 3.3565 - dense_1_loss_3: 2.5827 - dense_1_loss_4: 2.2392 - dense_1_loss_5: 1.9487 - dense_1_loss_6: 1.7125 - dense_1_loss_7: 1.7128 - dense_1_loss_8: 1.5777 - dense_1_loss_9: 1.4567 - dense_1_loss_10: 1.3825 - dense_1_loss_11: 1.5174 - dense_1_loss_12: 1.4108 - dense_1_loss_13: 1.2284 - dense_1_loss_14: 1.2419 - dense_1_loss_15: 1.4646 - dense_1_loss_16: 1.4063 - dense_1_loss_17: 1.3541 - dense_1_loss_18: 1.3419 - dense_1_loss_19: 1.2807 - dense_1_loss_20: 1.3653 - dense_1_loss_21: 1.3368 - dense_1_loss_22: 1.3361 - dense_1_loss_23: 1.3426 - dense_1_loss_24: 1.3394 - dense_1_loss_25: 1.4272 - dense_1_loss_26: 1.3304 - dense_1_loss_27: 1.5169 - dense_1_loss_28: 1.3627 - dense_1_loss_29: 1.3487 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0667 - dense_1_acc_2: 0.3333 - dense_1_acc_3: 0.4333 - dense_1_acc_4: 0.4333 - dense_1_acc_5: 0.4667 - dense_1_acc_6: 0.5167 - dense_1_acc_7: 0.5333 - dense_1_acc_8: 0.6500 - dense_1_acc_9: 0.7167 - dense_1_acc_10: 0.6833 - dense_1_acc_11: 0.6500 - dense_1_acc_12: 0.6167 - dense_1_acc_13: 0.8000 - dense_1_acc_14: 0.7333 - dense_1_acc_15: 0.5500 - dense_1_acc_16: 0.6000 - dense_1_acc_17: 0.6500 - dense_1_acc_18: 0.7000 - dense_1_acc_19: 0.7667 - dense_1_acc_20: 0.7000 - dense_1_acc_21: 0.6500 - dense_1_acc_22: 0.6333 - dense_1_acc_23: 0.7500 - dense_1_acc_24: 0.6500 - dense_1_acc_25: 0.6500 - dense_1_acc_26: 0.7333 - dense_1_acc_27: 0.6500 - dense_1_acc_28: 0.8000 - dense_1_acc_29: 0.7333 - dense_1_acc_30: 0.0000e+00     
Epoch 25/100
60/60 [==============================] - 0s - loss: 45.4820 - dense_1_loss_1: 4.0821 - dense_1_loss_2: 3.3035 - dense_1_loss_3: 2.4932 - dense_1_loss_4: 2.1394 - dense_1_loss_5: 1.8618 - dense_1_loss_6: 1.5927 - dense_1_loss_7: 1.5952 - dense_1_loss_8: 1.4709 - dense_1_loss_9: 1.3422 - dense_1_loss_10: 1.2773 - dense_1_loss_11: 1.4244 - dense_1_loss_12: 1.3318 - dense_1_loss_13: 1.1597 - dense_1_loss_14: 1.1760 - dense_1_loss_15: 1.3751 - dense_1_loss_16: 1.3219 - dense_1_loss_17: 1.2388 - dense_1_loss_18: 1.2431 - dense_1_loss_19: 1.1955 - dense_1_loss_20: 1.2844 - dense_1_loss_21: 1.2624 - dense_1_loss_22: 1.2682 - dense_1_loss_23: 1.2660 - dense_1_loss_24: 1.2423 - dense_1_loss_25: 1.3253 - dense_1_loss_26: 1.2659 - dense_1_loss_27: 1.4072 - dense_1_loss_28: 1.2809 - dense_1_loss_29: 1.2545 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0667 - dense_1_acc_2: 0.3333 - dense_1_acc_3: 0.4667 - dense_1_acc_4: 0.4500 - dense_1_acc_5: 0.4667 - dense_1_acc_6: 0.6333 - dense_1_acc_7: 0.6167 - dense_1_acc_8: 0.6833 - dense_1_acc_9: 0.7667 - dense_1_acc_10: 0.7333 - dense_1_acc_11: 0.6833 - dense_1_acc_12: 0.5833 - dense_1_acc_13: 0.7833 - dense_1_acc_14: 0.7500 - dense_1_acc_15: 0.6000 - dense_1_acc_16: 0.6167 - dense_1_acc_17: 0.7167 - dense_1_acc_18: 0.7000 - dense_1_acc_19: 0.7833 - dense_1_acc_20: 0.7333 - dense_1_acc_21: 0.7000 - dense_1_acc_22: 0.6500 - dense_1_acc_23: 0.7500 - dense_1_acc_24: 0.6833 - dense_1_acc_25: 0.7000 - dense_1_acc_26: 0.7167 - dense_1_acc_27: 0.6833 - dense_1_acc_28: 0.7833 - dense_1_acc_29: 0.8167 - dense_1_acc_30: 0.0167     
Epoch 26/100
60/60 [==============================] - 0s - loss: 43.0301 - dense_1_loss_1: 4.0738 - dense_1_loss_2: 3.2484 - dense_1_loss_3: 2.4048 - dense_1_loss_4: 2.0426 - dense_1_loss_5: 1.7783 - dense_1_loss_6: 1.5030 - dense_1_loss_7: 1.4859 - dense_1_loss_8: 1.3724 - dense_1_loss_9: 1.2571 - dense_1_loss_10: 1.1921 - dense_1_loss_11: 1.3145 - dense_1_loss_12: 1.2496 - dense_1_loss_13: 1.0994 - dense_1_loss_14: 1.0986 - dense_1_loss_15: 1.2701 - dense_1_loss_16: 1.2415 - dense_1_loss_17: 1.1565 - dense_1_loss_18: 1.1453 - dense_1_loss_19: 1.1117 - dense_1_loss_20: 1.2237 - dense_1_loss_21: 1.1896 - dense_1_loss_22: 1.1452 - dense_1_loss_23: 1.1705 - dense_1_loss_24: 1.1631 - dense_1_loss_25: 1.2423 - dense_1_loss_26: 1.1926 - dense_1_loss_27: 1.2864 - dense_1_loss_28: 1.1890 - dense_1_loss_29: 1.1818 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0667 - dense_1_acc_2: 0.3333 - dense_1_acc_3: 0.5167 - dense_1_acc_4: 0.4833 - dense_1_acc_5: 0.5167 - dense_1_acc_6: 0.6500 - dense_1_acc_7: 0.6333 - dense_1_acc_8: 0.7000 - dense_1_acc_9: 0.7833 - dense_1_acc_10: 0.7500 - dense_1_acc_11: 0.7500 - dense_1_acc_12: 0.7333 - dense_1_acc_13: 0.8167 - dense_1_acc_14: 0.7833 - dense_1_acc_15: 0.6833 - dense_1_acc_16: 0.7000 - dense_1_acc_17: 0.7833 - dense_1_acc_18: 0.7333 - dense_1_acc_19: 0.8000 - dense_1_acc_20: 0.7667 - dense_1_acc_21: 0.7667 - dense_1_acc_22: 0.7667 - dense_1_acc_23: 0.7833 - dense_1_acc_24: 0.7667 - dense_1_acc_25: 0.6167 - dense_1_acc_26: 0.7333 - dense_1_acc_27: 0.7333 - dense_1_acc_28: 0.8500 - dense_1_acc_29: 0.8333 - dense_1_acc_30: 0.0167     
Epoch 27/100
60/60 [==============================] - 0s - loss: 40.6489 - dense_1_loss_1: 4.0643 - dense_1_loss_2: 3.1968 - dense_1_loss_3: 2.3192 - dense_1_loss_4: 1.9529 - dense_1_loss_5: 1.7048 - dense_1_loss_6: 1.4007 - dense_1_loss_7: 1.3986 - dense_1_loss_8: 1.2981 - dense_1_loss_9: 1.1628 - dense_1_loss_10: 1.0877 - dense_1_loss_11: 1.2170 - dense_1_loss_12: 1.1667 - dense_1_loss_13: 1.0247 - dense_1_loss_14: 1.0150 - dense_1_loss_15: 1.2028 - dense_1_loss_16: 1.1495 - dense_1_loss_17: 1.0764 - dense_1_loss_18: 1.0719 - dense_1_loss_19: 1.0219 - dense_1_loss_20: 1.1116 - dense_1_loss_21: 1.1295 - dense_1_loss_22: 1.0810 - dense_1_loss_23: 1.0796 - dense_1_loss_24: 1.0548 - dense_1_loss_25: 1.1814 - dense_1_loss_26: 1.0977 - dense_1_loss_27: 1.1859 - dense_1_loss_28: 1.0990 - dense_1_loss_29: 1.0966 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0667 - dense_1_acc_2: 0.3667 - dense_1_acc_3: 0.5167 - dense_1_acc_4: 0.4667 - dense_1_acc_5: 0.5333 - dense_1_acc_6: 0.6667 - dense_1_acc_7: 0.6500 - dense_1_acc_8: 0.7500 - dense_1_acc_9: 0.8333 - dense_1_acc_10: 0.8333 - dense_1_acc_11: 0.7667 - dense_1_acc_12: 0.7833 - dense_1_acc_13: 0.8500 - dense_1_acc_14: 0.8667 - dense_1_acc_15: 0.7833 - dense_1_acc_16: 0.7833 - dense_1_acc_17: 0.8167 - dense_1_acc_18: 0.7333 - dense_1_acc_19: 0.8333 - dense_1_acc_20: 0.8500 - dense_1_acc_21: 0.7667 - dense_1_acc_22: 0.7833 - dense_1_acc_23: 0.8667 - dense_1_acc_24: 0.9000 - dense_1_acc_25: 0.7333 - dense_1_acc_26: 0.7500 - dense_1_acc_27: 0.8333 - dense_1_acc_28: 0.8667 - dense_1_acc_29: 0.8500 - dense_1_acc_30: 0.0167     
Epoch 28/100
60/60 [==============================] - 0s - loss: 38.5012 - dense_1_loss_1: 4.0554 - dense_1_loss_2: 3.1419 - dense_1_loss_3: 2.2324 - dense_1_loss_4: 1.8692 - dense_1_loss_5: 1.6332 - dense_1_loss_6: 1.3317 - dense_1_loss_7: 1.3088 - dense_1_loss_8: 1.2084 - dense_1_loss_9: 1.0790 - dense_1_loss_10: 1.0146 - dense_1_loss_11: 1.1289 - dense_1_loss_12: 1.0775 - dense_1_loss_13: 0.9498 - dense_1_loss_14: 0.9413 - dense_1_loss_15: 1.1165 - dense_1_loss_16: 1.0642 - dense_1_loss_17: 0.9985 - dense_1_loss_18: 0.9798 - dense_1_loss_19: 0.9792 - dense_1_loss_20: 1.0467 - dense_1_loss_21: 1.0503 - dense_1_loss_22: 1.0155 - dense_1_loss_23: 1.0102 - dense_1_loss_24: 0.9849 - dense_1_loss_25: 1.0981 - dense_1_loss_26: 1.0020 - dense_1_loss_27: 1.1428 - dense_1_loss_28: 1.0341 - dense_1_loss_29: 1.0062 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0667 - dense_1_acc_2: 0.3667 - dense_1_acc_3: 0.5333 - dense_1_acc_4: 0.4833 - dense_1_acc_5: 0.5333 - dense_1_acc_6: 0.7000 - dense_1_acc_7: 0.7000 - dense_1_acc_8: 0.7667 - dense_1_acc_9: 0.8667 - dense_1_acc_10: 0.8500 - dense_1_acc_11: 0.8000 - dense_1_acc_12: 0.8167 - dense_1_acc_13: 0.8500 - dense_1_acc_14: 0.9000 - dense_1_acc_15: 0.8500 - dense_1_acc_16: 0.8167 - dense_1_acc_17: 0.9000 - dense_1_acc_18: 0.8167 - dense_1_acc_19: 0.8667 - dense_1_acc_20: 0.8833 - dense_1_acc_21: 0.8500 - dense_1_acc_22: 0.8167 - dense_1_acc_23: 0.8667 - dense_1_acc_24: 0.9000 - dense_1_acc_25: 0.7833 - dense_1_acc_26: 0.8333 - dense_1_acc_27: 0.7833 - dense_1_acc_28: 0.8667 - dense_1_acc_29: 0.8833 - dense_1_acc_30: 0.0167         
Epoch 29/100
60/60 [==============================] - 0s - loss: 36.2900 - dense_1_loss_1: 4.0475 - dense_1_loss_2: 3.0890 - dense_1_loss_3: 2.1522 - dense_1_loss_4: 1.7732 - dense_1_loss_5: 1.5568 - dense_1_loss_6: 1.2499 - dense_1_loss_7: 1.2172 - dense_1_loss_8: 1.1149 - dense_1_loss_9: 0.9999 - dense_1_loss_10: 0.9437 - dense_1_loss_11: 1.0384 - dense_1_loss_12: 1.0027 - dense_1_loss_13: 0.8743 - dense_1_loss_14: 0.8947 - dense_1_loss_15: 1.0342 - dense_1_loss_16: 0.9878 - dense_1_loss_17: 0.9406 - dense_1_loss_18: 0.8991 - dense_1_loss_19: 0.9002 - dense_1_loss_20: 0.9664 - dense_1_loss_21: 0.9829 - dense_1_loss_22: 0.9229 - dense_1_loss_23: 0.9299 - dense_1_loss_24: 0.9025 - dense_1_loss_25: 1.0044 - dense_1_loss_26: 0.9331 - dense_1_loss_27: 1.0223 - dense_1_loss_28: 0.9672 - dense_1_loss_29: 0.9423 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0667 - dense_1_acc_2: 0.3667 - dense_1_acc_3: 0.5500 - dense_1_acc_4: 0.5000 - dense_1_acc_5: 0.5667 - dense_1_acc_6: 0.7667 - dense_1_acc_7: 0.7000 - dense_1_acc_8: 0.7833 - dense_1_acc_9: 0.8833 - dense_1_acc_10: 0.9000 - dense_1_acc_11: 0.8667 - dense_1_acc_12: 0.9000 - dense_1_acc_13: 0.9167 - dense_1_acc_14: 0.9000 - dense_1_acc_15: 0.8333 - dense_1_acc_16: 0.9000 - dense_1_acc_17: 0.9333 - dense_1_acc_18: 0.9500 - dense_1_acc_19: 0.9167 - dense_1_acc_20: 0.9167 - dense_1_acc_21: 0.8833 - dense_1_acc_22: 0.9000 - dense_1_acc_23: 0.8667 - dense_1_acc_24: 0.9333 - dense_1_acc_25: 0.8167 - dense_1_acc_26: 0.8500 - dense_1_acc_27: 0.8833 - dense_1_acc_28: 0.8833 - dense_1_acc_29: 0.9000 - dense_1_acc_30: 0.0167         
Epoch 30/100
60/60 [==============================] - 0s - loss: 34.2776 - dense_1_loss_1: 4.0400 - dense_1_loss_2: 3.0323 - dense_1_loss_3: 2.0729 - dense_1_loss_4: 1.6822 - dense_1_loss_5: 1.4782 - dense_1_loss_6: 1.1650 - dense_1_loss_7: 1.1360 - dense_1_loss_8: 1.0299 - dense_1_loss_9: 0.9242 - dense_1_loss_10: 0.8476 - dense_1_loss_11: 0.9565 - dense_1_loss_12: 0.9325 - dense_1_loss_13: 0.8164 - dense_1_loss_14: 0.8316 - dense_1_loss_15: 0.9561 - dense_1_loss_16: 0.9252 - dense_1_loss_17: 0.8828 - dense_1_loss_18: 0.8182 - dense_1_loss_19: 0.8294 - dense_1_loss_20: 0.9006 - dense_1_loss_21: 0.9198 - dense_1_loss_22: 0.8573 - dense_1_loss_23: 0.8831 - dense_1_loss_24: 0.8393 - dense_1_loss_25: 0.9440 - dense_1_loss_26: 0.8864 - dense_1_loss_27: 0.9272 - dense_1_loss_28: 0.9061 - dense_1_loss_29: 0.8567 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0667 - dense_1_acc_2: 0.3667 - dense_1_acc_3: 0.6000 - dense_1_acc_4: 0.5167 - dense_1_acc_5: 0.5667 - dense_1_acc_6: 0.8333 - dense_1_acc_7: 0.7833 - dense_1_acc_8: 0.7667 - dense_1_acc_9: 0.9333 - dense_1_acc_10: 0.9333 - dense_1_acc_11: 0.8667 - dense_1_acc_12: 0.9000 - dense_1_acc_13: 0.9167 - dense_1_acc_14: 0.8833 - dense_1_acc_15: 0.8833 - dense_1_acc_16: 0.8667 - dense_1_acc_17: 0.9167 - dense_1_acc_18: 0.9333 - dense_1_acc_19: 0.9167 - dense_1_acc_20: 0.9500 - dense_1_acc_21: 0.9167 - dense_1_acc_22: 0.9000 - dense_1_acc_23: 0.8667 - dense_1_acc_24: 0.9333 - dense_1_acc_25: 0.8667 - dense_1_acc_26: 0.8833 - dense_1_acc_27: 0.9000 - dense_1_acc_28: 0.9000 - dense_1_acc_29: 0.9167 - dense_1_acc_30: 0.0167         
Epoch 31/100
60/60 [==============================] - 0s - loss: 32.3874 - dense_1_loss_1: 4.0320 - dense_1_loss_2: 2.9795 - dense_1_loss_3: 1.9964 - dense_1_loss_4: 1.6013 - dense_1_loss_5: 1.4125 - dense_1_loss_6: 1.0834 - dense_1_loss_7: 1.0579 - dense_1_loss_8: 0.9622 - dense_1_loss_9: 0.8576 - dense_1_loss_10: 0.7816 - dense_1_loss_11: 0.8793 - dense_1_loss_12: 0.8621 - dense_1_loss_13: 0.7531 - dense_1_loss_14: 0.7716 - dense_1_loss_15: 0.8798 - dense_1_loss_16: 0.8482 - dense_1_loss_17: 0.8180 - dense_1_loss_18: 0.7467 - dense_1_loss_19: 0.7651 - dense_1_loss_20: 0.8593 - dense_1_loss_21: 0.8461 - dense_1_loss_22: 0.7903 - dense_1_loss_23: 0.8255 - dense_1_loss_24: 0.7743 - dense_1_loss_25: 0.8714 - dense_1_loss_26: 0.8223 - dense_1_loss_27: 0.8704 - dense_1_loss_28: 0.8394 - dense_1_loss_29: 0.8001 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0667 - dense_1_acc_2: 0.3667 - dense_1_acc_3: 0.6167 - dense_1_acc_4: 0.5833 - dense_1_acc_5: 0.6000 - dense_1_acc_6: 0.8500 - dense_1_acc_7: 0.8333 - dense_1_acc_8: 0.8667 - dense_1_acc_9: 0.9500 - dense_1_acc_10: 0.9833 - dense_1_acc_11: 0.9167 - dense_1_acc_12: 0.9333 - dense_1_acc_13: 0.9167 - dense_1_acc_14: 0.9500 - dense_1_acc_15: 0.9000 - dense_1_acc_16: 0.8833 - dense_1_acc_17: 0.9167 - dense_1_acc_18: 0.9500 - dense_1_acc_19: 0.9333 - dense_1_acc_20: 0.9500 - dense_1_acc_21: 0.9167 - dense_1_acc_22: 0.9000 - dense_1_acc_23: 0.8667 - dense_1_acc_24: 0.9500 - dense_1_acc_25: 0.8667 - dense_1_acc_26: 0.9000 - dense_1_acc_27: 0.9167 - dense_1_acc_28: 0.9000 - dense_1_acc_29: 0.9167 - dense_1_acc_30: 0.0167         
Epoch 32/100
60/60 [==============================] - 0s - loss: 30.6019 - dense_1_loss_1: 4.0253 - dense_1_loss_2: 2.9260 - dense_1_loss_3: 1.9226 - dense_1_loss_4: 1.5226 - dense_1_loss_5: 1.3456 - dense_1_loss_6: 0.9979 - dense_1_loss_7: 0.9865 - dense_1_loss_8: 0.8902 - dense_1_loss_9: 0.7965 - dense_1_loss_10: 0.7172 - dense_1_loss_11: 0.8154 - dense_1_loss_12: 0.8018 - dense_1_loss_13: 0.7015 - dense_1_loss_14: 0.7202 - dense_1_loss_15: 0.8234 - dense_1_loss_16: 0.7797 - dense_1_loss_17: 0.7551 - dense_1_loss_18: 0.6868 - dense_1_loss_19: 0.7120 - dense_1_loss_20: 0.7800 - dense_1_loss_21: 0.7890 - dense_1_loss_22: 0.7401 - dense_1_loss_23: 0.7447 - dense_1_loss_24: 0.7186 - dense_1_loss_25: 0.7967 - dense_1_loss_26: 0.7666 - dense_1_loss_27: 0.8148 - dense_1_loss_28: 0.7746 - dense_1_loss_29: 0.7506 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0667 - dense_1_acc_2: 0.3667 - dense_1_acc_3: 0.6167 - dense_1_acc_4: 0.5833 - dense_1_acc_5: 0.6167 - dense_1_acc_6: 0.8500 - dense_1_acc_7: 0.8500 - dense_1_acc_8: 0.9000 - dense_1_acc_9: 0.9500 - dense_1_acc_10: 0.9833 - dense_1_acc_11: 0.9167 - dense_1_acc_12: 0.9667 - dense_1_acc_13: 0.9500 - dense_1_acc_14: 0.9833 - dense_1_acc_15: 0.9333 - dense_1_acc_16: 0.9667 - dense_1_acc_17: 0.9333 - dense_1_acc_18: 0.9667 - dense_1_acc_19: 0.9333 - dense_1_acc_20: 0.9667 - dense_1_acc_21: 0.9167 - dense_1_acc_22: 0.9500 - dense_1_acc_23: 0.8833 - dense_1_acc_24: 0.9333 - dense_1_acc_25: 0.9167 - dense_1_acc_26: 0.9667 - dense_1_acc_27: 0.9333 - dense_1_acc_28: 0.9167 - dense_1_acc_29: 0.9333 - dense_1_acc_30: 0.0167         
Epoch 33/100
60/60 [==============================] - 0s - loss: 28.9155 - dense_1_loss_1: 4.0187 - dense_1_loss_2: 2.8712 - dense_1_loss_3: 1.8530 - dense_1_loss_4: 1.4376 - dense_1_loss_5: 1.2630 - dense_1_loss_6: 0.9279 - dense_1_loss_7: 0.9167 - dense_1_loss_8: 0.8237 - dense_1_loss_9: 0.7337 - dense_1_loss_10: 0.6539 - dense_1_loss_11: 0.7470 - dense_1_loss_12: 0.7365 - dense_1_loss_13: 0.6297 - dense_1_loss_14: 0.6557 - dense_1_loss_15: 0.7662 - dense_1_loss_16: 0.7226 - dense_1_loss_17: 0.7063 - dense_1_loss_18: 0.6266 - dense_1_loss_19: 0.6868 - dense_1_loss_20: 0.7298 - dense_1_loss_21: 0.7231 - dense_1_loss_22: 0.6905 - dense_1_loss_23: 0.6942 - dense_1_loss_24: 0.6825 - dense_1_loss_25: 0.7274 - dense_1_loss_26: 0.7129 - dense_1_loss_27: 0.7465 - dense_1_loss_28: 0.7272 - dense_1_loss_29: 0.7043 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0667 - dense_1_acc_2: 0.3667 - dense_1_acc_3: 0.6500 - dense_1_acc_4: 0.5833 - dense_1_acc_5: 0.6833 - dense_1_acc_6: 0.8667 - dense_1_acc_7: 0.8500 - dense_1_acc_8: 0.8833 - dense_1_acc_9: 0.9500 - dense_1_acc_10: 1.0000 - dense_1_acc_11: 0.9167 - dense_1_acc_12: 0.9833 - dense_1_acc_13: 0.9833 - dense_1_acc_14: 0.9667 - dense_1_acc_15: 0.9000 - dense_1_acc_16: 1.0000 - dense_1_acc_17: 0.9500 - dense_1_acc_18: 1.0000 - dense_1_acc_19: 0.9500 - dense_1_acc_20: 0.9833 - dense_1_acc_21: 0.9500 - dense_1_acc_22: 0.9667 - dense_1_acc_23: 0.9333 - dense_1_acc_24: 1.0000 - dense_1_acc_25: 0.9333 - dense_1_acc_26: 0.9667 - dense_1_acc_27: 0.9167 - dense_1_acc_28: 0.9167 - dense_1_acc_29: 0.9333 - dense_1_acc_30: 0.0167     
Epoch 34/100
60/60 [==============================] - 0s - loss: 27.3393 - dense_1_loss_1: 4.0116 - dense_1_loss_2: 2.8215 - dense_1_loss_3: 1.7820 - dense_1_loss_4: 1.3589 - dense_1_loss_5: 1.1964 - dense_1_loss_6: 0.8523 - dense_1_loss_7: 0.8466 - dense_1_loss_8: 0.7520 - dense_1_loss_9: 0.6712 - dense_1_loss_10: 0.5999 - dense_1_loss_11: 0.6884 - dense_1_loss_12: 0.6818 - dense_1_loss_13: 0.5985 - dense_1_loss_14: 0.6256 - dense_1_loss_15: 0.6824 - dense_1_loss_16: 0.6678 - dense_1_loss_17: 0.6643 - dense_1_loss_18: 0.5802 - dense_1_loss_19: 0.6263 - dense_1_loss_20: 0.6744 - dense_1_loss_21: 0.7033 - dense_1_loss_22: 0.6330 - dense_1_loss_23: 0.6447 - dense_1_loss_24: 0.6192 - dense_1_loss_25: 0.6902 - dense_1_loss_26: 0.6662 - dense_1_loss_27: 0.6732 - dense_1_loss_28: 0.6626 - dense_1_loss_29: 0.6646 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0667 - dense_1_acc_2: 0.3667 - dense_1_acc_3: 0.6500 - dense_1_acc_4: 0.5833 - dense_1_acc_5: 0.6833 - dense_1_acc_6: 0.9167 - dense_1_acc_7: 0.9000 - dense_1_acc_8: 0.9000 - dense_1_acc_9: 0.9500 - dense_1_acc_10: 1.0000 - dense_1_acc_11: 0.9167 - dense_1_acc_12: 0.9833 - dense_1_acc_13: 0.9667 - dense_1_acc_14: 0.9833 - dense_1_acc_15: 0.9833 - dense_1_acc_16: 1.0000 - dense_1_acc_17: 0.9667 - dense_1_acc_18: 1.0000 - dense_1_acc_19: 0.9500 - dense_1_acc_20: 0.9833 - dense_1_acc_21: 0.9500 - dense_1_acc_22: 0.9500 - dense_1_acc_23: 0.8833 - dense_1_acc_24: 0.9667 - dense_1_acc_25: 0.8833 - dense_1_acc_26: 0.9500 - dense_1_acc_27: 0.9333 - dense_1_acc_28: 0.9333 - dense_1_acc_29: 0.9167 - dense_1_acc_30: 0.0167         
Epoch 35/100
60/60 [==============================] - 0s - loss: 25.7952 - dense_1_loss_1: 4.0050 - dense_1_loss_2: 2.7683 - dense_1_loss_3: 1.7160 - dense_1_loss_4: 1.2795 - dense_1_loss_5: 1.1215 - dense_1_loss_6: 0.7937 - dense_1_loss_7: 0.7846 - dense_1_loss_8: 0.6910 - dense_1_loss_9: 0.6219 - dense_1_loss_10: 0.5480 - dense_1_loss_11: 0.6136 - dense_1_loss_12: 0.6243 - dense_1_loss_13: 0.5481 - dense_1_loss_14: 0.5498 - dense_1_loss_15: 0.6404 - dense_1_loss_16: 0.6050 - dense_1_loss_17: 0.6143 - dense_1_loss_18: 0.5306 - dense_1_loss_19: 0.5860 - dense_1_loss_20: 0.6265 - dense_1_loss_21: 0.6345 - dense_1_loss_22: 0.5871 - dense_1_loss_23: 0.5896 - dense_1_loss_24: 0.5945 - dense_1_loss_25: 0.6243 - dense_1_loss_26: 0.6103 - dense_1_loss_27: 0.6484 - dense_1_loss_28: 0.6233 - dense_1_loss_29: 0.6152 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0667 - dense_1_acc_2: 0.3833 - dense_1_acc_3: 0.6500 - dense_1_acc_4: 0.6333 - dense_1_acc_5: 0.7667 - dense_1_acc_6: 0.9167 - dense_1_acc_7: 0.9333 - dense_1_acc_8: 0.9167 - dense_1_acc_9: 0.9500 - dense_1_acc_10: 1.0000 - dense_1_acc_11: 0.9167 - dense_1_acc_12: 1.0000 - dense_1_acc_13: 0.9833 - dense_1_acc_14: 0.9667 - dense_1_acc_15: 0.9500 - dense_1_acc_16: 1.0000 - dense_1_acc_17: 0.9500 - dense_1_acc_18: 1.0000 - dense_1_acc_19: 0.9667 - dense_1_acc_20: 0.9667 - dense_1_acc_21: 0.9667 - dense_1_acc_22: 0.9667 - dense_1_acc_23: 0.9167 - dense_1_acc_24: 1.0000 - dense_1_acc_25: 0.9333 - dense_1_acc_26: 0.9667 - dense_1_acc_27: 0.9333 - dense_1_acc_28: 0.9500 - dense_1_acc_29: 0.9500 - dense_1_acc_30: 0.0167         
Epoch 36/100
60/60 [==============================] - 0s - loss: 24.2831 - dense_1_loss_1: 3.9989 - dense_1_loss_2: 2.7160 - dense_1_loss_3: 1.6521 - dense_1_loss_4: 1.2032 - dense_1_loss_5: 1.0577 - dense_1_loss_6: 0.7358 - dense_1_loss_7: 0.7281 - dense_1_loss_8: 0.6384 - dense_1_loss_9: 0.5761 - dense_1_loss_10: 0.5074 - dense_1_loss_11: 0.5741 - dense_1_loss_12: 0.5814 - dense_1_loss_13: 0.5035 - dense_1_loss_14: 0.5128 - dense_1_loss_15: 0.5973 - dense_1_loss_16: 0.5613 - dense_1_loss_17: 0.5635 - dense_1_loss_18: 0.4832 - dense_1_loss_19: 0.5292 - dense_1_loss_20: 0.5769 - dense_1_loss_21: 0.5806 - dense_1_loss_22: 0.5207 - dense_1_loss_23: 0.5265 - dense_1_loss_24: 0.5328 - dense_1_loss_25: 0.5807 - dense_1_loss_26: 0.5502 - dense_1_loss_27: 0.5725 - dense_1_loss_28: 0.5537 - dense_1_loss_29: 0.5686 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0667 - dense_1_acc_2: 0.4167 - dense_1_acc_3: 0.6500 - dense_1_acc_4: 0.6667 - dense_1_acc_5: 0.8000 - dense_1_acc_6: 0.9167 - dense_1_acc_7: 0.9333 - dense_1_acc_8: 0.9333 - dense_1_acc_9: 0.9500 - dense_1_acc_10: 1.0000 - dense_1_acc_11: 0.9333 - dense_1_acc_12: 1.0000 - dense_1_acc_13: 0.9833 - dense_1_acc_14: 0.9833 - dense_1_acc_15: 0.9833 - dense_1_acc_16: 1.0000 - dense_1_acc_17: 0.9667 - dense_1_acc_18: 1.0000 - dense_1_acc_19: 0.9833 - dense_1_acc_20: 0.9833 - dense_1_acc_21: 0.9667 - dense_1_acc_22: 0.9833 - dense_1_acc_23: 0.9500 - dense_1_acc_24: 1.0000 - dense_1_acc_25: 0.9500 - dense_1_acc_26: 0.9667 - dense_1_acc_27: 1.0000 - dense_1_acc_28: 0.9667 - dense_1_acc_29: 0.9667 - dense_1_acc_30: 0.0167     
Epoch 37/100
60/60 [==============================] - 0s - loss: 22.9767 - dense_1_loss_1: 3.9924 - dense_1_loss_2: 2.6642 - dense_1_loss_3: 1.5918 - dense_1_loss_4: 1.1276 - dense_1_loss_5: 0.9884 - dense_1_loss_6: 0.6889 - dense_1_loss_7: 0.6781 - dense_1_loss_8: 0.5838 - dense_1_loss_9: 0.5373 - dense_1_loss_10: 0.4593 - dense_1_loss_11: 0.5314 - dense_1_loss_12: 0.5226 - dense_1_loss_13: 0.4610 - dense_1_loss_14: 0.4660 - dense_1_loss_15: 0.5444 - dense_1_loss_16: 0.5156 - dense_1_loss_17: 0.5233 - dense_1_loss_18: 0.4348 - dense_1_loss_19: 0.4937 - dense_1_loss_20: 0.5467 - dense_1_loss_21: 0.5408 - dense_1_loss_22: 0.4763 - dense_1_loss_23: 0.4950 - dense_1_loss_24: 0.4919 - dense_1_loss_25: 0.5425 - dense_1_loss_26: 0.5039 - dense_1_loss_27: 0.5157 - dense_1_loss_28: 0.5252 - dense_1_loss_29: 0.5339 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0667 - dense_1_acc_2: 0.4167 - dense_1_acc_3: 0.6500 - dense_1_acc_4: 0.6833 - dense_1_acc_5: 0.7833 - dense_1_acc_6: 0.9167 - dense_1_acc_7: 0.9500 - dense_1_acc_8: 0.9667 - dense_1_acc_9: 0.9500 - dense_1_acc_10: 1.0000 - dense_1_acc_11: 0.9500 - dense_1_acc_12: 1.0000 - dense_1_acc_13: 0.9833 - dense_1_acc_14: 1.0000 - dense_1_acc_15: 1.0000 - dense_1_acc_16: 1.0000 - dense_1_acc_17: 0.9667 - dense_1_acc_18: 1.0000 - dense_1_acc_19: 0.9833 - dense_1_acc_20: 0.9833 - dense_1_acc_21: 0.9667 - dense_1_acc_22: 1.0000 - dense_1_acc_23: 0.9667 - dense_1_acc_24: 1.0000 - dense_1_acc_25: 0.9333 - dense_1_acc_26: 0.9667 - dense_1_acc_27: 1.0000 - dense_1_acc_28: 0.9667 - dense_1_acc_29: 0.9833 - dense_1_acc_30: 0.0167         
Epoch 38/100
60/60 [==============================] - 0s - loss: 21.6992 - dense_1_loss_1: 3.9866 - dense_1_loss_2: 2.6142 - dense_1_loss_3: 1.5343 - dense_1_loss_4: 1.0583 - dense_1_loss_5: 0.9259 - dense_1_loss_6: 0.6361 - dense_1_loss_7: 0.6163 - dense_1_loss_8: 0.5326 - dense_1_loss_9: 0.4863 - dense_1_loss_10: 0.4110 - dense_1_loss_11: 0.4792 - dense_1_loss_12: 0.4784 - dense_1_loss_13: 0.4247 - dense_1_loss_14: 0.4351 - dense_1_loss_15: 0.4932 - dense_1_loss_16: 0.4786 - dense_1_loss_17: 0.4662 - dense_1_loss_18: 0.4070 - dense_1_loss_19: 0.4537 - dense_1_loss_20: 0.4915 - dense_1_loss_21: 0.5037 - dense_1_loss_22: 0.4524 - dense_1_loss_23: 0.4481 - dense_1_loss_24: 0.4519 - dense_1_loss_25: 0.4978 - dense_1_loss_26: 0.4709 - dense_1_loss_27: 0.4895 - dense_1_loss_28: 0.4847 - dense_1_loss_29: 0.4910 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0667 - dense_1_acc_2: 0.4333 - dense_1_acc_3: 0.6667 - dense_1_acc_4: 0.6833 - dense_1_acc_5: 0.8000 - dense_1_acc_6: 0.9167 - dense_1_acc_7: 0.9500 - dense_1_acc_8: 0.9667 - dense_1_acc_9: 0.9500 - dense_1_acc_10: 1.0000 - dense_1_acc_11: 0.9500 - dense_1_acc_12: 1.0000 - dense_1_acc_13: 0.9833 - dense_1_acc_14: 1.0000 - dense_1_acc_15: 1.0000 - dense_1_acc_16: 1.0000 - dense_1_acc_17: 0.9833 - dense_1_acc_18: 1.0000 - dense_1_acc_19: 0.9833 - dense_1_acc_20: 0.9833 - dense_1_acc_21: 0.9667 - dense_1_acc_22: 1.0000 - dense_1_acc_23: 1.0000 - dense_1_acc_24: 1.0000 - dense_1_acc_25: 1.0000 - dense_1_acc_26: 0.9667 - dense_1_acc_27: 1.0000 - dense_1_acc_28: 0.9667 - dense_1_acc_29: 0.9667 - dense_1_acc_30: 0.0167         
Epoch 39/100
60/60 [==============================] - 0s - loss: 20.4963 - dense_1_loss_1: 3.9811 - dense_1_loss_2: 2.5633 - dense_1_loss_3: 1.4775 - dense_1_loss_4: 0.9943 - dense_1_loss_5: 0.8661 - dense_1_loss_6: 0.5924 - dense_1_loss_7: 0.5745 - dense_1_loss_8: 0.4959 - dense_1_loss_9: 0.4504 - dense_1_loss_10: 0.3755 - dense_1_loss_11: 0.4399 - dense_1_loss_12: 0.4438 - dense_1_loss_13: 0.3849 - dense_1_loss_14: 0.3939 - dense_1_loss_15: 0.4489 - dense_1_loss_16: 0.4411 - dense_1_loss_17: 0.4358 - dense_1_loss_18: 0.3657 - dense_1_loss_19: 0.4128 - dense_1_loss_20: 0.4565 - dense_1_loss_21: 0.4475 - dense_1_loss_22: 0.4039 - dense_1_loss_23: 0.4191 - dense_1_loss_24: 0.4126 - dense_1_loss_25: 0.4503 - dense_1_loss_26: 0.4174 - dense_1_loss_27: 0.4522 - dense_1_loss_28: 0.4428 - dense_1_loss_29: 0.4562 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0667 - dense_1_acc_2: 0.4500 - dense_1_acc_3: 0.6667 - dense_1_acc_4: 0.6833 - dense_1_acc_5: 0.8167 - dense_1_acc_6: 0.9167 - dense_1_acc_7: 0.9500 - dense_1_acc_8: 0.9667 - dense_1_acc_9: 0.9500 - dense_1_acc_10: 1.0000 - dense_1_acc_11: 0.9500 - dense_1_acc_12: 1.0000 - dense_1_acc_13: 0.9833 - dense_1_acc_14: 1.0000 - dense_1_acc_15: 1.0000 - dense_1_acc_16: 1.0000 - dense_1_acc_17: 0.9833 - dense_1_acc_18: 1.0000 - dense_1_acc_19: 0.9833 - dense_1_acc_20: 0.9833 - dense_1_acc_21: 0.9667 - dense_1_acc_22: 1.0000 - dense_1_acc_23: 1.0000 - dense_1_acc_24: 1.0000 - dense_1_acc_25: 1.0000 - dense_1_acc_26: 0.9833 - dense_1_acc_27: 1.0000 - dense_1_acc_28: 0.9667 - dense_1_acc_29: 0.9833 - dense_1_acc_30: 0.0167     
Epoch 40/100
60/60 [==============================] - 0s - loss: 19.4528 - dense_1_loss_1: 3.9756 - dense_1_loss_2: 2.5145 - dense_1_loss_3: 1.4269 - dense_1_loss_4: 0.9254 - dense_1_loss_5: 0.8088 - dense_1_loss_6: 0.5551 - dense_1_loss_7: 0.5304 - dense_1_loss_8: 0.4558 - dense_1_loss_9: 0.4263 - dense_1_loss_10: 0.3447 - dense_1_loss_11: 0.4116 - dense_1_loss_12: 0.4055 - dense_1_loss_13: 0.3525 - dense_1_loss_14: 0.3661 - dense_1_loss_15: 0.4096 - dense_1_loss_16: 0.3981 - dense_1_loss_17: 0.4117 - dense_1_loss_18: 0.3300 - dense_1_loss_19: 0.3792 - dense_1_loss_20: 0.4274 - dense_1_loss_21: 0.4123 - dense_1_loss_22: 0.3682 - dense_1_loss_23: 0.3872 - dense_1_loss_24: 0.3811 - dense_1_loss_25: 0.4246 - dense_1_loss_26: 0.3714 - dense_1_loss_27: 0.4072 - dense_1_loss_28: 0.4046 - dense_1_loss_29: 0.4408 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0667 - dense_1_acc_2: 0.4500 - dense_1_acc_3: 0.6833 - dense_1_acc_4: 0.7667 - dense_1_acc_5: 0.8500 - dense_1_acc_6: 0.9167 - dense_1_acc_7: 0.9500 - dense_1_acc_8: 0.9833 - dense_1_acc_9: 0.9500 - dense_1_acc_10: 1.0000 - dense_1_acc_11: 0.9500 - dense_1_acc_12: 1.0000 - dense_1_acc_13: 0.9833 - dense_1_acc_14: 1.0000 - dense_1_acc_15: 1.0000 - dense_1_acc_16: 1.0000 - dense_1_acc_17: 0.9833 - dense_1_acc_18: 1.0000 - dense_1_acc_19: 0.9833 - dense_1_acc_20: 0.9833 - dense_1_acc_21: 0.9667 - dense_1_acc_22: 1.0000 - dense_1_acc_23: 1.0000 - dense_1_acc_24: 1.0000 - dense_1_acc_25: 1.0000 - dense_1_acc_26: 0.9833 - dense_1_acc_27: 1.0000 - dense_1_acc_28: 0.9833 - dense_1_acc_29: 0.9833 - dense_1_acc_30: 0.0167     
Epoch 41/100
60/60 [==============================] - 0s - loss: 18.3972 - dense_1_loss_1: 3.9705 - dense_1_loss_2: 2.4647 - dense_1_loss_3: 1.3730 - dense_1_loss_4: 0.8653 - dense_1_loss_5: 0.7560 - dense_1_loss_6: 0.5100 - dense_1_loss_7: 0.4767 - dense_1_loss_8: 0.4146 - dense_1_loss_9: 0.3825 - dense_1_loss_10: 0.3136 - dense_1_loss_11: 0.3721 - dense_1_loss_12: 0.3677 - dense_1_loss_13: 0.3275 - dense_1_loss_14: 0.3405 - dense_1_loss_15: 0.3756 - dense_1_loss_16: 0.3667 - dense_1_loss_17: 0.3728 - dense_1_loss_18: 0.3067 - dense_1_loss_19: 0.3503 - dense_1_loss_20: 0.3827 - dense_1_loss_21: 0.3858 - dense_1_loss_22: 0.3512 - dense_1_loss_23: 0.3547 - dense_1_loss_24: 0.3416 - dense_1_loss_25: 0.3925 - dense_1_loss_26: 0.3499 - dense_1_loss_27: 0.3647 - dense_1_loss_28: 0.3743 - dense_1_loss_29: 0.3932 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0667 - dense_1_acc_2: 0.4500 - dense_1_acc_3: 0.6833 - dense_1_acc_4: 0.8000 - dense_1_acc_5: 0.8667 - dense_1_acc_6: 0.9333 - dense_1_acc_7: 0.9500 - dense_1_acc_8: 0.9833 - dense_1_acc_9: 0.9500 - dense_1_acc_10: 1.0000 - dense_1_acc_11: 0.9500 - dense_1_acc_12: 1.0000 - dense_1_acc_13: 1.0000 - dense_1_acc_14: 1.0000 - dense_1_acc_15: 1.0000 - dense_1_acc_16: 1.0000 - dense_1_acc_17: 0.9833 - dense_1_acc_18: 1.0000 - dense_1_acc_19: 0.9833 - dense_1_acc_20: 0.9833 - dense_1_acc_21: 0.9833 - dense_1_acc_22: 1.0000 - dense_1_acc_23: 1.0000 - dense_1_acc_24: 1.0000 - dense_1_acc_25: 1.0000 - dense_1_acc_26: 1.0000 - dense_1_acc_27: 1.0000 - dense_1_acc_28: 0.9667 - dense_1_acc_29: 0.9833 - dense_1_acc_30: 0.0167     
Epoch 42/100
60/60 [==============================] - 0s - loss: 17.4768 - dense_1_loss_1: 3.9652 - dense_1_loss_2: 2.4189 - dense_1_loss_3: 1.3234 - dense_1_loss_4: 0.8085 - dense_1_loss_5: 0.7067 - dense_1_loss_6: 0.4736 - dense_1_loss_7: 0.4420 - dense_1_loss_8: 0.3775 - dense_1_loss_9: 0.3542 - dense_1_loss_10: 0.2882 - dense_1_loss_11: 0.3358 - dense_1_loss_12: 0.3303 - dense_1_loss_13: 0.2971 - dense_1_loss_14: 0.3134 - dense_1_loss_15: 0.3472 - dense_1_loss_16: 0.3367 - dense_1_loss_17: 0.3444 - dense_1_loss_18: 0.2756 - dense_1_loss_19: 0.3269 - dense_1_loss_20: 0.3538 - dense_1_loss_21: 0.3535 - dense_1_loss_22: 0.3128 - dense_1_loss_23: 0.3258 - dense_1_loss_24: 0.3209 - dense_1_loss_25: 0.3503 - dense_1_loss_26: 0.3229 - dense_1_loss_27: 0.3470 - dense_1_loss_28: 0.3557 - dense_1_loss_29: 0.3685 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0667 - dense_1_acc_2: 0.5000 - dense_1_acc_3: 0.6833 - dense_1_acc_4: 0.8500 - dense_1_acc_5: 0.8833 - dense_1_acc_6: 0.9333 - dense_1_acc_7: 0.9500 - dense_1_acc_8: 0.9833 - dense_1_acc_9: 0.9500 - dense_1_acc_10: 1.0000 - dense_1_acc_11: 0.9500 - dense_1_acc_12: 1.0000 - dense_1_acc_13: 1.0000 - dense_1_acc_14: 1.0000 - dense_1_acc_15: 1.0000 - dense_1_acc_16: 1.0000 - dense_1_acc_17: 1.0000 - dense_1_acc_18: 1.0000 - dense_1_acc_19: 1.0000 - dense_1_acc_20: 1.0000 - dense_1_acc_21: 1.0000 - dense_1_acc_22: 1.0000 - dense_1_acc_23: 1.0000 - dense_1_acc_24: 1.0000 - dense_1_acc_25: 1.0000 - dense_1_acc_26: 1.0000 - dense_1_acc_27: 1.0000 - dense_1_acc_28: 0.9833 - dense_1_acc_29: 0.9667 - dense_1_acc_30: 0.0167         
Epoch 43/100
60/60 [==============================] - 0s - loss: 16.6251 - dense_1_loss_1: 3.9609 - dense_1_loss_2: 2.3713 - dense_1_loss_3: 1.2755 - dense_1_loss_4: 0.7573 - dense_1_loss_5: 0.6594 - dense_1_loss_6: 0.4422 - dense_1_loss_7: 0.4100 - dense_1_loss_8: 0.3483 - dense_1_loss_9: 0.3294 - dense_1_loss_10: 0.2625 - dense_1_loss_11: 0.3117 - dense_1_loss_12: 0.3121 - dense_1_loss_13: 0.2739 - dense_1_loss_14: 0.2842 - dense_1_loss_15: 0.3154 - dense_1_loss_16: 0.3160 - dense_1_loss_17: 0.3167 - dense_1_loss_18: 0.2524 - dense_1_loss_19: 0.2998 - dense_1_loss_20: 0.3208 - dense_1_loss_21: 0.3290 - dense_1_loss_22: 0.2954 - dense_1_loss_23: 0.2972 - dense_1_loss_24: 0.2913 - dense_1_loss_25: 0.3349 - dense_1_loss_26: 0.2963 - dense_1_loss_27: 0.3083 - dense_1_loss_28: 0.3178 - dense_1_loss_29: 0.3351 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0667 - dense_1_acc_2: 0.5000 - dense_1_acc_3: 0.6833 - dense_1_acc_4: 0.8833 - dense_1_acc_5: 0.8833 - dense_1_acc_6: 0.9667 - dense_1_acc_7: 0.9667 - dense_1_acc_8: 0.9833 - dense_1_acc_9: 0.9667 - dense_1_acc_10: 1.0000 - dense_1_acc_11: 0.9667 - dense_1_acc_12: 1.0000 - dense_1_acc_13: 1.0000 - dense_1_acc_14: 1.0000 - dense_1_acc_15: 1.0000 - dense_1_acc_16: 1.0000 - dense_1_acc_17: 1.0000 - dense_1_acc_18: 1.0000 - dense_1_acc_19: 1.0000 - dense_1_acc_20: 1.0000 - dense_1_acc_21: 1.0000 - dense_1_acc_22: 1.0000 - dense_1_acc_23: 1.0000 - dense_1_acc_24: 1.0000 - dense_1_acc_25: 1.0000 - dense_1_acc_26: 1.0000 - dense_1_acc_27: 1.0000 - dense_1_acc_28: 0.9833 - dense_1_acc_29: 0.9833 - dense_1_acc_30: 0.0167         
Epoch 44/100
60/60 [==============================] - 0s - loss: 15.8476 - dense_1_loss_1: 3.9561 - dense_1_loss_2: 2.3274 - dense_1_loss_3: 1.2316 - dense_1_loss_4: 0.7057 - dense_1_loss_5: 0.6175 - dense_1_loss_6: 0.4123 - dense_1_loss_7: 0.3831 - dense_1_loss_8: 0.3233 - dense_1_loss_9: 0.3050 - dense_1_loss_10: 0.2411 - dense_1_loss_11: 0.2888 - dense_1_loss_12: 0.2845 - dense_1_loss_13: 0.2520 - dense_1_loss_14: 0.2593 - dense_1_loss_15: 0.2974 - dense_1_loss_16: 0.2893 - dense_1_loss_17: 0.2940 - dense_1_loss_18: 0.2310 - dense_1_loss_19: 0.2732 - dense_1_loss_20: 0.3003 - dense_1_loss_21: 0.2938 - dense_1_loss_22: 0.2715 - dense_1_loss_23: 0.2785 - dense_1_loss_24: 0.2699 - dense_1_loss_25: 0.2968 - dense_1_loss_26: 0.2689 - dense_1_loss_27: 0.2867 - dense_1_loss_28: 0.2986 - dense_1_loss_29: 0.3102 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0667 - dense_1_acc_2: 0.5000 - dense_1_acc_3: 0.6833 - dense_1_acc_4: 0.9167 - dense_1_acc_5: 0.9000 - dense_1_acc_6: 0.9833 - dense_1_acc_7: 0.9833 - dense_1_acc_8: 0.9833 - dense_1_acc_9: 0.9667 - dense_1_acc_10: 1.0000 - dense_1_acc_11: 1.0000 - dense_1_acc_12: 1.0000 - dense_1_acc_13: 1.0000 - dense_1_acc_14: 1.0000 - dense_1_acc_15: 1.0000 - dense_1_acc_16: 1.0000 - dense_1_acc_17: 0.9833 - dense_1_acc_18: 1.0000 - dense_1_acc_19: 1.0000 - dense_1_acc_20: 1.0000 - dense_1_acc_21: 1.0000 - dense_1_acc_22: 1.0000 - dense_1_acc_23: 1.0000 - dense_1_acc_24: 1.0000 - dense_1_acc_25: 1.0000 - dense_1_acc_26: 1.0000 - dense_1_acc_27: 1.0000 - dense_1_acc_28: 0.9833 - dense_1_acc_29: 0.9833 - dense_1_acc_30: 0.0167         
Epoch 45/100
60/60 [==============================] - 0s - loss: 15.0966 - dense_1_loss_1: 3.9521 - dense_1_loss_2: 2.2829 - dense_1_loss_3: 1.1870 - dense_1_loss_4: 0.6609 - dense_1_loss_5: 0.5719 - dense_1_loss_6: 0.3823 - dense_1_loss_7: 0.3505 - dense_1_loss_8: 0.2926 - dense_1_loss_9: 0.2795 - dense_1_loss_10: 0.2252 - dense_1_loss_11: 0.2600 - dense_1_loss_12: 0.2566 - dense_1_loss_13: 0.2292 - dense_1_loss_14: 0.2456 - dense_1_loss_15: 0.2787 - dense_1_loss_16: 0.2599 - dense_1_loss_17: 0.2682 - dense_1_loss_18: 0.2142 - dense_1_loss_19: 0.2556 - dense_1_loss_20: 0.2776 - dense_1_loss_21: 0.2678 - dense_1_loss_22: 0.2434 - dense_1_loss_23: 0.2575 - dense_1_loss_24: 0.2477 - dense_1_loss_25: 0.2691 - dense_1_loss_26: 0.2460 - dense_1_loss_27: 0.2672 - dense_1_loss_28: 0.2769 - dense_1_loss_29: 0.2903 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0667 - dense_1_acc_2: 0.5000 - dense_1_acc_3: 0.7167 - dense_1_acc_4: 0.9333 - dense_1_acc_5: 0.9500 - dense_1_acc_6: 0.9833 - dense_1_acc_7: 0.9833 - dense_1_acc_8: 0.9833 - dense_1_acc_9: 1.0000 - dense_1_acc_10: 1.0000 - dense_1_acc_11: 1.0000 - dense_1_acc_12: 1.0000 - dense_1_acc_13: 1.0000 - dense_1_acc_14: 1.0000 - dense_1_acc_15: 1.0000 - dense_1_acc_16: 1.0000 - dense_1_acc_17: 0.9833 - dense_1_acc_18: 1.0000 - dense_1_acc_19: 1.0000 - dense_1_acc_20: 1.0000 - dense_1_acc_21: 1.0000 - dense_1_acc_22: 1.0000 - dense_1_acc_23: 1.0000 - dense_1_acc_24: 1.0000 - dense_1_acc_25: 1.0000 - dense_1_acc_26: 1.0000 - dense_1_acc_27: 1.0000 - dense_1_acc_28: 0.9833 - dense_1_acc_29: 0.9833 - dense_1_acc_30: 0.0167     
Epoch 46/100
60/60 [==============================] - 0s - loss: 14.4415 - dense_1_loss_1: 3.9469 - dense_1_loss_2: 2.2393 - dense_1_loss_3: 1.1466 - dense_1_loss_4: 0.6163 - dense_1_loss_5: 0.5400 - dense_1_loss_6: 0.3608 - dense_1_loss_7: 0.3170 - dense_1_loss_8: 0.2675 - dense_1_loss_9: 0.2564 - dense_1_loss_10: 0.2062 - dense_1_loss_11: 0.2393 - dense_1_loss_12: 0.2362 - dense_1_loss_13: 0.2131 - dense_1_loss_14: 0.2291 - dense_1_loss_15: 0.2463 - dense_1_loss_16: 0.2406 - dense_1_loss_17: 0.2495 - dense_1_loss_18: 0.2008 - dense_1_loss_19: 0.2352 - dense_1_loss_20: 0.2495 - dense_1_loss_21: 0.2561 - dense_1_loss_22: 0.2334 - dense_1_loss_23: 0.2386 - dense_1_loss_24: 0.2228 - dense_1_loss_25: 0.2535 - dense_1_loss_26: 0.2380 - dense_1_loss_27: 0.2355 - dense_1_loss_28: 0.2616 - dense_1_loss_29: 0.2654 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0667 - dense_1_acc_2: 0.5000 - dense_1_acc_3: 0.7333 - dense_1_acc_4: 0.9333 - dense_1_acc_5: 0.9500 - dense_1_acc_6: 0.9833 - dense_1_acc_7: 0.9833 - dense_1_acc_8: 0.9833 - dense_1_acc_9: 1.0000 - dense_1_acc_10: 1.0000 - dense_1_acc_11: 1.0000 - dense_1_acc_12: 1.0000 - dense_1_acc_13: 1.0000 - dense_1_acc_14: 1.0000 - dense_1_acc_15: 1.0000 - dense_1_acc_16: 1.0000 - dense_1_acc_17: 1.0000 - dense_1_acc_18: 1.0000 - dense_1_acc_19: 1.0000 - dense_1_acc_20: 1.0000 - dense_1_acc_21: 1.0000 - dense_1_acc_22: 1.0000 - dense_1_acc_23: 1.0000 - dense_1_acc_24: 1.0000 - dense_1_acc_25: 1.0000 - dense_1_acc_26: 1.0000 - dense_1_acc_27: 1.0000 - dense_1_acc_28: 0.9833 - dense_1_acc_29: 0.9833 - dense_1_acc_30: 0.0167     
Epoch 47/100
60/60 [==============================] - 0s - loss: 13.8042 - dense_1_loss_1: 3.9426 - dense_1_loss_2: 2.1985 - dense_1_loss_3: 1.1114 - dense_1_loss_4: 0.5765 - dense_1_loss_5: 0.5034 - dense_1_loss_6: 0.3380 - dense_1_loss_7: 0.2956 - dense_1_loss_8: 0.2473 - dense_1_loss_9: 0.2407 - dense_1_loss_10: 0.1889 - dense_1_loss_11: 0.2238 - dense_1_loss_12: 0.2141 - dense_1_loss_13: 0.1913 - dense_1_loss_14: 0.2097 - dense_1_loss_15: 0.2276 - dense_1_loss_16: 0.2211 - dense_1_loss_17: 0.2303 - dense_1_loss_18: 0.1813 - dense_1_loss_19: 0.2143 - dense_1_loss_20: 0.2309 - dense_1_loss_21: 0.2308 - dense_1_loss_22: 0.2108 - dense_1_loss_23: 0.2129 - dense_1_loss_24: 0.2109 - dense_1_loss_25: 0.2261 - dense_1_loss_26: 0.2130 - dense_1_loss_27: 0.2210 - dense_1_loss_28: 0.2410 - dense_1_loss_29: 0.2504 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0667 - dense_1_acc_2: 0.5000 - dense_1_acc_3: 0.7333 - dense_1_acc_4: 0.9500 - dense_1_acc_5: 0.9500 - dense_1_acc_6: 0.9833 - dense_1_acc_7: 0.9833 - dense_1_acc_8: 0.9833 - dense_1_acc_9: 1.0000 - dense_1_acc_10: 1.0000 - dense_1_acc_11: 1.0000 - dense_1_acc_12: 1.0000 - dense_1_acc_13: 1.0000 - dense_1_acc_14: 1.0000 - dense_1_acc_15: 1.0000 - dense_1_acc_16: 1.0000 - dense_1_acc_17: 1.0000 - dense_1_acc_18: 1.0000 - dense_1_acc_19: 1.0000 - dense_1_acc_20: 1.0000 - dense_1_acc_21: 1.0000 - dense_1_acc_22: 1.0000 - dense_1_acc_23: 1.0000 - dense_1_acc_24: 1.0000 - dense_1_acc_25: 1.0000 - dense_1_acc_26: 1.0000 - dense_1_acc_27: 1.0000 - dense_1_acc_28: 0.9833 - dense_1_acc_29: 0.9833 - dense_1_acc_30: 0.0167         
Epoch 48/100
60/60 [==============================] - 0s - loss: 13.2551 - dense_1_loss_1: 3.9382 - dense_1_loss_2: 2.1591 - dense_1_loss_3: 1.0758 - dense_1_loss_4: 0.5406 - dense_1_loss_5: 0.4749 - dense_1_loss_6: 0.3168 - dense_1_loss_7: 0.2752 - dense_1_loss_8: 0.2297 - dense_1_loss_9: 0.2259 - dense_1_loss_10: 0.1751 - dense_1_loss_11: 0.2064 - dense_1_loss_12: 0.2001 - dense_1_loss_13: 0.1779 - dense_1_loss_14: 0.1882 - dense_1_loss_15: 0.2160 - dense_1_loss_16: 0.2082 - dense_1_loss_17: 0.2112 - dense_1_loss_18: 0.1662 - dense_1_loss_19: 0.1949 - dense_1_loss_20: 0.2142 - dense_1_loss_21: 0.2100 - dense_1_loss_22: 0.1974 - dense_1_loss_23: 0.1975 - dense_1_loss_24: 0.1934 - dense_1_loss_25: 0.2136 - dense_1_loss_26: 0.1893 - dense_1_loss_27: 0.2061 - dense_1_loss_28: 0.2245 - dense_1_loss_29: 0.2288 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0667 - dense_1_acc_2: 0.5000 - dense_1_acc_3: 0.7333 - dense_1_acc_4: 0.9500 - dense_1_acc_5: 0.9667 - dense_1_acc_6: 0.9833 - dense_1_acc_7: 0.9833 - dense_1_acc_8: 1.0000 - dense_1_acc_9: 1.0000 - dense_1_acc_10: 1.0000 - dense_1_acc_11: 1.0000 - dense_1_acc_12: 1.0000 - dense_1_acc_13: 1.0000 - dense_1_acc_14: 1.0000 - dense_1_acc_15: 1.0000 - dense_1_acc_16: 1.0000 - dense_1_acc_17: 1.0000 - dense_1_acc_18: 1.0000 - dense_1_acc_19: 1.0000 - dense_1_acc_20: 1.0000 - dense_1_acc_21: 1.0000 - dense_1_acc_22: 1.0000 - dense_1_acc_23: 1.0000 - dense_1_acc_24: 1.0000 - dense_1_acc_25: 1.0000 - dense_1_acc_26: 1.0000 - dense_1_acc_27: 1.0000 - dense_1_acc_28: 0.9833 - dense_1_acc_29: 0.9833 - dense_1_acc_30: 0.0167         
Epoch 49/100
60/60 [==============================] - 0s - loss: 12.7389 - dense_1_loss_1: 3.9340 - dense_1_loss_2: 2.1200 - dense_1_loss_3: 1.0392 - dense_1_loss_4: 0.5080 - dense_1_loss_5: 0.4463 - dense_1_loss_6: 0.2969 - dense_1_loss_7: 0.2535 - dense_1_loss_8: 0.2126 - dense_1_loss_9: 0.2075 - dense_1_loss_10: 0.1634 - dense_1_loss_11: 0.1899 - dense_1_loss_12: 0.1864 - dense_1_loss_13: 0.1674 - dense_1_loss_14: 0.1747 - dense_1_loss_15: 0.1961 - dense_1_loss_16: 0.1925 - dense_1_loss_17: 0.1939 - dense_1_loss_18: 0.1562 - dense_1_loss_19: 0.1830 - dense_1_loss_20: 0.1961 - dense_1_loss_21: 0.1974 - dense_1_loss_22: 0.1808 - dense_1_loss_23: 0.1833 - dense_1_loss_24: 0.1742 - dense_1_loss_25: 0.1975 - dense_1_loss_26: 0.1805 - dense_1_loss_27: 0.1909 - dense_1_loss_28: 0.2049 - dense_1_loss_29: 0.2117 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0667 - dense_1_acc_2: 0.5000 - dense_1_acc_3: 0.7333 - dense_1_acc_4: 0.9500 - dense_1_acc_5: 0.9667 - dense_1_acc_6: 0.9833 - dense_1_acc_7: 0.9833 - dense_1_acc_8: 1.0000 - dense_1_acc_9: 1.0000 - dense_1_acc_10: 1.0000 - dense_1_acc_11: 1.0000 - dense_1_acc_12: 1.0000 - dense_1_acc_13: 1.0000 - dense_1_acc_14: 1.0000 - dense_1_acc_15: 1.0000 - dense_1_acc_16: 1.0000 - dense_1_acc_17: 1.0000 - dense_1_acc_18: 1.0000 - dense_1_acc_19: 1.0000 - dense_1_acc_20: 1.0000 - dense_1_acc_21: 1.0000 - dense_1_acc_22: 1.0000 - dense_1_acc_23: 1.0000 - dense_1_acc_24: 1.0000 - dense_1_acc_25: 1.0000 - dense_1_acc_26: 1.0000 - dense_1_acc_27: 1.0000 - dense_1_acc_28: 0.9833 - dense_1_acc_29: 0.9833 - dense_1_acc_30: 0.0167     
Epoch 50/100
60/60 [==============================] - 0s - loss: 12.2619 - dense_1_loss_1: 3.9299 - dense_1_loss_2: 2.0816 - dense_1_loss_3: 1.0073 - dense_1_loss_4: 0.4701 - dense_1_loss_5: 0.4167 - dense_1_loss_6: 0.2819 - dense_1_loss_7: 0.2354 - dense_1_loss_8: 0.1969 - dense_1_loss_9: 0.1929 - dense_1_loss_10: 0.1491 - dense_1_loss_11: 0.1719 - dense_1_loss_12: 0.1685 - dense_1_loss_13: 0.1572 - dense_1_loss_14: 0.1576 - dense_1_loss_15: 0.1878 - dense_1_loss_16: 0.1731 - dense_1_loss_17: 0.1813 - dense_1_loss_18: 0.1438 - dense_1_loss_19: 0.1683 - dense_1_loss_20: 0.1829 - dense_1_loss_21: 0.1834 - dense_1_loss_22: 0.1663 - dense_1_loss_23: 0.1692 - dense_1_loss_24: 0.1645 - dense_1_loss_25: 0.1859 - dense_1_loss_26: 0.1627 - dense_1_loss_27: 0.1809 - dense_1_loss_28: 0.1893 - dense_1_loss_29: 0.2058 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0667 - dense_1_acc_2: 0.5000 - dense_1_acc_3: 0.7500 - dense_1_acc_4: 0.9500 - dense_1_acc_5: 0.9667 - dense_1_acc_6: 0.9833 - dense_1_acc_7: 0.9833 - dense_1_acc_8: 1.0000 - dense_1_acc_9: 1.0000 - dense_1_acc_10: 1.0000 - dense_1_acc_11: 1.0000 - dense_1_acc_12: 1.0000 - dense_1_acc_13: 1.0000 - dense_1_acc_14: 1.0000 - dense_1_acc_15: 1.0000 - dense_1_acc_16: 1.0000 - dense_1_acc_17: 1.0000 - dense_1_acc_18: 1.0000 - dense_1_acc_19: 1.0000 - dense_1_acc_20: 1.0000 - dense_1_acc_21: 1.0000 - dense_1_acc_22: 1.0000 - dense_1_acc_23: 1.0000 - dense_1_acc_24: 1.0000 - dense_1_acc_25: 1.0000 - dense_1_acc_26: 1.0000 - dense_1_acc_27: 1.0000 - dense_1_acc_28: 0.9833 - dense_1_acc_29: 0.9833 - dense_1_acc_30: 0.0167     
Epoch 51/100
60/60 [==============================] - 0s - loss: 11.8306 - dense_1_loss_1: 3.9258 - dense_1_loss_2: 2.0443 - dense_1_loss_3: 0.9769 - dense_1_loss_4: 0.4424 - dense_1_loss_5: 0.3919 - dense_1_loss_6: 0.2642 - dense_1_loss_7: 0.2194 - dense_1_loss_8: 0.1835 - dense_1_loss_9: 0.1806 - dense_1_loss_10: 0.1379 - dense_1_loss_11: 0.1622 - dense_1_loss_12: 0.1546 - dense_1_loss_13: 0.1450 - dense_1_loss_14: 0.1532 - dense_1_loss_15: 0.1712 - dense_1_loss_16: 0.1607 - dense_1_loss_17: 0.1635 - dense_1_loss_18: 0.1337 - dense_1_loss_19: 0.1561 - dense_1_loss_20: 0.1706 - dense_1_loss_21: 0.1664 - dense_1_loss_22: 0.1556 - dense_1_loss_23: 0.1569 - dense_1_loss_24: 0.1506 - dense_1_loss_25: 0.1684 - dense_1_loss_26: 0.1533 - dense_1_loss_27: 0.1697 - dense_1_loss_28: 0.1806 - dense_1_loss_29: 0.1915 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0667 - dense_1_acc_2: 0.5000 - dense_1_acc_3: 0.7500 - dense_1_acc_4: 0.9500 - dense_1_acc_5: 0.9667 - dense_1_acc_6: 0.9833 - dense_1_acc_7: 1.0000 - dense_1_acc_8: 1.0000 - dense_1_acc_9: 1.0000 - dense_1_acc_10: 1.0000 - dense_1_acc_11: 1.0000 - dense_1_acc_12: 1.0000 - dense_1_acc_13: 1.0000 - dense_1_acc_14: 1.0000 - dense_1_acc_15: 1.0000 - dense_1_acc_16: 1.0000 - dense_1_acc_17: 1.0000 - dense_1_acc_18: 1.0000 - dense_1_acc_19: 1.0000 - dense_1_acc_20: 1.0000 - dense_1_acc_21: 1.0000 - dense_1_acc_22: 1.0000 - dense_1_acc_23: 1.0000 - dense_1_acc_24: 1.0000 - dense_1_acc_25: 1.0000 - dense_1_acc_26: 1.0000 - dense_1_acc_27: 1.0000 - dense_1_acc_28: 0.9833 - dense_1_acc_29: 0.9833 - dense_1_acc_30: 0.0167     
Epoch 52/100
60/60 [==============================] - 0s - loss: 11.4249 - dense_1_loss_1: 3.9217 - dense_1_loss_2: 2.0096 - dense_1_loss_3: 0.9442 - dense_1_loss_4: 0.4178 - dense_1_loss_5: 0.3699 - dense_1_loss_6: 0.2497 - dense_1_loss_7: 0.2020 - dense_1_loss_8: 0.1708 - dense_1_loss_9: 0.1691 - dense_1_loss_10: 0.1297 - dense_1_loss_11: 0.1520 - dense_1_loss_12: 0.1469 - dense_1_loss_13: 0.1323 - dense_1_loss_14: 0.1468 - dense_1_loss_15: 0.1535 - dense_1_loss_16: 0.1533 - dense_1_loss_17: 0.1519 - dense_1_loss_18: 0.1254 - dense_1_loss_19: 0.1455 - dense_1_loss_20: 0.1564 - dense_1_loss_21: 0.1541 - dense_1_loss_22: 0.1462 - dense_1_loss_23: 0.1451 - dense_1_loss_24: 0.1390 - dense_1_loss_25: 0.1558 - dense_1_loss_26: 0.1420 - dense_1_loss_27: 0.1523 - dense_1_loss_28: 0.1696 - dense_1_loss_29: 0.1723 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0667 - dense_1_acc_2: 0.5167 - dense_1_acc_3: 0.7667 - dense_1_acc_4: 0.9500 - dense_1_acc_5: 0.9833 - dense_1_acc_6: 0.9833 - dense_1_acc_7: 1.0000 - dense_1_acc_8: 1.0000 - dense_1_acc_9: 1.0000 - dense_1_acc_10: 1.0000 - dense_1_acc_11: 1.0000 - dense_1_acc_12: 1.0000 - dense_1_acc_13: 1.0000 - dense_1_acc_14: 1.0000 - dense_1_acc_15: 1.0000 - dense_1_acc_16: 1.0000 - dense_1_acc_17: 1.0000 - dense_1_acc_18: 1.0000 - dense_1_acc_19: 1.0000 - dense_1_acc_20: 1.0000 - dense_1_acc_21: 1.0000 - dense_1_acc_22: 1.0000 - dense_1_acc_23: 1.0000 - dense_1_acc_24: 1.0000 - dense_1_acc_25: 1.0000 - dense_1_acc_26: 1.0000 - dense_1_acc_27: 1.0000 - dense_1_acc_28: 0.9833 - dense_1_acc_29: 0.9833 - dense_1_acc_30: 0.0167         
Epoch 53/100
60/60 [==============================] - 0s - loss: 11.0681 - dense_1_loss_1: 3.9173 - dense_1_loss_2: 1.9748 - dense_1_loss_3: 0.9147 - dense_1_loss_4: 0.3944 - dense_1_loss_5: 0.3488 - dense_1_loss_6: 0.2380 - dense_1_loss_7: 0.1887 - dense_1_loss_8: 0.1593 - dense_1_loss_9: 0.1591 - dense_1_loss_10: 0.1198 - dense_1_loss_11: 0.1403 - dense_1_loss_12: 0.1389 - dense_1_loss_13: 0.1218 - dense_1_loss_14: 0.1349 - dense_1_loss_15: 0.1438 - dense_1_loss_16: 0.1435 - dense_1_loss_17: 0.1429 - dense_1_loss_18: 0.1154 - dense_1_loss_19: 0.1367 - dense_1_loss_20: 0.1478 - dense_1_loss_21: 0.1434 - dense_1_loss_22: 0.1348 - dense_1_loss_23: 0.1339 - dense_1_loss_24: 0.1330 - dense_1_loss_25: 0.1440 - dense_1_loss_26: 0.1320 - dense_1_loss_27: 0.1463 - dense_1_loss_28: 0.1575 - dense_1_loss_29: 0.1623 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0667 - dense_1_acc_2: 0.5167 - dense_1_acc_3: 0.7833 - dense_1_acc_4: 0.9500 - dense_1_acc_5: 0.9833 - dense_1_acc_6: 0.9833 - dense_1_acc_7: 1.0000 - dense_1_acc_8: 1.0000 - dense_1_acc_9: 1.0000 - dense_1_acc_10: 1.0000 - dense_1_acc_11: 1.0000 - dense_1_acc_12: 1.0000 - dense_1_acc_13: 1.0000 - dense_1_acc_14: 1.0000 - dense_1_acc_15: 1.0000 - dense_1_acc_16: 1.0000 - dense_1_acc_17: 1.0000 - dense_1_acc_18: 1.0000 - dense_1_acc_19: 1.0000 - dense_1_acc_20: 1.0000 - dense_1_acc_21: 1.0000 - dense_1_acc_22: 1.0000 - dense_1_acc_23: 1.0000 - dense_1_acc_24: 1.0000 - dense_1_acc_25: 1.0000 - dense_1_acc_26: 1.0000 - dense_1_acc_27: 1.0000 - dense_1_acc_28: 0.9833 - dense_1_acc_29: 0.9833 - dense_1_acc_30: 0.0167     
Epoch 54/100
60/60 [==============================] - 0s - loss: 10.7364 - dense_1_loss_1: 3.9134 - dense_1_loss_2: 1.9412 - dense_1_loss_3: 0.8867 - dense_1_loss_4: 0.3716 - dense_1_loss_5: 0.3284 - dense_1_loss_6: 0.2234 - dense_1_loss_7: 0.1779 - dense_1_loss_8: 0.1499 - dense_1_loss_9: 0.1483 - dense_1_loss_10: 0.1121 - dense_1_loss_11: 0.1307 - dense_1_loss_12: 0.1282 - dense_1_loss_13: 0.1138 - dense_1_loss_14: 0.1231 - dense_1_loss_15: 0.1380 - dense_1_loss_16: 0.1302 - dense_1_loss_17: 0.1349 - dense_1_loss_18: 0.1069 - dense_1_loss_19: 0.1291 - dense_1_loss_20: 0.1394 - dense_1_loss_21: 0.1313 - dense_1_loss_22: 0.1239 - dense_1_loss_23: 0.1264 - dense_1_loss_24: 0.1265 - dense_1_loss_25: 0.1338 - dense_1_loss_26: 0.1199 - dense_1_loss_27: 0.1424 - dense_1_loss_28: 0.1489 - dense_1_loss_29: 0.1560 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0667 - dense_1_acc_2: 0.5167 - dense_1_acc_3: 0.7833 - dense_1_acc_4: 0.9500 - dense_1_acc_5: 0.9833 - dense_1_acc_6: 0.9833 - dense_1_acc_7: 1.0000 - dense_1_acc_8: 1.0000 - dense_1_acc_9: 1.0000 - dense_1_acc_10: 1.0000 - dense_1_acc_11: 1.0000 - dense_1_acc_12: 1.0000 - dense_1_acc_13: 1.0000 - dense_1_acc_14: 1.0000 - dense_1_acc_15: 1.0000 - dense_1_acc_16: 1.0000 - dense_1_acc_17: 1.0000 - dense_1_acc_18: 1.0000 - dense_1_acc_19: 1.0000 - dense_1_acc_20: 1.0000 - dense_1_acc_21: 1.0000 - dense_1_acc_22: 1.0000 - dense_1_acc_23: 1.0000 - dense_1_acc_24: 1.0000 - dense_1_acc_25: 1.0000 - dense_1_acc_26: 1.0000 - dense_1_acc_27: 1.0000 - dense_1_acc_28: 0.9833 - dense_1_acc_29: 0.9833 - dense_1_acc_30: 0.0167         
Epoch 55/100
60/60 [==============================] - 0s - loss: 10.4277 - dense_1_loss_1: 3.9094 - dense_1_loss_2: 1.9075 - dense_1_loss_3: 0.8594 - dense_1_loss_4: 0.3515 - dense_1_loss_5: 0.3123 - dense_1_loss_6: 0.2099 - dense_1_loss_7: 0.1676 - dense_1_loss_8: 0.1407 - dense_1_loss_9: 0.1386 - dense_1_loss_10: 0.1074 - dense_1_loss_11: 0.1220 - dense_1_loss_12: 0.1198 - dense_1_loss_13: 0.1072 - dense_1_loss_14: 0.1162 - dense_1_loss_15: 0.1281 - dense_1_loss_16: 0.1212 - dense_1_loss_17: 0.1273 - dense_1_loss_18: 0.1009 - dense_1_loss_19: 0.1205 - dense_1_loss_20: 0.1304 - dense_1_loss_21: 0.1238 - dense_1_loss_22: 0.1166 - dense_1_loss_23: 0.1192 - dense_1_loss_24: 0.1165 - dense_1_loss_25: 0.1258 - dense_1_loss_26: 0.1145 - dense_1_loss_27: 0.1298 - dense_1_loss_28: 0.1403 - dense_1_loss_29: 0.1436 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0667 - dense_1_acc_2: 0.5667 - dense_1_acc_3: 0.7833 - dense_1_acc_4: 0.9500 - dense_1_acc_5: 0.9833 - dense_1_acc_6: 0.9833 - dense_1_acc_7: 1.0000 - dense_1_acc_8: 1.0000 - dense_1_acc_9: 1.0000 - dense_1_acc_10: 1.0000 - dense_1_acc_11: 1.0000 - dense_1_acc_12: 1.0000 - dense_1_acc_13: 1.0000 - dense_1_acc_14: 1.0000 - dense_1_acc_15: 1.0000 - dense_1_acc_16: 1.0000 - dense_1_acc_17: 1.0000 - dense_1_acc_18: 1.0000 - dense_1_acc_19: 1.0000 - dense_1_acc_20: 1.0000 - dense_1_acc_21: 1.0000 - dense_1_acc_22: 1.0000 - dense_1_acc_23: 1.0000 - dense_1_acc_24: 1.0000 - dense_1_acc_25: 1.0000 - dense_1_acc_26: 1.0000 - dense_1_acc_27: 1.0000 - dense_1_acc_28: 0.9833 - dense_1_acc_29: 0.9833 - dense_1_acc_30: 0.0167         
Epoch 56/100
60/60 [==============================] - 0s - loss: 10.1418 - dense_1_loss_1: 3.9056 - dense_1_loss_2: 1.8775 - dense_1_loss_3: 0.8332 - dense_1_loss_4: 0.3309 - dense_1_loss_5: 0.2947 - dense_1_loss_6: 0.1990 - dense_1_loss_7: 0.1562 - dense_1_loss_8: 0.1312 - dense_1_loss_9: 0.1310 - dense_1_loss_10: 0.1010 - dense_1_loss_11: 0.1135 - dense_1_loss_12: 0.1142 - dense_1_loss_13: 0.1012 - dense_1_loss_14: 0.1093 - dense_1_loss_15: 0.1186 - dense_1_loss_16: 0.1140 - dense_1_loss_17: 0.1177 - dense_1_loss_18: 0.0952 - dense_1_loss_19: 0.1125 - dense_1_loss_20: 0.1201 - dense_1_loss_21: 0.1179 - dense_1_loss_22: 0.1130 - dense_1_loss_23: 0.1106 - dense_1_loss_24: 0.1071 - dense_1_loss_25: 0.1203 - dense_1_loss_26: 0.1104 - dense_1_loss_27: 0.1191 - dense_1_loss_28: 0.1298 - dense_1_loss_29: 0.1372 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0667 - dense_1_acc_2: 0.5833 - dense_1_acc_3: 0.8000 - dense_1_acc_4: 0.9833 - dense_1_acc_5: 0.9833 - dense_1_acc_6: 0.9833 - dense_1_acc_7: 1.0000 - dense_1_acc_8: 1.0000 - dense_1_acc_9: 1.0000 - dense_1_acc_10: 1.0000 - dense_1_acc_11: 1.0000 - dense_1_acc_12: 1.0000 - dense_1_acc_13: 1.0000 - dense_1_acc_14: 1.0000 - dense_1_acc_15: 1.0000 - dense_1_acc_16: 1.0000 - dense_1_acc_17: 1.0000 - dense_1_acc_18: 1.0000 - dense_1_acc_19: 1.0000 - dense_1_acc_20: 1.0000 - dense_1_acc_21: 1.0000 - dense_1_acc_22: 1.0000 - dense_1_acc_23: 1.0000 - dense_1_acc_24: 1.0000 - dense_1_acc_25: 1.0000 - dense_1_acc_26: 1.0000 - dense_1_acc_27: 1.0000 - dense_1_acc_28: 0.9833 - dense_1_acc_29: 0.9833 - dense_1_acc_30: 0.0167    
Epoch 57/100
60/60 [==============================] - 0s - loss: 9.8832 - dense_1_loss_1: 3.9016 - dense_1_loss_2: 1.8465 - dense_1_loss_3: 0.8103 - dense_1_loss_4: 0.3129 - dense_1_loss_5: 0.2809 - dense_1_loss_6: 0.1905 - dense_1_loss_7: 0.1477 - dense_1_loss_8: 0.1242 - dense_1_loss_9: 0.1236 - dense_1_loss_10: 0.0950 - dense_1_loss_11: 0.1073 - dense_1_loss_12: 0.1076 - dense_1_loss_13: 0.0953 - dense_1_loss_14: 0.1039 - dense_1_loss_15: 0.1106 - dense_1_loss_16: 0.1071 - dense_1_loss_17: 0.1093 - dense_1_loss_18: 0.0897 - dense_1_loss_19: 0.1057 - dense_1_loss_20: 0.1140 - dense_1_loss_21: 0.1091 - dense_1_loss_22: 0.1045 - dense_1_loss_23: 0.1041 - dense_1_loss_24: 0.1014 - dense_1_loss_25: 0.1108 - dense_1_loss_26: 0.1019 - dense_1_loss_27: 0.1148 - dense_1_loss_28: 0.1240 - dense_1_loss_29: 0.1291 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0667 - dense_1_acc_2: 0.6000 - dense_1_acc_3: 0.8333 - dense_1_acc_4: 0.9833 - dense_1_acc_5: 0.9833 - dense_1_acc_6: 0.9833 - dense_1_acc_7: 1.0000 - dense_1_acc_8: 1.0000 - dense_1_acc_9: 1.0000 - dense_1_acc_10: 1.0000 - dense_1_acc_11: 1.0000 - dense_1_acc_12: 1.0000 - dense_1_acc_13: 1.0000 - dense_1_acc_14: 1.0000 - dense_1_acc_15: 1.0000 - dense_1_acc_16: 1.0000 - dense_1_acc_17: 1.0000 - dense_1_acc_18: 1.0000 - dense_1_acc_19: 1.0000 - dense_1_acc_20: 1.0000 - dense_1_acc_21: 1.0000 - dense_1_acc_22: 1.0000 - dense_1_acc_23: 1.0000 - dense_1_acc_24: 1.0000 - dense_1_acc_25: 1.0000 - dense_1_acc_26: 1.0000 - dense_1_acc_27: 1.0000 - dense_1_acc_28: 0.9833 - dense_1_acc_29: 0.9833 - dense_1_acc_30: 0.0167      
Epoch 58/100
60/60 [==============================] - 0s - loss: 9.6445 - dense_1_loss_1: 3.8976 - dense_1_loss_2: 1.8172 - dense_1_loss_3: 0.7894 - dense_1_loss_4: 0.2966 - dense_1_loss_5: 0.2667 - dense_1_loss_6: 0.1804 - dense_1_loss_7: 0.1403 - dense_1_loss_8: 0.1177 - dense_1_loss_9: 0.1161 - dense_1_loss_10: 0.0905 - dense_1_loss_11: 0.1008 - dense_1_loss_12: 0.1007 - dense_1_loss_13: 0.0893 - dense_1_loss_14: 0.0985 - dense_1_loss_15: 0.1045 - dense_1_loss_16: 0.1002 - dense_1_loss_17: 0.1020 - dense_1_loss_18: 0.0855 - dense_1_loss_19: 0.0992 - dense_1_loss_20: 0.1080 - dense_1_loss_21: 0.1009 - dense_1_loss_22: 0.0970 - dense_1_loss_23: 0.0990 - dense_1_loss_24: 0.0969 - dense_1_loss_25: 0.1022 - dense_1_loss_26: 0.0945 - dense_1_loss_27: 0.1118 - dense_1_loss_28: 0.1205 - dense_1_loss_29: 0.1205 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0667 - dense_1_acc_2: 0.6000 - dense_1_acc_3: 0.8333 - dense_1_acc_4: 0.9833 - dense_1_acc_5: 0.9833 - dense_1_acc_6: 1.0000 - dense_1_acc_7: 1.0000 - dense_1_acc_8: 1.0000 - dense_1_acc_9: 1.0000 - dense_1_acc_10: 1.0000 - dense_1_acc_11: 1.0000 - dense_1_acc_12: 1.0000 - dense_1_acc_13: 1.0000 - dense_1_acc_14: 1.0000 - dense_1_acc_15: 1.0000 - dense_1_acc_16: 1.0000 - dense_1_acc_17: 1.0000 - dense_1_acc_18: 1.0000 - dense_1_acc_19: 1.0000 - dense_1_acc_20: 1.0000 - dense_1_acc_21: 1.0000 - dense_1_acc_22: 1.0000 - dense_1_acc_23: 1.0000 - dense_1_acc_24: 1.0000 - dense_1_acc_25: 1.0000 - dense_1_acc_26: 1.0000 - dense_1_acc_27: 1.0000 - dense_1_acc_28: 0.9833 - dense_1_acc_29: 0.9833 - dense_1_acc_30: 0.0167      
Epoch 59/100
60/60 [==============================] - 0s - loss: 9.4135 - dense_1_loss_1: 3.8939 - dense_1_loss_2: 1.7900 - dense_1_loss_3: 0.7652 - dense_1_loss_4: 0.2821 - dense_1_loss_5: 0.2533 - dense_1_loss_6: 0.1707 - dense_1_loss_7: 0.1317 - dense_1_loss_8: 0.1113 - dense_1_loss_9: 0.1101 - dense_1_loss_10: 0.0852 - dense_1_loss_11: 0.0954 - dense_1_loss_12: 0.0956 - dense_1_loss_13: 0.0837 - dense_1_loss_14: 0.0929 - dense_1_loss_15: 0.0989 - dense_1_loss_16: 0.0947 - dense_1_loss_17: 0.0964 - dense_1_loss_18: 0.0807 - dense_1_loss_19: 0.0934 - dense_1_loss_20: 0.1013 - dense_1_loss_21: 0.0947 - dense_1_loss_22: 0.0925 - dense_1_loss_23: 0.0925 - dense_1_loss_24: 0.0900 - dense_1_loss_25: 0.0977 - dense_1_loss_26: 0.0893 - dense_1_loss_27: 0.1041 - dense_1_loss_28: 0.1122 - dense_1_loss_29: 0.1142 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0667 - dense_1_acc_2: 0.6333 - dense_1_acc_3: 0.8333 - dense_1_acc_4: 0.9833 - dense_1_acc_5: 0.9833 - dense_1_acc_6: 1.0000 - dense_1_acc_7: 1.0000 - dense_1_acc_8: 1.0000 - dense_1_acc_9: 1.0000 - dense_1_acc_10: 1.0000 - dense_1_acc_11: 1.0000 - dense_1_acc_12: 1.0000 - dense_1_acc_13: 1.0000 - dense_1_acc_14: 1.0000 - dense_1_acc_15: 1.0000 - dense_1_acc_16: 1.0000 - dense_1_acc_17: 1.0000 - dense_1_acc_18: 1.0000 - dense_1_acc_19: 1.0000 - dense_1_acc_20: 1.0000 - dense_1_acc_21: 1.0000 - dense_1_acc_22: 1.0000 - dense_1_acc_23: 1.0000 - dense_1_acc_24: 1.0000 - dense_1_acc_25: 1.0000 - dense_1_acc_26: 1.0000 - dense_1_acc_27: 1.0000 - dense_1_acc_28: 0.9833 - dense_1_acc_29: 1.0000 - dense_1_acc_30: 0.0167     
Epoch 60/100
60/60 [==============================] - 0s - loss: 9.2122 - dense_1_loss_1: 3.8900 - dense_1_loss_2: 1.7621 - dense_1_loss_3: 0.7447 - dense_1_loss_4: 0.2695 - dense_1_loss_5: 0.2403 - dense_1_loss_6: 0.1627 - dense_1_loss_7: 0.1240 - dense_1_loss_8: 0.1052 - dense_1_loss_9: 0.1047 - dense_1_loss_10: 0.0806 - dense_1_loss_11: 0.0900 - dense_1_loss_12: 0.0913 - dense_1_loss_13: 0.0791 - dense_1_loss_14: 0.0879 - dense_1_loss_15: 0.0938 - dense_1_loss_16: 0.0902 - dense_1_loss_17: 0.0917 - dense_1_loss_18: 0.0768 - dense_1_loss_19: 0.0887 - dense_1_loss_20: 0.0955 - dense_1_loss_21: 0.0904 - dense_1_loss_22: 0.0887 - dense_1_loss_23: 0.0868 - dense_1_loss_24: 0.0846 - dense_1_loss_25: 0.0944 - dense_1_loss_26: 0.0857 - dense_1_loss_27: 0.0972 - dense_1_loss_28: 0.1058 - dense_1_loss_29: 0.1097 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0667 - dense_1_acc_2: 0.6333 - dense_1_acc_3: 0.8333 - dense_1_acc_4: 0.9833 - dense_1_acc_5: 0.9833 - dense_1_acc_6: 1.0000 - dense_1_acc_7: 1.0000 - dense_1_acc_8: 1.0000 - dense_1_acc_9: 1.0000 - dense_1_acc_10: 1.0000 - dense_1_acc_11: 1.0000 - dense_1_acc_12: 1.0000 - dense_1_acc_13: 1.0000 - dense_1_acc_14: 1.0000 - dense_1_acc_15: 1.0000 - dense_1_acc_16: 1.0000 - dense_1_acc_17: 1.0000 - dense_1_acc_18: 1.0000 - dense_1_acc_19: 1.0000 - dense_1_acc_20: 1.0000 - dense_1_acc_21: 1.0000 - dense_1_acc_22: 1.0000 - dense_1_acc_23: 1.0000 - dense_1_acc_24: 1.0000 - dense_1_acc_25: 1.0000 - dense_1_acc_26: 1.0000 - dense_1_acc_27: 1.0000 - dense_1_acc_28: 0.9833 - dense_1_acc_29: 0.9833 - dense_1_acc_30: 0.0167         
Epoch 61/100
60/60 [==============================] - 0s - loss: 9.0186 - dense_1_loss_1: 3.8861 - dense_1_loss_2: 1.7365 - dense_1_loss_3: 0.7251 - dense_1_loss_4: 0.2558 - dense_1_loss_5: 0.2299 - dense_1_loss_6: 0.1554 - dense_1_loss_7: 0.1185 - dense_1_loss_8: 0.0995 - dense_1_loss_9: 0.0995 - dense_1_loss_10: 0.0765 - dense_1_loss_11: 0.0845 - dense_1_loss_12: 0.0860 - dense_1_loss_13: 0.0755 - dense_1_loss_14: 0.0832 - dense_1_loss_15: 0.0884 - dense_1_loss_16: 0.0850 - dense_1_loss_17: 0.0868 - dense_1_loss_18: 0.0725 - dense_1_loss_19: 0.0843 - dense_1_loss_20: 0.0911 - dense_1_loss_21: 0.0854 - dense_1_loss_22: 0.0831 - dense_1_loss_23: 0.0830 - dense_1_loss_24: 0.0801 - dense_1_loss_25: 0.0889 - dense_1_loss_26: 0.0801 - dense_1_loss_27: 0.0940 - dense_1_loss_28: 0.1001 - dense_1_loss_29: 0.1038 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0667 - dense_1_acc_2: 0.6333 - dense_1_acc_3: 0.8333 - dense_1_acc_4: 0.9833 - dense_1_acc_5: 0.9833 - dense_1_acc_6: 1.0000 - dense_1_acc_7: 1.0000 - dense_1_acc_8: 1.0000 - dense_1_acc_9: 1.0000 - dense_1_acc_10: 1.0000 - dense_1_acc_11: 1.0000 - dense_1_acc_12: 1.0000 - dense_1_acc_13: 1.0000 - dense_1_acc_14: 1.0000 - dense_1_acc_15: 1.0000 - dense_1_acc_16: 1.0000 - dense_1_acc_17: 1.0000 - dense_1_acc_18: 1.0000 - dense_1_acc_19: 1.0000 - dense_1_acc_20: 1.0000 - dense_1_acc_21: 1.0000 - dense_1_acc_22: 1.0000 - dense_1_acc_23: 1.0000 - dense_1_acc_24: 1.0000 - dense_1_acc_25: 1.0000 - dense_1_acc_26: 1.0000 - dense_1_acc_27: 1.0000 - dense_1_acc_28: 1.0000 - dense_1_acc_29: 1.0000 - dense_1_acc_30: 0.0167     
Epoch 62/100
60/60 [==============================] - 0s - loss: 8.8454 - dense_1_loss_1: 3.8823 - dense_1_loss_2: 1.7105 - dense_1_loss_3: 0.7066 - dense_1_loss_4: 0.2445 - dense_1_loss_5: 0.2197 - dense_1_loss_6: 0.1483 - dense_1_loss_7: 0.1133 - dense_1_loss_8: 0.0944 - dense_1_loss_9: 0.0944 - dense_1_loss_10: 0.0729 - dense_1_loss_11: 0.0801 - dense_1_loss_12: 0.0817 - dense_1_loss_13: 0.0724 - dense_1_loss_14: 0.0793 - dense_1_loss_15: 0.0842 - dense_1_loss_16: 0.0801 - dense_1_loss_17: 0.0830 - dense_1_loss_18: 0.0691 - dense_1_loss_19: 0.0799 - dense_1_loss_20: 0.0872 - dense_1_loss_21: 0.0811 - dense_1_loss_22: 0.0783 - dense_1_loss_23: 0.0797 - dense_1_loss_24: 0.0768 - dense_1_loss_25: 0.0841 - dense_1_loss_26: 0.0751 - dense_1_loss_27: 0.0912 - dense_1_loss_28: 0.0962 - dense_1_loss_29: 0.0990 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0667 - dense_1_acc_2: 0.6333 - dense_1_acc_3: 0.8333 - dense_1_acc_4: 0.9833 - dense_1_acc_5: 0.9833 - dense_1_acc_6: 1.0000 - dense_1_acc_7: 1.0000 - dense_1_acc_8: 1.0000 - dense_1_acc_9: 1.0000 - dense_1_acc_10: 1.0000 - dense_1_acc_11: 1.0000 - dense_1_acc_12: 1.0000 - dense_1_acc_13: 1.0000 - dense_1_acc_14: 1.0000 - dense_1_acc_15: 1.0000 - dense_1_acc_16: 1.0000 - dense_1_acc_17: 1.0000 - dense_1_acc_18: 1.0000 - dense_1_acc_19: 1.0000 - dense_1_acc_20: 1.0000 - dense_1_acc_21: 1.0000 - dense_1_acc_22: 1.0000 - dense_1_acc_23: 1.0000 - dense_1_acc_24: 1.0000 - dense_1_acc_25: 1.0000 - dense_1_acc_26: 1.0000 - dense_1_acc_27: 1.0000 - dense_1_acc_28: 1.0000 - dense_1_acc_29: 1.0000 - dense_1_acc_30: 0.0167     
Epoch 63/100
60/60 [==============================] - 0s - loss: 8.6780 - dense_1_loss_1: 3.8786 - dense_1_loss_2: 1.6861 - dense_1_loss_3: 0.6890 - dense_1_loss_4: 0.2339 - dense_1_loss_5: 0.2098 - dense_1_loss_6: 0.1412 - dense_1_loss_7: 0.1084 - dense_1_loss_8: 0.0901 - dense_1_loss_9: 0.0898 - dense_1_loss_10: 0.0693 - dense_1_loss_11: 0.0763 - dense_1_loss_12: 0.0779 - dense_1_loss_13: 0.0687 - dense_1_loss_14: 0.0756 - dense_1_loss_15: 0.0798 - dense_1_loss_16: 0.0756 - dense_1_loss_17: 0.0788 - dense_1_loss_18: 0.0661 - dense_1_loss_19: 0.0752 - dense_1_loss_20: 0.0825 - dense_1_loss_21: 0.0772 - dense_1_loss_22: 0.0749 - dense_1_loss_23: 0.0751 - dense_1_loss_24: 0.0734 - dense_1_loss_25: 0.0796 - dense_1_loss_26: 0.0718 - dense_1_loss_27: 0.0871 - dense_1_loss_28: 0.0917 - dense_1_loss_29: 0.0948 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0667 - dense_1_acc_2: 0.6333 - dense_1_acc_3: 0.8333 - dense_1_acc_4: 0.9833 - dense_1_acc_5: 0.9833 - dense_1_acc_6: 1.0000 - dense_1_acc_7: 1.0000 - dense_1_acc_8: 1.0000 - dense_1_acc_9: 1.0000 - dense_1_acc_10: 1.0000 - dense_1_acc_11: 1.0000 - dense_1_acc_12: 1.0000 - dense_1_acc_13: 1.0000 - dense_1_acc_14: 1.0000 - dense_1_acc_15: 1.0000 - dense_1_acc_16: 1.0000 - dense_1_acc_17: 1.0000 - dense_1_acc_18: 1.0000 - dense_1_acc_19: 1.0000 - dense_1_acc_20: 1.0000 - dense_1_acc_21: 1.0000 - dense_1_acc_22: 1.0000 - dense_1_acc_23: 1.0000 - dense_1_acc_24: 1.0000 - dense_1_acc_25: 1.0000 - dense_1_acc_26: 1.0000 - dense_1_acc_27: 1.0000 - dense_1_acc_28: 1.0000 - dense_1_acc_29: 1.0000 - dense_1_acc_30: 0.0167         
Epoch 64/100
60/60 [==============================] - 0s - loss: 8.5208 - dense_1_loss_1: 3.8746 - dense_1_loss_2: 1.6631 - dense_1_loss_3: 0.6701 - dense_1_loss_4: 0.2242 - dense_1_loss_5: 0.1993 - dense_1_loss_6: 0.1340 - dense_1_loss_7: 0.1033 - dense_1_loss_8: 0.0858 - dense_1_loss_9: 0.0857 - dense_1_loss_10: 0.0664 - dense_1_loss_11: 0.0731 - dense_1_loss_12: 0.0750 - dense_1_loss_13: 0.0654 - dense_1_loss_14: 0.0730 - dense_1_loss_15: 0.0757 - dense_1_loss_16: 0.0722 - dense_1_loss_17: 0.0744 - dense_1_loss_18: 0.0635 - dense_1_loss_19: 0.0713 - dense_1_loss_20: 0.0780 - dense_1_loss_21: 0.0738 - dense_1_loss_22: 0.0726 - dense_1_loss_23: 0.0708 - dense_1_loss_24: 0.0695 - dense_1_loss_25: 0.0761 - dense_1_loss_26: 0.0695 - dense_1_loss_27: 0.0817 - dense_1_loss_28: 0.0869 - dense_1_loss_29: 0.0916 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0667 - dense_1_acc_2: 0.6333 - dense_1_acc_3: 0.8333 - dense_1_acc_4: 0.9833 - dense_1_acc_5: 0.9833 - dense_1_acc_6: 1.0000 - dense_1_acc_7: 1.0000 - dense_1_acc_8: 1.0000 - dense_1_acc_9: 1.0000 - dense_1_acc_10: 1.0000 - dense_1_acc_11: 1.0000 - dense_1_acc_12: 1.0000 - dense_1_acc_13: 1.0000 - dense_1_acc_14: 1.0000 - dense_1_acc_15: 1.0000 - dense_1_acc_16: 1.0000 - dense_1_acc_17: 1.0000 - dense_1_acc_18: 1.0000 - dense_1_acc_19: 1.0000 - dense_1_acc_20: 1.0000 - dense_1_acc_21: 1.0000 - dense_1_acc_22: 1.0000 - dense_1_acc_23: 1.0000 - dense_1_acc_24: 1.0000 - dense_1_acc_25: 1.0000 - dense_1_acc_26: 1.0000 - dense_1_acc_27: 1.0000 - dense_1_acc_28: 1.0000 - dense_1_acc_29: 1.0000 - dense_1_acc_30: 0.0167         
Epoch 65/100
60/60 [==============================] - 0s - loss: 8.3772 - dense_1_loss_1: 3.8711 - dense_1_loss_2: 1.6401 - dense_1_loss_3: 0.6538 - dense_1_loss_4: 0.2153 - dense_1_loss_5: 0.1913 - dense_1_loss_6: 0.1284 - dense_1_loss_7: 0.0986 - dense_1_loss_8: 0.0820 - dense_1_loss_9: 0.0822 - dense_1_loss_10: 0.0634 - dense_1_loss_11: 0.0701 - dense_1_loss_12: 0.0720 - dense_1_loss_13: 0.0624 - dense_1_loss_14: 0.0701 - dense_1_loss_15: 0.0727 - dense_1_loss_16: 0.0688 - dense_1_loss_17: 0.0710 - dense_1_loss_18: 0.0604 - dense_1_loss_19: 0.0684 - dense_1_loss_20: 0.0749 - dense_1_loss_21: 0.0698 - dense_1_loss_22: 0.0688 - dense_1_loss_23: 0.0680 - dense_1_loss_24: 0.0660 - dense_1_loss_25: 0.0727 - dense_1_loss_26: 0.0662 - dense_1_loss_27: 0.0776 - dense_1_loss_28: 0.0827 - dense_1_loss_29: 0.0882 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0667 - dense_1_acc_2: 0.6500 - dense_1_acc_3: 0.8333 - dense_1_acc_4: 0.9833 - dense_1_acc_5: 0.9833 - dense_1_acc_6: 1.0000 - dense_1_acc_7: 1.0000 - dense_1_acc_8: 1.0000 - dense_1_acc_9: 1.0000 - dense_1_acc_10: 1.0000 - dense_1_acc_11: 1.0000 - dense_1_acc_12: 1.0000 - dense_1_acc_13: 1.0000 - dense_1_acc_14: 1.0000 - dense_1_acc_15: 1.0000 - dense_1_acc_16: 1.0000 - dense_1_acc_17: 1.0000 - dense_1_acc_18: 1.0000 - dense_1_acc_19: 1.0000 - dense_1_acc_20: 1.0000 - dense_1_acc_21: 1.0000 - dense_1_acc_22: 1.0000 - dense_1_acc_23: 1.0000 - dense_1_acc_24: 1.0000 - dense_1_acc_25: 1.0000 - dense_1_acc_26: 1.0000 - dense_1_acc_27: 1.0000 - dense_1_acc_28: 1.0000 - dense_1_acc_29: 1.0000 - dense_1_acc_30: 0.0167     
Epoch 66/100
60/60 [==============================] - 0s - loss: 8.2381 - dense_1_loss_1: 3.8672 - dense_1_loss_2: 1.6179 - dense_1_loss_3: 0.6384 - dense_1_loss_4: 0.2065 - dense_1_loss_5: 0.1827 - dense_1_loss_6: 0.1230 - dense_1_loss_7: 0.0947 - dense_1_loss_8: 0.0786 - dense_1_loss_9: 0.0784 - dense_1_loss_10: 0.0606 - dense_1_loss_11: 0.0662 - dense_1_loss_12: 0.0689 - dense_1_loss_13: 0.0593 - dense_1_loss_14: 0.0667 - dense_1_loss_15: 0.0698 - dense_1_loss_16: 0.0657 - dense_1_loss_17: 0.0676 - dense_1_loss_18: 0.0574 - dense_1_loss_19: 0.0656 - dense_1_loss_20: 0.0722 - dense_1_loss_21: 0.0665 - dense_1_loss_22: 0.0649 - dense_1_loss_23: 0.0653 - dense_1_loss_24: 0.0634 - dense_1_loss_25: 0.0692 - dense_1_loss_26: 0.0627 - dense_1_loss_27: 0.0754 - dense_1_loss_28: 0.0796 - dense_1_loss_29: 0.0838 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0667 - dense_1_acc_2: 0.6667 - dense_1_acc_3: 0.8333 - dense_1_acc_4: 1.0000 - dense_1_acc_5: 0.9833 - dense_1_acc_6: 1.0000 - dense_1_acc_7: 1.0000 - dense_1_acc_8: 1.0000 - dense_1_acc_9: 1.0000 - dense_1_acc_10: 1.0000 - dense_1_acc_11: 1.0000 - dense_1_acc_12: 1.0000 - dense_1_acc_13: 1.0000 - dense_1_acc_14: 1.0000 - dense_1_acc_15: 1.0000 - dense_1_acc_16: 1.0000 - dense_1_acc_17: 1.0000 - dense_1_acc_18: 1.0000 - dense_1_acc_19: 1.0000 - dense_1_acc_20: 1.0000 - dense_1_acc_21: 1.0000 - dense_1_acc_22: 1.0000 - dense_1_acc_23: 1.0000 - dense_1_acc_24: 1.0000 - dense_1_acc_25: 1.0000 - dense_1_acc_26: 1.0000 - dense_1_acc_27: 1.0000 - dense_1_acc_28: 1.0000 - dense_1_acc_29: 1.0000 - dense_1_acc_30: 0.0167         
Epoch 67/100
60/60 [==============================] - 0s - loss: 8.1140 - dense_1_loss_1: 3.8635 - dense_1_loss_2: 1.5965 - dense_1_loss_3: 0.6240 - dense_1_loss_4: 0.1987 - dense_1_loss_5: 0.1762 - dense_1_loss_6: 0.1186 - dense_1_loss_7: 0.0913 - dense_1_loss_8: 0.0757 - dense_1_loss_9: 0.0751 - dense_1_loss_10: 0.0580 - dense_1_loss_11: 0.0632 - dense_1_loss_12: 0.0661 - dense_1_loss_13: 0.0568 - dense_1_loss_14: 0.0634 - dense_1_loss_15: 0.0668 - dense_1_loss_16: 0.0629 - dense_1_loss_17: 0.0646 - dense_1_loss_18: 0.0551 - dense_1_loss_19: 0.0628 - dense_1_loss_20: 0.0691 - dense_1_loss_21: 0.0635 - dense_1_loss_22: 0.0620 - dense_1_loss_23: 0.0625 - dense_1_loss_24: 0.0614 - dense_1_loss_25: 0.0659 - dense_1_loss_26: 0.0600 - dense_1_loss_27: 0.0732 - dense_1_loss_28: 0.0771 - dense_1_loss_29: 0.0801 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0667 - dense_1_acc_2: 0.6667 - dense_1_acc_3: 0.8333 - dense_1_acc_4: 1.0000 - dense_1_acc_5: 0.9833 - dense_1_acc_6: 1.0000 - dense_1_acc_7: 1.0000 - dense_1_acc_8: 1.0000 - dense_1_acc_9: 1.0000 - dense_1_acc_10: 1.0000 - dense_1_acc_11: 1.0000 - dense_1_acc_12: 1.0000 - dense_1_acc_13: 1.0000 - dense_1_acc_14: 1.0000 - dense_1_acc_15: 1.0000 - dense_1_acc_16: 1.0000 - dense_1_acc_17: 1.0000 - dense_1_acc_18: 1.0000 - dense_1_acc_19: 1.0000 - dense_1_acc_20: 1.0000 - dense_1_acc_21: 1.0000 - dense_1_acc_22: 1.0000 - dense_1_acc_23: 1.0000 - dense_1_acc_24: 1.0000 - dense_1_acc_25: 1.0000 - dense_1_acc_26: 1.0000 - dense_1_acc_27: 1.0000 - dense_1_acc_28: 1.0000 - dense_1_acc_29: 1.0000 - dense_1_acc_30: 0.0167         
Epoch 68/100
60/60 [==============================] - 0s - loss: 7.9936 - dense_1_loss_1: 3.8597 - dense_1_loss_2: 1.5757 - dense_1_loss_3: 0.6089 - dense_1_loss_4: 0.1913 - dense_1_loss_5: 0.1685 - dense_1_loss_6: 0.1137 - dense_1_loss_7: 0.0877 - dense_1_loss_8: 0.0725 - dense_1_loss_9: 0.0719 - dense_1_loss_10: 0.0559 - dense_1_loss_11: 0.0609 - dense_1_loss_12: 0.0633 - dense_1_loss_13: 0.0547 - dense_1_loss_14: 0.0609 - dense_1_loss_15: 0.0640 - dense_1_loss_16: 0.0603 - dense_1_loss_17: 0.0622 - dense_1_loss_18: 0.0530 - dense_1_loss_19: 0.0601 - dense_1_loss_20: 0.0660 - dense_1_loss_21: 0.0610 - dense_1_loss_22: 0.0600 - dense_1_loss_23: 0.0598 - dense_1_loss_24: 0.0590 - dense_1_loss_25: 0.0635 - dense_1_loss_26: 0.0576 - dense_1_loss_27: 0.0699 - dense_1_loss_28: 0.0740 - dense_1_loss_29: 0.0772 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0667 - dense_1_acc_2: 0.6667 - dense_1_acc_3: 0.8333 - dense_1_acc_4: 1.0000 - dense_1_acc_5: 0.9833 - dense_1_acc_6: 1.0000 - dense_1_acc_7: 1.0000 - dense_1_acc_8: 1.0000 - dense_1_acc_9: 1.0000 - dense_1_acc_10: 1.0000 - dense_1_acc_11: 1.0000 - dense_1_acc_12: 1.0000 - dense_1_acc_13: 1.0000 - dense_1_acc_14: 1.0000 - dense_1_acc_15: 1.0000 - dense_1_acc_16: 1.0000 - dense_1_acc_17: 1.0000 - dense_1_acc_18: 1.0000 - dense_1_acc_19: 1.0000 - dense_1_acc_20: 1.0000 - dense_1_acc_21: 1.0000 - dense_1_acc_22: 1.0000 - dense_1_acc_23: 1.0000 - dense_1_acc_24: 1.0000 - dense_1_acc_25: 1.0000 - dense_1_acc_26: 1.0000 - dense_1_acc_27: 1.0000 - dense_1_acc_28: 1.0000 - dense_1_acc_29: 1.0000 - dense_1_acc_30: 0.0167     
Epoch 69/100
60/60 [==============================] - 0s - loss: 7.8778 - dense_1_loss_1: 3.8562 - dense_1_loss_2: 1.5556 - dense_1_loss_3: 0.5951 - dense_1_loss_4: 0.1849 - dense_1_loss_5: 0.1612 - dense_1_loss_6: 0.1086 - dense_1_loss_7: 0.0846 - dense_1_loss_8: 0.0698 - dense_1_loss_9: 0.0689 - dense_1_loss_10: 0.0539 - dense_1_loss_11: 0.0584 - dense_1_loss_12: 0.0607 - dense_1_loss_13: 0.0526 - dense_1_loss_14: 0.0588 - dense_1_loss_15: 0.0612 - dense_1_loss_16: 0.0577 - dense_1_loss_17: 0.0596 - dense_1_loss_18: 0.0510 - dense_1_loss_19: 0.0573 - dense_1_loss_20: 0.0632 - dense_1_loss_21: 0.0587 - dense_1_loss_22: 0.0579 - dense_1_loss_23: 0.0571 - dense_1_loss_24: 0.0562 - dense_1_loss_25: 0.0612 - dense_1_loss_26: 0.0555 - dense_1_loss_27: 0.0668 - dense_1_loss_28: 0.0705 - dense_1_loss_29: 0.0748 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0667 - dense_1_acc_2: 0.6667 - dense_1_acc_3: 0.8333 - dense_1_acc_4: 1.0000 - dense_1_acc_5: 0.9833 - dense_1_acc_6: 1.0000 - dense_1_acc_7: 1.0000 - dense_1_acc_8: 1.0000 - dense_1_acc_9: 1.0000 - dense_1_acc_10: 1.0000 - dense_1_acc_11: 1.0000 - dense_1_acc_12: 1.0000 - dense_1_acc_13: 1.0000 - dense_1_acc_14: 1.0000 - dense_1_acc_15: 1.0000 - dense_1_acc_16: 1.0000 - dense_1_acc_17: 1.0000 - dense_1_acc_18: 1.0000 - dense_1_acc_19: 1.0000 - dense_1_acc_20: 1.0000 - dense_1_acc_21: 1.0000 - dense_1_acc_22: 1.0000 - dense_1_acc_23: 1.0000 - dense_1_acc_24: 1.0000 - dense_1_acc_25: 1.0000 - dense_1_acc_26: 1.0000 - dense_1_acc_27: 1.0000 - dense_1_acc_28: 1.0000 - dense_1_acc_29: 1.0000 - dense_1_acc_30: 0.0167         
Epoch 70/100
60/60 [==============================] - 0s - loss: 7.7708 - dense_1_loss_1: 3.8526 - dense_1_loss_2: 1.5356 - dense_1_loss_3: 0.5815 - dense_1_loss_4: 0.1788 - dense_1_loss_5: 0.1550 - dense_1_loss_6: 0.1043 - dense_1_loss_7: 0.0815 - dense_1_loss_8: 0.0672 - dense_1_loss_9: 0.0663 - dense_1_loss_10: 0.0517 - dense_1_loss_11: 0.0562 - dense_1_loss_12: 0.0586 - dense_1_loss_13: 0.0507 - dense_1_loss_14: 0.0568 - dense_1_loss_15: 0.0585 - dense_1_loss_16: 0.0554 - dense_1_loss_17: 0.0573 - dense_1_loss_18: 0.0489 - dense_1_loss_19: 0.0552 - dense_1_loss_20: 0.0610 - dense_1_loss_21: 0.0564 - dense_1_loss_22: 0.0557 - dense_1_loss_23: 0.0549 - dense_1_loss_24: 0.0537 - dense_1_loss_25: 0.0588 - dense_1_loss_26: 0.0536 - dense_1_loss_27: 0.0644 - dense_1_loss_28: 0.0678 - dense_1_loss_29: 0.0723 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0667 - dense_1_acc_2: 0.6667 - dense_1_acc_3: 0.8500 - dense_1_acc_4: 1.0000 - dense_1_acc_5: 0.9833 - dense_1_acc_6: 1.0000 - dense_1_acc_7: 1.0000 - dense_1_acc_8: 1.0000 - dense_1_acc_9: 1.0000 - dense_1_acc_10: 1.0000 - dense_1_acc_11: 1.0000 - dense_1_acc_12: 1.0000 - dense_1_acc_13: 1.0000 - dense_1_acc_14: 1.0000 - dense_1_acc_15: 1.0000 - dense_1_acc_16: 1.0000 - dense_1_acc_17: 1.0000 - dense_1_acc_18: 1.0000 - dense_1_acc_19: 1.0000 - dense_1_acc_20: 1.0000 - dense_1_acc_21: 1.0000 - dense_1_acc_22: 1.0000 - dense_1_acc_23: 1.0000 - dense_1_acc_24: 1.0000 - dense_1_acc_25: 1.0000 - dense_1_acc_26: 1.0000 - dense_1_acc_27: 1.0000 - dense_1_acc_28: 1.0000 - dense_1_acc_29: 1.0000 - dense_1_acc_30: 0.0167     
Epoch 71/100
60/60 [==============================] - 0s - loss: 7.6692 - dense_1_loss_1: 3.8490 - dense_1_loss_2: 1.5173 - dense_1_loss_3: 0.5687 - dense_1_loss_4: 0.1723 - dense_1_loss_5: 0.1489 - dense_1_loss_6: 0.1006 - dense_1_loss_7: 0.0787 - dense_1_loss_8: 0.0647 - dense_1_loss_9: 0.0639 - dense_1_loss_10: 0.0499 - dense_1_loss_11: 0.0540 - dense_1_loss_12: 0.0567 - dense_1_loss_13: 0.0487 - dense_1_loss_14: 0.0549 - dense_1_loss_15: 0.0563 - dense_1_loss_16: 0.0534 - dense_1_loss_17: 0.0552 - dense_1_loss_18: 0.0470 - dense_1_loss_19: 0.0530 - dense_1_loss_20: 0.0588 - dense_1_loss_21: 0.0543 - dense_1_loss_22: 0.0535 - dense_1_loss_23: 0.0527 - dense_1_loss_24: 0.0517 - dense_1_loss_25: 0.0563 - dense_1_loss_26: 0.0516 - dense_1_loss_27: 0.0625 - dense_1_loss_28: 0.0650 - dense_1_loss_29: 0.0696 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0667 - dense_1_acc_2: 0.6667 - dense_1_acc_3: 0.8667 - dense_1_acc_4: 1.0000 - dense_1_acc_5: 0.9833 - dense_1_acc_6: 1.0000 - dense_1_acc_7: 1.0000 - dense_1_acc_8: 1.0000 - dense_1_acc_9: 1.0000 - dense_1_acc_10: 1.0000 - dense_1_acc_11: 1.0000 - dense_1_acc_12: 1.0000 - dense_1_acc_13: 1.0000 - dense_1_acc_14: 1.0000 - dense_1_acc_15: 1.0000 - dense_1_acc_16: 1.0000 - dense_1_acc_17: 1.0000 - dense_1_acc_18: 1.0000 - dense_1_acc_19: 1.0000 - dense_1_acc_20: 1.0000 - dense_1_acc_21: 1.0000 - dense_1_acc_22: 1.0000 - dense_1_acc_23: 1.0000 - dense_1_acc_24: 1.0000 - dense_1_acc_25: 1.0000 - dense_1_acc_26: 1.0000 - dense_1_acc_27: 1.0000 - dense_1_acc_28: 1.0000 - dense_1_acc_29: 1.0000 - dense_1_acc_30: 0.0167         
Epoch 72/100
60/60 [==============================] - 0s - loss: 7.5726 - dense_1_loss_1: 3.8456 - dense_1_loss_2: 1.4986 - dense_1_loss_3: 0.5563 - dense_1_loss_4: 0.1672 - dense_1_loss_5: 0.1430 - dense_1_loss_6: 0.0973 - dense_1_loss_7: 0.0760 - dense_1_loss_8: 0.0624 - dense_1_loss_9: 0.0617 - dense_1_loss_10: 0.0480 - dense_1_loss_11: 0.0519 - dense_1_loss_12: 0.0546 - dense_1_loss_13: 0.0471 - dense_1_loss_14: 0.0527 - dense_1_loss_15: 0.0542 - dense_1_loss_16: 0.0514 - dense_1_loss_17: 0.0533 - dense_1_loss_18: 0.0453 - dense_1_loss_19: 0.0511 - dense_1_loss_20: 0.0568 - dense_1_loss_21: 0.0522 - dense_1_loss_22: 0.0515 - dense_1_loss_23: 0.0509 - dense_1_loss_24: 0.0500 - dense_1_loss_25: 0.0540 - dense_1_loss_26: 0.0497 - dense_1_loss_27: 0.0604 - dense_1_loss_28: 0.0627 - dense_1_loss_29: 0.0666 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0667 - dense_1_acc_2: 0.6667 - dense_1_acc_3: 0.8667 - dense_1_acc_4: 1.0000 - dense_1_acc_5: 0.9833 - dense_1_acc_6: 1.0000 - dense_1_acc_7: 1.0000 - dense_1_acc_8: 1.0000 - dense_1_acc_9: 1.0000 - dense_1_acc_10: 1.0000 - dense_1_acc_11: 1.0000 - dense_1_acc_12: 1.0000 - dense_1_acc_13: 1.0000 - dense_1_acc_14: 1.0000 - dense_1_acc_15: 1.0000 - dense_1_acc_16: 1.0000 - dense_1_acc_17: 1.0000 - dense_1_acc_18: 1.0000 - dense_1_acc_19: 1.0000 - dense_1_acc_20: 1.0000 - dense_1_acc_21: 1.0000 - dense_1_acc_22: 1.0000 - dense_1_acc_23: 1.0000 - dense_1_acc_24: 1.0000 - dense_1_acc_25: 1.0000 - dense_1_acc_26: 1.0000 - dense_1_acc_27: 1.0000 - dense_1_acc_28: 1.0000 - dense_1_acc_29: 1.0000 - dense_1_acc_30: 0.0167     
Epoch 73/100
60/60 [==============================] - 0s - loss: 7.4828 - dense_1_loss_1: 3.8418 - dense_1_loss_2: 1.4815 - dense_1_loss_3: 0.5448 - dense_1_loss_4: 0.1619 - dense_1_loss_5: 0.1380 - dense_1_loss_6: 0.0940 - dense_1_loss_7: 0.0736 - dense_1_loss_8: 0.0603 - dense_1_loss_9: 0.0595 - dense_1_loss_10: 0.0463 - dense_1_loss_11: 0.0500 - dense_1_loss_12: 0.0528 - dense_1_loss_13: 0.0454 - dense_1_loss_14: 0.0508 - dense_1_loss_15: 0.0524 - dense_1_loss_16: 0.0494 - dense_1_loss_17: 0.0515 - dense_1_loss_18: 0.0439 - dense_1_loss_19: 0.0492 - dense_1_loss_20: 0.0547 - dense_1_loss_21: 0.0502 - dense_1_loss_22: 0.0497 - dense_1_loss_23: 0.0491 - dense_1_loss_24: 0.0484 - dense_1_loss_25: 0.0522 - dense_1_loss_26: 0.0479 - dense_1_loss_27: 0.0583 - dense_1_loss_28: 0.0606 - dense_1_loss_29: 0.0643 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0667 - dense_1_acc_2: 0.6667 - dense_1_acc_3: 0.8667 - dense_1_acc_4: 1.0000 - dense_1_acc_5: 0.9833 - dense_1_acc_6: 1.0000 - dense_1_acc_7: 1.0000 - dense_1_acc_8: 1.0000 - dense_1_acc_9: 1.0000 - dense_1_acc_10: 1.0000 - dense_1_acc_11: 1.0000 - dense_1_acc_12: 1.0000 - dense_1_acc_13: 1.0000 - dense_1_acc_14: 1.0000 - dense_1_acc_15: 1.0000 - dense_1_acc_16: 1.0000 - dense_1_acc_17: 1.0000 - dense_1_acc_18: 1.0000 - dense_1_acc_19: 1.0000 - dense_1_acc_20: 1.0000 - dense_1_acc_21: 1.0000 - dense_1_acc_22: 1.0000 - dense_1_acc_23: 1.0000 - dense_1_acc_24: 1.0000 - dense_1_acc_25: 1.0000 - dense_1_acc_26: 1.0000 - dense_1_acc_27: 1.0000 - dense_1_acc_28: 1.0000 - dense_1_acc_29: 1.0000 - dense_1_acc_30: 0.0167         
Epoch 74/100
60/60 [==============================] - 0s - loss: 7.3939 - dense_1_loss_1: 3.8382 - dense_1_loss_2: 1.4647 - dense_1_loss_3: 0.5331 - dense_1_loss_4: 0.1567 - dense_1_loss_5: 0.1320 - dense_1_loss_6: 0.0903 - dense_1_loss_7: 0.0711 - dense_1_loss_8: 0.0582 - dense_1_loss_9: 0.0572 - dense_1_loss_10: 0.0449 - dense_1_loss_11: 0.0483 - dense_1_loss_12: 0.0508 - dense_1_loss_13: 0.0439 - dense_1_loss_14: 0.0490 - dense_1_loss_15: 0.0507 - dense_1_loss_16: 0.0477 - dense_1_loss_17: 0.0497 - dense_1_loss_18: 0.0425 - dense_1_loss_19: 0.0475 - dense_1_loss_20: 0.0527 - dense_1_loss_21: 0.0485 - dense_1_loss_22: 0.0480 - dense_1_loss_23: 0.0474 - dense_1_loss_24: 0.0468 - dense_1_loss_25: 0.0506 - dense_1_loss_26: 0.0465 - dense_1_loss_27: 0.0563 - dense_1_loss_28: 0.0583 - dense_1_loss_29: 0.0622 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0667 - dense_1_acc_2: 0.6667 - dense_1_acc_3: 0.8667 - dense_1_acc_4: 1.0000 - dense_1_acc_5: 0.9833 - dense_1_acc_6: 1.0000 - dense_1_acc_7: 1.0000 - dense_1_acc_8: 1.0000 - dense_1_acc_9: 1.0000 - dense_1_acc_10: 1.0000 - dense_1_acc_11: 1.0000 - dense_1_acc_12: 1.0000 - dense_1_acc_13: 1.0000 - dense_1_acc_14: 1.0000 - dense_1_acc_15: 1.0000 - dense_1_acc_16: 1.0000 - dense_1_acc_17: 1.0000 - dense_1_acc_18: 1.0000 - dense_1_acc_19: 1.0000 - dense_1_acc_20: 1.0000 - dense_1_acc_21: 1.0000 - dense_1_acc_22: 1.0000 - dense_1_acc_23: 1.0000 - dense_1_acc_24: 1.0000 - dense_1_acc_25: 1.0000 - dense_1_acc_26: 1.0000 - dense_1_acc_27: 1.0000 - dense_1_acc_28: 1.0000 - dense_1_acc_29: 1.0000 - dense_1_acc_30: 0.0167         
Epoch 75/100
60/60 [==============================] - 0s - loss: 7.3134 - dense_1_loss_1: 3.8351 - dense_1_loss_2: 1.4480 - dense_1_loss_3: 0.5218 - dense_1_loss_4: 0.1525 - dense_1_loss_5: 0.1272 - dense_1_loss_6: 0.0873 - dense_1_loss_7: 0.0688 - dense_1_loss_8: 0.0563 - dense_1_loss_9: 0.0553 - dense_1_loss_10: 0.0435 - dense_1_loss_11: 0.0467 - dense_1_loss_12: 0.0492 - dense_1_loss_13: 0.0425 - dense_1_loss_14: 0.0475 - dense_1_loss_15: 0.0491 - dense_1_loss_16: 0.0462 - dense_1_loss_17: 0.0481 - dense_1_loss_18: 0.0411 - dense_1_loss_19: 0.0461 - dense_1_loss_20: 0.0510 - dense_1_loss_21: 0.0470 - dense_1_loss_22: 0.0465 - dense_1_loss_23: 0.0459 - dense_1_loss_24: 0.0453 - dense_1_loss_25: 0.0489 - dense_1_loss_26: 0.0451 - dense_1_loss_27: 0.0546 - dense_1_loss_28: 0.0564 - dense_1_loss_29: 0.0607 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0667 - dense_1_acc_2: 0.6667 - dense_1_acc_3: 0.8667 - dense_1_acc_4: 1.0000 - dense_1_acc_5: 0.9833 - dense_1_acc_6: 1.0000 - dense_1_acc_7: 1.0000 - dense_1_acc_8: 1.0000 - dense_1_acc_9: 1.0000 - dense_1_acc_10: 1.0000 - dense_1_acc_11: 1.0000 - dense_1_acc_12: 1.0000 - dense_1_acc_13: 1.0000 - dense_1_acc_14: 1.0000 - dense_1_acc_15: 1.0000 - dense_1_acc_16: 1.0000 - dense_1_acc_17: 1.0000 - dense_1_acc_18: 1.0000 - dense_1_acc_19: 1.0000 - dense_1_acc_20: 1.0000 - dense_1_acc_21: 1.0000 - dense_1_acc_22: 1.0000 - dense_1_acc_23: 1.0000 - dense_1_acc_24: 1.0000 - dense_1_acc_25: 1.0000 - dense_1_acc_26: 1.0000 - dense_1_acc_27: 1.0000 - dense_1_acc_28: 1.0000 - dense_1_acc_29: 1.0000 - dense_1_acc_30: 0.0167     
Epoch 76/100
60/60 [==============================] - 0s - loss: 7.2336 - dense_1_loss_1: 3.8316 - dense_1_loss_2: 1.4320 - dense_1_loss_3: 0.5102 - dense_1_loss_4: 0.1483 - dense_1_loss_5: 0.1226 - dense_1_loss_6: 0.0845 - dense_1_loss_7: 0.0665 - dense_1_loss_8: 0.0545 - dense_1_loss_9: 0.0536 - dense_1_loss_10: 0.0422 - dense_1_loss_11: 0.0451 - dense_1_loss_12: 0.0477 - dense_1_loss_13: 0.0411 - dense_1_loss_14: 0.0461 - dense_1_loss_15: 0.0475 - dense_1_loss_16: 0.0447 - dense_1_loss_17: 0.0464 - dense_1_loss_18: 0.0397 - dense_1_loss_19: 0.0446 - dense_1_loss_20: 0.0494 - dense_1_loss_21: 0.0455 - dense_1_loss_22: 0.0449 - dense_1_loss_23: 0.0445 - dense_1_loss_24: 0.0436 - dense_1_loss_25: 0.0474 - dense_1_loss_26: 0.0436 - dense_1_loss_27: 0.0528 - dense_1_loss_28: 0.0543 - dense_1_loss_29: 0.0588 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0667 - dense_1_acc_2: 0.6667 - dense_1_acc_3: 0.8667 - dense_1_acc_4: 1.0000 - dense_1_acc_5: 0.9833 - dense_1_acc_6: 1.0000 - dense_1_acc_7: 1.0000 - dense_1_acc_8: 1.0000 - dense_1_acc_9: 1.0000 - dense_1_acc_10: 1.0000 - dense_1_acc_11: 1.0000 - dense_1_acc_12: 1.0000 - dense_1_acc_13: 1.0000 - dense_1_acc_14: 1.0000 - dense_1_acc_15: 1.0000 - dense_1_acc_16: 1.0000 - dense_1_acc_17: 1.0000 - dense_1_acc_18: 1.0000 - dense_1_acc_19: 1.0000 - dense_1_acc_20: 1.0000 - dense_1_acc_21: 1.0000 - dense_1_acc_22: 1.0000 - dense_1_acc_23: 1.0000 - dense_1_acc_24: 1.0000 - dense_1_acc_25: 1.0000 - dense_1_acc_26: 1.0000 - dense_1_acc_27: 1.0000 - dense_1_acc_28: 1.0000 - dense_1_acc_29: 1.0000 - dense_1_acc_30: 0.0167     
Epoch 77/100
60/60 [==============================] - 0s - loss: 7.1616 - dense_1_loss_1: 3.8284 - dense_1_loss_2: 1.4166 - dense_1_loss_3: 0.5003 - dense_1_loss_4: 0.1444 - dense_1_loss_5: 0.1190 - dense_1_loss_6: 0.0820 - dense_1_loss_7: 0.0647 - dense_1_loss_8: 0.0529 - dense_1_loss_9: 0.0520 - dense_1_loss_10: 0.0410 - dense_1_loss_11: 0.0435 - dense_1_loss_12: 0.0464 - dense_1_loss_13: 0.0399 - dense_1_loss_14: 0.0446 - dense_1_loss_15: 0.0460 - dense_1_loss_16: 0.0434 - dense_1_loss_17: 0.0449 - dense_1_loss_18: 0.0385 - dense_1_loss_19: 0.0432 - dense_1_loss_20: 0.0480 - dense_1_loss_21: 0.0440 - dense_1_loss_22: 0.0434 - dense_1_loss_23: 0.0431 - dense_1_loss_24: 0.0424 - dense_1_loss_25: 0.0458 - dense_1_loss_26: 0.0424 - dense_1_loss_27: 0.0512 - dense_1_loss_28: 0.0526 - dense_1_loss_29: 0.0569 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0667 - dense_1_acc_2: 0.6667 - dense_1_acc_3: 0.8667 - dense_1_acc_4: 1.0000 - dense_1_acc_5: 0.9833 - dense_1_acc_6: 1.0000 - dense_1_acc_7: 1.0000 - dense_1_acc_8: 1.0000 - dense_1_acc_9: 1.0000 - dense_1_acc_10: 1.0000 - dense_1_acc_11: 1.0000 - dense_1_acc_12: 1.0000 - dense_1_acc_13: 1.0000 - dense_1_acc_14: 1.0000 - dense_1_acc_15: 1.0000 - dense_1_acc_16: 1.0000 - dense_1_acc_17: 1.0000 - dense_1_acc_18: 1.0000 - dense_1_acc_19: 1.0000 - dense_1_acc_20: 1.0000 - dense_1_acc_21: 1.0000 - dense_1_acc_22: 1.0000 - dense_1_acc_23: 1.0000 - dense_1_acc_24: 1.0000 - dense_1_acc_25: 1.0000 - dense_1_acc_26: 1.0000 - dense_1_acc_27: 1.0000 - dense_1_acc_28: 1.0000 - dense_1_acc_29: 1.0000 - dense_1_acc_30: 0.0167     
Epoch 78/100
60/60 [==============================] - 0s - loss: 7.0901 - dense_1_loss_1: 3.8249 - dense_1_loss_2: 1.4014 - dense_1_loss_3: 0.4909 - dense_1_loss_4: 0.1406 - dense_1_loss_5: 0.1150 - dense_1_loss_6: 0.0794 - dense_1_loss_7: 0.0628 - dense_1_loss_8: 0.0513 - dense_1_loss_9: 0.0504 - dense_1_loss_10: 0.0397 - dense_1_loss_11: 0.0420 - dense_1_loss_12: 0.0450 - dense_1_loss_13: 0.0387 - dense_1_loss_14: 0.0432 - dense_1_loss_15: 0.0443 - dense_1_loss_16: 0.0419 - dense_1_loss_17: 0.0436 - dense_1_loss_18: 0.0373 - dense_1_loss_19: 0.0418 - dense_1_loss_20: 0.0465 - dense_1_loss_21: 0.0426 - dense_1_loss_22: 0.0419 - dense_1_loss_23: 0.0419 - dense_1_loss_24: 0.0411 - dense_1_loss_25: 0.0443 - dense_1_loss_26: 0.0411 - dense_1_loss_27: 0.0498 - dense_1_loss_28: 0.0513 - dense_1_loss_29: 0.0552 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0667 - dense_1_acc_2: 0.6667 - dense_1_acc_3: 0.8667 - dense_1_acc_4: 1.0000 - dense_1_acc_5: 1.0000 - dense_1_acc_6: 1.0000 - dense_1_acc_7: 1.0000 - dense_1_acc_8: 1.0000 - dense_1_acc_9: 1.0000 - dense_1_acc_10: 1.0000 - dense_1_acc_11: 1.0000 - dense_1_acc_12: 1.0000 - dense_1_acc_13: 1.0000 - dense_1_acc_14: 1.0000 - dense_1_acc_15: 1.0000 - dense_1_acc_16: 1.0000 - dense_1_acc_17: 1.0000 - dense_1_acc_18: 1.0000 - dense_1_acc_19: 1.0000 - dense_1_acc_20: 1.0000 - dense_1_acc_21: 1.0000 - dense_1_acc_22: 1.0000 - dense_1_acc_23: 1.0000 - dense_1_acc_24: 1.0000 - dense_1_acc_25: 1.0000 - dense_1_acc_26: 1.0000 - dense_1_acc_27: 1.0000 - dense_1_acc_28: 1.0000 - dense_1_acc_29: 1.0000 - dense_1_acc_30: 0.0167         
Epoch 79/100
60/60 [==============================] - 0s - loss: 7.0188 - dense_1_loss_1: 3.8219 - dense_1_loss_2: 1.3867 - dense_1_loss_3: 0.4792 - dense_1_loss_4: 0.1368 - dense_1_loss_5: 0.1106 - dense_1_loss_6: 0.0770 - dense_1_loss_7: 0.0610 - dense_1_loss_8: 0.0497 - dense_1_loss_9: 0.0488 - dense_1_loss_10: 0.0386 - dense_1_loss_11: 0.0406 - dense_1_loss_12: 0.0437 - dense_1_loss_13: 0.0374 - dense_1_loss_14: 0.0418 - dense_1_loss_15: 0.0429 - dense_1_loss_16: 0.0407 - dense_1_loss_17: 0.0423 - dense_1_loss_18: 0.0362 - dense_1_loss_19: 0.0404 - dense_1_loss_20: 0.0451 - dense_1_loss_21: 0.0414 - dense_1_loss_22: 0.0406 - dense_1_loss_23: 0.0408 - dense_1_loss_24: 0.0400 - dense_1_loss_25: 0.0429 - dense_1_loss_26: 0.0399 - dense_1_loss_27: 0.0483 - dense_1_loss_28: 0.0498 - dense_1_loss_29: 0.0536 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0667 - dense_1_acc_2: 0.6667 - dense_1_acc_3: 0.8833 - dense_1_acc_4: 1.0000 - dense_1_acc_5: 1.0000 - dense_1_acc_6: 1.0000 - dense_1_acc_7: 1.0000 - dense_1_acc_8: 1.0000 - dense_1_acc_9: 1.0000 - dense_1_acc_10: 1.0000 - dense_1_acc_11: 1.0000 - dense_1_acc_12: 1.0000 - dense_1_acc_13: 1.0000 - dense_1_acc_14: 1.0000 - dense_1_acc_15: 1.0000 - dense_1_acc_16: 1.0000 - dense_1_acc_17: 1.0000 - dense_1_acc_18: 1.0000 - dense_1_acc_19: 1.0000 - dense_1_acc_20: 1.0000 - dense_1_acc_21: 1.0000 - dense_1_acc_22: 1.0000 - dense_1_acc_23: 1.0000 - dense_1_acc_24: 1.0000 - dense_1_acc_25: 1.0000 - dense_1_acc_26: 1.0000 - dense_1_acc_27: 1.0000 - dense_1_acc_28: 1.0000 - dense_1_acc_29: 1.0000 - dense_1_acc_30: 0.0167         
Epoch 80/100
60/60 [==============================] - 0s - loss: 6.9546 - dense_1_loss_1: 3.8185 - dense_1_loss_2: 1.3724 - dense_1_loss_3: 0.4708 - dense_1_loss_4: 0.1336 - dense_1_loss_5: 0.1074 - dense_1_loss_6: 0.0747 - dense_1_loss_7: 0.0593 - dense_1_loss_8: 0.0484 - dense_1_loss_9: 0.0475 - dense_1_loss_10: 0.0375 - dense_1_loss_11: 0.0394 - dense_1_loss_12: 0.0424 - dense_1_loss_13: 0.0363 - dense_1_loss_14: 0.0405 - dense_1_loss_15: 0.0416 - dense_1_loss_16: 0.0396 - dense_1_loss_17: 0.0411 - dense_1_loss_18: 0.0353 - dense_1_loss_19: 0.0391 - dense_1_loss_20: 0.0437 - dense_1_loss_21: 0.0402 - dense_1_loss_22: 0.0396 - dense_1_loss_23: 0.0395 - dense_1_loss_24: 0.0389 - dense_1_loss_25: 0.0419 - dense_1_loss_26: 0.0388 - dense_1_loss_27: 0.0465 - dense_1_loss_28: 0.0483 - dense_1_loss_29: 0.0518 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0667 - dense_1_acc_2: 0.6667 - dense_1_acc_3: 0.8833 - dense_1_acc_4: 1.0000 - dense_1_acc_5: 1.0000 - dense_1_acc_6: 1.0000 - dense_1_acc_7: 1.0000 - dense_1_acc_8: 1.0000 - dense_1_acc_9: 1.0000 - dense_1_acc_10: 1.0000 - dense_1_acc_11: 1.0000 - dense_1_acc_12: 1.0000 - dense_1_acc_13: 1.0000 - dense_1_acc_14: 1.0000 - dense_1_acc_15: 1.0000 - dense_1_acc_16: 1.0000 - dense_1_acc_17: 1.0000 - dense_1_acc_18: 1.0000 - dense_1_acc_19: 1.0000 - dense_1_acc_20: 1.0000 - dense_1_acc_21: 1.0000 - dense_1_acc_22: 1.0000 - dense_1_acc_23: 1.0000 - dense_1_acc_24: 1.0000 - dense_1_acc_25: 1.0000 - dense_1_acc_26: 1.0000 - dense_1_acc_27: 1.0000 - dense_1_acc_28: 1.0000 - dense_1_acc_29: 1.0000 - dense_1_acc_30: 0.0167         
Epoch 81/100
60/60 [==============================] - 0s - loss: 6.8913 - dense_1_loss_1: 3.8153 - dense_1_loss_2: 1.3583 - dense_1_loss_3: 0.4611 - dense_1_loss_4: 0.1306 - dense_1_loss_5: 0.1035 - dense_1_loss_6: 0.0726 - dense_1_loss_7: 0.0576 - dense_1_loss_8: 0.0471 - dense_1_loss_9: 0.0461 - dense_1_loss_10: 0.0365 - dense_1_loss_11: 0.0383 - dense_1_loss_12: 0.0412 - dense_1_loss_13: 0.0353 - dense_1_loss_14: 0.0394 - dense_1_loss_15: 0.0403 - dense_1_loss_16: 0.0384 - dense_1_loss_17: 0.0399 - dense_1_loss_18: 0.0343 - dense_1_loss_19: 0.0379 - dense_1_loss_20: 0.0425 - dense_1_loss_21: 0.0391 - dense_1_loss_22: 0.0386 - dense_1_loss_23: 0.0382 - dense_1_loss_24: 0.0378 - dense_1_loss_25: 0.0408 - dense_1_loss_26: 0.0377 - dense_1_loss_27: 0.0453 - dense_1_loss_28: 0.0470 - dense_1_loss_29: 0.0507 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0667 - dense_1_acc_2: 0.6667 - dense_1_acc_3: 0.8833 - dense_1_acc_4: 1.0000 - dense_1_acc_5: 1.0000 - dense_1_acc_6: 1.0000 - dense_1_acc_7: 1.0000 - dense_1_acc_8: 1.0000 - dense_1_acc_9: 1.0000 - dense_1_acc_10: 1.0000 - dense_1_acc_11: 1.0000 - dense_1_acc_12: 1.0000 - dense_1_acc_13: 1.0000 - dense_1_acc_14: 1.0000 - dense_1_acc_15: 1.0000 - dense_1_acc_16: 1.0000 - dense_1_acc_17: 1.0000 - dense_1_acc_18: 1.0000 - dense_1_acc_19: 1.0000 - dense_1_acc_20: 1.0000 - dense_1_acc_21: 1.0000 - dense_1_acc_22: 1.0000 - dense_1_acc_23: 1.0000 - dense_1_acc_24: 1.0000 - dense_1_acc_25: 1.0000 - dense_1_acc_26: 1.0000 - dense_1_acc_27: 1.0000 - dense_1_acc_28: 1.0000 - dense_1_acc_29: 1.0000 - dense_1_acc_30: 0.0167     
Epoch 82/100
60/60 [==============================] - 0s - loss: 6.8326 - dense_1_loss_1: 3.8121 - dense_1_loss_2: 1.3449 - dense_1_loss_3: 0.4525 - dense_1_loss_4: 0.1276 - dense_1_loss_5: 0.1007 - dense_1_loss_6: 0.0708 - dense_1_loss_7: 0.0561 - dense_1_loss_8: 0.0459 - dense_1_loss_9: 0.0449 - dense_1_loss_10: 0.0355 - dense_1_loss_11: 0.0372 - dense_1_loss_12: 0.0401 - dense_1_loss_13: 0.0343 - dense_1_loss_14: 0.0383 - dense_1_loss_15: 0.0394 - dense_1_loss_16: 0.0374 - dense_1_loss_17: 0.0388 - dense_1_loss_18: 0.0333 - dense_1_loss_19: 0.0369 - dense_1_loss_20: 0.0415 - dense_1_loss_21: 0.0380 - dense_1_loss_22: 0.0375 - dense_1_loss_23: 0.0370 - dense_1_loss_24: 0.0367 - dense_1_loss_25: 0.0395 - dense_1_loss_26: 0.0366 - dense_1_loss_27: 0.0444 - dense_1_loss_28: 0.0454 - dense_1_loss_29: 0.0495 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0667 - dense_1_acc_2: 0.6667 - dense_1_acc_3: 0.8833 - dense_1_acc_4: 1.0000 - dense_1_acc_5: 1.0000 - dense_1_acc_6: 1.0000 - dense_1_acc_7: 1.0000 - dense_1_acc_8: 1.0000 - dense_1_acc_9: 1.0000 - dense_1_acc_10: 1.0000 - dense_1_acc_11: 1.0000 - dense_1_acc_12: 1.0000 - dense_1_acc_13: 1.0000 - dense_1_acc_14: 1.0000 - dense_1_acc_15: 1.0000 - dense_1_acc_16: 1.0000 - dense_1_acc_17: 1.0000 - dense_1_acc_18: 1.0000 - dense_1_acc_19: 1.0000 - dense_1_acc_20: 1.0000 - dense_1_acc_21: 1.0000 - dense_1_acc_22: 1.0000 - dense_1_acc_23: 1.0000 - dense_1_acc_24: 1.0000 - dense_1_acc_25: 1.0000 - dense_1_acc_26: 1.0000 - dense_1_acc_27: 1.0000 - dense_1_acc_28: 1.0000 - dense_1_acc_29: 1.0000 - dense_1_acc_30: 0.0167         
Epoch 83/100
60/60 [==============================] - 0s - loss: 6.7723 - dense_1_loss_1: 3.8089 - dense_1_loss_2: 1.3310 - dense_1_loss_3: 0.4437 - dense_1_loss_4: 0.1244 - dense_1_loss_5: 0.0973 - dense_1_loss_6: 0.0687 - dense_1_loss_7: 0.0546 - dense_1_loss_8: 0.0446 - dense_1_loss_9: 0.0436 - dense_1_loss_10: 0.0345 - dense_1_loss_11: 0.0360 - dense_1_loss_12: 0.0390 - dense_1_loss_13: 0.0333 - dense_1_loss_14: 0.0373 - dense_1_loss_15: 0.0382 - dense_1_loss_16: 0.0363 - dense_1_loss_17: 0.0378 - dense_1_loss_18: 0.0323 - dense_1_loss_19: 0.0359 - dense_1_loss_20: 0.0405 - dense_1_loss_21: 0.0369 - dense_1_loss_22: 0.0364 - dense_1_loss_23: 0.0360 - dense_1_loss_24: 0.0357 - dense_1_loss_25: 0.0383 - dense_1_loss_26: 0.0356 - dense_1_loss_27: 0.0433 - dense_1_loss_28: 0.0441 - dense_1_loss_29: 0.0481 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0667 - dense_1_acc_2: 0.6667 - dense_1_acc_3: 0.8833 - dense_1_acc_4: 1.0000 - dense_1_acc_5: 1.0000 - dense_1_acc_6: 1.0000 - dense_1_acc_7: 1.0000 - dense_1_acc_8: 1.0000 - dense_1_acc_9: 1.0000 - dense_1_acc_10: 1.0000 - dense_1_acc_11: 1.0000 - dense_1_acc_12: 1.0000 - dense_1_acc_13: 1.0000 - dense_1_acc_14: 1.0000 - dense_1_acc_15: 1.0000 - dense_1_acc_16: 1.0000 - dense_1_acc_17: 1.0000 - dense_1_acc_18: 1.0000 - dense_1_acc_19: 1.0000 - dense_1_acc_20: 1.0000 - dense_1_acc_21: 1.0000 - dense_1_acc_22: 1.0000 - dense_1_acc_23: 1.0000 - dense_1_acc_24: 1.0000 - dense_1_acc_25: 1.0000 - dense_1_acc_26: 1.0000 - dense_1_acc_27: 1.0000 - dense_1_acc_28: 1.0000 - dense_1_acc_29: 1.0000 - dense_1_acc_30: 0.0167         
Epoch 84/100
60/60 [==============================] - 0s - loss: 6.7171 - dense_1_loss_1: 3.8058 - dense_1_loss_2: 1.3178 - dense_1_loss_3: 0.4352 - dense_1_loss_4: 0.1217 - dense_1_loss_5: 0.0946 - dense_1_loss_6: 0.0670 - dense_1_loss_7: 0.0533 - dense_1_loss_8: 0.0434 - dense_1_loss_9: 0.0424 - dense_1_loss_10: 0.0336 - dense_1_loss_11: 0.0351 - dense_1_loss_12: 0.0379 - dense_1_loss_13: 0.0324 - dense_1_loss_14: 0.0363 - dense_1_loss_15: 0.0371 - dense_1_loss_16: 0.0353 - dense_1_loss_17: 0.0368 - dense_1_loss_18: 0.0315 - dense_1_loss_19: 0.0350 - dense_1_loss_20: 0.0394 - dense_1_loss_21: 0.0359 - dense_1_loss_22: 0.0354 - dense_1_loss_23: 0.0351 - dense_1_loss_24: 0.0348 - dense_1_loss_25: 0.0373 - dense_1_loss_26: 0.0347 - dense_1_loss_27: 0.0421 - dense_1_loss_28: 0.0431 - dense_1_loss_29: 0.0469 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0667 - dense_1_acc_2: 0.6667 - dense_1_acc_3: 0.8833 - dense_1_acc_4: 1.0000 - dense_1_acc_5: 1.0000 - dense_1_acc_6: 1.0000 - dense_1_acc_7: 1.0000 - dense_1_acc_8: 1.0000 - dense_1_acc_9: 1.0000 - dense_1_acc_10: 1.0000 - dense_1_acc_11: 1.0000 - dense_1_acc_12: 1.0000 - dense_1_acc_13: 1.0000 - dense_1_acc_14: 1.0000 - dense_1_acc_15: 1.0000 - dense_1_acc_16: 1.0000 - dense_1_acc_17: 1.0000 - dense_1_acc_18: 1.0000 - dense_1_acc_19: 1.0000 - dense_1_acc_20: 1.0000 - dense_1_acc_21: 1.0000 - dense_1_acc_22: 1.0000 - dense_1_acc_23: 1.0000 - dense_1_acc_24: 1.0000 - dense_1_acc_25: 1.0000 - dense_1_acc_26: 1.0000 - dense_1_acc_27: 1.0000 - dense_1_acc_28: 1.0000 - dense_1_acc_29: 1.0000 - dense_1_acc_30: 0.0167         
Epoch 85/100
60/60 [==============================] - 0s - loss: 6.6634 - dense_1_loss_1: 3.8027 - dense_1_loss_2: 1.3057 - dense_1_loss_3: 0.4270 - dense_1_loss_4: 0.1189 - dense_1_loss_5: 0.0918 - dense_1_loss_6: 0.0652 - dense_1_loss_7: 0.0520 - dense_1_loss_8: 0.0422 - dense_1_loss_9: 0.0413 - dense_1_loss_10: 0.0328 - dense_1_loss_11: 0.0342 - dense_1_loss_12: 0.0369 - dense_1_loss_13: 0.0316 - dense_1_loss_14: 0.0353 - dense_1_loss_15: 0.0361 - dense_1_loss_16: 0.0344 - dense_1_loss_17: 0.0359 - dense_1_loss_18: 0.0308 - dense_1_loss_19: 0.0341 - dense_1_loss_20: 0.0382 - dense_1_loss_21: 0.0349 - dense_1_loss_22: 0.0346 - dense_1_loss_23: 0.0343 - dense_1_loss_24: 0.0339 - dense_1_loss_25: 0.0364 - dense_1_loss_26: 0.0338 - dense_1_loss_27: 0.0406 - dense_1_loss_28: 0.0422 - dense_1_loss_29: 0.0456 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0667 - dense_1_acc_2: 0.6667 - dense_1_acc_3: 0.8833 - dense_1_acc_4: 1.0000 - dense_1_acc_5: 1.0000 - dense_1_acc_6: 1.0000 - dense_1_acc_7: 1.0000 - dense_1_acc_8: 1.0000 - dense_1_acc_9: 1.0000 - dense_1_acc_10: 1.0000 - dense_1_acc_11: 1.0000 - dense_1_acc_12: 1.0000 - dense_1_acc_13: 1.0000 - dense_1_acc_14: 1.0000 - dense_1_acc_15: 1.0000 - dense_1_acc_16: 1.0000 - dense_1_acc_17: 1.0000 - dense_1_acc_18: 1.0000 - dense_1_acc_19: 1.0000 - dense_1_acc_20: 1.0000 - dense_1_acc_21: 1.0000 - dense_1_acc_22: 1.0000 - dense_1_acc_23: 1.0000 - dense_1_acc_24: 1.0000 - dense_1_acc_25: 1.0000 - dense_1_acc_26: 1.0000 - dense_1_acc_27: 1.0000 - dense_1_acc_28: 1.0000 - dense_1_acc_29: 1.0000 - dense_1_acc_30: 0.0167         
Epoch 86/100
60/60 [==============================] - 0s - loss: 6.6121 - dense_1_loss_1: 3.7999 - dense_1_loss_2: 1.2929 - dense_1_loss_3: 0.4192 - dense_1_loss_4: 0.1162 - dense_1_loss_5: 0.0893 - dense_1_loss_6: 0.0636 - dense_1_loss_7: 0.0508 - dense_1_loss_8: 0.0411 - dense_1_loss_9: 0.0402 - dense_1_loss_10: 0.0320 - dense_1_loss_11: 0.0334 - dense_1_loss_12: 0.0360 - dense_1_loss_13: 0.0308 - dense_1_loss_14: 0.0344 - dense_1_loss_15: 0.0352 - dense_1_loss_16: 0.0335 - dense_1_loss_17: 0.0350 - dense_1_loss_18: 0.0301 - dense_1_loss_19: 0.0332 - dense_1_loss_20: 0.0372 - dense_1_loss_21: 0.0341 - dense_1_loss_22: 0.0338 - dense_1_loss_23: 0.0335 - dense_1_loss_24: 0.0332 - dense_1_loss_25: 0.0356 - dense_1_loss_26: 0.0330 - dense_1_loss_27: 0.0396 - dense_1_loss_28: 0.0411 - dense_1_loss_29: 0.0444 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0667 - dense_1_acc_2: 0.6667 - dense_1_acc_3: 0.9000 - dense_1_acc_4: 1.0000 - dense_1_acc_5: 1.0000 - dense_1_acc_6: 1.0000 - dense_1_acc_7: 1.0000 - dense_1_acc_8: 1.0000 - dense_1_acc_9: 1.0000 - dense_1_acc_10: 1.0000 - dense_1_acc_11: 1.0000 - dense_1_acc_12: 1.0000 - dense_1_acc_13: 1.0000 - dense_1_acc_14: 1.0000 - dense_1_acc_15: 1.0000 - dense_1_acc_16: 1.0000 - dense_1_acc_17: 1.0000 - dense_1_acc_18: 1.0000 - dense_1_acc_19: 1.0000 - dense_1_acc_20: 1.0000 - dense_1_acc_21: 1.0000 - dense_1_acc_22: 1.0000 - dense_1_acc_23: 1.0000 - dense_1_acc_24: 1.0000 - dense_1_acc_25: 1.0000 - dense_1_acc_26: 1.0000 - dense_1_acc_27: 1.0000 - dense_1_acc_28: 1.0000 - dense_1_acc_29: 1.0000 - dense_1_acc_30: 0.0167     
Epoch 87/100
60/60 [==============================] - 0s - loss: 6.5639 - dense_1_loss_1: 3.7966 - dense_1_loss_2: 1.2814 - dense_1_loss_3: 0.4125 - dense_1_loss_4: 0.1138 - dense_1_loss_5: 0.0872 - dense_1_loss_6: 0.0620 - dense_1_loss_7: 0.0496 - dense_1_loss_8: 0.0402 - dense_1_loss_9: 0.0393 - dense_1_loss_10: 0.0312 - dense_1_loss_11: 0.0325 - dense_1_loss_12: 0.0351 - dense_1_loss_13: 0.0300 - dense_1_loss_14: 0.0334 - dense_1_loss_15: 0.0344 - dense_1_loss_16: 0.0327 - dense_1_loss_17: 0.0341 - dense_1_loss_18: 0.0294 - dense_1_loss_19: 0.0323 - dense_1_loss_20: 0.0362 - dense_1_loss_21: 0.0332 - dense_1_loss_22: 0.0329 - dense_1_loss_23: 0.0327 - dense_1_loss_24: 0.0324 - dense_1_loss_25: 0.0346 - dense_1_loss_26: 0.0323 - dense_1_loss_27: 0.0388 - dense_1_loss_28: 0.0397 - dense_1_loss_29: 0.0434 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0667 - dense_1_acc_2: 0.6667 - dense_1_acc_3: 0.9000 - dense_1_acc_4: 1.0000 - dense_1_acc_5: 1.0000 - dense_1_acc_6: 1.0000 - dense_1_acc_7: 1.0000 - dense_1_acc_8: 1.0000 - dense_1_acc_9: 1.0000 - dense_1_acc_10: 1.0000 - dense_1_acc_11: 1.0000 - dense_1_acc_12: 1.0000 - dense_1_acc_13: 1.0000 - dense_1_acc_14: 1.0000 - dense_1_acc_15: 1.0000 - dense_1_acc_16: 1.0000 - dense_1_acc_17: 1.0000 - dense_1_acc_18: 1.0000 - dense_1_acc_19: 1.0000 - dense_1_acc_20: 1.0000 - dense_1_acc_21: 1.0000 - dense_1_acc_22: 1.0000 - dense_1_acc_23: 1.0000 - dense_1_acc_24: 1.0000 - dense_1_acc_25: 1.0000 - dense_1_acc_26: 1.0000 - dense_1_acc_27: 1.0000 - dense_1_acc_28: 1.0000 - dense_1_acc_29: 1.0000 - dense_1_acc_30: 0.0167     
Epoch 88/100
60/60 [==============================] - 0s - loss: 6.5147 - dense_1_loss_1: 3.7935 - dense_1_loss_2: 1.2693 - dense_1_loss_3: 0.4044 - dense_1_loss_4: 0.1115 - dense_1_loss_5: 0.0849 - dense_1_loss_6: 0.0605 - dense_1_loss_7: 0.0484 - dense_1_loss_8: 0.0393 - dense_1_loss_9: 0.0383 - dense_1_loss_10: 0.0305 - dense_1_loss_11: 0.0317 - dense_1_loss_12: 0.0343 - dense_1_loss_13: 0.0293 - dense_1_loss_14: 0.0326 - dense_1_loss_15: 0.0335 - dense_1_loss_16: 0.0319 - dense_1_loss_17: 0.0332 - dense_1_loss_18: 0.0287 - dense_1_loss_19: 0.0315 - dense_1_loss_20: 0.0353 - dense_1_loss_21: 0.0324 - dense_1_loss_22: 0.0320 - dense_1_loss_23: 0.0319 - dense_1_loss_24: 0.0315 - dense_1_loss_25: 0.0337 - dense_1_loss_26: 0.0315 - dense_1_loss_27: 0.0380 - dense_1_loss_28: 0.0387 - dense_1_loss_29: 0.0424 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0667 - dense_1_acc_2: 0.6667 - dense_1_acc_3: 0.9000 - dense_1_acc_4: 1.0000 - dense_1_acc_5: 1.0000 - dense_1_acc_6: 1.0000 - dense_1_acc_7: 1.0000 - dense_1_acc_8: 1.0000 - dense_1_acc_9: 1.0000 - dense_1_acc_10: 1.0000 - dense_1_acc_11: 1.0000 - dense_1_acc_12: 1.0000 - dense_1_acc_13: 1.0000 - dense_1_acc_14: 1.0000 - dense_1_acc_15: 1.0000 - dense_1_acc_16: 1.0000 - dense_1_acc_17: 1.0000 - dense_1_acc_18: 1.0000 - dense_1_acc_19: 1.0000 - dense_1_acc_20: 1.0000 - dense_1_acc_21: 1.0000 - dense_1_acc_22: 1.0000 - dense_1_acc_23: 1.0000 - dense_1_acc_24: 1.0000 - dense_1_acc_25: 1.0000 - dense_1_acc_26: 1.0000 - dense_1_acc_27: 1.0000 - dense_1_acc_28: 1.0000 - dense_1_acc_29: 1.0000 - dense_1_acc_30: 0.0167         
Epoch 89/100
60/60 [==============================] - 0s - loss: 6.4671 - dense_1_loss_1: 3.7905 - dense_1_loss_2: 1.2575 - dense_1_loss_3: 0.3967 - dense_1_loss_4: 0.1090 - dense_1_loss_5: 0.0824 - dense_1_loss_6: 0.0589 - dense_1_loss_7: 0.0474 - dense_1_loss_8: 0.0383 - dense_1_loss_9: 0.0373 - dense_1_loss_10: 0.0298 - dense_1_loss_11: 0.0308 - dense_1_loss_12: 0.0335 - dense_1_loss_13: 0.0286 - dense_1_loss_14: 0.0317 - dense_1_loss_15: 0.0328 - dense_1_loss_16: 0.0310 - dense_1_loss_17: 0.0325 - dense_1_loss_18: 0.0279 - dense_1_loss_19: 0.0307 - dense_1_loss_20: 0.0346 - dense_1_loss_21: 0.0316 - dense_1_loss_22: 0.0312 - dense_1_loss_23: 0.0312 - dense_1_loss_24: 0.0307 - dense_1_loss_25: 0.0330 - dense_1_loss_26: 0.0308 - dense_1_loss_27: 0.0371 - dense_1_loss_28: 0.0378 - dense_1_loss_29: 0.0416 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0667 - dense_1_acc_2: 0.6667 - dense_1_acc_3: 0.9000 - dense_1_acc_4: 1.0000 - dense_1_acc_5: 1.0000 - dense_1_acc_6: 1.0000 - dense_1_acc_7: 1.0000 - dense_1_acc_8: 1.0000 - dense_1_acc_9: 1.0000 - dense_1_acc_10: 1.0000 - dense_1_acc_11: 1.0000 - dense_1_acc_12: 1.0000 - dense_1_acc_13: 1.0000 - dense_1_acc_14: 1.0000 - dense_1_acc_15: 1.0000 - dense_1_acc_16: 1.0000 - dense_1_acc_17: 1.0000 - dense_1_acc_18: 1.0000 - dense_1_acc_19: 1.0000 - dense_1_acc_20: 1.0000 - dense_1_acc_21: 1.0000 - dense_1_acc_22: 1.0000 - dense_1_acc_23: 1.0000 - dense_1_acc_24: 1.0000 - dense_1_acc_25: 1.0000 - dense_1_acc_26: 1.0000 - dense_1_acc_27: 1.0000 - dense_1_acc_28: 1.0000 - dense_1_acc_29: 1.0000 - dense_1_acc_30: 0.0167     
Epoch 90/100
60/60 [==============================] - 0s - loss: 6.4240 - dense_1_loss_1: 3.7876 - dense_1_loss_2: 1.2468 - dense_1_loss_3: 0.3902 - dense_1_loss_4: 0.1068 - dense_1_loss_5: 0.0807 - dense_1_loss_6: 0.0575 - dense_1_loss_7: 0.0464 - dense_1_loss_8: 0.0375 - dense_1_loss_9: 0.0365 - dense_1_loss_10: 0.0291 - dense_1_loss_11: 0.0301 - dense_1_loss_12: 0.0327 - dense_1_loss_13: 0.0280 - dense_1_loss_14: 0.0309 - dense_1_loss_15: 0.0321 - dense_1_loss_16: 0.0302 - dense_1_loss_17: 0.0317 - dense_1_loss_18: 0.0273 - dense_1_loss_19: 0.0300 - dense_1_loss_20: 0.0338 - dense_1_loss_21: 0.0308 - dense_1_loss_22: 0.0305 - dense_1_loss_23: 0.0305 - dense_1_loss_24: 0.0300 - dense_1_loss_25: 0.0324 - dense_1_loss_26: 0.0301 - dense_1_loss_27: 0.0361 - dense_1_loss_28: 0.0371 - dense_1_loss_29: 0.0406 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0667 - dense_1_acc_2: 0.6667 - dense_1_acc_3: 0.9000 - dense_1_acc_4: 1.0000 - dense_1_acc_5: 1.0000 - dense_1_acc_6: 1.0000 - dense_1_acc_7: 1.0000 - dense_1_acc_8: 1.0000 - dense_1_acc_9: 1.0000 - dense_1_acc_10: 1.0000 - dense_1_acc_11: 1.0000 - dense_1_acc_12: 1.0000 - dense_1_acc_13: 1.0000 - dense_1_acc_14: 1.0000 - dense_1_acc_15: 1.0000 - dense_1_acc_16: 1.0000 - dense_1_acc_17: 1.0000 - dense_1_acc_18: 1.0000 - dense_1_acc_19: 1.0000 - dense_1_acc_20: 1.0000 - dense_1_acc_21: 1.0000 - dense_1_acc_22: 1.0000 - dense_1_acc_23: 1.0000 - dense_1_acc_24: 1.0000 - dense_1_acc_25: 1.0000 - dense_1_acc_26: 1.0000 - dense_1_acc_27: 1.0000 - dense_1_acc_28: 1.0000 - dense_1_acc_29: 1.0000 - dense_1_acc_30: 0.0167     
Epoch 91/100
60/60 [==============================] - 0s - loss: 6.3809 - dense_1_loss_1: 3.7849 - dense_1_loss_2: 1.2358 - dense_1_loss_3: 0.3836 - dense_1_loss_4: 0.1048 - dense_1_loss_5: 0.0787 - dense_1_loss_6: 0.0561 - dense_1_loss_7: 0.0454 - dense_1_loss_8: 0.0366 - dense_1_loss_9: 0.0356 - dense_1_loss_10: 0.0285 - dense_1_loss_11: 0.0294 - dense_1_loss_12: 0.0320 - dense_1_loss_13: 0.0273 - dense_1_loss_14: 0.0302 - dense_1_loss_15: 0.0313 - dense_1_loss_16: 0.0296 - dense_1_loss_17: 0.0309 - dense_1_loss_18: 0.0267 - dense_1_loss_19: 0.0293 - dense_1_loss_20: 0.0330 - dense_1_loss_21: 0.0301 - dense_1_loss_22: 0.0298 - dense_1_loss_23: 0.0297 - dense_1_loss_24: 0.0293 - dense_1_loss_25: 0.0317 - dense_1_loss_26: 0.0294 - dense_1_loss_27: 0.0352 - dense_1_loss_28: 0.0363 - dense_1_loss_29: 0.0396 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0667 - dense_1_acc_2: 0.6667 - dense_1_acc_3: 0.9000 - dense_1_acc_4: 1.0000 - dense_1_acc_5: 1.0000 - dense_1_acc_6: 1.0000 - dense_1_acc_7: 1.0000 - dense_1_acc_8: 1.0000 - dense_1_acc_9: 1.0000 - dense_1_acc_10: 1.0000 - dense_1_acc_11: 1.0000 - dense_1_acc_12: 1.0000 - dense_1_acc_13: 1.0000 - dense_1_acc_14: 1.0000 - dense_1_acc_15: 1.0000 - dense_1_acc_16: 1.0000 - dense_1_acc_17: 1.0000 - dense_1_acc_18: 1.0000 - dense_1_acc_19: 1.0000 - dense_1_acc_20: 1.0000 - dense_1_acc_21: 1.0000 - dense_1_acc_22: 1.0000 - dense_1_acc_23: 1.0000 - dense_1_acc_24: 1.0000 - dense_1_acc_25: 1.0000 - dense_1_acc_26: 1.0000 - dense_1_acc_27: 1.0000 - dense_1_acc_28: 1.0000 - dense_1_acc_29: 1.0000 - dense_1_acc_30: 0.0167     
Epoch 92/100
60/60 [==============================] - 0s - loss: 6.3380 - dense_1_loss_1: 3.7818 - dense_1_loss_2: 1.2247 - dense_1_loss_3: 0.3769 - dense_1_loss_4: 0.1026 - dense_1_loss_5: 0.0769 - dense_1_loss_6: 0.0549 - dense_1_loss_7: 0.0444 - dense_1_loss_8: 0.0359 - dense_1_loss_9: 0.0348 - dense_1_loss_10: 0.0278 - dense_1_loss_11: 0.0287 - dense_1_loss_12: 0.0313 - dense_1_loss_13: 0.0266 - dense_1_loss_14: 0.0296 - dense_1_loss_15: 0.0305 - dense_1_loss_16: 0.0290 - dense_1_loss_17: 0.0302 - dense_1_loss_18: 0.0261 - dense_1_loss_19: 0.0286 - dense_1_loss_20: 0.0322 - dense_1_loss_21: 0.0294 - dense_1_loss_22: 0.0291 - dense_1_loss_23: 0.0290 - dense_1_loss_24: 0.0287 - dense_1_loss_25: 0.0309 - dense_1_loss_26: 0.0287 - dense_1_loss_27: 0.0346 - dense_1_loss_28: 0.0353 - dense_1_loss_29: 0.0387 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0667 - dense_1_acc_2: 0.6667 - dense_1_acc_3: 0.9000 - dense_1_acc_4: 1.0000 - dense_1_acc_5: 1.0000 - dense_1_acc_6: 1.0000 - dense_1_acc_7: 1.0000 - dense_1_acc_8: 1.0000 - dense_1_acc_9: 1.0000 - dense_1_acc_10: 1.0000 - dense_1_acc_11: 1.0000 - dense_1_acc_12: 1.0000 - dense_1_acc_13: 1.0000 - dense_1_acc_14: 1.0000 - dense_1_acc_15: 1.0000 - dense_1_acc_16: 1.0000 - dense_1_acc_17: 1.0000 - dense_1_acc_18: 1.0000 - dense_1_acc_19: 1.0000 - dense_1_acc_20: 1.0000 - dense_1_acc_21: 1.0000 - dense_1_acc_22: 1.0000 - dense_1_acc_23: 1.0000 - dense_1_acc_24: 1.0000 - dense_1_acc_25: 1.0000 - dense_1_acc_26: 1.0000 - dense_1_acc_27: 1.0000 - dense_1_acc_28: 1.0000 - dense_1_acc_29: 1.0000 - dense_1_acc_30: 0.0167             
Epoch 93/100
60/60 [==============================] - 0s - loss: 6.2986 - dense_1_loss_1: 3.7789 - dense_1_loss_2: 1.2147 - dense_1_loss_3: 0.3708 - dense_1_loss_4: 0.1008 - dense_1_loss_5: 0.0752 - dense_1_loss_6: 0.0537 - dense_1_loss_7: 0.0435 - dense_1_loss_8: 0.0351 - dense_1_loss_9: 0.0340 - dense_1_loss_10: 0.0272 - dense_1_loss_11: 0.0280 - dense_1_loss_12: 0.0306 - dense_1_loss_13: 0.0260 - dense_1_loss_14: 0.0290 - dense_1_loss_15: 0.0297 - dense_1_loss_16: 0.0284 - dense_1_loss_17: 0.0295 - dense_1_loss_18: 0.0256 - dense_1_loss_19: 0.0280 - dense_1_loss_20: 0.0315 - dense_1_loss_21: 0.0288 - dense_1_loss_22: 0.0284 - dense_1_loss_23: 0.0284 - dense_1_loss_24: 0.0281 - dense_1_loss_25: 0.0301 - dense_1_loss_26: 0.0281 - dense_1_loss_27: 0.0340 - dense_1_loss_28: 0.0346 - dense_1_loss_29: 0.0377 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0667 - dense_1_acc_2: 0.6667 - dense_1_acc_3: 0.9000 - dense_1_acc_4: 1.0000 - dense_1_acc_5: 1.0000 - dense_1_acc_6: 1.0000 - dense_1_acc_7: 1.0000 - dense_1_acc_8: 1.0000 - dense_1_acc_9: 1.0000 - dense_1_acc_10: 1.0000 - dense_1_acc_11: 1.0000 - dense_1_acc_12: 1.0000 - dense_1_acc_13: 1.0000 - dense_1_acc_14: 1.0000 - dense_1_acc_15: 1.0000 - dense_1_acc_16: 1.0000 - dense_1_acc_17: 1.0000 - dense_1_acc_18: 1.0000 - dense_1_acc_19: 1.0000 - dense_1_acc_20: 1.0000 - dense_1_acc_21: 1.0000 - dense_1_acc_22: 1.0000 - dense_1_acc_23: 1.0000 - dense_1_acc_24: 1.0000 - dense_1_acc_25: 1.0000 - dense_1_acc_26: 1.0000 - dense_1_acc_27: 1.0000 - dense_1_acc_28: 1.0000 - dense_1_acc_29: 1.0000 - dense_1_acc_30: 0.0167     
Epoch 94/100
60/60 [==============================] - 0s - loss: 6.2593 - dense_1_loss_1: 3.7764 - dense_1_loss_2: 1.2041 - dense_1_loss_3: 0.3640 - dense_1_loss_4: 0.0992 - dense_1_loss_5: 0.0735 - dense_1_loss_6: 0.0526 - dense_1_loss_7: 0.0426 - dense_1_loss_8: 0.0344 - dense_1_loss_9: 0.0332 - dense_1_loss_10: 0.0266 - dense_1_loss_11: 0.0274 - dense_1_loss_12: 0.0300 - dense_1_loss_13: 0.0255 - dense_1_loss_14: 0.0283 - dense_1_loss_15: 0.0291 - dense_1_loss_16: 0.0278 - dense_1_loss_17: 0.0289 - dense_1_loss_18: 0.0250 - dense_1_loss_19: 0.0274 - dense_1_loss_20: 0.0308 - dense_1_loss_21: 0.0282 - dense_1_loss_22: 0.0278 - dense_1_loss_23: 0.0278 - dense_1_loss_24: 0.0275 - dense_1_loss_25: 0.0295 - dense_1_loss_26: 0.0275 - dense_1_loss_27: 0.0334 - dense_1_loss_28: 0.0339 - dense_1_loss_29: 0.0369 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0667 - dense_1_acc_2: 0.6667 - dense_1_acc_3: 0.9167 - dense_1_acc_4: 1.0000 - dense_1_acc_5: 1.0000 - dense_1_acc_6: 1.0000 - dense_1_acc_7: 1.0000 - dense_1_acc_8: 1.0000 - dense_1_acc_9: 1.0000 - dense_1_acc_10: 1.0000 - dense_1_acc_11: 1.0000 - dense_1_acc_12: 1.0000 - dense_1_acc_13: 1.0000 - dense_1_acc_14: 1.0000 - dense_1_acc_15: 1.0000 - dense_1_acc_16: 1.0000 - dense_1_acc_17: 1.0000 - dense_1_acc_18: 1.0000 - dense_1_acc_19: 1.0000 - dense_1_acc_20: 1.0000 - dense_1_acc_21: 1.0000 - dense_1_acc_22: 1.0000 - dense_1_acc_23: 1.0000 - dense_1_acc_24: 1.0000 - dense_1_acc_25: 1.0000 - dense_1_acc_26: 1.0000 - dense_1_acc_27: 1.0000 - dense_1_acc_28: 1.0000 - dense_1_acc_29: 1.0000 - dense_1_acc_30: 0.0167             
Epoch 95/100
60/60 [==============================] - 0s - loss: 6.2215 - dense_1_loss_1: 3.7735 - dense_1_loss_2: 1.1943 - dense_1_loss_3: 0.3574 - dense_1_loss_4: 0.0976 - dense_1_loss_5: 0.0719 - dense_1_loss_6: 0.0513 - dense_1_loss_7: 0.0418 - dense_1_loss_8: 0.0337 - dense_1_loss_9: 0.0325 - dense_1_loss_10: 0.0261 - dense_1_loss_11: 0.0268 - dense_1_loss_12: 0.0293 - dense_1_loss_13: 0.0250 - dense_1_loss_14: 0.0276 - dense_1_loss_15: 0.0285 - dense_1_loss_16: 0.0273 - dense_1_loss_17: 0.0283 - dense_1_loss_18: 0.0245 - dense_1_loss_19: 0.0268 - dense_1_loss_20: 0.0302 - dense_1_loss_21: 0.0276 - dense_1_loss_22: 0.0272 - dense_1_loss_23: 0.0272 - dense_1_loss_24: 0.0270 - dense_1_loss_25: 0.0288 - dense_1_loss_26: 0.0269 - dense_1_loss_27: 0.0327 - dense_1_loss_28: 0.0332 - dense_1_loss_29: 0.0362 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0667 - dense_1_acc_2: 0.6667 - dense_1_acc_3: 0.9167 - dense_1_acc_4: 1.0000 - dense_1_acc_5: 1.0000 - dense_1_acc_6: 1.0000 - dense_1_acc_7: 1.0000 - dense_1_acc_8: 1.0000 - dense_1_acc_9: 1.0000 - dense_1_acc_10: 1.0000 - dense_1_acc_11: 1.0000 - dense_1_acc_12: 1.0000 - dense_1_acc_13: 1.0000 - dense_1_acc_14: 1.0000 - dense_1_acc_15: 1.0000 - dense_1_acc_16: 1.0000 - dense_1_acc_17: 1.0000 - dense_1_acc_18: 1.0000 - dense_1_acc_19: 1.0000 - dense_1_acc_20: 1.0000 - dense_1_acc_21: 1.0000 - dense_1_acc_22: 1.0000 - dense_1_acc_23: 1.0000 - dense_1_acc_24: 1.0000 - dense_1_acc_25: 1.0000 - dense_1_acc_26: 1.0000 - dense_1_acc_27: 1.0000 - dense_1_acc_28: 1.0000 - dense_1_acc_29: 1.0000 - dense_1_acc_30: 0.0167     
Epoch 96/100
60/60 [==============================] - 0s - loss: 6.1845 - dense_1_loss_1: 3.7707 - dense_1_loss_2: 1.1841 - dense_1_loss_3: 0.3518 - dense_1_loss_4: 0.0957 - dense_1_loss_5: 0.0705 - dense_1_loss_6: 0.0504 - dense_1_loss_7: 0.0410 - dense_1_loss_8: 0.0330 - dense_1_loss_9: 0.0320 - dense_1_loss_10: 0.0256 - dense_1_loss_11: 0.0262 - dense_1_loss_12: 0.0287 - dense_1_loss_13: 0.0245 - dense_1_loss_14: 0.0270 - dense_1_loss_15: 0.0279 - dense_1_loss_16: 0.0267 - dense_1_loss_17: 0.0277 - dense_1_loss_18: 0.0240 - dense_1_loss_19: 0.0262 - dense_1_loss_20: 0.0296 - dense_1_loss_21: 0.0270 - dense_1_loss_22: 0.0267 - dense_1_loss_23: 0.0266 - dense_1_loss_24: 0.0264 - dense_1_loss_25: 0.0282 - dense_1_loss_26: 0.0263 - dense_1_loss_27: 0.0320 - dense_1_loss_28: 0.0324 - dense_1_loss_29: 0.0355 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0667 - dense_1_acc_2: 0.6667 - dense_1_acc_3: 0.9167 - dense_1_acc_4: 1.0000 - dense_1_acc_5: 1.0000 - dense_1_acc_6: 1.0000 - dense_1_acc_7: 1.0000 - dense_1_acc_8: 1.0000 - dense_1_acc_9: 1.0000 - dense_1_acc_10: 1.0000 - dense_1_acc_11: 1.0000 - dense_1_acc_12: 1.0000 - dense_1_acc_13: 1.0000 - dense_1_acc_14: 1.0000 - dense_1_acc_15: 1.0000 - dense_1_acc_16: 1.0000 - dense_1_acc_17: 1.0000 - dense_1_acc_18: 1.0000 - dense_1_acc_19: 1.0000 - dense_1_acc_20: 1.0000 - dense_1_acc_21: 1.0000 - dense_1_acc_22: 1.0000 - dense_1_acc_23: 1.0000 - dense_1_acc_24: 1.0000 - dense_1_acc_25: 1.0000 - dense_1_acc_26: 1.0000 - dense_1_acc_27: 1.0000 - dense_1_acc_28: 1.0000 - dense_1_acc_29: 1.0000 - dense_1_acc_30: 0.0167     
Epoch 97/100
60/60 [==============================] - 0s - loss: 6.1481 - dense_1_loss_1: 3.7679 - dense_1_loss_2: 1.1742 - dense_1_loss_3: 0.3459 - dense_1_loss_4: 0.0940 - dense_1_loss_5: 0.0688 - dense_1_loss_6: 0.0494 - dense_1_loss_7: 0.0402 - dense_1_loss_8: 0.0323 - dense_1_loss_9: 0.0314 - dense_1_loss_10: 0.0250 - dense_1_loss_11: 0.0257 - dense_1_loss_12: 0.0281 - dense_1_loss_13: 0.0239 - dense_1_loss_14: 0.0265 - dense_1_loss_15: 0.0273 - dense_1_loss_16: 0.0261 - dense_1_loss_17: 0.0272 - dense_1_loss_18: 0.0235 - dense_1_loss_19: 0.0257 - dense_1_loss_20: 0.0289 - dense_1_loss_21: 0.0264 - dense_1_loss_22: 0.0262 - dense_1_loss_23: 0.0260 - dense_1_loss_24: 0.0259 - dense_1_loss_25: 0.0276 - dense_1_loss_26: 0.0259 - dense_1_loss_27: 0.0314 - dense_1_loss_28: 0.0318 - dense_1_loss_29: 0.0349 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0667 - dense_1_acc_2: 0.6667 - dense_1_acc_3: 0.9167 - dense_1_acc_4: 1.0000 - dense_1_acc_5: 1.0000 - dense_1_acc_6: 1.0000 - dense_1_acc_7: 1.0000 - dense_1_acc_8: 1.0000 - dense_1_acc_9: 1.0000 - dense_1_acc_10: 1.0000 - dense_1_acc_11: 1.0000 - dense_1_acc_12: 1.0000 - dense_1_acc_13: 1.0000 - dense_1_acc_14: 1.0000 - dense_1_acc_15: 1.0000 - dense_1_acc_16: 1.0000 - dense_1_acc_17: 1.0000 - dense_1_acc_18: 1.0000 - dense_1_acc_19: 1.0000 - dense_1_acc_20: 1.0000 - dense_1_acc_21: 1.0000 - dense_1_acc_22: 1.0000 - dense_1_acc_23: 1.0000 - dense_1_acc_24: 1.0000 - dense_1_acc_25: 1.0000 - dense_1_acc_26: 1.0000 - dense_1_acc_27: 1.0000 - dense_1_acc_28: 1.0000 - dense_1_acc_29: 1.0000 - dense_1_acc_30: 0.0167     
Epoch 98/100
60/60 [==============================] - 0s - loss: 6.1153 - dense_1_loss_1: 3.7651 - dense_1_loss_2: 1.1656 - dense_1_loss_3: 0.3412 - dense_1_loss_4: 0.0922 - dense_1_loss_5: 0.0674 - dense_1_loss_6: 0.0486 - dense_1_loss_7: 0.0395 - dense_1_loss_8: 0.0316 - dense_1_loss_9: 0.0308 - dense_1_loss_10: 0.0244 - dense_1_loss_11: 0.0252 - dense_1_loss_12: 0.0276 - dense_1_loss_13: 0.0234 - dense_1_loss_14: 0.0260 - dense_1_loss_15: 0.0267 - dense_1_loss_16: 0.0256 - dense_1_loss_17: 0.0266 - dense_1_loss_18: 0.0231 - dense_1_loss_19: 0.0252 - dense_1_loss_20: 0.0283 - dense_1_loss_21: 0.0259 - dense_1_loss_22: 0.0257 - dense_1_loss_23: 0.0255 - dense_1_loss_24: 0.0254 - dense_1_loss_25: 0.0271 - dense_1_loss_26: 0.0254 - dense_1_loss_27: 0.0308 - dense_1_loss_28: 0.0312 - dense_1_loss_29: 0.0342 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0667 - dense_1_acc_2: 0.6667 - dense_1_acc_3: 0.9167 - dense_1_acc_4: 1.0000 - dense_1_acc_5: 1.0000 - dense_1_acc_6: 1.0000 - dense_1_acc_7: 1.0000 - dense_1_acc_8: 1.0000 - dense_1_acc_9: 1.0000 - dense_1_acc_10: 1.0000 - dense_1_acc_11: 1.0000 - dense_1_acc_12: 1.0000 - dense_1_acc_13: 1.0000 - dense_1_acc_14: 1.0000 - dense_1_acc_15: 1.0000 - dense_1_acc_16: 1.0000 - dense_1_acc_17: 1.0000 - dense_1_acc_18: 1.0000 - dense_1_acc_19: 1.0000 - dense_1_acc_20: 1.0000 - dense_1_acc_21: 1.0000 - dense_1_acc_22: 1.0000 - dense_1_acc_23: 1.0000 - dense_1_acc_24: 1.0000 - dense_1_acc_25: 1.0000 - dense_1_acc_26: 1.0000 - dense_1_acc_27: 1.0000 - dense_1_acc_28: 1.0000 - dense_1_acc_29: 1.0000 - dense_1_acc_30: 0.0167         
Epoch 99/100
60/60 [==============================] - 0s - loss: 6.0815 - dense_1_loss_1: 3.7623 - dense_1_loss_2: 1.1560 - dense_1_loss_3: 0.3359 - dense_1_loss_4: 0.0907 - dense_1_loss_5: 0.0661 - dense_1_loss_6: 0.0477 - dense_1_loss_7: 0.0387 - dense_1_loss_8: 0.0311 - dense_1_loss_9: 0.0301 - dense_1_loss_10: 0.0240 - dense_1_loss_11: 0.0246 - dense_1_loss_12: 0.0271 - dense_1_loss_13: 0.0229 - dense_1_loss_14: 0.0254 - dense_1_loss_15: 0.0261 - dense_1_loss_16: 0.0251 - dense_1_loss_17: 0.0261 - dense_1_loss_18: 0.0226 - dense_1_loss_19: 0.0247 - dense_1_loss_20: 0.0277 - dense_1_loss_21: 0.0254 - dense_1_loss_22: 0.0252 - dense_1_loss_23: 0.0250 - dense_1_loss_24: 0.0249 - dense_1_loss_25: 0.0266 - dense_1_loss_26: 0.0249 - dense_1_loss_27: 0.0301 - dense_1_loss_28: 0.0306 - dense_1_loss_29: 0.0335 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0667 - dense_1_acc_2: 0.6667 - dense_1_acc_3: 0.9167 - dense_1_acc_4: 1.0000 - dense_1_acc_5: 1.0000 - dense_1_acc_6: 1.0000 - dense_1_acc_7: 1.0000 - dense_1_acc_8: 1.0000 - dense_1_acc_9: 1.0000 - dense_1_acc_10: 1.0000 - dense_1_acc_11: 1.0000 - dense_1_acc_12: 1.0000 - dense_1_acc_13: 1.0000 - dense_1_acc_14: 1.0000 - dense_1_acc_15: 1.0000 - dense_1_acc_16: 1.0000 - dense_1_acc_17: 1.0000 - dense_1_acc_18: 1.0000 - dense_1_acc_19: 1.0000 - dense_1_acc_20: 1.0000 - dense_1_acc_21: 1.0000 - dense_1_acc_22: 1.0000 - dense_1_acc_23: 1.0000 - dense_1_acc_24: 1.0000 - dense_1_acc_25: 1.0000 - dense_1_acc_26: 1.0000 - dense_1_acc_27: 1.0000 - dense_1_acc_28: 1.0000 - dense_1_acc_29: 1.0000 - dense_1_acc_30: 0.0167     
Epoch 100/100
60/60 [==============================] - 0s - loss: 6.0489 - dense_1_loss_1: 3.7597 - dense_1_loss_2: 1.1471 - dense_1_loss_3: 0.3306 - dense_1_loss_4: 0.0894 - dense_1_loss_5: 0.0648 - dense_1_loss_6: 0.0468 - dense_1_loss_7: 0.0380 - dense_1_loss_8: 0.0305 - dense_1_loss_9: 0.0295 - dense_1_loss_10: 0.0236 - dense_1_loss_11: 0.0241 - dense_1_loss_12: 0.0265 - dense_1_loss_13: 0.0224 - dense_1_loss_14: 0.0250 - dense_1_loss_15: 0.0256 - dense_1_loss_16: 0.0247 - dense_1_loss_17: 0.0256 - dense_1_loss_18: 0.0222 - dense_1_loss_19: 0.0242 - dense_1_loss_20: 0.0272 - dense_1_loss_21: 0.0249 - dense_1_loss_22: 0.0246 - dense_1_loss_23: 0.0245 - dense_1_loss_24: 0.0245 - dense_1_loss_25: 0.0261 - dense_1_loss_26: 0.0244 - dense_1_loss_27: 0.0295 - dense_1_loss_28: 0.0301 - dense_1_loss_29: 0.0328 - dense_1_loss_30: 0.0000e+00 - dense_1_acc_1: 0.0667 - dense_1_acc_2: 0.6667 - dense_1_acc_3: 0.9167 - dense_1_acc_4: 1.0000 - dense_1_acc_5: 1.0000 - dense_1_acc_6: 1.0000 - dense_1_acc_7: 1.0000 - dense_1_acc_8: 1.0000 - dense_1_acc_9: 1.0000 - dense_1_acc_10: 1.0000 - dense_1_acc_11: 1.0000 - dense_1_acc_12: 1.0000 - dense_1_acc_13: 1.0000 - dense_1_acc_14: 1.0000 - dense_1_acc_15: 1.0000 - dense_1_acc_16: 1.0000 - dense_1_acc_17: 1.0000 - dense_1_acc_18: 1.0000 - dense_1_acc_19: 1.0000 - dense_1_acc_20: 1.0000 - dense_1_acc_21: 1.0000 - dense_1_acc_22: 1.0000 - dense_1_acc_23: 1.0000 - dense_1_acc_24: 1.0000 - dense_1_acc_25: 1.0000 - dense_1_acc_26: 1.0000 - dense_1_acc_27: 1.0000 - dense_1_acc_28: 1.0000 - dense_1_acc_29: 1.0000 - dense_1_acc_30: 0.0167





&amp;lt;keras.callbacks.History at 0x7f4551f7c208&amp;gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;You should see the model loss going down. Now that you have trained a model, lets go on the the final section to implement an inference algorithm, and generate some music! &lt;/p&gt;
&lt;h2 id=&quot;3-generating-music&quot;&gt;3 - Generating music&lt;/h2&gt;
&lt;p&gt;You now have a trained model which has learned the patterns of the jazz soloist. Lets now use this model to synthesize new music. &lt;/p&gt;
&lt;h4 id=&quot;31-predicting-sampling&quot;&gt;3.1 - Predicting &amp;amp; Sampling&lt;/h4&gt;
&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/karenyyy/Coursera_and_Udemy/master/deeplearningai_coursera/Sequence%20Models/images/music_gen.png&quot; style=&quot;width:600;height:400px;&quot;&gt;&lt;/p&gt;
&lt;p&gt;At each step of sampling, you will take as input the activation &lt;code&gt;a&lt;/code&gt; and cell state &lt;code&gt;c&lt;/code&gt; from the previous state of the LSTM, forward propagate by one step, and get a new output activation as well as cell state. The new activation &lt;code&gt;a&lt;/code&gt; can then be used to generate the output, using &lt;code&gt;densor&lt;/code&gt; as before. &lt;/p&gt;
&lt;p&gt;To start off the model, we will initialize &lt;code&gt;x0&lt;/code&gt; as well as the LSTM activation and and cell value &lt;code&gt;a0&lt;/code&gt; and &lt;code&gt;c0&lt;/code&gt; to be zeros. &lt;/p&gt;
&lt;!-- 
You are about to build a function that will do this inference for you. Your function takes in your previous model and the number of time steps `Ty` that you want to sample. It will return a keras model that would be able to generate sequences for you. Furthermore, the function takes in a dense layer of `78` units and the number of activations. 
!--&gt;

&lt;p&gt;&lt;strong&gt;Exercise:&lt;/strong&gt; Implement the function below to sample a sequence of musical values. Here are some of the key steps you&#39;ll need to implement inside the for-loop that generates the $T_y$ output characters: &lt;/p&gt;
&lt;p&gt;Step 2.A: Use &lt;code&gt;LSTM_Cell&lt;/code&gt;, which inputs the previous step&#39;s &lt;code&gt;c&lt;/code&gt; and &lt;code&gt;a&lt;/code&gt; to generate the current step&#39;s &lt;code&gt;c&lt;/code&gt; and &lt;code&gt;a&lt;/code&gt;. &lt;/p&gt;
&lt;p&gt;Step 2.B: Use &lt;code&gt;densor&lt;/code&gt; (defined previously) to compute a softmax on &lt;code&gt;a&lt;/code&gt; to get the output for the current step. &lt;/p&gt;
&lt;p&gt;Step 2.C: Save the output you have just generated by appending it to &lt;code&gt;outputs&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;Step 2.D: Sample x to the be &quot;out&quot;&#39;s one-hot version (the prediction) so that you can pass it to the next LSTM&#39;s step.  We have already provided this line of code, which uses a &lt;a href=&quot;https://keras.io/layers/core/#lambda&quot;&gt;Lambda&lt;/a&gt; function. &lt;/p&gt;
&lt;div class=&quot;codehilite&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Lambda&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;one_hot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;out&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; 
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;[Minor technical note: Rather than sampling a value at random according to the probabilities in &lt;code&gt;out&lt;/code&gt;, this line of code actually chooses the single most likely note at each step using an argmax.]&lt;/p&gt;
&lt;div class=&quot;codehilite&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;c1&quot;&gt;# GRADED FUNCTION: music_inference_model&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;music_inference_model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;LSTM_cell&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;densor&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n_values&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;78&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n_a&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;64&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Ty&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;100&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;sd&quot;&gt;&amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    Uses the trained &amp;quot;LSTM_cell&amp;quot; and &amp;quot;densor&amp;quot; from model() to generate a sequence of values.&lt;/span&gt;

&lt;span class=&quot;sd&quot;&gt;    Arguments:&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    LSTM_cell -- the trained &amp;quot;LSTM_cell&amp;quot; from model(), Keras layer object&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    densor -- the trained &amp;quot;densor&amp;quot; from model(), Keras layer object&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    n_values -- integer, umber of unique values&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    n_a -- number of units in the LSTM_cell&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    Ty -- integer, number of time steps to generate&lt;/span&gt;

&lt;span class=&quot;sd&quot;&gt;    Returns:&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    inference_model -- Keras model instance&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    &amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;

    &lt;span class=&quot;c1&quot;&gt;# Define the input of your model with a shape &lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;x0&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Input&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n_values&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;

    &lt;span class=&quot;c1&quot;&gt;# Define s0, initial hidden state for the decoder LSTM&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;a0&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Input&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n_a&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;a0&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;c0&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Input&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n_a&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;c0&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;a&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;a0&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;c&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;c0&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x0&lt;/span&gt;


    &lt;span class=&quot;c1&quot;&gt;# Step 1: Create an empty list of &amp;quot;outputs&amp;quot; to later store your predicted values (≈1 line)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;outputs&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[]&lt;/span&gt;

    &lt;span class=&quot;c1&quot;&gt;# Step 2: Loop over Ty and generate a value at every time step&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;t&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Ty&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;

        &lt;span class=&quot;c1&quot;&gt;# Step 2.A: Perform one step of LSTM_cell (≈1 line)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;_&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;c&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;LSTM_cell&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;initial_state&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;c&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;

        &lt;span class=&quot;c1&quot;&gt;# Step 2.B: Apply Dense layer to the hidden state output of the LSTM_cell (≈1 line)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;out&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;densor&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

        &lt;span class=&quot;c1&quot;&gt;# Step 2.C: Append the prediction &amp;quot;out&amp;quot; to &amp;quot;outputs&amp;quot;. out.shape = (None, 78) (≈1 line)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;outputs&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;append&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;out&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

        &lt;span class=&quot;c1&quot;&gt;# Step 2.D: Select the next value according to &amp;quot;out&amp;quot;, and set &amp;quot;x&amp;quot; to be the one-hot representation of the&lt;/span&gt;
        &lt;span class=&quot;c1&quot;&gt;#           selected value, which will be passed as the input to LSTM_cell on the next step. We have provided &lt;/span&gt;
        &lt;span class=&quot;c1&quot;&gt;#           the line of code you need to do this. &lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Lambda&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;one_hot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;out&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

    &lt;span class=&quot;c1&quot;&gt;# Step 3: Create model instance with the correct &amp;quot;inputs&amp;quot; and &amp;quot;outputs&amp;quot; (≈1 line)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;inference_model&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;inputs&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;a0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;c0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;outputs&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;outputs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;



    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;inference_model&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Run the cell below to define your inference model. This model is hard coded to generate 50 values.&lt;/p&gt;
&lt;div class=&quot;codehilite&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;inference_model&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;music_inference_model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;LSTM_cell&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;densor&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n_values&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;78&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n_a&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;64&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Ty&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;50&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Finally, this creates the zero-valued vectors you will use to initialize &lt;code&gt;x&lt;/code&gt; and the LSTM state variables &lt;code&gt;a&lt;/code&gt; and &lt;code&gt;c&lt;/code&gt;. &lt;/p&gt;
&lt;div class=&quot;codehilite&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x_initializer&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;zeros&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;((&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;78&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;a_initializer&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;zeros&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;((&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n_a&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;c_initializer&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;zeros&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;((&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n_a&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;strong&gt;Exercise&lt;/strong&gt;: Implement &lt;code&gt;predict_and_sample()&lt;/code&gt;. This function takes many arguments including the inputs [x_initializer, a_initializer, c_initializer]. In order to predict the output corresponding to this input, you will need to carry-out 3 steps:
1. Use your inference model to predict an output given your set of inputs. The output &lt;code&gt;pred&lt;/code&gt; should be a list of length $T_y$ where each element is a numpy-array of shape (1, n_values).
2. Convert &lt;code&gt;pred&lt;/code&gt; into a numpy array of $T_y$ indices. Each index corresponds is computed by taking the &lt;code&gt;argmax&lt;/code&gt; of an element of the &lt;code&gt;pred&lt;/code&gt; list. &lt;a href=&quot;https://docs.scipy.org/doc/numpy/reference/generated/numpy.argmax.html&quot;&gt;Hint&lt;/a&gt;.
3. Convert the indices into their one-hot vector representations. &lt;a href=&quot;https://keras.io/utils/#to_categorical&quot;&gt;Hint&lt;/a&gt;.&lt;/p&gt;
&lt;div class=&quot;codehilite&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;c1&quot;&gt;# GRADED FUNCTION: predict_and_sample&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;predict_and_sample&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;inference_model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x_initializer&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x_initializer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;a_initializer&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;a_initializer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; 
                       &lt;span class=&quot;n&quot;&gt;c_initializer&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;c_initializer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;sd&quot;&gt;&amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    Predicts the next value of values using the inference model.&lt;/span&gt;

&lt;span class=&quot;sd&quot;&gt;    Arguments:&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    inference_model -- Keras model instance for inference time&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    x_initializer -- numpy array of shape (1, 1, 78), one-hot vector initializing the values generation&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    a_initializer -- numpy array of shape (1, n_a), initializing the hidden state of the LSTM_cell&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    c_initializer -- numpy array of shape (1, n_a), initializing the cell state of the LSTM_cel&lt;/span&gt;

&lt;span class=&quot;sd&quot;&gt;    Returns:&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    results -- numpy-array of shape (Ty, 78), matrix of one-hot vectors representing the values generated&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    indices -- numpy-array of shape (Ty, 1), matrix of indices representing the values generated&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    &amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;


    &lt;span class=&quot;c1&quot;&gt;# Step 1: Use your inference model to predict an output sequence given x_initializer, a_initializer and c_initializer.&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;pred&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;inference_model&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;predict&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x_initializer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;a_initializer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;c_initializer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
    &lt;span class=&quot;c1&quot;&gt;# Step 2: Convert &amp;quot;pred&amp;quot; into an np.array() of indices with the maximum probabilities&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;indices&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;argmax&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pred&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;axis&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;c1&quot;&gt;# Step 3: Convert indices to one-hot vectors, the shape of the results should be (1, )&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;results&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;to_categorical&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;indices&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;num_classes&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;78&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;


    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;results&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;indices&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div class=&quot;codehilite&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;results&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;indices&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;predict_and_sample&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;inference_model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x_initializer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;a_initializer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;c_initializer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;np.argmax(results[12]) =&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;argmax&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;results&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;12&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]))&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;np.argmax(results[17]) =&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;argmax&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;results&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;17&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]))&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;list(indices[12:18]) =&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;list&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;indices&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;12&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;18&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]))&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div class=&quot;codehilite&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;np.argmax(results[12]) = 71
np.argmax(results[17]) = 35
list(indices[12:18]) = [array([71]), array([60]), array([32]), array([41]), array([33]), array([35])]
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;strong&gt;Expected Output&lt;/strong&gt;: Your results may differ because Keras&#39; results are not completely predictable. However, if you have trained your LSTM_cell with model.fit() for exactly 100 epochs as described above, you should very likely observe a sequence of indices that are not all identical. Moreover, you should observe that: np.argmax(results[12]) is the first element of list(indices[12:18]) and np.argmax(results[17]) is the last element of list(indices[12:18]). &lt;/p&gt;
&lt;table&gt;
    &lt;tr&gt;
        &lt;td&gt;
            **np.argmax(results[12])** =
        &lt;/td&gt;
        &lt;td&gt;
        1
        &lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
        &lt;td&gt;
            **np.argmax(results[12])** =
        &lt;/td&gt;
        &lt;td&gt;
        42
        &lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
        &lt;td&gt;
            **list(indices[12:18])** =
        &lt;/td&gt;
        &lt;td&gt;
            [array([1]), array([42]), array([54]), array([17]), array([1]), array([42])]
        &lt;/td&gt;
    &lt;/tr&gt;
&lt;/table&gt;

&lt;h4 id=&quot;33-generate-music&quot;&gt;3.3 - Generate music&lt;/h4&gt;
&lt;p&gt;Finally, you are ready to generate music. Your RNN generates a sequence of values. The following code generates music by first calling your &lt;code&gt;predict_and_sample()&lt;/code&gt; function. These values are then post-processed into musical chords (meaning that multiple values or notes can be played at the same time). &lt;/p&gt;
&lt;p&gt;Most computational music algorithms use some post-processing because it is difficult to generate music that sounds good without such post-processing. The post-processing does things such as clean up the generated audio by making sure the same sound is not repeated too many times, that two successive notes are not too far from each other in pitch, and so on. One could argue that a lot of these post-processing steps are hacks; also, a lot the music generation literature has also focused on hand-crafting post-processors, and a lot of the output quality depends on the quality of the post-processing and not just the quality of the RNN. But this post-processing does make a huge difference, so lets use it in our implementation as well. &lt;/p&gt;
&lt;p&gt;Lets make some music! &lt;/p&gt;
&lt;p&gt;Run the following cell to generate music and record it into your &lt;code&gt;out_stream&lt;/code&gt;. This can take a couple of minutes.&lt;/p&gt;
&lt;div class=&quot;codehilite&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;out_stream&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;generate_music&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;inference_model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div class=&quot;codehilite&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;Predicting new values for different set of chords.
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;To listen to your music, click File-&amp;gt;Open... Then go to &quot;output/&quot; and download &quot;my_music.midi&quot;. Either play it on your computer with an application that can read midi files if you have one, or use one of the free online &quot;MIDI to mp3&quot; conversion tools to convert this to mp3.  &lt;/p&gt;
&lt;p&gt;As reference, here also is a 30sec audio clip we generated using this algorithm. &lt;/p&gt;
&lt;div class=&quot;codehilite&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;IPython&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;display&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Audio&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;./data/30s_trained_model.mp3&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;h3 id=&quot;congratulations&quot;&gt;Congratulations!&lt;/h3&gt;
&lt;p&gt;You have come to the end of the notebook. &lt;/p&gt;
&lt;p&gt;&lt;font color=&quot;blue&quot;&gt;
Here&#39;s what you should remember:
- A sequence model can be used to generate musical values, which are then post-processed into midi music. 
- Fairly similar models can be used to generate dinosaur names or to generate music, with the major difference being the input fed to the model.&lt;br /&gt;
- In Keras, sequence generation involves defining layers with shared weights, which are then repeated for the different time steps $1, \ldots, T_x$. &lt;/p&gt;
&lt;p&gt;Congratulations on completing this assignment and generating a jazz solo! &lt;/p&gt;
&lt;p&gt;&lt;strong&gt;References&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;The ideas presented in this notebook came primarily from three computational music papers cited below. The implementation here also took significant inspiration and used many components from Ji-Sung Kim&#39;s github repository.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Ji-Sung Kim, 2016, &lt;a href=&quot;https://github.com/jisungk/deepjazz&quot;&gt;deepjazz&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Jon Gillick, Kevin Tang and Robert Keller, 2009. &lt;a href=&quot;http://ai.stanford.edu/~kdtang/papers/smc09-jazzgrammar.pdf&quot;&gt;Learning Jazz Grammars&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Robert Keller and David Morrison, 2007, &lt;a href=&quot;http://smc07.uoa.gr/SMC07%20Proceedings/SMC07%20Paper%2055.pdf&quot;&gt;A Grammatical Approach to Automatic Improvisation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;François Pachet, 1999, &lt;a href=&quot;http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.5.7473&amp;amp;rep=rep1&amp;amp;type=pdf&quot;&gt;Surprising Harmonies&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;deeplearning.ai - Sequence Model - Week 2 Assignment 1
# Operations on word vectors

Welcome to your first assignment of this week! 

Because word embeddings are very computionally expensive to train, most ML practitioners will load a pre-trained set of embeddings. 

**After this assignment you will be able to:**

- Load pre-trained word vectors, and measure similarity using cosine similarity
- Use word embeddings to solve word analogy problems such as Man is to Woman as King is to ______. 
- Modify word embeddings to reduce their gender bias 

Let&#39;s get started! Run the following cell to load the packages you will need.


```python
import numpy as np
from w2v_utils import *
```

    Using TensorFlow backend.


Next, lets load the word vectors. For this assignment, we will use 50-dimensional GloVe vectors to represent words. Run the following cell to load the `word_to_vec_map`. 


```python
words, word_to_vec_map = read_glove_vecs(&#39;data/glove.6B.50d.txt&#39;)
```


```python
import random
{word:(word_to_vec_map[word],word_to_vec_map[word].shape) for word in random.sample(words, 5)}
```




    {&#39;baranek&#39;: (array([ 0.17901  , -0.84042  ,  0.22052  , -0.68751  ,  1.234    ,
              0.5027   ,  0.70022  , -0.30293  ,  0.16086  ,  0.82204  ,
              0.79056  ,  0.0056231,  0.15948  ,  0.47571  ,  0.010601 ,
             -0.39776  ,  0.60254  , -0.33966  ,  0.58514  ,  0.30357  ,
             -0.51967  ,  0.090852 ,  0.38717  ,  0.10578  , -0.47562  ,
              1.2      ,  0.77222  , -0.049116 , -0.32038  , -0.8487   ,
             -1.3703   ,  0.035829 , -0.12203  ,  0.52572  ,  0.4045   ,
              0.18378  ,  0.11391  ,  0.39126  ,  0.10677  ,  0.47038  ,
              0.59311  ,  0.4868   ,  0.16764  , -0.74558  ,  0.068736 ,
             -0.35072  ,  0.67015  ,  0.83776  , -0.88906  ,  0.19203  ]), (50,)),
     &#39;biedenharn&#39;: (array([ 0.12814 , -0.29026 , -0.56041 , -0.16827 ,  0.45403 , -0.36148 ,
             -0.28351 ,  0.20889 ,  0.29914 ,  0.18777 , -0.21659 ,  0.45294 ,
              0.39445 , -0.34683 , -0.20377 ,  0.043054, -0.04924 , -0.15109 ,
              0.40728 , -0.26973 ,  0.31218 , -0.20948 ,  0.033253, -0.043316,
             -0.069875,  1.2687  , -0.057549,  0.16081 , -0.070575, -0.21203 ,
             -1.9392  , -0.57622 ,  0.032348,  0.1417  ,  0.41214 ,  0.40238 ,
              0.25019 ,  1.0414  ,  0.13132 ,  0.58121 ,  0.7523  , -0.11715 ,
             -0.73243 ,  0.10852 ,  0.052733,  0.66743 , -0.096627, -0.61399 ,
             -0.22789 , -0.003776]), (50,)),
     &#39;lonnieb001&#39;: (array([ 0.065632,  0.82419 ,  0.69959 , -1.3197  , -1.4725  , -2.5575  ,
             -0.80366 ,  0.82416 ,  0.83744 ,  0.62602 , -0.47748 ,  1.2495  ,
              0.31795 , -0.14244 ,  1.5082  , -0.10396 ,  0.2637  ,  0.29775 ,
             -1.4833  ,  0.31837 , -1.1044  ,  0.87982 ,  0.91347 ,  0.23803 ,
              0.22616 ,  0.23059 ,  1.8211  , -1.0218  , -0.79281 ,  0.42808 ,
             -0.58352 ,  0.57979 , -0.36858 , -0.44536 , -1.3533  ,  0.32365 ,
              0.98719 ,  0.043084, -0.14167 , -2.062   ,  1.4528  , -0.45904 ,
              0.49206 ,  1.6483  ,  0.82197 , -0.076591, -0.57874 , -0.72346 ,
             -0.7767  ,  1.2842  ]), (50,)),
     &#39;sambia&#39;: (array([ 0.46756  , -0.40139  , -0.73451  , -0.44012  , -0.55169  ,
             -0.10246  ,  0.73369  ,  0.37191  , -0.35266  , -0.20931  ,
              0.39166  ,  0.073888 ,  0.42072  , -0.42146  , -0.73332  ,
              0.1126   ,  0.11893  , -0.0064731, -0.013552 ,  1.1351   ,
             -0.40627  , -0.19306  ,  0.089075 ,  0.074128 ,  0.1305   ,
              0.83148  , -0.20618  , -0.14594  , -0.33704  , -0.24363  ,
             -1.2225   ,  0.42751  ,  0.54438  ,  0.18337  ,  0.20503  ,
             -0.033906 , -0.60527  , -0.29548  , -0.10937  ,  0.37433  ,
             -0.25878  , -0.50921  ,  0.50777  , -0.11073  , -0.33643  ,
             -0.26508  ,  0.57026  ,  0.34857  , -0.21176  , -0.43014  ]), (50,)),
     &#39;yoplait&#39;: (array([-0.51133 ,  0.012252, -0.72766 ,  0.97479 , -0.38208 ,  0.85444 ,
              0.30653 , -0.40731 ,  0.3794  ,  0.47519 ,  0.97934 ,  0.66818 ,
              0.026614, -0.48414 , -0.31844 ,  0.76404 , -1.063   ,  1.5166  ,
              1.1065  , -0.064872,  0.58152 ,  0.064811,  0.78675 ,  0.81462 ,
             -0.43685 ,  0.50596 ,  0.2132  ,  0.96366 ,  0.59195 ,  0.24254 ,
             -0.60861 ,  1.3405  ,  0.51385 ,  1.1441  ,  0.5644  ,  0.44189 ,
             -0.77499 ,  0.12849 , -0.28625 ,  0.2291  ,  0.43939 , -0.17499 ,
             -0.64282 , -0.4644  ,  0.2909  ,  0.43318 , -0.35462 ,  0.36997 ,
              0.68794 , -0.57376 ]), (50,))}



You&#39;ve loaded:
- `words`: set of words in the vocabulary.
- `word_to_vec_map`: dictionary mapping words to their GloVe vector representation.

You&#39;ve seen that one-hot vectors do not do a good job cpaturing what words are similar. GloVe vectors provide much more useful information about the meaning of individual words. Lets now see how you can use GloVe vectors to decide how similar two words are. 



# 1 - Cosine similarity

To measure how similar two words are, we need a way to measure the degree of similarity between two embedding vectors for the two words. Given two vectors $u$ and $v$, cosine similarity is defined as follows: 

$$\text{CosineSimilarity(u, v)} = \frac {u . v} {||u||_2 ||v||_2} = cos(\theta) \tag{1}$$

where $u.v$ is the dot product (or inner product) of two vectors, $||u||_2$ is the norm (or length) of the vector $u$, and $\theta$ is the angle between $u$ and $v$. This similarity depends on the angle between $u$ and $v$. If $u$ and $v$ are very similar, their cosine similarity will be close to 1; if they are dissimilar, the cosine similarity will take a smaller value. 

&lt;img src=&quot;https://raw.githubusercontent.com/karenyyy/Coursera_and_Udemy/master/deeplearningai_coursera/Sequence%20Models/images/cosine_sim.png&quot; style=&quot;width:800px;height:250px;&quot;&gt;
&lt;caption&gt;&lt;center&gt; **Figure 1**: The cosine of the angle between two vectors is a measure of how similar they are&lt;/center&gt;&lt;/caption&gt;

**Exercise**: Implement the function `cosine_similarity()` to evaluate similarity between word vectors.

**Reminder**: The norm of $u$ is defined as $ ||u||_2 = \sqrt{\sum_{i=1}^{n} u_i^2}$


```python
# GRADED FUNCTION: cosine_similarity

def cosine_similarity(u, v):
    &quot;&quot;&quot;
    Cosine similarity reflects the degree of similariy between u and v
        
    Arguments:
        u -- a word vector of shape (n,)          
        v -- a word vector of shape (n,)

    Returns:
        cosine_similarity -- the cosine similarity between u and v defined by the formula above.
    &quot;&quot;&quot;
    
    distance = 0.0
    
    
    # Compute the dot product between u and v (≈1 line)
    dot = np.dot(u,v)
    # Compute the L2 norm of u (≈1 line)
    norm_u = np.linalg.norm(u)
    
    # Compute the L2 norm of v (≈1 line)
    norm_v = np.linalg.norm(v)
    # Compute the cosine similarity defined by formula (1) (≈1 line)
    cosine_similarity = np.divide(dot, np.multiply(norm_u, norm_v))
    
    
    return cosine_similarity
```


```python
father = word_to_vec_map[&quot;father&quot;]
mother = word_to_vec_map[&quot;mother&quot;]
ball = word_to_vec_map[&quot;ball&quot;]
crocodile = word_to_vec_map[&quot;crocodile&quot;]
france = word_to_vec_map[&quot;france&quot;]
italy = word_to_vec_map[&quot;italy&quot;]
paris = word_to_vec_map[&quot;paris&quot;]
rome = word_to_vec_map[&quot;rome&quot;]

print(&quot;cosine_similarity(father, mother) = &quot;, cosine_similarity(father, mother))
print(&quot;cosine_similarity(ball, crocodile) = &quot;,cosine_similarity(ball, crocodile))
print(&quot;cosine_similarity(france - paris, rome - italy) = &quot;,cosine_similarity(france - paris, rome - italy))
```

    cosine_similarity(father, mother) =  0.890903844289
    cosine_similarity(ball, crocodile) =  0.274392462614
    cosine_similarity(france - paris, rome - italy) =  -0.675147930817


**Expected Output**:

&lt;table&gt;
    &lt;tr&gt;
        &lt;td&gt;
            **cosine_similarity(father, mother)** =
        &lt;/td&gt;
        &lt;td&gt;
         0.890903844289
        &lt;/td&gt;
    &lt;/tr&gt;
        &lt;tr&gt;
        &lt;td&gt;
            **cosine_similarity(ball, crocodile)** =
        &lt;/td&gt;
        &lt;td&gt;
         0.274392462614
        &lt;/td&gt;
    &lt;/tr&gt;
        &lt;tr&gt;
        &lt;td&gt;
            **cosine_similarity(france - paris, rome - italy)** =
        &lt;/td&gt;
        &lt;td&gt;
         -0.675147930817
        &lt;/td&gt;
    &lt;/tr&gt;
&lt;/table&gt;

After you get the correct expected output, please feel free to modify the inputs and measure the cosine similarity between other pairs of words! Playing around the cosine similarity of other inputs will give you a better sense of how word vectors behave. 

## 2 - Word analogy task

In the word analogy task, we complete the sentence &lt;font color=&#39;brown&#39;&gt;&quot;*a* is to *b* as *c* is to **____**&quot;&lt;/font&gt;. An example is &lt;font color=&#39;brown&#39;&gt; &#39;*man* is to *woman* as *king* is to *queen*&#39; &lt;/font&gt;. In detail, we are trying to find a word *d*, such that the associated word vectors $e_a, e_b, e_c, e_d$ are related in the following manner: $e_b - e_a \approx e_d - e_c$. We will measure the similarity between $e_b - e_a$ and $e_d - e_c$ using cosine similarity. 

**Exercise**: Complete the code below to be able to perform word analogies!


```python
# GRADED FUNCTION: complete_analogy

def complete_analogy(word_a, word_b, word_c, word_to_vec_map):
    &quot;&quot;&quot;
    Performs the word analogy task as explained above: a is to b as c is to ____. 
    
    Arguments:
    word_a -- a word, string
    word_b -- a word, string
    word_c -- a word, string
    word_to_vec_map -- dictionary that maps words to their corresponding vectors. 
    
    Returns:
    best_word --  the word such that v_b - v_a is close to v_best_word - v_c, as measured by cosine similarity
    &quot;&quot;&quot;
    
    # convert words to lower case
    word_a, word_b, word_c = word_a.lower(), word_b.lower(), word_c.lower()
    
    
    # Get the word embeddings v_a, v_b and v_c (≈1-3 lines)
    e_a, e_b, e_c = word_to_vec_map[word_a], word_to_vec_map[word_b], word_to_vec_map[word_c]
    
    
    words = word_to_vec_map.keys()
    max_cosine_sim = -100              # Initialize max_cosine_sim to a large negative number
    best_word = None                   # Initialize best_word with None, it will help keep track of the word to output

    # loop over the whole word vector set
    for w in words:        
        # to avoid best_word being one of the input words, pass on them.
        if w in [word_a, word_b, word_c] :
            continue
        
        
        # Compute cosine similarity between the vector (e_b - e_a) and the vector ((w&#39;s vector representation) - e_c)  (≈1 line)
        cosine_sim = cosine_similarity(e_b - e_a, word_to_vec_map[w] - e_c)
        
        # If the cosine_sim is more than the max_cosine_sim seen so far,
            # then: set the new max_cosine_sim to the current cosine_sim and the best_word to the current word (≈3 lines)
        if cosine_sim &gt; max_cosine_sim:
            max_cosine_sim = cosine_sim
            best_word = w
        
        
    return best_word
```

Run the cell below to test your code, this may take 1-2 minutes.


```python
triads_to_try = [(&#39;italy&#39;, &#39;italian&#39;, &#39;spain&#39;), (&#39;india&#39;, &#39;delhi&#39;, &#39;japan&#39;), (&#39;man&#39;, &#39;woman&#39;, &#39;boy&#39;), (&#39;small&#39;, &#39;smaller&#39;, &#39;large&#39;)]
for triad in triads_to_try:
    print (&#39;{} -&gt; {} :: {} -&gt; {}&#39;.format( *triad, complete_analogy(*triad,word_to_vec_map)))
```

    italy -&gt; italian :: spain -&gt; spanish
    india -&gt; delhi :: japan -&gt; tokyo
    man -&gt; woman :: boy -&gt; girl
    small -&gt; smaller :: large -&gt; larger


**Expected Output**:

&lt;table&gt;
    &lt;tr&gt;
        &lt;td&gt;
            **italy -&gt; italian** ::
        &lt;/td&gt;
        &lt;td&gt;
         spain -&gt; spanish
        &lt;/td&gt;
    &lt;/tr&gt;
        &lt;tr&gt;
        &lt;td&gt;
            **india -&gt; delhi** ::
        &lt;/td&gt;
        &lt;td&gt;
         japan -&gt; tokyo
        &lt;/td&gt;
    &lt;/tr&gt;
        &lt;tr&gt;
        &lt;td&gt;
            **man -&gt; woman ** ::
        &lt;/td&gt;
        &lt;td&gt;
         boy -&gt; girl
        &lt;/td&gt;
    &lt;/tr&gt;
        &lt;tr&gt;
        &lt;td&gt;
            **small -&gt; smaller ** ::
        &lt;/td&gt;
        &lt;td&gt;
         large -&gt; larger
        &lt;/td&gt;
    &lt;/tr&gt;
&lt;/table&gt;

Once you get the correct expected output, please feel free to modify the input cells above to test your own analogies. Try to find some other analogy pairs that do work, but also find some where the algorithm doesn&#39;t give the right answer: For example, you can try small-&gt;smaller as big-&gt;?.  

### Congratulations!

You&#39;ve come to the end of this assignment. Here are the main points you should remember:

- Cosine similarity a good way to compare similarity between pairs of word vectors. (Though L2 distance works too.) 
- For NLP applications, using a pre-trained set of word vectors from the internet is often a good way to get started. 

Even though you have finished the graded portions, we recommend you take a look too at the rest of this notebook. 

Congratulations on finishing the graded portions of this notebook! 


## 3 - Debiasing word vectors (OPTIONAL/UNGRADED) 

In the following exercise, you will examine gender biases that can be reflected in a word embedding, and explore algorithms for reducing the bias. In addition to learning about the topic of debiasing, this exercise will also help hone your intuition about what word vectors are doing. This section involves a bit of linear algebra, though you can probably complete it even without being expert in linear algebra, and we encourage you to give it a shot. This portion of the notebook is optional and is not graded. 

Lets first see how the GloVe word embeddings relate to gender. You will first compute a vector $g = e_{woman}-e_{man}$, where $e_{woman}$ represents the word vector corresponding to the word *woman*, and $e_{man}$ corresponds to the word vector corresponding to the word *man*. The resulting vector $g$ roughly encodes the concept of &quot;gender&quot;. (You might get a more accurate representation if you compute $g_1 = e_{mother}-e_{father}$, $g_2 = e_{girl}-e_{boy}$, etc. and average over them. But just using $e_{woman}-e_{man}$ will give good enough results for now.) 



```python
g = word_to_vec_map[&#39;woman&#39;] - word_to_vec_map[&#39;man&#39;]
print(g)
```

    [-0.087144    0.2182     -0.40986    -0.03922    -0.1032      0.94165
     -0.06042     0.32988     0.46144    -0.35962     0.31102    -0.86824
      0.96006     0.01073     0.24337     0.08193    -1.02722    -0.21122
      0.695044   -0.00222     0.29106     0.5053     -0.099454    0.40445
      0.30181     0.1355     -0.0606     -0.07131    -0.19245    -0.06115
     -0.3204      0.07165    -0.13337    -0.25068714 -0.14293    -0.224957
     -0.149       0.048882    0.12191    -0.27362    -0.165476   -0.20426
      0.54376    -0.271425   -0.10245    -0.32108     0.2516     -0.33455
     -0.04371     0.01258   ]


Now, you will consider the cosine similarity of different words with $g$. Consider what a positive value of similarity means vs a negative cosine similarity. 


```python
print (&#39;List of names and their similarities with constructed vector:&#39;)

# girls and boys name
name_list = [&#39;john&#39;, &#39;marie&#39;, &#39;sophie&#39;, &#39;ronaldo&#39;, &#39;priya&#39;, &#39;rahul&#39;, &#39;danielle&#39;, &#39;reza&#39;, &#39;katy&#39;, &#39;yasmin&#39;]

for w in name_list:
    print (w, cosine_similarity(word_to_vec_map[w], g))
```

    List of names and their similarities with constructed vector:
    john -0.23163356146
    marie 0.315597935396
    sophie 0.318687898594
    ronaldo -0.312447968503
    priya 0.17632041839
    rahul -0.169154710392
    danielle 0.243932992163
    reza -0.079304296722
    katy 0.283106865957
    yasmin 0.233138577679


As you can see, female first names tend to have a positive cosine similarity with our constructed vector $g$, while male first names tend to have a negative cosine similarity. This is not suprising, and the result seems acceptable. 

But let&#39;s try with some other words.


```python
print(&#39;Other words and their similarities:&#39;)
word_list = [&#39;lipstick&#39;, &#39;guns&#39;, &#39;science&#39;, &#39;arts&#39;, &#39;literature&#39;, &#39;warrior&#39;,&#39;doctor&#39;, &#39;tree&#39;, &#39;receptionist&#39;, 
             &#39;technology&#39;,  &#39;fashion&#39;, &#39;teacher&#39;, &#39;engineer&#39;, &#39;pilot&#39;, &#39;computer&#39;, &#39;singer&#39;]
for w in word_list:
    print (w, cosine_similarity(word_to_vec_map[w], g))
```

    Other words and their similarities:
    lipstick 0.276919162564
    guns -0.18884855679
    science -0.0608290654093
    arts 0.00818931238588
    literature 0.0647250443346
    warrior -0.209201646411
    doctor 0.118952894109
    tree -0.0708939917548
    receptionist 0.330779417506
    technology -0.131937324476
    fashion 0.0356389462577
    teacher 0.179209234318
    engineer -0.0803928049452
    pilot 0.00107644989919
    computer -0.103303588739
    singer 0.185005181365


Do you notice anything surprising? It is astonishing how these results reflect certain unhealthy gender stereotypes. For example, &quot;computer&quot; is closer to &quot;man&quot; while &quot;literature&quot; is closer to &quot;woman&quot;. Ouch! 

We&#39;ll see below how to reduce the bias of these vectors, using an algorithm due to [Boliukbasi et al., 2016](https://arxiv.org/abs/1607.06520). Note that some word pairs such as &quot;actor&quot;/&quot;actress&quot; or &quot;grandmother&quot;/&quot;grandfather&quot; should remain gender specific, while other words such as &quot;receptionist&quot; or &quot;technology&quot; should be neutralized, i.e. not be gender-related. You will have to treat these two type of words differently when debiasing.

### 3.1 - Neutralize bias for non-gender specific words 

The figure below should help you visualize what neutralizing does. If you&#39;re using a 50-dimensional word embedding, the 50 dimensional space can be split into two parts: The bias-direction $g$, and the remaining 49 dimensions, which we&#39;ll call $g_{\perp}$. In linear algebra, we say that the 49 dimensional $g_{\perp}$ is perpendicular (or &quot;othogonal&quot;) to $g$, meaning it is at 90 degrees to $g$. The neutralization step takes a vector such as $e_{receptionist}$ and zeros out the component in the direction of $g$, giving us $e_{receptionist}^{debiased}$. 

Even though $g_{\perp}$ is 49 dimensional, given the limitations of what we can draw on a screen, we illustrate it using a 1 dimensional axis below. 

&lt;img src=&quot;https://raw.githubusercontent.com/karenyyy/Coursera_and_Udemy/master/deeplearningai_coursera/Sequence%20Models/images/neutral.png&quot; style=&quot;width:800px;height:300px;&quot;&gt;
&lt;caption&gt;&lt;center&gt; **Figure 2**: The word vector for &quot;receptionist&quot; represented before and after applying the neutralize operation. &lt;/center&gt;&lt;/caption&gt;

**Exercise**: Implement `neutralize()` to remove the bias of words such as &quot;receptionist&quot; or &quot;scientist&quot;. Given an input embedding $e$, you can use the following formulas to compute $e^{debiased}$: 

$$e^{bias\_component} = \frac{e \cdot g}{||g||_2^2} * g\tag{2}$$
$$e^{debiased} = e - e^{bias\_component}\tag{3}$$

If you are an expert in linear algebra, you may recognize $e^{bias\_component}$ as the projection of $e$ onto the direction $g$. If you&#39;re not an expert in linear algebra, don&#39;t worry about this.

&lt;!-- 
**Reminder**: a vector $u$ can be split into two parts: its projection over a vector-axis $v_B$ and its projection over the axis orthogonal to $v$:
$$u = u_B + u_{\perp}$$
where : $u_B = $ and $ u_{\perp} = u - u_B $
!--&gt; 


```python
def neutralize(word, g, word_to_vec_map):
    &quot;&quot;&quot;
    Removes the bias of &quot;word&quot; by projecting it on the space orthogonal to the bias axis. 
    This function ensures that gender neutral words are zero in the gender subspace.
    
    Arguments:
        word -- string indicating the word to debias
        g -- numpy-array of shape (50,), corresponding to the bias axis (such as gender)
        word_to_vec_map -- dictionary mapping words to their corresponding vectors.
    
    Returns:
        e_debiased -- neutralized word vector representation of the input &quot;word&quot;
    &quot;&quot;&quot;
    
    
    # Select word vector representation of &quot;word&quot;. Use word_to_vec_map. (≈ 1 line)
    e = word_to_vec_map[word]
    
    # Compute e_biascomponent using the formula give above. (≈ 1 line)
    e_biascomponent = np.multiply(np.divide(np.dot(e, g), np.square(np.linalg.norm(g))), g)
 
    # Neutralize e by substracting e_biascomponent from it 
    # e_debiased should be equal to its orthogonal projection. (≈ 1 line)
    e_debiased = np.subtract(e, e_biascomponent)
    
    
    return e_debiased
```


```python
e = &quot;receptionist&quot;
print(&quot;cosine similarity between &quot; + e + &quot; and g, before neutralizing: &quot;, cosine_similarity(word_to_vec_map[&quot;receptionist&quot;], g))

e_debiased = neutralize(&quot;receptionist&quot;, g, word_to_vec_map)
print(&quot;cosine similarity between &quot; + e + &quot; and g, after neutralizing: &quot;, cosine_similarity(e_debiased, g))
```

    cosine similarity between receptionist and g, before neutralizing:  0.330779417506
    cosine similarity between receptionist and g, after neutralizing:  -3.26732746085e-17


**Expected Output**: The second result is essentially 0, up to numerical roundof (on the order of $10^{-17}$).


&lt;table&gt;
    &lt;tr&gt;
        &lt;td&gt;
            **cosine similarity between receptionist and g, before neutralizing:** :
        &lt;/td&gt;
        &lt;td&gt;
         0.330779417506
        &lt;/td&gt;
    &lt;/tr&gt;
        &lt;tr&gt;
        &lt;td&gt;
            **cosine similarity between receptionist and g, after neutralizing:** :
        &lt;/td&gt;
        &lt;td&gt;
         -3.26732746085e-17
    &lt;/tr&gt;
&lt;/table&gt;

### 3.2 - Equalization algorithm for gender-specific words

Next, lets see how debiasing can also be applied to word pairs such as &quot;actress&quot; and &quot;actor.&quot; Equalization is applied to pairs of words that you might want to have differ only through the gender property. As a concrete example, suppose that &quot;actress&quot; is closer to &quot;babysit&quot; than &quot;actor.&quot; By applying neutralizing to &quot;babysit&quot; we can reduce the gender-stereotype associated with babysitting. But this still does not guarantee that &quot;actor&quot; and &quot;actress&quot; are equidistant from &quot;babysit.&quot; The equalization algorithm takes care of this. 

The key idea behind equalization is to make sure that a particular pair of words are equi-distant from the 49-dimensional $g_\perp$. The equalization step also ensures that the two equalized steps are now the same distance from $e_{receptionist}^{debiased}$, or from any other work that has been neutralized. In pictures, this is how equalization works: 

&lt;img src=&quot;https://raw.githubusercontent.com/karenyyy/Coursera_and_Udemy/master/deeplearningai_coursera/Sequence%20Models/images/equalize10.png&quot; style=&quot;width:800px;height:400px;&quot;&gt;


The derivation of the linear algebra to do this is a bit more complex. (See Bolukbasi et al., 2016 for details.) But the key equations are: 

$$ \mu = \frac{e_{w1} + e_{w2}}{2}\tag{4}$$ 

$$ \mu_{B} = \frac {\mu \cdot \text{bias_axis}}{||\text{bias_axis}||_2^2} *\text{bias_axis}
\tag{5}$$ 

$$\mu_{\perp} = \mu - \mu_{B} \tag{6}$$

$$ e_{w1B} = \frac {e_{w1} \cdot \text{bias_axis}}{||\text{bias_axis}||_2^2} *\text{bias_axis}
\tag{7}$$ 
$$ e_{w2B} = \frac {e_{w2} \cdot \text{bias_axis}}{||\text{bias_axis}||_2^2} *\text{bias_axis}
\tag{8}$$


$$e_{w1B}^{corrected} = \sqrt{ |{1 - ||\mu_{\perp} ||^2_2} |} * \frac{e_{\text{w1B}} - \mu_B} {|(e_{w1} - \mu_{\perp}) - \mu_B)|} \tag{9}$$


$$e_{w2B}^{corrected} = \sqrt{ |{1 - ||\mu_{\perp} ||^2_2} |} * \frac{e_{\text{w2B}} - \mu_B} {|(e_{w2} - \mu_{\perp}) - \mu_B)|} \tag{10}$$

$$e_1 = e_{w1B}^{corrected} + \mu_{\perp} \tag{11}$$
$$e_2 = e_{w2B}^{corrected} + \mu_{\perp} \tag{12}$$


**Exercise**: Implement the function below. Use the equations above to get the final equalized version of the pair of words. Good luck!


```python
def equalize(pair, bias_axis, word_to_vec_map):
    &quot;&quot;&quot;
    Debias gender specific words by following the equalize method described in the figure above.
    
    Arguments:
    pair -- pair of strings of gender specific words to debias, e.g. (&quot;actress&quot;, &quot;actor&quot;) 
    bias_axis -- numpy-array of shape (50,), vector corresponding to the bias axis, e.g. gender
    word_to_vec_map -- dictionary mapping words to their corresponding vectors
    
    Returns
    e_1 -- word vector corresponding to the first word
    e_2 -- word vector corresponding to the second word
    &quot;&quot;&quot;
    
    
    # Step 1: Select word vector representation of &quot;word&quot;. Use word_to_vec_map. (≈ 2 lines)
    w1, w2 = pair
    e_w1, e_w2 = word_to_vec_map[w1], word_to_vec_map[w2]
    
    # Step 2: Compute the mean of e_w1 and e_w2 (≈ 1 line)
    mu = np.divide(e_w1+e_w2, 2)

    # Step 3: Compute the projections of mu over the bias axis and the orthogonal axis (≈ 2 lines)
    mu_B = np.multiply(np.divide(np.dot(mu, bias_axis), np.square(np.linalg.norm(bias_axis))), bias_axis)
    mu_orth = mu - mu_B

    # Step 4: Use equations (7) and (8) to compute e_w1B and e_w2B (≈2 lines)
    e_w1B = np.multiply(np.divide(np.dot(e_w1, bias_axis), np.square(np.linalg.norm(bias_axis))), bias_axis)
    e_w2B = np.multiply(np.divide(np.dot(e_w2, bias_axis), np.square(np.linalg.norm(bias_axis))), bias_axis)
        
    # Step 5: Adjust the Bias part of e_w1B and e_w2B using the formulas (9) and (10) given above (≈2 lines)
    corrected_e_w1B = np.multiply(np.sqrt(np.abs(1-np.square(np.linalg.norm(mu_orth)))), np.divide(e_w1B-mu_B,np.linalg.norm(e_w1-mu_orth-mu_B)))
    corrected_e_w2B = np.multiply(np.sqrt(np.abs(1-np.square(np.linalg.norm(mu_orth)))), np.divide(e_w2B-mu_B,np.linalg.norm(e_w2-mu_orth-mu_B)))

    # Step 6: Debias by equalizing e1 and e2 to the sum of their corrected projections (≈2 lines)
    e1 = corrected_e_w1B + mu_orth
    e2 = corrected_e_w2B + mu_orth
                                                                
    
    
    return e1, e2
```


```python
print(&quot;cosine similarities before equalizing:&quot;)
print(&quot;cosine_similarity(word_to_vec_map[\&quot;man\&quot;], gender) = &quot;, cosine_similarity(word_to_vec_map[&quot;man&quot;], g))
print(&quot;cosine_similarity(word_to_vec_map[\&quot;woman\&quot;], gender) = &quot;, cosine_similarity(word_to_vec_map[&quot;woman&quot;], g))
print()
e1, e2 = equalize((&quot;man&quot;, &quot;woman&quot;), g, word_to_vec_map)
print(&quot;cosine similarities after equalizing:&quot;)
print(&quot;cosine_similarity(e1, gender) = &quot;, cosine_similarity(e1, g))
print(&quot;cosine_similarity(e2, gender) = &quot;, cosine_similarity(e2, g))
```

    cosine similarities before equalizing:
    cosine_similarity(word_to_vec_map[&quot;man&quot;], gender) =  -0.117110957653
    cosine_similarity(word_to_vec_map[&quot;woman&quot;], gender) =  0.356666188463
    
    cosine similarities after equalizing:
    cosine_similarity(e1, gender) =  -0.700436428931
    cosine_similarity(e2, gender) =  0.700436428931


**Expected Output**:

cosine similarities before equalizing:
&lt;table&gt;
    &lt;tr&gt;
        &lt;td&gt;
            **cosine_similarity(word_to_vec_map[&quot;man&quot;], gender)** =
        &lt;/td&gt;
        &lt;td&gt;
         -0.117110957653
        &lt;/td&gt;
    &lt;/tr&gt;
        &lt;tr&gt;
        &lt;td&gt;
            **cosine_similarity(word_to_vec_map[&quot;woman&quot;], gender)** =
        &lt;/td&gt;
        &lt;td&gt;
         0.356666188463
        &lt;/td&gt;
    &lt;/tr&gt;
&lt;/table&gt;

cosine similarities after equalizing:
&lt;table&gt;
    &lt;tr&gt;
        &lt;td&gt;
            **cosine_similarity(u1, gender)** =
        &lt;/td&gt;
        &lt;td&gt;
         -0.700436428931
        &lt;/td&gt;
    &lt;/tr&gt;
        &lt;tr&gt;
        &lt;td&gt;
            **cosine_similarity(u2, gender)** =
        &lt;/td&gt;
        &lt;td&gt;
         0.700436428931
        &lt;/td&gt;
    &lt;/tr&gt;
&lt;/table&gt;

Please feel free to play with the input words in the cell above, to apply equalization to other pairs of words. 

These debiasing algorithms are very helpful for reducing bias, but are not perfect and do not eliminate all traces of bias. For example, one weakness of this implementation was that the bias direction $g$ was defined using only the pair of words _woman_ and _man_. As discussed earlier, if $g$ were defined by computing $g_1 = e_{woman} - e_{man}$; $g_2 = e_{mother} - e_{father}$; $g_3 = e_{girl} - e_{boy}$; and so on and averaging over them, you would obtain a better estimate of the &quot;gender&quot; dimension in the 50 dimensional word embedding space. Feel free to play with such variants as well.  
              

**References**:
- The debiasing algorithm is from Bolukbasi et al., 2016, [Man is to Computer Programmer as Woman is to
Homemaker? Debiasing Word Embeddings](https://papers.nips.cc/paper/6228-man-is-to-computer-programmer-as-woman-is-to-homemaker-debiasing-word-embeddings.pdf)
- The GloVe word embeddings were due to Jeffrey Pennington, Richard Socher, and Christopher D. Manning. (https://nlp.stanford.edu/projects/glove/)deeplearning.ai - Sequence Model - Week 1 Assignment 1
# Building your Recurrent Neural Network - Step by Step

Welcome to Course 5&#39;s first assignment! In this assignment, you will implement your first Recurrent Neural Network in numpy.

Recurrent Neural Networks (RNN) are very effective for Natural Language Processing and other sequence tasks because they have &quot;memory&quot;. They can read inputs $x^{\langle t \rangle}$ (such as words) one at a time, and remember some information/context through the hidden layer activations that get passed from one time-step to the next. This allows a uni-directional RNN to take information from the past to process later inputs. A bidirection RNN can take context from both the past and the future. 

**Notation**:
- Superscript $[l]$ denotes an object associated with the $l^{th}$ layer. 
    - Example: $a^{[4]}$ is the $4^{th}$ layer activation. $W^{[5]}$ and $b^{[5]}$ are the $5^{th}$ layer parameters.

- Superscript $(i)$ denotes an object associated with the $i^{th}$ example. 
    - Example: $x^{(i)}$ is the $i^{th}$ training example input.

- Superscript $\langle t \rangle$ denotes an object at the $t^{th}$ time-step. 
    - Example: $x^{\langle t \rangle}$ is the input x at the $t^{th}$ time-step. $x^{(i)\langle t \rangle}$ is the input at the $t^{th}$ timestep of example $i$.
    
- Lowerscript $i$ denotes the $i^{th}$ entry of a vector.
    - Example: $a^{[l]}_i$ denotes the $i^{th}$ entry of the activations in layer $l$.

We assume that you are already familiar with `numpy` and/or have completed the previous courses of the specialization. Let&#39;s get started!

Let&#39;s first import all the packages that you will need during this assignment.


```python
import numpy as np
from rnn_utils import *
```

## 1 - Forward propagation for the basic Recurrent Neural Network

Later this week, you will generate music using an RNN. The basic RNN that you will implement has the structure below. In this example, $T_x = T_y$. 

&lt;img src=&quot;https://raw.githubusercontent.com/karenyyy/Coursera_and_Udemy/master/deeplearningai_coursera/Sequence%20Models/images/RNN.png&quot; style=&quot;width:500;height:300px;&quot;&gt;
&lt;caption&gt;&lt;center&gt; **Figure 1**: Basic RNN model &lt;/center&gt;&lt;/caption&gt;

Here&#39;s how you can implement an RNN: 

**Steps**:
1. Implement the calculations needed for one time-step of the RNN.
2. Implement a loop over $T_x$ time-steps in order to process all the inputs, one at a time. 

Let&#39;s go!

## 1.1 - RNN cell

A Recurrent neural network can be seen as the repetition of a single cell. You are first going to implement the computations for a single time-step. The following figure describes the operations for a single time-step of an RNN cell. 

&lt;img src=&quot;https://raw.githubusercontent.com/karenyyy/Coursera_and_Udemy/master/deeplearningai_coursera/Sequence%20Models/images/rnn_step_forward.png&quot; style=&quot;width:700px;height:300px;&quot;&gt;
&lt;caption&gt;&lt;center&gt; **Figure 2**: Basic RNN cell. Takes as input $x^{\langle t \rangle}$ (current input) and $a^{\langle t - 1\rangle}$ (previous hidden state containing information from the past), and outputs $a^{\langle t \rangle}$ which is given to the next RNN cell and also used to predict $y^{\langle t \rangle}$ &lt;/center&gt;&lt;/caption&gt;

**Exercise**: Implement the RNN-cell described in Figure (2).

**Instructions**:
1. Compute the hidden state with tanh activation: $a^{\langle t \rangle} = \tanh(W_{aa} a^{\langle t-1 \rangle} + W_{ax} x^{\langle t \rangle} + b_a)$.
2. Using your new hidden state $a^{\langle t \rangle}$, compute the prediction $\hat{y}^{\langle t \rangle} = softmax(W_{ya} a^{\langle t \rangle} + b_y)$. We provided you a function: `softmax`.
3. Store $(a^{\langle t \rangle}, a^{\langle t-1 \rangle}, x^{\langle t \rangle}, parameters)$ in cache
4. Return $a^{\langle t \rangle}$ , $y^{\langle t \rangle}$ and cache

We will vectorize over $m$ examples. Thus, $x^{\langle t \rangle}$ will have dimension $(n_x,m)$, and $a^{\langle t \rangle}$ will have dimension $(n_a,m)$. 


```python
# GRADED FUNCTION: rnn_cell_forward

def rnn_cell_forward(xt, a_prev, parameters):
    &quot;&quot;&quot;
    Implements a single forward step of the RNN-cell as described in Figure (2)

    Arguments:
    xt -- your input data at timestep &quot;t&quot;, numpy array of shape (n_x, m).
    a_prev -- Hidden state at timestep &quot;t-1&quot;, numpy array of shape (n_a, m)
    parameters -- python dictionary containing:
                        Wax -- Weight matrix multiplying the input, numpy array of shape (n_a, n_x)
                        Waa -- Weight matrix multiplying the hidden state, numpy array of shape (n_a, n_a)
                        Wya -- Weight matrix relating the hidden-state to the output, numpy array of shape (n_y, n_a)
                        ba --  Bias, numpy array of shape (n_a, 1)
                        by -- Bias relating the hidden-state to the output, numpy array of shape (n_y, 1)
    Returns:
    a_next -- next hidden state, of shape (n_a, m)
    yt_pred -- prediction at timestep &quot;t&quot;, numpy array of shape (n_y, m)
    cache -- tuple of values needed for the backward pass, contains (a_next, a_prev, xt, parameters)
    &quot;&quot;&quot;
    
    # Retrieve parameters from &quot;parameters&quot;
    Wax = parameters[&quot;Wax&quot;]
    Waa = parameters[&quot;Waa&quot;]
    Wya = parameters[&quot;Wya&quot;]
    ba = parameters[&quot;ba&quot;]
    by = parameters[&quot;by&quot;]
    
    
    # compute next activation state using the formula given above
    a_next = np.tanh(np.matmul(Waa,a_prev)+np.matmul(Wax,xt)+ba)
    # compute output of the current cell using the formula given above
    yt_pred = softmax(np.matmul(Wya, a_next)+by)   
    
    
    # store values you need for backward propagation in cache
    cache = (a_next, a_prev, xt, parameters)
    
    return a_next, yt_pred, cache
```


```python
np.random.seed(1)
xt = np.random.randn(3,10)
a_prev = np.random.randn(5,10)
Waa = np.random.randn(5,5)
Wax = np.random.randn(5,3)
Wya = np.random.randn(2,5)
ba = np.random.randn(5,1)
by = np.random.randn(2,1)
parameters = {&quot;Waa&quot;: Waa, &quot;Wax&quot;: Wax, &quot;Wya&quot;: Wya, &quot;ba&quot;: ba, &quot;by&quot;: by}

a_next, yt_pred, cache = rnn_cell_forward(xt, a_prev, parameters)

print(&quot;a_next[4] = &quot;, a_next[4])
print(&quot;a_next.shape = &quot;, a_next.shape)
print(&quot;yt_pred[1] =&quot;, yt_pred[1])
print(&quot;yt_pred.shape = &quot;, yt_pred.shape)
```

    a_next[4] =  [ 0.59584544  0.18141802  0.61311866  0.99808218  0.85016201  0.99980978
     -0.18887155  0.99815551  0.6531151   0.82872037]
    a_next.shape =  (5, 10)
    yt_pred[1] = [ 0.9888161   0.01682021  0.21140899  0.36817467  0.98988387  0.88945212
      0.36920224  0.9966312   0.9982559   0.17746526]
    yt_pred.shape =  (2, 10)


**Expected Output**: 

&lt;table&gt;
    &lt;tr&gt;
        &lt;td&gt;
            **a_next[4]**:
        &lt;/td&gt;
        &lt;td&gt;
           [ 0.59584544  0.18141802  0.61311866  0.99808218  0.85016201  0.99980978
 -0.18887155  0.99815551  0.6531151   0.82872037]
        &lt;/td&gt;
    &lt;/tr&gt;
        &lt;tr&gt;
        &lt;td&gt;
            **a_next.shape**:
        &lt;/td&gt;
        &lt;td&gt;
           (5, 10)
        &lt;/td&gt;
    &lt;/tr&gt;
        &lt;tr&gt;
        &lt;td&gt;
            **yt[1]**:
        &lt;/td&gt;
        &lt;td&gt;
           [ 0.9888161   0.01682021  0.21140899  0.36817467  0.98988387  0.88945212
  0.36920224  0.9966312   0.9982559   0.17746526]
        &lt;/td&gt;
    &lt;/tr&gt;
        &lt;tr&gt;
        &lt;td&gt;
            **yt.shape**:
        &lt;/td&gt;
        &lt;td&gt;
           (2, 10)
        &lt;/td&gt;
    &lt;/tr&gt;

&lt;/table&gt;

## 1.2 - RNN forward pass 

You can see an RNN as the repetition of the cell you&#39;ve just built. If your input sequence of data is carried over 10 time steps, then you will copy the RNN cell 10 times. Each cell takes as input the hidden state from the previous cell ($a^{\langle t-1 \rangle}$) and the current time-step&#39;s input data ($x^{\langle t \rangle}$). It outputs a hidden state ($a^{\langle t \rangle}$) and a prediction ($y^{\langle t \rangle}$) for this time-step.


&lt;img src=&quot;https://raw.githubusercontent.com/karenyyy/Coursera_and_Udemy/master/deeplearningai_coursera/Sequence%20Models/images/rnn.png&quot; style=&quot;width:800px;height:300px;&quot;&gt;
&lt;caption&gt;&lt;center&gt; **Figure 3**: Basic RNN. The input sequence $x = (x^{\langle 1 \rangle}, x^{\langle 2 \rangle}, ..., x^{\langle T_x \rangle})$  is carried over $T_x$ time steps. The network outputs $y = (y^{\langle 1 \rangle}, y^{\langle 2 \rangle}, ..., y^{\langle T_x \rangle})$. &lt;/center&gt;&lt;/caption&gt;



**Exercise**: Code the forward propagation of the RNN described in Figure (3).

**Instructions**:
1. Create a vector of zeros ($a$) that will store all the hidden states computed by the RNN.
2. Initialize the &quot;next&quot; hidden state as $a_0$ (initial hidden state).
3. Start looping over each time step, your incremental index is $t$ :
    - Update the &quot;next&quot; hidden state and the cache by running `rnn_cell_forward`
    - Store the &quot;next&quot; hidden state in $a$ ($t^{th}$ position) 
    - Store the prediction in y
    - Add the cache to the list of caches
4. Return $a$, $y$ and caches


```python
# GRADED FUNCTION: rnn_forward

def rnn_forward(x, a0, parameters):
    &quot;&quot;&quot;
    Implement the forward propagation of the recurrent neural network described in Figure (3).

    Arguments:
    x -- Input data for every time-step, of shape (n_x, m, T_x).
    a0 -- Initial hidden state, of shape (n_a, m)
    parameters -- python dictionary containing:
                        Waa -- Weight matrix multiplying the hidden state, numpy array of shape (n_a, n_a)
                        Wax -- Weight matrix multiplying the input, numpy array of shape (n_a, n_x)
                        Wya -- Weight matrix relating the hidden-state to the output, numpy array of shape (n_y, n_a)
                        ba --  Bias numpy array of shape (n_a, 1)
                        by -- Bias relating the hidden-state to the output, numpy array of shape (n_y, 1)

    Returns:
    a -- Hidden states for every time-step, numpy array of shape (n_a, m, T_x)
    y_pred -- Predictions for every time-step, numpy array of shape (n_y, m, T_x)
    caches -- tuple of values needed for the backward pass, contains (list of caches, x)
    &quot;&quot;&quot;
    
    # Initialize &quot;caches&quot; which will contain the list of all caches
    caches = []
    
    # Retrieve dimensions from shapes of x and parameters[&quot;Wya&quot;]
    n_x, m, T_x = x.shape
    n_y, n_a = parameters[&quot;Wya&quot;].shape
    
    
    
    # initialize &quot;a&quot; and &quot;y&quot; with zeros (≈2 lines)
    a = np.zeros((n_a, m, T_x))
    y_pred = np.zeros((n_y, m, T_x))
    
    # Initialize a_next (≈1 line)
    a_next = a0
    
    # loop over all time-steps
    for t in range(T_x):
        # Update next hidden state, compute the prediction, get the cache (≈1 line)
        a_next, yt_pred, cache = rnn_cell_forward(x[:,:,t], a_next, parameters)
        # Save the value of the new &quot;next&quot; hidden state in a (≈1 line)
        a[:,:,t] = a_next
        # Save the value of the prediction in y (≈1 line)
        y_pred[:,:,t] = yt_pred
        # Append &quot;cache&quot; to &quot;caches&quot; (≈1 line)
        caches.append(cache)
        
    
    
    # store values needed for backward propagation in cache
    caches = (caches, x)
    
    return a, y_pred, caches
```


```python
np.random.seed(1)
x = np.random.randn(3,10,4)
a0 = np.random.randn(5,10)
Waa = np.random.randn(5,5)
Wax = np.random.randn(5,3)
Wya = np.random.randn(2,5)
ba = np.random.randn(5,1)
by = np.random.randn(2,1)
parameters = {&quot;Waa&quot;: Waa, &quot;Wax&quot;: Wax, &quot;Wya&quot;: Wya, &quot;ba&quot;: ba, &quot;by&quot;: by}

a, y_pred, caches = rnn_forward(x, a0, parameters)
print(&quot;a[4][1] = &quot;, a[4][1])
print(&quot;a.shape = &quot;, a.shape)
print(&quot;y_pred[1][3] =&quot;, y_pred[1][3])
print(&quot;y_pred.shape = &quot;, y_pred.shape)
print(&quot;caches[1][1][3] =&quot;, caches[1][1][3])
print(&quot;len(caches) = &quot;, len(caches))
```

    a[4][1] =  [-0.99999375  0.77911235 -0.99861469 -0.99833267]
    a.shape =  (5, 10, 4)
    y_pred[1][3] = [ 0.79560373  0.86224861  0.11118257  0.81515947]
    y_pred.shape =  (2, 10, 4)
    caches[1][1][3] = [-1.1425182  -0.34934272 -0.20889423  0.58662319]
    len(caches) =  2


**Expected Output**:

&lt;table&gt;
    &lt;tr&gt;
        &lt;td&gt;
            **a[4][1]**:
        &lt;/td&gt;
        &lt;td&gt;
           [-0.99999375  0.77911235 -0.99861469 -0.99833267]
        &lt;/td&gt;
    &lt;/tr&gt;
        &lt;tr&gt;
        &lt;td&gt;
            **a.shape**:
        &lt;/td&gt;
        &lt;td&gt;
           (5, 10, 4)
        &lt;/td&gt;
    &lt;/tr&gt;
        &lt;tr&gt;
        &lt;td&gt;
            **y[1][3]**:
        &lt;/td&gt;
        &lt;td&gt;
           [ 0.79560373  0.86224861  0.11118257  0.81515947]
        &lt;/td&gt;
    &lt;/tr&gt;
        &lt;tr&gt;
        &lt;td&gt;
            **y.shape**:
        &lt;/td&gt;
        &lt;td&gt;
           (2, 10, 4)
        &lt;/td&gt;
    &lt;/tr&gt;
        &lt;tr&gt;
        &lt;td&gt;
            **cache[1][1][3]**:
        &lt;/td&gt;
        &lt;td&gt;
           [-1.1425182  -0.34934272 -0.20889423  0.58662319]
        &lt;/td&gt;
    &lt;/tr&gt;
        &lt;tr&gt;
        &lt;td&gt;
            **len(cache)**:
        &lt;/td&gt;
        &lt;td&gt;
           2
        &lt;/td&gt;
    &lt;/tr&gt;

&lt;/table&gt;

Congratulations! You&#39;ve successfully built the forward propagation of a recurrent neural network from scratch. This will work well enough for some applications, but it suffers from vanishing gradient problems. So it works best when each output $y^{\langle t \rangle}$ can be estimated using mainly &quot;local&quot; context (meaning information from inputs $x^{\langle t&#39; \rangle}$ where $t&#39;$ is not too far from $t$). 

In the next part, you will build a more complex LSTM model, which is better at addressing vanishing gradients. The LSTM will be better able to remember a piece of information and keep it saved for many timesteps. 

## 2 - Long Short-Term Memory (LSTM) network

This following figure shows the operations of an LSTM-cell.

&lt;img src=&quot;https://raw.githubusercontent.com/karenyyy/Coursera_and_Udemy/master/deeplearningai_coursera/Sequence%20Models/images/LSTM.png&quot; style=&quot;width:500;height:400px;&quot;&gt;
&lt;caption&gt;&lt;center&gt; **Figure 4**: LSTM-cell. This tracks and updates a &quot;cell state&quot; or memory variable $c^{\langle t \rangle}$ at every time-step, which can be different from $a^{\langle t \rangle}$. &lt;/center&gt;&lt;/caption&gt;

Similar to the RNN example above, you will start by implementing the LSTM cell for a single time-step. Then you can iteratively call it from inside a for-loop to have it process an input with $T_x$ time-steps. 

### About the gates

#### - Forget gate

For the sake of this illustration, lets assume we are reading words in a piece of text, and want use an LSTM to keep track of grammatical structures, such as whether the subject is singular or plural. If the subject changes from a singular word to a plural word, we need to find a way to get rid of our previously stored memory value of the singular/plural state. In an LSTM, the forget gate lets us do this: 

$$\Gamma_f^{\langle t \rangle} = \sigma(W_f[a^{\langle t-1 \rangle}, x^{\langle t \rangle}] + b_f)\tag{1} $$

Here, $W_f$ are weights that govern the forget gate&#39;s behavior. We concatenate $[a^{\langle t-1 \rangle}, x^{\langle t \rangle}]$ and multiply by $W_f$. The equation above results in a vector $\Gamma_f^{\langle t \rangle}$ with values between 0 and 1. This forget gate vector will be multiplied element-wise by the previous cell state $c^{\langle t-1 \rangle}$. So if one of the values of $\Gamma_f^{\langle t \rangle}$ is 0 (or close to 0) then it means that the LSTM should remove that piece of information (e.g. the singular subject) in the corresponding component of $c^{\langle t-1 \rangle}$. If one of the values is 1, then it will keep the information. 

#### - Update gate

Once we forget that the subject being discussed is singular, we need to find a way to update it to reflect that the new subject is now plural. Here is the formulat for the update gate: 

$$\Gamma_u^{\langle t \rangle} = \sigma(W_u[a^{\langle t-1 \rangle}, x^{\{t\}}] + b_u)\tag{2} $$ 

Similar to the forget gate, here $\Gamma_u^{\langle t \rangle}$ is again a vector of values between 0 and 1. This will be multiplied element-wise with $\tilde{c}^{\langle t \rangle}$, in order to compute $c^{\langle t \rangle}$.

#### - Updating the cell 

To update the new subject we need to create a new vector of numbers that we can add to our previous cell state. The equation we use is: 

$$ \tilde{c}^{\langle t \rangle} = \tanh(W_c[a^{\langle t-1 \rangle}, x^{\langle t \rangle}] + b_c)\tag{3} $$

Finally, the new cell state is: 

$$ c^{\langle t \rangle} = \Gamma_f^{\langle t \rangle}* c^{\langle t-1 \rangle} + \Gamma_u^{\langle t \rangle} *\tilde{c}^{\langle t \rangle} \tag{4} $$


#### - Output gate

To decide which outputs we will use, we will use the following two formulas: 

$$ \Gamma_o^{\langle t \rangle}=  \sigma(W_o[a^{\langle t-1 \rangle}, x^{\langle t \rangle}] + b_o)\tag{5}$$ 
$$ a^{\langle t \rangle} = \Gamma_o^{\langle t \rangle}* \tanh(c^{\langle t \rangle})\tag{6} $$

Where in equation 5 you decide what to output using a sigmoid function and in equation 6 you multiply that by the $\tanh$ of the previous state. 

### 2.1 - LSTM cell

**Exercise**: Implement the LSTM cell described in the Figure (3).

**Instructions**:
1. Concatenate $a^{\langle t-1 \rangle}$ and $x^{\langle t \rangle}$ in a single matrix: $concat = \begin{bmatrix} a^{\langle t-1 \rangle} \\ x^{\langle t \rangle} \end{bmatrix}$
2. Compute all the formulas 1-6. You can use `sigmoid()` (provided) and `np.tanh()`.
3. Compute the prediction $y^{\langle t \rangle}$. You can use `softmax()` (provided).


```python
# GRADED FUNCTION: lstm_cell_forward

def lstm_cell_forward(xt, a_prev, c_prev, parameters):
    &quot;&quot;&quot;
    Implement a single forward step of the LSTM-cell as described in Figure (4)

    Arguments:
    xt -- your input data at timestep &quot;t&quot;, numpy array of shape (n_x, m).
    a_prev -- Hidden state at timestep &quot;t-1&quot;, numpy array of shape (n_a, m)
    c_prev -- Memory state at timestep &quot;t-1&quot;, numpy array of shape (n_a, m)
    parameters -- python dictionary containing:
                        Wf -- Weight matrix of the forget gate, numpy array of shape (n_a, n_a + n_x)
                        bf -- Bias of the forget gate, numpy array of shape (n_a, 1)
                        Wi -- Weight matrix of the update gate, numpy array of shape (n_a, n_a + n_x)
                        bi -- Bias of the update gate, numpy array of shape (n_a, 1)
                        Wc -- Weight matrix of the first &quot;tanh&quot;, numpy array of shape (n_a, n_a + n_x)
                        bc --  Bias of the first &quot;tanh&quot;, numpy array of shape (n_a, 1)
                        Wo -- Weight matrix of the output gate, numpy array of shape (n_a, n_a + n_x)
                        bo --  Bias of the output gate, numpy array of shape (n_a, 1)
                        Wy -- Weight matrix relating the hidden-state to the output, numpy array of shape (n_y, n_a)
                        by -- Bias relating the hidden-state to the output, numpy array of shape (n_y, 1)
                        
    Returns:
    a_next -- next hidden state, of shape (n_a, m)
    c_next -- next memory state, of shape (n_a, m)
    yt_pred -- prediction at timestep &quot;t&quot;, numpy array of shape (n_y, m)
    cache -- tuple of values needed for the backward pass, contains (a_next, c_next, a_prev, c_prev, xt, parameters)
    
    Note: ft/it/ot stand for the forget/update/output gates, cct stands for the candidate value (c tilde),
          c stands for the memory value
    &quot;&quot;&quot;

    # Retrieve parameters from &quot;parameters&quot;
    Wf = parameters[&quot;Wf&quot;]
    bf = parameters[&quot;bf&quot;]
    Wi = parameters[&quot;Wi&quot;]
    bi = parameters[&quot;bi&quot;]
    Wc = parameters[&quot;Wc&quot;]
    bc = parameters[&quot;bc&quot;]
    Wo = parameters[&quot;Wo&quot;]
    bo = parameters[&quot;bo&quot;]
    Wy = parameters[&quot;Wy&quot;]
    by = parameters[&quot;by&quot;]
    
    # Retrieve dimensions from shapes of xt and Wy
    n_x, m = xt.shape
    n_y, n_a = Wy.shape

    
    # Concatenate a_prev and xt (≈3 lines)
    concat = np.zeros((n_a+n_x, m))
    concat[: n_a, :] = a_prev
    concat[n_a :, :] = xt

    # Compute values for ft, it, cct, c_next, ot, a_next using the formulas given figure (4) (≈6 lines)
    ft = sigmoid(np.matmul(Wf, concat)+bf)
    it = sigmoid(np.matmul(Wi, concat)+bi)
    cct = np.tanh(np.matmul(Wc, concat)+bc)
    c_next = ft*c_prev + it*cct
    ot = sigmoid(np.matmul(Wo, concat)+bo)
    a_next = ot*np.tanh(c_next)
    
    # Compute prediction of the LSTM cell (≈1 line)
    yt_pred = softmax(np.matmul(Wy, a_next)+by)
    

    # store values needed for backward propagation in cache
    cache = (a_next, c_next, a_prev, c_prev, ft, it, cct, ot, xt, parameters)

    return a_next, c_next, yt_pred, cache
```


```python
np.random.seed(1)
xt = np.random.randn(3,10)
a_prev = np.random.randn(5,10)
c_prev = np.random.randn(5,10)
Wf = np.random.randn(5, 5+3)
bf = np.random.randn(5,1)
Wi = np.random.randn(5, 5+3)
bi = np.random.randn(5,1)
Wo = np.random.randn(5, 5+3)
bo = np.random.randn(5,1)
Wc = np.random.randn(5, 5+3)
bc = np.random.randn(5,1)
Wy = np.random.randn(2,5)
by = np.random.randn(2,1)

parameters = {&quot;Wf&quot;: Wf, &quot;Wi&quot;: Wi, &quot;Wo&quot;: Wo, &quot;Wc&quot;: Wc, &quot;Wy&quot;: Wy, &quot;bf&quot;: bf, &quot;bi&quot;: bi, &quot;bo&quot;: bo, &quot;bc&quot;: bc, &quot;by&quot;: by}

a_next, c_next, yt, cache = lstm_cell_forward(xt, a_prev, c_prev, parameters)
print(&quot;a_next[4] = &quot;, a_next[4])
print(&quot;a_next.shape = &quot;, c_next.shape)
print(&quot;c_next[2] = &quot;, c_next[2])
print(&quot;c_next.shape = &quot;, c_next.shape)
print(&quot;yt[1] =&quot;, yt[1])
print(&quot;yt.shape = &quot;, yt.shape)
print(&quot;cache[1][3] =&quot;, cache[1][3])
print(&quot;len(cache) = &quot;, len(cache))
```

    a_next[4] =  [-0.66408471  0.0036921   0.02088357  0.22834167 -0.85575339  0.00138482
      0.76566531  0.34631421 -0.00215674  0.43827275]
    a_next.shape =  (5, 10)
    c_next[2] =  [ 0.63267805  1.00570849  0.35504474  0.20690913 -1.64566718  0.11832942
      0.76449811 -0.0981561  -0.74348425 -0.26810932]
    c_next.shape =  (5, 10)
    yt[1] = [ 0.79913913  0.15986619  0.22412122  0.15606108  0.97057211  0.31146381
      0.00943007  0.12666353  0.39380172  0.07828381]
    yt.shape =  (2, 10)
    cache[1][3] = [-0.16263996  1.03729328  0.72938082 -0.54101719  0.02752074 -0.30821874
      0.07651101 -1.03752894  1.41219977 -0.37647422]
    len(cache) =  10


**Expected Output**:

&lt;table&gt;
    &lt;tr&gt;
        &lt;td&gt;
            **a_next[4]**:
        &lt;/td&gt;
        &lt;td&gt;
           [-0.66408471  0.0036921   0.02088357  0.22834167 -0.85575339  0.00138482
  0.76566531  0.34631421 -0.00215674  0.43827275]
        &lt;/td&gt;
    &lt;/tr&gt;
        &lt;tr&gt;
        &lt;td&gt;
            **a_next.shape**:
        &lt;/td&gt;
        &lt;td&gt;
           (5, 10)
        &lt;/td&gt;
    &lt;/tr&gt;
        &lt;tr&gt;
        &lt;td&gt;
            **c_next[2]**:
        &lt;/td&gt;
        &lt;td&gt;
           [ 0.63267805  1.00570849  0.35504474  0.20690913 -1.64566718  0.11832942
  0.76449811 -0.0981561  -0.74348425 -0.26810932]
        &lt;/td&gt;
    &lt;/tr&gt;
        &lt;tr&gt;
        &lt;td&gt;
            **c_next.shape**:
        &lt;/td&gt;
        &lt;td&gt;
           (5, 10)
        &lt;/td&gt;
    &lt;/tr&gt;
        &lt;tr&gt;
        &lt;td&gt;
            **yt[1]**:
        &lt;/td&gt;
        &lt;td&gt;
           [ 0.79913913  0.15986619  0.22412122  0.15606108  0.97057211  0.31146381
  0.00943007  0.12666353  0.39380172  0.07828381]
        &lt;/td&gt;
    &lt;/tr&gt;
        &lt;tr&gt;
        &lt;td&gt;
            **yt.shape**:
        &lt;/td&gt;
        &lt;td&gt;
           (2, 10)
        &lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
        &lt;td&gt;
            **cache[1][3]**:
        &lt;/td&gt;
        &lt;td&gt;
           [-0.16263996  1.03729328  0.72938082 -0.54101719  0.02752074 -0.30821874
  0.07651101 -1.03752894  1.41219977 -0.37647422]
        &lt;/td&gt;
    &lt;/tr&gt;
        &lt;tr&gt;
        &lt;td&gt;
            **len(cache)**:
        &lt;/td&gt;
        &lt;td&gt;
           10
        &lt;/td&gt;
    &lt;/tr&gt;

&lt;/table&gt;

### 2.2 - Forward pass for LSTM

Now that you have implemented one step of an LSTM, you can now iterate this over this using a for-loop to process a sequence of $T_x$ inputs. 

&lt;img src=&quot;https://raw.githubusercontent.com/karenyyy/Coursera_and_Udemy/master/deeplearningai_coursera/Sequence%20Models/images/LSTM_rnn.png&quot; style=&quot;width:500;height:300px;&quot;&gt;
&lt;caption&gt;&lt;center&gt; **Figure 4**: LSTM over multiple time-steps. &lt;/center&gt;&lt;/caption&gt;

**Exercise:** Implement `lstm_forward()` to run an LSTM over $T_x$ time-steps. 

**Note**: $c^{\langle 0 \rangle}$ is initialized with zeros.


```python
# GRADED FUNCTION: lstm_forward

def lstm_forward(x, a0, parameters):
    &quot;&quot;&quot;
    Implement the forward propagation of the recurrent neural network using an LSTM-cell described in Figure (3).

    Arguments:
    x -- Input data for every time-step, of shape (n_x, m, T_x).
    a0 -- Initial hidden state, of shape (n_a, m)
    parameters -- python dictionary containing:
                        Wf -- Weight matrix of the forget gate, numpy array of shape (n_a, n_a + n_x)
                        bf -- Bias of the forget gate, numpy array of shape (n_a, 1)
                        Wi -- Weight matrix of the update gate, numpy array of shape (n_a, n_a + n_x)
                        bi -- Bias of the update gate, numpy array of shape (n_a, 1)
                        Wc -- Weight matrix of the first &quot;tanh&quot;, numpy array of shape (n_a, n_a + n_x)
                        bc -- Bias of the first &quot;tanh&quot;, numpy array of shape (n_a, 1)
                        Wo -- Weight matrix of the output gate, numpy array of shape (n_a, n_a + n_x)
                        bo -- Bias of the output gate, numpy array of shape (n_a, 1)
                        Wy -- Weight matrix relating the hidden-state to the output, numpy array of shape (n_y, n_a)
                        by -- Bias relating the hidden-state to the output, numpy array of shape (n_y, 1)
                        
    Returns:
    a -- Hidden states for every time-step, numpy array of shape (n_a, m, T_x)
    y -- Predictions for every time-step, numpy array of shape (n_y, m, T_x)
    caches -- tuple of values needed for the backward pass, contains (list of all the caches, x)
    &quot;&quot;&quot;

    # Initialize &quot;caches&quot;, which will track the list of all the caches
    caches = []
    
    
    # Retrieve dimensions from shapes of x and parameters[&#39;Wy&#39;] (≈2 lines)
    n_x, m, T_x = x.shape
    n_y, n_a = parameters[&#39;Wy&#39;].shape
    
    # initialize &quot;a&quot;, &quot;c&quot; and &quot;y&quot; with zeros (≈3 lines)
    a = np.zeros((n_a, m, T_x))
    c = np.zeros((n_a, m, T_x))
    y = np.zeros((n_y, m, T_x))
    
    # Initialize a_next and c_next (≈2 lines)
    a_next = a0
    c_next = np.zeros(a0.shape)
    
    # loop over all time-steps
    for t in range(T_x):
        # Update next hidden state, next memory state, compute the prediction, get the cache (≈1 line)
        a_next, c_next, yt, cache = lstm_cell_forward(x[:,:,t], a_next, c_next, parameters)
        # Save the value of the new &quot;next&quot; hidden state in a (≈1 line)
        a[:,:,t] = a_next
        # Save the value of the prediction in y (≈1 line)
        y[:,:,t] = yt
        # Save the value of the next cell state (≈1 line)
        c[:,:,t]  = c_next
        # Append the cache into caches (≈1 line)
        caches.append(cache)
        
    
    
    # store values needed for backward propagation in cache
    caches = (caches, x)

    return a, y, c, caches
```


```python
np.random.seed(1)
x = np.random.randn(3,10,7)
a0 = np.random.randn(5,10)
Wf = np.random.randn(5, 5+3)
bf = np.random.randn(5,1)
Wi = np.random.randn(5, 5+3)
bi = np.random.randn(5,1)
Wo = np.random.randn(5, 5+3)
bo = np.random.randn(5,1)
Wc = np.random.randn(5, 5+3)
bc = np.random.randn(5,1)
Wy = np.random.randn(2,5)
by = np.random.randn(2,1)

parameters = {&quot;Wf&quot;: Wf, &quot;Wi&quot;: Wi, &quot;Wo&quot;: Wo, &quot;Wc&quot;: Wc, &quot;Wy&quot;: Wy, &quot;bf&quot;: bf, &quot;bi&quot;: bi, &quot;bo&quot;: bo, &quot;bc&quot;: bc, &quot;by&quot;: by}

a, y, c, caches = lstm_forward(x, a0, parameters)
print(&quot;a[4][3][6] = &quot;, a[4][3][6])
print(&quot;a.shape = &quot;, a.shape)
print(&quot;y[1][4][3] =&quot;, y[1][4][3])
print(&quot;y.shape = &quot;, y.shape)
print(&quot;caches[1][1[1]] =&quot;, caches[1][1][1])
print(&quot;c[1][2][1]&quot;, c[1][2][1])
print(&quot;len(caches) = &quot;, len(caches))
```

    a[4][3][6] =  0.172117767533
    a.shape =  (5, 10, 7)
    y[1][4][3] = 0.95087346185
    y.shape =  (2, 10, 7)
    caches[1][1[1]] = [ 0.82797464  0.23009474  0.76201118 -0.22232814 -0.20075807  0.18656139
      0.41005165]
    c[1][2][1] -0.855544916718
    len(caches) =  2


**Expected Output**:

&lt;table&gt;
    &lt;tr&gt;
        &lt;td&gt;
            **a[4][3][6]** =
        &lt;/td&gt;
        &lt;td&gt;
           0.172117767533
        &lt;/td&gt;
    &lt;/tr&gt;
        &lt;tr&gt;
        &lt;td&gt;
            **a.shape** =
        &lt;/td&gt;
        &lt;td&gt;
           (5, 10, 7)
        &lt;/td&gt;
    &lt;/tr&gt;
        &lt;tr&gt;
        &lt;td&gt;
            **y[1][4][3]** =
        &lt;/td&gt;
        &lt;td&gt;
           0.95087346185
        &lt;/td&gt;
    &lt;/tr&gt;
        &lt;tr&gt;
        &lt;td&gt;
            **y.shape** =
        &lt;/td&gt;
        &lt;td&gt;
           (2, 10, 7)
        &lt;/td&gt;
    &lt;/tr&gt;
        &lt;tr&gt;
        &lt;td&gt;
            **caches[1][1][1]** =
        &lt;/td&gt;
        &lt;td&gt;
           [ 0.82797464  0.23009474  0.76201118 -0.22232814 -0.20075807  0.18656139
  0.41005165]
        &lt;/td&gt;
        
     &lt;/tr&gt;
        &lt;tr&gt;
        &lt;td&gt;
            **c[1][2][1]** =
        &lt;/td&gt;
        &lt;td&gt;
           -0.855544916718
        &lt;/td&gt;
    &lt;/tr&gt;       
        
    &lt;/tr&gt;
        &lt;tr&gt;
        &lt;td&gt;
            **len(caches)** =
        &lt;/td&gt;
        &lt;td&gt;
           2
        &lt;/td&gt;
    &lt;/tr&gt;

&lt;/table&gt;

Congratulations! You have now implemented the forward passes for the basic RNN and the LSTM. When using a deep learning framework, implementing the forward pass is sufficient to build systems that achieve great performance. 

The rest of this notebook is optional, and will not be graded.

## 3 - Backpropagation in recurrent neural networks (OPTIONAL / UNGRADED)

In modern deep learning frameworks, you only have to implement the forward pass, and the framework takes care of the backward pass, so most deep learning engineers do not need to bother with the details of the backward pass. If however you are an expert in calculus and want to see the details of backprop in RNNs, you can work through this optional portion of the notebook. 

When in an earlier course you implemented a simple (fully connected) neural network, you used backpropagation to compute the derivatives with respect to the cost to update the parameters. Similarly, in recurrent neural networks you can to calculate the derivatives with respect to the cost in order to update the parameters. The backprop equations are quite complicated and we did not derive them in lecture. However, we will briefly present them below. 

### 3.1 - Basic RNN  backward pass

We will start by computing the backward pass for the basic RNN-cell.

&lt;img src=&quot;https://raw.githubusercontent.com/karenyyy/Coursera_and_Udemy/master/deeplearningai_coursera/Sequence%20Models/images/rnn_cell_backprop.png&quot; style=&quot;width:500;height:300px;&quot;&gt; &lt;br&gt;
&lt;caption&gt;&lt;center&gt; **Figure 5**: RNN-cell&#39;s backward pass. Just like in a fully-connected neural network, the derivative of the cost function $J$ backpropagates through the RNN by following the chain-rule from calculas. The chain-rule is also used to calculate $(\frac{\partial J}{\partial W_{ax}},\frac{\partial J}{\partial W_{aa}},\frac{\partial J}{\partial b})$ to update the parameters $(W_{ax}, W_{aa}, b_a)$. &lt;/center&gt;&lt;/caption&gt;

#### Deriving the one step backward functions: 

To compute the `rnn_cell_backward` you need to compute the following equations. It is a good exercise to derive them by hand. 

The derivative of $\tanh$ is $1-\tanh(x)^2$. You can find the complete proof [here](https://www.wyzant.com/resources/lessons/math/calculus/derivative_proofs/tanx). Note that: $ \text{sech}(x)^2 = 1 - \tanh(x)^2$

Similarly for $\frac{ \partial a^{\langle t \rangle} } {\partial W_{ax}}, \frac{ \partial a^{\langle t \rangle} } {\partial W_{aa}},  \frac{ \partial a^{\langle t \rangle} } {\partial b}$, the derivative of  $\tanh(u)$ is $(1-\tanh(u)^2)du$. 

The final two equations also follow same rule and are derived using the $\tanh$ derivative. Note that the arrangement is done in a way to get the same dimensions to match.


```python
def rnn_cell_backward(da_next, cache):
    &quot;&quot;&quot;
    Implements the backward pass for the RNN-cell (single time-step).

    Arguments:
    da_next -- Gradient of loss with respect to next hidden state
    cache -- python dictionary containing useful values (output of rnn_cell_forward())

    Returns:
    gradients -- python dictionary containing:
                        dx -- Gradients of input data, of shape (n_x, m)
                        da_prev -- Gradients of previous hidden state, of shape (n_a, m)
                        dWax -- Gradients of input-to-hidden weights, of shape (n_a, n_x)
                        dWaa -- Gradients of hidden-to-hidden weights, of shape (n_a, n_a)
                        dba -- Gradients of bias vector, of shape (n_a, 1)
    &quot;&quot;&quot;
    
    # Retrieve values from cache
    (a_next, a_prev, xt, parameters) = cache

    # Retrieve values from parameters
    Wax = parameters[&quot;Wax&quot;]
    Waa = parameters[&quot;Waa&quot;]
    Wya = parameters[&quot;Wya&quot;]
    ba = parameters[&quot;ba&quot;]
    by = parameters[&quot;by&quot;]

    
    # compute the gradient of tanh with respect to a_next (≈1 line)
    dtanh = (1-a_next**2)*da_next  

    # compute the gradient of the loss with respect to Wax (≈2 lines)
    dxt = np.dot(Wax.T, dtanh)   # formula 6
    dWax = np.dot(dtanh, xt.T)   # formula 3

    # compute the gradient with respect to Waa (≈2 lines)
    da_prev = np.dot(Waa.T, dtanh) # formula 7
    dWaa = np.dot( dtanh,a_prev.T) # formula 4

    # compute the gradient with respect to b (≈1 line)
    dba = np.sum( dtanh,keepdims=True,axis=-1) # formula 5

    

    # Store the gradients in a python dictionary
    gradients = {&quot;dxt&quot;: dxt, &quot;da_prev&quot;: da_prev, &quot;dWax&quot;: dWax, &quot;dWaa&quot;: dWaa, &quot;dba&quot;: dba}

    return gradients
```


```python
np.random.seed(1)
xt = np.random.randn(3,10)
a_prev = np.random.randn(5,10)
Wax = np.random.randn(5,3)
Waa = np.random.randn(5,5)
Wya = np.random.randn(2,5)
b = np.random.randn(5,1)
by = np.random.randn(2,1)
parameters = {&quot;Wax&quot;: Wax, &quot;Waa&quot;: Waa, &quot;Wya&quot;: Wya, &quot;ba&quot;: ba, &quot;by&quot;: by}

a_next, yt, cache = rnn_cell_forward(xt, a_prev, parameters)

da_next = np.random.randn(5,10)
gradients = rnn_cell_backward(da_next, cache)
print(&quot;gradients[\&quot;dxt\&quot;][1][2] =&quot;, gradients[&quot;dxt&quot;][1][2])
print(&quot;gradients[\&quot;dxt\&quot;].shape =&quot;, gradients[&quot;dxt&quot;].shape)
print(&quot;gradients[\&quot;da_prev\&quot;][2][3] =&quot;, gradients[&quot;da_prev&quot;][2][3])
print(&quot;gradients[\&quot;da_prev\&quot;].shape =&quot;, gradients[&quot;da_prev&quot;].shape)
print(&quot;gradients[\&quot;dWax\&quot;][3][1] =&quot;, gradients[&quot;dWax&quot;][3][1])
print(&quot;gradients[\&quot;dWax\&quot;].shape =&quot;, gradients[&quot;dWax&quot;].shape)
print(&quot;gradients[\&quot;dWaa\&quot;][1][2] =&quot;, gradients[&quot;dWaa&quot;][1][2])
print(&quot;gradients[\&quot;dWaa\&quot;].shape =&quot;, gradients[&quot;dWaa&quot;].shape)
print(&quot;gradients[\&quot;dba\&quot;][4] =&quot;, gradients[&quot;dba&quot;][4])
print(&quot;gradients[\&quot;dba\&quot;].shape =&quot;, gradients[&quot;dba&quot;].shape)
```

    gradients[&quot;dxt&quot;][1][2] = -0.460564103059
    gradients[&quot;dxt&quot;].shape = (3, 10)
    gradients[&quot;da_prev&quot;][2][3] = 0.0842968653807
    gradients[&quot;da_prev&quot;].shape = (5, 10)
    gradients[&quot;dWax&quot;][3][1] = 0.393081873922
    gradients[&quot;dWax&quot;].shape = (5, 3)
    gradients[&quot;dWaa&quot;][1][2] = -0.28483955787
    gradients[&quot;dWaa&quot;].shape = (5, 5)
    gradients[&quot;dba&quot;][4] = [ 0.80517166]
    gradients[&quot;dba&quot;].shape = (5, 1)


**Expected Output**:

&lt;table&gt;
    &lt;tr&gt;
        &lt;td&gt;
            **gradients[&quot;dxt&quot;][1][2]** =
        &lt;/td&gt;
        &lt;td&gt;
           -0.460564103059
        &lt;/td&gt;
    &lt;/tr&gt;
        &lt;tr&gt;
        &lt;td&gt;
            **gradients[&quot;dxt&quot;].shape** =
        &lt;/td&gt;
        &lt;td&gt;
           (3, 10)
        &lt;/td&gt;
    &lt;/tr&gt;
        &lt;tr&gt;
        &lt;td&gt;
            **gradients[&quot;da_prev&quot;][2][3]** =
        &lt;/td&gt;
        &lt;td&gt;
           0.0842968653807
        &lt;/td&gt;
    &lt;/tr&gt;
        &lt;tr&gt;
        &lt;td&gt;
            **gradients[&quot;da_prev&quot;].shape** =
        &lt;/td&gt;
        &lt;td&gt;
           (5, 10)
        &lt;/td&gt;
    &lt;/tr&gt;
        &lt;tr&gt;
        &lt;td&gt;
            **gradients[&quot;dWax&quot;][3][1]** =
        &lt;/td&gt;
        &lt;td&gt;
           0.393081873922
        &lt;/td&gt;
    &lt;/tr&gt;
            &lt;tr&gt;
        &lt;td&gt;
            **gradients[&quot;dWax&quot;].shape** =
        &lt;/td&gt;
        &lt;td&gt;
           (5, 3)
        &lt;/td&gt;
    &lt;/tr&gt;
        &lt;tr&gt;
        &lt;td&gt;
            **gradients[&quot;dWaa&quot;][1][2]** = 
        &lt;/td&gt;
        &lt;td&gt;
           -0.28483955787
        &lt;/td&gt;
    &lt;/tr&gt;
        &lt;tr&gt;
        &lt;td&gt;
            **gradients[&quot;dWaa&quot;].shape** =
        &lt;/td&gt;
        &lt;td&gt;
           (5, 5)
        &lt;/td&gt;
    &lt;/tr&gt;
        &lt;tr&gt;
        &lt;td&gt;
            **gradients[&quot;dba&quot;][4]** = 
        &lt;/td&gt;
        &lt;td&gt;
           [ 0.80517166]
        &lt;/td&gt;
    &lt;/tr&gt;
        &lt;tr&gt;
        &lt;td&gt;
            **gradients[&quot;dba&quot;].shape** = 
        &lt;/td&gt;
        &lt;td&gt;
           (5, 1)
        &lt;/td&gt;
    &lt;/tr&gt;
&lt;/table&gt;

#### Backward pass through the RNN

Computing the gradients of the cost with respect to $a^{\langle t \rangle}$ at every time-step $t$ is useful because it is what helps the gradient backpropagate to the previous RNN-cell. To do so, you need to iterate through all the time steps starting at the end, and at each step, you increment the overall $db_a$, $dW_{aa}$, $dW_{ax}$ and you store $dx$.

**Instructions**:

Implement the `rnn_backward` function. Initialize the return variables with zeros first and then loop through all the time steps while calling the `rnn_cell_backward` at each time timestep, update the other variables accordingly.


```python
def rnn_backward(da, caches):
    &quot;&quot;&quot;
    Implement the backward pass for a RNN over an entire sequence of input data.

    Arguments:
    da -- Upstream gradients of all hidden states, of shape (n_a, m, T_x)
    caches -- tuple containing information from the forward pass (rnn_forward)
    
    Returns:
    gradients -- python dictionary containing:
                        dx -- Gradient w.r.t. the input data, numpy-array of shape (n_x, m, T_x)
                        da0 -- Gradient w.r.t the initial hidden state, numpy-array of shape (n_a, m)
                        dWax -- Gradient w.r.t the input&#39;s weight matrix, numpy-array of shape (n_a, n_x)
                        dWaa -- Gradient w.r.t the hidden state&#39;s weight matrix, numpy-arrayof shape (n_a, n_a)
                        dba -- Gradient w.r.t the bias, of shape (n_a, 1)
    &quot;&quot;&quot;
        
    
    
    # Retrieve values from the first cache (t=1) of caches (≈2 lines)
    (caches, x) = caches
    (a1, a0, x1, parameters) = caches[0]
    
    # Retrieve dimensions from da&#39;s and x1&#39;s shapes (≈2 lines)
    n_a, m, T_x = da.shape
    n_x, m = x1.shape
    
    # initialize the gradients with the right sizes (≈6 lines)
    dx = np.zeros((n_x, m, T_x))
    dWax = np.zeros((n_a, n_x))
    dWaa = np.zeros((n_a, n_a))
    dba = np.zeros((n_a, 1))
    da0 = np.zeros((n_a, m))
    da_prevt = np.zeros((n_a, m))
    
    # Loop through all the time steps
    for t in reversed(range(T_x)):
        # Compute gradients at time step t. Choose wisely the &quot;da_next&quot; and the &quot;cache&quot; to use in the backward propagation step. (≈1 line)
        gradients = rnn_cell_backward(da[:,:,t]+da_prevt, caches[t])
        # Retrieve derivatives from gradients (≈ 1 line)
        dxt, da_prevt, dWaxt, dWaat, dbat = gradients[&quot;dxt&quot;], gradients[&quot;da_prev&quot;], gradients[&quot;dWax&quot;], gradients[&quot;dWaa&quot;], gradients[&quot;dba&quot;]
        # Increment global derivatives w.r.t parameters by adding their derivative at time-step t (≈4 lines)
        dx[:, :, t] = dxt
        dWax += dWaxt
        dWaa += dWaat
        dba += dbat
        
    # Set da0 to the gradient of a which has been backpropagated through all time-steps (≈1 line) 
    da0 = da_prevt
    

    # Store the gradients in a python dictionary
    gradients = {&quot;dx&quot;: dx, &quot;da0&quot;: da0, &quot;dWax&quot;: dWax, &quot;dWaa&quot;: dWaa,&quot;dba&quot;: dba}
    
    return gradients
```


```python
np.random.seed(1)
x = np.random.randn(3,10,4)
a0 = np.random.randn(5,10)
Wax = np.random.randn(5,3)
Waa = np.random.randn(5,5)
Wya = np.random.randn(2,5)
ba = np.random.randn(5,1)
by = np.random.randn(2,1)
parameters = {&quot;Wax&quot;: Wax, &quot;Waa&quot;: Waa, &quot;Wya&quot;: Wya, &quot;ba&quot;: ba, &quot;by&quot;: by}
a, y, caches = rnn_forward(x, a0, parameters)
da = np.random.randn(5, 10, 4)
gradients = rnn_backward(da, caches)

print(&quot;gradients[\&quot;dx\&quot;][1][2] =&quot;, gradients[&quot;dx&quot;][1][2])
print(&quot;gradients[\&quot;dx\&quot;].shape =&quot;, gradients[&quot;dx&quot;].shape)
print(&quot;gradients[\&quot;da0\&quot;][2][3] =&quot;, gradients[&quot;da0&quot;][2][3])
print(&quot;gradients[\&quot;da0\&quot;].shape =&quot;, gradients[&quot;da0&quot;].shape)
print(&quot;gradients[\&quot;dWax\&quot;][3][1] =&quot;, gradients[&quot;dWax&quot;][3][1])
print(&quot;gradients[\&quot;dWax\&quot;].shape =&quot;, gradients[&quot;dWax&quot;].shape)
print(&quot;gradients[\&quot;dWaa\&quot;][1][2] =&quot;, gradients[&quot;dWaa&quot;][1][2])
print(&quot;gradients[\&quot;dWaa\&quot;].shape =&quot;, gradients[&quot;dWaa&quot;].shape)
print(&quot;gradients[\&quot;dba\&quot;][4] =&quot;, gradients[&quot;dba&quot;][4])
print(&quot;gradients[\&quot;dba\&quot;].shape =&quot;, gradients[&quot;dba&quot;].shape)
```

    gradients[&quot;dx&quot;][1][2] = [-2.07101689 -0.59255627  0.02466855  0.01483317]
    gradients[&quot;dx&quot;].shape = (3, 10, 4)
    gradients[&quot;da0&quot;][2][3] = -0.314942375127
    gradients[&quot;da0&quot;].shape = (5, 10)
    gradients[&quot;dWax&quot;][3][1] = 11.2641044965
    gradients[&quot;dWax&quot;].shape = (5, 3)
    gradients[&quot;dWaa&quot;][1][2] = 2.30333312658
    gradients[&quot;dWaa&quot;].shape = (5, 5)
    gradients[&quot;dba&quot;][4] = [-0.74747722]
    gradients[&quot;dba&quot;].shape = (5, 1)


**Expected Output**:

&lt;table&gt;
    &lt;tr&gt;
        &lt;td&gt;
            **gradients[&quot;dx&quot;][1][2]** =
        &lt;/td&gt;
        &lt;td&gt;
           [-2.07101689 -0.59255627  0.02466855  0.01483317]
        &lt;/td&gt;
    &lt;/tr&gt;
        &lt;tr&gt;
        &lt;td&gt;
            **gradients[&quot;dx&quot;].shape** =
        &lt;/td&gt;
        &lt;td&gt;
           (3, 10, 4)
        &lt;/td&gt;
    &lt;/tr&gt;
        &lt;tr&gt;
        &lt;td&gt;
            **gradients[&quot;da0&quot;][2][3]** =
        &lt;/td&gt;
        &lt;td&gt;
           -0.314942375127
        &lt;/td&gt;
    &lt;/tr&gt;
        &lt;tr&gt;
        &lt;td&gt;
            **gradients[&quot;da0&quot;].shape** =
        &lt;/td&gt;
        &lt;td&gt;
           (5, 10)
        &lt;/td&gt;
    &lt;/tr&gt;
         &lt;tr&gt;
        &lt;td&gt;
            **gradients[&quot;dWax&quot;][3][1]** =
        &lt;/td&gt;
        &lt;td&gt;
           11.2641044965
        &lt;/td&gt;
    &lt;/tr&gt;
        &lt;tr&gt;
        &lt;td&gt;
            **gradients[&quot;dWax&quot;].shape** =
        &lt;/td&gt;
        &lt;td&gt;
           (5, 3)
        &lt;/td&gt;
    &lt;/tr&gt;
        &lt;tr&gt;
        &lt;td&gt;
            **gradients[&quot;dWaa&quot;][1][2]** = 
        &lt;/td&gt;
        &lt;td&gt;
           2.30333312658
        &lt;/td&gt;
    &lt;/tr&gt;
        &lt;tr&gt;
        &lt;td&gt;
            **gradients[&quot;dWaa&quot;].shape** =
        &lt;/td&gt;
        &lt;td&gt;
           (5, 5)
        &lt;/td&gt;
    &lt;/tr&gt;
        &lt;tr&gt;
        &lt;td&gt;
            **gradients[&quot;dba&quot;][4]** = 
        &lt;/td&gt;
        &lt;td&gt;
           [-0.74747722]
        &lt;/td&gt;
    &lt;/tr&gt;
        &lt;tr&gt;
        &lt;td&gt;
            **gradients[&quot;dba&quot;].shape** = 
        &lt;/td&gt;
        &lt;td&gt;
           (5, 1)
        &lt;/td&gt;
    &lt;/tr&gt;
&lt;/table&gt;

## 3.2 - LSTM backward pass

### 3.2.1 One Step backward

The LSTM backward pass is slighltly more complicated than the forward one. We have provided you with all the equations for the LSTM backward pass below. (If you enjoy calculus exercises feel free to try deriving these from scratch yourself.) 

### 3.2.2 gate derivatives

$$d \Gamma_o^{\langle t \rangle} = da_{next}*\tanh(c_{next}) * \Gamma_o^{\langle t \rangle}*(1-\Gamma_o^{\langle t \rangle})\tag{7}$$

$$d\tilde c^{\langle t \rangle} = dc_{next}*\Gamma_u^{\langle t \rangle}+ \Gamma_o^{\langle t \rangle} (1-\tanh(c_{next})^2) * i_t * da_{next} * \tilde c^{\langle t \rangle} * (1-\tanh(\tilde c)^2) \tag{8}$$

$$d\Gamma_u^{\langle t \rangle} = dc_{next}*\tilde c^{\langle t \rangle} + \Gamma_o^{\langle t \rangle} (1-\tanh(c_{next})^2) * \tilde c^{\langle t \rangle} * da_{next}*\Gamma_u^{\langle t \rangle}*(1-\Gamma_u^{\langle t \rangle})\tag{9}$$

$$d\Gamma_f^{\langle t \rangle} = dc_{next}*\tilde c_{prev} + \Gamma_o^{\langle t \rangle} (1-\tanh(c_{next})^2) * c_{prev} * da_{next}*\Gamma_f^{\langle t \rangle}*(1-\Gamma_f^{\langle t \rangle})\tag{10}$$

### 3.2.3 parameter derivatives 

$$ dW_f = d\Gamma_f^{\langle t \rangle} * \begin{pmatrix} a_{prev} \\ x_t\end{pmatrix}^T \tag{11} $$
$$ dW_u = d\Gamma_u^{\langle t \rangle} * \begin{pmatrix} a_{prev} \\ x_t\end{pmatrix}^T \tag{12} $$
$$ dW_c = d\tilde c^{\langle t \rangle} * \begin{pmatrix} a_{prev} \\ x_t\end{pmatrix}^T \tag{13} $$
$$ dW_o = d\Gamma_o^{\langle t \rangle} * \begin{pmatrix} a_{prev} \\ x_t\end{pmatrix}^T \tag{14}$$

To calculate $db_f, db_u, db_c, db_o$ you just need to sum across the horizontal (axis= 1) axis on $d\Gamma_f^{\langle t \rangle}, d\Gamma_u^{\langle t \rangle}, d\tilde c^{\langle t \rangle}, d\Gamma_o^{\langle t \rangle}$ respectively. Note that you should have the `keep_dims = True` option.

Finally, you will compute the derivative with respect to the previous hidden state, previous memory state, and input.

$$ da_{prev} = W_f^T*d\Gamma_f^{\langle t \rangle} + W_u^T * d\Gamma_u^{\langle t \rangle}+ W_c^T * d\tilde c^{\langle t \rangle} + W_o^T * d\Gamma_o^{\langle t \rangle} \tag{15}$$
Here, the weights for equations 13 are the first n_a, (i.e. $W_f = W_f[:n_a,:]$ etc...)

$$ dc_{prev} = dc_{next}\Gamma_f^{\langle t \rangle} + \Gamma_o^{\langle t \rangle} * (1- \tanh(c_{next})^2)*\Gamma_f^{\langle t \rangle}*da_{next} \tag{16}$$
$$ dx^{\langle t \rangle} = W_f^T*d\Gamma_f^{\langle t \rangle} + W_u^T * d\Gamma_u^{\langle t \rangle}+ W_c^T * d\tilde c_t + W_o^T * d\Gamma_o^{\langle t \rangle}\tag{17} $$
where the weights for equation 15 are from n_a to the end, (i.e. $W_f = W_f[n_a:,:]$ etc...)

**Exercise:** Implement `lstm_cell_backward` by implementing equations $7-17$ below. Good luck! :)


```python
def lstm_cell_backward(da_next, dc_next, cache):
    &quot;&quot;&quot;
    Implement the backward pass for the LSTM-cell (single time-step).

    Arguments:
    da_next -- Gradients of next hidden state, of shape (n_a, m)
    dc_next -- Gradients of next cell state, of shape (n_a, m)
    cache -- cache storing information from the forward pass

    Returns:
    gradients -- python dictionary containing:
                        dxt -- Gradient of input data at time-step t, of shape (n_x, m)
                        da_prev -- Gradient w.r.t. the previous hidden state, numpy array of shape (n_a, m)
                        dc_prev -- Gradient w.r.t. the previous memory state, of shape (n_a, m, T_x)
                        dWf -- Gradient w.r.t. the weight matrix of the forget gate, numpy array of shape (n_a, n_a + n_x)
                        dWi -- Gradient w.r.t. the weight matrix of the update gate, numpy array of shape (n_a, n_a + n_x)
                        dWc -- Gradient w.r.t. the weight matrix of the memory gate, numpy array of shape (n_a, n_a + n_x)
                        dWo -- Gradient w.r.t. the weight matrix of the output gate, numpy array of shape (n_a, n_a + n_x)
                        dbf -- Gradient w.r.t. biases of the forget gate, of shape (n_a, 1)
                        dbi -- Gradient w.r.t. biases of the update gate, of shape (n_a, 1)
                        dbc -- Gradient w.r.t. biases of the memory gate, of shape (n_a, 1)
                        dbo -- Gradient w.r.t. biases of the output gate, of shape (n_a, 1)
    &quot;&quot;&quot;

    # Retrieve information from &quot;cache&quot;
    (a_next, c_next, a_prev, c_prev, ft, it, cct, ot, xt, parameters) = cache
    
    
    # Retrieve dimensions from xt&#39;s and a_next&#39;s shape (≈2 lines)
    n_x, m = xt.shape
    n_a, m = a_next.shape
    
    # Compute gates related derivatives, you can find their values can be found by looking carefully at equations (7) to (10) (≈4 lines)
    dot = da_next*np.tanh(c_next)*ot*(1-ot)
    dcct = (dc_next*it+ot*(1-np.square(np.tanh(c_next)))*it*da_next)*(1-np.square(cct))
    dit = (dc_next*cct+ot*(1-np.square(np.tanh(c_next)))*cct*da_next)*it*(1-it)
    dft = (dc_next*c_prev+ot*(1-np.square(np.tanh(c_next)))*c_prev*da_next)*ft*(1-ft) 
    

    # Compute parameters related derivatives. Use equations (11)-(14) (≈8 lines)
    dWf = np.dot(dft,np.concatenate((a_prev, xt), axis=0).T)
    dWi = np.dot(dit,np.concatenate((a_prev, xt), axis=0).T)  
    dWc = np.dot(dcct,np.concatenate((a_prev, xt), axis=0).T)  
    dWo = np.dot(dot,np.concatenate((a_prev, xt), axis=0).T)  
    dbf = np.sum(dft,axis=1,keepdims=True)  
    dbi = np.sum(dit,axis=1,keepdims=True)  
    dbc = np.sum(dcct,axis=1,keepdims=True)  
    dbo = np.sum(dot,axis=1,keepdims=True) 

    # Compute derivatives w.r.t previous hidden state, previous memory state and input. Use equations (15)-(17). (≈3 lines)
    da_prev = np.dot(parameters[&#39;Wf&#39;][:,:n_a].T,dft)+np.dot(parameters[&#39;Wi&#39;][:,:n_a].T,dit)+np.dot(parameters[&#39;Wc&#39;][:,:n_a].T,dcct)+np.dot(parameters[&#39;Wo&#39;][:,:n_a].T,dot)  
    dc_prev = dc_next*ft+ot*(1-np.square(np.tanh(c_next)))*ft*da_next  
    dxt = np.dot(parameters[&#39;Wf&#39;][:,n_a:].T,dft)+np.dot(parameters[&#39;Wi&#39;][:,n_a:].T,dit)+np.dot(parameters[&#39;Wc&#39;][:,n_a:].T,dcct)+np.dot(parameters[&#39;Wo&#39;][:,n_a:].T,dot) 
    
    
    # Save gradients in dictionary
    gradients = {&quot;dxt&quot;: dxt, &quot;da_prev&quot;: da_prev, &quot;dc_prev&quot;: dc_prev, &quot;dWf&quot;: dWf,&quot;dbf&quot;: dbf, &quot;dWi&quot;: dWi,&quot;dbi&quot;: dbi,
                &quot;dWc&quot;: dWc,&quot;dbc&quot;: dbc, &quot;dWo&quot;: dWo,&quot;dbo&quot;: dbo}

    return gradients
```


```python
np.random.seed(1)
xt = np.random.randn(3,10)
a_prev = np.random.randn(5,10)
c_prev = np.random.randn(5,10)
Wf = np.random.randn(5, 5+3)
bf = np.random.randn(5,1)
Wi = np.random.randn(5, 5+3)
bi = np.random.randn(5,1)
Wo = np.random.randn(5, 5+3)
bo = np.random.randn(5,1)
Wc = np.random.randn(5, 5+3)
bc = np.random.randn(5,1)
Wy = np.random.randn(2,5)
by = np.random.randn(2,1)

parameters = {&quot;Wf&quot;: Wf, &quot;Wi&quot;: Wi, &quot;Wo&quot;: Wo, &quot;Wc&quot;: Wc, &quot;Wy&quot;: Wy, &quot;bf&quot;: bf, &quot;bi&quot;: bi, &quot;bo&quot;: bo, &quot;bc&quot;: bc, &quot;by&quot;: by}

a_next, c_next, yt, cache = lstm_cell_forward(xt, a_prev, c_prev, parameters)

da_next = np.random.randn(5,10)
dc_next = np.random.randn(5,10)
gradients = lstm_cell_backward(da_next, dc_next, cache)
print(&quot;gradients[\&quot;dxt\&quot;][1][2] =&quot;, gradients[&quot;dxt&quot;][1][2])
print(&quot;gradients[\&quot;dxt\&quot;].shape =&quot;, gradients[&quot;dxt&quot;].shape)
print(&quot;gradients[\&quot;da_prev\&quot;][2][3] =&quot;, gradients[&quot;da_prev&quot;][2][3])
print(&quot;gradients[\&quot;da_prev\&quot;].shape =&quot;, gradients[&quot;da_prev&quot;].shape)
print(&quot;gradients[\&quot;dc_prev\&quot;][2][3] =&quot;, gradients[&quot;dc_prev&quot;][2][3])
print(&quot;gradients[\&quot;dc_prev\&quot;].shape =&quot;, gradients[&quot;dc_prev&quot;].shape)
print(&quot;gradients[\&quot;dWf\&quot;][3][1] =&quot;, gradients[&quot;dWf&quot;][3][1])
print(&quot;gradients[\&quot;dWf\&quot;].shape =&quot;, gradients[&quot;dWf&quot;].shape)
print(&quot;gradients[\&quot;dWi\&quot;][1][2] =&quot;, gradients[&quot;dWi&quot;][1][2])
print(&quot;gradients[\&quot;dWi\&quot;].shape =&quot;, gradients[&quot;dWi&quot;].shape)
print(&quot;gradients[\&quot;dWc\&quot;][3][1] =&quot;, gradients[&quot;dWc&quot;][3][1])
print(&quot;gradients[\&quot;dWc\&quot;].shape =&quot;, gradients[&quot;dWc&quot;].shape)
print(&quot;gradients[\&quot;dWo\&quot;][1][2] =&quot;, gradients[&quot;dWo&quot;][1][2])
print(&quot;gradients[\&quot;dWo\&quot;].shape =&quot;, gradients[&quot;dWo&quot;].shape)
print(&quot;gradients[\&quot;dbf\&quot;][4] =&quot;, gradients[&quot;dbf&quot;][4])
print(&quot;gradients[\&quot;dbf\&quot;].shape =&quot;, gradients[&quot;dbf&quot;].shape)
print(&quot;gradients[\&quot;dbi\&quot;][4] =&quot;, gradients[&quot;dbi&quot;][4])
print(&quot;gradients[\&quot;dbi\&quot;].shape =&quot;, gradients[&quot;dbi&quot;].shape)
print(&quot;gradients[\&quot;dbc\&quot;][4] =&quot;, gradients[&quot;dbc&quot;][4])
print(&quot;gradients[\&quot;dbc\&quot;].shape =&quot;, gradients[&quot;dbc&quot;].shape)
print(&quot;gradients[\&quot;dbo\&quot;][4] =&quot;, gradients[&quot;dbo&quot;][4])
print(&quot;gradients[\&quot;dbo\&quot;].shape =&quot;, gradients[&quot;dbo&quot;].shape)
```

    gradients[&quot;dxt&quot;][1][2] = 3.23055911511
    gradients[&quot;dxt&quot;].shape = (3, 10)
    gradients[&quot;da_prev&quot;][2][3] = -0.0639621419711
    gradients[&quot;da_prev&quot;].shape = (5, 10)
    gradients[&quot;dc_prev&quot;][2][3] = 0.797522038797
    gradients[&quot;dc_prev&quot;].shape = (5, 10)
    gradients[&quot;dWf&quot;][3][1] = -0.147954838164
    gradients[&quot;dWf&quot;].shape = (5, 8)
    gradients[&quot;dWi&quot;][1][2] = 1.05749805523
    gradients[&quot;dWi&quot;].shape = (5, 8)
    gradients[&quot;dWc&quot;][3][1] = 2.30456216369
    gradients[&quot;dWc&quot;].shape = (5, 8)
    gradients[&quot;dWo&quot;][1][2] = 0.331311595289
    gradients[&quot;dWo&quot;].shape = (5, 8)
    gradients[&quot;dbf&quot;][4] = [ 0.18864637]
    gradients[&quot;dbf&quot;].shape = (5, 1)
    gradients[&quot;dbi&quot;][4] = [-0.40142491]
    gradients[&quot;dbi&quot;].shape = (5, 1)
    gradients[&quot;dbc&quot;][4] = [ 0.25587763]
    gradients[&quot;dbc&quot;].shape = (5, 1)
    gradients[&quot;dbo&quot;][4] = [ 0.13893342]
    gradients[&quot;dbo&quot;].shape = (5, 1)


**Expected Output**:

&lt;table&gt;
    &lt;tr&gt;
        &lt;td&gt;
            **gradients[&quot;dxt&quot;][1][2]** =
        &lt;/td&gt;
        &lt;td&gt;
           3.23055911511
        &lt;/td&gt;
    &lt;/tr&gt;
        &lt;tr&gt;
        &lt;td&gt;
            **gradients[&quot;dxt&quot;].shape** =
        &lt;/td&gt;
        &lt;td&gt;
           (3, 10)
        &lt;/td&gt;
    &lt;/tr&gt;
        &lt;tr&gt;
        &lt;td&gt;
            **gradients[&quot;da_prev&quot;][2][3]** =
        &lt;/td&gt;
        &lt;td&gt;
           -0.0639621419711
        &lt;/td&gt;
    &lt;/tr&gt;
        &lt;tr&gt;
        &lt;td&gt;
            **gradients[&quot;da_prev&quot;].shape** =
        &lt;/td&gt;
        &lt;td&gt;
           (5, 10)
        &lt;/td&gt;
    &lt;/tr&gt;
         &lt;tr&gt;
        &lt;td&gt;
            **gradients[&quot;dc_prev&quot;][2][3]** =
        &lt;/td&gt;
        &lt;td&gt;
           0.797522038797
        &lt;/td&gt;
    &lt;/tr&gt;
        &lt;tr&gt;
        &lt;td&gt;
            **gradients[&quot;dc_prev&quot;].shape** =
        &lt;/td&gt;
        &lt;td&gt;
           (5, 10)
        &lt;/td&gt;
    &lt;/tr&gt;
        &lt;tr&gt;
        &lt;td&gt;
            **gradients[&quot;dWf&quot;][3][1]** = 
        &lt;/td&gt;
        &lt;td&gt;
           -0.147954838164
        &lt;/td&gt;
    &lt;/tr&gt;
        &lt;tr&gt;
        &lt;td&gt;
            **gradients[&quot;dWf&quot;].shape** =
        &lt;/td&gt;
        &lt;td&gt;
           (5, 8)
        &lt;/td&gt;
    &lt;/tr&gt;
        &lt;tr&gt;
        &lt;td&gt;
            **gradients[&quot;dWi&quot;][1][2]** = 
        &lt;/td&gt;
        &lt;td&gt;
           1.05749805523
        &lt;/td&gt;
    &lt;/tr&gt;
        &lt;tr&gt;
        &lt;td&gt;
            **gradients[&quot;dWi&quot;].shape** = 
        &lt;/td&gt;
        &lt;td&gt;
           (5, 8)
        &lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
        &lt;td&gt;
            **gradients[&quot;dWc&quot;][3][1]** = 
        &lt;/td&gt;
        &lt;td&gt;
           2.30456216369
        &lt;/td&gt;
    &lt;/tr&gt;
        &lt;tr&gt;
        &lt;td&gt;
            **gradients[&quot;dWc&quot;].shape** = 
        &lt;/td&gt;
        &lt;td&gt;
           (5, 8)
        &lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
        &lt;td&gt;
            **gradients[&quot;dWo&quot;][1][2]** = 
        &lt;/td&gt;
        &lt;td&gt;
           0.331311595289
        &lt;/td&gt;
    &lt;/tr&gt;
        &lt;tr&gt;
        &lt;td&gt;
            **gradients[&quot;dWo&quot;].shape** = 
        &lt;/td&gt;
        &lt;td&gt;
           (5, 8)
        &lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
        &lt;td&gt;
            **gradients[&quot;dbf&quot;][4]** = 
        &lt;/td&gt;
        &lt;td&gt;
           [ 0.18864637]
        &lt;/td&gt;
    &lt;/tr&gt;
        &lt;tr&gt;
        &lt;td&gt;
            **gradients[&quot;dbf&quot;].shape** = 
        &lt;/td&gt;
        &lt;td&gt;
           (5, 1)
        &lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
        &lt;td&gt;
            **gradients[&quot;dbi&quot;][4]** = 
        &lt;/td&gt;
        &lt;td&gt;
           [-0.40142491]
        &lt;/td&gt;
    &lt;/tr&gt;
        &lt;tr&gt;
        &lt;td&gt;
            **gradients[&quot;dbi&quot;].shape** = 
        &lt;/td&gt;
        &lt;td&gt;
           (5, 1)
        &lt;/td&gt;
    &lt;/tr&gt;
        &lt;tr&gt;
        &lt;td&gt;
            **gradients[&quot;dbc&quot;][4]** = 
        &lt;/td&gt;
        &lt;td&gt;
           [ 0.25587763]
        &lt;/td&gt;
    &lt;/tr&gt;
        &lt;tr&gt;
        &lt;td&gt;
            **gradients[&quot;dbc&quot;].shape** = 
        &lt;/td&gt;
        &lt;td&gt;
           (5, 1)
        &lt;/td&gt;
    &lt;/tr&gt;
        &lt;tr&gt;
        &lt;td&gt;
            **gradients[&quot;dbo&quot;][4]** = 
        &lt;/td&gt;
        &lt;td&gt;
           [ 0.13893342]
        &lt;/td&gt;
    &lt;/tr&gt;
        &lt;tr&gt;
        &lt;td&gt;
            **gradients[&quot;dbo&quot;].shape** = 
        &lt;/td&gt;
        &lt;td&gt;
           (5, 1)
        &lt;/td&gt;
    &lt;/tr&gt;
&lt;/table&gt;

### 3.3 Backward pass through the LSTM RNN

This part is very similar to the `rnn_backward` function you implemented above. You will first create variables of the same dimension as your return variables. You will then iterate over all the time steps starting from the end and call the one step function you implemented for LSTM at each iteration. You will then update the parameters by summing them individually. Finally return a dictionary with the new gradients. 

**Instructions**: Implement the `lstm_backward` function. Create a for loop starting from $T_x$ and going backward. For each step call `lstm_cell_backward` and update the your old gradients by adding the new gradients to them. Note that `dxt` is not updated but is stored.


```python
def lstm_backward(da, caches):
    
    &quot;&quot;&quot;
    Implement the backward pass for the RNN with LSTM-cell (over a whole sequence).

    Arguments:
    da -- Gradients w.r.t the hidden states, numpy-array of shape (n_a, m, T_x)
    dc -- Gradients w.r.t the memory states, numpy-array of shape (n_a, m, T_x)
    caches -- cache storing information from the forward pass (lstm_forward)

    Returns:
    gradients -- python dictionary containing:
                        dx -- Gradient of inputs, of shape (n_x, m, T_x)
                        da0 -- Gradient w.r.t. the previous hidden state, numpy array of shape (n_a, m)
                        dWf -- Gradient w.r.t. the weight matrix of the forget gate, numpy array of shape (n_a, n_a + n_x)
                        dWi -- Gradient w.r.t. the weight matrix of the update gate, numpy array of shape (n_a, n_a + n_x)
                        dWc -- Gradient w.r.t. the weight matrix of the memory gate, numpy array of shape (n_a, n_a + n_x)
                        dWo -- Gradient w.r.t. the weight matrix of the save gate, numpy array of shape (n_a, n_a + n_x)
                        dbf -- Gradient w.r.t. biases of the forget gate, of shape (n_a, 1)
                        dbi -- Gradient w.r.t. biases of the update gate, of shape (n_a, 1)
                        dbc -- Gradient w.r.t. biases of the memory gate, of shape (n_a, 1)
                        dbo -- Gradient w.r.t. biases of the save gate, of shape (n_a, 1)
    &quot;&quot;&quot;

    # Retrieve values from the first cache (t=1) of caches.
    (caches, x) = caches
    (a1, c1, a0, c0, f1, i1, cc1, o1, x1, parameters) = caches[0]
    
    
    # Retrieve dimensions from da&#39;s and x1&#39;s shapes (≈2 lines)
    n_a, m, T_x = da.shape  
    n_x, m = x1.shape 

    # initialize the gradients with the right sizes (≈12 lines)
    dx = np.zeros((n_x, m, T_x))  
    da0 = np.zeros((n_a, m))  
    da_prevt = np.zeros((n_a, m))  
    dc_prevt = np.zeros((n_a, m))  
    dWf = np.zeros((n_a, n_a + n_x))  
    dWi = np.zeros((n_a, n_a + n_x))  
    dWc = np.zeros((n_a, n_a + n_x))  
    dWo = np.zeros((n_a, n_a + n_x))  
    dbf = np.zeros((n_a, 1))  
    dbi = np.zeros((n_a, 1))  
    dbc = np.zeros((n_a, 1))  
    dbo = np.zeros((n_a, 1)) 

    
    # loop back over the whole sequence
    for t in reversed(range(T_x)):
        
        # Compute all gradients using lstm_cell_backward
        gradients = lstm_cell_backward(da[:,:,t]+da_prevt,dc_prevt,caches[t])  
        
        # Store or add the gradient to the parameters&#39; previous step&#39;s gradient
        dx[:, :, t] = gradients[&#39;dxt&#39;]  
        dWf = dWf+gradients[&#39;dWf&#39;]  
        dWi = dWi+gradients[&#39;dWi&#39;]  
        dWc = dWc+gradients[&#39;dWc&#39;]  
        dWo = dWo+gradients[&#39;dWo&#39;]  
        dbf = dbf+gradients[&#39;dbf&#39;]  
        dbi = dbi+gradients[&#39;dbi&#39;]  
        dbc = dbc+gradients[&#39;dbc&#39;]  
        dbo = dbo+gradients[&#39;dbo&#39;]  
    # Set the first activation&#39;s gradient to the backpropagated gradient da_prev.
    da0 =gradients[&#39;da_prev&#39;]
    
    

    # Store the gradients in a python dictionary
    gradients = {&quot;dx&quot;: dx, &quot;da0&quot;: da0, &quot;dWf&quot;: dWf,&quot;dbf&quot;: dbf, &quot;dWi&quot;: dWi,&quot;dbi&quot;: dbi,
                &quot;dWc&quot;: dWc,&quot;dbc&quot;: dbc, &quot;dWo&quot;: dWo,&quot;dbo&quot;: dbo}
    
    return gradients
```


```python
np.random.seed(1)
x = np.random.randn(3,10,7)
a0 = np.random.randn(5,10)
Wf = np.random.randn(5, 5+3)
bf = np.random.randn(5,1)
Wi = np.random.randn(5, 5+3)
bi = np.random.randn(5,1)
Wo = np.random.randn(5, 5+3)
bo = np.random.randn(5,1)
Wc = np.random.randn(5, 5+3)
bc = np.random.randn(5,1)

parameters = {&quot;Wf&quot;: Wf, &quot;Wi&quot;: Wi, &quot;Wo&quot;: Wo, &quot;Wc&quot;: Wc, &quot;Wy&quot;: Wy, &quot;bf&quot;: bf, &quot;bi&quot;: bi, &quot;bo&quot;: bo, &quot;bc&quot;: bc, &quot;by&quot;: by}

a, y, c, caches = lstm_forward(x, a0, parameters)

da = np.random.randn(5, 10, 4)
gradients = lstm_backward(da, caches)

print(&quot;gradients[\&quot;dx\&quot;][1][2] =&quot;, gradients[&quot;dx&quot;][1][2])
print(&quot;gradients[\&quot;dx\&quot;].shape =&quot;, gradients[&quot;dx&quot;].shape)
print(&quot;gradients[\&quot;da0\&quot;][2][3] =&quot;, gradients[&quot;da0&quot;][2][3])
print(&quot;gradients[\&quot;da0\&quot;].shape =&quot;, gradients[&quot;da0&quot;].shape)
print(&quot;gradients[\&quot;dWf\&quot;][3][1] =&quot;, gradients[&quot;dWf&quot;][3][1])
print(&quot;gradients[\&quot;dWf\&quot;].shape =&quot;, gradients[&quot;dWf&quot;].shape)
print(&quot;gradients[\&quot;dWi\&quot;][1][2] =&quot;, gradients[&quot;dWi&quot;][1][2])
print(&quot;gradients[\&quot;dWi\&quot;].shape =&quot;, gradients[&quot;dWi&quot;].shape)
print(&quot;gradients[\&quot;dWc\&quot;][3][1] =&quot;, gradients[&quot;dWc&quot;][3][1])
print(&quot;gradients[\&quot;dWc\&quot;].shape =&quot;, gradients[&quot;dWc&quot;].shape)
print(&quot;gradients[\&quot;dWo\&quot;][1][2] =&quot;, gradients[&quot;dWo&quot;][1][2])
print(&quot;gradients[\&quot;dWo\&quot;].shape =&quot;, gradients[&quot;dWo&quot;].shape)
print(&quot;gradients[\&quot;dbf\&quot;][4] =&quot;, gradients[&quot;dbf&quot;][4])
print(&quot;gradients[\&quot;dbf\&quot;].shape =&quot;, gradients[&quot;dbf&quot;].shape)
print(&quot;gradients[\&quot;dbi\&quot;][4] =&quot;, gradients[&quot;dbi&quot;][4])
print(&quot;gradients[\&quot;dbi\&quot;].shape =&quot;, gradients[&quot;dbi&quot;].shape)
print(&quot;gradients[\&quot;dbc\&quot;][4] =&quot;, gradients[&quot;dbc&quot;][4])
print(&quot;gradients[\&quot;dbc\&quot;].shape =&quot;, gradients[&quot;dbc&quot;].shape)
print(&quot;gradients[\&quot;dbo\&quot;][4] =&quot;, gradients[&quot;dbo&quot;][4])
print(&quot;gradients[\&quot;dbo\&quot;].shape =&quot;, gradients[&quot;dbo&quot;].shape)
```

    gradients[&quot;dx&quot;][1][2] = [-0.00173313  0.08287442 -0.30545663 -0.43281115]
    gradients[&quot;dx&quot;].shape = (3, 10, 4)
    gradients[&quot;da0&quot;][2][3] = -0.095911501954
    gradients[&quot;da0&quot;].shape = (5, 10)
    gradients[&quot;dWf&quot;][3][1] = -0.0698198561274
    gradients[&quot;dWf&quot;].shape = (5, 8)
    gradients[&quot;dWi&quot;][1][2] = 0.102371820249
    gradients[&quot;dWi&quot;].shape = (5, 8)
    gradients[&quot;dWc&quot;][3][1] = -0.0624983794927
    gradients[&quot;dWc&quot;].shape = (5, 8)
    gradients[&quot;dWo&quot;][1][2] = 0.0484389131444
    gradients[&quot;dWo&quot;].shape = (5, 8)
    gradients[&quot;dbf&quot;][4] = [-0.0565788]
    gradients[&quot;dbf&quot;].shape = (5, 1)
    gradients[&quot;dbi&quot;][4] = [-0.15399065]
    gradients[&quot;dbi&quot;].shape = (5, 1)
    gradients[&quot;dbc&quot;][4] = [-0.29691142]
    gradients[&quot;dbc&quot;].shape = (5, 1)
    gradients[&quot;dbo&quot;][4] = [-0.29798344]
    gradients[&quot;dbo&quot;].shape = (5, 1)


**Expected Output**:

&lt;table&gt;
    &lt;tr&gt;
        &lt;td&gt;
            **gradients[&quot;dx&quot;][1][2]** =
        &lt;/td&gt;
        &lt;td&gt;
           [-0.00173313  0.08287442 -0.30545663 -0.43281115]
        &lt;/td&gt;
    &lt;/tr&gt;
        &lt;tr&gt;
        &lt;td&gt;
            **gradients[&quot;dx&quot;].shape** =
        &lt;/td&gt;
        &lt;td&gt;
           (3, 10, 4)
        &lt;/td&gt;
    &lt;/tr&gt;
        &lt;tr&gt;
        &lt;td&gt;
            **gradients[&quot;da0&quot;][2][3]** =
        &lt;/td&gt;
        &lt;td&gt;
           -0.095911501954
        &lt;/td&gt;
    &lt;/tr&gt;
        &lt;tr&gt;
        &lt;td&gt;
            **gradients[&quot;da0&quot;].shape** =
        &lt;/td&gt;
        &lt;td&gt;
           (5, 10)
        &lt;/td&gt;
    &lt;/tr&gt;
        &lt;tr&gt;
        &lt;td&gt;
            **gradients[&quot;dWf&quot;][3][1]** = 
        &lt;/td&gt;
        &lt;td&gt;
           -0.0698198561274
        &lt;/td&gt;
    &lt;/tr&gt;
        &lt;tr&gt;
        &lt;td&gt;
            **gradients[&quot;dWf&quot;].shape** =
        &lt;/td&gt;
        &lt;td&gt;
           (5, 8)
        &lt;/td&gt;
    &lt;/tr&gt;
        &lt;tr&gt;
        &lt;td&gt;
            **gradients[&quot;dWi&quot;][1][2]** = 
        &lt;/td&gt;
        &lt;td&gt;
           0.102371820249
        &lt;/td&gt;
    &lt;/tr&gt;
        &lt;tr&gt;
        &lt;td&gt;
            **gradients[&quot;dWi&quot;].shape** = 
        &lt;/td&gt;
        &lt;td&gt;
           (5, 8)
        &lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
        &lt;td&gt;
            **gradients[&quot;dWc&quot;][3][1]** = 
        &lt;/td&gt;
        &lt;td&gt;
           -0.0624983794927
        &lt;/td&gt;
    &lt;/tr&gt;
        &lt;tr&gt;
        &lt;td&gt;
            **gradients[&quot;dWc&quot;].shape** = 
        &lt;/td&gt;
        &lt;td&gt;
           (5, 8)
        &lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
        &lt;td&gt;
            **gradients[&quot;dWo&quot;][1][2]** = 
        &lt;/td&gt;
        &lt;td&gt;
           0.0484389131444
        &lt;/td&gt;
    &lt;/tr&gt;
        &lt;tr&gt;
        &lt;td&gt;
            **gradients[&quot;dWo&quot;].shape** = 
        &lt;/td&gt;
        &lt;td&gt;
           (5, 8)
        &lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
        &lt;td&gt;
            **gradients[&quot;dbf&quot;][4]** = 
        &lt;/td&gt;
        &lt;td&gt;
           [-0.0565788]
        &lt;/td&gt;
    &lt;/tr&gt;
        &lt;tr&gt;
        &lt;td&gt;
            **gradients[&quot;dbf&quot;].shape** = 
        &lt;/td&gt;
        &lt;td&gt;
           (5, 1)
        &lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
        &lt;td&gt;
            **gradients[&quot;dbi&quot;][4]** = 
        &lt;/td&gt;
        &lt;td&gt;
           [-0.06997391]
        &lt;/td&gt;
    &lt;/tr&gt;
        &lt;tr&gt;
        &lt;td&gt;
            **gradients[&quot;dbi&quot;].shape** = 
        &lt;/td&gt;
        &lt;td&gt;
           (5, 1)
        &lt;/td&gt;
    &lt;/tr&gt;
        &lt;tr&gt;
        &lt;td&gt;
            **gradients[&quot;dbc&quot;][4]** = 
        &lt;/td&gt;
        &lt;td&gt;
           [-0.27441821]
        &lt;/td&gt;
    &lt;/tr&gt;
        &lt;tr&gt;
        &lt;td&gt;
            **gradients[&quot;dbc&quot;].shape** = 
        &lt;/td&gt;
        &lt;td&gt;
           (5, 1)
        &lt;/td&gt;
    &lt;/tr&gt;
        &lt;tr&gt;
        &lt;td&gt;
            **gradients[&quot;dbo&quot;][4]** = 
        &lt;/td&gt;
        &lt;td&gt;
           [ 0.16532821]
        &lt;/td&gt;
    &lt;/tr&gt;
        &lt;tr&gt;
        &lt;td&gt;
            **gradients[&quot;dbo&quot;].shape** = 
        &lt;/td&gt;
        &lt;td&gt;
           (5, 1)
        &lt;/td&gt;
    &lt;/tr&gt;
&lt;/table&gt;deeplearning.ai - Sequence Model - Week 1 Assignment 2
# Character level language model - Dinosaurus land

Welcome to Dinosaurus Island! 65 million years ago, dinosaurs existed, and in this assignment they are back. You are in charge of a special task. Leading biology researchers are creating new breeds of dinosaurs and bringing them to life on earth, and your job is to give names to these dinosaurs. If a dinosaur does not like its name, it might go beserk, so choose wisely! 

&lt;table&gt;
&lt;td&gt;
&lt;img src=&quot;https://raw.githubusercontent.com/karenyyy/Coursera_and_Udemy/master/deeplearningai_coursera/Sequence%20Models/images/dino.jpg&quot; style=&quot;width:250;height:300px;&quot;&gt;

&lt;/td&gt;

&lt;/table&gt;

Luckily you have learned some deep learning and you will use it to save the day. Your assistant has collected a list of all the dinosaur names they could find, and compiled them into this [dataset](dinos.txt). (Feel free to take a look by clicking the previous link.) To create new dinosaur names, you will build a character level language model to generate new names. Your algorithm will learn the different name patterns, and randomly generate new names. Hopefully this algorithm will keep you and your team safe from the dinosaurs&#39; wrath! 

By completing this assignment you will learn:

- How to store text data for processing using an RNN 
- How to synthesize data, by sampling predictions at each time step and passing it to the next RNN-cell unit
- How to build a character-level text generation recurrent neural network
- Why clipping the gradients is important

We will begin by loading in some functions that we have provided for you in `rnn_utils`. Specifically, you have access to functions such as `rnn_forward` and `rnn_backward` which are equivalent to those you&#39;ve implemented in the previous assignment. 


```python
import numpy as np
from utils import *
import random
```

## 1 - Problem Statement

### 1.1 - Dataset and Preprocessing

Run the following cell to read the dataset of dinosaur names, create a list of unique characters (such as a-z), and compute the dataset and vocabulary size. 


```python
data = open(&#39;dinos.txt&#39;, &#39;r&#39;).read()
data= data.lower()
chars = list(set(data))
data_size, vocab_size = len(data), len(chars)
print(&#39;There are %d total characters and %d unique characters in your data.&#39; % (data_size, vocab_size))
```

    There are 19909 total characters and 27 unique characters in your data.


The characters are a-z (26 characters) plus the &quot;\n&quot; (or newline character), which in this assignment plays a role similar to the `&lt;EOS&gt;` (or &quot;End of sentence&quot;) token we had discussed in lecture, only here it indicates the end of the dinosaur name rather than the end of a sentence. In the cell below, we create a python dictionary (i.e., a hash table) to map each character to an index from 0-26. We also create a second python dictionary that maps each index back to the corresponding character character. This will help you figure out what index corresponds to what character in the probability distribution output of the softmax layer. Below, `char_to_ix` and `ix_to_char` are the python dictionaries. 


```python
char_to_ix = { ch:i for i,ch in enumerate(sorted(chars)) }
ix_to_char = { i:ch for i,ch in enumerate(sorted(chars)) }
print(ix_to_char)
```

    {0: &#39;\n&#39;, 1: &#39;a&#39;, 2: &#39;b&#39;, 3: &#39;c&#39;, 4: &#39;d&#39;, 5: &#39;e&#39;, 6: &#39;f&#39;, 7: &#39;g&#39;, 8: &#39;h&#39;, 9: &#39;i&#39;, 10: &#39;j&#39;, 11: &#39;k&#39;, 12: &#39;l&#39;, 13: &#39;m&#39;, 14: &#39;n&#39;, 15: &#39;o&#39;, 16: &#39;p&#39;, 17: &#39;q&#39;, 18: &#39;r&#39;, 19: &#39;s&#39;, 20: &#39;t&#39;, 21: &#39;u&#39;, 22: &#39;v&#39;, 23: &#39;w&#39;, 24: &#39;x&#39;, 25: &#39;y&#39;, 26: &#39;z&#39;}


### 1.2 - Overview of the model

Your model will have the following structure: 

- Initialize parameters 
- Run the optimization loop
    - Forward propagation to compute the loss function
    - Backward propagation to compute the gradients with respect to the loss function
    - Clip the gradients to avoid exploding gradients
    - Using the gradients, update your parameter with the gradient descent update rule.
- Return the learned parameters 
    
&lt;img src=&quot;https://raw.githubusercontent.com/karenyyy/Coursera_and_Udemy/master/deeplearningai_coursera/Sequence%20Models/images/rnn.png&quot; style=&quot;width:450;height:300px;&quot;&gt;
&lt;caption&gt;&lt;center&gt; **Figure 1**: Recurrent Neural Network, similar to what you had built in the previous notebook &quot;Building a RNN - Step by Step&quot;.  &lt;/center&gt;&lt;/caption&gt;

At each time-step, the RNN tries to predict what is the next character given the previous characters. The dataset $X = (x^{\langle 1 \rangle}, x^{\langle 2 \rangle}, ..., x^{\langle T_x \rangle})$ is a list of characters in the training set, while $Y = (y^{\langle 1 \rangle}, y^{\langle 2 \rangle}, ..., y^{\langle T_x \rangle})$ is such that at every time-step $t$, we have $y^{\langle t \rangle} = x^{\langle t+1 \rangle}$. 

## 2 - Building blocks of the model

In this part, you will build two important blocks of the overall model:
- Gradient clipping: to avoid exploding gradients
- Sampling: a technique used to generate characters

You will then apply these two functions to build the model.

### 2.1 - Clipping the gradients in the optimization loop

In this section you will implement the `clip` function that you will call inside of your optimization loop. Recall that your overall loop structure usually consists of a forward pass, a cost computation, a backward pass, and a parameter update. Before updating the parameters, you will perform gradient clipping when needed to make sure that your gradients are not &quot;exploding,&quot; meaning taking on overly large values. 

In the exercise below, you will implement a function `clip` that takes in a dictionary of gradients and returns a clipped version of gradients if needed. There are different ways to clip gradients; we will use a simple element-wise clipping procedure, in which every element of the gradient vector is clipped to lie between some range [-N, N]. More generally, you will provide a `maxValue` (say 10). In this example, if any component of the gradient vector is greater than 10, it would be set to 10; and if any component of the gradient vector is less than -10, it would be set to -10. If it is between -10 and 10, it is left alone. 

&lt;img src=&quot;https://raw.githubusercontent.com/karenyyy/Coursera_and_Udemy/master/deeplearningai_coursera/Sequence%20Models/images/clip.png&quot; style=&quot;width:400;height:150px;&quot;&gt;
&lt;caption&gt;&lt;center&gt; **Figure 2**: Visualization of gradient descent with and without gradient clipping, in a case where the network is running into slight &quot;exploding gradient&quot; problems. &lt;/center&gt;&lt;/caption&gt;

**Exercise**: Implement the function below to return the clipped gradients of your dictionary `gradients`. Your function takes in a maximum threshold and returns the clipped versions of your gradients. You can check out this [hint](https://docs.scipy.org/doc/numpy-1.13.0/reference/generated/numpy.clip.html) for examples of how to clip in numpy. You will need to use the argument `out = ...`.


```python
### GRADED FUNCTION: clip

def clip(gradients, maxValue):
    &#39;&#39;&#39;
    Clips the gradients&#39; values between minimum and maximum.
    
    Arguments:
    gradients -- a dictionary containing the gradients &quot;dWaa&quot;, &quot;dWax&quot;, &quot;dWya&quot;, &quot;db&quot;, &quot;dby&quot;
    maxValue -- everything above this number is set to this number, and everything less than -maxValue is set to -maxValue
    
    Returns: 
    gradients -- a dictionary with the clipped gradients.
    &#39;&#39;&#39;
    
    dWaa, dWax, dWya, db, dby = gradients[&#39;dWaa&#39;], gradients[&#39;dWax&#39;], gradients[&#39;dWya&#39;], gradients[&#39;db&#39;], gradients[&#39;dby&#39;]
   
    
    # clip to mitigate exploding gradients, loop over [dWax, dWaa, dWya, db, dby]. (≈2 lines)
    for gradient in [dWax, dWaa, dWya, db, dby]:
        gradient = np.clip(gradient, -maxValue, maxValue, out=gradient)
    
    
    gradients = {&quot;dWaa&quot;: dWaa, &quot;dWax&quot;: dWax, &quot;dWya&quot;: dWya, &quot;db&quot;: db, &quot;dby&quot;: dby}
    
    return gradients
```


```python
np.random.seed(3)
dWax = np.random.randn(5,3)*10
dWaa = np.random.randn(5,5)*10
dWya = np.random.randn(2,5)*10
db = np.random.randn(5,1)*10
dby = np.random.randn(2,1)*10
gradients = {&quot;dWax&quot;: dWax, &quot;dWaa&quot;: dWaa, &quot;dWya&quot;: dWya, &quot;db&quot;: db, &quot;dby&quot;: dby}
gradients = clip(gradients, 10)
print(&quot;gradients[\&quot;dWaa\&quot;][1][2] =&quot;, gradients[&quot;dWaa&quot;][1][2])
print(&quot;gradients[\&quot;dWax\&quot;][3][1] =&quot;, gradients[&quot;dWax&quot;][3][1])
print(&quot;gradients[\&quot;dWya\&quot;][1][2] =&quot;, gradients[&quot;dWya&quot;][1][2])
print(&quot;gradients[\&quot;db\&quot;][4] =&quot;, gradients[&quot;db&quot;][4])
print(&quot;gradients[\&quot;dby\&quot;][1] =&quot;, gradients[&quot;dby&quot;][1])
```

    gradients[&quot;dWaa&quot;][1][2] = 10.0
    gradients[&quot;dWax&quot;][3][1] = -10.0
    gradients[&quot;dWya&quot;][1][2] = 0.29713815361
    gradients[&quot;db&quot;][4] = [ 10.]
    gradients[&quot;dby&quot;][1] = [ 8.45833407]


** Expected output:**

&lt;table&gt;
&lt;tr&gt;
    &lt;td&gt; 
    **gradients[&quot;dWaa&quot;][1][2] **
    &lt;/td&gt;
    &lt;td&gt; 
    10.0
    &lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
    &lt;td&gt; 
    **gradients[&quot;dWax&quot;][3][1]**
    &lt;/td&gt;
    &lt;td&gt; 
    -10.0
    &lt;/td&gt;
    &lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
    &lt;td&gt; 
    **gradients[&quot;dWya&quot;][1][2]**
    &lt;/td&gt;
    &lt;td&gt; 
0.29713815361
    &lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
    &lt;td&gt; 
    **gradients[&quot;db&quot;][4]**
    &lt;/td&gt;
    &lt;td&gt; 
[ 10.]
    &lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
    &lt;td&gt; 
    **gradients[&quot;dby&quot;][1]**
    &lt;/td&gt;
    &lt;td&gt; 
[ 8.45833407]
    &lt;/td&gt;
&lt;/tr&gt;

&lt;/table&gt;

### 2.2 - Sampling

Now assume that your model is trained. You would like to generate new text (characters). The process of generation is explained in the picture below:

&lt;img src=&quot;https://raw.githubusercontent.com/karenyyy/Coursera_and_Udemy/master/deeplearningai_coursera/Sequence%20Models/images/dinos3.png&quot; style=&quot;width:500;height:300px;&quot;&gt;
&lt;caption&gt;&lt;center&gt; **Figure 3**: In this picture, we assume the model is already trained. We pass in $x^{\langle 1\rangle} = \vec{0}$ at the first time step, and have the network then sample one character at a time. &lt;/center&gt;&lt;/caption&gt;

**Exercise**: Implement the `sample` function below to sample characters. You need to carry out 4 steps:

- **Step 1**: Pass the network the first &quot;dummy&quot; input $x^{\langle 1 \rangle} = \vec{0}$ (the vector of zeros). This is the default input before we&#39;ve generated any characters. We also set $a^{\langle 0 \rangle} = \vec{0}$

- **Step 2**: Run one step of forward propagation to get $a^{\langle 1 \rangle}$ and $\hat{y}^{\langle 1 \rangle}$. Here are the equations:

$$ a^{\langle t+1 \rangle} = \tanh(W_{ax}  x^{\langle t \rangle } + W_{aa} a^{\langle t \rangle } + b)\tag{1}$$

$$ z^{\langle t + 1 \rangle } = W_{ya}  a^{\langle t + 1 \rangle } + b_y \tag{2}$$

$$ \hat{y}^{\langle t+1 \rangle } = softmax(z^{\langle t + 1 \rangle })\tag{3}$$

Note that $\hat{y}^{\langle t+1 \rangle }$ is a (softmax) probability vector (its entries are between 0 and 1 and sum to 1). $\hat{y}^{\langle t+1 \rangle}_i$ represents the probability that the character indexed by &quot;i&quot; is the next character.  We have provided a `softmax()` function that you can use.

- **Step 3**: Carry out sampling: Pick the next character&#39;s index according to the probability distribution specified by $\hat{y}^{\langle t+1 \rangle }$. This means that if $\hat{y}^{\langle t+1 \rangle }_i = 0.16$, you will pick the index &quot;i&quot; with 16% probability. To implement it, you can use [`np.random.choice`](https://docs.scipy.org/doc/numpy-1.13.0/reference/generated/numpy.random.choice.html).

Here is an example of how to use `np.random.choice()`:
```python
np.random.seed(0)
p = np.array([0.1, 0.0, 0.7, 0.2])
index = np.random.choice([0, 1, 2, 3], p = p.ravel())
```
This means that you will pick the `index` according to the distribution: 
$P(index = 0) = 0.1, P(index = 1) = 0.0, P(index = 2) = 0.7, P(index = 3) = 0.2$.

- **Step 4**: The last step to implement in `sample()` is to overwrite the variable `x`, which currently stores $x^{\langle t \rangle }$, with the value of $x^{\langle t + 1 \rangle }$. You will represent $x^{\langle t + 1 \rangle }$ by creating a one-hot vector corresponding to the character you&#39;ve chosen as your prediction. You will then forward propagate $x^{\langle t + 1 \rangle }$ in Step 1 and keep repeating the process until you get a &quot;\n&quot; character, indicating you&#39;ve reached the end of the dinosaur name. 


```python
# GRADED FUNCTION: sample

def sample(parameters, char_to_ix, seed):
    &quot;&quot;&quot;
    Sample a sequence of characters according to a sequence of probability distributions output of the RNN

    Arguments:
    parameters -- python dictionary containing the parameters Waa, Wax, Wya, by, and b. 
    char_to_ix -- python dictionary mapping each character to an index.
    seed -- used for grading purposes. Do not worry about it.

    Returns:
    indices -- a list of length n containing the indices of the sampled characters.
    &quot;&quot;&quot;
    
    # Retrieve parameters and relevant shapes from &quot;parameters&quot; dictionary
    Waa, Wax, Wya, by, b = parameters[&#39;Waa&#39;], parameters[&#39;Wax&#39;], parameters[&#39;Wya&#39;], parameters[&#39;by&#39;], parameters[&#39;b&#39;]
    vocab_size = by.shape[0]
    n_a = Waa.shape[1]
    
    
    # Step 1: Create the one-hot vector x for the first character (initializing the sequence generation). (≈1 line)
    x = np.zeros((vocab_size, 1))
    # Step 1&#39;: Initialize a_prev as zeros (≈1 line)
    a_prev = np.zeros((n_a, 1))
    
    # Create an empty list of indices, this is the list which will contain the list of indices of the characters to generate (≈1 line)
    indices = []
    
    # Idx is a flag to detect a newline character, we initialize it to -1
    idx = -1 
    
    # Loop over time-steps t. At each time-step, sample a character from a probability distribution and append 
    # its index to &quot;indices&quot;. We&#39;ll stop if we reach 50 characters (which should be very unlikely with a well 
    # trained model), which helps debugging and prevents entering an infinite loop. 
    counter = 0
    newline_character = char_to_ix[&#39;\n&#39;] # the index of &#39;\n&#39;
    
    while (idx != newline_character and counter != 50):
        
        # Step 2: Forward propagate x using the equations (1), (2) and (3)
        a = np.tanh(np.dot(Waa, a_prev)+np.dot(Wax, x)+b)
        z = np.dot(Wya, a)+by
        y = softmax(z)
        
        # for grading purposes
        np.random.seed(counter+seed) 
        
        # Step 3: Sample the index of a character within the vocabulary from the probability distribution y
        idx = np.random.choice(range(vocab_size), p=y.ravel())

        # Append the index to &quot;indices&quot;
        indices.append(idx)
        
        # Step 4: Overwrite the input character as the one corresponding to the sampled index.
        x = np.zeros((vocab_size, 1))
        x[idx] = 1
        
        # Update &quot;a_prev&quot; to be &quot;a&quot;
        a_prev = a
        
        # for grading purposes
        seed += 1
        counter +=1
        
    

    if (counter == 50):
        indices.append(char_to_ix[&#39;\n&#39;])
    
    return indices
```


```python
np.random.seed(2)
_, n_a = 20, 100
Wax, Waa, Wya = np.random.randn(n_a, vocab_size), np.random.randn(n_a, n_a), np.random.randn(vocab_size, n_a)
b, by = np.random.randn(n_a, 1), np.random.randn(vocab_size, 1)
parameters = {&quot;Wax&quot;: Wax, &quot;Waa&quot;: Waa, &quot;Wya&quot;: Wya, &quot;b&quot;: b, &quot;by&quot;: by}


indices = sample(parameters, char_to_ix, 0)
print(&quot;Sampling:&quot;)
print(&quot;list of sampled indices:&quot;, indices)
print(&quot;list of sampled characters:&quot;, [ix_to_char[i] for i in indices])
```

    Sampling:
    list of sampled indices: [12, 17, 24, 14, 13, 9, 10, 22, 24, 6, 13, 11, 12, 6, 21, 15, 21, 14, 3, 2, 1, 21, 18, 24, 7, 25, 6, 25, 18, 10, 16, 2, 3, 8, 15, 12, 11, 7, 1, 12, 10, 2, 7, 7, 11, 5, 6, 12, 25, 0, 0]
    list of sampled characters: [&#39;l&#39;, &#39;q&#39;, &#39;x&#39;, &#39;n&#39;, &#39;m&#39;, &#39;i&#39;, &#39;j&#39;, &#39;v&#39;, &#39;x&#39;, &#39;f&#39;, &#39;m&#39;, &#39;k&#39;, &#39;l&#39;, &#39;f&#39;, &#39;u&#39;, &#39;o&#39;, &#39;u&#39;, &#39;n&#39;, &#39;c&#39;, &#39;b&#39;, &#39;a&#39;, &#39;u&#39;, &#39;r&#39;, &#39;x&#39;, &#39;g&#39;, &#39;y&#39;, &#39;f&#39;, &#39;y&#39;, &#39;r&#39;, &#39;j&#39;, &#39;p&#39;, &#39;b&#39;, &#39;c&#39;, &#39;h&#39;, &#39;o&#39;, &#39;l&#39;, &#39;k&#39;, &#39;g&#39;, &#39;a&#39;, &#39;l&#39;, &#39;j&#39;, &#39;b&#39;, &#39;g&#39;, &#39;g&#39;, &#39;k&#39;, &#39;e&#39;, &#39;f&#39;, &#39;l&#39;, &#39;y&#39;, &#39;\n&#39;, &#39;\n&#39;]


** Expected output:**
&lt;table&gt;
&lt;tr&gt;
    &lt;td&gt; 
    **list of sampled indices:**
    &lt;/td&gt;
    &lt;td&gt; 
    [12, 17, 24, 14, 13, 9, 10, 22, 24, 6, 13, 11, 12, 6, 21, 15, 21, 14, 3, 2, 1, 21, 18, 24, &lt;br&gt;
    7, 25, 6, 25, 18, 10, 16, 2, 3, 8, 15, 12, 11, 7, 1, 12, 10, 2, 7, 7, 11, 5, 6, 12, 25, 0, 0]
    &lt;/td&gt;
    &lt;/tr&gt;&lt;tr&gt;
    &lt;td&gt; 
    **list of sampled characters:**
    &lt;/td&gt;
    &lt;td&gt; 
    [&#39;l&#39;, &#39;q&#39;, &#39;x&#39;, &#39;n&#39;, &#39;m&#39;, &#39;i&#39;, &#39;j&#39;, &#39;v&#39;, &#39;x&#39;, &#39;f&#39;, &#39;m&#39;, &#39;k&#39;, &#39;l&#39;, &#39;f&#39;, &#39;u&#39;, &#39;o&#39;, &lt;br&gt;
    &#39;u&#39;, &#39;n&#39;, &#39;c&#39;, &#39;b&#39;, &#39;a&#39;, &#39;u&#39;, &#39;r&#39;, &#39;x&#39;, &#39;g&#39;, &#39;y&#39;, &#39;f&#39;, &#39;y&#39;, &#39;r&#39;, &#39;j&#39;, &#39;p&#39;, &#39;b&#39;, &#39;c&#39;, &#39;h&#39;, &#39;o&#39;, &lt;br&gt;
    &#39;l&#39;, &#39;k&#39;, &#39;g&#39;, &#39;a&#39;, &#39;l&#39;, &#39;j&#39;, &#39;b&#39;, &#39;g&#39;, &#39;g&#39;, &#39;k&#39;, &#39;e&#39;, &#39;f&#39;, &#39;l&#39;, &#39;y&#39;, &#39;\n&#39;, &#39;\n&#39;]
    &lt;/td&gt;
    
        
    
&lt;/tr&gt;
&lt;/table&gt;

## 3 - Building the language model 

It is time to build the character-level language model for text generation. 


### 3.1 - Gradient descent 

In this section you will implement a function performing one step of stochastic gradient descent (with clipped gradients). You will go through the training examples one at a time, so the optimization algorithm will be stochastic gradient descent. As a reminder, here are the steps of a common optimization loop for an RNN:

- Forward propagate through the RNN to compute the loss
- Backward propagate through time to compute the gradients of the loss with respect to the parameters
- Clip the gradients if necessary 
- Update your parameters using gradient descent 

**Exercise**: Implement this optimization process (one step of stochastic gradient descent). 

We provide you with the following functions: 

```python
def rnn_forward(X, Y, a_prev, parameters):
    &quot;&quot;&quot; Performs the forward propagation through the RNN and computes the cross-entropy loss.
    It returns the loss&#39; value as well as a &quot;cache&quot; storing values to be used in the backpropagation.&quot;&quot;&quot;
    ....
    return loss, cache
    
def rnn_backward(X, Y, parameters, cache):
    &quot;&quot;&quot; Performs the backward propagation through time to compute the gradients of the loss with respect
    to the parameters. It returns also all the hidden states.&quot;&quot;&quot;
    ...
    return gradients, a

def update_parameters(parameters, gradients, learning_rate):
    &quot;&quot;&quot; Updates parameters using the Gradient Descent Update Rule.&quot;&quot;&quot;
    ...
    return parameters
```


```python
# GRADED FUNCTION: optimize

def optimize(X, Y, a_prev, parameters, learning_rate = 0.01):
    &quot;&quot;&quot;
    Execute one step of the optimization to train the model.
    
    Arguments:
    X -- list of integers, where each integer is a number that maps to a character in the vocabulary.
    Y -- list of integers, exactly the same as X but shifted one index to the left.
    a_prev -- previous hidden state.
    parameters -- python dictionary containing:
                        Wax -- Weight matrix multiplying the input, numpy array of shape (n_a, n_x)
                        Waa -- Weight matrix multiplying the hidden state, numpy array of shape (n_a, n_a)
                        Wya -- Weight matrix relating the hidden-state to the output, numpy array of shape (n_y, n_a)
                        b --  Bias, numpy array of shape (n_a, 1)
                        by -- Bias relating the hidden-state to the output, numpy array of shape (n_y, 1)
    learning_rate -- learning rate for the model.
    
    Returns:
    loss -- value of the loss function (cross-entropy)
    gradients -- python dictionary containing:
                        dWax -- Gradients of input-to-hidden weights, of shape (n_a, n_x)
                        dWaa -- Gradients of hidden-to-hidden weights, of shape (n_a, n_a)
                        dWya -- Gradients of hidden-to-output weights, of shape (n_y, n_a)
                        db -- Gradients of bias vector, of shape (n_a, 1)
                        dby -- Gradients of output bias vector, of shape (n_y, 1)
    a[len(X)-1] -- the last hidden state, of shape (n_a, 1)
    &quot;&quot;&quot;
    
    
    
    # Forward propagate through time (≈1 line)
    loss, cache = rnn_forward(X, Y, a_prev, parameters)
    
    # Backpropagate through time (≈1 line)
    gradients, a = rnn_backward(X, Y, parameters, cache)
    
    # Clip your gradients between -5 (min) and 5 (max) (≈1 line)
    gradients = clip(gradients, maxValue=5)
    
    # Update parameters (≈1 line)
    parameters = update_parameters(parameters, gradients, learning_rate)
    
    
    
    return loss, gradients, a[len(X)-1]
```


```python
np.random.seed(1)
vocab_size, n_a = 27, 100
a_prev = np.random.randn(n_a, 1)
Wax, Waa, Wya = np.random.randn(n_a, vocab_size), np.random.randn(n_a, n_a), np.random.randn(vocab_size, n_a)
b, by = np.random.randn(n_a, 1), np.random.randn(vocab_size, 1)
parameters = {&quot;Wax&quot;: Wax, &quot;Waa&quot;: Waa, &quot;Wya&quot;: Wya, &quot;b&quot;: b, &quot;by&quot;: by}
X = [12,3,5,11,22,3]
Y = [4,14,11,22,25, 26]

loss, gradients, a_last = optimize(X, Y, a_prev, parameters, learning_rate = 0.01)
print(&quot;Loss =&quot;, loss)
print(&quot;gradients[\&quot;dWaa\&quot;][1][2] =&quot;, gradients[&quot;dWaa&quot;][1][2])
print(&quot;np.argmax(gradients[\&quot;dWax\&quot;]) =&quot;, np.argmax(gradients[&quot;dWax&quot;]))
print(&quot;gradients[\&quot;dWya\&quot;][1][2] =&quot;, gradients[&quot;dWya&quot;][1][2])
print(&quot;gradients[\&quot;db\&quot;][4] =&quot;, gradients[&quot;db&quot;][4])
print(&quot;gradients[\&quot;dby\&quot;][1] =&quot;, gradients[&quot;dby&quot;][1])
print(&quot;a_last[4] =&quot;, a_last[4])
```

    Loss = 126.503975722
    gradients[&quot;dWaa&quot;][1][2] = 0.194709315347
    np.argmax(gradients[&quot;dWax&quot;]) = 93
    gradients[&quot;dWya&quot;][1][2] = -0.007773876032
    gradients[&quot;db&quot;][4] = [-0.06809825]
    gradients[&quot;dby&quot;][1] = [ 0.01538192]
    a_last[4] = [-1.]


** Expected output:**

&lt;table&gt;


&lt;tr&gt;
    &lt;td&gt; 
    **Loss **
    &lt;/td&gt;
    &lt;td&gt; 
    126.503975722
    &lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
    &lt;td&gt; 
    **gradients[&quot;dWaa&quot;][1][2]**
    &lt;/td&gt;
    &lt;td&gt; 
    0.194709315347
    &lt;/td&gt;
&lt;tr&gt;
    &lt;td&gt; 
    **np.argmax(gradients[&quot;dWax&quot;])**
    &lt;/td&gt;
    &lt;td&gt; 93
    &lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
    &lt;td&gt; 
    **gradients[&quot;dWya&quot;][1][2]**
    &lt;/td&gt;
    &lt;td&gt; -0.007773876032
    &lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
    &lt;td&gt; 
    **gradients[&quot;db&quot;][4]**
    &lt;/td&gt;
    &lt;td&gt; [-0.06809825]
    &lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
    &lt;td&gt; 
    **gradients[&quot;dby&quot;][1]**
    &lt;/td&gt;
    &lt;td&gt;[ 0.01538192]
    &lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
    &lt;td&gt; 
    **a_last[4]**
    &lt;/td&gt;
    &lt;td&gt; [-1.]
    &lt;/td&gt;
&lt;/tr&gt;

&lt;/table&gt;

### 3.2 - Training the model 

Given the dataset of dinosaur names, we use each line of the dataset (one name) as one training example. Every 100 steps of stochastic gradient descent, you will sample 10 randomly chosen names to see how the algorithm is doing. Remember to shuffle the dataset, so that stochastic gradient descent visits the examples in random order. 

**Exercise**: Follow the instructions and implement `model()`. When `examples[index]` contains one dinosaur name (string), to create an example (X, Y), you can use this:
```python
        index = j % len(examples)
        X = [None] + [char_to_ix[ch] for ch in examples[index]] 
        Y = X[1:] + [char_to_ix[&quot;\n&quot;]]
```
Note that we use: `index= j % len(examples)`, where `j = 1....num_iterations`, to make sure that `examples[index]` is always a valid statement (`index` is smaller than `len(examples)`).
The first entry of `X` being `None` will be interpreted by `rnn_forward()` as setting $x^{\langle 0 \rangle} = \vec{0}$. Further, this ensures that `Y` is equal to `X` but shifted one step to the left, and with an additional &quot;\n&quot; appended to signify the end of the dinosaur name. 


```python
# GRADED FUNCTION: model

def model(data, ix_to_char, char_to_ix, num_iterations = 35000, n_a = 50, dino_names = 7, vocab_size = 27):
    &quot;&quot;&quot;
    Trains the model and generates dinosaur names. 
    
    Arguments:
    data -- text corpus
    ix_to_char -- dictionary that maps the index to a character
    char_to_ix -- dictionary that maps a character to an index
    num_iterations -- number of iterations to train the model for
    n_a -- number of units of the RNN cell
    dino_names -- number of dinosaur names you want to sample at each iteration. 
    vocab_size -- number of unique characters found in the text, size of the vocabulary
    
    Returns:
    parameters -- learned parameters
    &quot;&quot;&quot;
    
    # Retrieve n_x and n_y from vocab_size
    n_x, n_y = vocab_size, vocab_size
    
    # Initialize parameters
    parameters = initialize_parameters(n_a, n_x, n_y)
    
    # Initialize loss (this is required because we want to smooth our loss, don&#39;t worry about it)
    loss = get_initial_loss(vocab_size, dino_names)
    
    # Build list of all dinosaur names (training examples).
    with open(&quot;dinos.txt&quot;) as f:
        examples = f.readlines()
    examples = [x.lower().strip() for x in examples]
    
    # Shuffle list of all dinosaur names
    np.random.seed(0)
    np.random.shuffle(examples)
    
    # Initialize the hidden state of your LSTM
    a_prev = np.zeros((n_a, 1))
    
    # Optimization loop
    for j in range(num_iterations):
        
        
        
        # Use the hint above to define one training example (X,Y) (≈ 2 lines)
        index = j % len(examples)
        X = [None] + [char_to_ix[ch] for ch in examples[index]] 
        Y = X[1:] + [char_to_ix[&quot;\n&quot;]]
        
        # Perform one optimization step: Forward-prop -&gt; Backward-prop -&gt; Clip -&gt; Update parameters
        # Choose a learning rate of 0.01
        curr_loss, gradients, a_prev = optimize(X, Y, a_prev, parameters, learning_rate = 0.01)
        
        
        
        # Use a latency trick to keep the loss smooth. It happens here to accelerate the training.
        loss = smooth(loss, curr_loss)

        # Every 2000 Iteration, generate &quot;n&quot; characters thanks to sample() to check if the model is learning properly
        if j % 2000 == 0:
            
            print(&#39;Iteration: %d, Loss: %f&#39; % (j, loss) + &#39;\n&#39;)
            
            # The number of dinosaur names to print
            seed = 0
            for name in range(dino_names):
                
                # Sample indices and print them
                sampled_indices = sample(parameters, char_to_ix, seed)
                print_sample(sampled_indices, ix_to_char)
                
                seed += 1  # To get the same result for grading purposed, increment the seed by one. 
      
            print(&#39;\n&#39;)
        
    return parameters
```

Run the following cell, you should observe your model outputting random-looking characters at the first iteration. After a few thousand iterations, your model should learn to generate reasonable-looking names. 


```python
parameters = model(data, ix_to_char, char_to_ix)
```

    Iteration: 0, Loss: 23.087336
    
    Nkzxwtdmfqoeyhsqwasjkjvu
    Kneb
    Kzxwtdmfqoeyhsqwasjkjvu
    Neb
    Zxwtdmfqoeyhsqwasjkjvu
    Eb
    Xwtdmfqoeyhsqwasjkjvu
    
    
    Iteration: 2000, Loss: 27.884160
    
    Liusskeomnolxeros
    Hmdaairus
    Hytroligoraurus
    Lecalosapaus
    Xusicikoraurus
    Abalpsamantisaurus
    Tpraneronxeros
    
    
    Iteration: 4000, Loss: 25.901815
    
    Mivrosaurus
    Inee
    Ivtroplisaurus
    Mbaaisaurus
    Wusichisaurus
    Cabaselachus
    Toraperlethosdarenitochusthiamamumamaon
    
    
    Iteration: 6000, Loss: 24.608779
    
    Onwusceomosaurus
    Lieeaerosaurus
    Lxussaurus
    Oma
    Xusteonosaurus
    Eeahosaurus
    Toreonosaurus
    
    
    Iteration: 8000, Loss: 24.070350
    
    Onxusichepriuon
    Kilabersaurus
    Lutrodon
    Omaaerosaurus
    Xutrcheps
    Edaksoje
    Trodiktonus
    
    
    Iteration: 10000, Loss: 23.844446
    
    Onyusaurus
    Klecalosaurus
    Lustodon
    Ola
    Xusodonia
    Eeaeosaurus
    Troceosaurus
    
    
    Iteration: 12000, Loss: 23.291971
    
    Onyxosaurus
    Kica
    Lustrepiosaurus
    Olaagrraiansaurus
    Yuspangosaurus
    Eealosaurus
    Trognesaurus
    
    
    Iteration: 14000, Loss: 23.382339
    
    Meutromodromurus
    Inda
    Iutroinatorsaurus
    Maca
    Yusteratoptititan
    Ca
    Troclosaurus
    
    
    Iteration: 16000, Loss: 23.288447
    
    Meuspsangosaurus
    Ingaa
    Iusosaurus
    Macalosaurus
    Yushanis
    Daalosaurus
    Trpandon
    
    
    Iteration: 18000, Loss: 22.823526
    
    Phytrolonhonyg
    Mela
    Mustrerasaurus
    Peg
    Ytronorosaurus
    Ehalosaurus
    Trolomeehus
    
    
    Iteration: 20000, Loss: 23.041871
    
    Nousmofonosaurus
    Loma
    Lytrognatiasaurus
    Ngaa
    Ytroenetiaudostarmilus
    Eiafosaurus
    Troenchulunosaurus
    
    
    Iteration: 22000, Loss: 22.728849
    
    Piutyrangosaurus
    Midaa
    Myroranisaurus
    Pedadosaurus
    Ytrodon
    Eiadosaurus
    Trodoniomusitocorces
    
    
    Iteration: 24000, Loss: 22.683403
    
    Meutromeisaurus
    Indeceratlapsaurus
    Jurosaurus
    Ndaa
    Yusicheropterus
    Eiaeropectus
    Trodonasaurus
    
    
    Iteration: 26000, Loss: 22.554523
    
    Phyusaurus
    Liceceron
    Lyusichenodylus
    Pegahus
    Yustenhtonthosaurus
    Elagosaurus
    Trodontonsaurus
    
    
    Iteration: 28000, Loss: 22.484472
    
    Onyutimaerihus
    Koia
    Lytusaurus
    Ola
    Ytroheltorus
    Eiadosaurus
    Trofiashates
    
    
    Iteration: 30000, Loss: 22.774404
    
    Phytys
    Lica
    Lysus
    Pacalosaurus
    Ytrochisaurus
    Eiacosaurus
    Trochesaurus
    
    
    Iteration: 32000, Loss: 22.209473
    
    Mawusaurus
    Jica
    Lustoia
    Macaisaurus
    Yusolenqtesaurus
    Eeaeosaurus
    Trnanatrax
    
    
    Iteration: 34000, Loss: 22.396744
    
    Mavptokekus
    Ilabaisaurus
    Itosaurus
    Macaesaurus
    Yrosaurus
    Eiaeosaurus
    Trodon
    
    


## Conclusion

You can see that your algorithm has started to generate plausible dinosaur names towards the end of the training. At first, it was generating random characters, but towards the end you could see dinosaur names with cool endings. Feel free to run the algorithm even longer and play with hyperparameters to see if you can get even better results. Our implemetation generated some really cool names like `maconucon`, `marloralus` and `macingsersaurus`. Your model hopefully also learned that dinosaur names tend to end in `saurus`, `don`, `aura`, `tor`, etc.

If your model generates some non-cool names, don&#39;t blame the model entirely--not all actual dinosaur names sound cool. (For example, `dromaeosauroides` is an actual dinosaur name and is in the training set.) But this model should give you a set of candidates from which you can pick the coolest! 

This assignment had used a relatively small dataset, so that you could train an RNN quickly on a CPU. Training a model of the english language requires a much bigger dataset, and usually needs much more computation, and could run for many hours on GPUs. We ran our dinosaur name for quite some time, and so far our favoriate name is the great, undefeatable, and fierce: Mangosaurus!

&lt;img src=&quot;https://raw.githubusercontent.com/karenyyy/Coursera_and_Udemy/master/deeplearningai_coursera/Sequence%20Models/images/mangosaurus.jpeg&quot; style=&quot;width:250;height:300px;&quot;&gt;

## 4 - Writing like Shakespeare

The rest of this notebook is optional and is not graded, but we hope you&#39;ll do it anyway since it&#39;s quite fun and informative. 

A similar (but more complicated) task is to generate Shakespeare poems. Instead of learning from a dataset of Dinosaur names you can use a collection of Shakespearian poems. Using LSTM cells, you can learn longer term dependencies that span many characters in the text--e.g., where a character appearing somewhere a sequence can influence what should be a different character much much later in ths sequence. These long term dependencies were less important with dinosaur names, since the names were quite short. 


&lt;img src=&quot;https://raw.githubusercontent.com/karenyyy/Coursera_and_Udemy/master/deeplearningai_coursera/Sequence%20Models/images/shakespeare.jpg&quot; style=&quot;width:500;height:400px;&quot;&gt;
&lt;caption&gt;&lt;center&gt; Let&#39;s become poets! &lt;/center&gt;&lt;/caption&gt;

We have implemented a Shakespeare poem generator with Keras. Run the following cell to load the required packages and models. This may take a few minutes. 


```python
from __future__ import print_function
from keras.callbacks import LambdaCallback
from keras.models import Model, load_model, Sequential
from keras.layers import Dense, Activation, Dropout, Input, Masking
from keras.layers import LSTM
from keras.utils.data_utils import get_file
from keras.preprocessing.sequence import pad_sequences
from shakespeare_utils import *
import sys
import io
```

    Using TensorFlow backend.


    Loading text data...
    Creating training set...
    number of training examples: 31412
    Vectorizing training set...
    Loading model...


To save you some time, we have already trained a model for ~1000 epochs on a collection of Shakespearian poems called [*&quot;The Sonnets&quot;*](shakespeare.txt). 

Let&#39;s train the model for one more epoch. When it finishes training for an epoch---this will also take a few minutes---you can run `generate_output`, which will prompt asking you for an input (`&lt;`40 characters). The poem will start with your sentence, and our RNN-Shakespeare will complete the rest of the poem for you! For example, try &quot;Forsooth this maketh no sense &quot; (don&#39;t enter the quotation marks). Depending on whether you include the space at the end, your results might also differ--try it both ways, and try other inputs as well. 



```python
print_callback = LambdaCallback(on_epoch_end=on_epoch_end)

model.fit(x, y, batch_size=128, epochs=1, callbacks=[print_callback])
```

    Epoch 1/1
    31412/31412 [==============================] - 241s - loss: 2.5634   





    &lt;keras.callbacks.History at 0x7fec9767f7f0&gt;




```python
# Run this cell to try with different inputs without having to re-train the model 
generate_output()
```

    Write the beginning of your poem, the Shakespeare machine will complete it. Your input is: to be or not to be
    
    
    Here is your poem: 
    
    to be or not to be night.
     
    
    wo should for why feates hith shate sweet:
    so troy, wime from my geith with assed ben,
    thas filface more but falreoves level and.
    liath eyes you thy hasfs wise do lodghing,
    (tiad paingy shomunt lobe fur bear for my ra;lese:
    but diwhit thou youl creeliye (erstan in prase,
    be fairssed his lissawe is the doth chen,
    and prain theaming hest other, fres for now,
    tive ow (rock i am the will th

The RNN-Shakespeare model is very similar to the one you have built for dinosaur names. The only major differences are:
- LSTMs instead of the basic RNN to capture longer-range dependencies
- The model is a deeper, stacked LSTM model (2 layer)
- Using Keras instead of python to simplify the code 

If you want to learn more, you can also check out the Keras Team&#39;s text generation implementation on GitHub: https://github.com/keras-team/keras/blob/master/examples/lstm_text_generation.py.


**References**:
- This exercise took inspiration from Andrej Karpathy&#39;s implementation: https://gist.github.com/karpathy/d4dee566867f8291f086. To learn more about text generation, also check out Karpathy&#39;s [blog post](http://karpathy.github.io/2015/05/21/rnn-effectiveness/).
- For the Shakespearian poem generator, our implementation was based on the implementation of an LSTM text generator by the Keras team: https://github.com/keras-team/keras/blob/master/examples/lstm_text_generation.pydeeplearning.ai - Improving Deep Neural Networks - Week 3 Assignment
&lt;h1 id=&quot;tensorflow-tutorial&quot;&gt;TensorFlow Tutorial&lt;/h1&gt;
&lt;p&gt;Welcome to this week&#39;s programming assignment. Until now, you&#39;ve always used numpy to build neural networks. Now we will step you through a deep learning framework that will allow you to build neural networks more easily. Machine learning frameworks like TensorFlow, PaddlePaddle, Torch, Caffe, Keras, and many others can speed up your machine learning development significantly. All of these frameworks also have a lot of documentation, which you should feel free to read. In this assignment, you will learn to do the following in TensorFlow: &lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Initialize variables&lt;/li&gt;
&lt;li&gt;Start your own session&lt;/li&gt;
&lt;li&gt;Train algorithms &lt;/li&gt;
&lt;li&gt;Implement a Neural Network&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Programing frameworks can not only shorten your coding time, but sometimes also perform optimizations that speed up your code. &lt;/p&gt;
&lt;h2 id=&quot;1-exploring-the-tensorflow-library&quot;&gt;1 - Exploring the Tensorflow Library&lt;/h2&gt;
&lt;p&gt;To start, you will import the library:&lt;/p&gt;
&lt;div class=&quot;codehilite&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;math&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;numpy&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;np&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;h5py&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;matplotlib.pyplot&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;plt&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;tensorflow&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;tf&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;tensorflow.python.framework&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ops&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;tf_utils&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;load_dataset&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;random_mini_batches&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;convert_to_one_hot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;predict&lt;/span&gt;

&lt;span class=&quot;o&quot;&gt;%&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;matplotlib&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;inline&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;random&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;seed&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Now that you have imported the library, we will walk you through its different applications. You will start with an example, where we compute for you the loss of one training example. 
$$loss = \mathcal{L}(\hat{y}, y) = (\hat y^{(i)} - y^{(i)})^2 \tag{1}$$&lt;/p&gt;
&lt;div class=&quot;codehilite&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y_hat&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;constant&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;36&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;y_hat&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;            &lt;span class=&quot;c1&quot;&gt;# Define y_hat constant. Set to 36.&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;y&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;constant&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;39&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;y&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;                    &lt;span class=&quot;c1&quot;&gt;# Define y. Set to 39&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;loss&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Variable&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;((&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y_hat&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;**&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;loss&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# Create a variable for the loss&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;init&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;global_variables_initializer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;         &lt;span class=&quot;c1&quot;&gt;# When init is run later (session.run(init)),&lt;/span&gt;
                                                 &lt;span class=&quot;c1&quot;&gt;# the loss variable will be initialized and ready to be computed&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;with&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Session&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;session&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;                    &lt;span class=&quot;c1&quot;&gt;# Create a session and print the output&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;session&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;run&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;init&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;                            &lt;span class=&quot;c1&quot;&gt;# Initializes the variables&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;session&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;run&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;loss&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;                     &lt;span class=&quot;c1&quot;&gt;# Prints the loss&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div class=&quot;codehilite&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;9
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Writing and running programs in TensorFlow has the following steps:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Create Tensors (variables) that are not yet executed/evaluated. &lt;/li&gt;
&lt;li&gt;Write operations between those Tensors.&lt;/li&gt;
&lt;li&gt;Initialize your Tensors. &lt;/li&gt;
&lt;li&gt;Create a Session. &lt;/li&gt;
&lt;li&gt;Run the Session. This will run the operations you&#39;d written above. &lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Therefore, when we created a variable for the loss, we simply defined the loss as a function of other quantities, but did not evaluate its value. To evaluate it, we had to run &lt;code&gt;init=tf.global_variables_initializer()&lt;/code&gt;. That initialized the loss variable, and in the last line we were finally able to evaluate the value of &lt;code&gt;loss&lt;/code&gt; and print its value.&lt;/p&gt;
&lt;p&gt;Now let us look at an easy example. Run the cell below:&lt;/p&gt;
&lt;div class=&quot;codehilite&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;a&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;constant&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;b&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;constant&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;c&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;multiply&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;b&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;c&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div class=&quot;codehilite&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;Tensor(&amp;quot;Mul:0&amp;quot;, shape=(), dtype=int32)
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;As expected, you will not see 20! You got a tensor saying that the result is a tensor that does not have the shape attribute, and is of type &quot;int32&quot;. All you did was put in the &#39;computation graph&#39;, but you have not run this computation yet. In order to actually multiply the two numbers, you will have to create a session and run it.&lt;/p&gt;
&lt;div class=&quot;codehilite&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sess&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Session&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sess&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;run&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;c&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div class=&quot;codehilite&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;20
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Great! To summarize, &lt;strong&gt;remember to initialize your variables, create a session and run the operations inside the session&lt;/strong&gt;. &lt;/p&gt;
&lt;p&gt;Next, you&#39;ll also have to know about placeholders. A placeholder is an object whose value you can specify only later. 
To specify values for a placeholder, you can pass in values by using a &quot;feed dictionary&quot; (&lt;code&gt;feed_dict&lt;/code&gt; variable). Below, we created a placeholder for x. This allows us to pass in a number later when we run the session. &lt;/p&gt;
&lt;div class=&quot;codehilite&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;c1&quot;&gt;# Change the value of x in the feed_dict&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;placeholder&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;int64&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;name&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&amp;#39;x&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sess&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;run&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;feed_dict&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}))&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;sess&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;close&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div class=&quot;codehilite&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;6
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;When you first defined &lt;code&gt;x&lt;/code&gt; you did not have to specify a value for it. A placeholder is simply a variable that you will assign data to only later, when running the session. We say that you &lt;strong&gt;feed data&lt;/strong&gt; to these placeholders when running the session. &lt;/p&gt;
&lt;p&gt;Here&#39;s what&#39;s happening: When you specify the operations needed for a computation, you are telling TensorFlow how to construct a computation graph. The computation graph can have some placeholders whose values you will specify only later. Finally, when you run the session, you are telling TensorFlow to execute the computation graph.&lt;/p&gt;
&lt;h3 id=&quot;11-linear-function&quot;&gt;1.1 - Linear function&lt;/h3&gt;
&lt;p&gt;Lets start this programming exercise by computing the following equation: $Y = WX + b$, where $W$ and $X$ are random matrices and b is a random vector. &lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Exercise&lt;/strong&gt;: Compute $WX + b$ where $W, X$, and $b$ are drawn from a random normal distribution. W is of shape (4, 3), X is (3,1) and b is (4,1). As an example, here is how you would define a constant X that has shape (3,1):&lt;/p&gt;
&lt;div class=&quot;codehilite&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;constant&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;random&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;randn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;name&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&amp;quot;X&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;You might find the following functions helpful: 
- tf.matmul(..., ...) to do a matrix multiplication
- tf.add(..., ...) to do an addition
- np.random.randn(...) to initialize randomly&lt;/p&gt;
&lt;div class=&quot;codehilite&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;c1&quot;&gt;# GRADED FUNCTION: linear_function&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;linear_function&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;():&lt;/span&gt;
    &lt;span class=&quot;sd&quot;&gt;&amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    Implements a linear function: &lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;            Initializes W to be a random tensor of shape (4,3)&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;            Initializes X to be a random tensor of shape (3,1)&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;            Initializes b to be a random tensor of shape (4,1)&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    Returns: &lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    result -- runs the session for Y = WX + b &lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    &amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;

    &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;random&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;seed&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;


    &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;random&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;randn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;W&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;random&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;randn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;b&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;random&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;randn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;Y&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;add&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;matmul&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;W&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;b&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;


    &lt;span class=&quot;c1&quot;&gt;# Create the session using tf.Session() and run it with sess.run(...) on the variable you want to calculate&lt;/span&gt;


    &lt;span class=&quot;n&quot;&gt;sess&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Session&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;result&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sess&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;run&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;


    &lt;span class=&quot;c1&quot;&gt;# close the session &lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;sess&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;close&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;

    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;result&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div class=&quot;codehilite&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&amp;quot;result = &amp;quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;linear_function&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()))&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div class=&quot;codehilite&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;result = [[-2.15657382]
 [ 2.95891446]
 [-1.08926781]
 [-0.84538042]]
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;strong&gt;&lt;em&gt; Expected Output &lt;/em&gt;&lt;/strong&gt;: &lt;/p&gt;
&lt;table&gt; 
&lt;tr&gt; 
&lt;td&gt;
**result**
&lt;/td&gt;
&lt;td&gt;
[[-2.15657382]
 [ 2.95891446]
 [-1.08926781]
 [-0.84538042]]
&lt;/td&gt;
&lt;/tr&gt;

&lt;/table&gt;

&lt;h3 id=&quot;12-computing-the-sigmoid&quot;&gt;1.2 - Computing the sigmoid&lt;/h3&gt;
&lt;p&gt;Great! You just implemented a linear function. Tensorflow offers a variety of commonly used neural network functions like &lt;code&gt;tf.sigmoid&lt;/code&gt; and &lt;code&gt;tf.softmax&lt;/code&gt;. For this exercise lets compute the sigmoid function of an input. &lt;/p&gt;
&lt;p&gt;You will do this exercise using a placeholder variable &lt;code&gt;x&lt;/code&gt;. When running the session, you should use the feed dictionary to pass in the input &lt;code&gt;z&lt;/code&gt;. In this exercise, you will have to (i) create a placeholder &lt;code&gt;x&lt;/code&gt;, (ii) define the operations needed to compute the sigmoid using &lt;code&gt;tf.sigmoid&lt;/code&gt;, and then (iii) run the session. &lt;/p&gt;
&lt;p&gt;&lt;strong&gt; Exercise &lt;/strong&gt;: Implement the sigmoid function below. You should use the following: &lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;tf.placeholder(tf.float32, name = &quot;...&quot;)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;tf.sigmoid(...)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;sess.run(..., feed_dict = {x: z})&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Note that there are two typical ways to create and use sessions in tensorflow: &lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Method 1:&lt;/strong&gt;&lt;/p&gt;
&lt;div class=&quot;codehilite&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sess&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Session&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;# Run the variables initialization (if needed), run the operations&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;result&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sess&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;run&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;...&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;feed_dict&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;...&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;})&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;sess&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;close&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;# Close the session&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;strong&gt;Method 2:&lt;/strong&gt;&lt;/p&gt;
&lt;div class=&quot;codehilite&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;with&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Session&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sess&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; 
    &lt;span class=&quot;c1&quot;&gt;# run the variables initialization (if needed), run the operations&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;result&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sess&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;run&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;...&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;feed_dict&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;...&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;})&lt;/span&gt;
    &lt;span class=&quot;c1&quot;&gt;# This takes care of closing the session for you :)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div class=&quot;codehilite&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;c1&quot;&gt;# GRADED FUNCTION: sigmoid&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;sigmoid&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;z&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;sd&quot;&gt;&amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    Computes the sigmoid of z&lt;/span&gt;

&lt;span class=&quot;sd&quot;&gt;    Arguments:&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    z -- input value, scalar or vector&lt;/span&gt;

&lt;span class=&quot;sd&quot;&gt;    Returns: &lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    results -- the sigmoid of z&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    &amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;


    &lt;span class=&quot;c1&quot;&gt;# Create a placeholder for x. Name it &amp;#39;x&amp;#39;.&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;placeholder&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;float32&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;x&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

    &lt;span class=&quot;c1&quot;&gt;# compute sigmoid(x)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;sigmoid&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sigmoid&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

    &lt;span class=&quot;c1&quot;&gt;# Create a session, and run it. Please use the method 2 explained above. &lt;/span&gt;
    &lt;span class=&quot;c1&quot;&gt;# You should use a feed_dict to pass z&amp;#39;s value to x. &lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;with&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Session&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sess&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; 
        &lt;span class=&quot;c1&quot;&gt;# Run session and call the output &amp;quot;result&amp;quot;&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;result&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;result&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sess&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;run&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sigmoid&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;feed_dict&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;z&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;})&lt;/span&gt;



    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;result&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div class=&quot;codehilite&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;sigmoid(0) = &amp;quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sigmoid&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)))&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;sigmoid(12) = &amp;quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sigmoid&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;12&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)))&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div class=&quot;codehilite&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;sigmoid(0) = 0.5
sigmoid(12) = 0.999994
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;strong&gt;&lt;em&gt; Expected Output &lt;/em&gt;&lt;/strong&gt;: &lt;/p&gt;
&lt;table&gt; 
&lt;tr&gt; 
&lt;td&gt;
**sigmoid(0)**
&lt;/td&gt;
&lt;td&gt;
0.5
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt; 
&lt;td&gt;
**sigmoid(12)**
&lt;/td&gt;
&lt;td&gt;
0.999994
&lt;/td&gt;
&lt;/tr&gt;

&lt;/table&gt;

&lt;p&gt;&lt;strong&gt;To summarize, you how know how to&lt;/strong&gt;:
1. Create placeholders
2. Specify the computation graph corresponding to operations you want to compute
3. Create the session
4. Run the session, using a feed dictionary if necessary to specify placeholder variables&#39; values. &lt;/p&gt;
&lt;h3 id=&quot;13-computing-the-cost&quot;&gt;1.3 -  Computing the Cost&lt;/h3&gt;
&lt;p&gt;You can also use a built-in function to compute the cost of your neural network. So instead of needing to write code to compute this as a function of $a^{&lt;a href=&quot;i&quot;&gt;2&lt;/a&gt;}$ and $y^{(i)}$ for i=1...m: 
$$ J = - \frac{1}{m}  \sum_{i = 1}^m  \large ( \small y^{(i)} \log a^{ [2] (i)} + (1-y^{(i)})\log (1-a^{ [2] (i)} )\large )\small\tag{2}$$&lt;/p&gt;
&lt;p&gt;you can do it in one line of code in tensorflow!&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Exercise&lt;/strong&gt;: Implement the cross entropy loss. The function you will use is: &lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;tf.nn.sigmoid_cross_entropy_with_logits(logits = ...,  labels = ...)&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Your code should input &lt;code&gt;z&lt;/code&gt;, compute the sigmoid (to get &lt;code&gt;a&lt;/code&gt;) and then compute the cross entropy cost $J$. All this can be done using one call to &lt;code&gt;tf.nn.sigmoid_cross_entropy_with_logits&lt;/code&gt;, which computes&lt;/p&gt;
&lt;p&gt;$$- \frac{1}{m}  \sum_{i = 1}^m  \large ( \small y^{(i)} \log \sigma(z^{&lt;a href=&quot;i&quot;&gt;2&lt;/a&gt;}) + (1-y^{(i)})\log (1-\sigma(z^{&lt;a href=&quot;i&quot;&gt;2&lt;/a&gt;})\large )\small\tag{2}$$&lt;/p&gt;
&lt;div class=&quot;codehilite&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;c1&quot;&gt;# GRADED FUNCTION: cost&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;cost&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;logits&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;labels&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;sd&quot;&gt;&amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    Computes the cost using the sigmoid cross entropy&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    &lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    Arguments:&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    logits -- vector containing z, output of the last linear unit (before the final sigmoid activation)&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    labels -- vector of labels y (1 or 0) &lt;/span&gt;

&lt;span class=&quot;sd&quot;&gt;    Note: What we&amp;#39;ve been calling &amp;quot;z&amp;quot; and &amp;quot;y&amp;quot; in this class are respectively called &amp;quot;logits&amp;quot; and &amp;quot;labels&amp;quot; &lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    in the TensorFlow documentation. So logits will feed into z, and labels into y. &lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    &lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    Returns:&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    cost -- runs the session of the cost (formula (2))&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    &amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;



    &lt;span class=&quot;c1&quot;&gt;# Create the placeholders for &amp;quot;logits&amp;quot; (z) and &amp;quot;labels&amp;quot; (y) (approx. 2 lines)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;z&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;placeholder&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;float32&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;z&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;placeholder&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;float32&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;y&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

    &lt;span class=&quot;c1&quot;&gt;# Use the loss function (approx. 1 line)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;cost&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sigmoid_cross_entropy_with_logits&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;logits&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;z&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;labels&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

    &lt;span class=&quot;c1&quot;&gt;# Create a session (approx. 1 line). See method 1 above.&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;sess&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Session&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;

    &lt;span class=&quot;c1&quot;&gt;# Run the session (approx. 1 line).&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;cost&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sess&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;run&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cost&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;feed_dict&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;z&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;logits&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;labels&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;})&lt;/span&gt;

    &lt;span class=&quot;c1&quot;&gt;# Close the session (approx. 1 line). See method 1 above.&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;sess&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;close&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;



    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cost&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div class=&quot;codehilite&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;logits&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sigmoid&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;array&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.7&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.9&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]))&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;cost&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cost&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;logits&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;array&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]))&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;cost = &amp;quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cost&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div class=&quot;codehilite&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;cost = [ 1.00538719  1.03664088  0.41385433  0.39956614]
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;strong&gt; Expected Output&lt;/strong&gt; : &lt;/p&gt;
&lt;table&gt; 
    &lt;tr&gt; 
        &lt;td&gt;
            **cost**
        &lt;/td&gt;
        &lt;td&gt;
        [ 1.00538719  1.03664088  0.41385433  0.39956614]
        &lt;/td&gt;
    &lt;/tr&gt;

&lt;/table&gt;

&lt;h3 id=&quot;14-using-one-hot-encodings&quot;&gt;1.4 - Using One Hot encodings&lt;/h3&gt;
&lt;p&gt;Many times in deep learning you will have a y vector with numbers ranging from 0 to C-1, where C is the number of classes. If C is for example 4, then you might have the following y vector which you will need to convert as follows:&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/enggen/Deep-Learning-Coursera/master/Improving%20Deep%20Neural%20Networks%20Hyperparameter%20tuning%2C%20Regularization%20and%20Optimization/images/onehot.png&quot; style=&quot;width:600px;height:150px;&quot;&gt;&lt;/p&gt;
&lt;p&gt;This is called a &quot;one hot&quot; encoding, because in the converted representation exactly one element of each column is &quot;hot&quot; (meaning set to 1). To do this conversion in numpy, you might have to write a few lines of code. In tensorflow, you can use one line of code: &lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;tf.one_hot(labels, depth, axis) &lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Exercise:&lt;/strong&gt; Implement the function below to take one vector of labels and the total number of classes $C$, and return the one hot encoding. Use &lt;code&gt;tf.one_hot()&lt;/code&gt; to do this. &lt;/p&gt;
&lt;div class=&quot;codehilite&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;c1&quot;&gt;# GRADED FUNCTION: one_hot_matrix&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;one_hot_matrix&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;labels&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;C&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;sd&quot;&gt;&amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    Creates a matrix where the i-th row corresponds to the ith class number and the jth column&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;                     corresponds to the jth training example. So if example j had a label i. Then entry (i,j) &lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;                     will be 1. &lt;/span&gt;

&lt;span class=&quot;sd&quot;&gt;    Arguments:&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    labels -- vector containing the labels &lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    C -- number of classes, the depth of the one hot dimension&lt;/span&gt;

&lt;span class=&quot;sd&quot;&gt;    Returns: &lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    one_hot -- one hot matrix&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    &amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;



    &lt;span class=&quot;c1&quot;&gt;# Create a tf.constant equal to C (depth), name it &amp;#39;C&amp;#39;. (approx. 1 line)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;C&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;constant&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;C&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;C&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

    &lt;span class=&quot;c1&quot;&gt;# Use tf.one_hot, be careful with the axis (approx. 1 line)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;one_hot_matrix&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;one_hot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;indices&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;labels&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;depth&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;C&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;axis&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

    &lt;span class=&quot;c1&quot;&gt;# Create the session (approx. 1 line)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;sess&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Session&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;

    &lt;span class=&quot;c1&quot;&gt;# Run the session (approx. 1 line)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;one_hot&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sess&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;run&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;one_hot_matrix&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

    &lt;span class=&quot;c1&quot;&gt;# Close the session (approx. 1 line). See method 1 above.&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;sess&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;close&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;



    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;one_hot&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div class=&quot;codehilite&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;labels&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;array&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;one_hot&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;one_hot_matrix&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;labels&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;C&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;one_hot = &amp;quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;one_hot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div class=&quot;codehilite&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;one_hot = [[ 0.  0.  0.  1.  0.  0.]
 [ 1.  0.  0.  0.  0.  1.]
 [ 0.  1.  0.  0.  1.  0.]
 [ 0.  0.  1.  0.  0.  0.]]
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;strong&gt;Expected Output&lt;/strong&gt;: &lt;/p&gt;
&lt;table&gt; 
    &lt;tr&gt; 
        &lt;td&gt;
            **one_hot**
        &lt;/td&gt;
        &lt;td&gt;
        [[ 0.  0.  0.  1.  0.  0.]
 [ 1.  0.  0.  0.  0.  1.]
 [ 0.  1.  0.  0.  1.  0.]
 [ 0.  0.  1.  0.  0.  0.]]
        &lt;/td&gt;
    &lt;/tr&gt;

&lt;/table&gt;

&lt;h3 id=&quot;15-initialize-with-zeros-and-ones&quot;&gt;1.5 - Initialize with zeros and ones&lt;/h3&gt;
&lt;p&gt;Now you will learn how to initialize a vector of zeros and ones. The function you will be calling is &lt;code&gt;tf.ones()&lt;/code&gt;. To initialize with zeros you could use tf.zeros() instead. These functions take in a shape and return an array of dimension shape full of zeros and ones respectively. &lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Exercise:&lt;/strong&gt; Implement the function below to take in a shape and to return an array (of the shape&#39;s dimension of ones). &lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;tf.ones(shape)&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&quot;codehilite&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;c1&quot;&gt;# GRADED FUNCTION: ones&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;ones&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;sd&quot;&gt;&amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    Creates an array of ones of dimension shape&lt;/span&gt;

&lt;span class=&quot;sd&quot;&gt;    Arguments:&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    shape -- shape of the array you want to create&lt;/span&gt;

&lt;span class=&quot;sd&quot;&gt;    Returns: &lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    ones -- array containing only ones&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    &amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;



    &lt;span class=&quot;c1&quot;&gt;# Create &amp;quot;ones&amp;quot; tensor using tf.ones(...). (approx. 1 line)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;ones&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ones&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

    &lt;span class=&quot;c1&quot;&gt;# Create the session (approx. 1 line)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;sess&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Session&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;

    &lt;span class=&quot;c1&quot;&gt;# Run the session to compute &amp;#39;ones&amp;#39; (approx. 1 line)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;ones&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sess&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;run&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ones&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

    &lt;span class=&quot;c1&quot;&gt;# Close the session (approx. 1 line). See method 1 above.&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;sess&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;close&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;


    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ones&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div class=&quot;codehilite&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;ones = &amp;quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ones&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])))&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div class=&quot;codehilite&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;ones = [ 1.  1.  1.]
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;strong&gt;Expected Output:&lt;/strong&gt;&lt;/p&gt;
&lt;table&gt; 
    &lt;tr&gt; 
        &lt;td&gt;
            **ones**
        &lt;/td&gt;
        &lt;td&gt;
        [ 1.  1.  1.]
        &lt;/td&gt;
    &lt;/tr&gt;

&lt;/table&gt;

&lt;h1 id=&quot;2-building-your-first-neural-network-in-tensorflow&quot;&gt;2 - Building your first neural network in tensorflow&lt;/h1&gt;
&lt;p&gt;In this part of the assignment you will build a neural network using tensorflow. Remember that there are two parts to implement a tensorflow model:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Create the computation graph&lt;/li&gt;
&lt;li&gt;Run the graph&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Let&#39;s delve into the problem you&#39;d like to solve!&lt;/p&gt;
&lt;h3 id=&quot;20-problem-statement-signs-dataset&quot;&gt;2.0 - Problem statement: SIGNS Dataset&lt;/h3&gt;
&lt;p&gt;One afternoon, with some friends we decided to teach our computers to decipher sign language. We spent a few hours taking pictures in front of a white wall and came up with the following dataset. It&#39;s now your job to build an algorithm that would facilitate communications from a speech-impaired person to someone who doesn&#39;t understand sign language.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Training set&lt;/strong&gt;: 1080 pictures (64 by 64 pixels) of signs representing numbers from 0 to 5 (180 pictures per number).&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Test set&lt;/strong&gt;: 120 pictures (64 by 64 pixels) of signs representing numbers from 0 to 5 (20 pictures per number).&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Note that this is a subset of the SIGNS dataset. The complete dataset contains many more signs.&lt;/p&gt;
&lt;p&gt;Here are examples for each number, and how an explanation of how we represent the labels. These are the original pictures, before we lowered the image resolutoion to 64 by 64 pixels.
&lt;img src=&quot;https://raw.githubusercontent.com/enggen/Deep-Learning-Coursera/master/Improving%20Deep%20Neural%20Networks%20Hyperparameter%20tuning%2C%20Regularization%20and%20Optimization/images/hands.png&quot; style=&quot;width:800px;height:350px;&quot;&gt;&lt;caption&gt;&lt;center&gt; &lt;u&gt; &lt;strong&gt;Figure 1&lt;/strong&gt;&lt;/u&gt;: SIGNS dataset &lt;br&gt; &lt;font color=&#39;black&#39;&gt; &lt;/center&gt;&lt;/p&gt;
&lt;p&gt;Run the following code to load the dataset.&lt;/p&gt;
&lt;div class=&quot;codehilite&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;c1&quot;&gt;# Loading the dataset&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;X_train_orig&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Y_train_orig&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X_test_orig&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Y_test_orig&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;classes&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;load_dataset&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Change the index below and run the cell to visualize some examples in the dataset.&lt;/p&gt;
&lt;div class=&quot;codehilite&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;c1&quot;&gt;# Example of a picture&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;index&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;imshow&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X_train_orig&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;index&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;y = &amp;quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;squeeze&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Y_train_orig&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[:,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;index&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])))&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div class=&quot;codehilite&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;y = 5
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;img alt=&quot;png&quot; src=&quot;https://raw.githubusercontent.com/karenyyy/Coursera_and_Udemy/master/deeplearningai_coursera/Improving%20Deep%20Neural%20Networks%3A%20Hyperparameter%20tuning%2C%20Regularization%20and%20Optimization%20Home/images/week3/output_35_1.png&quot; /&gt;&lt;/p&gt;
&lt;p&gt;As usual you flatten the image dataset, then normalize it by dividing by 255. On top of that, you will convert each label to a one-hot vector as shown in Figure 1. Run the cell below to do so.&lt;/p&gt;
&lt;div class=&quot;codehilite&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;c1&quot;&gt;# Flatten the training and test images&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;X_train_flatten&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X_train_orig&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;reshape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X_train_orig&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;T&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;X_test_flatten&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X_test_orig&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;reshape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X_test_orig&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;T&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;# Normalize image vectors&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;X_train&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X_train_flatten&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;255.&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;X_test&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X_test_flatten&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;255.&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;# Convert training and test labels to one hot matrices&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;Y_train&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;convert_to_one_hot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Y_train_orig&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;6&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;Y_test&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;convert_to_one_hot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Y_test_orig&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;6&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;number of training examples = &amp;quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X_train&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]))&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;number of test examples = &amp;quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X_test&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]))&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;X_train shape: &amp;quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X_train&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;Y_train shape: &amp;quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Y_train&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;X_test shape: &amp;quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X_test&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;Y_test shape: &amp;quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Y_test&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div class=&quot;codehilite&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;number of training examples = 1080
number of test examples = 120
X_train shape: (12288, 1080)
Y_train shape: (6, 1080)
X_test shape: (12288, 120)
Y_test shape: (6, 120)
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt; that 12288 comes from $64 \times 64 \times 3$. Each image is square, 64 by 64 pixels, and 3 is for the RGB colors. Please make sure all these shapes make sense to you before continuing.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Your goal&lt;/strong&gt; is to build an algorithm capable of recognizing a sign with high accuracy. To do so, you are going to build a tensorflow model that is almost the same as one you have previously built in numpy for cat recognition (but now using a softmax output). It is a great occasion to compare your numpy implementation to the tensorflow one. &lt;/p&gt;
&lt;p&gt;&lt;strong&gt;The model&lt;/strong&gt; is &lt;em&gt;LINEAR -&amp;gt; RELU -&amp;gt; LINEAR -&amp;gt; RELU -&amp;gt; LINEAR -&amp;gt; SOFTMAX&lt;/em&gt;. The SIGMOID output layer has been converted to a SOFTMAX. A SOFTMAX layer generalizes SIGMOID to when there are more than two classes. &lt;/p&gt;
&lt;h3 id=&quot;21-create-placeholders&quot;&gt;2.1 - Create placeholders&lt;/h3&gt;
&lt;p&gt;Your first task is to create placeholders for &lt;code&gt;X&lt;/code&gt; and &lt;code&gt;Y&lt;/code&gt;. This will allow you to later pass your training data in when you run your session. &lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Exercise:&lt;/strong&gt; Implement the function below to create the placeholders in tensorflow.&lt;/p&gt;
&lt;div class=&quot;codehilite&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;c1&quot;&gt;# GRADED FUNCTION: create_placeholders&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;create_placeholders&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n_x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n_y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;sd&quot;&gt;&amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    Creates the placeholders for the tensorflow session.&lt;/span&gt;

&lt;span class=&quot;sd&quot;&gt;    Arguments:&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    n_x -- scalar, size of an image vector (num_px * num_px = 64 * 64 * 3 = 12288)&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    n_y -- scalar, number of classes (from 0 to 5, so -&amp;gt; 6)&lt;/span&gt;

&lt;span class=&quot;sd&quot;&gt;    Returns:&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    X -- placeholder for the data input, of shape [n_x, None] and dtype &amp;quot;float&amp;quot;&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    Y -- placeholder for the input labels, of shape [n_y, None] and dtype &amp;quot;float&amp;quot;&lt;/span&gt;

&lt;span class=&quot;sd&quot;&gt;    Tips:&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    - You will use None because it let&amp;#39;s us be flexible on the number of examples you will for the placeholders.&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;      In fact, the number of examples during test/train is different.&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    &amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;


    &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;placeholder&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;float32&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n_x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;None&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;X&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;Y&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;placeholder&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;float32&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n_y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;None&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;Y&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;


    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Y&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div class=&quot;codehilite&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Y&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;create_placeholders&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;12288&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;6&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;X = &amp;quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;Y = &amp;quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div class=&quot;codehilite&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;X = Tensor(&amp;quot;X:0&amp;quot;, shape=(12288, ?), dtype=float32)
Y = Tensor(&amp;quot;Y:0&amp;quot;, shape=(6, ?), dtype=float32)
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;strong&gt;Expected Output&lt;/strong&gt;: &lt;/p&gt;
&lt;table&gt; 
    &lt;tr&gt; 
        &lt;td&gt;
            **X**
        &lt;/td&gt;
        &lt;td&gt;
        Tensor(&quot;Placeholder_1:0&quot;, shape=(12288, ?), dtype=float32) (not necessarily Placeholder_1)
        &lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt; 
        &lt;td&gt;
            **Y**
        &lt;/td&gt;
        &lt;td&gt;
        Tensor(&quot;Placeholder_2:0&quot;, shape=(6, ?), dtype=float32) (not necessarily Placeholder_2)
        &lt;/td&gt;
    &lt;/tr&gt;

&lt;/table&gt;

&lt;h3 id=&quot;22-initializing-the-parameters&quot;&gt;2.2 - Initializing the parameters&lt;/h3&gt;
&lt;p&gt;Your second task is to initialize the parameters in tensorflow.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Exercise:&lt;/strong&gt; Implement the function below to initialize the parameters in tensorflow. You are going use Xavier Initialization for weights and Zero Initialization for biases. The shapes are given below. As an example, to help you, for W1 and b1 you could use: &lt;/p&gt;
&lt;div class=&quot;codehilite&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;W1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;get_variable&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;W1&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;25&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;12288&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;initializer&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;contrib&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;layers&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;xavier_initializer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;seed&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;b1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;get_variable&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;b1&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;25&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;initializer&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;zeros_initializer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;())&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Please use &lt;code&gt;seed = 1&lt;/code&gt; to make sure your results match ours.&lt;/p&gt;
&lt;div class=&quot;codehilite&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;c1&quot;&gt;# GRADED FUNCTION: initialize_parameters&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;initialize_parameters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;():&lt;/span&gt;
    &lt;span class=&quot;sd&quot;&gt;&amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    Initializes parameters to build a neural network with tensorflow. The shapes are:&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;                        W1 : [25, 12288]&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;                        b1 : [25, 1]&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;                        W2 : [12, 25]&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;                        b2 : [12, 1]&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;                        W3 : [6, 12]&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;                        b3 : [6, 1]&lt;/span&gt;

&lt;span class=&quot;sd&quot;&gt;    Returns:&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    parameters -- a dictionary of tensors containing W1, b1, W2, b2, W3, b3&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    &amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;

    &lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;set_random_seed&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;                   &lt;span class=&quot;c1&quot;&gt;# so that your &amp;quot;random&amp;quot; numbers match ours&lt;/span&gt;


    &lt;span class=&quot;n&quot;&gt;W1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;get_variable&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;W1&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;25&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;12288&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;initializer&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;contrib&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;layers&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;xavier_initializer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;seed&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;b1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;get_variable&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;b1&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;25&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;initializer&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;zeros_initializer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;())&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;W2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;get_variable&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;W2&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;12&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;25&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;initializer&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;contrib&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;layers&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;xavier_initializer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;seed&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;b2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;get_variable&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;b2&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;12&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;initializer&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;zeros_initializer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;())&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;W3&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;get_variable&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;W3&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;6&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;12&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;initializer&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;contrib&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;layers&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;xavier_initializer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;seed&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;b3&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;get_variable&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;b3&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;6&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;initializer&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;zeros_initializer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;())&lt;/span&gt;


    &lt;span class=&quot;n&quot;&gt;parameters&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;W1&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;W1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                  &lt;span class=&quot;s2&quot;&gt;&amp;quot;b1&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;b1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                  &lt;span class=&quot;s2&quot;&gt;&amp;quot;W2&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;W2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                  &lt;span class=&quot;s2&quot;&gt;&amp;quot;b2&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;b2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                  &lt;span class=&quot;s2&quot;&gt;&amp;quot;W3&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;W3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                  &lt;span class=&quot;s2&quot;&gt;&amp;quot;b3&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;b3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;

    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;parameters&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div class=&quot;codehilite&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;reset_default_graph&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;with&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Session&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sess&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;parameters&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;initialize_parameters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;W1 = &amp;quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;parameters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;W1&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]))&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;b1 = &amp;quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;parameters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;b1&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]))&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;W2 = &amp;quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;parameters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;W2&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]))&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;b2 = &amp;quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;parameters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;b2&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]))&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div class=&quot;codehilite&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;W1 = &amp;lt;tf.Variable &amp;#39;W1:0&amp;#39; shape=(25, 12288) dtype=float32_ref&amp;gt;
b1 = &amp;lt;tf.Variable &amp;#39;b1:0&amp;#39; shape=(25, 1) dtype=float32_ref&amp;gt;
W2 = &amp;lt;tf.Variable &amp;#39;W2:0&amp;#39; shape=(12, 25) dtype=float32_ref&amp;gt;
b2 = &amp;lt;tf.Variable &amp;#39;b2:0&amp;#39; shape=(12, 1) dtype=float32_ref&amp;gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;strong&gt;Expected Output&lt;/strong&gt;: &lt;/p&gt;
&lt;table&gt; 
    &lt;tr&gt; 
        &lt;td&gt;
            **W1**
        &lt;/td&gt;
        &lt;td&gt;
         &lt; tf.Variable &#39;W1:0&#39; shape=(25, 12288) dtype=float32_ref &gt;
        &lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt; 
        &lt;td&gt;
            **b1**
        &lt;/td&gt;
        &lt;td&gt;
        &lt; tf.Variable &#39;b1:0&#39; shape=(25, 1) dtype=float32_ref &gt;
        &lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt; 
        &lt;td&gt;
            **W2**
        &lt;/td&gt;
        &lt;td&gt;
        &lt; tf.Variable &#39;W2:0&#39; shape=(12, 25) dtype=float32_ref &gt;
        &lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt; 
        &lt;td&gt;
            **b2**
        &lt;/td&gt;
        &lt;td&gt;
        &lt; tf.Variable &#39;b2:0&#39; shape=(12, 1) dtype=float32_ref &gt;
        &lt;/td&gt;
    &lt;/tr&gt;

&lt;/table&gt;

&lt;p&gt;As expected, the parameters haven&#39;t been evaluated yet.&lt;/p&gt;
&lt;h3 id=&quot;23-forward-propagation-in-tensorflow&quot;&gt;2.3 - Forward propagation in tensorflow&lt;/h3&gt;
&lt;p&gt;You will now implement the forward propagation module in tensorflow. The function will take in a dictionary of parameters and it will complete the forward pass. The functions you will be using are: &lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;tf.add(...,...)&lt;/code&gt; to do an addition&lt;/li&gt;
&lt;li&gt;&lt;code&gt;tf.matmul(...,...)&lt;/code&gt; to do a matrix multiplication&lt;/li&gt;
&lt;li&gt;&lt;code&gt;tf.nn.relu(...)&lt;/code&gt; to apply the ReLU activation&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Question:&lt;/strong&gt; Implement the forward pass of the neural network. We commented for you the numpy equivalents so that you can compare the tensorflow implementation to numpy. It is important to note that the forward propagation stops at &lt;code&gt;z3&lt;/code&gt;. The reason is that in tensorflow the last linear layer output is given as input to the function computing the loss. Therefore, you don&#39;t need &lt;code&gt;a3&lt;/code&gt;!&lt;/p&gt;
&lt;div class=&quot;codehilite&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;c1&quot;&gt;# GRADED FUNCTION: forward_propagation&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;forward_propagation&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;parameters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;sd&quot;&gt;&amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    Implements the forward propagation for the model: LINEAR -&amp;gt; RELU -&amp;gt; LINEAR -&amp;gt; RELU -&amp;gt; LINEAR -&amp;gt; SOFTMAX&lt;/span&gt;

&lt;span class=&quot;sd&quot;&gt;    Arguments:&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    X -- input dataset placeholder, of shape (input size, number of examples)&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    parameters -- python dictionary containing your parameters &amp;quot;W1&amp;quot;, &amp;quot;b1&amp;quot;, &amp;quot;W2&amp;quot;, &amp;quot;b2&amp;quot;, &amp;quot;W3&amp;quot;, &amp;quot;b3&amp;quot;&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;                  the shapes are given in initialize_parameters&lt;/span&gt;

&lt;span class=&quot;sd&quot;&gt;    Returns:&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    Z3 -- the output of the last LINEAR unit&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    &amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;

    &lt;span class=&quot;c1&quot;&gt;# Retrieve the parameters from the dictionary &amp;quot;parameters&amp;quot; &lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;W1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;parameters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;W1&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;b1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;parameters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;b1&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;W2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;parameters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;W2&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;b2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;parameters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;b2&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;W3&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;parameters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;W3&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;b3&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;parameters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;b3&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;


    &lt;span class=&quot;n&quot;&gt;Z1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;add&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;matmul&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;W1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;b1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;                      &lt;span class=&quot;c1&quot;&gt;# Z1 = np.dot(W1, X) + b1&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;A1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;relu&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Z1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;                                    &lt;span class=&quot;c1&quot;&gt;# A1 = relu(Z1)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;Z2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;add&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;matmul&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;W2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;A1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;b2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;                     &lt;span class=&quot;c1&quot;&gt;# Z2 = np.dot(W2, a1) + b2&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;A2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;relu&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Z2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;                                    &lt;span class=&quot;c1&quot;&gt;# A2 = relu(Z2)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;Z3&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;add&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;matmul&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;W3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;A2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;b3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;                     &lt;span class=&quot;c1&quot;&gt;# Z3 = np.dot(W3,Z2) + b3&lt;/span&gt;


    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Z3&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div class=&quot;codehilite&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;reset_default_graph&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;with&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Session&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sess&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Y&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;create_placeholders&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;12288&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;6&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;parameters&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;initialize_parameters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;Z3&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;forward_propagation&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;parameters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;Z3 = &amp;quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Z3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div class=&quot;codehilite&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;Z3 = Tensor(&amp;quot;Add_2:0&amp;quot;, shape=(6, ?), dtype=float32)
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;strong&gt;Expected Output&lt;/strong&gt;: &lt;/p&gt;
&lt;table&gt; 
    &lt;tr&gt; 
        &lt;td&gt;
            **Z3**
        &lt;/td&gt;
        &lt;td&gt;
        Tensor(&quot;Add_2:0&quot;, shape=(6, ?), dtype=float32)
        &lt;/td&gt;
    &lt;/tr&gt;

&lt;/table&gt;

&lt;p&gt;You may have noticed that the forward propagation doesn&#39;t output any cache. You will understand why below, when we get to brackpropagation.&lt;/p&gt;
&lt;h3 id=&quot;24-compute-cost&quot;&gt;2.4 Compute cost&lt;/h3&gt;
&lt;p&gt;As seen before, it is very easy to compute the cost using:&lt;/p&gt;
&lt;div class=&quot;codehilite&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;reduce_mean&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;softmax_cross_entropy_with_logits&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;logits&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;...&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;labels&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;...&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;strong&gt;Question&lt;/strong&gt;: Implement the cost function below. 
- It is important to know that the &quot;&lt;code&gt;logits&lt;/code&gt;&quot; and &quot;&lt;code&gt;labels&lt;/code&gt;&quot; inputs of &lt;code&gt;tf.nn.softmax_cross_entropy_with_logits&lt;/code&gt; are expected to be of shape (number of examples, num_classes). We have thus transposed Z3 and Y for you.
- Besides, &lt;code&gt;tf.reduce_mean&lt;/code&gt; basically does the summation over the examples.&lt;/p&gt;
&lt;div class=&quot;codehilite&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;c1&quot;&gt;# GRADED FUNCTION: compute_cost &lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;compute_cost&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Z3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;sd&quot;&gt;&amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    Computes the cost&lt;/span&gt;

&lt;span class=&quot;sd&quot;&gt;    Arguments:&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    Z3 -- output of forward propagation (output of the last LINEAR unit), of shape (6, number of examples)&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    Y -- &amp;quot;true&amp;quot; labels vector placeholder, same shape as Z3&lt;/span&gt;

&lt;span class=&quot;sd&quot;&gt;    Returns:&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    cost - Tensor of the cost function&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    &amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;

    &lt;span class=&quot;c1&quot;&gt;# to fit the tensorflow requirement for tf.nn.softmax_cross_entropy_with_logits(...,...)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;logits&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;transpose&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Z3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;labels&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;transpose&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;


    &lt;span class=&quot;n&quot;&gt;cost&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;reduce_mean&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;softmax_cross_entropy_with_logits&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;logits&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;logits&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;labels&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;labels&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;


    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cost&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div class=&quot;codehilite&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;reset_default_graph&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;with&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Session&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sess&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Y&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;create_placeholders&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;12288&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;6&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;parameters&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;initialize_parameters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;Z3&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;forward_propagation&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;parameters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;cost&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;compute_cost&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Z3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;cost = &amp;quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cost&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div class=&quot;codehilite&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;cost = Tensor(&amp;quot;Mean:0&amp;quot;, shape=(), dtype=float32)
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;strong&gt;Expected Output&lt;/strong&gt;: &lt;/p&gt;
&lt;table&gt; 
    &lt;tr&gt; 
        &lt;td&gt;
            **cost**
        &lt;/td&gt;
        &lt;td&gt;
        Tensor(&quot;Mean:0&quot;, shape=(), dtype=float32)
        &lt;/td&gt;
    &lt;/tr&gt;

&lt;/table&gt;

&lt;h3 id=&quot;25-backward-propagation-parameter-updates&quot;&gt;2.5 - Backward propagation &amp;amp; parameter updates&lt;/h3&gt;
&lt;p&gt;This is where you become grateful to programming frameworks. All the backpropagation and the parameters update is taken care of in 1 line of code. It is very easy to incorporate this line in the model.&lt;/p&gt;
&lt;p&gt;After you compute the cost function. You will create an &quot;&lt;code&gt;optimizer&lt;/code&gt;&quot; object. You have to call this object along with the cost when running the tf.session. When called, it will perform an optimization on the given cost with the chosen method and learning rate.&lt;/p&gt;
&lt;p&gt;For instance, for gradient descent the optimizer would be:&lt;/p&gt;
&lt;div class=&quot;codehilite&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;optimizer&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;train&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;GradientDescentOptimizer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;learning_rate&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;learning_rate&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;minimize&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cost&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;To make the optimization you would do:&lt;/p&gt;
&lt;div class=&quot;codehilite&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;_&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;c&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sess&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;run&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;optimizer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cost&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;feed_dict&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;minibatch_X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;minibatch_Y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;})&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;This computes the backpropagation by passing through the tensorflow graph in the reverse order. From cost to inputs.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt; When coding, we often use &lt;code&gt;_&lt;/code&gt; as a &quot;throwaway&quot; variable to store values that we won&#39;t need to use later. Here, &lt;code&gt;_&lt;/code&gt; takes on the evaluated value of &lt;code&gt;optimizer&lt;/code&gt;, which we don&#39;t need (and &lt;code&gt;c&lt;/code&gt; takes the value of the &lt;code&gt;cost&lt;/code&gt; variable). &lt;/p&gt;
&lt;h3 id=&quot;26-building-the-model&quot;&gt;2.6 - Building the model&lt;/h3&gt;
&lt;p&gt;Now, you will bring it all together! &lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Exercise:&lt;/strong&gt; Implement the model. You will be calling the functions you had previously implemented.&lt;/p&gt;
&lt;div class=&quot;codehilite&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X_train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Y_train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X_test&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Y_test&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;learning_rate&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.0001&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
          &lt;span class=&quot;n&quot;&gt;num_epochs&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1500&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;minibatch_size&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;32&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;print_cost&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;sd&quot;&gt;&amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    Implements a three-layer tensorflow neural network: LINEAR-&amp;gt;RELU-&amp;gt;LINEAR-&amp;gt;RELU-&amp;gt;LINEAR-&amp;gt;SOFTMAX.&lt;/span&gt;

&lt;span class=&quot;sd&quot;&gt;    Arguments:&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    X_train -- training set, of shape (input size = 12288, number of training examples = 1080)&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    Y_train -- test set, of shape (output size = 6, number of training examples = 1080)&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    X_test -- training set, of shape (input size = 12288, number of training examples = 120)&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    Y_test -- test set, of shape (output size = 6, number of test examples = 120)&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    learning_rate -- learning rate of the optimization&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    num_epochs -- number of epochs of the optimization loop&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    minibatch_size -- size of a minibatch&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    print_cost -- True to print the cost every 100 epochs&lt;/span&gt;

&lt;span class=&quot;sd&quot;&gt;    Returns:&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    parameters -- parameters learnt by the model. They can then be used to predict.&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    &amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;

    &lt;span class=&quot;n&quot;&gt;ops&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;reset_default_graph&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;                         &lt;span class=&quot;c1&quot;&gt;# to be able to rerun the model without overwriting tf variables&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;set_random_seed&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;                             &lt;span class=&quot;c1&quot;&gt;# to keep consistent results&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;seed&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;                                          &lt;span class=&quot;c1&quot;&gt;# to keep consistent results&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n_x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;m&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X_train&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;                          &lt;span class=&quot;c1&quot;&gt;# (n_x: input size, m : number of examples in the train set)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;n_y&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Y_train&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;                            &lt;span class=&quot;c1&quot;&gt;# n_y : output size&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;costs&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[]&lt;/span&gt;                                        &lt;span class=&quot;c1&quot;&gt;# To keep track of the cost&lt;/span&gt;

    &lt;span class=&quot;c1&quot;&gt;# Create Placeholders of shape (n_x, n_y)&lt;/span&gt;

    &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Y&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;create_placeholders&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n_x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n_y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;


    &lt;span class=&quot;c1&quot;&gt;# Initialize parameters&lt;/span&gt;

    &lt;span class=&quot;n&quot;&gt;parameters&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;initialize_parameters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;


    &lt;span class=&quot;c1&quot;&gt;# Forward propagation: Build the forward propagation in the tensorflow graph&lt;/span&gt;

    &lt;span class=&quot;n&quot;&gt;Z3&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;forward_propagation&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;parameters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;


    &lt;span class=&quot;c1&quot;&gt;# Cost function: Add cost function to tensorflow graph&lt;/span&gt;

    &lt;span class=&quot;n&quot;&gt;cost&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;compute_cost&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Z3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;


    &lt;span class=&quot;c1&quot;&gt;# Backpropagation: Define the tensorflow optimizer. Use an AdamOptimizer.&lt;/span&gt;

    &lt;span class=&quot;n&quot;&gt;optimizer&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;train&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;AdamOptimizer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;learning_rate&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;learning_rate&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;minimize&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cost&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;


    &lt;span class=&quot;c1&quot;&gt;# Initialize all the variables&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;init&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;global_variables_initializer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;

    &lt;span class=&quot;c1&quot;&gt;# Start the session to compute the tensorflow graph&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;with&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Session&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sess&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;

        &lt;span class=&quot;c1&quot;&gt;# Run the initialization&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;sess&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;run&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;init&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

        &lt;span class=&quot;c1&quot;&gt;# Do the training loop&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;epoch&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;num_epochs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;

            &lt;span class=&quot;n&quot;&gt;epoch_cost&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.&lt;/span&gt;                       &lt;span class=&quot;c1&quot;&gt;# Defines a cost related to an epoch&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;num_minibatches&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;int&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;m&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;minibatch_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;# number of minibatches of size minibatch_size in the train set&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;seed&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;seed&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;minibatches&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;random_mini_batches&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X_train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Y_train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;minibatch_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;seed&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

            &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;minibatch&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;minibatches&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;

                &lt;span class=&quot;c1&quot;&gt;# Select a minibatch&lt;/span&gt;
                &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;minibatch_X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;minibatch_Y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;minibatch&lt;/span&gt;

                &lt;span class=&quot;c1&quot;&gt;# IMPORTANT: The line that runs the graph on a minibatch.&lt;/span&gt;
                &lt;span class=&quot;c1&quot;&gt;# Run the session to execute the &amp;quot;optimizer&amp;quot; and the &amp;quot;cost&amp;quot;, the feedict should contain a minibatch for (X,Y).&lt;/span&gt;

                &lt;span class=&quot;n&quot;&gt;_&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;minibatch_cost&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sess&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;run&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;optimizer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cost&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;feed_dict&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;minibatch_X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;minibatch_Y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;})&lt;/span&gt;


                &lt;span class=&quot;n&quot;&gt;epoch_cost&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;minibatch_cost&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;num_minibatches&lt;/span&gt;

            &lt;span class=&quot;c1&quot;&gt;# Print the cost every epoch&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;print_cost&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;and&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;epoch&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;%&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;100&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
                &lt;span class=&quot;k&quot;&gt;print&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;Cost after epoch &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;%i&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;: &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;%f&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;%&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;epoch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;epoch_cost&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;print_cost&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;and&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;epoch&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;%&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;costs&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;append&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;epoch_cost&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

        &lt;span class=&quot;c1&quot;&gt;# plot the cost&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;plot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;squeeze&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;costs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ylabel&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;cost&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;xlabel&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;iterations (per tens)&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;title&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;Learning rate =&amp;quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;learning_rate&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;show&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;

        &lt;span class=&quot;c1&quot;&gt;# lets save the parameters in a variable&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;parameters&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sess&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;run&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;parameters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;Parameters have been trained!&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

        &lt;span class=&quot;c1&quot;&gt;# Calculate the correct predictions&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;correct_prediction&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;equal&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;argmax&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Z3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;argmax&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;

        &lt;span class=&quot;c1&quot;&gt;# Calculate accuracy on the test set&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;accuracy&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;reduce_mean&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cast&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;correct_prediction&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&amp;quot;float&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;

        &lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;Train Accuracy:&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;accuracy&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;eval&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;({&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X_train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Y_train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}))&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;Test Accuracy:&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;accuracy&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;eval&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;({&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X_test&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Y_test&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}))&lt;/span&gt;

        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;parameters&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Run the following cell to train your model! On our machine it takes about 5 minutes. Your &quot;Cost after epoch 100&quot; should be 1.016458. If it&#39;s not, don&#39;t waste time; interrupt the training by clicking on the square (⬛) in the upper bar of the notebook, and try to correct your code. If it is the correct cost, take a break and come back in 5 minutes!&lt;/p&gt;
&lt;div class=&quot;codehilite&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;parameters&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X_train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Y_train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X_test&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Y_test&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div class=&quot;codehilite&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;Cost after epoch 0: 1.855702
Cost after epoch 100: 1.016458
Cost after epoch 200: 0.733102
Cost after epoch 300: 0.572940
Cost after epoch 400: 0.468774
Cost after epoch 500: 0.381021
Cost after epoch 600: 0.313822
Cost after epoch 700: 0.254158
Cost after epoch 800: 0.203829
Cost after epoch 900: 0.166421
Cost after epoch 1000: 0.141486
Cost after epoch 1100: 0.107580
Cost after epoch 1200: 0.086270
Cost after epoch 1300: 0.059371
Cost after epoch 1400: 0.052228
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;img alt=&quot;png&quot; src=&quot;https://raw.githubusercontent.com/karenyyy/Coursera_and_Udemy/master/deeplearningai_coursera/Improving%20Deep%20Neural%20Networks%3A%20Hyperparameter%20tuning%2C%20Regularization%20and%20Optimization%20Home/images/week3/output_62_1.png&quot; /&gt;&lt;/p&gt;
&lt;div class=&quot;codehilite&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;Parameters have been trained!
Train Accuracy: 0.999074
Test Accuracy: 0.716667
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;strong&gt;Expected Output&lt;/strong&gt;:&lt;/p&gt;
&lt;table&gt; 
    &lt;tr&gt; 
        &lt;td&gt;
            **Train Accuracy**
        &lt;/td&gt;
        &lt;td&gt;
        0.999074
        &lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt; 
        &lt;td&gt;
            **Test Accuracy**
        &lt;/td&gt;
        &lt;td&gt;
        0.716667
        &lt;/td&gt;
    &lt;/tr&gt;

&lt;/table&gt;

&lt;p&gt;Amazing, your algorithm can recognize a sign representing a figure between 0 and 5 with 71.7% accuracy.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Insights&lt;/strong&gt;:
- Your model seems big enough to fit the training set well. However, given the difference between train and test accuracy, you could try to add L2 or dropout regularization to reduce overfitting. 
- Think about the session as a block of code to train the model. Each time you run the session on a minibatch, it trains the parameters. In total you have run the session a large number of times (1500 epochs) until you obtained well trained parameters.&lt;/p&gt;
&lt;h3 id=&quot;27-test-with-your-own-image-optional-ungraded-exercise&quot;&gt;2.7 - Test with your own image (optional / ungraded exercise)&lt;/h3&gt;
&lt;p&gt;Congratulations on finishing this assignment. You can now take a picture of your hand and see the output of your model. To do that:
    1. Click on &quot;File&quot; in the upper bar of this notebook, then click &quot;Open&quot; to go on your Coursera Hub.
    2. Add your image to this Jupyter Notebook&#39;s directory, in the &quot;images&quot; folder
    3. Write your image&#39;s name in the following code
    4. Run the code and check if the algorithm is right!&lt;/p&gt;
&lt;div class=&quot;codehilite&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;scipy&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;PIL&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Image&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;scipy&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ndimage&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;## START CODE HERE ## (PUT YOUR IMAGE NAME) &lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;my_image&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&amp;quot;thumbs_up.jpg&amp;quot;&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;## END CODE HERE ##&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# We preprocess your image to fit your algorithm.&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;fname&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&amp;quot;images/&amp;quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;my_image&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;image&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;array&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ndimage&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;imread&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fname&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;flatten&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;False&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;my_image&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;scipy&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;misc&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;imresize&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;image&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;size&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;64&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;64&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;reshape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;((&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;64&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;64&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;T&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;my_image_prediction&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;predict&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;my_image&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;parameters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;imshow&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;image&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;Your algorithm predicts: y = &amp;quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;squeeze&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;my_image_prediction&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)))&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div class=&quot;codehilite&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;Your algorithm predicts: y = 3
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;img alt=&quot;png&quot; src=&quot;https://raw.githubusercontent.com/karenyyy/Coursera_and_Udemy/master/deeplearningai_coursera/Improving%20Deep%20Neural%20Networks%3A%20Hyperparameter%20tuning%2C%20Regularization%20and%20Optimization%20Home/images/week3/output_65_1.png&quot; /&gt;&lt;/p&gt;
&lt;p&gt;You indeed deserved a &quot;thumbs-up&quot; although as you can see the algorithm seems to classify it incorrectly. The reason is that the training set doesn&#39;t contain any &quot;thumbs-up&quot;, so the model doesn&#39;t know how to deal with it! We call that a &quot;mismatched data distribution&quot; and it is one of the various of the next course on &quot;Structuring Machine Learning Projects&quot;.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;What you should remember&lt;/strong&gt;:
- Tensorflow is a programming framework used in deep learning
- The two main object classes in tensorflow are Tensors and Operators. 
- When you code in tensorflow you have to take the following steps:
    - Create a graph containing Tensors (Variables, Placeholders ...) and Operations (tf.matmul, tf.add, ...)
    - Create a session
    - Initialize the session
    - Run the session to execute the graph
- You can execute the graph multiple times as you&#39;ve seen in model()
- The backpropagation and optimization is automatically done when running the session on the &quot;optimizer&quot; object.&lt;/p&gt;deeplearning.ai - Improving Deep Neural Networks - Week 1 Notes
&lt;h2 id=&quot;week1&quot;&gt;Week1&lt;/h2&gt;
&lt;h3 id=&quot;traindevelopmentdevtest-datasets&quot;&gt;Train/development(dev)/test datasets&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Notes: &lt;ul&gt;
&lt;li&gt;train test split ratio in normal dataset and modern big dataset is quite different.&lt;/li&gt;
&lt;li&gt;not having test dataset is also ok, just use the dev set as the test set.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://raw.githubusercontent.com/karenyyy/Coursera_and_Udemy/master/deeplearningai_coursera/Improving%20Deep%20Neural%20Networks%3A%20Hyperparameter%20tuning%2C%20Regularization%20and%20Optimization%20Home/images/1.png&quot; /&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;What if the distribution between training dataset and the validation dataset are mismatched?&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;strong&gt;Fix: Make sure the dev and test dataset come from the same distribution!&lt;/strong&gt;
&lt;img alt=&quot;&quot; src=&quot;![](https://raw.githubusercontent.com/karenyyy/Coursera_and_Udemy/master/deeplearningai_coursera/Improving%20Deep%20Neural%20Networks%3A%20Hyperparameter%20tuning%2C%20Regularization%20and%20Optimization%20Home/images/2.png&quot; /&gt;&lt;/p&gt;
&lt;h3 id=&quot;bias-and-variance-bias-variance-trade-off&quot;&gt;Bias and Variance (bias-variance trade-off)&lt;/h3&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://raw.githubusercontent.com/karenyyy/Coursera_and_Udemy/master/deeplearningai_coursera/Improving%20Deep%20Neural%20Networks%3A%20Hyperparameter%20tuning%2C%20Regularization%20and%20Optimization%20Home/images/3.png&quot; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://raw.githubusercontent.com/karenyyy/Coursera_and_Udemy/master/deeplearningai_coursera/Improving%20Deep%20Neural%20Networks%3A%20Hyperparameter%20tuning%2C%20Regularization%20and%20Optimization%20Home/images/4.png&quot; /&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Basic recipes for machine learning&lt;/strong&gt;&lt;ul&gt;
&lt;li&gt;High bias (underfitting)&lt;ul&gt;
&lt;li&gt;bigger network&lt;/li&gt;
&lt;li&gt;train longer iterations&lt;/li&gt;
&lt;li&gt;try other neural network architecture approach&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;High variance (overfitting)&lt;ul&gt;
&lt;li&gt;get more data (data augmentation)&lt;/li&gt;
&lt;li&gt;regularization&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://raw.githubusercontent.com/karenyyy/Coursera_and_Udemy/master/deeplearningai_coursera/Improving%20Deep%20Neural%20Networks%3A%20Hyperparameter%20tuning%2C%20Regularization%20and%20Optimization%20Home/images/5.png&quot; /&gt;&lt;/p&gt;
&lt;h3 id=&quot;regularization&quot;&gt;Regularization&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;For a single layer NN:
$$\min_{w, b} J(w, b)$$&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;$$\text{ where } J(w,b) = \frac{1}{m} \sum^m_{i=1} L(\hat y^{(i)}, y^{(i)}) + \frac{\lambda}{2m} ||w||_2^2$$&lt;/p&gt;
&lt;p&gt;$$\text{ and where },   ||w||&lt;em j=&quot;1&quot;&gt;2^2 = \sum&lt;/em&gt;^{n_x} w_j^2 = w^Tw$$&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;For a multiple-layer NN
$$J(w^{[1]}, b^{[1]}, ..., w^{[L]}, b^{[L]}) = \frac{1}{m}\sum^n_{i=1} L(\hat y ^{(i)},  y^{(i)}) + \frac{\lambda}{2m} \sum^{L}_{l=1} ||w^{[l]}||^2_F$$&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;$$\text{ where } ||w^{[l]}||^2_F = \sum^{}&lt;em&gt;{}\sum^{}&lt;/em&gt; (w_{ij}^{[l]})^2 $$&lt;/p&gt;
&lt;p&gt;So&lt;/p&gt;
&lt;p&gt;$$dw^{[l]} = (\text{ from backprop }) + \frac{\lambda}{m} w^{[l]}$$&lt;/p&gt;
&lt;p&gt;$$\text{ here from backprop } dw^{[l]} = \frac{1}{m} dz^{[l]}A^{T} $$
$$w^{[l]} = w^{[l]} - \alpha \cdot dw^{[l]}$$&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;why can regularization prevent overfitting?&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://raw.githubusercontent.com/karenyyy/Coursera_and_Udemy/master/deeplearningai_coursera/Improving%20Deep%20Neural%20Networks%3A%20Hyperparameter%20tuning%2C%20Regularization%20and%20Optimization%20Home/images/6.png&quot; /&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;One piece of intuition is that, if you crank the regularization lambda to be really big, they will be incentivized to set the weight matrices W to be reasonably close to zero, which is basically zeroing out a lot of the impact of these hidden units&lt;/li&gt;
&lt;li&gt;Vice Versa. If w is really big, then lambda is close to zero;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://raw.githubusercontent.com/karenyyy/Coursera_and_Udemy/master/deeplearningai_coursera/Improving%20Deep%20Neural%20Networks%3A%20Hyperparameter%20tuning%2C%20Regularization%20and%20Optimization%20Home/images/7.png&quot; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://raw.githubusercontent.com/karenyyy/Coursera_and_Udemy/master/deeplearningai_coursera/Improving%20Deep%20Neural%20Networks%3A%20Hyperparameter%20tuning%2C%20Regularization%20and%20Optimization%20Home/images/8.png&quot; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Note: Put all the intuition aside, zeroing out W in practice is not actually what happens. We should think of it as zeroing out or at least reducing the impact of a lot of the hidden units so you end up with what might feel like a simpler network.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;The intuition of completely zeroing out a hidden unit isn&#39;t quite right. What actually happens is they will still use all the hidden units, but each of them would just have a much smaller effect. But you do end up with a simpler network and as thus less prome to overfitting.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://raw.githubusercontent.com/karenyyy/Coursera_and_Udemy/master/deeplearningai_coursera/Improving%20Deep%20Neural%20Networks%3A%20Hyperparameter%20tuning%2C%20Regularization%20and%20Optimization%20Home/images/9.png&quot; /&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;An example exactly why regularization prevent overfitting?&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Use tanh as activation function&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;if z is quite small, if z takes on only a smallish range of parameters, &lt;strong&gt;then you are just using the linear regime of the tanh&lt;/strong&gt;, only if z is allowed to wander up to larger values or smaller values like so, then the activation function starts to become less linear.&lt;/li&gt;
&lt;li&gt;So, as we know, if lambda is large, w will be small, because they are penalized being large into a cost function, since &lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;$$z^{[l]} = w^{[l]} a^{[l-1]} +b^{[l]}$$&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;if w tends to be very small, then z will also be relatively small, and if z ends up taking relatively small values,  then g(z) will be roughly linear, so if every layer is roughly linear, then the whole network is basically linea, &lt;strong&gt;so not able to fit the very non-linear decision boundaries that allow it to really overfit right to datasets like we saw on the overfitting high variance case&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&quot;extra-note&quot;&gt;Extra note:&lt;/h4&gt;
&lt;blockquote&gt;
&lt;p&gt;how to use cost function to debug gradient descent function?&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://raw.githubusercontent.com/karenyyy/Coursera_and_Udemy/master/deeplearningai_coursera/Improving%20Deep%20Neural%20Networks%3A%20Hyperparameter%20tuning%2C%20Regularization%20and%20Optimization%20Home/images/10.png&quot; /&gt;&lt;/p&gt;
&lt;p&gt;As we can see, the expected cost decreases monotonically after every elevation of gradient descent.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Make sure add the regularization part into J!!&lt;/strong&gt;&lt;/p&gt;
&lt;h4 id=&quot;dropout-regularization&quot;&gt;Dropout Regularization&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;Inverted dropout&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://raw.githubusercontent.com/karenyyy/Coursera_and_Udemy/master/deeplearningai_coursera/Improving%20Deep%20Neural%20Networks%3A%20Hyperparameter%20tuning%2C%20Regularization%20and%20Optimization%20Home/images/11.png&quot; /&gt;&lt;/p&gt;
&lt;p&gt;Since the NN value of a is reduced, to make sure the NN value of z remains the same, use inverted dropout, which means increase NN size of a by &lt;strong&gt;a/ = keep.prob&lt;/strong&gt;, so that we don&#39;t need to add add in an extra scalling parameter at test time, and this inverted dropout technique makes test time when evaluating the NN easier, because we have less of a scaling problem.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;No Dropout at test time! that&#39;s just adding noise to the final result&lt;/strong&gt;&lt;/p&gt;
&lt;h4 id=&quot;why-does-dropout-work&quot;&gt;Why does dropout work?&lt;/h4&gt;
&lt;p&gt;&lt;strong&gt;Intuition: Can&#39;t rely on any one feature, so have to spread out weights.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://raw.githubusercontent.com/karenyyy/Coursera_and_Udemy/master/deeplearningai_coursera/Improving%20Deep%20Neural%20Networks%3A%20Hyperparameter%20tuning%2C%20Regularization%20and%20Optimization%20Home/images/12.png&quot; /&gt;&lt;/p&gt;
&lt;h4 id=&quot;other-methods-of-regularization&quot;&gt;Other methods of regularization&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;Data Augmentation&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://raw.githubusercontent.com/karenyyy/Coursera_and_Udemy/master/deeplearningai_coursera/Improving%20Deep%20Neural%20Networks%3A%20Hyperparameter%20tuning%2C%20Regularization%20and%20Optimization%20Home/images/13.png&quot; /&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Early Stopping&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://raw.githubusercontent.com/karenyyy/Coursera_and_Udemy/master/deeplearningai_coursera/Improving%20Deep%20Neural%20Networks%3A%20Hyperparameter%20tuning%2C%20Regularization%20and%20Optimization%20Home/images/15.png&quot; /&gt;&lt;/p&gt;
&lt;h3 id=&quot;setting-up-your-optimization-problem&quot;&gt;Setting up your optimization problem&lt;/h3&gt;
&lt;h4 id=&quot;normalizing-inputs&quot;&gt;Normalizing inputs&lt;/h4&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://raw.githubusercontent.com/karenyyy/Coursera_and_Udemy/master/deeplearningai_coursera/Improving%20Deep%20Neural%20Networks%3A%20Hyperparameter%20tuning%2C%20Regularization%20and%20Optimization%20Home/images/16.png&quot; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Note: If you normalize your features, your cost function will on average look more symmetric. So when you are running gradient descent on the cost function like the one on the left, might need to use a very small learning rate because GD might need a lot of steps to oscillate back and forth before it finds its way to the minimum.&lt;/strong&gt;&lt;/p&gt;
&lt;h4 id=&quot;vanishing-exploding-gradients&quot;&gt;Vanishing / Exploding gradients&lt;/h4&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://raw.githubusercontent.com/karenyyy/Coursera_and_Udemy/master/deeplearningai_coursera/Improving%20Deep%20Neural%20Networks%3A%20Hyperparameter%20tuning%2C%20Regularization%20and%20Optimization%20Home/images/17.png&quot; /&gt;&lt;/p&gt;
&lt;p&gt;$$\hat y = 1.5^L \rightarrow gradident \: explode$$&lt;/p&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://raw.githubusercontent.com/karenyyy/Coursera_and_Udemy/master/deeplearningai_coursera/Improving%20Deep%20Neural%20Networks%3A%20Hyperparameter%20tuning%2C%20Regularization%20and%20Optimization%20Home/images/18.png&quot; /&gt;&lt;/p&gt;
&lt;p&gt;$$\hat y = 0.5^L \rightarrow gradident \: vanish$$&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Fix: Careful with the weight initialization for deep networks&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://raw.githubusercontent.com/karenyyy/Coursera_and_Udemy/master/deeplearningai_coursera/Improving%20Deep%20Neural%20Networks%3A%20Hyperparameter%20tuning%2C%20Regularization%20and%20Optimization%20Home/images/19.png&quot; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Xavier initialization: if you are using tanh as activation function&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://raw.githubusercontent.com/karenyyy/Coursera_and_Udemy/master/deeplearningai_coursera/Improving%20Deep%20Neural%20Networks%3A%20Hyperparameter%20tuning%2C%20Regularization%20and%20Optimization%20Home/images/20.png&quot; /&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;another approach
&lt;img alt=&quot;&quot; src=&quot;https://raw.githubusercontent.com/karenyyy/Coursera_and_Udemy/master/deeplearningai_coursera/Improving%20Deep%20Neural%20Networks%3A%20Hyperparameter%20tuning%2C%20Regularization%20and%20Optimization%20Home/images/21.png&quot; /&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;Gradient checking (&lt;strong&gt;use centered gradient(two-sided)&lt;/strong&gt;): to make sure your backprop is correct&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://raw.githubusercontent.com/karenyyy/Coursera_and_Udemy/master/deeplearningai_coursera/Improving%20Deep%20Neural%20Networks%3A%20Hyperparameter%20tuning%2C%20Regularization%20and%20Optimization%20Home/images/22.png&quot; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://raw.githubusercontent.com/karenyyy/Coursera_and_Udemy/master/deeplearningai_coursera/Improving%20Deep%20Neural%20Networks%3A%20Hyperparameter%20tuning%2C%20Regularization%20and%20Optimization%20Home/images/23.png&quot; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://raw.githubusercontent.com/karenyyy/Coursera_and_Udemy/master/deeplearningai_coursera/Improving%20Deep%20Neural%20Networks%3A%20Hyperparameter%20tuning%2C%20Regularization%20and%20Optimization%20Home/images/24.png&quot; /&gt;&lt;/p&gt;deeplearning.ai - Improving Deep Neural Networks - Week 2 Notes
&lt;h2 id=&quot;mini-batch-gradient-descent&quot;&gt;Mini-batch gradient descent&lt;/h2&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://raw.githubusercontent.com/karenyyy/Coursera_and_Udemy/master/deeplearningai_coursera/Improving%20Deep%20Neural%20Networks%3A%20Hyperparameter%20tuning%2C%20Regularization%20and%20Optimization%20Home/images/26.png&quot; /&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;cluster a batch as one variable for training&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://raw.githubusercontent.com/karenyyy/Coursera_and_Udemy/master/deeplearningai_coursera/Improving%20Deep%20Neural%20Networks%3A%20Hyperparameter%20tuning%2C%20Regularization%20and%20Optimization%20Home/images/27.png&quot; /&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Cost oscillates when using mini-batch gradient descent&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://raw.githubusercontent.com/karenyyy/Coursera_and_Udemy/master/deeplearningai_coursera/Improving%20Deep%20Neural%20Networks%3A%20Hyperparameter%20tuning%2C%20Regularization%20and%20Optimization%20Home/images/28.png&quot; /&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Choosing your mini-batch size&lt;ul&gt;
&lt;li&gt;If mini-batch size = m: Batch GD&lt;/li&gt;
&lt;li&gt;If mini-batch size = 1: Stochastic GD&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Every example is its own mini-batch.&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://raw.githubusercontent.com/karenyyy/Coursera_and_Udemy/master/deeplearningai_coursera/Improving%20Deep%20Neural%20Networks%3A%20Hyperparameter%20tuning%2C%20Regularization%20and%20Optimization%20Home/images/29.png&quot; /&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The batch GD might start somewhere and be able to take relatively low noise, large steps, and keep marching to the minimum.&lt;/li&gt;
&lt;li&gt;The stochastic GD can be extremely noisy, won&#39;t always converge, always oscillate and wander around the region of the minimum.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;In practice, mini-batch size should be in between [1, n]&lt;/strong&gt;&lt;/p&gt;
&lt;h3 id=&quot;gradient-descent-with-momentum&quot;&gt;Gradient descent with momentum&lt;/h3&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://raw.githubusercontent.com/karenyyy/Coursera_and_Udemy/master/deeplearningai_coursera/Improving%20Deep%20Neural%20Networks%3A%20Hyperparameter%20tuning%2C%20Regularization%20and%20Optimization%20Home/images/30.png&quot; /&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;smooth out the steps of gradient descent&lt;/li&gt;
&lt;li&gt;gradient descent with momentum ends up eventually just taking steps that are much smaller oscillations in the vertical direction&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://raw.githubusercontent.com/karenyyy/Coursera_and_Udemy/master/deeplearningai_coursera/Improving%20Deep%20Neural%20Networks%3A%20Hyperparameter%20tuning%2C%20Regularization%20and%20Optimization%20Home/images/31.png&quot; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://raw.githubusercontent.com/karenyyy/Coursera_and_Udemy/master/deeplearningai_coursera/Improving%20Deep%20Neural%20Networks%3A%20Hyperparameter%20tuning%2C%20Regularization%20and%20Optimization%20Home/images/32.png&quot; /&gt;&lt;/p&gt;
&lt;h3 id=&quot;root-mean-square-prop-rmsprop&quot;&gt;Root Mean Square Prop (RMSprop)&lt;/h3&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://raw.githubusercontent.com/karenyyy/Coursera_and_Udemy/master/deeplearningai_coursera/Improving%20Deep%20Neural%20Networks%3A%20Hyperparameter%20tuning%2C%20Regularization%20and%20Optimization%20Home/images/33.png&quot; /&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;How exactly does it work?&lt;/p&gt;
&lt;/blockquote&gt;
&lt;ul&gt;
&lt;li&gt;In the W direction, we want the learning to go faster&lt;ul&gt;
&lt;li&gt;we want Sdw to be relatively &lt;strong&gt;small&lt;/strong&gt; so when updating w, we are dividing by relatively small number, so w gets updated faster&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;In the b direction, we want to slow down all the oscillations into the vertical direction&lt;ul&gt;
&lt;li&gt;Sdb will be relatively &lt;strong&gt;large&lt;/strong&gt;, so that we are dividing by relatively large number in order to slow down the updates on a vertical direction&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;And indeed if we look at the derivatives, the derivatives are much larger in the vertical direction than the horizontal direction. So the slope is very large in the b direction.&lt;/p&gt;
&lt;p&gt;So with derivatives like this, this is a very large db and a relatively small dw, because the function is sloped much more steeply in the vertical direction.&lt;/p&gt;
&lt;p&gt;Thus the net impact of using RMSprop is that &lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;updates in the vertical direction are divided by a much larger number, and so that helps damp out the oscillations.&lt;/li&gt;
&lt;li&gt;updates in the horizontal direction are divided by a smaller number, making learning rate larger, moving towards the destination in a faster rate. &lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://raw.githubusercontent.com/karenyyy/Coursera_and_Udemy/master/deeplearningai_coursera/Improving%20Deep%20Neural%20Networks%3A%20Hyperparameter%20tuning%2C%20Regularization%20and%20Optimization%20Home/images/34.png&quot; /&gt;&lt;/p&gt;
&lt;h3 id=&quot;adam-optimization&quot;&gt;Adam Optimization&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;Combine Momentum and RMSprop together&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://raw.githubusercontent.com/karenyyy/Coursera_and_Udemy/master/deeplearningai_coursera/Improving%20Deep%20Neural%20Networks%3A%20Hyperparameter%20tuning%2C%20Regularization%20and%20Optimization%20Home/images/35.png&quot; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://raw.githubusercontent.com/karenyyy/Coursera_and_Udemy/master/deeplearningai_coursera/Improving%20Deep%20Neural%20Networks%3A%20Hyperparameter%20tuning%2C%20Regularization%20and%20Optimization%20Home/images/36.png&quot; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://raw.githubusercontent.com/karenyyy/Coursera_and_Udemy/master/deeplearningai_coursera/Improving%20Deep%20Neural%20Networks%3A%20Hyperparameter%20tuning%2C%20Regularization%20and%20Optimization%20Home/images/37.png&quot; /&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;To avoid the case that the steps being noisy and never converge, ends up wandering around the destination, &lt;strong&gt;because we are using some fixed value for learning rate alpha!&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;But if we can slowly reduce learning rate alpha, then during the initial phases, while learning rate alpha is still large, we will have relatively fast learning.&lt;/p&gt;
&lt;p&gt;But then as alpha gets smaller, the steps we take will be slower and smaller. &lt;/p&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://raw.githubusercontent.com/karenyyy/Coursera_and_Udemy/master/deeplearningai_coursera/Improving%20Deep%20Neural%20Networks%3A%20Hyperparameter%20tuning%2C%20Regularization%20and%20Optimization%20Home/images/38.png&quot; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://raw.githubusercontent.com/karenyyy/Coursera_and_Udemy/master/deeplearningai_coursera/Improving%20Deep%20Neural%20Networks%3A%20Hyperparameter%20tuning%2C%20Regularization%20and%20Optimization%20Home/images/39.png&quot; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Note:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;There will be some oscillations when you&#39;re using mini-batch gradient descent since there could be some noisy data example in batches. &lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;However batch gradient descent always guarantees a lower &lt;strong&gt;&lt;em&gt;J&lt;/em&gt;&lt;/strong&gt; before reaching the optimal.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;deeplearning.ai - Improving Deep Neural Networks - Week 2 Assignment
&lt;h1 id=&quot;optimization-methods&quot;&gt;Optimization Methods&lt;/h1&gt;
&lt;p&gt;Until now, you&#39;ve always used Gradient Descent to update the parameters and minimize the cost. In this notebook, you will learn more advanced optimization methods that can speed up learning and perhaps even get you to a better final value for the cost function. Having a good optimization algorithm can be the difference between waiting days vs. just a few hours to get a good result. &lt;/p&gt;
&lt;p&gt;Gradient descent goes &quot;downhill&quot; on a cost function $J$. Think of it as trying to do this: &lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Notations&lt;/strong&gt;: As usual, $\frac{\partial J}{\partial a } = $ &lt;code&gt;da&lt;/code&gt; for any variable &lt;code&gt;a&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;To get started, run the following code to import the libraries you will need.&lt;/p&gt;
&lt;div class=&quot;codehilite&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;numpy&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;np&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;matplotlib.pyplot&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;plt&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;scipy.io&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;math&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;sklearn&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;sklearn.datasets&lt;/span&gt;

&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;opt_utils&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;load_params_and_grads&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;initialize_parameters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;forward_propagation&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;backward_propagation&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;opt_utils&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;compute_cost&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;predict&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;predict_dec&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;plot_decision_boundary&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;load_dataset&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;testCases&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;

&lt;span class=&quot;o&quot;&gt;%&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;matplotlib&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;inline&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;rcParams&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;figure.figsize&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;7.0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;4.0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;# set default size of plots&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;rcParams&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;image.interpolation&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&amp;#39;nearest&amp;#39;&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;rcParams&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;image.cmap&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&amp;#39;gray&amp;#39;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;h2 id=&quot;1-gradient-descent&quot;&gt;1 - Gradient Descent&lt;/h2&gt;
&lt;p&gt;A simple optimization method in machine learning is gradient descent (GD). When you take gradient steps with respect to all $m$ examples on each step, it is also called Batch Gradient Descent. &lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Warm-up exercise&lt;/strong&gt;: Implement the gradient descent update rule. The  gradient descent rule is, for $l = 1, ..., L$: 
$$ W^{[l]} = W^{[l]} - \alpha \text{ } dW^{[l]} \tag{1}$$
$$ b^{[l]} = b^{[l]} - \alpha \text{ } db^{[l]} \tag{2}$$&lt;/p&gt;
&lt;p&gt;where L is the number of layers and $\alpha$ is the learning rate. All parameters should be stored in the &lt;code&gt;parameters&lt;/code&gt; dictionary. Note that the iterator &lt;code&gt;l&lt;/code&gt; starts at 0 in the &lt;code&gt;for&lt;/code&gt; loop while the first parameters are $W^{[1]}$ and $b^{[1]}$. You need to shift &lt;code&gt;l&lt;/code&gt; to &lt;code&gt;l+1&lt;/code&gt; when coding.&lt;/p&gt;
&lt;div class=&quot;codehilite&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;c1&quot;&gt;# GRADED FUNCTION: update_parameters_with_gd&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;update_parameters_with_gd&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;parameters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;grads&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;learning_rate&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;sd&quot;&gt;&amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    Update parameters using one step of gradient descent&lt;/span&gt;

&lt;span class=&quot;sd&quot;&gt;    Arguments:&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    parameters -- python dictionary containing your parameters to be updated:&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;                    parameters[&amp;#39;W&amp;#39; + str(l)] = Wl&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;                    parameters[&amp;#39;b&amp;#39; + str(l)] = bl&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    grads -- python dictionary containing your gradients to update each parameters:&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;                    grads[&amp;#39;dW&amp;#39; + str(l)] = dWl&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;                    grads[&amp;#39;db&amp;#39; + str(l)] = dbl&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    learning_rate -- the learning rate, scalar.&lt;/span&gt;

&lt;span class=&quot;sd&quot;&gt;    Returns:&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    parameters -- python dictionary containing your updated parameters &lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    &amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;

    &lt;span class=&quot;n&quot;&gt;L&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;parameters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;//&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;# number of layers in the neural networks&lt;/span&gt;

    &lt;span class=&quot;c1&quot;&gt;# Update rule for each parameter&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;l&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;L&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;

        &lt;span class=&quot;n&quot;&gt;parameters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;W&amp;quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;l&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;parameters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;W&amp;#39;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;l&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;learning_rate&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;grads&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;dW&amp;#39;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;l&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)]&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;parameters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;b&amp;quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;l&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;parameters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;b&amp;#39;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;l&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;learning_rate&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;grads&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;db&amp;#39;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;l&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)]&lt;/span&gt;


    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;parameters&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div class=&quot;codehilite&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;parameters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;grads&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;learning_rate&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;update_parameters_with_gd_test_case&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;parameters&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;update_parameters_with_gd&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;parameters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;grads&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;learning_rate&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;W1 = &amp;quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;parameters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;W1&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]))&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;b1 = &amp;quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;parameters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;b1&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]))&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;W2 = &amp;quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;parameters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;W2&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]))&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;b2 = &amp;quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;parameters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;b2&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]))&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div class=&quot;codehilite&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;W1 = [[ 1.63535156 -0.62320365 -0.53718766]
 [-1.07799357  0.85639907 -2.29470142]]
b1 = [[ 1.74604067]
 [-0.75184921]]
W2 = [[ 0.32171798 -0.25467393  1.46902454]
 [-2.05617317 -0.31554548 -0.3756023 ]
 [ 1.1404819  -1.09976462 -0.1612551 ]]
b2 = [[-0.88020257]
 [ 0.02561572]
 [ 0.57539477]]
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;strong&gt;Expected Output&lt;/strong&gt;:&lt;/p&gt;
&lt;table&gt; 
    &lt;tr&gt;
    &lt;td &gt; **W1** &lt;/td&gt; 
           &lt;td &gt; [[ 1.63535156 -0.62320365 -0.53718766]
 [-1.07799357  0.85639907 -2.29470142]] &lt;/td&gt; 
    &lt;/tr&gt;

    &lt;tr&gt;
    &lt;td &gt; **b1** &lt;/td&gt; 
           &lt;td &gt; [[ 1.74604067]
 [-0.75184921]] &lt;/td&gt; 
    &lt;/tr&gt; 

    &lt;tr&gt;
    &lt;td &gt; **W2** &lt;/td&gt; 
           &lt;td &gt; [[ 0.32171798 -0.25467393  1.46902454]
 [-2.05617317 -0.31554548 -0.3756023 ]
 [ 1.1404819  -1.09976462 -0.1612551 ]] &lt;/td&gt; 
    &lt;/tr&gt; 

    &lt;tr&gt;
    &lt;td &gt; **b2** &lt;/td&gt; 
           &lt;td &gt; [[-0.88020257]
 [ 0.02561572]
 [ 0.57539477]] &lt;/td&gt; 
    &lt;/tr&gt; 
&lt;/table&gt;

&lt;p&gt;A variant of this is Stochastic Gradient Descent (SGD), which is equivalent to mini-batch gradient descent where each mini-batch has just 1 example. The update rule that you have just implemented does not change. What changes is that you would be computing gradients on just one training example at a time, rather than on the whole training set. The code examples below illustrate the difference between stochastic gradient descent and (batch) gradient descent. &lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;(Batch) Gradient Descent&lt;/strong&gt;:&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&quot;codehilite&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;data_input&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;Y&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;labels&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;parameters&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;initialize_parameters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;layers_dims&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;num_iterations&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;c1&quot;&gt;# Forward propagation&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;caches&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;forward_propagation&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;parameters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;c1&quot;&gt;# Compute cost.&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;cost&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;compute_cost&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;c1&quot;&gt;# Backward propagation.&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;grads&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;backward_propagation&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;caches&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;parameters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;c1&quot;&gt;# Update parameters.&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;parameters&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;update_parameters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;parameters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;grads&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Stochastic Gradient Descent&lt;/strong&gt;:&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&quot;codehilite&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;data_input&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;Y&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;labels&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;parameters&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;initialize_parameters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;layers_dims&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;num_iterations&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;j&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;m&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;c1&quot;&gt;# Forward propagation&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;caches&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;forward_propagation&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[:,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;j&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;parameters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;c1&quot;&gt;# Compute cost&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;cost&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;compute_cost&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[:,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;j&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
        &lt;span class=&quot;c1&quot;&gt;# Backward propagation&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;grads&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;backward_propagation&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;caches&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;parameters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;c1&quot;&gt;# Update parameters.&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;parameters&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;update_parameters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;parameters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;grads&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;In Stochastic Gradient Descent, you use only 1 training example before updating the gradients. When the training set is large, SGD can be faster. But the parameters will &quot;oscillate&quot; toward the minimum rather than converge smoothly. Here is an illustration of this: &lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/karenyyy/Coursera_and_Udemy/master/deeplearningai_coursera/Improving%20Deep%20Neural%20Networks%3A%20Hyperparameter%20tuning%2C%20Regularization%20and%20Optimization%20Home/images/kiank_sgd.png&quot; style=&quot;width:750px;height:250px;&quot;&gt;
&lt;caption&gt;&lt;center&gt; &lt;u&gt; &lt;strong&gt;Figure 1&lt;/strong&gt; &lt;/u&gt;  : &lt;strong&gt;SGD vs GD&lt;/strong&gt;&lt;br&gt; &quot;+&quot; denotes a minimum of the cost. SGD leads to many oscillations to reach convergence. But each step is a lot faster to compute for SGD than for GD, as it uses only one training example (vs. the whole batch for GD). &lt;/center&gt;&lt;/caption&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt; also that implementing SGD requires 3 for-loops in total:
1. Over the number of iterations
2. Over the $m$ training examples
3. Over the layers (to update all parameters, from $(W^{[1]},b^{[1]})$ to $(W^{[L]},b^{[L]})$)&lt;/p&gt;
&lt;p&gt;In practice, you&#39;ll often get faster results if you do not use neither the whole training set, nor only one training example, to perform each update. Mini-batch gradient descent uses an intermediate number of examples for each step. With mini-batch gradient descent, you loop over the mini-batches instead of looping over individual training examples.&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/karenyyy/Coursera_and_Udemy/master/deeplearningai_coursera/Improving%20Deep%20Neural%20Networks%3A%20Hyperparameter%20tuning%2C%20Regularization%20and%20Optimization%20Home/images/kiank_minibatch.png&quot; style=&quot;width:750px;height:250px;&quot;&gt;
&lt;caption&gt;&lt;center&gt; &lt;u&gt;  &lt;strong&gt;Figure 2&lt;/strong&gt; &lt;/u&gt;:  &lt;strong&gt;SGD vs Mini-Batch GD&lt;/strong&gt;&lt;br&gt; &quot;+&quot; denotes a minimum of the cost. Using mini-batches in your optimization algorithm often leads to faster optimization. &lt;/center&gt;&lt;/caption&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;What you should remember&lt;/strong&gt;:
- The difference between gradient descent, mini-batch gradient descent and stochastic gradient descent is the number of examples you use to perform one update step.
- You have to tune a learning rate hyperparameter $\alpha$.
- With a well-turned mini-batch size, usually it outperforms either gradient descent or stochastic gradient descent (particularly when the training set is large).&lt;/p&gt;
&lt;h2 id=&quot;2-mini-batch-gradient-descent&quot;&gt;2 - Mini-Batch Gradient descent&lt;/h2&gt;
&lt;p&gt;Let&#39;s learn how to build mini-batches from the training set (X, Y).&lt;/p&gt;
&lt;p&gt;There are two steps:
- &lt;strong&gt;Shuffle&lt;/strong&gt;: Create a shuffled version of the training set (X, Y) as shown below. Each column of X and Y represents a training example. Note that the random shuffling is done synchronously between X and Y. Such that after the shuffling the $i^{th}$ column of X is the example corresponding to the $i^{th}$ label in Y. The shuffling step ensures that examples will be split randomly into different mini-batches. &lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/karenyyy/Coursera_and_Udemy/master/deeplearningai_coursera/Improving%20Deep%20Neural%20Networks%3A%20Hyperparameter%20tuning%2C%20Regularization%20and%20Optimization%20Home/images/kiank_shuffle.png&quot; style=&quot;width:550px;height:300px;&quot;&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Partition&lt;/strong&gt;: Partition the shuffled (X, Y) into mini-batches of size &lt;code&gt;mini_batch_size&lt;/code&gt; (here 64). Note that the number of training examples is not always divisible by &lt;code&gt;mini_batch_size&lt;/code&gt;. The last mini batch might be smaller, but you don&#39;t need to worry about this. When the final mini-batch is smaller than the full &lt;code&gt;mini_batch_size&lt;/code&gt;, it will look like this: &lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/karenyyy/Coursera_and_Udemy/master/deeplearningai_coursera/Improving%20Deep%20Neural%20Networks%3A%20Hyperparameter%20tuning%2C%20Regularization%20and%20Optimization%20Home/images/kiank_partition.png&quot; style=&quot;width:550px;height:300px;&quot;&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Exercise&lt;/strong&gt;: Implement &lt;code&gt;random_mini_batches&lt;/code&gt;. We coded the shuffling part for you. To help you with the partitioning step, we give you the following code that selects the indexes for the $1^{st}$ and $2^{nd}$ mini-batches:&lt;/p&gt;
&lt;div class=&quot;codehilite&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;first_mini_batch_X&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;shuffled_X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[:,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mini_batch_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;second_mini_batch_X&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;shuffled_X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[:,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mini_batch_size&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mini_batch_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;...&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Note that the last mini-batch might end up smaller than &lt;code&gt;mini_batch_size=64&lt;/code&gt;. Let $\lfloor s \rfloor$ represents $s$ rounded down to the nearest integer (this is &lt;code&gt;math.floor(s)&lt;/code&gt; in Python). If the total number of examples is not a multiple of &lt;code&gt;mini_batch_size=64&lt;/code&gt; then there will be $\lfloor \frac{m}{mini_batch_size}\rfloor$ mini-batches with a full 64 examples, and the number of examples in the final mini-batch will be ($m-mini__batch__size \times \lfloor \frac{m}{mini_batch_size}\rfloor$). &lt;/p&gt;
&lt;div class=&quot;codehilite&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;c1&quot;&gt;# GRADED FUNCTION: random_mini_batches&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;random_mini_batches&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mini_batch_size&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;64&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;seed&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;sd&quot;&gt;&amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    Creates a list of random minibatches from (X, Y)&lt;/span&gt;

&lt;span class=&quot;sd&quot;&gt;    Arguments:&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    X -- input data, of shape (input size, number of examples)&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    Y -- true &amp;quot;label&amp;quot; vector (1 for blue dot / 0 for red dot), of shape (1, number of examples)&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    mini_batch_size -- size of the mini-batches, integer&lt;/span&gt;

&lt;span class=&quot;sd&quot;&gt;    Returns:&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    mini_batches -- list of synchronous (mini_batch_X, mini_batch_Y)&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    &amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;

    &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;random&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;seed&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;seed&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;            &lt;span class=&quot;c1&quot;&gt;# To make your &amp;quot;random&amp;quot; minibatches the same as ours&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;m&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;                  &lt;span class=&quot;c1&quot;&gt;# number of training examples&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;mini_batches&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[]&lt;/span&gt;

    &lt;span class=&quot;c1&quot;&gt;# Step 1: Shuffle (X, Y)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;permutation&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;list&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;random&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;permutation&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;m&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;shuffled_X&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[:,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;permutation&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;shuffled_Y&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[:,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;permutation&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;reshape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;((&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;m&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;

    &lt;span class=&quot;c1&quot;&gt;# Step 2: Partition (shuffled_X, shuffled_Y). Minus the end case.&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;num_complete_minibatches&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;math&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;floor&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;m&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mini_batch_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;# number of mini batches of size mini_batch_size in your partitionning&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;k&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;num_complete_minibatches&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;

        &lt;span class=&quot;n&quot;&gt;mini_batch_X&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;shuffled_X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[:,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;k&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mini_batch_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;k&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mini_batch_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;mini_batch_Y&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;shuffled_Y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[:,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;k&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mini_batch_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;k&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mini_batch_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;

        &lt;span class=&quot;n&quot;&gt;mini_batch&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mini_batch_X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mini_batch_Y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;mini_batches&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;append&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mini_batch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

    &lt;span class=&quot;c1&quot;&gt;# Handling the end case (last mini-batch &amp;lt; mini_batch_size)&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;m&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;%&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mini_batch_size&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;!=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;

        &lt;span class=&quot;n&quot;&gt;mini_batch_X&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;shuffled_X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[:,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;num_complete_minibatches&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mini_batch_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:]&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;mini_batch_Y&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;shuffled_Y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[:,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;num_complete_minibatches&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mini_batch_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:]&lt;/span&gt;

        &lt;span class=&quot;n&quot;&gt;mini_batch&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mini_batch_X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mini_batch_Y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;mini_batches&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;append&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mini_batch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mini_batches&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div class=&quot;codehilite&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X_assess&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Y_assess&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mini_batch_size&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;random_mini_batches_test_case&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;mini_batches&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;random_mini_batches&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X_assess&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Y_assess&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mini_batch_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;shape of the 1st mini_batch_X: &amp;quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mini_batches&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;][&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;shape of the 2nd mini_batch_X: &amp;quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mini_batches&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;][&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;shape of the 3rd mini_batch_X: &amp;quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mini_batches&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;][&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;shape of the 1st mini_batch_Y: &amp;quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mini_batches&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;][&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;shape of the 2nd mini_batch_Y: &amp;quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mini_batches&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;][&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt; 
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;shape of the 3rd mini_batch_Y: &amp;quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mini_batches&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;][&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;mini batch sanity check: &amp;quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mini_batches&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;][&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;][&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;][&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]))&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div class=&quot;codehilite&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;shape of the 1st mini_batch_X: (12288, 64)
shape of the 2nd mini_batch_X: (12288, 64)
shape of the 3rd mini_batch_X: (12288, 20)
shape of the 1st mini_batch_Y: (1, 64)
shape of the 2nd mini_batch_Y: (1, 64)
shape of the 3rd mini_batch_Y: (1, 20)
mini batch sanity check: [ 0.90085595 -0.7612069   0.2344157 ]
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;strong&gt;Expected Output&lt;/strong&gt;:&lt;/p&gt;
&lt;table style=&quot;width:50%&quot;&gt; 
    &lt;tr&gt;
    &lt;td &gt; **shape of the 1st mini_batch_X** &lt;/td&gt; 
           &lt;td &gt; (12288, 64) &lt;/td&gt; 
    &lt;/tr&gt;

    &lt;tr&gt;
    &lt;td &gt; **shape of the 2nd mini_batch_X** &lt;/td&gt; 
           &lt;td &gt; (12288, 64) &lt;/td&gt; 
    &lt;/tr&gt; 

    &lt;tr&gt;
    &lt;td &gt; **shape of the 3rd mini_batch_X** &lt;/td&gt; 
           &lt;td &gt; (12288, 20) &lt;/td&gt; 
    &lt;/tr&gt;
    &lt;tr&gt;
    &lt;td &gt; **shape of the 1st mini_batch_Y** &lt;/td&gt; 
           &lt;td &gt; (1, 64) &lt;/td&gt; 
    &lt;/tr&gt; 
    &lt;tr&gt;
    &lt;td &gt; **shape of the 2nd mini_batch_Y** &lt;/td&gt; 
           &lt;td &gt; (1, 64) &lt;/td&gt; 
    &lt;/tr&gt; 
    &lt;tr&gt;
    &lt;td &gt; **shape of the 3rd mini_batch_Y** &lt;/td&gt; 
           &lt;td &gt; (1, 20) &lt;/td&gt; 
    &lt;/tr&gt; 
    &lt;tr&gt;
    &lt;td &gt; **mini batch sanity check** &lt;/td&gt; 
           &lt;td &gt; [ 0.90085595 -0.7612069   0.2344157 ] &lt;/td&gt; 
    &lt;/tr&gt;

&lt;/table&gt;

&lt;p&gt;&lt;strong&gt;What you should remember&lt;/strong&gt;:
- Shuffling and Partitioning are the two steps required to build mini-batches
- Powers of two are often chosen to be the mini-batch size, e.g., 16, 32, 64, 128.&lt;/p&gt;
&lt;h2 id=&quot;3-momentum&quot;&gt;3 - Momentum&lt;/h2&gt;
&lt;p&gt;Because mini-batch gradient descent makes a parameter update after seeing just a subset of examples, the direction of the update has some variance, and so the path taken by mini-batch gradient descent will &quot;oscillate&quot; toward convergence. Using momentum can reduce these oscillations. &lt;/p&gt;
&lt;p&gt;Momentum takes into account the past gradients to smooth out the update. We will store the &#39;direction&#39; of the previous gradients in the variable $v$. Formally, this will be the exponentially weighted average of the gradient on previous steps. You can also think of $v$ as the &quot;velocity&quot; of a ball rolling downhill, building up speed (and momentum) according to the direction of the gradient/slope of the hill. &lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/karenyyy/Coursera_and_Udemy/master/deeplearningai_coursera/Improving%20Deep%20Neural%20Networks%3A%20Hyperparameter%20tuning%2C%20Regularization%20and%20Optimization%20Home/images/opt_momentum.png&quot; style=&quot;width:400px;height:250px;&quot;&gt;
&lt;caption&gt;&lt;center&gt; &lt;u&gt;&lt;strong&gt;Figure 3&lt;/strong&gt;&lt;/u&gt;: The red arrows shows the direction taken by one step of mini-batch gradient descent with momentum. The blue points show the direction of the gradient (with respect to the current mini-batch) on each step. Rather than just following the gradient, we let the gradient influence $v$ and then take a step in the direction of $v$.&lt;br&gt; &lt;font color=&#39;black&#39;&gt; &lt;/center&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Exercise&lt;/strong&gt;: Initialize the velocity. The velocity, $v$, is a python dictionary that needs to be initialized with arrays of zeros. Its keys are the same as those in the &lt;code&gt;grads&lt;/code&gt; dictionary, that is:
for $l =1,...,L$:&lt;/p&gt;
&lt;div class=&quot;codehilite&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;v&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;dW&amp;quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;l&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;...&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;#(numpy array of zeros with the same shape as parameters[&amp;quot;W&amp;quot; + str(l+1)])&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;v&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;db&amp;quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;l&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;...&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;#(numpy array of zeros with the same shape as parameters[&amp;quot;b&amp;quot; + str(l+1)])&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt; that the iterator l starts at 0 in the for loop while the first parameters are v[&quot;dW1&quot;] and v[&quot;db1&quot;] (that&#39;s a &quot;one&quot; on the superscript). This is why we are shifting l to l+1 in the &lt;code&gt;for&lt;/code&gt; loop.&lt;/p&gt;
&lt;div class=&quot;codehilite&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;c1&quot;&gt;# GRADED FUNCTION: initialize_velocity&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;initialize_velocity&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;parameters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;sd&quot;&gt;&amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    Initializes the velocity as a python dictionary with:&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;                - keys: &amp;quot;dW1&amp;quot;, &amp;quot;db1&amp;quot;, ..., &amp;quot;dWL&amp;quot;, &amp;quot;dbL&amp;quot; &lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;                - values: numpy arrays of zeros of the same shape as the corresponding gradients/parameters.&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    Arguments:&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    parameters -- python dictionary containing your parameters.&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;                    parameters[&amp;#39;W&amp;#39; + str(l)] = Wl&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;                    parameters[&amp;#39;b&amp;#39; + str(l)] = bl&lt;/span&gt;

&lt;span class=&quot;sd&quot;&gt;    Returns:&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    v -- python dictionary containing the current velocity.&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;                    v[&amp;#39;dW&amp;#39; + str(l)] = velocity of dWl&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;                    v[&amp;#39;db&amp;#39; + str(l)] = velocity of dbl&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    &amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;

    &lt;span class=&quot;n&quot;&gt;L&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;parameters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;//&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;# number of layers in the neural networks&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;v&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{}&lt;/span&gt;

    &lt;span class=&quot;c1&quot;&gt;# Initialize velocity&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;l&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;L&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;

        &lt;span class=&quot;n&quot;&gt;v&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;dW&amp;quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;l&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;zeros&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;((&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;parameters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;W&amp;quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;l&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)]&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;v&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;db&amp;quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;l&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;zeros&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;((&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;parameters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;b&amp;quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;l&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)]&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;


    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;v&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div class=&quot;codehilite&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;parameters&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;initialize_velocity_test_case&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;v&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;initialize_velocity&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;parameters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;v[&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\&amp;quot;&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;dW1&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\&amp;quot;&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;] = &amp;quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;v&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;dW1&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]))&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;v[&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\&amp;quot;&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;db1&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\&amp;quot;&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;] = &amp;quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;v&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;db1&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]))&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;v[&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\&amp;quot;&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;dW2&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\&amp;quot;&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;] = &amp;quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;v&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;dW2&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]))&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;v[&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\&amp;quot;&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;db2&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\&amp;quot;&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;] = &amp;quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;v&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;db2&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]))&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div class=&quot;codehilite&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;v[&amp;quot;dW1&amp;quot;] = [[ 0.  0.  0.]
 [ 0.  0.  0.]]
v[&amp;quot;db1&amp;quot;] = [[ 0.]
 [ 0.]]
v[&amp;quot;dW2&amp;quot;] = [[ 0.  0.  0.]
 [ 0.  0.  0.]
 [ 0.  0.  0.]]
v[&amp;quot;db2&amp;quot;] = [[ 0.]
 [ 0.]
 [ 0.]]
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;strong&gt;Expected Output&lt;/strong&gt;:&lt;/p&gt;
&lt;table style=&quot;width:40%&quot;&gt; 
    &lt;tr&gt;
    &lt;td &gt; **v[&quot;dW1&quot;]** &lt;/td&gt; 
           &lt;td &gt; [[ 0.  0.  0.]
 [ 0.  0.  0.]] &lt;/td&gt; 
    &lt;/tr&gt;

    &lt;tr&gt;
    &lt;td &gt; **v[&quot;db1&quot;]** &lt;/td&gt; 
           &lt;td &gt; [[ 0.]
 [ 0.]] &lt;/td&gt; 
    &lt;/tr&gt; 

    &lt;tr&gt;
    &lt;td &gt; **v[&quot;dW2&quot;]** &lt;/td&gt; 
           &lt;td &gt; [[ 0.  0.  0.]
 [ 0.  0.  0.]
 [ 0.  0.  0.]] &lt;/td&gt; 
    &lt;/tr&gt; 

    &lt;tr&gt;
    &lt;td &gt; **v[&quot;db2&quot;]** &lt;/td&gt; 
           &lt;td &gt; [[ 0.]
 [ 0.]
 [ 0.]] &lt;/td&gt; 
    &lt;/tr&gt; 
&lt;/table&gt;

&lt;p&gt;&lt;strong&gt;Exercise&lt;/strong&gt;:  Now, implement the parameters update with momentum. The momentum update rule is, for $l = 1, ..., L$: &lt;/p&gt;
&lt;p&gt;$$ \begin{cases}
v_{dW^{[l]}} = \beta v_{dW^{[l]}} + (1 - \beta) dW^{[l]} \
W^{[l]} = W^{[l]} - \alpha v_{dW^{[l]}}
\end{cases}\tag{3}$$&lt;/p&gt;
&lt;p&gt;$$\begin{cases}
v_{db^{[l]}} = \beta v_{db^{[l]}} + (1 - \beta) db^{[l]} \
b^{[l]} = b^{[l]} - \alpha v_{db^{[l]}} 
\end{cases}\tag{4}$$&lt;/p&gt;
&lt;p&gt;where L is the number of layers, $\beta$ is the momentum and $\alpha$ is the learning rate. All parameters should be stored in the &lt;code&gt;parameters&lt;/code&gt; dictionary.  Note that the iterator &lt;code&gt;l&lt;/code&gt; starts at 0 in the &lt;code&gt;for&lt;/code&gt; loop while the first parameters are $W^{[1]}$ and $b^{[1]}$ (that&#39;s a &quot;one&quot; on the superscript). So you will need to shift &lt;code&gt;l&lt;/code&gt; to &lt;code&gt;l+1&lt;/code&gt; when coding.&lt;/p&gt;
&lt;div class=&quot;codehilite&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;c1&quot;&gt;# GRADED FUNCTION: update_parameters_with_momentum&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;update_parameters_with_momentum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;parameters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;grads&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;v&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;beta&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;learning_rate&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;sd&quot;&gt;&amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    Update parameters using Momentum&lt;/span&gt;

&lt;span class=&quot;sd&quot;&gt;    Arguments:&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    parameters -- python dictionary containing your parameters:&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;                    parameters[&amp;#39;W&amp;#39; + str(l)] = Wl&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;                    parameters[&amp;#39;b&amp;#39; + str(l)] = bl&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    grads -- python dictionary containing your gradients for each parameters:&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;                    grads[&amp;#39;dW&amp;#39; + str(l)] = dWl&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;                    grads[&amp;#39;db&amp;#39; + str(l)] = dbl&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    v -- python dictionary containing the current velocity:&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;                    v[&amp;#39;dW&amp;#39; + str(l)] = ...&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;                    v[&amp;#39;db&amp;#39; + str(l)] = ...&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    beta -- the momentum hyperparameter, scalar&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    learning_rate -- the learning rate, scalar&lt;/span&gt;

&lt;span class=&quot;sd&quot;&gt;    Returns:&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    parameters -- python dictionary containing your updated parameters &lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    v -- python dictionary containing your updated velocities&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    &amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;

    &lt;span class=&quot;n&quot;&gt;L&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;parameters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;//&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;# number of layers in the neural networks&lt;/span&gt;

    &lt;span class=&quot;c1&quot;&gt;# Momentum update for each parameter&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;l&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;L&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;


        &lt;span class=&quot;c1&quot;&gt;# compute velocities&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;v&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;dW&amp;quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;l&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;beta&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;v&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;dW&amp;quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;l&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;beta&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;grads&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;dW&amp;#39;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;l&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)]&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;v&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;db&amp;quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;l&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;beta&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;v&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;db&amp;quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;l&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;beta&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;grads&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;db&amp;#39;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;l&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)]&lt;/span&gt;
        &lt;span class=&quot;c1&quot;&gt;# update parameters&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;parameters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;W&amp;quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;l&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;parameters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;W&amp;quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;l&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;learning_rate&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;v&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;dW&amp;quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;l&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)]&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;parameters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;b&amp;quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;l&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;parameters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;b&amp;quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;l&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;learning_rate&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;v&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;db&amp;quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;l&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)]&lt;/span&gt;


    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;parameters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;v&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div class=&quot;codehilite&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;parameters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;grads&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;v&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;update_parameters_with_momentum_test_case&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;parameters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;v&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;update_parameters_with_momentum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;parameters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;grads&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;v&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;beta&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.9&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;learning_rate&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.01&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;W1 = &amp;quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;parameters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;W1&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]))&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;b1 = &amp;quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;parameters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;b1&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]))&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;W2 = &amp;quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;parameters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;W2&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]))&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;b2 = &amp;quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;parameters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;b2&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]))&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;v[&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\&amp;quot;&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;dW1&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\&amp;quot;&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;] = &amp;quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;v&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;dW1&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]))&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;v[&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\&amp;quot;&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;db1&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\&amp;quot;&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;] = &amp;quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;v&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;db1&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]))&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;v[&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\&amp;quot;&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;dW2&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\&amp;quot;&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;] = &amp;quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;v&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;dW2&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]))&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;v[&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\&amp;quot;&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;db2&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\&amp;quot;&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;] = &amp;quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;v&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;db2&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]))&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div class=&quot;codehilite&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;W1 = [[ 1.62544598 -0.61290114 -0.52907334]
 [-1.07347112  0.86450677 -2.30085497]]
b1 = [[ 1.74493465]
 [-0.76027113]]
W2 = [[ 0.31930698 -0.24990073  1.4627996 ]
 [-2.05974396 -0.32173003 -0.38320915]
 [ 1.13444069 -1.0998786  -0.1713109 ]]
b2 = [[-0.87809283]
 [ 0.04055394]
 [ 0.58207317]]
v[&amp;quot;dW1&amp;quot;] = [[-0.11006192  0.11447237  0.09015907]
 [ 0.05024943  0.09008559 -0.06837279]]
v[&amp;quot;db1&amp;quot;] = [[-0.01228902]
 [-0.09357694]]
v[&amp;quot;dW2&amp;quot;] = [[-0.02678881  0.05303555 -0.06916608]
 [-0.03967535 -0.06871727 -0.08452056]
 [-0.06712461 -0.00126646 -0.11173103]]
v[&amp;quot;db2&amp;quot;] = [[ 0.02344157]
 [ 0.16598022]
 [ 0.07420442]]
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;strong&gt;Expected Output&lt;/strong&gt;:&lt;/p&gt;
&lt;table style=&quot;width:90%&quot;&gt; 
    &lt;tr&gt;
    &lt;td &gt; **W1** &lt;/td&gt; 
           &lt;td &gt; [[ 1.62544598 -0.61290114 -0.52907334]
 [-1.07347112  0.86450677 -2.30085497]] &lt;/td&gt; 
    &lt;/tr&gt;

    &lt;tr&gt;
    &lt;td &gt; **b1** &lt;/td&gt; 
           &lt;td &gt; [[ 1.74493465]
 [-0.76027113]] &lt;/td&gt; 
    &lt;/tr&gt; 

    &lt;tr&gt;
    &lt;td &gt; **W2** &lt;/td&gt; 
           &lt;td &gt; [[ 0.31930698 -0.24990073  1.4627996 ]
 [-2.05974396 -0.32173003 -0.38320915]
 [ 1.13444069 -1.0998786  -0.1713109 ]] &lt;/td&gt; 
    &lt;/tr&gt; 

    &lt;tr&gt;
    &lt;td &gt; **b2** &lt;/td&gt; 
           &lt;td &gt; [[-0.87809283]
 [ 0.04055394]
 [ 0.58207317]] &lt;/td&gt; 
    &lt;/tr&gt; 

    &lt;tr&gt;
    &lt;td &gt; **v[&quot;dW1&quot;]** &lt;/td&gt; 
           &lt;td &gt; [[-0.11006192  0.11447237  0.09015907]
 [ 0.05024943  0.09008559 -0.06837279]] &lt;/td&gt; 
    &lt;/tr&gt; 

    &lt;tr&gt;
    &lt;td &gt; **v[&quot;db1&quot;]** &lt;/td&gt; 
           &lt;td &gt; [[-0.01228902]
 [-0.09357694]] &lt;/td&gt; 
    &lt;/tr&gt; 

    &lt;tr&gt;
    &lt;td &gt; **v[&quot;dW2&quot;]** &lt;/td&gt; 
           &lt;td &gt; [[-0.02678881  0.05303555 -0.06916608]
 [-0.03967535 -0.06871727 -0.08452056]
 [-0.06712461 -0.00126646 -0.11173103]] &lt;/td&gt; 
    &lt;/tr&gt; 

    &lt;tr&gt;
    &lt;td &gt; **v[&quot;db2&quot;]** &lt;/td&gt; 
           &lt;td &gt; [[ 0.02344157]
 [ 0.16598022]
 [ 0.07420442]]&lt;/td&gt; 
    &lt;/tr&gt; 
&lt;/table&gt;

&lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt; that:
- The velocity is initialized with zeros. So the algorithm will take a few iterations to &quot;build up&quot; velocity and start to take bigger steps.
- If $\beta = 0$, then this just becomes standard gradient descent without momentum. &lt;/p&gt;
&lt;p&gt;&lt;strong&gt;How do you choose $\beta$?&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The larger the momentum $\beta$ is, the smoother the update because the more we take the past gradients into account. But if $\beta$ is too big, it could also smooth out the updates too much. &lt;/li&gt;
&lt;li&gt;Common values for $\beta$ range from 0.8 to 0.999. If you don&#39;t feel inclined to tune this, $\beta = 0.9$ is often a reasonable default. &lt;/li&gt;
&lt;li&gt;Tuning the optimal $\beta$ for your model might need trying several values to see what works best in term of reducing the value of the cost function $J$. &lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;What you should remember&lt;/strong&gt;:
- Momentum takes past gradients into account to smooth out the steps of gradient descent. It can be applied with batch gradient descent, mini-batch gradient descent or stochastic gradient descent.
- You have to tune a momentum hyperparameter $\beta$ and a learning rate $\alpha$.&lt;/p&gt;
&lt;h2 id=&quot;4-adam&quot;&gt;4 - Adam&lt;/h2&gt;
&lt;p&gt;Adam is one of the most effective optimization algorithms for training neural networks. It combines ideas from RMSProp (described in lecture) and Momentum. &lt;/p&gt;
&lt;p&gt;&lt;strong&gt;How does Adam work?&lt;/strong&gt;
1. It calculates an exponentially weighted average of past gradients, and stores it in variables $v$ (before bias correction) and $v^{corrected}$ (with bias correction). 
2. It calculates an exponentially weighted average of the squares of the past gradients, and  stores it in variables $s$ (before bias correction) and $s^{corrected}$ (with bias correction). 
3. It updates parameters in a direction based on combining information from &quot;1&quot; and &quot;2&quot;.&lt;/p&gt;
&lt;p&gt;The update rule is, for $l = 1, ..., L$: &lt;/p&gt;
&lt;p&gt;$$\begin{cases}
v_{dW^{[l]}} = \beta_1 v_{dW^{[l]}} + (1 - \beta_1) \frac{\partial \mathcal{J} }{ \partial W^{[l]} } \
v^{corrected}&lt;em dW_l_=&quot;dW^{[l]&quot;&gt;{dW^{[l]}} = \frac{v&lt;/em&gt;}}{1 - (\beta_1)^t} \
s_{dW^{[l]}} = \beta_2 s_{dW^{[l]}} + (1 - \beta_2) (\frac{\partial \mathcal{J} }{\partial W^{[l]} })^2 \
s^{corrected}&lt;em dW_l_=&quot;dW^{[l]&quot;&gt;{dW^{[l]}} = \frac{s&lt;/em&gt;}}{1 - (\beta_1)^t} \
W^{[l]} = W^{[l]} - \alpha \frac{v^{corrected}&lt;em dW_l_=&quot;dW^{[l]&quot;&gt;{dW^{[l]}}}{\sqrt{s^{corrected}&lt;/em&gt;}} + \varepsilon}
\end{cases}$$
where:
- t counts the number of steps taken of Adam 
- L is the number of layers
- $\beta_1$ and $\beta_2$ are hyperparameters that control the two exponentially weighted averages. 
- $\alpha$ is the learning rate
- $\varepsilon$ is a very small number to avoid dividing by zero&lt;/p&gt;
&lt;p&gt;As usual, we will store all parameters in the &lt;code&gt;parameters&lt;/code&gt; dictionary  &lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Exercise&lt;/strong&gt;: Initialize the Adam variables $v, s$ which keep track of the past information.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Instruction&lt;/strong&gt;: The variables $v, s$ are python dictionaries that need to be initialized with arrays of zeros. Their keys are the same as for &lt;code&gt;grads&lt;/code&gt;, that is:
for $l = 1, ..., L$:&lt;/p&gt;
&lt;div class=&quot;codehilite&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;v&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;dW&amp;quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;l&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;...&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;#(numpy array of zeros with the same shape as parameters[&amp;quot;W&amp;quot; + str(l+1)])&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;v&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;db&amp;quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;l&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;...&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;#(numpy array of zeros with the same shape as parameters[&amp;quot;b&amp;quot; + str(l+1)])&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;s&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;dW&amp;quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;l&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;...&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;#(numpy array of zeros with the same shape as parameters[&amp;quot;W&amp;quot; + str(l+1)])&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;s&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;db&amp;quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;l&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;...&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;#(numpy array of zeros with the same shape as parameters[&amp;quot;b&amp;quot; + str(l+1)])&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div class=&quot;codehilite&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;c1&quot;&gt;# GRADED FUNCTION: initialize_adam&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;initialize_adam&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;parameters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;sd&quot;&gt;&amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    Initializes v and s as two python dictionaries with:&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;                - keys: &amp;quot;dW1&amp;quot;, &amp;quot;db1&amp;quot;, ..., &amp;quot;dWL&amp;quot;, &amp;quot;dbL&amp;quot; &lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;                - values: numpy arrays of zeros of the same shape as the corresponding gradients/parameters.&lt;/span&gt;

&lt;span class=&quot;sd&quot;&gt;    Arguments:&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    parameters -- python dictionary containing your parameters.&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;                    parameters[&amp;quot;W&amp;quot; + str(l)] = Wl&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;                    parameters[&amp;quot;b&amp;quot; + str(l)] = bl&lt;/span&gt;

&lt;span class=&quot;sd&quot;&gt;    Returns: &lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    v -- python dictionary that will contain the exponentially weighted average of the gradient.&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;                    v[&amp;quot;dW&amp;quot; + str(l)] = ...&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;                    v[&amp;quot;db&amp;quot; + str(l)] = ...&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    s -- python dictionary that will contain the exponentially weighted average of the squared gradient.&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;                    s[&amp;quot;dW&amp;quot; + str(l)] = ...&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;                    s[&amp;quot;db&amp;quot; + str(l)] = ...&lt;/span&gt;

&lt;span class=&quot;sd&quot;&gt;    &amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;

    &lt;span class=&quot;n&quot;&gt;L&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;parameters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;//&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;# number of layers in the neural networks&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;v&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{}&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;s&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{}&lt;/span&gt;

    &lt;span class=&quot;c1&quot;&gt;# Initialize v, s. Input: &amp;quot;parameters&amp;quot;. Outputs: &amp;quot;v, s&amp;quot;.&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;l&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;L&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;

        &lt;span class=&quot;n&quot;&gt;v&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;dW&amp;quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;l&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;zeros&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;((&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;parameters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;W&amp;quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;l&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)]&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;v&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;db&amp;quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;l&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;zeros&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;((&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;parameters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;b&amp;quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;l&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)]&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;s&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;dW&amp;quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;l&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;zeros&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;((&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;parameters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;W&amp;quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;l&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)]&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;s&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;db&amp;quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;l&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;zeros&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;((&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;parameters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;b&amp;quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;l&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)]&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;


    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;v&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;s&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div class=&quot;codehilite&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;parameters&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;initialize_adam_test_case&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;v&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;s&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;initialize_adam&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;parameters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;v[&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\&amp;quot;&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;dW1&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\&amp;quot;&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;] = &amp;quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;v&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;dW1&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]))&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;v[&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\&amp;quot;&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;db1&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\&amp;quot;&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;] = &amp;quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;v&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;db1&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]))&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;v[&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\&amp;quot;&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;dW2&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\&amp;quot;&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;] = &amp;quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;v&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;dW2&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]))&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;v[&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\&amp;quot;&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;db2&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\&amp;quot;&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;] = &amp;quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;v&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;db2&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]))&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;s[&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\&amp;quot;&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;dW1&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\&amp;quot;&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;] = &amp;quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;s&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;dW1&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]))&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;s[&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\&amp;quot;&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;db1&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\&amp;quot;&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;] = &amp;quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;s&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;db1&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]))&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;s[&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\&amp;quot;&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;dW2&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\&amp;quot;&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;] = &amp;quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;s&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;dW2&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]))&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;s[&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\&amp;quot;&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;db2&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\&amp;quot;&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;] = &amp;quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;s&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;db2&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]))&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div class=&quot;codehilite&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;v[&amp;quot;dW1&amp;quot;] = [[ 0.  0.  0.]
 [ 0.  0.  0.]]
v[&amp;quot;db1&amp;quot;] = [[ 0.]
 [ 0.]]
v[&amp;quot;dW2&amp;quot;] = [[ 0.  0.  0.]
 [ 0.  0.  0.]
 [ 0.  0.  0.]]
v[&amp;quot;db2&amp;quot;] = [[ 0.]
 [ 0.]
 [ 0.]]
s[&amp;quot;dW1&amp;quot;] = [[ 0.  0.  0.]
 [ 0.  0.  0.]]
s[&amp;quot;db1&amp;quot;] = [[ 0.]
 [ 0.]]
s[&amp;quot;dW2&amp;quot;] = [[ 0.  0.  0.]
 [ 0.  0.  0.]
 [ 0.  0.  0.]]
s[&amp;quot;db2&amp;quot;] = [[ 0.]
 [ 0.]
 [ 0.]]
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;strong&gt;Expected Output&lt;/strong&gt;:&lt;/p&gt;
&lt;table style=&quot;width:40%&quot;&gt; 
    &lt;tr&gt;
    &lt;td &gt; **v[&quot;dW1&quot;]** &lt;/td&gt; 
           &lt;td &gt; [[ 0.  0.  0.]
 [ 0.  0.  0.]] &lt;/td&gt; 
    &lt;/tr&gt;

    &lt;tr&gt;
    &lt;td &gt; **v[&quot;db1&quot;]** &lt;/td&gt; 
           &lt;td &gt; [[ 0.]
 [ 0.]] &lt;/td&gt; 
    &lt;/tr&gt; 

    &lt;tr&gt;
    &lt;td &gt; **v[&quot;dW2&quot;]** &lt;/td&gt; 
           &lt;td &gt; [[ 0.  0.  0.]
 [ 0.  0.  0.]
 [ 0.  0.  0.]] &lt;/td&gt; 
    &lt;/tr&gt; 

    &lt;tr&gt;
    &lt;td &gt; **v[&quot;db2&quot;]** &lt;/td&gt; 
           &lt;td &gt; [[ 0.]
 [ 0.]
 [ 0.]] &lt;/td&gt; 
    &lt;/tr&gt; 
    &lt;tr&gt;
    &lt;td &gt; **s[&quot;dW1&quot;]** &lt;/td&gt; 
           &lt;td &gt; [[ 0.  0.  0.]
 [ 0.  0.  0.]] &lt;/td&gt; 
    &lt;/tr&gt; 

    &lt;tr&gt;
    &lt;td &gt; **s[&quot;db1&quot;]** &lt;/td&gt; 
           &lt;td &gt; [[ 0.]
 [ 0.]] &lt;/td&gt; 
    &lt;/tr&gt; 

    &lt;tr&gt;
    &lt;td &gt; **s[&quot;dW2&quot;]** &lt;/td&gt; 
           &lt;td &gt; [[ 0.  0.  0.]
 [ 0.  0.  0.]
 [ 0.  0.  0.]] &lt;/td&gt; 
    &lt;/tr&gt; 

    &lt;tr&gt;
    &lt;td &gt; **s[&quot;db2&quot;]** &lt;/td&gt; 
           &lt;td &gt; [[ 0.]
 [ 0.]
 [ 0.]] &lt;/td&gt; 
    &lt;/tr&gt;

&lt;/table&gt;

&lt;p&gt;&lt;strong&gt;Exercise&lt;/strong&gt;:  Now, implement the parameters update with Adam. Recall the general update rule is, for $l = 1, ..., L$: &lt;/p&gt;
&lt;p&gt;$$\begin{cases}
v_{W^{[l]}} = \beta_1 v_{W^{[l]}} + (1 - \beta_1) \frac{\partial J }{ \partial W^{[l]} } \
v^{corrected}&lt;em W_l_=&quot;W^{[l]&quot;&gt;{W^{[l]}} = \frac{v&lt;/em&gt;}}{1 - (\beta_1)^t} \
s_{W^{[l]}} = \beta_2 s_{W^{[l]}} + (1 - \beta_2) (\frac{\partial J }{\partial W^{[l]} })^2 \
s^{corrected}&lt;em W_l_=&quot;W^{[l]&quot;&gt;{W^{[l]}} = \frac{s&lt;/em&gt;}}{1 - (\beta_2)^t} \
W^{[l]} = W^{[l]} - \alpha \frac{v^{corrected}&lt;em W_l_=&quot;W^{[l]&quot;&gt;{W^{[l]}}}{\sqrt{s^{corrected}&lt;/em&gt;}}+\varepsilon}
\end{cases}$$&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt; that the iterator &lt;code&gt;l&lt;/code&gt; starts at 0 in the &lt;code&gt;for&lt;/code&gt; loop while the first parameters are $W^{[1]}$ and $b^{[1]}$. You need to shift &lt;code&gt;l&lt;/code&gt; to &lt;code&gt;l+1&lt;/code&gt; when coding.&lt;/p&gt;
&lt;div class=&quot;codehilite&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;c1&quot;&gt;# GRADED FUNCTION: update_parameters_with_adam&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;update_parameters_with_adam&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;parameters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;grads&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;v&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;s&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;learning_rate&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.01&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                                &lt;span class=&quot;n&quot;&gt;beta1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.9&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;beta2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.999&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;  &lt;span class=&quot;n&quot;&gt;epsilon&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;1e-8&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;sd&quot;&gt;&amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    Update parameters using Adam&lt;/span&gt;

&lt;span class=&quot;sd&quot;&gt;    Arguments:&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    parameters -- python dictionary containing your parameters:&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;                    parameters[&amp;#39;W&amp;#39; + str(l)] = Wl&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;                    parameters[&amp;#39;b&amp;#39; + str(l)] = bl&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    grads -- python dictionary containing your gradients for each parameters:&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;                    grads[&amp;#39;dW&amp;#39; + str(l)] = dWl&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;                    grads[&amp;#39;db&amp;#39; + str(l)] = dbl&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    v -- Adam variable, moving average of the first gradient, python dictionary&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    s -- Adam variable, moving average of the squared gradient, python dictionary&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    learning_rate -- the learning rate, scalar.&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    beta1 -- Exponential decay hyperparameter for the first moment estimates &lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    beta2 -- Exponential decay hyperparameter for the second moment estimates &lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    epsilon -- hyperparameter preventing division by zero in Adam updates&lt;/span&gt;

&lt;span class=&quot;sd&quot;&gt;    Returns:&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    parameters -- python dictionary containing your updated parameters &lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    v -- Adam variable, moving average of the first gradient, python dictionary&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    s -- Adam variable, moving average of the squared gradient, python dictionary&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    &amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;

    &lt;span class=&quot;n&quot;&gt;L&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;parameters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;//&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;                 &lt;span class=&quot;c1&quot;&gt;# number of layers in the neural networks&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;v_corrected&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{}&lt;/span&gt;                         &lt;span class=&quot;c1&quot;&gt;# Initializing first moment estimate, python dictionary&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;s_corrected&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{}&lt;/span&gt;                         &lt;span class=&quot;c1&quot;&gt;# Initializing second moment estimate, python dictionary&lt;/span&gt;

    &lt;span class=&quot;c1&quot;&gt;# Perform Adam update on all parameters&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;l&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;L&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;c1&quot;&gt;# Moving average of the gradients. Inputs: &amp;quot;v, grads, beta1&amp;quot;. Output: &amp;quot;v&amp;quot;.&lt;/span&gt;

        &lt;span class=&quot;n&quot;&gt;v&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;dW&amp;quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;l&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;beta1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;v&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;dW&amp;quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;l&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;beta1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;grads&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;dW&amp;#39;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;l&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)]&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;v&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;db&amp;quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;l&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;beta1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;v&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;db&amp;quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;l&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;beta1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;grads&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;db&amp;#39;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;l&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)]&lt;/span&gt;


        &lt;span class=&quot;c1&quot;&gt;# Compute bias-corrected first moment estimate. Inputs: &amp;quot;v, beta1, t&amp;quot;. Output: &amp;quot;v_corrected&amp;quot;.&lt;/span&gt;

        &lt;span class=&quot;n&quot;&gt;v_corrected&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;dW&amp;quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;l&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;v&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;dW&amp;quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;l&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;beta1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;**&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;v_corrected&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;db&amp;quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;l&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;v&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;db&amp;quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;l&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;beta1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;**&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;


        &lt;span class=&quot;c1&quot;&gt;# Moving average of the squared gradients. Inputs: &amp;quot;s, grads, beta2&amp;quot;. Output: &amp;quot;s&amp;quot;.&lt;/span&gt;

        &lt;span class=&quot;n&quot;&gt;s&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;dW&amp;quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;l&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;beta2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;s&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;dW&amp;quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;l&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;beta2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;grads&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;dW&amp;#39;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;l&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)])&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;**&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;s&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;db&amp;quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;l&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;beta2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;s&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;db&amp;quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;l&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;beta2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;grads&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;db&amp;#39;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;l&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)])&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;**&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;


        &lt;span class=&quot;c1&quot;&gt;# Compute bias-corrected second raw moment estimate. Inputs: &amp;quot;s, beta2, t&amp;quot;. Output: &amp;quot;s_corrected&amp;quot;.&lt;/span&gt;

        &lt;span class=&quot;n&quot;&gt;s_corrected&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;dW&amp;quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;l&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;s&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;dW&amp;quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;l&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;beta2&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;**&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;s_corrected&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;db&amp;quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;l&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;s&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;db&amp;quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;l&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;beta2&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;**&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;


        &lt;span class=&quot;c1&quot;&gt;# Update parameters. Inputs: &amp;quot;parameters, learning_rate, v_corrected, s_corrected, epsilon&amp;quot;. Output: &amp;quot;parameters&amp;quot;.&lt;/span&gt;

        &lt;span class=&quot;n&quot;&gt;parameters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;W&amp;quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;l&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;parameters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;W&amp;quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;l&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;learning_rate&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;v_corrected&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;dW&amp;quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;l&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; 
                                                                                  &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sqrt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;s_corrected&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;dW&amp;quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;l&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)])&lt;/span&gt;
                                                                                          &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;epsilon&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;parameters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;b&amp;quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;l&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;parameters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;b&amp;quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;l&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;learning_rate&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;v_corrected&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;db&amp;quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;l&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; 
                                                                                  &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sqrt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;s_corrected&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;db&amp;quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;l&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)])&lt;/span&gt;
                                                                                          &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;epsilon&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;


    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;parameters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;v&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;s&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div class=&quot;codehilite&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;parameters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;grads&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;v&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;s&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;update_parameters_with_adam_test_case&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;parameters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;v&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;s&lt;/span&gt;  &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;update_parameters_with_adam&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;parameters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;grads&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;v&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;s&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;t&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;W1 = &amp;quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;parameters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;W1&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]))&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;b1 = &amp;quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;parameters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;b1&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]))&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;W2 = &amp;quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;parameters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;W2&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]))&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;b2 = &amp;quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;parameters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;b2&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]))&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;v[&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\&amp;quot;&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;dW1&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\&amp;quot;&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;] = &amp;quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;v&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;dW1&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]))&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;v[&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\&amp;quot;&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;db1&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\&amp;quot;&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;] = &amp;quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;v&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;db1&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]))&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;v[&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\&amp;quot;&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;dW2&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\&amp;quot;&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;] = &amp;quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;v&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;dW2&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]))&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;v[&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\&amp;quot;&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;db2&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\&amp;quot;&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;] = &amp;quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;v&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;db2&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]))&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;s[&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\&amp;quot;&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;dW1&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\&amp;quot;&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;] = &amp;quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;s&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;dW1&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]))&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;s[&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\&amp;quot;&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;db1&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\&amp;quot;&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;] = &amp;quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;s&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;db1&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]))&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;s[&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\&amp;quot;&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;dW2&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\&amp;quot;&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;] = &amp;quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;s&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;dW2&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]))&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;s[&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\&amp;quot;&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;db2&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\&amp;quot;&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;] = &amp;quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;s&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;db2&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]))&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div class=&quot;codehilite&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;W1 = [[ 1.63178673 -0.61919778 -0.53561312]
 [-1.08040999  0.85796626 -2.29409733]]
b1 = [[ 1.75225313]
 [-0.75376553]]
W2 = [[ 0.32648046 -0.25681174  1.46954931]
 [-2.05269934 -0.31497584 -0.37661299]
 [ 1.14121081 -1.09244991 -0.16498684]]
b2 = [[-0.88529979]
 [ 0.03477238]
 [ 0.57537385]]
v[&amp;quot;dW1&amp;quot;] = [[-0.11006192  0.11447237  0.09015907]
 [ 0.05024943  0.09008559 -0.06837279]]
v[&amp;quot;db1&amp;quot;] = [[-0.01228902]
 [-0.09357694]]
v[&amp;quot;dW2&amp;quot;] = [[-0.02678881  0.05303555 -0.06916608]
 [-0.03967535 -0.06871727 -0.08452056]
 [-0.06712461 -0.00126646 -0.11173103]]
v[&amp;quot;db2&amp;quot;] = [[ 0.02344157]
 [ 0.16598022]
 [ 0.07420442]]
s[&amp;quot;dW1&amp;quot;] = [[ 0.00121136  0.00131039  0.00081287]
 [ 0.0002525   0.00081154  0.00046748]]
s[&amp;quot;db1&amp;quot;] = [[  1.51020075e-05]
 [  8.75664434e-04]]
s[&amp;quot;dW2&amp;quot;] = [[  7.17640232e-05   2.81276921e-04   4.78394595e-04]
 [  1.57413361e-04   4.72206320e-04   7.14372576e-04]
 [  4.50571368e-04   1.60392066e-07   1.24838242e-03]]
s[&amp;quot;db2&amp;quot;] = [[  5.49507194e-05]
 [  2.75494327e-03]
 [  5.50629536e-04]]
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;strong&gt;Expected Output&lt;/strong&gt;:&lt;/p&gt;
&lt;table&gt; 
    &lt;tr&gt;
    &lt;td &gt; **W1** &lt;/td&gt; 
           &lt;td &gt; [[ 1.63178673 -0.61919778 -0.53561312]
 [-1.08040999  0.85796626 -2.29409733]] &lt;/td&gt; 
    &lt;/tr&gt;

    &lt;tr&gt;
    &lt;td &gt; **b1** &lt;/td&gt; 
           &lt;td &gt; [[ 1.75225313]
 [-0.75376553]] &lt;/td&gt; 
    &lt;/tr&gt; 

    &lt;tr&gt;
    &lt;td &gt; **W2** &lt;/td&gt; 
           &lt;td &gt; [[ 0.32648046 -0.25681174  1.46954931]
 [-2.05269934 -0.31497584 -0.37661299]
 [ 1.14121081 -1.09245036 -0.16498684]] &lt;/td&gt; 
    &lt;/tr&gt; 

    &lt;tr&gt;
    &lt;td &gt; **b2** &lt;/td&gt; 
           &lt;td &gt; [[-0.88529978]
 [ 0.03477238]
 [ 0.57537385]] &lt;/td&gt; 
    &lt;/tr&gt; 
    &lt;tr&gt;
    &lt;td &gt; **v[&quot;dW1&quot;]** &lt;/td&gt; 
           &lt;td &gt; [[-0.11006192  0.11447237  0.09015907]
 [ 0.05024943  0.09008559 -0.06837279]] &lt;/td&gt; 
    &lt;/tr&gt; 

    &lt;tr&gt;
    &lt;td &gt; **v[&quot;db1&quot;]** &lt;/td&gt; 
           &lt;td &gt; [[-0.01228902]
 [-0.09357694]] &lt;/td&gt; 
    &lt;/tr&gt; 

    &lt;tr&gt;
    &lt;td &gt; **v[&quot;dW2&quot;]** &lt;/td&gt; 
           &lt;td &gt; [[-0.02678881  0.05303555 -0.06916608]
 [-0.03967535 -0.06871727 -0.08452056]
 [-0.06712461 -0.00126646 -0.11173103]] &lt;/td&gt; 
    &lt;/tr&gt; 

    &lt;tr&gt;
    &lt;td &gt; **v[&quot;db2&quot;]** &lt;/td&gt; 
           &lt;td &gt; [[ 0.02344157]
 [ 0.16598022]
 [ 0.07420442]] &lt;/td&gt; 
    &lt;/tr&gt; 
    &lt;tr&gt;
    &lt;td &gt; **s[&quot;dW1&quot;]** &lt;/td&gt; 
           &lt;td &gt; [[ 0.00121136  0.00131039  0.00081287]
 [ 0.0002525   0.00081154  0.00046748]] &lt;/td&gt; 
    &lt;/tr&gt; 

    &lt;tr&gt;
    &lt;td &gt; **s[&quot;db1&quot;]** &lt;/td&gt; 
           &lt;td &gt; [[  1.51020075e-05]
 [  8.75664434e-04]] &lt;/td&gt; 
    &lt;/tr&gt; 

    &lt;tr&gt;
    &lt;td &gt; **s[&quot;dW2&quot;]** &lt;/td&gt; 
           &lt;td &gt; [[  7.17640232e-05   2.81276921e-04   4.78394595e-04]
 [  1.57413361e-04   4.72206320e-04   7.14372576e-04]
 [  4.50571368e-04   1.60392066e-07   1.24838242e-03]] &lt;/td&gt; 
    &lt;/tr&gt; 

    &lt;tr&gt;
    &lt;td &gt; **s[&quot;db2&quot;]** &lt;/td&gt; 
           &lt;td &gt; [[  5.49507194e-05]
 [  2.75494327e-03]
 [  5.50629536e-04]] &lt;/td&gt; 
    &lt;/tr&gt;
&lt;/table&gt;

&lt;p&gt;You now have three working optimization algorithms (mini-batch gradient descent, Momentum, Adam). Let&#39;s implement a model with each of these optimizers and observe the difference.&lt;/p&gt;
&lt;h2 id=&quot;5-model-with-different-optimization-algorithms&quot;&gt;5 - Model with different optimization algorithms&lt;/h2&gt;
&lt;p&gt;Lets use the following &quot;moons&quot; dataset to test the different optimization methods. (The dataset is named &quot;moons&quot; because the data from each of the two classes looks a bit like a crescent-shaped moon.) &lt;/p&gt;
&lt;div class=&quot;codehilite&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;train_X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;train_Y&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;load_dataset&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;img alt=&quot;png&quot; src=&quot;https://raw.githubusercontent.com/karenyyy/Coursera_and_Udemy/master/deeplearningai_coursera/Improving%20Deep%20Neural%20Networks%3A%20Hyperparameter%20tuning%2C%20Regularization%20and%20Optimization%20Home/images/week2/output_34_0.png&quot; /&gt;&lt;/p&gt;
&lt;p&gt;We have already implemented a 3-layer neural network. You will train it with: 
- Mini-batch &lt;strong&gt;Gradient Descent&lt;/strong&gt;: it will call your function:
    - &lt;code&gt;update_parameters_with_gd()&lt;/code&gt;
- Mini-batch &lt;strong&gt;Momentum&lt;/strong&gt;: it will call your functions:
    - &lt;code&gt;initialize_velocity()&lt;/code&gt; and &lt;code&gt;update_parameters_with_momentum()&lt;/code&gt;
- Mini-batch &lt;strong&gt;Adam&lt;/strong&gt;: it will call your functions:
    - &lt;code&gt;initialize_adam()&lt;/code&gt; and &lt;code&gt;update_parameters_with_adam()&lt;/code&gt;&lt;/p&gt;
&lt;div class=&quot;codehilite&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;layers_dims&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;optimizer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;learning_rate&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.0007&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mini_batch_size&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;64&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;beta&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.9&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
          &lt;span class=&quot;n&quot;&gt;beta1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.9&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;beta2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.999&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;  &lt;span class=&quot;n&quot;&gt;epsilon&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;1e-8&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;num_epochs&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;10000&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;print_cost&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;sd&quot;&gt;&amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    3-layer neural network model which can be run in different optimizer modes.&lt;/span&gt;

&lt;span class=&quot;sd&quot;&gt;    Arguments:&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    X -- input data, of shape (2, number of examples)&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    Y -- true &amp;quot;label&amp;quot; vector (1 for blue dot / 0 for red dot), of shape (1, number of examples)&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    layers_dims -- python list, containing the size of each layer&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    learning_rate -- the learning rate, scalar.&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    mini_batch_size -- the size of a mini batch&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    beta -- Momentum hyperparameter&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    beta1 -- Exponential decay hyperparameter for the past gradients estimates &lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    beta2 -- Exponential decay hyperparameter for the past squared gradients estimates &lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    epsilon -- hyperparameter preventing division by zero in Adam updates&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    num_epochs -- number of epochs&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    print_cost -- True to print the cost every 1000 epochs&lt;/span&gt;

&lt;span class=&quot;sd&quot;&gt;    Returns:&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    parameters -- python dictionary containing your updated parameters &lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    &amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;

    &lt;span class=&quot;n&quot;&gt;L&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;layers_dims&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;             &lt;span class=&quot;c1&quot;&gt;# number of layers in the neural networks&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;costs&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[]&lt;/span&gt;                       &lt;span class=&quot;c1&quot;&gt;# to keep track of the cost&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;t&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;                            &lt;span class=&quot;c1&quot;&gt;# initializing the counter required for Adam update&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;seed&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;                        &lt;span class=&quot;c1&quot;&gt;# For grading purposes, so that your &amp;quot;random&amp;quot; minibatches are the same as ours&lt;/span&gt;

    &lt;span class=&quot;c1&quot;&gt;# Initialize parameters&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;parameters&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;initialize_parameters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;layers_dims&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

    &lt;span class=&quot;c1&quot;&gt;# Initialize the optimizer&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;optimizer&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&amp;quot;gd&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;pass&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;# no initialization required for gradient descent&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;elif&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;optimizer&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&amp;quot;momentum&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;v&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;initialize_velocity&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;parameters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;elif&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;optimizer&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&amp;quot;adam&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;v&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;s&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;initialize_adam&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;parameters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

    &lt;span class=&quot;c1&quot;&gt;# Optimization loop&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;num_epochs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;

        &lt;span class=&quot;c1&quot;&gt;# Define the random minibatches. We increment the seed to reshuffle differently the dataset after each epoch&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;seed&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;seed&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;minibatches&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;random_mini_batches&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mini_batch_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;seed&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

        &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;minibatch&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;minibatches&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;

            &lt;span class=&quot;c1&quot;&gt;# Select a minibatch&lt;/span&gt;
            &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;minibatch_X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;minibatch_Y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;minibatch&lt;/span&gt;

            &lt;span class=&quot;c1&quot;&gt;# Forward propagation&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;a3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;caches&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;forward_propagation&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;minibatch_X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;parameters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

            &lt;span class=&quot;c1&quot;&gt;# Compute cost&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;cost&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;compute_cost&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;a3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;minibatch_Y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

            &lt;span class=&quot;c1&quot;&gt;# Backward propagation&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;grads&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;backward_propagation&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;minibatch_X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;minibatch_Y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;caches&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

            &lt;span class=&quot;c1&quot;&gt;# Update parameters&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;optimizer&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&amp;quot;gd&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;parameters&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;update_parameters_with_gd&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;parameters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;grads&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;learning_rate&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;elif&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;optimizer&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&amp;quot;momentum&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;parameters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;v&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;update_parameters_with_momentum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;parameters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;grads&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;v&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;beta&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;learning_rate&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;elif&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;optimizer&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&amp;quot;adam&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;t&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;t&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;# Adam counter&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;parameters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;v&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;s&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;update_parameters_with_adam&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;parameters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;grads&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;v&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;s&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                                                               &lt;span class=&quot;n&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;learning_rate&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;beta1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;beta2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;  &lt;span class=&quot;n&quot;&gt;epsilon&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

        &lt;span class=&quot;c1&quot;&gt;# Print the cost every 1000 epoch&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;print_cost&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;and&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;%&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1000&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;print&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;Cost after epoch &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;%i&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;: &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;%f&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;%&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cost&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;print_cost&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;and&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;%&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;100&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;costs&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;append&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cost&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

    &lt;span class=&quot;c1&quot;&gt;# plot the cost&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;plot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;costs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ylabel&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;cost&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;xlabel&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;epochs (per 100)&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;title&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;Learning rate = &amp;quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;learning_rate&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;show&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;

    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;parameters&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;You will now run this 3 layer neural network with each of the 3 optimization methods.&lt;/p&gt;
&lt;h3 id=&quot;51-mini-batch-gradient-descent&quot;&gt;5.1 - Mini-batch Gradient descent&lt;/h3&gt;
&lt;p&gt;Run the following code to see how the model does with mini-batch gradient descent.&lt;/p&gt;
&lt;div class=&quot;codehilite&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;c1&quot;&gt;# train 3-layer model&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;layers_dims&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;train_X&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;parameters&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;train_X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;train_Y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;layers_dims&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;optimizer&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&amp;quot;gd&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Predict&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;predictions&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;predict&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;train_X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;train_Y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;parameters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Plot decision boundary&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;title&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;Model with Gradient Descent optimization&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;axes&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;gca&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;axes&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;set_xlim&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;1.5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;2.5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;axes&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;set_ylim&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;1.5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;plot_decision_boundary&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;lambda&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;predict_dec&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;parameters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;T&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;train_X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;train_Y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div class=&quot;codehilite&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;Cost after epoch 0: 0.690736
Cost after epoch 1000: 0.685273
Cost after epoch 2000: 0.647072
Cost after epoch 3000: 0.619525
Cost after epoch 4000: 0.576584
Cost after epoch 5000: 0.607243
Cost after epoch 6000: 0.529403
Cost after epoch 7000: 0.460768
Cost after epoch 8000: 0.465586
Cost after epoch 9000: 0.464518
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;img alt=&quot;png&quot; src=&quot;https://raw.githubusercontent.com/karenyyy/Coursera_and_Udemy/master/deeplearningai_coursera/Improving%20Deep%20Neural%20Networks%3A%20Hyperparameter%20tuning%2C%20Regularization%20and%20Optimization%20Home/images/week2/output_38_1.png&quot; /&gt;&lt;/p&gt;
&lt;div class=&quot;codehilite&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Accuracy&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.796666666667&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;img alt=&quot;png&quot; src=&quot;https://raw.githubusercontent.com/karenyyy/Coursera_and_Udemy/master/deeplearningai_coursera/Improving%20Deep%20Neural%20Networks%3A%20Hyperparameter%20tuning%2C%20Regularization%20and%20Optimization%20Home/images/week2/output_38_3.png&quot; /&gt;&lt;/p&gt;
&lt;h3 id=&quot;52-mini-batch-gradient-descent-with-momentum&quot;&gt;5.2 - Mini-batch gradient descent with momentum&lt;/h3&gt;
&lt;p&gt;Run the following code to see how the model does with momentum. Because this example is relatively simple, the gains from using momemtum are small; but for more complex problems you might see bigger gains.&lt;/p&gt;
&lt;div class=&quot;codehilite&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;c1&quot;&gt;# train 3-layer model&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;layers_dims&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;train_X&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;parameters&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;train_X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;train_Y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;layers_dims&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;beta&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.9&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;optimizer&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&amp;quot;momentum&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Predict&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;predictions&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;predict&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;train_X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;train_Y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;parameters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Plot decision boundary&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;title&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;Model with Momentum optimization&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;axes&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;gca&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;axes&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;set_xlim&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;1.5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;2.5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;axes&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;set_ylim&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;1.5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;plot_decision_boundary&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;lambda&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;predict_dec&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;parameters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;T&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;train_X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;train_Y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div class=&quot;codehilite&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;Cost after epoch 0: 0.690741
Cost after epoch 1000: 0.685341
Cost after epoch 2000: 0.647145
Cost after epoch 3000: 0.619594
Cost after epoch 4000: 0.576665
Cost after epoch 5000: 0.607324
Cost after epoch 6000: 0.529476
Cost after epoch 7000: 0.460936
Cost after epoch 8000: 0.465780
Cost after epoch 9000: 0.464740
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;img alt=&quot;png&quot; src=&quot;https://raw.githubusercontent.com/karenyyy/Coursera_and_Udemy/master/deeplearningai_coursera/Improving%20Deep%20Neural%20Networks%3A%20Hyperparameter%20tuning%2C%20Regularization%20and%20Optimization%20Home/images/week2/output_40_1.png&quot; /&gt;&lt;/p&gt;
&lt;div class=&quot;codehilite&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Accuracy&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.796666666667&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;img alt=&quot;png&quot; src=&quot;https://raw.githubusercontent.com/karenyyy/Coursera_and_Udemy/master/deeplearningai_coursera/Improving%20Deep%20Neural%20Networks%3A%20Hyperparameter%20tuning%2C%20Regularization%20and%20Optimization%20Home/images/week2/output_40_3.png&quot; /&gt;&lt;/p&gt;
&lt;h3 id=&quot;53-mini-batch-with-adam-mode&quot;&gt;5.3 - Mini-batch with Adam mode&lt;/h3&gt;
&lt;p&gt;Run the following code to see how the model does with Adam.&lt;/p&gt;
&lt;div class=&quot;codehilite&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;c1&quot;&gt;# train 3-layer model&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;layers_dims&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;train_X&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;parameters&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;train_X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;train_Y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;layers_dims&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;optimizer&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&amp;quot;adam&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Predict&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;predictions&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;predict&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;train_X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;train_Y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;parameters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Plot decision boundary&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;title&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;Model with Adam optimization&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;axes&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;gca&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;axes&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;set_xlim&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;1.5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;2.5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;axes&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;set_ylim&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;1.5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;plot_decision_boundary&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;lambda&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;predict_dec&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;parameters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;T&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;train_X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;train_Y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div class=&quot;codehilite&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;Cost after epoch 0: 0.690552
Cost after epoch 1000: 0.185567
Cost after epoch 2000: 0.150852
Cost after epoch 3000: 0.074454
Cost after epoch 4000: 0.125936
Cost after epoch 5000: 0.104235
Cost after epoch 6000: 0.100552
Cost after epoch 7000: 0.031601
Cost after epoch 8000: 0.111709
Cost after epoch 9000: 0.197648
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;img alt=&quot;png&quot; src=&quot;https://raw.githubusercontent.com/karenyyy/Coursera_and_Udemy/master/deeplearningai_coursera/Improving%20Deep%20Neural%20Networks%3A%20Hyperparameter%20tuning%2C%20Regularization%20and%20Optimization%20Home/images/week2/output_42_1.png&quot; /&gt;&lt;/p&gt;
&lt;div class=&quot;codehilite&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Accuracy&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.94&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;img alt=&quot;png&quot; src=&quot;https://raw.githubusercontent.com/karenyyy/Coursera_and_Udemy/master/deeplearningai_coursera/Improving%20Deep%20Neural%20Networks%3A%20Hyperparameter%20tuning%2C%20Regularization%20and%20Optimization%20Home/images/week2/output_42_3.png&quot; /&gt;&lt;/p&gt;
&lt;h3 id=&quot;54-summary&quot;&gt;5.4 - Summary&lt;/h3&gt;
&lt;table&gt; 
    &lt;tr&gt;
        &lt;td&gt;
        **optimization method**
        &lt;/td&gt;
        &lt;td&gt;
        **accuracy**
        &lt;/td&gt;
        &lt;td&gt;
        **cost shape**
        &lt;/td&gt;

    &lt;/tr&gt;
        &lt;td&gt;
        Gradient descent
        &lt;/td&gt;
        &lt;td&gt;
        79.7%
        &lt;/td&gt;
        &lt;td&gt;
        oscillations
        &lt;/td&gt;
    &lt;tr&gt;
        &lt;td&gt;
        Momentum
        &lt;/td&gt;
        &lt;td&gt;
        79.7%
        &lt;/td&gt;
        &lt;td&gt;
        oscillations
        &lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
        &lt;td&gt;
        Adam
        &lt;/td&gt;
        &lt;td&gt;
        94%
        &lt;/td&gt;
        &lt;td&gt;
        smoother
        &lt;/td&gt;
    &lt;/tr&gt;
&lt;/table&gt;

&lt;p&gt;Momentum usually helps, but given the small learning rate and the simplistic dataset, its impact is almost negligeable. Also, the huge oscillations you see in the cost come from the fact that some minibatches are more difficult thans others for the optimization algorithm.&lt;/p&gt;
&lt;p&gt;Adam on the other hand, clearly outperforms mini-batch gradient descent and Momentum. If you run the model for more epochs on this simple dataset, all three methods will lead to very good results. However, you&#39;ve seen that Adam converges a lot faster.&lt;/p&gt;
&lt;p&gt;Some advantages of Adam include:
- Relatively low memory requirements (though higher than gradient descent and gradient descent with momentum) 
- Usually works well even with little tuning of hyperparameters (except $\alpha$)&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;References&lt;/strong&gt;:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Adam paper: https://arxiv.org/pdf/1412.6980.pdf&lt;/li&gt;
&lt;/ul&gt;deeplearning.ai - Improving Deep Neural Networks - Week 1 Assignment 1
&lt;h1 id=&quot;initialization&quot;&gt;Initialization&lt;/h1&gt;
&lt;p&gt;Welcome to the first assignment of &quot;Improving Deep Neural Networks&quot;. &lt;/p&gt;
&lt;p&gt;Training your neural network requires specifying an initial value of the weights. A well chosen initialization method will help learning.  &lt;/p&gt;
&lt;p&gt;If you completed the previous course of this specialization, you probably followed our instructions for weight initialization, and it has worked out so far. But how do you choose the initialization for a new neural network? In this notebook, you will see how different initializations lead to different results. &lt;/p&gt;
&lt;p&gt;A well chosen initialization can:
- Speed up the convergence of gradient descent
- Increase the odds of gradient descent converging to a lower training (and generalization) error &lt;/p&gt;
&lt;p&gt;To get started, run the following cell to load the packages and the planar dataset you will try to classify.&lt;/p&gt;
&lt;div class=&quot;codehilite&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;numpy&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;np&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;matplotlib.pyplot&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;plt&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;sklearn&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;sklearn.datasets&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;init_utils&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sigmoid&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;relu&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;compute_loss&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;forward_propagation&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;backward_propagation&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;init_utils&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;update_parameters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;predict&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;load_dataset&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;plot_decision_boundary&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;predict_dec&lt;/span&gt;

&lt;span class=&quot;o&quot;&gt;%&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;matplotlib&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;inline&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;rcParams&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;figure.figsize&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;7.0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;4.0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;# set default size of plots&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;rcParams&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;image.interpolation&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&amp;#39;nearest&amp;#39;&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;rcParams&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;image.cmap&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&amp;#39;gray&amp;#39;&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# load image dataset: blue/red dots in circles&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;train_X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;train_Y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;test_X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;test_Y&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;load_dataset&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;img alt=&quot;png&quot; src=&quot;https://raw.githubusercontent.com/karenyyy/Coursera_and_Udemy/master/deeplearningai_coursera/Improving%20Deep%20Neural%20Networks%3A%20Hyperparameter%20tuning%2C%20Regularization%20and%20Optimization%20Home/images/week1/output_1_0.png&quot; /&gt;&lt;/p&gt;
&lt;p&gt;You would like a classifier to separate the blue dots from the red dots.&lt;/p&gt;
&lt;h2 id=&quot;1-neural-network-model&quot;&gt;1 - Neural Network model&lt;/h2&gt;
&lt;p&gt;You will use a 3-layer neural network (already implemented for you). Here are the initialization methods you will experiment with:&lt;br /&gt;
- &lt;em&gt;Zeros initialization&lt;/em&gt; --  setting &lt;code&gt;initialization = &quot;zeros&quot;&lt;/code&gt; in the input argument.
- &lt;em&gt;Random initialization&lt;/em&gt; -- setting &lt;code&gt;initialization = &quot;random&quot;&lt;/code&gt; in the input argument. This initializes the weights to large random values.&lt;br /&gt;
- &lt;em&gt;He initialization&lt;/em&gt; -- setting &lt;code&gt;initialization = &quot;he&quot;&lt;/code&gt; in the input argument. This initializes the weights to random values scaled according to a paper by He et al., 2015. &lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Instructions&lt;/strong&gt;: Please quickly read over the code below, and run it. In the next part you will implement the three initialization methods that this &lt;code&gt;model()&lt;/code&gt; calls.&lt;/p&gt;
&lt;div class=&quot;codehilite&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;learning_rate&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.01&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;num_iterations&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;15000&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;print_cost&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;initialization&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&amp;quot;he&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;sd&quot;&gt;&amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    Implements a three-layer neural network: LINEAR-&amp;gt;RELU-&amp;gt;LINEAR-&amp;gt;RELU-&amp;gt;LINEAR-&amp;gt;SIGMOID.&lt;/span&gt;

&lt;span class=&quot;sd&quot;&gt;    Arguments:&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    X -- input data, of shape (2, number of examples)&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    Y -- true &amp;quot;label&amp;quot; vector (containing 0 for red dots; 1 for blue dots), of shape (1, number of examples)&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    learning_rate -- learning rate for gradient descent &lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    num_iterations -- number of iterations to run gradient descent&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    print_cost -- if True, print the cost every 1000 iterations&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    initialization -- flag to choose which initialization to use (&amp;quot;zeros&amp;quot;,&amp;quot;random&amp;quot; or &amp;quot;he&amp;quot;)&lt;/span&gt;

&lt;span class=&quot;sd&quot;&gt;    Returns:&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    parameters -- parameters learnt by the model&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    &amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;

    &lt;span class=&quot;n&quot;&gt;grads&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{}&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;costs&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[]&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;# to keep track of the loss&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;m&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;# number of examples&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;layers_dims&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;

    &lt;span class=&quot;c1&quot;&gt;# Initialize parameters dictionary.&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;initialization&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&amp;quot;zeros&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;parameters&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;initialize_parameters_zeros&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;layers_dims&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;elif&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;initialization&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&amp;quot;random&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;parameters&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;initialize_parameters_random&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;layers_dims&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;elif&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;initialization&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&amp;quot;he&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;parameters&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;initialize_parameters_he&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;layers_dims&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

    &lt;span class=&quot;c1&quot;&gt;# Loop (gradient descent)&lt;/span&gt;

    &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;num_iterations&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;

        &lt;span class=&quot;c1&quot;&gt;# Forward propagation: LINEAR -&amp;gt; RELU -&amp;gt; LINEAR -&amp;gt; RELU -&amp;gt; LINEAR -&amp;gt; SIGMOID.&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;a3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cache&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;forward_propagation&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;parameters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

        &lt;span class=&quot;c1&quot;&gt;# Loss&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;cost&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;compute_loss&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;a3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

        &lt;span class=&quot;c1&quot;&gt;# Backward propagation.&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;grads&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;backward_propagation&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cache&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

        &lt;span class=&quot;c1&quot;&gt;# Update parameters.&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;parameters&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;update_parameters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;parameters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;grads&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;learning_rate&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

        &lt;span class=&quot;c1&quot;&gt;# Print the loss every 1000 iterations&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;print_cost&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;and&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;%&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1000&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;Cost after iteration {}: {}&amp;quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;format&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cost&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;costs&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;append&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cost&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

    &lt;span class=&quot;c1&quot;&gt;# plot the loss&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;plot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;costs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ylabel&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;cost&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;xlabel&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;iterations (per hundreds)&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;title&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;Learning rate =&amp;quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;learning_rate&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;show&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;

    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;parameters&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;h2 id=&quot;2-zero-initialization&quot;&gt;2 - Zero initialization&lt;/h2&gt;
&lt;p&gt;There are two types of parameters to initialize in a neural network:
- the weight matrices $(W^{[1]}, W^{[2]}, W^{[3]}, ..., W^{[L-1]}, W^{[L]})$
- the bias vectors $(b^{[1]}, b^{[2]}, b^{[3]}, ..., b^{[L-1]}, b^{[L]})$&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Exercise&lt;/strong&gt;: Implement the following function to initialize all parameters to zeros. You&#39;ll see later that this does not work well since it fails to &quot;break symmetry&quot;, but lets try it anyway and see what happens. Use np.zeros((..,..)) with the correct shapes.&lt;/p&gt;
&lt;div class=&quot;codehilite&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;c1&quot;&gt;# GRADED FUNCTION: initialize_parameters_zeros &lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;initialize_parameters_zeros&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;layers_dims&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;sd&quot;&gt;&amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    Arguments:&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    layer_dims -- python array (list) containing the size of each layer.&lt;/span&gt;

&lt;span class=&quot;sd&quot;&gt;    Returns:&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    parameters -- python dictionary containing your parameters &amp;quot;W1&amp;quot;, &amp;quot;b1&amp;quot;, ..., &amp;quot;WL&amp;quot;, &amp;quot;bL&amp;quot;:&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;                    W1 -- weight matrix of shape (layers_dims[1], layers_dims[0])&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;                    b1 -- bias vector of shape (layers_dims[1], 1)&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;                    ...&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;                    WL -- weight matrix of shape (layers_dims[L], layers_dims[L-1])&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;                    bL -- bias vector of shape (layers_dims[L], 1)&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    &amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;

    &lt;span class=&quot;n&quot;&gt;parameters&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{}&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;L&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;layers_dims&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;            &lt;span class=&quot;c1&quot;&gt;# number of layers in the network&lt;/span&gt;

    &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;l&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;L&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;

        &lt;span class=&quot;n&quot;&gt;parameters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;W&amp;#39;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;l&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;zeros&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;((&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;layers_dims&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;l&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;layers_dims&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;l&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]))&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;parameters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;b&amp;#39;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;l&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;zeros&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;((&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;layers_dims&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;l&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;

    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;parameters&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div class=&quot;codehilite&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;parameters&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;initialize_parameters_zeros&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;W1 = &amp;quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;parameters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;W1&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]))&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;b1 = &amp;quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;parameters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;b1&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]))&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;W2 = &amp;quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;parameters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;W2&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]))&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;b2 = &amp;quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;parameters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;b2&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]))&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div class=&quot;codehilite&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;W1 = [[ 0.  0.  0.]
 [ 0.  0.  0.]]
b1 = [[ 0.]
 [ 0.]]
W2 = [[ 0.  0.]]
b2 = [[ 0.]]
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;strong&gt;Expected Output&lt;/strong&gt;:&lt;/p&gt;
&lt;table&gt; 
    &lt;tr&gt;
    &lt;td&gt;
    **W1**
    &lt;/td&gt;
        &lt;td&gt;
    [[ 0.  0.  0.]
 [ 0.  0.  0.]]
    &lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
    &lt;td&gt;
    **b1**
    &lt;/td&gt;
        &lt;td&gt;
    [[ 0.]
 [ 0.]]
    &lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
    &lt;td&gt;
    **W2**
    &lt;/td&gt;
        &lt;td&gt;
    [[ 0.  0.]]
    &lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
    &lt;td&gt;
    **b2**
    &lt;/td&gt;
        &lt;td&gt;
    [[ 0.]]
    &lt;/td&gt;
    &lt;/tr&gt;

&lt;/table&gt;

&lt;p&gt;Run the following code to train your model on 15,000 iterations using zeros initialization.&lt;/p&gt;
&lt;div class=&quot;codehilite&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;parameters&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;train_X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;train_Y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;initialization&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&amp;quot;zeros&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;On the train set:&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;predictions_train&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;predict&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;train_X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;train_Y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;parameters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;On the test set:&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;predictions_test&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;predict&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;test_X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;test_Y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;parameters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div class=&quot;codehilite&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;Cost after iteration 0: 0.6931471805599453
Cost after iteration 1000: 0.6931471805599453
Cost after iteration 2000: 0.6931471805599453
Cost after iteration 3000: 0.6931471805599453
Cost after iteration 4000: 0.6931471805599453
Cost after iteration 5000: 0.6931471805599453
Cost after iteration 6000: 0.6931471805599453
Cost after iteration 7000: 0.6931471805599453
Cost after iteration 8000: 0.6931471805599453
Cost after iteration 9000: 0.6931471805599453
Cost after iteration 10000: 0.6931471805599455
Cost after iteration 11000: 0.6931471805599453
Cost after iteration 12000: 0.6931471805599453
Cost after iteration 13000: 0.6931471805599453
Cost after iteration 14000: 0.6931471805599453
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;img alt=&quot;png&quot; src=&quot;https://raw.githubusercontent.com/karenyyy/Coursera_and_Udemy/master/deeplearningai_coursera/Improving%20Deep%20Neural%20Networks%3A%20Hyperparameter%20tuning%2C%20Regularization%20and%20Optimization%20Home/images/week1/output_11_1.png&quot; /&gt;&lt;/p&gt;
&lt;div class=&quot;codehilite&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;On the train set:
Accuracy: 0.5
On the test set:
Accuracy: 0.5
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;The performance is really bad, and the cost does not really decrease, and the algorithm performs no better than random guessing. Why? Lets look at the details of the predictions and the decision boundary:&lt;/p&gt;
&lt;div class=&quot;codehilite&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;predictions_train = &amp;quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;predictions_train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;predictions_test = &amp;quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;predictions_test&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div class=&quot;codehilite&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;predictions_train = [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
  0 0 0 0]]
predictions_test = [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]
&lt;/pre&gt;&lt;/div&gt;


&lt;div class=&quot;codehilite&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;title&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;Model with Zeros initialization&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;axes&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;gca&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;axes&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;set_xlim&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;1.5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;1.5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;axes&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;set_ylim&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;1.5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;1.5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;plot_decision_boundary&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;lambda&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;predict_dec&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;parameters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;T&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;train_X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;train_Y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;img alt=&quot;png&quot; src=&quot;https://raw.githubusercontent.com/karenyyy/Coursera_and_Udemy/master/deeplearningai_coursera/Improving%20Deep%20Neural%20Networks%3A%20Hyperparameter%20tuning%2C%20Regularization%20and%20Optimization%20Home/images/week1/output_14_0.png&quot; /&gt;&lt;/p&gt;
&lt;p&gt;The model is predicting 0 for every example. &lt;/p&gt;
&lt;p&gt;In general, initializing all the weights to zero results in the network failing to break symmetry. This means that every neuron in each layer will learn the same thing, and you might as well be training a neural network with $n^{[l]}=1$ for every layer, and the network is no more powerful than a linear classifier such as logistic regression. &lt;/p&gt;
&lt;p&gt;&lt;strong&gt;What you should remember&lt;/strong&gt;:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;The weights $W^{[l]}$ should be initialized randomly to break symmetry. &lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;It is however okay to initialize the biases $b^{[l]}$ to zeros. Symmetry is still broken so long as $W^{[l]}$ is initialized randomly. &lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;3-random-initialization&quot;&gt;3 - Random initialization&lt;/h2&gt;
&lt;p&gt;To break symmetry, lets intialize the weights randomly. Following random initialization, each neuron can then proceed to learn a different function of its inputs. In this exercise, you will see what happens if the weights are intialized randomly, but to very large values. &lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Exercise&lt;/strong&gt;: Implement the following function to initialize your weights to large random values (scaled by *10) and your biases to zeros. Use &lt;code&gt;np.random.randn(..,..) * 10&lt;/code&gt; for weights and &lt;code&gt;np.zeros((.., ..))&lt;/code&gt; for biases. We are using a fixed &lt;code&gt;np.random.seed(..)&lt;/code&gt; to make sure your &quot;random&quot; weights  match ours, so don&#39;t worry if running several times your code gives you always the same initial values for the parameters. &lt;/p&gt;
&lt;div class=&quot;codehilite&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;c1&quot;&gt;# GRADED FUNCTION: initialize_parameters_random&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;initialize_parameters_random&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;layers_dims&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;sd&quot;&gt;&amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    Arguments:&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    layer_dims -- python array (list) containing the size of each layer.&lt;/span&gt;

&lt;span class=&quot;sd&quot;&gt;    Returns:&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    parameters -- python dictionary containing your parameters &amp;quot;W1&amp;quot;, &amp;quot;b1&amp;quot;, ..., &amp;quot;WL&amp;quot;, &amp;quot;bL&amp;quot;:&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;                    W1 -- weight matrix of shape (layers_dims[1], layers_dims[0])&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;                    b1 -- bias vector of shape (layers_dims[1], 1)&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;                    ...&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;                    WL -- weight matrix of shape (layers_dims[L], layers_dims[L-1])&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;                    bL -- bias vector of shape (layers_dims[L], 1)&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    &amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;

    &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;random&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;seed&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;               &lt;span class=&quot;c1&quot;&gt;# This seed makes sure your &amp;quot;random&amp;quot; numbers will be the as ours&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;parameters&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{}&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;L&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;layers_dims&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;            &lt;span class=&quot;c1&quot;&gt;# integer representing the number of layers&lt;/span&gt;

    &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;l&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;L&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;

        &lt;span class=&quot;n&quot;&gt;parameters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;W&amp;#39;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;l&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;random&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;randn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;layers_dims&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;l&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;layers_dims&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;l&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;parameters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;b&amp;#39;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;l&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;zeros&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;((&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;layers_dims&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;l&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;


    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;parameters&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div class=&quot;codehilite&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;parameters&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;initialize_parameters_random&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;W1 = &amp;quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;parameters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;W1&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]))&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;b1 = &amp;quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;parameters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;b1&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]))&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;W2 = &amp;quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;parameters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;W2&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]))&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;b2 = &amp;quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;parameters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;b2&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]))&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div class=&quot;codehilite&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;W1 = [[ 17.88628473   4.36509851   0.96497468]
 [-18.63492703  -2.77388203  -3.54758979]]
b1 = [[ 0.]
 [ 0.]]
W2 = [[-0.82741481 -6.27000677]]
b2 = [[ 0.]]
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;strong&gt;Expected Output&lt;/strong&gt;:&lt;/p&gt;
&lt;table&gt; 
    &lt;tr&gt;
    &lt;td&gt;
    **W1**
    &lt;/td&gt;
        &lt;td&gt;
    [[ 17.88628473   4.36509851   0.96497468]
 [-18.63492703  -2.77388203  -3.54758979]]
    &lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
    &lt;td&gt;
    **b1**
    &lt;/td&gt;
        &lt;td&gt;
    [[ 0.]
 [ 0.]]
    &lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
    &lt;td&gt;
    **W2**
    &lt;/td&gt;
        &lt;td&gt;
    [[-0.82741481 -6.27000677]]
    &lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
    &lt;td&gt;
    **b2**
    &lt;/td&gt;
        &lt;td&gt;
    [[ 0.]]
    &lt;/td&gt;
    &lt;/tr&gt;

&lt;/table&gt;

&lt;p&gt;Run the following code to train your model on 15,000 iterations using random initialization.&lt;/p&gt;
&lt;div class=&quot;codehilite&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;parameters&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;train_X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;train_Y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;initialization&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&amp;quot;random&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;On the train set:&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;predictions_train&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;predict&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;train_X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;train_Y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;parameters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;On the test set:&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;predictions_test&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;predict&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;test_X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;test_Y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;parameters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div class=&quot;codehilite&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;/home/jovyan/work/week5/Initialization/init_utils.py:145: RuntimeWarning: divide by zero encountered in log
  logprobs = np.multiply(-np.log(a3),Y) + np.multiply(-np.log(1 - a3), 1 - Y)
/home/jovyan/work/week5/Initialization/init_utils.py:145: RuntimeWarning: invalid value encountered in multiply
  logprobs = np.multiply(-np.log(a3),Y) + np.multiply(-np.log(1 - a3), 1 - Y)


Cost after iteration 0: inf
Cost after iteration 1000: 0.6237287551108738
Cost after iteration 2000: 0.5981106708339466
Cost after iteration 3000: 0.5638353726276827
Cost after iteration 4000: 0.550152614449184
Cost after iteration 5000: 0.5444235275228304
Cost after iteration 6000: 0.5374184054630083
Cost after iteration 7000: 0.47357131493578297
Cost after iteration 8000: 0.39775634899580387
Cost after iteration 9000: 0.3934632865981078
Cost after iteration 10000: 0.39202525076484457
Cost after iteration 11000: 0.38921493051297673
Cost after iteration 12000: 0.38614221789840486
Cost after iteration 13000: 0.38497849983013926
Cost after iteration 14000: 0.38278397192120406
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;img alt=&quot;png&quot; src=&quot;https://raw.githubusercontent.com/karenyyy/Coursera_and_Udemy/master/deeplearningai_coursera/Improving%20Deep%20Neural%20Networks%3A%20Hyperparameter%20tuning%2C%20Regularization%20and%20Optimization%20Home/images/week1/output_22_2.png&quot; /&gt;&lt;/p&gt;
&lt;div class=&quot;codehilite&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;On the train set:
Accuracy: 0.83
On the test set:
Accuracy: 0.86
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;If you see &quot;inf&quot; as the cost after the iteration 0, this is because of numerical roundoff; a more numerically sophisticated implementation would fix this. But this isn&#39;t worth worrying about for our purposes. &lt;/p&gt;
&lt;p&gt;Anyway, it looks like you have broken symmetry, and this gives better results. than before. The model is no longer outputting all 0s. &lt;/p&gt;
&lt;div class=&quot;codehilite&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;predictions_train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;predictions_test&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div class=&quot;codehilite&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;[[1 0 1 1 0 0 1 1 1 1 1 0 1 0 0 1 0 1 1 0 0 0 1 0 1 1 1 1 1 1 0 1 1 0 0 1 1
  1 1 1 1 1 1 0 1 1 1 1 0 1 0 1 1 1 1 0 0 1 1 1 1 0 1 1 0 1 0 1 1 1 1 0 0 0
  0 0 1 0 1 0 1 1 1 0 0 1 1 1 1 1 1 0 0 1 1 1 0 1 1 0 1 0 1 1 0 1 1 0 1 0 1
  1 0 0 1 0 0 1 1 0 1 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 0 1 1 0 0 1 1 0 0 0 1 0
  1 0 1 0 1 1 1 0 0 1 1 1 1 0 1 1 0 1 0 1 1 0 1 0 1 1 1 1 0 1 1 1 1 0 1 0 1
  0 1 1 1 1 0 1 1 0 1 1 0 1 1 0 1 0 1 1 1 0 1 1 1 0 1 0 1 0 0 1 0 1 1 0 1 1
  0 1 1 0 1 1 1 0 1 1 1 1 0 1 0 0 1 1 0 1 1 1 0 0 0 1 1 0 1 1 1 1 0 1 1 0 1
  1 1 0 0 1 0 0 0 1 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 1 1 1 1 1 1 1 0 0 0 1
  1 1 1 0]]
[[1 1 1 1 0 1 0 1 1 0 1 1 1 0 0 0 0 1 0 1 0 0 1 0 1 0 1 1 1 1 1 0 0 0 0 1 0
  1 1 0 0 1 1 1 1 1 0 1 1 1 0 1 0 1 1 0 1 0 1 0 1 1 1 1 1 1 1 1 1 0 1 0 1 1
  1 1 1 0 1 0 0 1 0 0 0 1 1 0 1 1 0 0 0 1 1 0 1 1 0 0]]
&lt;/pre&gt;&lt;/div&gt;


&lt;div class=&quot;codehilite&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;title&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;Model with large random initialization&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;axes&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;gca&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;axes&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;set_xlim&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;1.5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;1.5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;axes&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;set_ylim&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;1.5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;1.5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;plot_decision_boundary&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;lambda&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;predict_dec&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;parameters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;T&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;train_X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;train_Y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;img alt=&quot;png&quot; src=&quot;https://raw.githubusercontent.com/karenyyy/Coursera_and_Udemy/master/deeplearningai_coursera/Improving%20Deep%20Neural%20Networks%3A%20Hyperparameter%20tuning%2C%20Regularization%20and%20Optimization%20Home/images/week1/output_25_0.png&quot; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Observations&lt;/strong&gt;:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;The cost starts very high. This is because with large random-valued weights, the last activation (sigmoid) outputs results that are very close to 0 or 1 for some examples, and when it gets that example wrong it incurs a very high loss for that example. Indeed, when $\log(a^{[3]}) = \log(0)$, the loss goes to infinity.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Poor initialization can lead to vanishing/exploding gradients, which also slows down the optimization algorithm. &lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;If you train this network longer you will see better results, but initializing with overly large random numbers slows down the optimization.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;In summary&lt;/strong&gt;:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Initializing weights to very large random values does not work well. &lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Hopefully intializing with small random values does better. The important question is: how small should be these random values be? Lets find out in the next part! &lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;4-he-initialization&quot;&gt;4 - He initialization&lt;/h2&gt;
&lt;p&gt;Finally, try &quot;He Initialization&quot;; this is named for the first author of He et al., 2015. (If you have heard of &quot;Xavier initialization&quot;, this is similar except Xavier initialization uses a scaling factor for the weights $W^{[l]}$ of &lt;code&gt;sqrt(1./layers_dims[l-1])&lt;/code&gt; where He initialization would use &lt;code&gt;sqrt(2./layers_dims[l-1])&lt;/code&gt;.)&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Exercise&lt;/strong&gt;: Implement the following function to initialize your parameters with He initialization.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Hint&lt;/strong&gt;: This function is similar to the previous &lt;code&gt;initialize_parameters_random(...)&lt;/code&gt;. The only difference is that instead of multiplying &lt;code&gt;np.random.randn(..,..)&lt;/code&gt; by 10, you will multiply it by $\sqrt{\frac{2}{\text{dimension of the previous layer}}}$, which is what He initialization recommends for layers with a ReLU activation. &lt;/p&gt;
&lt;div class=&quot;codehilite&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;c1&quot;&gt;# GRADED FUNCTION: initialize_parameters_he&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;initialize_parameters_he&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;layers_dims&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;sd&quot;&gt;&amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    Arguments:&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    layer_dims -- python array (list) containing the size of each layer.&lt;/span&gt;

&lt;span class=&quot;sd&quot;&gt;    Returns:&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    parameters -- python dictionary containing your parameters &amp;quot;W1&amp;quot;, &amp;quot;b1&amp;quot;, ..., &amp;quot;WL&amp;quot;, &amp;quot;bL&amp;quot;:&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;                    W1 -- weight matrix of shape (layers_dims[1], layers_dims[0])&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;                    b1 -- bias vector of shape (layers_dims[1], 1)&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;                    ...&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;                    WL -- weight matrix of shape (layers_dims[L], layers_dims[L-1])&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;                    bL -- bias vector of shape (layers_dims[L], 1)&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    &amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;

    &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;random&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;seed&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;parameters&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{}&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;L&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;layers_dims&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;# integer representing the number of layers&lt;/span&gt;

    &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;l&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;L&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;

        &lt;span class=&quot;n&quot;&gt;parameters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;W&amp;#39;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;l&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;random&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;randn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;layers_dims&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;l&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;layers_dims&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;l&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sqrt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;2.&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;layers_dims&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;l&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;parameters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;b&amp;#39;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;l&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;zeros&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;((&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;layers_dims&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;l&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;


    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;parameters&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div class=&quot;codehilite&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;parameters&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;initialize_parameters_he&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;W1 = &amp;quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;parameters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;W1&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]))&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;b1 = &amp;quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;parameters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;b1&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]))&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;W2 = &amp;quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;parameters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;W2&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]))&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;b2 = &amp;quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;parameters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;b2&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]))&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div class=&quot;codehilite&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;W1 = [[ 1.78862847  0.43650985]
 [ 0.09649747 -1.8634927 ]
 [-0.2773882  -0.35475898]
 [-0.08274148 -0.62700068]]
b1 = [[ 0.]
 [ 0.]
 [ 0.]
 [ 0.]]
W2 = [[-0.03098412 -0.33744411 -0.92904268  0.62552248]]
b2 = [[ 0.]]
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;strong&gt;Expected Output&lt;/strong&gt;:&lt;/p&gt;
&lt;table&gt; 
    &lt;tr&gt;
    &lt;td&gt;
    **W1**
    &lt;/td&gt;
        &lt;td&gt;
    [[ 1.78862847  0.43650985]
 [ 0.09649747 -1.8634927 ]
 [-0.2773882  -0.35475898]
 [-0.08274148 -0.62700068]]
    &lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
    &lt;td&gt;
    **b1**
    &lt;/td&gt;
        &lt;td&gt;
    [[ 0.]
 [ 0.]
 [ 0.]
 [ 0.]]
    &lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
    &lt;td&gt;
    **W2**
    &lt;/td&gt;
        &lt;td&gt;
    [[-0.03098412 -0.33744411 -0.92904268  0.62552248]]
    &lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
    &lt;td&gt;
    **b2**
    &lt;/td&gt;
        &lt;td&gt;
    [[ 0.]]
    &lt;/td&gt;
    &lt;/tr&gt;

&lt;/table&gt;

&lt;p&gt;Run the following code to train your model on 15,000 iterations using He initialization.&lt;/p&gt;
&lt;div class=&quot;codehilite&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;parameters&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;train_X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;train_Y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;initialization&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&amp;quot;he&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;On the train set:&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;predictions_train&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;predict&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;train_X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;train_Y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;parameters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;On the test set:&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;predictions_test&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;predict&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;test_X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;test_Y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;parameters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div class=&quot;codehilite&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;Cost after iteration 0: 0.8830537463419761
Cost after iteration 1000: 0.6879825919728063
Cost after iteration 2000: 0.6751286264523371
Cost after iteration 3000: 0.6526117768893807
Cost after iteration 4000: 0.6082958970572938
Cost after iteration 5000: 0.5304944491717495
Cost after iteration 6000: 0.4138645817071794
Cost after iteration 7000: 0.3117803464844441
Cost after iteration 8000: 0.23696215330322562
Cost after iteration 9000: 0.18597287209206836
Cost after iteration 10000: 0.1501555628037182
Cost after iteration 11000: 0.12325079292273548
Cost after iteration 12000: 0.09917746546525937
Cost after iteration 13000: 0.0845705595402428
Cost after iteration 14000: 0.07357895962677366
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;img alt=&quot;png&quot; src=&quot;https://raw.githubusercontent.com/karenyyy/Coursera_and_Udemy/master/deeplearningai_coursera/Improving%20Deep%20Neural%20Networks%3A%20Hyperparameter%20tuning%2C%20Regularization%20and%20Optimization%20Home/images/week1/output_32_1.png&quot; /&gt;&lt;/p&gt;
&lt;div class=&quot;codehilite&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;On the train set:
Accuracy: 0.993333333333
On the test set:
Accuracy: 0.96
&lt;/pre&gt;&lt;/div&gt;


&lt;div class=&quot;codehilite&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;title&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;Model with He initialization&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;axes&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;gca&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;axes&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;set_xlim&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;1.5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;1.5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;axes&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;set_ylim&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;1.5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;1.5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;plot_decision_boundary&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;lambda&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;predict_dec&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;parameters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;T&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;train_X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;train_Y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;img alt=&quot;png&quot; src=&quot;https://raw.githubusercontent.com/karenyyy/Coursera_and_Udemy/master/deeplearningai_coursera/Improving%20Deep%20Neural%20Networks%3A%20Hyperparameter%20tuning%2C%20Regularization%20and%20Optimization%20Home/images/week1/output_33_0.png&quot; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Observations&lt;/strong&gt;:
- The model with He initialization separates the blue and the red dots very well in a small number of iterations.&lt;/p&gt;
&lt;h2 id=&quot;5-conclusions&quot;&gt;5 - Conclusions&lt;/h2&gt;
&lt;p&gt;You have seen three different types of initializations. For the same number of iterations and same hyperparameters the comparison is:&lt;/p&gt;
&lt;table&gt; 
    &lt;tr&gt;
        &lt;td&gt;
        **Model**
        &lt;/td&gt;
        &lt;td&gt;
        **Train accuracy**
        &lt;/td&gt;
        &lt;td&gt;
        **Problem/Comment**
        &lt;/td&gt;

    &lt;/tr&gt;
        &lt;td&gt;
        3-layer NN with zeros initialization
        &lt;/td&gt;
        &lt;td&gt;
        50%
        &lt;/td&gt;
        &lt;td&gt;
        fails to break symmetry
        &lt;/td&gt;
    &lt;tr&gt;
        &lt;td&gt;
        3-layer NN with large random initialization
        &lt;/td&gt;
        &lt;td&gt;
        83%
        &lt;/td&gt;
        &lt;td&gt;
        too large weights 
        &lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
        &lt;td&gt;
        3-layer NN with He initialization
        &lt;/td&gt;
        &lt;td&gt;
        99%
        &lt;/td&gt;
        &lt;td&gt;
        recommended method
        &lt;/td&gt;
    &lt;/tr&gt;
&lt;/table&gt;

&lt;p&gt;&lt;strong&gt;What you should remember from this notebook&lt;/strong&gt;:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Different initializations lead to different results&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Random initialization is used to break symmetry and make sure different hidden units can learn different things&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Don&#39;t intialize to values that are too large&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;He initialization works well for networks with ReLU activations.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;deeplearning.ai - Neural Networks and Deep Learning - Week 4 Assignment 2
&lt;h1 id=&quot;deep-neural-network-for-image-classification-application&quot;&gt;Deep Neural Network for Image Classification: Application&lt;/h1&gt;
&lt;p&gt;When you finish this, you will have finished the last programming assignment of Week 4, and also the last programming assignment of this course! &lt;/p&gt;
&lt;p&gt;You will use use the functions you&#39;d implemented in the previous assignment to build a deep network, and apply it to cat vs non-cat classification. Hopefully, you will see an improvement in accuracy relative to your previous logistic regression implementation.  &lt;/p&gt;
&lt;p&gt;&lt;strong&gt;After this assignment you will be able to:&lt;/strong&gt;
- Build and apply a deep neural network to supervised learning. &lt;/p&gt;
&lt;p&gt;Let&#39;s get started!&lt;/p&gt;
&lt;h2 id=&quot;1-packages&quot;&gt;1 - Packages&lt;/h2&gt;
&lt;p&gt;Let&#39;s first import all the packages that you will need during this assignment. 
- &lt;a href=&quot;www.numpy.org&quot;&gt;numpy&lt;/a&gt; is the fundamental package for scientific computing with Python.
- &lt;a href=&quot;http://matplotlib.org&quot;&gt;matplotlib&lt;/a&gt; is a library to plot graphs in Python.
- &lt;a href=&quot;http://www.h5py.org&quot;&gt;h5py&lt;/a&gt; is a common package to interact with a dataset that is stored on an H5 file.
- &lt;a href=&quot;http://www.pythonware.com/products/pil/&quot;&gt;PIL&lt;/a&gt; and &lt;a href=&quot;https://www.scipy.org/&quot;&gt;scipy&lt;/a&gt; are used here to test your model with your own picture at the end.
- dnn_app_utils provides the functions implemented in the &quot;Building your Deep Neural Network: Step by Step&quot; assignment to this notebook.
- np.random.seed(1) is used to keep all the random function calls consistent. It will help us grade your work.&lt;/p&gt;
&lt;div class=&quot;codehilite&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;time&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;numpy&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;np&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;h5py&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;matplotlib.pyplot&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;plt&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;scipy&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;PIL&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Image&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;scipy&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ndimage&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;dnn_app_utils_v3&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;

&lt;span class=&quot;o&quot;&gt;%&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;matplotlib&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;inline&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;rcParams&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;figure.figsize&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;5.0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;4.0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;# set default size of plots&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;rcParams&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;image.interpolation&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&amp;#39;nearest&amp;#39;&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;rcParams&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;image.cmap&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&amp;#39;gray&amp;#39;&lt;/span&gt;

&lt;span class=&quot;o&quot;&gt;%&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;load_ext&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;autoreload&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;%&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;autoreload&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;random&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;seed&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div class=&quot;codehilite&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;/opt/conda/lib/python3.5/site-packages/matplotlib/font_manager.py:273: UserWarning: Matplotlib is building the font cache using fc-list. This may take a moment.
  warnings.warn(&amp;#39;Matplotlib is building the font cache using fc-list. This may take a moment.&amp;#39;)
/opt/conda/lib/python3.5/site-packages/matplotlib/font_manager.py:273: UserWarning: Matplotlib is building the font cache using fc-list. This may take a moment.
  warnings.warn(&amp;#39;Matplotlib is building the font cache using fc-list. This may take a moment.&amp;#39;)
&lt;/pre&gt;&lt;/div&gt;


&lt;h2 id=&quot;2-dataset&quot;&gt;2 - Dataset&lt;/h2&gt;
&lt;p&gt;You will use the same &quot;Cat vs non-Cat&quot; dataset as in &quot;Logistic Regression as a Neural Network&quot; (Assignment 2). The model you had built had 70% test accuracy on classifying cats vs non-cats images. Hopefully, your new model will perform a better!&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Problem Statement&lt;/strong&gt;: You are given a dataset (&quot;data.h5&quot;) containing:
    - a training set of m_train images labelled as cat (1) or non-cat (0)
    - a test set of m_test images labelled as cat and non-cat
    - each image is of shape (num_px, num_px, 3) where 3 is for the 3 channels (RGB).&lt;/p&gt;
&lt;p&gt;Let&#39;s get more familiar with the dataset. Load the data by running the cell below.&lt;/p&gt;
&lt;div class=&quot;codehilite&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;train_x_orig&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;train_y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;test_x_orig&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;test_y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;classes&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;load_data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;The following code will show you an image in the dataset. Feel free to change the index and re-run the cell multiple times to see other images. &lt;/p&gt;
&lt;div class=&quot;codehilite&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;c1&quot;&gt;# Example of a picture&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;index&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;imshow&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;train_x_orig&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;index&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;y = &amp;quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;train_y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;index&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&amp;quot;. It&amp;#39;s a &amp;quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;classes&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;train_y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;index&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]]&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;decode&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;utf-8&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;  &lt;span class=&quot;s2&quot;&gt;&amp;quot; picture.&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div class=&quot;codehilite&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;y = 0. It&amp;#39;s a non-cat picture.
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;img alt=&quot;png&quot; src=&quot;https://raw.githubusercontent.com/karenyyy/Coursera_and_Udemy/master/deeplearningai_coursera/Neural_Networks_and_Deep_Learning/images/week4/output_7_1.png&quot; /&gt;&lt;/p&gt;
&lt;div class=&quot;codehilite&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;c1&quot;&gt;# Explore your dataset &lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;m_train&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;train_x_orig&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;num_px&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;train_x_orig&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;m_test&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;test_x_orig&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;Number of training examples: &amp;quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;m_train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;Number of testing examples: &amp;quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;m_test&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;Each image is of size: (&amp;quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;num_px&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&amp;quot;, &amp;quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;num_px&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&amp;quot;, 3)&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;train_x_orig shape: &amp;quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;train_x_orig&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;train_y shape: &amp;quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;train_y&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;test_x_orig shape: &amp;quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;test_x_orig&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;test_y shape: &amp;quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;test_y&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div class=&quot;codehilite&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;Number of training examples: 209
Number of testing examples: 50
Each image is of size: (64, 64, 3)
train_x_orig shape: (209, 64, 64, 3)
train_y shape: (1, 209)
test_x_orig shape: (50, 64, 64, 3)
test_y shape: (1, 50)
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;As usual, you reshape and standardize the images before feeding them to the network. The code is given in the cell below.&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/karenyyy/Coursera_and_Udemy/master/deeplearningai_coursera/Neural_Networks_and_Deep_Learning/images/imvectorkiank.png&quot; style=&quot;width:450px;height:300px;&quot;&gt;&lt;/p&gt;
&lt;p&gt;&lt;caption&gt;&lt;center&gt; &lt;u&gt;Figure 1&lt;/u&gt;: Image to vector conversion. &lt;br&gt; &lt;/center&gt;&lt;/caption&gt;&lt;/p&gt;
&lt;div class=&quot;codehilite&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;c1&quot;&gt;# Reshape the training and test examples &lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;train_x_flatten&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;train_x_orig&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;reshape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;train_x_orig&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;T&lt;/span&gt;   &lt;span class=&quot;c1&quot;&gt;# The &amp;quot;-1&amp;quot; makes reshape flatten the remaining dimensions&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;test_x_flatten&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;test_x_orig&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;reshape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;test_x_orig&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;T&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Standardize data to have feature values between 0 and 1.&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;train_x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;train_x_flatten&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;255.&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;test_x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;test_x_flatten&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;255.&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;train_x&amp;#39;s shape: &amp;quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;train_x&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;test_x&amp;#39;s shape: &amp;quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;test_x&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div class=&quot;codehilite&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;train_x&amp;#39;s shape: (12288, 209)
test_x&amp;#39;s shape: (12288, 50)
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;$12,288$ equals $64 \times 64 \times 3$ which is the size of one reshaped image vector.&lt;/p&gt;
&lt;h2 id=&quot;3-architecture-of-your-model&quot;&gt;3 - Architecture of your model&lt;/h2&gt;
&lt;p&gt;Now that you are familiar with the dataset, it is time to build a deep neural network to distinguish cat images from non-cat images.&lt;/p&gt;
&lt;p&gt;You will build two different models:
- A 2-layer neural network
- An L-layer deep neural network&lt;/p&gt;
&lt;p&gt;You will then compare the performance of these models, and also try out different values for $L$. &lt;/p&gt;
&lt;p&gt;Let&#39;s look at the two architectures.&lt;/p&gt;
&lt;h3 id=&quot;31-2-layer-neural-network&quot;&gt;3.1 - 2-layer neural network&lt;/h3&gt;
&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/karenyyy/Coursera_and_Udemy/master/deeplearningai_coursera/Neural_Networks_and_Deep_Learning/images/2layerNN_kiank.png&quot; style=&quot;width:650px;height:400px;&quot;&gt;
&lt;caption&gt;&lt;center&gt; &lt;u&gt;Figure 2&lt;/u&gt;: 2-layer neural network. &lt;br&gt; The model can be summarized as: &lt;strong&gt;&lt;em&gt;INPUT -&amp;gt; LINEAR -&amp;gt; RELU -&amp;gt; LINEAR -&amp;gt; SIGMOID -&amp;gt; OUTPUT&lt;/em&gt;&lt;/strong&gt;. &lt;/center&gt;&lt;/caption&gt;&lt;/p&gt;
&lt;p&gt;&lt;u&gt;Detailed Architecture of figure 2&lt;/u&gt;:
- The input is a (64,64,3) image which is flattened to a vector of size $(12288,1)$. 
- The corresponding vector: $[x_0,x_1,...,x_{12287}]^T$ is then multiplied by the weight matrix $W^{[1]}$ of size $(n^{[1]}, 12288)$.
- You then add a bias term and take its relu to get the following vector: $[a_0^{[1]}, a_1^{[1]},..., a_{n^{[1]}-1}^{[1]}]^T$.
- You then repeat the same process.
- You multiply the resulting vector by $W^{[2]}$ and add your intercept (bias). 
- Finally, you take the sigmoid of the result. If it is greater than 0.5, you classify it to be a cat.&lt;/p&gt;
&lt;h3 id=&quot;32-l-layer-deep-neural-network&quot;&gt;3.2 - L-layer deep neural network&lt;/h3&gt;
&lt;p&gt;It is hard to represent an L-layer deep neural network with the above representation. However, here is a simplified network representation:&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/karenyyy/Coursera_and_Udemy/master/deeplearningai_coursera/Neural_Networks_and_Deep_Learning/images/LlayerNN_kiank.png&quot; style=&quot;width:650px;height:400px;&quot;&gt;
&lt;caption&gt;&lt;center&gt; &lt;u&gt;Figure 3&lt;/u&gt;: L-layer neural network. &lt;br&gt; The model can be summarized as: &lt;strong&gt;&lt;em&gt;[LINEAR -&amp;gt; RELU] $\times$ (L-1) -&amp;gt; LINEAR -&amp;gt; SIGMOID&lt;/em&gt;&lt;/strong&gt;&lt;/center&gt;&lt;/caption&gt;&lt;/p&gt;
&lt;p&gt;&lt;u&gt;Detailed Architecture of figure 3&lt;/u&gt;:
- The input is a (64,64,3) image which is flattened to a vector of size (12288,1).
- The corresponding vector: $[x_0,x_1,...,x_{12287}]^T$ is then multiplied by the weight matrix $W^{[1]}$ and then you add the intercept $b^{[1]}$. The result is called the linear unit.
- Next, you take the relu of the linear unit. This process could be repeated several times for each $(W^{[l]}, b^{[l]})$ depending on the model architecture.
- Finally, you take the sigmoid of the final linear unit. If it is greater than 0.5, you classify it to be a cat.&lt;/p&gt;
&lt;h3 id=&quot;33-general-methodology&quot;&gt;3.3 - General methodology&lt;/h3&gt;
&lt;p&gt;As usual you will follow the Deep Learning methodology to build the model:
    1. Initialize parameters / Define hyperparameters
    2. Loop for num_iterations:
        a. Forward propagation
        b. Compute cost function
        c. Backward propagation
        d. Update parameters (using parameters, and grads from backprop) 
    4. Use trained parameters to predict labels&lt;/p&gt;
&lt;p&gt;Let&#39;s now implement those two models!&lt;/p&gt;
&lt;h2 id=&quot;4-two-layer-neural-network&quot;&gt;4 - Two-layer neural network&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;Question&lt;/strong&gt;:  Use the helper functions you have implemented in the previous assignment to build a 2-layer neural network with the following structure: &lt;em&gt;LINEAR -&amp;gt; RELU -&amp;gt; LINEAR -&amp;gt; SIGMOID&lt;/em&gt;. The functions you may need and their inputs are:&lt;/p&gt;
&lt;div class=&quot;codehilite&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;initialize_parameters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n_x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n_h&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n_y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;o&quot;&gt;...&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;parameters&lt;/span&gt; 
&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;linear_activation_forward&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;A_prev&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;W&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;b&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;activation&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;o&quot;&gt;...&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;A&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cache&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;compute_cost&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;AL&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;o&quot;&gt;...&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cost&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;linear_activation_backward&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dA&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cache&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;activation&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;o&quot;&gt;...&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dA_prev&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dW&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;db&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;update_parameters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;parameters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;grads&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;learning_rate&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;o&quot;&gt;...&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;parameters&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div class=&quot;codehilite&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;c1&quot;&gt;### CONSTANTS DEFINING THE MODEL ####&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;n_x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;12288&lt;/span&gt;     &lt;span class=&quot;c1&quot;&gt;# num_px * num_px * 3&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;n_h&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;7&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;n_y&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;layers_dims&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n_x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n_h&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n_y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div class=&quot;codehilite&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;c1&quot;&gt;# GRADED FUNCTION: two_layer_model&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;two_layer_model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;layers_dims&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;learning_rate&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.0075&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;num_iterations&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;3000&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;print_cost&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;False&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;sd&quot;&gt;&amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    Implements a two-layer neural network: LINEAR-&amp;gt;RELU-&amp;gt;LINEAR-&amp;gt;SIGMOID.&lt;/span&gt;

&lt;span class=&quot;sd&quot;&gt;    Arguments:&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    X -- input data, of shape (n_x, number of examples)&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    Y -- true &amp;quot;label&amp;quot; vector (containing 0 if cat, 1 if non-cat), of shape (1, number of examples)&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    layers_dims -- dimensions of the layers (n_x, n_h, n_y)&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    num_iterations -- number of iterations of the optimization loop&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    learning_rate -- learning rate of the gradient descent update rule&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    print_cost -- If set to True, this will print the cost every 100 iterations &lt;/span&gt;

&lt;span class=&quot;sd&quot;&gt;    Returns:&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    parameters -- a dictionary containing W1, W2, b1, and b2&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    &amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;

    &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;random&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;seed&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;grads&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{}&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;costs&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[]&lt;/span&gt;                              &lt;span class=&quot;c1&quot;&gt;# to keep track of the cost&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;m&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;                           &lt;span class=&quot;c1&quot;&gt;# number of examples&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n_x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n_h&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n_y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;layers_dims&lt;/span&gt;

    &lt;span class=&quot;c1&quot;&gt;# Initialize parameters dictionary, by calling one of the functions you&amp;#39;d previously implemented&lt;/span&gt;

    &lt;span class=&quot;n&quot;&gt;parameters&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;initialize_parameters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n_x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n_h&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n_y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;


    &lt;span class=&quot;c1&quot;&gt;# Get W1, b1, W2 and b2 from the dictionary parameters.&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;W1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;parameters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;W1&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;b1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;parameters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;b1&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;W2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;parameters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;W2&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;b2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;parameters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;b2&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;

    &lt;span class=&quot;c1&quot;&gt;# Loop (gradient descent)&lt;/span&gt;

    &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;num_iterations&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;

        &lt;span class=&quot;c1&quot;&gt;# Forward propagation: LINEAR -&amp;gt; RELU -&amp;gt; LINEAR -&amp;gt; SIGMOID. Inputs: &amp;quot;X, W1, b1, W2, b2&amp;quot;. Output: &amp;quot;A1, cache1, A2, cache2&amp;quot;.&lt;/span&gt;

        &lt;span class=&quot;n&quot;&gt;A1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cache1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;linear_activation_forward&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;W1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;b1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&amp;quot;relu&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;A2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cache2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;linear_activation_forward&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;A1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;W2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;b2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&amp;quot;sigmoid&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;


        &lt;span class=&quot;c1&quot;&gt;# Compute cost&lt;/span&gt;

        &lt;span class=&quot;n&quot;&gt;cost&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;compute_cost&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;A2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;


        &lt;span class=&quot;c1&quot;&gt;# Initializing backward propagation&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;dA2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;divide&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;A2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;divide&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;A2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;

        &lt;span class=&quot;c1&quot;&gt;# Backward propagation. Inputs: &amp;quot;dA2, cache2, cache1&amp;quot;. Outputs: &amp;quot;dA1, dW2, db2; also dA0 (not used), dW1, db1&amp;quot;.&lt;/span&gt;

        &lt;span class=&quot;n&quot;&gt;dA1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dW2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;db2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;linear_activation_backward&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dA2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cache2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&amp;quot;sigmoid&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;dA0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dW1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;db1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;linear_activation_backward&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dA1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cache1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&amp;quot;relu&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;


        &lt;span class=&quot;c1&quot;&gt;# Set grads[&amp;#39;dWl&amp;#39;] to dW1, grads[&amp;#39;db1&amp;#39;] to db1, grads[&amp;#39;dW2&amp;#39;] to dW2, grads[&amp;#39;db2&amp;#39;] to db2&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;grads&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;dW1&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dW1&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;grads&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;db1&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;db1&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;grads&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;dW2&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dW2&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;grads&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;db2&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;db2&lt;/span&gt;

        &lt;span class=&quot;c1&quot;&gt;# Update parameters.&lt;/span&gt;

        &lt;span class=&quot;n&quot;&gt;parameters&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;update_parameters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;parameters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;grads&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;learning_rate&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;


        &lt;span class=&quot;c1&quot;&gt;# Retrieve W1, b1, W2, b2 from parameters&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;W1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;parameters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;W1&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;b1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;parameters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;b1&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;W2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;parameters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;W2&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;b2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;parameters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;b2&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;

        &lt;span class=&quot;c1&quot;&gt;# Print the cost every 100 training example&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;print_cost&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;and&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;%&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;100&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;Cost after iteration {}: {}&amp;quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;format&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;squeeze&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cost&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)))&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;print_cost&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;and&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;%&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;100&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;costs&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;append&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cost&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

    &lt;span class=&quot;c1&quot;&gt;# plot the cost&lt;/span&gt;

    &lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;plot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;squeeze&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;costs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ylabel&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;cost&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;xlabel&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;iterations (per tens)&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;title&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;Learning rate =&amp;quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;learning_rate&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;show&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;

    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;parameters&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Run the cell below to train your parameters. See if your model runs. The cost should be decreasing. It may take up to 5 minutes to run 2500 iterations. Check if the &quot;Cost after iteration 0&quot; matches the expected output below, if not click on the square (⬛) on the upper bar of the notebook to stop the cell and try to find your error.&lt;/p&gt;
&lt;div class=&quot;codehilite&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;parameters&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;two_layer_model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;train_x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;train_y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;layers_dims&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n_x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n_h&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n_y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;num_iterations&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2500&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;print_cost&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div class=&quot;codehilite&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;Cost after iteration 0: 0.693049735659989
Cost after iteration 100: 0.6464320953428849
Cost after iteration 200: 0.6325140647912678
Cost after iteration 300: 0.6015024920354665
Cost after iteration 400: 0.5601966311605748
Cost after iteration 500: 0.515830477276473
Cost after iteration 600: 0.4754901313943325
Cost after iteration 700: 0.43391631512257495
Cost after iteration 800: 0.4007977536203886
Cost after iteration 900: 0.35807050113237987
Cost after iteration 1000: 0.3394281538366413
Cost after iteration 1100: 0.30527536361962654
Cost after iteration 1200: 0.2749137728213015
Cost after iteration 1300: 0.24681768210614827
Cost after iteration 1400: 0.1985073503746611
Cost after iteration 1500: 0.17448318112556593
Cost after iteration 1600: 0.1708076297809661
Cost after iteration 1700: 0.11306524562164737
Cost after iteration 1800: 0.09629426845937163
Cost after iteration 1900: 0.08342617959726878
Cost after iteration 2000: 0.0743907870431909
Cost after iteration 2100: 0.06630748132267938
Cost after iteration 2200: 0.05919329501038176
Cost after iteration 2300: 0.05336140348560564
Cost after iteration 2400: 0.048554785628770226
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;img alt=&quot;png&quot; src=&quot;https://raw.githubusercontent.com/karenyyy/Coursera_and_Udemy/master/deeplearningai_coursera/Neural_Networks_and_Deep_Learning/images/week4/output_18_1.png&quot; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Expected Output&lt;/strong&gt;:
&lt;table&gt; 
    &lt;tr&gt;
        &lt;td&gt; &lt;strong&gt;Cost after iteration 0&lt;/strong&gt;&lt;/td&gt;
        &lt;td&gt; 0.6930497356599888 &lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
        &lt;td&gt; &lt;strong&gt;Cost after iteration 100&lt;/strong&gt;&lt;/td&gt;
        &lt;td&gt; 0.6464320953428849 &lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
        &lt;td&gt; &lt;strong&gt;...&lt;/strong&gt;&lt;/td&gt;
        &lt;td&gt; ... &lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
        &lt;td&gt; &lt;strong&gt;Cost after iteration 2400&lt;/strong&gt;&lt;/td&gt;
        &lt;td&gt; 0.048554785628770206 &lt;/td&gt;
    &lt;/tr&gt;
&lt;/table&gt;&lt;/p&gt;
&lt;p&gt;Good thing you built a vectorized implementation! Otherwise it might have taken 10 times longer to train this.&lt;/p&gt;
&lt;p&gt;Now, you can use the trained parameters to classify images from the dataset. To see your predictions on the training and test sets, run the cell below.&lt;/p&gt;
&lt;div class=&quot;codehilite&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;predictions_train&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;predict&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;train_x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;train_y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;parameters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div class=&quot;codehilite&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Accuracy&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;1.0&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;strong&gt;Expected Output&lt;/strong&gt;:
&lt;table&gt; 
    &lt;tr&gt;
        &lt;td&gt; &lt;strong&gt;Accuracy&lt;/strong&gt;&lt;/td&gt;
        &lt;td&gt; 1.0 &lt;/td&gt;
    &lt;/tr&gt;
&lt;/table&gt;&lt;/p&gt;
&lt;div class=&quot;codehilite&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;predictions_test&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;predict&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;test_x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;test_y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;parameters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div class=&quot;codehilite&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Accuracy&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.72&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;strong&gt;Expected Output&lt;/strong&gt;:&lt;/p&gt;
&lt;table&gt; 
    &lt;tr&gt;
        &lt;td&gt; **Accuracy**&lt;/td&gt;
        &lt;td&gt; 0.72 &lt;/td&gt;
    &lt;/tr&gt;
&lt;/table&gt;

&lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt;: You may notice that running the model on fewer iterations (say 1500) gives better accuracy on the test set. This is called &quot;early stopping&quot; and we will talk about it in the next course. Early stopping is a way to prevent overfitting. &lt;/p&gt;
&lt;p&gt;Congratulations! It seems that your 2-layer neural network has better performance (72%) than the logistic regression implementation (70%, assignment week 2). Let&#39;s see if you can do even better with an $L$-layer model.&lt;/p&gt;
&lt;h2 id=&quot;5-l-layer-neural-network&quot;&gt;5 - L-layer Neural Network&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;Question&lt;/strong&gt;: Use the helper functions you have implemented previously to build an $L$-layer neural network with the following structure: &lt;em&gt;[LINEAR -&amp;gt; RELU]$\times$(L-1) -&amp;gt; LINEAR -&amp;gt; SIGMOID&lt;/em&gt;. The functions you may need and their inputs are:&lt;/p&gt;
&lt;div class=&quot;codehilite&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;initialize_parameters_deep&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;layers_dims&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;o&quot;&gt;...&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;parameters&lt;/span&gt; 
&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;L_model_forward&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;parameters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;o&quot;&gt;...&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;AL&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;caches&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;compute_cost&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;AL&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;o&quot;&gt;...&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cost&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;L_model_backward&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;AL&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;caches&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;o&quot;&gt;...&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;grads&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;update_parameters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;parameters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;grads&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;learning_rate&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;o&quot;&gt;...&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;parameters&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div class=&quot;codehilite&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;c1&quot;&gt;### CONSTANTS ###&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;layers_dims&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;12288&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;20&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;7&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;#  4-layer model&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div class=&quot;codehilite&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;c1&quot;&gt;# GRADED FUNCTION: L_layer_model&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;L_layer_model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;layers_dims&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;learning_rate&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.0075&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;num_iterations&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;3000&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;print_cost&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;False&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;&lt;span class=&quot;c1&quot;&gt;#lr was 0.009&lt;/span&gt;
    &lt;span class=&quot;sd&quot;&gt;&amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    Implements a L-layer neural network: [LINEAR-&amp;gt;RELU]*(L-1)-&amp;gt;LINEAR-&amp;gt;SIGMOID.&lt;/span&gt;

&lt;span class=&quot;sd&quot;&gt;    Arguments:&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    X -- data, numpy array of shape (number of examples, num_px * num_px * 3)&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    Y -- true &amp;quot;label&amp;quot; vector (containing 0 if cat, 1 if non-cat), of shape (1, number of examples)&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    layers_dims -- list containing the input size and each layer size, of length (number of layers + 1).&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    learning_rate -- learning rate of the gradient descent update rule&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    num_iterations -- number of iterations of the optimization loop&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    print_cost -- if True, it prints the cost every 100 steps&lt;/span&gt;

&lt;span class=&quot;sd&quot;&gt;    Returns:&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    parameters -- parameters learnt by the model. They can then be used to predict.&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    &amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;

    &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;random&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;seed&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;costs&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[]&lt;/span&gt;                         &lt;span class=&quot;c1&quot;&gt;# keep track of cost&lt;/span&gt;

    &lt;span class=&quot;c1&quot;&gt;# Parameters initialization. (≈ 1 line of code)&lt;/span&gt;

    &lt;span class=&quot;n&quot;&gt;parameters&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;initialize_parameters_deep&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;layers_dims&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;


    &lt;span class=&quot;c1&quot;&gt;# Loop (gradient descent)&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;num_iterations&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;

        &lt;span class=&quot;c1&quot;&gt;# Forward propagation: [LINEAR -&amp;gt; RELU]*(L-1) -&amp;gt; LINEAR -&amp;gt; SIGMOID.&lt;/span&gt;

        &lt;span class=&quot;n&quot;&gt;AL&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;caches&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;L_model_forward&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;parameters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;


        &lt;span class=&quot;c1&quot;&gt;# Compute cost.&lt;/span&gt;

        &lt;span class=&quot;n&quot;&gt;cost&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;compute_cost&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;AL&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;


        &lt;span class=&quot;c1&quot;&gt;# Backward propagation.&lt;/span&gt;

        &lt;span class=&quot;n&quot;&gt;grads&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;L_model_backward&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;AL&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;caches&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;


        &lt;span class=&quot;c1&quot;&gt;# Update parameters.&lt;/span&gt;

        &lt;span class=&quot;n&quot;&gt;parameters&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;update_parameters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;parameters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;grads&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;learning_rate&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;


        &lt;span class=&quot;c1&quot;&gt;# Print the cost every 100 training example&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;print_cost&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;and&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;%&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;100&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;print&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;Cost after iteration &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;%i&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;: &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;%f&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;%&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cost&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;print_cost&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;and&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;%&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;100&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;costs&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;append&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cost&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

    &lt;span class=&quot;c1&quot;&gt;# plot the cost&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;plot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;squeeze&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;costs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ylabel&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;cost&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;xlabel&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;iterations (per tens)&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;title&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;Learning rate =&amp;quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;learning_rate&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;show&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;

    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;parameters&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;You will now train the model as a 4-layer neural network. &lt;/p&gt;
&lt;p&gt;Run the cell below to train your model. The cost should decrease on every iteration. It may take up to 5 minutes to run 2500 iterations. Check if the &quot;Cost after iteration 0&quot; matches the expected output below, if not click on the square (⬛) on the upper bar of the notebook to stop the cell and try to find your error.&lt;/p&gt;
&lt;div class=&quot;codehilite&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;parameters&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;L_layer_model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;train_x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;train_y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;layers_dims&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;num_iterations&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2500&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;print_cost&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div class=&quot;codehilite&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;Cost after iteration 0: 0.771749
Cost after iteration 100: 0.672053
Cost after iteration 200: 0.648263
Cost after iteration 300: 0.611507
Cost after iteration 400: 0.567047
Cost after iteration 500: 0.540138
Cost after iteration 600: 0.527930
Cost after iteration 700: 0.465477
Cost after iteration 800: 0.369126
Cost after iteration 900: 0.391747
Cost after iteration 1000: 0.315187
Cost after iteration 1100: 0.272700
Cost after iteration 1200: 0.237419
Cost after iteration 1300: 0.199601
Cost after iteration 1400: 0.189263
Cost after iteration 1500: 0.161189
Cost after iteration 1600: 0.148214
Cost after iteration 1700: 0.137775
Cost after iteration 1800: 0.129740
Cost after iteration 1900: 0.121225
Cost after iteration 2000: 0.113821
Cost after iteration 2100: 0.107839
Cost after iteration 2200: 0.102855
Cost after iteration 2300: 0.100897
Cost after iteration 2400: 0.092878
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;img alt=&quot;png&quot; src=&quot;https://raw.githubusercontent.com/karenyyy/Coursera_and_Udemy/master/deeplearningai_coursera/Neural_Networks_and_Deep_Learning/images/week4/output_30_1.png&quot; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Expected Output&lt;/strong&gt;:
&lt;table&gt; 
    &lt;tr&gt;
        &lt;td&gt; &lt;strong&gt;Cost after iteration 0&lt;/strong&gt;&lt;/td&gt;
        &lt;td&gt; 0.771749 &lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
        &lt;td&gt; &lt;strong&gt;Cost after iteration 100&lt;/strong&gt;&lt;/td&gt;
        &lt;td&gt; 0.672053 &lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
        &lt;td&gt; &lt;strong&gt;...&lt;/strong&gt;&lt;/td&gt;
        &lt;td&gt; ... &lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
        &lt;td&gt; &lt;strong&gt;Cost after iteration 2400&lt;/strong&gt;&lt;/td&gt;
        &lt;td&gt; 0.092878 &lt;/td&gt;
    &lt;/tr&gt;
&lt;/table&gt;&lt;/p&gt;
&lt;div class=&quot;codehilite&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pred_train&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;predict&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;train_x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;train_y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;parameters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div class=&quot;codehilite&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Accuracy&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.985645933014&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;table&gt;
    &lt;tr&gt;
    &lt;td&gt;
    **Train Accuracy**
    &lt;/td&gt;
    &lt;td&gt;
    0.985645933014
    &lt;/td&gt;
    &lt;/tr&gt;
&lt;/table&gt;

&lt;div class=&quot;codehilite&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pred_test&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;predict&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;test_x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;test_y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;parameters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div class=&quot;codehilite&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Accuracy&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.8&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;strong&gt;Expected Output&lt;/strong&gt;:&lt;/p&gt;
&lt;table&gt; 
    &lt;tr&gt;
        &lt;td&gt; **Test Accuracy**&lt;/td&gt;
        &lt;td&gt; 0.8 &lt;/td&gt;
    &lt;/tr&gt;
&lt;/table&gt;

&lt;p&gt;Congrats! It seems that your 4-layer neural network has better performance (80%) than your 2-layer neural network (72%) on the same test set. &lt;/p&gt;
&lt;p&gt;This is good performance for this task. Nice job! &lt;/p&gt;
&lt;p&gt;Though in the next course on &quot;Improving deep neural networks&quot; you will learn how to obtain even higher accuracy by systematically searching for better hyperparameters (learning_rate, layers_dims, num_iterations, and others you&#39;ll also learn in the next course). &lt;/p&gt;
&lt;h2 id=&quot;6-results-analysis&quot;&gt;6) Results Analysis&lt;/h2&gt;
&lt;p&gt;First, let&#39;s take a look at some images the L-layer model labeled incorrectly. This will show a few mislabeled images. &lt;/p&gt;
&lt;div class=&quot;codehilite&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;print_mislabeled_images&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;classes&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;test_x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;test_y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pred_test&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;img alt=&quot;png&quot; src=&quot;https://raw.githubusercontent.com/karenyyy/Coursera_and_Udemy/master/deeplearningai_coursera/Neural_Networks_and_Deep_Learning/images/week4/output_38_0.png&quot; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;A few types of images the model tends to do poorly on include:&lt;/strong&gt; 
- Cat body in an unusual position
- Cat appears against a background of a similar color
- Unusual cat color and species
- Camera Angle
- Brightness of the picture
- Scale variation (cat is very large or small in image) &lt;/p&gt;
&lt;h2 id=&quot;7-test-with-your-own-image-optionalungraded-exercise&quot;&gt;7) Test with your own image (optional/ungraded exercise)&lt;/h2&gt;
&lt;p&gt;Congratulations on finishing this assignment. You can use your own image and see the output of your model. To do that:
    1. Click on &quot;File&quot; in the upper bar of this notebook, then click &quot;Open&quot; to go on your Coursera Hub.
    2. Add your image to this Jupyter Notebook&#39;s directory, in the &quot;images&quot; folder
    3. Change your image&#39;s name in the following code
    4. Run the code and check if the algorithm is right (1 = cat, 0 = non-cat)!&lt;/p&gt;
&lt;div class=&quot;codehilite&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;c1&quot;&gt;## START CODE HERE ##&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;skimage&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;io&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;my_image&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&amp;quot;https://dynaimage.cdn.cnn.com/cnn/q_auto,w_1024,c_fill,g_auto,h_576,ar_16:9/http%3A&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;%2F%2F&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;cdn.cnn.com&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;%2F&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;cnnnext&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;%2F&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;dam&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;%2F&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;assets&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;%2F&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;180316113418-travel-with-a-dog-3.jpg&amp;quot;&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;# change this to the name of your image file &lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;my_label_y&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;# the true class of your image (1 -&amp;gt; cat, 0 -&amp;gt; non-cat)&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;## END CODE HERE ##&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# fname = &amp;quot;images/&amp;quot; + my_image&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;image&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;array&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;io&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;imread&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;my_image&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;flatten&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;False&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;my_image&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;scipy&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;misc&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;imresize&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;image&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;size&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;num_px&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;num_px&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;reshape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;((&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;num_px&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;num_px&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;my_image&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;my_image&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;255.&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;my_predicted_image&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;predict&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;my_image&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;my_label_y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;parameters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;imshow&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;image&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;y = &amp;quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;squeeze&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;my_predicted_image&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&amp;quot;, your L-layer model predicts a &lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\&amp;quot;&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;classes&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;int&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;squeeze&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;my_predicted_image&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)),]&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;decode&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;utf-8&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;  &lt;span class=&quot;s2&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\&amp;quot;&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt; picture.&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div class=&quot;codehilite&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Accuracy&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.0&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;y&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.0&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;your&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;L&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;layer&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;model&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;predicts&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;a&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&amp;quot;non-cat&amp;quot;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;picture&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;img alt=&quot;png&quot; src=&quot;https://raw.githubusercontent.com/karenyyy/Coursera_and_Udemy/master/deeplearningai_coursera/Neural_Networks_and_Deep_Learning/images/week4/output_41_1.png&quot; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;References&lt;/strong&gt;:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;for auto-reloading external module: http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython&lt;/li&gt;
&lt;/ul&gt;tensorflow notes - optimizers
&lt;h1 id=&quot;optimizers&quot;&gt;Optimizers&lt;/h1&gt;
&lt;h2 id=&quot;basic-gradient-descent&quot;&gt;Basic Gradient Descent&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;minimize an objective function by updating the parameters in the opposite direction of the gradient of the objective function**. &lt;/li&gt;
&lt;li&gt;&lt;strong&gt;The learning rate determines the size of the steps to reach a (local) minimum.&lt;/strong&gt; In other words, we follow &lt;strong&gt;the direction of the slope&lt;/strong&gt; of the surface created by the objective function downhill until we reach a valley.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/karenyyy/data_science/master/TF_cv/images/grad.png&quot; width=&quot;600&quot;&gt;&lt;/p&gt;
&lt;p&gt;TensorFlow train module &lt;strong&gt;&lt;code&gt;tf.train&lt;/code&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;div class=&quot;codehilite&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;tf.train.GradientDescentOptimizer
tf.train.MomentumOptimizer
tf.train.RMSPropOptimizer
tf.train.AdadeltaOptimizer
tf.train.AdagradOptimizer
tf.train.AdamOptimizer
tf.train.AdagradDAOptimizer
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;TF-Keras optimizer module &lt;strong&gt;&lt;code&gt;tf.contrib.keras.optimizers&lt;/code&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;div class=&quot;codehilite&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;tf_keras.optimizers.SGD
tf_keras.optimizers.Adadelta
tf_keras.optimizers.Adagrad
tf_keras.optimizers.RMSprop
tf_keras.optimizers.Adamax
tf_keras.optimizers.Nadam
tf_keras.optimizers.Optimizer
&lt;/pre&gt;&lt;/div&gt;


&lt;h2 id=&quot;gradient-descent-variants&quot;&gt;Gradient Descent Variants&lt;/h2&gt;
&lt;p&gt;$$\theta = \theta - \eta \cdot \nabla_\theta J( \theta; x; y)$$&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Batch gradient descent&lt;/strong&gt;&lt;ul&gt;
&lt;li&gt;computes the gradient of the cost function to the parameters θ for the entire training dataset.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Stochastic gradient descent&lt;/strong&gt;&lt;ul&gt;
&lt;li&gt;computes a parameter update for each training example x and label y&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Mini-batch gradient descent&lt;/strong&gt;&lt;ul&gt;
&lt;li&gt;computes an update for every mini-batch of nn training examples&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Mini-batch gradient descent is typically the algorithm of choice&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;updates have lower variances than  stochastic gradient descent, the model converges better.&lt;/li&gt;
&lt;li&gt;the dataset doesn&#39;t need to fit in memory like for batch gradient descent&lt;/li&gt;
&lt;li&gt;gradient computation step is faster, because&lt;ul&gt;
&lt;li&gt;the batch is smaller&lt;/li&gt;
&lt;li&gt;make use of highly optimized matrix multiplication operation common to state-of-the-art deep learning libraries.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Short Comings of Mini-Batch Gradient Descent&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/karenyyy/data_science/master/TF_cv/images/learning_rates.jpg&quot; width=&quot;400&quot;&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Learning rate magnitude&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;learning rate too large:&lt;ul&gt;
&lt;li&gt;loss function fluctuates around the minimum preventing convergence&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;learning rate too small: &lt;ul&gt;
&lt;li&gt;training takes too long to reach convergence&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Challenge of minimizing highly non-convex error functions&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;escaping suboptimal local minima or saddle points (gradients close to zero in most dimensions) can be difficult&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&quot;codehilite&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;c1&quot;&gt;# model Mini-Batch gradient descent optimizer&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;# Tensorflow optimizer&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;optimizer&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;train&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;GradientDescentOptimizer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;learning_rate&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;learning_rate&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# TF-Keras optimzer&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;optimizer&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tf_keras&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;optimizers&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;SGD&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;lr&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;learning_rate&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;h2 id=&quot;momentum-optimizer&quot;&gt;Momentum Optimizer&lt;/h2&gt;
&lt;p&gt;&lt;b&gt;SGD tends to oscillate when the loss surface curves much more steeply in one dimension than in another, which are common around local optima.&lt;/b&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/karenyyy/data_science/master/TF_cv/images/momentum.png&quot; width=&quot;600&quot;&gt;&lt;/p&gt;
&lt;p&gt;Momentum : almost always enjoys better converge rates on deep networks. 
- In a sense the Momentum optimizer gives potential energy to the update step. 
    - allows the parameter vector to build up velocity in any direction that has &lt;strong&gt;consistent gradient&lt;/strong&gt;. Eg: pushing a ball down a hill. The ball accumulates momentum as it rolls downhill, becoming faster and faster on the way.
- As a result, we gain faster convergence and reduced oscillation.&lt;/p&gt;
&lt;p&gt;Update step:&lt;/p&gt;
&lt;p&gt;$$v_t = \gamma v_{t-1} + \eta \nabla_\theta J( \theta)$$
$$\theta = \theta - v_t$$&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;The momentum term (friction term) gamma is usually set to 0.9 or a similar value.&lt;/strong&gt;&lt;/p&gt;
&lt;div class=&quot;codehilite&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;c1&quot;&gt;# Momentum Optimizers&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Tensorflow optimizer&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;optimizer&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;train&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;MomentumOptimizer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;learning_rate&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;learning_rate&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;momentum&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;momentum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# TF-Keras optimizer&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;optimizer&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tf_keras&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;optimizers&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;SGD&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;lr&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;learning_rate&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;momentum&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;momentum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;h2 id=&quot;nesterov-accelerated-gradient-nag-optimizer&quot;&gt;Nesterov Accelerated Gradient (NAG) Optimizer&lt;/h2&gt;
&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/karenyyy/data_science/master/TF_cv/images/nesterov.jpeg&quot; width=&quot;800&quot;&gt;&lt;/p&gt;
&lt;p&gt;Instead of evaluating gradient at the current position (red circle), we know that &lt;em&gt;our momentum is about to carry us to the tip of the green arrow&lt;/em&gt;. &lt;strong&gt;With Nesterov momentum we therefore instead evaluate the gradient at this &quot;looked-ahead&quot; position.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;$$v_t = \gamma v_{t-1} + \eta \nabla_\theta J( \theta - \gamma v_{t-1} )$$
$$\theta = \theta - v_t$$&lt;/p&gt;
&lt;h3 id=&quot;this-anticipatory-update-prevents-us-from-going-too-fast-overshooting-which-has-significantly-increased-the-performance-of-rnns-on-a-number-of-tasks&quot;&gt;This anticipatory update prevents us from going too fast (overshooting), which has significantly increased the performance of RNNs on a number of tasks.&lt;/h3&gt;
&lt;div class=&quot;codehilite&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;c1&quot;&gt;# Nesterov Optimizers&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Tensorflow optimizer&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;optimizer&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;train&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;MomentumOptimizer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;learning_rate&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;learning_rate&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;momentum&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;momentum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;use_nesterov&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# TF-Keras optimizer&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;optimizer&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tf_keras&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;optimizers&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;SGD&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;lr&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;learning_rate&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;momentum&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;momentum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nesterov&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;h2 id=&quot;adagrad-optimizer&quot;&gt;Adagrad Optimizer&lt;/h2&gt;
&lt;p&gt;In Adagrad the &lt;strong&gt;learning rate is normalized by the sum of squared gradients on a per-parameter basis.&lt;/strong&gt; 
   - well-suited for dealing with sparse data:
       - larger updates for infrequent parameters
       - smaller updates for frequent parameters&lt;/p&gt;
&lt;div class=&quot;codehilite&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;c1&quot;&gt;# Simplified update step:&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Assume the gradient dx and parameter vector x&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;cache&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dx&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;**&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+=&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;learning_rate&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dx&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sqrt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cache&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;eps&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div class=&quot;codehilite&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;c1&quot;&gt;# Adagrad Optimizers&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Tensorflow optimizer&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;optimizer&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;train&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;AdagradOptimizer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;learning_rate&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;learning_rate&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;


&lt;span class=&quot;c1&quot;&gt;# TF-keras optimizer&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;optimizer&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tf_keras&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;optimizers&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Adagrad&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;lr&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;learning_rate&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;h2 id=&quot;adadelta-and-rmsprop&quot;&gt;AdaDelta and RMSprop&lt;/h2&gt;
&lt;p&gt;AdaDelta and RMSprop are both very similar optimizers that improves on Adagrad;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;by &lt;strong&gt;normalizing the learning rate&lt;/strong&gt; with &lt;strong&gt;the moving average of squared gradients&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;this reduces the aggressive, monotonically decreasing learning rate found in Adagrad.&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&quot;codehilite&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;c1&quot;&gt;#Simplified update step:&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;cache&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;decay_rate&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cache&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;decay_rate&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dx&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;**&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+=&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;learning_rate&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dx&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sqrt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cache&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;eps&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div class=&quot;codehilite&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;c1&quot;&gt;# Adadelta&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;optimizer&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;train&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;AdadeltaOptimizer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;learning_rate&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;learning_rate&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# RMSprop&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;optimizer&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;train&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;RMSPropOptimizer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;learning_rate&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;learning_rate&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;


&lt;span class=&quot;c1&quot;&gt;# TF-keras optimizer&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Adadelta&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;optimizer&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tf_keras&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;optimizers&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Adadelta&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;lr&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;learning_rate&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# RMSprop&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;optimizer&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tf_keras&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;optimizers&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;RMSprop&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;lr&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;learning_rate&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;h2 id=&quot;adaptive-moment-estimation-adam-optimizer&quot;&gt;Adaptive Moment Estimation (Adam) Optimizer&lt;/h2&gt;
&lt;h3 id=&quot;the-most-recommended-optimizer&quot;&gt;the most recommended optimizer&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;It combines idea from both RMSProp the Momentum method.&lt;/strong&gt; &lt;/li&gt;
&lt;li&gt;It generates a &quot;smooth&quot; estimate (exponentially decaying average) of the gradients&#39; mean and variance. &lt;/li&gt;
&lt;li&gt;Giving you the best a less noisy gradient and an adaptive learning rates for each parameter.&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&quot;codehilite&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;c1&quot;&gt;# Simplified update step:&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;m&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;beta1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;m&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;beta1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dx&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;v&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;beta2&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;v&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;beta2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dx&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;**&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+=&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;learning_rate&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;m&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sqrt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;v&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;eps&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;deeplearning.ai - Improving Deep Neural Networks - Week 1 Assignment 3
&lt;h1 id=&quot;gradient-checking&quot;&gt;Gradient Checking&lt;/h1&gt;
&lt;p&gt;Welcome to the final assignment for this week! In this assignment you will learn to implement and use gradient checking. &lt;/p&gt;
&lt;p&gt;You are part of a team working to make mobile payments available globally, and are asked to build a deep learning model to detect fraud--whenever someone makes a payment, you want to see if the payment might be fraudulent, such as if the user&#39;s account has been taken over by a hacker. &lt;/p&gt;
&lt;p&gt;But backpropagation is quite challenging to implement, and sometimes has bugs. Because this is a mission-critical application, your company&#39;s CEO wants to be really certain that your implementation of backpropagation is correct. Your CEO says, &quot;Give me a proof that your backpropagation is actually working!&quot; To give this reassurance, you are going to use &quot;gradient checking&quot;.&lt;/p&gt;
&lt;p&gt;Let&#39;s do it!&lt;/p&gt;
&lt;div class=&quot;codehilite&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;c1&quot;&gt;# Packages&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;numpy&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;np&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;testCases&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;gc_utils&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sigmoid&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;relu&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dictionary_to_vector&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;vector_to_dictionary&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;gradients_to_vector&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;h2 id=&quot;1-how-does-gradient-checking-work&quot;&gt;1) How does gradient checking work?&lt;/h2&gt;
&lt;p&gt;Backpropagation computes the gradients $\frac{\partial J}{\partial \theta}$, where $\theta$ denotes the parameters of the model. $J$ is computed using forward propagation and your loss function.&lt;/p&gt;
&lt;p&gt;Because forward propagation is relatively easy to implement, you&#39;re confident you got that right, and so you&#39;re almost  100% sure that you&#39;re computing the cost $J$ correctly. Thus, you can use your code for computing $J$ to verify the code for computing $\frac{\partial J}{\partial \theta}$. &lt;/p&gt;
&lt;p&gt;Let&#39;s look back at the definition of a derivative (or gradient):
$$ \frac{\partial J}{\partial \theta} = \lim_{\varepsilon \to 0} \frac{J(\theta + \varepsilon) - J(\theta - \varepsilon)}{2 \varepsilon} \tag{1}$$&lt;/p&gt;
&lt;p&gt;If you&#39;re not familiar with the &quot;$\displaystyle \lim_{\varepsilon \to 0}$&quot; notation, it&#39;s just a way of saying &quot;when $\varepsilon$ is really really small.&quot;&lt;/p&gt;
&lt;p&gt;We know the following:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;$\frac{\partial J}{\partial \theta}$ is what you want to make sure you&#39;re computing correctly. &lt;/li&gt;
&lt;li&gt;You can compute $J(\theta + \varepsilon)$ and $J(\theta - \varepsilon)$ (in the case that $\theta$ is a real number), since you&#39;re confident your implementation for $J$ is correct. &lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Lets use equation (1) and a small value for $\varepsilon$ to convince your CEO that your code for computing  $\frac{\partial J}{\partial \theta}$ is correct!&lt;/p&gt;
&lt;h2 id=&quot;2-1-dimensional-gradient-checking&quot;&gt;2) 1-dimensional gradient checking&lt;/h2&gt;
&lt;p&gt;Consider a 1D linear function $J(\theta) = \theta x$. The model contains only a single real-valued parameter $\theta$, and takes $x$ as input.&lt;/p&gt;
&lt;p&gt;You will implement code to compute $J(.)$ and its derivative $\frac{\partial J}{\partial \theta}$. You will then use gradient checking to make sure your derivative computation for $J$ is correct. &lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/karenyyy/Coursera_and_Udemy/master/deeplearningai_coursera/Improving%20Deep%20Neural%20Networks%3A%20Hyperparameter%20tuning%2C%20Regularization%20and%20Optimization%20Home/images/1Dgrad_kiank.png&quot; style=&quot;width:600px;height:250px;&quot;&gt;
&lt;caption&gt;&lt;center&gt; &lt;u&gt; &lt;strong&gt;Figure 1&lt;/strong&gt; &lt;/u&gt;: &lt;strong&gt;1D linear model&lt;/strong&gt;&lt;br&gt; &lt;/center&gt;&lt;/caption&gt;&lt;/p&gt;
&lt;p&gt;The diagram above shows the key computation steps: First start with $x$, then evaluate the function $J(x)$ (&quot;forward propagation&quot;). Then compute the derivative $\frac{\partial J}{\partial \theta}$ (&quot;backward propagation&quot;). &lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Exercise&lt;/strong&gt;: implement &quot;forward propagation&quot; and &quot;backward propagation&quot; for this simple function. I.e., compute both $J(.)$ (&quot;forward propagation&quot;) and its derivative with respect to $\theta$ (&quot;backward propagation&quot;), in two separate functions. &lt;/p&gt;
&lt;div class=&quot;codehilite&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;c1&quot;&gt;# GRADED FUNCTION: forward_propagation&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;forward_propagation&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;theta&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;sd&quot;&gt;&amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    Implement the linear forward propagation (compute J) presented in Figure 1 (J(theta) = theta * x)&lt;/span&gt;

&lt;span class=&quot;sd&quot;&gt;    Arguments:&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    x -- a real-valued input&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    theta -- our parameter, a real number as well&lt;/span&gt;

&lt;span class=&quot;sd&quot;&gt;    Returns:&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    J -- the value of function J, computed using the formula J(theta) = theta * x&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    &amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;


    &lt;span class=&quot;n&quot;&gt;J&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;theta&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;


    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;J&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div class=&quot;codehilite&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;theta&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;J&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;forward_propagation&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;theta&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;J = &amp;quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;J&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div class=&quot;codehilite&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;J = 8
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;strong&gt;Expected Output&lt;/strong&gt;:&lt;/p&gt;
&lt;table style=&gt;
    &lt;tr&gt;
        &lt;td&gt;  ** J **  &lt;/td&gt;
        &lt;td&gt; 8&lt;/td&gt;
    &lt;/tr&gt;
&lt;/table&gt;

&lt;p&gt;&lt;strong&gt;Exercise&lt;/strong&gt;: Now, implement the backward propagation step (derivative computation) of Figure 1. That is, compute the derivative of $J(\theta) = \theta x$ with respect to $\theta$. To save you from doing the calculus, you should get $dtheta = \frac { \partial J }{ \partial \theta} = x$.&lt;/p&gt;
&lt;div class=&quot;codehilite&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;c1&quot;&gt;# GRADED FUNCTION: backward_propagation&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;backward_propagation&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;theta&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;sd&quot;&gt;&amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    Computes the derivative of J with respect to theta (see Figure 1).&lt;/span&gt;

&lt;span class=&quot;sd&quot;&gt;    Arguments:&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    x -- a real-valued input&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    theta -- our parameter, a real number as well&lt;/span&gt;

&lt;span class=&quot;sd&quot;&gt;    Returns:&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    dtheta -- the gradient of the cost with respect to theta&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    &amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;


    &lt;span class=&quot;n&quot;&gt;dtheta&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;


    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dtheta&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div class=&quot;codehilite&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;theta&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;dtheta&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;backward_propagation&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;theta&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;dtheta = &amp;quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dtheta&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div class=&quot;codehilite&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;dtheta = 2
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;strong&gt;Expected Output&lt;/strong&gt;:&lt;/p&gt;
&lt;table&gt;
    &lt;tr&gt;
        &lt;td&gt;  ** dtheta **  &lt;/td&gt;
        &lt;td&gt; 2 &lt;/td&gt;
    &lt;/tr&gt;
&lt;/table&gt;

&lt;p&gt;&lt;strong&gt;Exercise&lt;/strong&gt;: To show that the &lt;code&gt;backward_propagation()&lt;/code&gt; function is correctly computing the gradient $\frac{\partial J}{\partial \theta}$, let&#39;s implement gradient checking.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Instructions&lt;/strong&gt;:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;First compute &quot;gradapprox&quot; using the formula above (1) and a small value of $\varepsilon$. Here are the Steps to follow:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;$\theta^{+} = \theta + \varepsilon$&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;$\theta^{-} = \theta - \varepsilon$&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;$J^{+} = J(\theta^{+})$&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;$J^{-} = J(\theta^{-})$&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;$gradapprox = \frac{J^{+} - J^{-}}{2  \varepsilon}$&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Then compute the gradient using backward propagation, and store the result in a variable &quot;grad&quot;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Finally, compute the relative difference between &quot;gradapprox&quot; and the &quot;grad&quot; using the following formula:
$$ difference = \frac {\mid\mid grad - gradapprox \mid\mid_2}{\mid\mid grad \mid\mid_2 + \mid\mid gradapprox \mid\mid_2} \tag{2}$$
You will need 3 Steps to compute this formula:&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;1&#39;. compute the numerator using np.linalg.norm(...)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;2&#39;. compute the denominator. You will need to call np.linalg.norm(...) twice.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;3&#39;. divide them.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;If this difference is small (say less than $10^{-7}$), you can be quite confident that you have computed your gradient correctly. Otherwise, there may be a mistake in the gradient computation. &lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&quot;codehilite&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;c1&quot;&gt;# GRADED FUNCTION: gradient_check&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;gradient_check&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;theta&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;epsilon&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;1e-7&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;sd&quot;&gt;&amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    Implement the backward propagation presented in Figure 1.&lt;/span&gt;

&lt;span class=&quot;sd&quot;&gt;    Arguments:&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    x -- a real-valued input&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    theta -- our parameter, a real number as well&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    epsilon -- tiny shift to the input to compute approximated gradient with formula(1)&lt;/span&gt;

&lt;span class=&quot;sd&quot;&gt;    Returns:&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    difference -- difference (2) between the approximated gradient and the backward propagation gradient&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    &amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;

    &lt;span class=&quot;c1&quot;&gt;# Compute gradapprox using left side of formula (1). epsilon is small enough, you don&amp;#39;t need to worry about the limit.&lt;/span&gt;

    &lt;span class=&quot;n&quot;&gt;thetaplus&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;theta&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;epsilon&lt;/span&gt;                               &lt;span class=&quot;c1&quot;&gt;# Step 1&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;thetaminus&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;theta&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;epsilon&lt;/span&gt;                              &lt;span class=&quot;c1&quot;&gt;# Step 2&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;J_plus&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;forward_propagation&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;thetaplus&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;                &lt;span class=&quot;c1&quot;&gt;# Step 3&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;J_minus&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;forward_propagation&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;thetaminus&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;              &lt;span class=&quot;c1&quot;&gt;# Step 4&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;gradapprox&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;J_plus&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;J_minus&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;epsilon&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;                 &lt;span class=&quot;c1&quot;&gt;# Step 5&lt;/span&gt;


    &lt;span class=&quot;c1&quot;&gt;# Check if gradapprox is close enough to the output of backward_propagation()&lt;/span&gt;

    &lt;span class=&quot;n&quot;&gt;grad&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;backward_propagation&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;theta&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;



    &lt;span class=&quot;n&quot;&gt;numerator&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;linalg&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;norm&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;grad&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;gradapprox&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;                               &lt;span class=&quot;c1&quot;&gt;# Step 1&amp;#39;&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;denominator&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;linalg&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;norm&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;grad&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;linalg&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;norm&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;gradapprox&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;             &lt;span class=&quot;c1&quot;&gt;# Step 2&amp;#39;&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;difference&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;numerator&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;denominator&lt;/span&gt;                                        &lt;span class=&quot;c1&quot;&gt;# Step 3&amp;#39;&lt;/span&gt;


    &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;difference&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;1e-7&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;print&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;The gradient is correct!&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;else&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;print&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;The gradient is wrong!&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;difference&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div class=&quot;codehilite&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;theta&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;difference&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;gradient_check&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;theta&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;difference = &amp;quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;difference&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div class=&quot;codehilite&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;The gradient is correct!
difference = 2.91933588329e-10
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;strong&gt;Expected Output&lt;/strong&gt;:
The gradient is correct!
&lt;table&gt;
    &lt;tr&gt;
        &lt;td&gt;  &lt;strong&gt; difference &lt;/strong&gt;  &lt;/td&gt;
        &lt;td&gt; 2.9193358103083e-10 &lt;/td&gt;
    &lt;/tr&gt;
&lt;/table&gt;&lt;/p&gt;
&lt;p&gt;Congrats, the difference is smaller than the $10^{-7}$ threshold. So you can have high confidence that you&#39;ve correctly computed the gradient in &lt;code&gt;backward_propagation()&lt;/code&gt;. &lt;/p&gt;
&lt;p&gt;Now, in the more general case, your cost function $J$ has more than a single 1D input. When you are training a neural network, $\theta$ actually consists of multiple matrices $W^{[l]}$ and biases $b^{[l]}$! It is important to know how to do a gradient check with higher-dimensional inputs. Let&#39;s do it!&lt;/p&gt;
&lt;h2 id=&quot;3-n-dimensional-gradient-checking&quot;&gt;3) N-dimensional gradient checking&lt;/h2&gt;
&lt;p&gt;The following figure describes the forward and backward propagation of your fraud detection model.&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/karenyyy/Coursera_and_Udemy/master/deeplearningai_coursera/Improving%20Deep%20Neural%20Networks%3A%20Hyperparameter%20tuning%2C%20Regularization%20and%20Optimization%20Home/images/NDgrad_kiank.png&quot; style=&quot;width:600px;height:400px;&quot;&gt;
&lt;caption&gt;&lt;center&gt; &lt;u&gt; &lt;strong&gt;Figure 2&lt;/strong&gt; &lt;/u&gt;: &lt;strong&gt;deep neural network&lt;/strong&gt;&lt;br&gt;&lt;em&gt;LINEAR -&amp;gt; RELU -&amp;gt; LINEAR -&amp;gt; RELU -&amp;gt; LINEAR -&amp;gt; SIGMOID&lt;/em&gt;&lt;/center&gt;&lt;/caption&gt;&lt;/p&gt;
&lt;p&gt;Let&#39;s look at your implementations for forward propagation and backward propagation. &lt;/p&gt;
&lt;div class=&quot;codehilite&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;forward_propagation_n&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;parameters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;sd&quot;&gt;&amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    Implements the forward propagation (and computes the cost) presented in Figure 3.&lt;/span&gt;

&lt;span class=&quot;sd&quot;&gt;    Arguments:&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    X -- training set for m examples&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    Y -- labels for m examples &lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    parameters -- python dictionary containing your parameters &amp;quot;W1&amp;quot;, &amp;quot;b1&amp;quot;, &amp;quot;W2&amp;quot;, &amp;quot;b2&amp;quot;, &amp;quot;W3&amp;quot;, &amp;quot;b3&amp;quot;:&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;                    W1 -- weight matrix of shape (5, 4)&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;                    b1 -- bias vector of shape (5, 1)&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;                    W2 -- weight matrix of shape (3, 5)&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;                    b2 -- bias vector of shape (3, 1)&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;                    W3 -- weight matrix of shape (1, 3)&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;                    b3 -- bias vector of shape (1, 1)&lt;/span&gt;

&lt;span class=&quot;sd&quot;&gt;    Returns:&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    cost -- the cost function (logistic cost for one example)&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    &amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;

    &lt;span class=&quot;c1&quot;&gt;# retrieve parameters&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;m&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;W1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;parameters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;W1&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;b1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;parameters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;b1&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;W2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;parameters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;W2&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;b2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;parameters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;b2&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;W3&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;parameters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;W3&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;b3&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;parameters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;b3&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;

    &lt;span class=&quot;c1&quot;&gt;# LINEAR -&amp;gt; RELU -&amp;gt; LINEAR -&amp;gt; RELU -&amp;gt; LINEAR -&amp;gt; SIGMOID&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;Z1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;W1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;b1&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;A1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;relu&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Z1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;Z2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;W2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;A1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;b2&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;A2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;relu&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Z2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;Z3&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;W3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;A2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;b3&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;A3&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sigmoid&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Z3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

    &lt;span class=&quot;c1&quot;&gt;# Cost&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;logprobs&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;multiply&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;log&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;A3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;multiply&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;log&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;A3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;cost&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;1.&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;m&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;logprobs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

    &lt;span class=&quot;n&quot;&gt;cache&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Z1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;A1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;W1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;b1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Z2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;A2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;W2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;b2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Z3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;A3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;W3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;b3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cost&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cache&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Now, run backward propagation.&lt;/p&gt;
&lt;div class=&quot;codehilite&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;backward_propagation_n&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cache&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;sd&quot;&gt;&amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    Implement the backward propagation presented in figure 2.&lt;/span&gt;

&lt;span class=&quot;sd&quot;&gt;    Arguments:&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    X -- input datapoint, of shape (input size, 1)&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    Y -- true &amp;quot;label&amp;quot;&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    cache -- cache output from forward_propagation_n()&lt;/span&gt;

&lt;span class=&quot;sd&quot;&gt;    Returns:&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    gradients -- A dictionary with the gradients of the cost with respect to each parameter, activation and pre-activation variables.&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    &amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;

    &lt;span class=&quot;n&quot;&gt;m&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Z1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;A1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;W1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;b1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Z2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;A2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;W2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;b2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Z3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;A3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;W3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;b3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cache&lt;/span&gt;

    &lt;span class=&quot;n&quot;&gt;dZ3&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;A3&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Y&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;dW3&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;1.&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;m&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dZ3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;A2&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;T&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;db3&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;1.&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;m&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dZ3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;axis&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;keepdims&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

    &lt;span class=&quot;n&quot;&gt;dA2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;W3&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;T&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dZ3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;dZ2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;multiply&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dA2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;int64&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;A2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;dW2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;1.&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;m&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dZ2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;A1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;T&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;db2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;1.&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;m&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dZ2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;axis&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;keepdims&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

    &lt;span class=&quot;n&quot;&gt;dA1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;W2&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;T&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dZ2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;dZ1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;multiply&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dA1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;int64&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;A1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;dW1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;1.&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;m&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dZ1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;T&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;db1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;4.&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;m&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dZ1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;axis&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;keepdims&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

    &lt;span class=&quot;n&quot;&gt;gradients&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;dZ3&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dZ3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&amp;quot;dW3&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dW3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&amp;quot;db3&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;db3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                 &lt;span class=&quot;s2&quot;&gt;&amp;quot;dA2&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dA2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&amp;quot;dZ2&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dZ2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&amp;quot;dW2&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dW2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&amp;quot;db2&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;db2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                 &lt;span class=&quot;s2&quot;&gt;&amp;quot;dA1&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dA1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&amp;quot;dZ1&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dZ1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&amp;quot;dW1&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dW1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&amp;quot;db1&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;db1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;

    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;gradients&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;You obtained some results on the fraud detection test set but you are not 100% sure of your model. Nobody&#39;s perfect! Let&#39;s implement gradient checking to verify if your gradients are correct.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;How does gradient checking work?&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;As in 1) and 2), you want to compare &quot;gradapprox&quot; to the gradient computed by backpropagation. The formula is still:&lt;/p&gt;
&lt;p&gt;$$ \frac{\partial J}{\partial \theta} = \lim_{\varepsilon \to 0} \frac{J(\theta + \varepsilon) - J(\theta - \varepsilon)}{2 \varepsilon} \tag{1}$$&lt;/p&gt;
&lt;p&gt;However, $\theta$ is not a scalar anymore. It is a dictionary called &quot;parameters&quot;. We implemented a function &quot;&lt;code&gt;dictionary_to_vector()&lt;/code&gt;&quot; for you. It converts the &quot;parameters&quot; dictionary into a vector called &quot;values&quot;, obtained by reshaping all parameters (W1, b1, W2, b2, W3, b3) into vectors and concatenating them.&lt;/p&gt;
&lt;p&gt;The inverse function is &quot;&lt;code&gt;vector_to_dictionary&lt;/code&gt;&quot; which outputs back the &quot;parameters&quot; dictionary.&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/karenyyy/Coursera_and_Udemy/master/deeplearningai_coursera/Improving%20Deep%20Neural%20Networks%3A%20Hyperparameter%20tuning%2C%20Regularization%20and%20Optimization%20Home/images/dictionary_to_vector.png&quot; style=&quot;width:600px;height:400px;&quot;&gt;
&lt;caption&gt;&lt;center&gt; &lt;u&gt; &lt;strong&gt;Figure 2&lt;/strong&gt; &lt;/u&gt;: &lt;strong&gt;dictionary_to_vector() and vector_to_dictionary()&lt;/strong&gt;&lt;br&gt; You will need these functions in gradient_check_n()&lt;/center&gt;&lt;/caption&gt;&lt;/p&gt;
&lt;p&gt;We have also converted the &quot;gradients&quot; dictionary into a vector &quot;grad&quot; using gradients_to_vector(). You don&#39;t need to worry about that.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Exercise&lt;/strong&gt;: Implement gradient_check_n().&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Instructions&lt;/strong&gt;: Here is pseudo-code that will help you implement the gradient check.&lt;/p&gt;
&lt;p&gt;For each i in num_parameters:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;To compute &lt;code&gt;J_plus[i]&lt;/code&gt;:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Set $\theta^{+}$ to &lt;code&gt;np.copy(parameters_values)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Set $\theta^{+}_i$ to $\theta^{+}_i + \varepsilon$&lt;/li&gt;
&lt;li&gt;Calculate $J^{+}_i$ using to &lt;code&gt;forward_propagation_n(x, y, vector_to_dictionary(&lt;/code&gt;$\theta^{+}$ &lt;code&gt;))&lt;/code&gt;.     &lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;To compute &lt;code&gt;J_minus[i]&lt;/code&gt;: do the same thing with $\theta^{-}$&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Compute $gradapprox[i] = \frac{J^{+}_i - J^{-}_i}{2 \varepsilon}$&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Thus, you get a vector gradapprox, where gradapprox[i] is an approximation of the gradient with respect to &lt;code&gt;parameter_values[i]&lt;/code&gt;. You can now compare this gradapprox vector to the gradients vector from backpropagation. Just like for the 1D case (Steps 1&#39;, 2&#39;, 3&#39;), compute: 
$$ difference = \frac {| grad - gradapprox |_2}{| grad |_2 + | gradapprox |_2 } \tag{3}$$&lt;/p&gt;
&lt;div class=&quot;codehilite&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;c1&quot;&gt;# GRADED FUNCTION: gradient_check_n&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;gradient_check_n&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;parameters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;gradients&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;epsilon&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;1e-7&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;sd&quot;&gt;&amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    Checks if backward_propagation_n computes correctly the gradient of the cost output by forward_propagation_n&lt;/span&gt;

&lt;span class=&quot;sd&quot;&gt;    Arguments:&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    parameters -- python dictionary containing your parameters &amp;quot;W1&amp;quot;, &amp;quot;b1&amp;quot;, &amp;quot;W2&amp;quot;, &amp;quot;b2&amp;quot;, &amp;quot;W3&amp;quot;, &amp;quot;b3&amp;quot;:&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    grad -- output of backward_propagation_n, contains gradients of the cost with respect to the parameters. &lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    x -- input datapoint, of shape (input size, 1)&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    y -- true &amp;quot;label&amp;quot;&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    epsilon -- tiny shift to the input to compute approximated gradient with formula(1)&lt;/span&gt;

&lt;span class=&quot;sd&quot;&gt;    Returns:&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    difference -- difference (2) between the approximated gradient and the backward propagation gradient&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    &amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;

    &lt;span class=&quot;c1&quot;&gt;# Set-up variables&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;parameters_values&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;_&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dictionary_to_vector&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;parameters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;grad&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;gradients_to_vector&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;gradients&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;num_parameters&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;parameters_values&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;J_plus&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;zeros&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;((&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;num_parameters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;J_minus&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;zeros&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;((&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;num_parameters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;gradapprox&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;zeros&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;((&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;num_parameters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;

    &lt;span class=&quot;c1&quot;&gt;# Compute gradapprox&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;num_parameters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;

        &lt;span class=&quot;c1&quot;&gt;# Compute J_plus[i]. Inputs: &amp;quot;parameters_values, epsilon&amp;quot;. Output = &amp;quot;J_plus[i]&amp;quot;.&lt;/span&gt;
        &lt;span class=&quot;c1&quot;&gt;# &amp;quot;_&amp;quot; is used because the function you have to outputs two parameters but we only care about the first one&lt;/span&gt;

        &lt;span class=&quot;n&quot;&gt;thetaplus&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;copy&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;parameters_values&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;                &lt;span class=&quot;c1&quot;&gt;# Step 1&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;thetaplus&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;][&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;thetaplus&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;][&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;epsilon&lt;/span&gt;                   &lt;span class=&quot;c1&quot;&gt;# Step 2&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;J_plus&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;_&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;forward_propagation_n&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;vector_to_dictionary&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;thetaplus&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;                                   &lt;span class=&quot;c1&quot;&gt;# Step 3&lt;/span&gt;


        &lt;span class=&quot;c1&quot;&gt;# Compute J_minus[i]. Inputs: &amp;quot;parameters_values, epsilon&amp;quot;. Output = &amp;quot;J_minus[i]&amp;quot;.&lt;/span&gt;

        &lt;span class=&quot;n&quot;&gt;thetaminus&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;copy&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;parameters_values&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;                                    &lt;span class=&quot;c1&quot;&gt;# Step 1&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;thetaminus&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;][&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;thetaminus&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;][&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;epsilon&lt;/span&gt;                               &lt;span class=&quot;c1&quot;&gt;# Step 2        &lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;J_minus&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;_&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;forward_propagation_n&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;vector_to_dictionary&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;thetaminus&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;     &lt;span class=&quot;c1&quot;&gt;# Step 3&lt;/span&gt;


        &lt;span class=&quot;c1&quot;&gt;# Compute gradapprox[i]&lt;/span&gt;

        &lt;span class=&quot;n&quot;&gt;gradapprox&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;J_plus&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;J_minus&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;epsilon&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;


    &lt;span class=&quot;c1&quot;&gt;# Compare gradapprox to backward propagation gradients by computing difference.&lt;/span&gt;

    &lt;span class=&quot;n&quot;&gt;numerator&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;linalg&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;norm&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;grad&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;gradapprox&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;                               &lt;span class=&quot;c1&quot;&gt;# Step 1&amp;#39;&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;denominator&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;linalg&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;norm&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;grad&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;linalg&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;norm&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;gradapprox&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;             &lt;span class=&quot;c1&quot;&gt;# Step 2&amp;#39;&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;difference&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;numerator&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;denominator&lt;/span&gt;                                        &lt;span class=&quot;c1&quot;&gt;# Step 3&amp;#39;&lt;/span&gt;


    &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;difference&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;2e-7&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;print&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\033&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;[93m&amp;quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&amp;quot;There is a mistake in the backward propagation! difference = &amp;quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;difference&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\033&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;[0m&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;else&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;print&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\033&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;[92m&amp;quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&amp;quot;Your backward propagation works perfectly fine! difference = &amp;quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;difference&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\033&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;[0m&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;difference&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div class=&quot;codehilite&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;parameters&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;gradient_check_n_test_case&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;cost&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cache&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;forward_propagation_n&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;parameters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;gradients&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;backward_propagation_n&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cache&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;difference&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;gradient_check_n&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;parameters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;gradients&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div class=&quot;codehilite&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;[93mThere is a mistake in the backward propagation! difference = 0.285093156781[0m
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;strong&gt;Expected output&lt;/strong&gt;:&lt;/p&gt;
&lt;table&gt;
    &lt;tr&gt;
        &lt;td&gt;  ** There is a mistake in the backward propagation!**  &lt;/td&gt;
        &lt;td&gt; difference = 0.285093156781 &lt;/td&gt;
    &lt;/tr&gt;
&lt;/table&gt;

&lt;p&gt;It seems that there were errors in the &lt;code&gt;backward_propagation_n&lt;/code&gt; code we gave you! Good that you&#39;ve implemented the gradient check. Go back to &lt;code&gt;backward_propagation&lt;/code&gt; and try to find/correct the errors &lt;em&gt;(Hint: check dW2 and db1)&lt;/em&gt;. Rerun the gradient check when you think you&#39;ve fixed it. Remember you&#39;ll need to re-execute the cell defining &lt;code&gt;backward_propagation_n()&lt;/code&gt; if you modify the code. &lt;/p&gt;
&lt;p&gt;Can you get gradient check to declare your derivative computation correct? Even though this part of the assignment isn&#39;t graded, we strongly urge you to try to find the bug and re-run gradient check until you&#39;re convinced backprop is now correctly implemented. &lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Gradient Checking is slow! Approximating the gradient with $\frac{\partial J}{\partial \theta} \approx  \frac{J(\theta + \varepsilon) - J(\theta - \varepsilon)}{2 \varepsilon}$ is computationally costly. For this reason, we don&#39;t run gradient checking at every iteration during training. Just a few times to check if the gradient is correct. &lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Gradient Checking, at least as we&#39;ve presented it, doesn&#39;t work with dropout. You would usually run the gradient check algorithm without dropout to make sure your backprop is correct, then add dropout. &lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Congrats, you can be confident that your deep learning model for fraud detection is working correctly! You can even use this to convince your CEO. :) &lt;/p&gt;
&lt;p&gt;&lt;strong&gt;What you should remember from this notebook&lt;/strong&gt;:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Gradient checking verifies closeness between the gradients from backpropagation and the numerical approximation of the gradient (computed using forward propagation).&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Gradient checking is slow, so we don&#39;t run it in every iteration of training. You would usually run it only to make sure your code is correct, then turn it off and use backprop for the actual learning process.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;deeplearning.ai - Improving Deep Neural Networks - Week 1 Assignment  2
# Regularization

Welcome to the second assignment of this week. Deep Learning models have so much flexibility and capacity that **overfitting can be a serious problem**, if the training dataset is not big enough. Sure it does well on the training set, but the learned network **doesn&#39;t generalize to new examples** that it has never seen!

**You will learn to:** Use regularization in your deep learning models.

Let&#39;s first import the packages you are going to use.


```python
# import packages
import numpy as np
import matplotlib.pyplot as plt
from reg_utils import sigmoid, relu, plot_decision_boundary, initialize_parameters, load_2D_dataset, predict_dec
from reg_utils import compute_cost, predict, forward_propagation, backward_propagation, update_parameters
import sklearn
import sklearn.datasets
import scipy.io
from testCases import *

%matplotlib inline
plt.rcParams[&#39;figure.figsize&#39;] = (7.0, 4.0) # set default size of plots
plt.rcParams[&#39;image.interpolation&#39;] = &#39;nearest&#39;
plt.rcParams[&#39;image.cmap&#39;] = &#39;gray&#39;
```

**Problem Statement**: You have just been hired as an AI expert by the French Football Corporation. They would like you to recommend positions where France&#39;s goal keeper should kick the ball so that the French team&#39;s players can then hit it with their head. 

&lt;img https://raw.githubusercontent.com/karenyyy/Coursera_and_Udemy/master/deeplearningai_coursera/Improving%20Deep%20Neural%20Networks%3A%20Hyperparameter%20tuning%2C%20Regularization%20and%20Optimization%20Home/images/field_kiank.png&quot; style=&quot;width:600px;height:350px;&quot;&gt;
&lt;caption&gt;&lt;center&gt; &lt;u&gt; **Figure 1** &lt;/u&gt;: **Football field**&lt;br&gt; The goal keeper kicks the ball in the air, the players of each team are fighting to hit the ball with their head &lt;/center&gt;&lt;/caption&gt;


They give you the following 2D dataset from France&#39;s past 10 games.


```python
train_X, train_Y, test_X, test_Y = load_2D_dataset()
```


![png](https://raw.githubusercontent.com/karenyyy/Coursera_and_Udemy/master/deeplearningai_coursera/Improving%20Deep%20Neural%20Networks%3A%20Hyperparameter%20tuning%2C%20Regularization%20and%20Optimization%20Home/images/week1/output_3_0.png)


Each dot corresponds to a position on the football field where a football player has hit the ball with his/her head after the French goal keeper has shot the ball from the left side of the football field.
- If the dot is blue, it means the French player managed to hit the ball with his/her head
- If the dot is red, it means the other team&#39;s player hit the ball with their head

**Your goal**: Use a deep learning model to find the positions on the field where the goalkeeper should kick the ball.

**Analysis of the dataset**: This dataset is a little noisy, but it looks like a diagonal line separating the upper left half (blue) from the lower right half (red) would work well. 

You will first try a non-regularized model. Then you&#39;ll learn how to regularize it and decide which model you will choose to solve the French Football Corporation&#39;s problem. 

## 1 - Non-regularized model

You will use the following neural network (already implemented for you below). This model can be used:
- in *regularization mode* -- by setting the `lambd` input to a non-zero value. We use &quot;`lambd`&quot; instead of &quot;`lambda`&quot; because &quot;`lambda`&quot; is a reserved keyword in Python. 
- in *dropout mode* -- by setting the `keep_prob` to a value less than one

You will first try the model without any regularization. Then, you will implement:
- *L2 regularization* -- functions: &quot;`compute_cost_with_regularization()`&quot; and &quot;`backward_propagation_with_regularization()`&quot;
- *Dropout* -- functions: &quot;`forward_propagation_with_dropout()`&quot; and &quot;`backward_propagation_with_dropout()`&quot;

In each part, you will run this model with the correct inputs so that it calls the functions you&#39;ve implemented. Take a look at the code below to familiarize yourself with the model.


```python
def model(X, Y, learning_rate = 0.3, num_iterations = 30000, print_cost = True, lambd = 0, keep_prob = 1):
    &quot;&quot;&quot;
    Implements a three-layer neural network: LINEAR-&gt;RELU-&gt;LINEAR-&gt;RELU-&gt;LINEAR-&gt;SIGMOID.
    
    Arguments:
    X -- input data, of shape (input size, number of examples)
    Y -- true &quot;label&quot; vector (1 for blue dot / 0 for red dot), of shape (output size, number of examples)
    learning_rate -- learning rate of the optimization
    num_iterations -- number of iterations of the optimization loop
    print_cost -- If True, print the cost every 10000 iterations
    lambd -- regularization hyperparameter, scalar
    keep_prob - probability of keeping a neuron active during drop-out, scalar.
    
    Returns:
    parameters -- parameters learned by the model. They can then be used to predict.
    &quot;&quot;&quot;
        
    grads = {}
    costs = []                            # to keep track of the cost
    m = X.shape[1]                        # number of examples
    layers_dims = [X.shape[0], 20, 3, 1]
    
    # Initialize parameters dictionary.
    parameters = initialize_parameters(layers_dims)

    # Loop (gradient descent)

    for i in range(0, num_iterations):

        # Forward propagation: LINEAR -&gt; RELU -&gt; LINEAR -&gt; RELU -&gt; LINEAR -&gt; SIGMOID.
        if keep_prob == 1:
            a3, cache = forward_propagation(X, parameters)
        elif keep_prob &lt; 1:
            a3, cache = forward_propagation_with_dropout(X, parameters, keep_prob)
        
        # Cost function
        if lambd == 0:
            cost = compute_cost(a3, Y)
        else:
            cost = compute_cost_with_regularization(a3, Y, parameters, lambd)
            
        # Backward propagation.
        assert(lambd==0 or keep_prob==1)    # it is possible to use both L2 regularization and dropout, 
                                            # but this assignment will only explore one at a time
        if lambd == 0 and keep_prob == 1:
            grads = backward_propagation(X, Y, cache)
        elif lambd != 0:
            grads = backward_propagation_with_regularization(X, Y, cache, lambd)
        elif keep_prob &lt; 1:
            grads = backward_propagation_with_dropout(X, Y, cache, keep_prob)
        
        # Update parameters.
        parameters = update_parameters(parameters, grads, learning_rate)
        
        # Print the loss every 10000 iterations
        if print_cost and i % 10000 == 0:
            print(&quot;Cost after iteration {}: {}&quot;.format(i, cost))
        if print_cost and i % 1000 == 0:
            costs.append(cost)
    
    # plot the cost
    plt.plot(costs)
    plt.ylabel(&#39;cost&#39;)
    plt.xlabel(&#39;iterations (x1,000)&#39;)
    plt.title(&quot;Learning rate =&quot; + str(learning_rate))
    plt.show()
    
    return parameters
```

Let&#39;s train the model without any regularization, and observe the accuracy on the train/test sets.


```python
parameters = model(train_X, train_Y)
print (&quot;On the training set:&quot;)
predictions_train = predict(train_X, train_Y, parameters)
print (&quot;On the test set:&quot;)
predictions_test = predict(test_X, test_Y, parameters)
```

    Cost after iteration 0: 0.6557412523481002
    Cost after iteration 10000: 0.16329987525724216
    Cost after iteration 20000: 0.13851642423255986



![png](https://raw.githubusercontent.com/karenyyy/Coursera_and_Udemy/master/deeplearningai_coursera/Improving%20Deep%20Neural%20Networks%3A%20Hyperparameter%20tuning%2C%20Regularization%20and%20Optimization%20Home/images/week1/output_9_1.png)


    On the training set:
    Accuracy: 0.947867298578
    On the test set:
    Accuracy: 0.915


The train accuracy is 94.8% while the test accuracy is 91.5%. This is the **baseline model** (you will observe the impact of regularization on this model). Run the following code to plot the decision boundary of your model.


```python
plt.title(&quot;Model without regularization&quot;)
axes = plt.gca()
axes.set_xlim([-0.75,0.40])
axes.set_ylim([-0.75,0.65])
plot_decision_boundary(lambda x: predict_dec(parameters, x.T), train_X, train_Y)
```


![png](https://raw.githubusercontent.com/karenyyy/Coursera_and_Udemy/master/deeplearningai_coursera/Improving%20Deep%20Neural%20Networks%3A%20Hyperparameter%20tuning%2C%20Regularization%20and%20Optimization%20Home/images/week1/output_11_0.png)


The non-regularized model is obviously overfitting the training set. It is fitting the noisy points! Lets now look at two techniques to reduce overfitting.

## 2 - L2 Regularization

The standard way to avoid overfitting is called **L2 regularization**. It consists of appropriately modifying your cost function, from:
$$J = -\frac{1}{m} \sum\limits_{i = 1}^{m} \large{(}\small  y^{(i)}\log\left(a^{[L](i)}\right) + (1-y^{(i)})\log\left(1- a^{[L](i)}\right) \large{)} \tag{1}$$
To:
$$J_{regularized} = \small \underbrace{-\frac{1}{m} \sum\limits_{i = 1}^{m} \large{(}\small y^{(i)}\log\left(a^{[L](i)}\right) + (1-y^{(i)})\log\left(1- a^{[L](i)}\right) \large{)} }_\text{cross-entropy cost} + \underbrace{\frac{1}{m} \frac{\lambda}{2} \sum\limits_l\sum\limits_k\sum\limits_j W_{k,j}^{[l]2} }_\text{L2 regularization cost} \tag{2}$$

Let&#39;s modify your cost and observe the consequences.

**Exercise**: Implement `compute_cost_with_regularization()` which computes the cost given by formula (2). To calculate $\sum\limits_k\sum\limits_j W_{k,j}^{[l]2}$  , use :
```python
np.sum(np.square(Wl))
```
Note that you have to do this for $W^{[1]}$, $W^{[2]}$ and $W^{[3]}$, then sum the three terms and multiply by $ \frac{1}{m} \frac{\lambda}{2} $.


```python
# GRADED FUNCTION: compute_cost_with_regularization

def compute_cost_with_regularization(A3, Y, parameters, lambd):
    &quot;&quot;&quot;
    Implement the cost function with L2 regularization. See formula (2) above.
    
    Arguments:
    A3 -- post-activation, output of forward propagation, of shape (output size, number of examples)
    Y -- &quot;true&quot; labels vector, of shape (output size, number of examples)
    parameters -- python dictionary containing parameters of the model
    
    Returns:
    cost - value of the regularized loss function (formula (2))
    &quot;&quot;&quot;
    m = Y.shape[1]
    W1 = parameters[&quot;W1&quot;]
    W2 = parameters[&quot;W2&quot;]
    W3 = parameters[&quot;W3&quot;]
    
    cross_entropy_cost = compute_cost(A3, Y) # This gives you the cross-entropy part of the cost
    
    
    L2_regularization_cost = (1/m)*(lambd/2)*(np.sum(np.square(W1))+np.sum(np.square(W2))+np.sum(np.square(W3)))
    
    
    cost = cross_entropy_cost + L2_regularization_cost
    
    return cost
```


```python
A3, Y_assess, parameters = compute_cost_with_regularization_test_case()

print(&quot;cost = &quot; + str(compute_cost_with_regularization(A3, Y_assess, parameters, lambd = 0.1)))
```

    cost = 1.78648594516


**Expected Output**: 

&lt;table&gt; 
    &lt;tr&gt;
    &lt;td&gt;
    **cost**
    &lt;/td&gt;
        &lt;td&gt;
    1.78648594516
    &lt;/td&gt;
    
    &lt;/tr&gt;

&lt;/table&gt; 

Of course, because you changed the cost, you have to change backward propagation as well! All the gradients have to be computed with respect to this new cost. 

**Exercise**: Implement the changes needed in backward propagation to take into account regularization. The changes only concern dW1, dW2 and dW3. For each, you have to add the regularization term&#39;s gradient ($\frac{d}{dW} ( \frac{1}{2}\frac{\lambda}{m}  W^2) = \frac{\lambda}{m} W$).


```python
# GRADED FUNCTION: backward_propagation_with_regularization

def backward_propagation_with_regularization(X, Y, cache, lambd):
    &quot;&quot;&quot;
    Implements the backward propagation of our baseline model to which we added an L2 regularization.
    
    Arguments:
    X -- input dataset, of shape (input size, number of examples)
    Y -- &quot;true&quot; labels vector, of shape (output size, number of examples)
    cache -- cache output from forward_propagation()
    lambd -- regularization hyperparameter, scalar
    
    Returns:
    gradients -- A dictionary with the gradients with respect to each parameter, activation and pre-activation variables
    &quot;&quot;&quot;
    
    m = X.shape[1]
    (Z1, A1, W1, b1, Z2, A2, W2, b2, Z3, A3, W3, b3) = cache
    
    dZ3 = A3 - Y
    
    
    dW3 = 1./m * np.dot(dZ3, A2.T) + (lambd/m)*W3
    
    db3 = 1./m * np.sum(dZ3, axis=1, keepdims = True)
    
    dA2 = np.dot(W3.T, dZ3)
    dZ2 = np.multiply(dA2, np.int64(A2 &gt; 0))
    
    dW2 = 1./m * np.dot(dZ2, A1.T) + (lambd/m)*W2
    
    db2 = 1./m * np.sum(dZ2, axis=1, keepdims = True)
    
    dA1 = np.dot(W2.T, dZ2)
    dZ1 = np.multiply(dA1, np.int64(A1 &gt; 0))
    
    dW1 = 1./m * np.dot(dZ1, X.T) + (lambd/m)*W1
    
    db1 = 1./m * np.sum(dZ1, axis=1, keepdims = True)
    
    gradients = {&quot;dZ3&quot;: dZ3, &quot;dW3&quot;: dW3, &quot;db3&quot;: db3,&quot;dA2&quot;: dA2,
                 &quot;dZ2&quot;: dZ2, &quot;dW2&quot;: dW2, &quot;db2&quot;: db2, &quot;dA1&quot;: dA1, 
                 &quot;dZ1&quot;: dZ1, &quot;dW1&quot;: dW1, &quot;db1&quot;: db1}
    
    return gradients
```


```python
X_assess, Y_assess, cache = backward_propagation_with_regularization_test_case()

grads = backward_propagation_with_regularization(X_assess, Y_assess, cache, lambd = 0.7)
print (&quot;dW1 = &quot;+ str(grads[&quot;dW1&quot;]))
print (&quot;dW2 = &quot;+ str(grads[&quot;dW2&quot;]))
print (&quot;dW3 = &quot;+ str(grads[&quot;dW3&quot;]))
```

    dW1 = [[-0.25604646  0.12298827 -0.28297129]
     [-0.17706303  0.34536094 -0.4410571 ]]
    dW2 = [[ 0.79276486  0.85133918]
     [-0.0957219  -0.01720463]
     [-0.13100772 -0.03750433]]
    dW3 = [[-1.77691347 -0.11832879 -0.09397446]]


**Expected Output**:

&lt;table&gt; 
    &lt;tr&gt;
    &lt;td&gt;
    **dW1**
    &lt;/td&gt;
        &lt;td&gt;
    [[-0.25604646  0.12298827 -0.28297129]
 [-0.17706303  0.34536094 -0.4410571 ]]
    &lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
    &lt;td&gt;
    **dW2**
    &lt;/td&gt;
        &lt;td&gt;
    [[ 0.79276486  0.85133918]
 [-0.0957219  -0.01720463]
 [-0.13100772 -0.03750433]]
    &lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
    &lt;td&gt;
    **dW3**
    &lt;/td&gt;
        &lt;td&gt;
    [[-1.77691347 -0.11832879 -0.09397446]]
    &lt;/td&gt;
    &lt;/tr&gt;
&lt;/table&gt; 

Let&#39;s now run the model with L2 regularization $(\lambda = 0.7)$. The `model()` function will call: 

- `compute_cost_with_regularization` instead of `compute_cost`

- `backward_propagation_with_regularization` instead of `backward_propagation`


```python
parameters = model(train_X, train_Y, lambd = 0.7)
print (&quot;On the train set:&quot;)
predictions_train = predict(train_X, train_Y, parameters)
print (&quot;On the test set:&quot;)
predictions_test = predict(test_X, test_Y, parameters)
```

    Cost after iteration 0: 0.6974484493131264
    Cost after iteration 10000: 0.2684918873282239
    Cost after iteration 20000: 0.2680916337127301



![png](https://raw.githubusercontent.com/karenyyy/Coursera_and_Udemy/master/deeplearningai_coursera/Improving%20Deep%20Neural%20Networks%3A%20Hyperparameter%20tuning%2C%20Regularization%20and%20Optimization%20Home/images/week1/output_22_1.png)


    On the train set:
    Accuracy: 0.938388625592
    On the test set:
    Accuracy: 0.93


Congrats, the test set accuracy increased to 93%. You have saved the French football team!

You are not overfitting the training data anymore. Let&#39;s plot the decision boundary.


```python
plt.title(&quot;Model with L2-regularization&quot;)
axes = plt.gca()
axes.set_xlim([-0.75,0.40])
axes.set_ylim([-0.75,0.65])
plot_decision_boundary(lambda x: predict_dec(parameters, x.T), train_X, train_Y)
```


![png](https://raw.githubusercontent.com/karenyyy/Coursera_and_Udemy/master/deeplearningai_coursera/Improving%20Deep%20Neural%20Networks%3A%20Hyperparameter%20tuning%2C%20Regularization%20and%20Optimization%20Home/images/week1/output_24_0.png)


**Observations**:

- The value of $\lambda$ is a hyperparameter that you can tune using a dev set.

- L2 regularization makes your decision boundary smoother. If $\lambda$ is too large, it is also possible to &quot;oversmooth&quot;, resulting in a model with high bias.

**What is L2-regularization actually doing?**:

L2-regularization relies on the assumption that a model with small weights is simpler than a model with large weights. Thus, by penalizing the square values of the weights in the cost function you drive all the weights to smaller values. It becomes too costly for the cost to have large weights! This leads to a smoother model in which the output changes more slowly as the input changes. 

**What you should remember** -- the implications of L2-regularization on:

- The cost computation:

    - A regularization term is added to the cost

- The backpropagation function:

    - There are extra terms in the gradients with respect to weight matrices

- Weights end up smaller (&quot;weight decay&quot;): 

    - Weights are pushed to smaller values.

## 3 - Dropout

Finally, **dropout** is a widely used regularization technique that is specific to deep learning. 
**It randomly shuts down some neurons in each iteration.** Watch these two videos to see what this means!

&lt;!--
To understand drop-out, consider this conversation with a friend:

- Friend: &quot;Why do you need all these neurons to train your network and classify images?&quot;. 

- You: &quot;Because each neuron contains a weight and can learn specific features/details/shape of an image. The more neurons I have, the more featurse my model learns!&quot;

- Friend: &quot;I see, but are you sure that your neurons are learning different features and not all the same features?&quot;

- You: &quot;Good point... Neurons in the same layer actually don&#39;t talk to each other. It should be definitly possible that they learn the same image features/shapes/forms/details... which would be redundant. There should be a solution.&quot;
!--&gt; 


&lt;center&gt;
&lt;video width=&quot;620&quot; height=&quot;440&quot; https://raw.githubusercontent.com/karenyyy/Coursera_and_Udemy/master/deeplearningai_coursera/Improving%20Deep%20Neural%20Networks%3A%20Hyperparameter%20tuning%2C%20Regularization%20and%20Optimization%20Home/images/dropout1_kiank.mp4&quot; type=&quot;video/mp4&quot; controls&gt;
&lt;/video&gt;
&lt;/center&gt;
&lt;br&gt;
&lt;caption&gt;&lt;center&gt; &lt;u&gt; Figure 2 &lt;/u&gt;: Drop-out on the second hidden layer. &lt;br&gt; At each iteration, you shut down (= set to zero) each neuron of a layer with probability $1 - keep\_prob$ or keep it with probability $keep\_prob$ (50% here). The dropped neurons don&#39;t contribute to the training in both the forward and backward propagations of the iteration. &lt;/center&gt;&lt;/caption&gt;

&lt;center&gt;
&lt;video width=&quot;620&quot; height=&quot;440&quot; https://raw.githubusercontent.com/karenyyy/Coursera_and_Udemy/master/deeplearningai_coursera/Improving%20Deep%20Neural%20Networks%3A%20Hyperparameter%20tuning%2C%20Regularization%20and%20Optimization%20Home/images/dropout2_kiank.mp4&quot; type=&quot;video/mp4&quot; controls&gt;
&lt;/video&gt;
&lt;/center&gt;

&lt;caption&gt;&lt;center&gt; &lt;u&gt; Figure 3 &lt;/u&gt;: Drop-out on the first and third hidden layers. &lt;br&gt; $1^{st}$ layer: we shut down on average 40% of the neurons.  $3^{rd}$ layer: we shut down on average 20% of the neurons. &lt;/center&gt;&lt;/caption&gt;


When you shut some neurons down, you actually modify your model. The idea behind drop-out is that at each iteration, you train a different model that uses only a subset of your neurons. With dropout, your neurons thus become less sensitive to the activation of one other specific neuron, because that other neuron might be shut down at any time. 

### 3.1 - Forward propagation with dropout

**Exercise**: Implement the forward propagation with dropout. You are using a 3 layer neural network, and will add dropout to the first and second hidden layers. We will not apply dropout to the input layer or output layer. 

**Instructions**:
You would like to shut down some neurons in the first and second layers. To do that, you are going to carry out 4 Steps:
1. In lecture, we dicussed creating a variable $d^{[1]}$ with the same shape as $a^{[1]}$ using `np.random.rand()` to randomly get numbers between 0 and 1. Here, you will use a vectorized implementation, so create a random matrix $D^{[1]} = [d^{[1](1)} d^{[1](2)} ... d^{[1](m)}] $ of the same dimension as $A^{[1]}$.
2. Set each entry of $D^{[1]}$ to be 0 with probability (`1-keep_prob`) or 1 with probability (`keep_prob`), by thresholding values in $D^{[1]}$ appropriately. Hint: to set all the entries of a matrix X to 0 (if entry is less than 0.5) or 1 (if entry is more than 0.5) you would do: `X = (X &lt; 0.5)`. Note that 0 and 1 are respectively equivalent to False and True.
3. Set $A^{[1]}$ to $A^{[1]} * D^{[1]}$. (You are shutting down some neurons). You can think of $D^{[1]}$ as a mask, so that when it is multiplied with another matrix, it shuts down some of the values.
4. Divide $A^{[1]}$ by `keep_prob`. By doing this you are assuring that the result of the cost will still have the same expected value as without drop-out. (This technique is also called inverted dropout.)


```python
# GRADED FUNCTION: forward_propagation_with_dropout

def forward_propagation_with_dropout(X, parameters, keep_prob = 0.5):
    &quot;&quot;&quot;
    Implements the forward propagation: LINEAR -&gt; RELU + DROPOUT -&gt; LINEAR -&gt; RELU + DROPOUT -&gt; LINEAR -&gt; SIGMOID.
    
    Arguments:
    X -- input dataset, of shape (2, number of examples)
    parameters -- python dictionary containing your parameters &quot;W1&quot;, &quot;b1&quot;, &quot;W2&quot;, &quot;b2&quot;, &quot;W3&quot;, &quot;b3&quot;:
                    W1 -- weight matrix of shape (20, 2)
                    b1 -- bias vector of shape (20, 1)
                    W2 -- weight matrix of shape (3, 20)
                    b2 -- bias vector of shape (3, 1)
                    W3 -- weight matrix of shape (1, 3)
                    b3 -- bias vector of shape (1, 1)
    keep_prob - probability of keeping a neuron active during drop-out, scalar
    
    Returns:
    A3 -- last activation value, output of the forward propagation, of shape (1,1)
    cache -- tuple, information stored for computing the backward propagation
    &quot;&quot;&quot;
    
    np.random.seed(1)
    
    # retrieve parameters
    W1 = parameters[&quot;W1&quot;]
    b1 = parameters[&quot;b1&quot;]
    W2 = parameters[&quot;W2&quot;]
    b2 = parameters[&quot;b2&quot;]
    W3 = parameters[&quot;W3&quot;]
    b3 = parameters[&quot;b3&quot;]
    
    # LINEAR -&gt; RELU -&gt; LINEAR -&gt; RELU -&gt; LINEAR -&gt; SIGMOID
    Z1 = np.dot(W1, X) + b1
    A1 = relu(Z1)
    
    D1 = np.random.rand(A1.shape[0], A1.shape[1])     # Step 1: initialize matrix D1 = np.random.rand(..., ...)
    D1 = D1&lt;keep_prob                  # Step 2: convert entries of D1 to 0 or 1 (using keep_prob as the threshold)
    A1 = A1*D1                                         # Step 3: shut down some neurons of A1
    A1 = A1/keep_prob                                 # Step 4: scale the value of neurons that haven&#39;t been shut down
    
    Z2 = np.dot(W2, A1) + b2
    A2 = relu(Z2)
    
    D2 = np.random.rand(A2.shape[0], A2.shape[1])     # Step 1: initialize matrix D2 = np.random.rand(..., ...)
    D2 = D2&lt;keep_prob                                  # Step 2: convert entries of D2 to 0 or 1 (using keep_prob as the threshold)
    A2 = A2*D2                                         # Step 3: shut down some neurons of A2
    A2 = A2/keep_prob                                  # Step 4: scale the value of neurons that haven&#39;t been shut down
    
    Z3 = np.dot(W3, A2) + b3
    A3 = sigmoid(Z3)
    
    cache = (Z1, D1, A1, W1, b1, Z2, D2, A2, W2, b2, Z3, A3, W3, b3)
    
    return A3, cache
```


```python
X_assess, parameters = forward_propagation_with_dropout_test_case()

A3, cache = forward_propagation_with_dropout(X_assess, parameters, keep_prob = 0.7)
print (&quot;A3 = &quot; + str(A3))
```

    A3 = [[ 0.36974721  0.00305176  0.04565099  0.49683389  0.36974721]]


**Expected Output**: 

&lt;table&gt; 
    &lt;tr&gt;
    &lt;td&gt;
    **A3**
    &lt;/td&gt;
        &lt;td&gt;
    [[ 0.36974721  0.00305176  0.04565099  0.49683389  0.36974721]]
    &lt;/td&gt;
    
    &lt;/tr&gt;

&lt;/table&gt; 

### 3.2 - Backward propagation with dropout

**Exercise**: Implement the backward propagation with dropout. As before, you are training a 3 layer network. Add dropout to the first and second hidden layers, using the masks $D^{[1]}$ and $D^{[2]}$ stored in the cache. 

**Instruction**:
Backpropagation with dropout is actually quite easy. You will have to carry out 2 Steps:
1. You had previously shut down some neurons during forward propagation, by applying a mask $D^{[1]}$ to `A1`. In backpropagation, you will have to shut down the same neurons, by reapplying the same mask $D^{[1]}$ to `dA1`. 
2. During forward propagation, you had divided `A1` by `keep_prob`. In backpropagation, you&#39;ll therefore have to divide `dA1` by `keep_prob` again (the calculus interpretation is that if $A^{[1]}$ is scaled by `keep_prob`, then its derivative $dA^{[1]}$ is also scaled by the same `keep_prob`).



```python
# GRADED FUNCTION: backward_propagation_with_dropout

def backward_propagation_with_dropout(X, Y, cache, keep_prob):
    &quot;&quot;&quot;
    Implements the backward propagation of our baseline model to which we added dropout.
    
    Arguments:
    X -- input dataset, of shape (2, number of examples)
    Y -- &quot;true&quot; labels vector, of shape (output size, number of examples)
    cache -- cache output from forward_propagation_with_dropout()
    keep_prob - probability of keeping a neuron active during drop-out, scalar
    
    Returns:
    gradients -- A dictionary with the gradients with respect to each parameter, activation and pre-activation variables
    &quot;&quot;&quot;
    
    m = X.shape[1]
    (Z1, D1, A1, W1, b1, Z2, D2, A2, W2, b2, Z3, A3, W3, b3) = cache
    
    dZ3 = A3 - Y
    dW3 = 1./m * np.dot(dZ3, A2.T)
    db3 = 1./m * np.sum(dZ3, axis=1, keepdims = True)
    dA2 = np.dot(W3.T, dZ3)
    
    dA2 = dA2*D2              # Step 1: Apply mask D2 to shut down the same neurons as during the forward propagation
    dA2 = dA2/keep_prob              # Step 2: Scale the value of neurons that haven&#39;t been shut down
    
    dZ2 = np.multiply(dA2, np.int64(A2 &gt; 0))
    dW2 = 1./m * np.dot(dZ2, A1.T)
    db2 = 1./m * np.sum(dZ2, axis=1, keepdims = True)
    
    dA1 = np.dot(W2.T, dZ2)
    
    dA1 = dA1*D1              # Step 1: Apply mask D1 to shut down the same neurons as during the forward propagation
    dA1 = dA1/keep_prob              # Step 2: Scale the value of neurons that haven&#39;t been shut down
    
    dZ1 = np.multiply(dA1, np.int64(A1 &gt; 0))
    dW1 = 1./m * np.dot(dZ1, X.T)
    db1 = 1./m * np.sum(dZ1, axis=1, keepdims = True)
    
    gradients = {&quot;dZ3&quot;: dZ3, &quot;dW3&quot;: dW3, &quot;db3&quot;: db3,&quot;dA2&quot;: dA2,
                 &quot;dZ2&quot;: dZ2, &quot;dW2&quot;: dW2, &quot;db2&quot;: db2, &quot;dA1&quot;: dA1, 
                 &quot;dZ1&quot;: dZ1, &quot;dW1&quot;: dW1, &quot;db1&quot;: db1}
    
    return gradients
```


```python
X_assess, Y_assess, cache = backward_propagation_with_dropout_test_case()

gradients = backward_propagation_with_dropout(X_assess, Y_assess, cache, keep_prob = 0.8)

print (&quot;dA1 = &quot; + str(gradients[&quot;dA1&quot;]))
print (&quot;dA2 = &quot; + str(gradients[&quot;dA2&quot;]))
```

    dA1 = [[ 0.36544439  0.         -0.00188233  0.         -0.17408748]
     [ 0.65515713  0.         -0.00337459  0.         -0.        ]]
    dA2 = [[ 0.58180856  0.         -0.00299679  0.         -0.27715731]
     [ 0.          0.53159854 -0.          0.53159854 -0.34089673]
     [ 0.          0.         -0.00292733  0.         -0.        ]]


**Expected Output**: 

&lt;table&gt; 
    &lt;tr&gt;
    &lt;td&gt;
    **dA1**
    &lt;/td&gt;
        &lt;td&gt;
    [[ 0.36544439  0.         -0.00188233  0.         -0.17408748]
 [ 0.65515713  0.         -0.00337459  0.         -0.        ]]
    &lt;/td&gt;
    
    &lt;/tr&gt;
    &lt;tr&gt;
    &lt;td&gt;
    **dA2**
    &lt;/td&gt;
        &lt;td&gt;
    [[ 0.58180856  0.         -0.00299679  0.         -0.27715731]
 [ 0.          0.53159854 -0.          0.53159854 -0.34089673]
 [ 0.          0.         -0.00292733  0.         -0.        ]]
    &lt;/td&gt;
    
    &lt;/tr&gt;
&lt;/table&gt; 

Let&#39;s now run the model with dropout (`keep_prob = 0.86`). It means at every iteration you shut down each neurons of layer 1 and 2 with 14% probability. The function `model()` will now call:

- `forward_propagation_with_dropout` instead of `forward_propagation`.

- `backward_propagation_with_dropout` instead of `backward_propagation`.


```python
parameters = model(train_X, train_Y, keep_prob = 0.86, learning_rate = 0.3)

print (&quot;On the train set:&quot;)
predictions_train = predict(train_X, train_Y, parameters)
print (&quot;On the test set:&quot;)
predictions_test = predict(test_X, test_Y, parameters)
```

    Cost after iteration 0: 0.6543912405149825


    /home/jovyan/work/week5/Regularization/reg_utils.py:236: RuntimeWarning: divide by zero encountered in log
      logprobs = np.multiply(-np.log(a3),Y) + np.multiply(-np.log(1 - a3), 1 - Y)
    /home/jovyan/work/week5/Regularization/reg_utils.py:236: RuntimeWarning: invalid value encountered in multiply
      logprobs = np.multiply(-np.log(a3),Y) + np.multiply(-np.log(1 - a3), 1 - Y)


    Cost after iteration 10000: 0.06101698657490559
    Cost after iteration 20000: 0.060582435798513114



![png](https://raw.githubusercontent.com/karenyyy/Coursera_and_Udemy/master/deeplearningai_coursera/Improving%20Deep%20Neural%20Networks%3A%20Hyperparameter%20tuning%2C%20Regularization%20and%20Optimization%20Home/images/week1/output_35_3.png)


    On the train set:
    Accuracy: 0.928909952607
    On the test set:
    Accuracy: 0.95


Dropout works great! The test accuracy has increased again (to 95%)! Your model is not overfitting the training set and does a great job on the test set. The French football team will be forever grateful to you! 

Run the code below to plot the decision boundary.


```python
plt.title(&quot;Model with dropout&quot;)
axes = plt.gca()
axes.set_xlim([-0.75,0.40])
axes.set_ylim([-0.75,0.65])
plot_decision_boundary(lambda x: predict_dec(parameters, x.T), train_X, train_Y)
```


![png](https://raw.githubusercontent.com/karenyyy/Coursera_and_Udemy/master/deeplearningai_coursera/Improving%20Deep%20Neural%20Networks%3A%20Hyperparameter%20tuning%2C%20Regularization%20and%20Optimization%20Home/images/week1/output_37_0.png)


**Note**:
- A **common mistake** when using dropout is to use it both in training and testing. You should use dropout (randomly eliminate nodes) only in training. 

- Deep learning frameworks like [tensorflow](https://www.tensorflow.org/api_docs/python/tf/nn/dropout), [PaddlePaddle](http://doc.paddlepaddle.org/release_doc/0.9.0/doc/ui/api/trainer_config_helpers/attrs.html), [keras](https://keras.io/layers/core/#dropout) or [caffe](http://caffe.berkeleyvision.org/tutorial/layers/dropout.html) come with a dropout layer implementation. Don&#39;t stress - you will soon learn some of these frameworks.


**What you should remember about dropout:**

- Dropout is a regularization technique.

- You only use dropout during training. Don&#39;t use dropout (randomly eliminate nodes) during test time.

- Apply dropout both during forward and backward propagation.

- During training time, divide each dropout layer by keep_prob to keep the same expected value for the activations. For example, if keep_prob is 0.5, then we will on average shut down half the nodes, so the output will be scaled by 0.5 since only the remaining half are contributing to the solution. Dividing by 0.5 is equivalent to multiplying by 2. Hence, the output now has the same expected value. You can check that this works even when keep_prob is other values than 0.5.  

## 4 - Conclusions

**Here are the results of our three models**: 

&lt;table&gt; 
    &lt;tr&gt;
        &lt;td&gt;
        **model**
        &lt;/td&gt;
        &lt;td&gt;
        **train accuracy**
        &lt;/td&gt;
        &lt;td&gt;
        **test accuracy**
        &lt;/td&gt;

    &lt;/tr&gt;
        &lt;td&gt;
        3-layer NN without regularization
        &lt;/td&gt;
        &lt;td&gt;
        95%
        &lt;/td&gt;
        &lt;td&gt;
        91.5%
        &lt;/td&gt;
    &lt;tr&gt;
        &lt;td&gt;
        3-layer NN with L2-regularization
        &lt;/td&gt;
        &lt;td&gt;
        94%
        &lt;/td&gt;
        &lt;td&gt;
        93%
        &lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
        &lt;td&gt;
        3-layer NN with dropout
        &lt;/td&gt;
        &lt;td&gt;
        93%
        &lt;/td&gt;
        &lt;td&gt;
        95%
        &lt;/td&gt;
    &lt;/tr&gt;
&lt;/table&gt; 

Note that regularization hurts training set performance! This is because it limits the ability of the network to overfit to the training set. But since it ultimately gives better test accuracy, it is helping your system. 

Congratulations for finishing this assignment! And also for revolutionizing French football. :-) 


**What we want you to remember from this notebook**:

- Regularization will help you reduce overfitting.

- Regularization will drive your weights to lower values.

- L2 regularization and Dropout are two very effective regularization techniques.deeplearning.ai - Neural Networks and Deep Learning - Week 3 Notes
&lt;h2 id=&quot;neural-network-representation&quot;&gt;Neural Network Representation&lt;/h2&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://raw.githubusercontent.com/karenyyy/Coursera_and_Udemy/master/deeplearningai_coursera/Neural_Networks_and_Deep_Learning/images/22.png&quot; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Notes: the input layer does not count as an official layer(layer 0)&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://raw.githubusercontent.com/karenyyy/Coursera_and_Udemy/master/deeplearningai_coursera/Neural_Networks_and_Deep_Learning/images/23.png&quot; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://raw.githubusercontent.com/karenyyy/Coursera_and_Udemy/master/deeplearningai_coursera/Neural_Networks_and_Deep_Learning/images/24.png&quot; /&gt;&lt;/p&gt;
&lt;h3 id=&quot;further-explanation-of-how-the-vectorization-works-pay-attention-to-how-the-shape-changes&quot;&gt;Further explanation of how the vectorization works: (&lt;strong&gt;pay attention to how the shape changes!&lt;/strong&gt;)&lt;/h3&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://raw.githubusercontent.com/karenyyy/Coursera_and_Udemy/master/deeplearningai_coursera/Neural_Networks_and_Deep_Learning/images/25.png&quot; /&gt;&lt;/p&gt;
&lt;h3 id=&quot;activation-function&quot;&gt;Activation Function&lt;/h3&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://raw.githubusercontent.com/karenyyy/Coursera_and_Udemy/master/deeplearningai_coursera/Neural_Networks_and_Deep_Learning/images/26.png&quot; /&gt;
- Seldom use sigmoid, only for binary classification
- can use different activation function at different layers(hidden tanh, output sigmoid)&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Downside&lt;/strong&gt;:
- if Z is either very large or very small, then the derivative of the function becomes very small (gradient vanishing)&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;How to fix?&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;strong&gt;RELU&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://raw.githubusercontent.com/karenyyy/Coursera_and_Udemy/master/deeplearningai_coursera/Neural_Networks_and_Deep_Learning/images/27.png&quot; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Rule of thumbs when choosing activation function:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;if output is 0/1 -&amp;gt; sigmoid&lt;/li&gt;
&lt;li&gt;otherwise, the default choice is always &lt;strong&gt;RELU&lt;/strong&gt;&lt;ul&gt;
&lt;li&gt;and &lt;strong&gt;RELU&lt;/strong&gt; always make model training faster, since less of the effect of the slope of the function slowing down the gradient descent&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Summary&lt;/strong&gt;  &lt;br /&gt;
&lt;img alt=&quot;&quot; src=&quot;https://raw.githubusercontent.com/karenyyy/Coursera_and_Udemy/master/deeplearningai_coursera/Neural_Networks_and_Deep_Learning/images/28.png&quot; /&gt;    &lt;/p&gt;
&lt;h3 id=&quot;why-does-nn-need-a-non-linear-activation-function&quot;&gt;Why does NN need a non-linear activation function&lt;/h3&gt;
&lt;p&gt;if not, then you will end up with a linear function in the end. (&lt;strong&gt;Exceptions: sometimes linear activation function could be used in the output layer(fully connected layer)&lt;/strong&gt;)&lt;/p&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://raw.githubusercontent.com/karenyyy/Coursera_and_Udemy/master/deeplearningai_coursera/Neural_Networks_and_Deep_Learning/images/29.png&quot; /&gt; &lt;/p&gt;
&lt;h3 id=&quot;backpropagation&quot;&gt;Backpropagation&lt;/h3&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://raw.githubusercontent.com/karenyyy/Coursera_and_Udemy/master/deeplearningai_coursera/Neural_Networks_and_Deep_Learning/images/30.png&quot; /&gt; &lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Here: 
$$\text{since } \frac{\partial L}{\partial z} = \frac{\partial L}{\partial a}  \cdot \frac{\partial a}{\partial z}$$&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;$$\text{ so } dz = a-y = da \cdot g&#39;(z), \text{ where } da=\frac{d}{da}L(a,y) = [-y \log a- (1-y) \log (1-a)]&#39; = - \frac{y}{a} + \frac{1-y}{1-a} $$&lt;/p&gt;
&lt;p&gt;$$\text{ and when } g(z) = \frac{1}{1+e^{-z}}, g&#39;(z) = g(z)(1-g(z))$$&lt;/p&gt;
&lt;p&gt;$$\text{ so, } dz = da \cdot g&#39;(z) = \frac{-y(1-a)+a(1-y)}{a(1-a)} \cdot [a(1-a)] $$&lt;/p&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://raw.githubusercontent.com/karenyyy/Coursera_and_Udemy/master/deeplearningai_coursera/Neural_Networks_and_Deep_Learning/images/31.png&quot; /&gt; &lt;/p&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://raw.githubusercontent.com/karenyyy/Coursera_and_Udemy/master/deeplearningai_coursera/Neural_Networks_and_Deep_Learning/images/32.png&quot; /&gt; &lt;/p&gt;
&lt;h3 id=&quot;random-initialization&quot;&gt;Random initialization&lt;/h3&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://raw.githubusercontent.com/karenyyy/Coursera_and_Udemy/master/deeplearningai_coursera/Neural_Networks_and_Deep_Learning/images/33.png&quot; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Symmetric Breaking Problem&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Result: Each neuron in the &lt;strong&gt;first hidden layer&lt;/strong&gt; will perform the same computation. So even after multiple iterations of gradient descent each neuron in the layer will be computing the same thing as other neurons. (&lt;strong&gt;want different hidden units computing different functions&lt;/strong&gt;)&lt;/p&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://raw.githubusercontent.com/karenyyy/Coursera_and_Udemy/master/deeplearningai_coursera/Neural_Networks_and_Deep_Learning/images/34.png&quot; /&gt;&lt;/p&gt;
&lt;p&gt;__Note: Make sure w is small to _avoid gradient vanishing___
&lt;img alt=&quot;&quot; src=&quot;https://raw.githubusercontent.com/karenyyy/Coursera_and_Udemy/master/deeplearningai_coursera/Neural_Networks_and_Deep_Learning/images/35.png&quot; /&gt;&lt;/p&gt;
&lt;h3 id=&quot;other-notes&quot;&gt;Other notes&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;The tanh activation usually works better than sigmoid activation function for hidden units because the mean of its output is closer to zero, and so it centers the data better for the next layer. (&lt;em&gt;As seen in lecture the output of the tanh is between -1 and 1, it thus centers the data which makes the learning simpler for the next layer.&lt;/em&gt;)&lt;/li&gt;
&lt;/ul&gt;deeplearning.ai - Neural Networks and Deep Learning - Week 4 Assignment 1
&lt;h1 id=&quot;building-your-deep-neural-network-step-by-step&quot;&gt;Building your Deep Neural Network: Step by Step&lt;/h1&gt;
&lt;p&gt;&lt;a href=&quot;https://github.com/karenyyy/Coursera_and_Udemy/blob/master/deeplearningai_coursera/Neural_Networks_and_Deep_Learning/notebooks/Building%2Byour%2BDeep%2BNeural%2BNetwork%2B-%2BStep%2Bby%2BStep%2Bv8.ipynb&quot;&gt;in case the mathjax layout is somehow messed up, see notebook here on github&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Welcome to your week 4 assignment (part 1 of 2)! You have previously trained a 2-layer Neural Network (with a single hidden layer). This week, you will build a deep neural network, with as many layers as you want!&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;In this notebook, you will implement all the functions required to build a deep neural network.&lt;/li&gt;
&lt;li&gt;In the next assignment, you will use these functions to build a deep neural network for image classification.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;After this assignment you will be able to:&lt;/strong&gt;
- Use non-linear units like ReLU to improve your model
- Build a deeper neural network (with more than 1 hidden layer)
- Implement an easy-to-use neural network class&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Notation&lt;/strong&gt;:
- Superscript $[l]$ denotes a quantity associated with the $l^{th}$ layer. 
    - Example: $a^{[L]}$ is the $L^{th}$ layer activation. $W^{[L]}$ and $b^{[L]}$ are the $L^{th}$ layer parameters.
- Superscript $(i)$ denotes a quantity associated with the $i^{th}$ example. 
    - Example: $x^{(i)}$ is the $i^{th}$ training example.
- Lowerscript $i$ denotes the $i^{th}$ entry of a vector.
    - Example: $a^{[l]}_i$ denotes the $i^{th}$ entry of the $l^{th}$ layer&#39;s activations).&lt;/p&gt;
&lt;p&gt;Let&#39;s get started!&lt;/p&gt;
&lt;h2 id=&quot;1-packages&quot;&gt;1 - Packages&lt;/h2&gt;
&lt;p&gt;Let&#39;s first import all the packages that you will need during this assignment. 
- &lt;a href=&quot;www.numpy.org&quot;&gt;numpy&lt;/a&gt; is the main package for scientific computing with Python.
- &lt;a href=&quot;http://matplotlib.org&quot;&gt;matplotlib&lt;/a&gt; is a library to plot graphs in Python.
- dnn_utils provides some necessary functions for this notebook.
- testCases provides some test cases to assess the correctness of your functions
- np.random.seed(1) is used to keep all the random function calls consistent. It will help us grade your work. Please don&#39;t change the seed. &lt;/p&gt;
&lt;div class=&quot;codehilite&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;numpy&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;np&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;h5py&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;matplotlib.pyplot&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;plt&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;testCases_v4&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;dnn_utils_v2&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sigmoid&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sigmoid_backward&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;relu&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;relu_backward&lt;/span&gt;

&lt;span class=&quot;o&quot;&gt;%&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;matplotlib&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;inline&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;rcParams&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;figure.figsize&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;5.0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;4.0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;# set default size of plots&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;rcParams&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;image.interpolation&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&amp;#39;nearest&amp;#39;&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;rcParams&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;image.cmap&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&amp;#39;gray&amp;#39;&lt;/span&gt;

&lt;span class=&quot;o&quot;&gt;%&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;load_ext&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;autoreload&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;%&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;autoreload&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;random&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;seed&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div class=&quot;codehilite&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;/opt/conda/lib/python3.5/site-packages/matplotlib/font_manager.py:273: UserWarning: Matplotlib is building the font cache using fc-list. This may take a moment.
  warnings.warn(&amp;#39;Matplotlib is building the font cache using fc-list. This may take a moment.&amp;#39;)
/opt/conda/lib/python3.5/site-packages/matplotlib/font_manager.py:273: UserWarning: Matplotlib is building the font cache using fc-list. This may take a moment.
  warnings.warn(&amp;#39;Matplotlib is building the font cache using fc-list. This may take a moment.&amp;#39;)
&lt;/pre&gt;&lt;/div&gt;


&lt;h2 id=&quot;2-outline-of-the-assignment&quot;&gt;2 - Outline of the Assignment&lt;/h2&gt;
&lt;p&gt;To build your neural network, you will be implementing several &quot;helper functions&quot;. These helper functions will be used in the next assignment to build a two-layer neural network and an L-layer neural network. Each small helper function you will implement will have detailed instructions that will walk you through the necessary steps. Here is an outline of this assignment, you will:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Initialize the parameters for a two-layer network and for an $L$-layer neural network.&lt;/li&gt;
&lt;li&gt;Implement the forward propagation module (shown in purple in the figure below).&lt;ul&gt;
&lt;li&gt;Complete the LINEAR part of a layer&#39;s forward propagation step (resulting in $Z^{[l]}$).&lt;/li&gt;
&lt;li&gt;We give you the ACTIVATION function (relu/sigmoid).&lt;/li&gt;
&lt;li&gt;Combine the previous two steps into a new [LINEAR-&amp;gt;ACTIVATION] forward function.&lt;/li&gt;
&lt;li&gt;Stack the [LINEAR-&amp;gt;RELU] forward function L-1 time (for layers 1 through L-1) and add a [LINEAR-&amp;gt;SIGMOID] at the end (for the final layer $L$). This gives you a new L_model_forward function.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Compute the loss.&lt;/li&gt;
&lt;li&gt;Implement the backward propagation module (denoted in red in the figure below).&lt;ul&gt;
&lt;li&gt;Complete the LINEAR part of a layer&#39;s backward propagation step.&lt;/li&gt;
&lt;li&gt;We give you the gradient of the ACTIVATE function (relu_backward/sigmoid_backward) &lt;/li&gt;
&lt;li&gt;Combine the previous two steps into a new [LINEAR-&amp;gt;ACTIVATION] backward function.&lt;/li&gt;
&lt;li&gt;Stack [LINEAR-&amp;gt;RELU] backward L-1 times and add [LINEAR-&amp;gt;SIGMOID] backward in a new L_model_backward function&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Finally update the parameters.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/karenyyy/Coursera_and_Udemy/master/deeplearningai_coursera/Neural_Networks_and_Deep_Learning/images/final outline.png&quot; style=&quot;width:800px;height:500px;&quot;&gt;
&lt;caption&gt;&lt;center&gt; &lt;strong&gt;Figure 1&lt;/strong&gt;&lt;/center&gt;&lt;/caption&gt;&lt;br&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt; that for every forward function, there is a corresponding backward function. That is why at every step of your forward module you will be storing some values in a cache. The cached values are useful for computing gradients. In the backpropagation module you will then use the cache to calculate the gradients. This assignment will show you exactly how to carry out each of these steps. &lt;/p&gt;
&lt;h2 id=&quot;3-initialization&quot;&gt;3 - Initialization&lt;/h2&gt;
&lt;p&gt;You will write two helper functions that will initialize the parameters for your model. The first function will be used to initialize parameters for a two layer model. The second one will generalize this initialization process to $L$ layers.&lt;/p&gt;
&lt;h3 id=&quot;31-2-layer-neural-network&quot;&gt;3.1 - 2-layer Neural Network&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;Exercise&lt;/strong&gt;: Create and initialize the parameters of the 2-layer neural network.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Instructions&lt;/strong&gt;:
- The model&#39;s structure is: &lt;em&gt;LINEAR -&amp;gt; RELU -&amp;gt; LINEAR -&amp;gt; SIGMOID&lt;/em&gt;. 
- Use random initialization for the weight matrices. Use &lt;code&gt;np.random.randn(shape)*0.01&lt;/code&gt; with the correct shape.
- Use zero initialization for the biases. Use &lt;code&gt;np.zeros(shape)&lt;/code&gt;.&lt;/p&gt;
&lt;div class=&quot;codehilite&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;c1&quot;&gt;# GRADED FUNCTION: initialize_parameters&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;initialize_parameters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n_x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n_h&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n_y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;sd&quot;&gt;&amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    Argument:&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    n_x -- size of the input layer&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    n_h -- size of the hidden layer&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    n_y -- size of the output layer&lt;/span&gt;

&lt;span class=&quot;sd&quot;&gt;    Returns:&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    parameters -- python dictionary containing your parameters:&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;                    W1 -- weight matrix of shape (n_h, n_x)&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;                    b1 -- bias vector of shape (n_h, 1)&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;                    W2 -- weight matrix of shape (n_y, n_h)&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;                    b2 -- bias vector of shape (n_y, 1)&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    &amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;

    &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;random&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;seed&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;


    &lt;span class=&quot;n&quot;&gt;W1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;random&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;randn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n_h&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n_x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.01&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;b1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;zeros&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;((&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n_h&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;W2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;random&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;randn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n_y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n_h&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.01&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;b2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;zeros&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;((&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n_y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;


    &lt;span class=&quot;k&quot;&gt;assert&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;W1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n_h&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n_x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;assert&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;b1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n_h&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;assert&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;W2&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n_y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n_h&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;assert&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;b2&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n_y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;

    &lt;span class=&quot;n&quot;&gt;parameters&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;W1&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;W1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                  &lt;span class=&quot;s2&quot;&gt;&amp;quot;b1&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;b1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                  &lt;span class=&quot;s2&quot;&gt;&amp;quot;W2&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;W2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                  &lt;span class=&quot;s2&quot;&gt;&amp;quot;b2&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;b2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;

    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;parameters&lt;/span&gt;    
&lt;/pre&gt;&lt;/div&gt;


&lt;div class=&quot;codehilite&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;parameters&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;initialize_parameters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;W1 = &amp;quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;parameters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;W1&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]))&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;b1 = &amp;quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;parameters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;b1&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]))&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;W2 = &amp;quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;parameters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;W2&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]))&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;b2 = &amp;quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;parameters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;b2&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]))&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div class=&quot;codehilite&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;W1 = [[ 0.01624345 -0.00611756 -0.00528172]
 [-0.01072969  0.00865408 -0.02301539]]
b1 = [[ 0.]
 [ 0.]]
W2 = [[ 0.01744812 -0.00761207]]
b2 = [[ 0.]]
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;strong&gt;Expected output&lt;/strong&gt;:&lt;/p&gt;
&lt;table style=&quot;width:80%&quot;&gt;
  &lt;tr&gt;
    &lt;td&gt; **W1** &lt;/td&gt;
    &lt;td&gt; [[ 0.01624345 -0.00611756 -0.00528172]
 [-0.01072969  0.00865408 -0.02301539]] &lt;/td&gt; 
  &lt;/tr&gt;

  &lt;tr&gt;
    &lt;td&gt; **b1**&lt;/td&gt;
    &lt;td&gt;[[ 0.]
 [ 0.]]&lt;/td&gt; 
  &lt;/tr&gt;

  &lt;tr&gt;
    &lt;td&gt;**W2**&lt;/td&gt;
    &lt;td&gt; [[ 0.01744812 -0.00761207]]&lt;/td&gt;
  &lt;/tr&gt;

  &lt;tr&gt;
    &lt;td&gt; **b2** &lt;/td&gt;
    &lt;td&gt; [[ 0.]] &lt;/td&gt; 
  &lt;/tr&gt;

&lt;/table&gt;

&lt;h3 id=&quot;32-l-layer-neural-network&quot;&gt;3.2 - L-layer Neural Network&lt;/h3&gt;
&lt;p&gt;The initialization for a deeper L-layer neural network is more complicated because there are many more weight matrices and bias vectors. When completing the &lt;code&gt;initialize_parameters_deep&lt;/code&gt;, you should make sure that your dimensions match between each layer. Recall that $n^{[l]}$ is the number of units in layer $l$. Thus for example if the size of our input $X$ is $(12288, 209)$ (with $m=209$ examples) then:&lt;/p&gt;
&lt;table style=&quot;width:100%&quot;&gt;

    &lt;tr&gt;
        &lt;td&gt;  &lt;/td&gt; 
        &lt;td&gt; **Shape of W** &lt;/td&gt; 
        &lt;td&gt; **Shape of b**  &lt;/td&gt; 
        &lt;td&gt; **Activation** &lt;/td&gt;
        &lt;td&gt; **Shape of Activation** &lt;/td&gt; 
    &lt;tr&gt;

    &lt;tr&gt;
        &lt;td&gt; **Layer 1** &lt;/td&gt; 
        &lt;td&gt; $(n^{[1]},12288)$ &lt;/td&gt; 
        &lt;td&gt; $(n^{[1]},1)$ &lt;/td&gt; 
        &lt;td&gt; $Z^{[1]} = W^{[1]}  X + b^{[1]} $ &lt;/td&gt; 

        &lt;td&gt; $(n^{[1]},209)$ &lt;/td&gt; 
    &lt;tr&gt;

    &lt;tr&gt;
        &lt;td&gt; **Layer 2** &lt;/td&gt; 
        &lt;td&gt; $(n^{[2]}, n^{[1]})$  &lt;/td&gt; 
        &lt;td&gt; $(n^{[2]},1)$ &lt;/td&gt; 
        &lt;td&gt;$Z^{[2]} = W^{[2]} A^{[1]} + b^{[2]}$ &lt;/td&gt; 
        &lt;td&gt; $(n^{[2]}, 209)$ &lt;/td&gt; 
    &lt;tr&gt;

       &lt;tr&gt;
        &lt;td&gt; $\vdots$ &lt;/td&gt; 
        &lt;td&gt; $\vdots$  &lt;/td&gt; 
        &lt;td&gt; $\vdots$  &lt;/td&gt; 
        &lt;td&gt; $\vdots$&lt;/td&gt; 
        &lt;td&gt; $\vdots$  &lt;/td&gt; 
    &lt;tr&gt;

   &lt;tr&gt;
        &lt;td&gt; **Layer L-1** &lt;/td&gt; 
        &lt;td&gt; $(n^{[L-1]}, n^{[L-2]})$ &lt;/td&gt; 
        &lt;td&gt; $(n^{[L-1]}, 1)$  &lt;/td&gt; 
        &lt;td&gt;$Z^{[L-1]} =  W^{[L-1]} A^{[L-2]} + b^{[L-1]}$ &lt;/td&gt; 
        &lt;td&gt; $(n^{[L-1]}, 209)$ &lt;/td&gt; 
    &lt;tr&gt;


   &lt;tr&gt;
        &lt;td&gt; **Layer L** &lt;/td&gt; 
        &lt;td&gt; $(n^{[L]}, n^{[L-1]})$ &lt;/td&gt; 
        &lt;td&gt; $(n^{[L]}, 1)$ &lt;/td&gt;
        &lt;td&gt; $Z^{[L]} =  W^{[L]} A^{[L-1]} + b^{[L]}$&lt;/td&gt;
        &lt;td&gt; $(n^{[L]}, 209)$  &lt;/td&gt; 
    &lt;tr&gt;

&lt;/table&gt;

&lt;p&gt;Remember that when we compute $W X + b$ in python, it carries out broadcasting. For example, if: &lt;/p&gt;
&lt;p&gt;$$ W = \begin{bmatrix}
    j  &amp;amp; k  &amp;amp; l\
    m  &amp;amp; n &amp;amp; o \
    p  &amp;amp; q &amp;amp; r 
\end{bmatrix}\;\;\; X = \begin{bmatrix}
    a  &amp;amp; b  &amp;amp; c\
    d  &amp;amp; e &amp;amp; f \
    g  &amp;amp; h &amp;amp; i 
\end{bmatrix} \;\;\; b =\begin{bmatrix}
    s  \
    t  \
    u
\end{bmatrix}\tag{2}$$&lt;/p&gt;
&lt;p&gt;Then $WX + b$ will be:&lt;/p&gt;
&lt;p&gt;$$ WX + b = \begin{bmatrix}
    (ja + kd + lg) + s  &amp;amp; (jb + ke + lh) + s  &amp;amp; (jc + kf + li)+ s\
    (ma + nd + og) + t &amp;amp; (mb + ne + oh) + t &amp;amp; (mc + nf + oi) + t\
    (pa + qd + rg) + u &amp;amp; (pb + qe + rh) + u &amp;amp; (pc + qf + ri)+ u
\end{bmatrix}\tag{3}  $$&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Exercise&lt;/strong&gt;: Implement initialization for an L-layer Neural Network. &lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Instructions&lt;/strong&gt;:
- The model&#39;s structure is &lt;em&gt;[LINEAR -&amp;gt; RELU] $ \times$ (L-1) -&amp;gt; LINEAR -&amp;gt; SIGMOID&lt;/em&gt;. I.e., it has $L-1$ layers using a ReLU activation function followed by an output layer with a sigmoid activation function.
- Use random initialization for the weight matrices. Use &lt;code&gt;np.random.randn(shape) * 0.01&lt;/code&gt;.
- Use zeros initialization for the biases. Use &lt;code&gt;np.zeros(shape)&lt;/code&gt;.
- We will store $n^{[l]}$, the number of units in different layers, in a variable &lt;code&gt;layer_dims&lt;/code&gt;. For example, the &lt;code&gt;layer_dims&lt;/code&gt; for the &quot;Planar Data classification model&quot; from last week would have been [2,4,1]: There were two inputs, one hidden layer with 4 hidden units, and an output layer with 1 output unit. Thus means &lt;code&gt;W1&lt;/code&gt;&#39;s shape was (4,2), &lt;code&gt;b1&lt;/code&gt; was (4,1), &lt;code&gt;W2&lt;/code&gt; was (1,4) and &lt;code&gt;b2&lt;/code&gt; was (1,1). Now you will generalize this to $L$ layers! 
- Here is the implementation for $L=1$ (one layer neural network). It should inspire you to implement the general case (L-layer neural network).&lt;/p&gt;
&lt;div class=&quot;codehilite&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;    &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;L&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;parameters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;W&amp;quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;L&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;random&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;randn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;layer_dims&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;layer_dims&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.01&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;parameters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;b&amp;quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;L&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;zeros&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;((&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;layer_dims&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div class=&quot;codehilite&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;c1&quot;&gt;# GRADED FUNCTION: initialize_parameters_deep&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;initialize_parameters_deep&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;layer_dims&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;sd&quot;&gt;&amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    Arguments:&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    layer_dims -- python array (list) containing the dimensions of each layer in our network&lt;/span&gt;

&lt;span class=&quot;sd&quot;&gt;    Returns:&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    parameters -- python dictionary containing your parameters &amp;quot;W1&amp;quot;, &amp;quot;b1&amp;quot;, ..., &amp;quot;WL&amp;quot;, &amp;quot;bL&amp;quot;:&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;                    Wl -- weight matrix of shape (layer_dims[l], layer_dims[l-1])&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;                    bl -- bias vector of shape (layer_dims[l], 1)&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    &amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;

    &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;random&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;seed&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;parameters&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{}&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;L&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;layer_dims&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;            &lt;span class=&quot;c1&quot;&gt;# number of layers in the network&lt;/span&gt;

    &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;l&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;L&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;

        &lt;span class=&quot;n&quot;&gt;parameters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;W&amp;#39;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;l&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;random&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;randn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;layer_dims&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;l&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;layer_dims&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;l&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.01&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;parameters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;b&amp;#39;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;l&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;zeros&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;((&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;layer_dims&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;l&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;


        &lt;span class=&quot;k&quot;&gt;assert&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;parameters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;W&amp;#39;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;l&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)]&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;layer_dims&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;l&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;layer_dims&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;l&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]))&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;assert&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;parameters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;b&amp;#39;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;l&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)]&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;layer_dims&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;l&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;


    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;parameters&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div class=&quot;codehilite&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;parameters&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;initialize_parameters_deep&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;W1 = &amp;quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;parameters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;W1&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]))&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;b1 = &amp;quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;parameters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;b1&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]))&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;W2 = &amp;quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;parameters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;W2&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]))&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;b2 = &amp;quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;parameters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;b2&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]))&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div class=&quot;codehilite&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;W1 = [[ 0.01788628  0.0043651   0.00096497 -0.01863493 -0.00277388]
 [-0.00354759 -0.00082741 -0.00627001 -0.00043818 -0.00477218]
 [-0.01313865  0.00884622  0.00881318  0.01709573  0.00050034]
 [-0.00404677 -0.0054536  -0.01546477  0.00982367 -0.01101068]]
b1 = [[ 0.]
 [ 0.]
 [ 0.]
 [ 0.]]
W2 = [[-0.01185047 -0.0020565   0.01486148  0.00236716]
 [-0.01023785 -0.00712993  0.00625245 -0.00160513]
 [-0.00768836 -0.00230031  0.00745056  0.01976111]]
b2 = [[ 0.]
 [ 0.]
 [ 0.]]
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;strong&gt;Expected output&lt;/strong&gt;:&lt;/p&gt;
&lt;table style=&quot;width:80%&quot;&gt;
  &lt;tr&gt;
    &lt;td&gt; **W1** &lt;/td&gt;
    &lt;td&gt;[[ 0.01788628  0.0043651   0.00096497 -0.01863493 -0.00277388]
 [-0.00354759 -0.00082741 -0.00627001 -0.00043818 -0.00477218]
 [-0.01313865  0.00884622  0.00881318  0.01709573  0.00050034]
 [-0.00404677 -0.0054536  -0.01546477  0.00982367 -0.01101068]]&lt;/td&gt; 
  &lt;/tr&gt;

  &lt;tr&gt;
    &lt;td&gt;**b1** &lt;/td&gt;
    &lt;td&gt;[[ 0.]
 [ 0.]
 [ 0.]
 [ 0.]]&lt;/td&gt; 
  &lt;/tr&gt;

  &lt;tr&gt;
    &lt;td&gt;**W2** &lt;/td&gt;
    &lt;td&gt;[[-0.01185047 -0.0020565   0.01486148  0.00236716]
 [-0.01023785 -0.00712993  0.00625245 -0.00160513]
 [-0.00768836 -0.00230031  0.00745056  0.01976111]]&lt;/td&gt; 
  &lt;/tr&gt;

  &lt;tr&gt;
    &lt;td&gt;**b2** &lt;/td&gt;
    &lt;td&gt;[[ 0.]
 [ 0.]
 [ 0.]]&lt;/td&gt; 
  &lt;/tr&gt;

&lt;/table&gt;

&lt;h2 id=&quot;4-forward-propagation-module&quot;&gt;4 - Forward propagation module&lt;/h2&gt;
&lt;h3 id=&quot;41-linear-forward&quot;&gt;4.1 - Linear Forward&lt;/h3&gt;
&lt;p&gt;Now that you have initialized your parameters, you will do the forward propagation module. You will start by implementing some basic functions that you will use later when implementing the model. You will complete three functions in this order:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;LINEAR&lt;/li&gt;
&lt;li&gt;LINEAR -&amp;gt; ACTIVATION where ACTIVATION will be either ReLU or Sigmoid. &lt;/li&gt;
&lt;li&gt;[LINEAR -&amp;gt; RELU] $\times$ (L-1) -&amp;gt; LINEAR -&amp;gt; SIGMOID (whole model)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The linear forward module (vectorized over all the examples) computes the following equations:&lt;/p&gt;
&lt;p&gt;$$Z^{[l]} = W^{[l]}A^{[l-1]} +b^{[l]}\tag{4}$$&lt;/p&gt;
&lt;p&gt;where $A^{[0]} = X$. &lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Exercise&lt;/strong&gt;: Build the linear part of forward propagation.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Reminder&lt;/strong&gt;:
The mathematical representation of this unit is $Z^{[l]} = W^{[l]}A^{[l-1]} +b^{[l]}$. You may also find &lt;code&gt;np.dot()&lt;/code&gt; useful. If your dimensions don&#39;t match, printing &lt;code&gt;W.shape&lt;/code&gt; may help.&lt;/p&gt;
&lt;div class=&quot;codehilite&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;c1&quot;&gt;# GRADED FUNCTION: linear_forward&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;linear_forward&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;A&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;W&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;b&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;sd&quot;&gt;&amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    Implement the linear part of a layer&amp;#39;s forward propagation.&lt;/span&gt;

&lt;span class=&quot;sd&quot;&gt;    Arguments:&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    A -- activations from previous layer (or input data): (size of previous layer, number of examples)&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    W -- weights matrix: numpy array of shape (size of current layer, size of previous layer)&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    b -- bias vector, numpy array of shape (size of the current layer, 1)&lt;/span&gt;

&lt;span class=&quot;sd&quot;&gt;    Returns:&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    Z -- the input of the activation function, also called pre-activation parameter &lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    cache -- a python dictionary containing &amp;quot;A&amp;quot;, &amp;quot;W&amp;quot; and &amp;quot;b&amp;quot; ; stored for computing the backward pass efficiently&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    &amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;


    &lt;span class=&quot;n&quot;&gt;Z&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;W&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;A&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;b&lt;/span&gt;


    &lt;span class=&quot;k&quot;&gt;assert&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Z&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;W&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;A&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]))&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;cache&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;A&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;W&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;b&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Z&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cache&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div class=&quot;codehilite&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;A&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;W&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;b&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;linear_forward_test_case&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;Z&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;linear_cache&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;linear_forward&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;A&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;W&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;b&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;Z = &amp;quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Z&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div class=&quot;codehilite&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;Z = [[ 3.26295337 -1.23429987]]
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;strong&gt;Expected output&lt;/strong&gt;:&lt;/p&gt;
&lt;table style=&quot;width:35%&quot;&gt;

  &lt;tr&gt;
    &lt;td&gt; **Z** &lt;/td&gt;
    &lt;td&gt; [[ 3.26295337 -1.23429987]] &lt;/td&gt; 
  &lt;/tr&gt;

&lt;/table&gt;

&lt;h3 id=&quot;42-linear-activation-forward&quot;&gt;4.2 - Linear-Activation Forward&lt;/h3&gt;
&lt;p&gt;In this notebook, you will use two activation functions:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Sigmoid&lt;/strong&gt;: $\sigma(Z) = \sigma(W A + b) = \frac{1}{ 1 + e^{-(W A + b)}}$. We have provided you with the &lt;code&gt;sigmoid&lt;/code&gt; function. This function returns &lt;strong&gt;two&lt;/strong&gt; items: the activation value &quot;&lt;code&gt;a&lt;/code&gt;&quot; and a &quot;&lt;code&gt;cache&lt;/code&gt;&quot; that contains &quot;&lt;code&gt;Z&lt;/code&gt;&quot; (it&#39;s what we will feed in to the corresponding backward function). To use it you could just call: &lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&quot;codehilite&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;A&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;activation_cache&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sigmoid&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Z&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;ReLU&lt;/strong&gt;: The mathematical formula for ReLu is $A = RELU(Z) = max(0, Z)$. We have provided you with the &lt;code&gt;relu&lt;/code&gt; function. This function returns &lt;strong&gt;two&lt;/strong&gt; items: the activation value &quot;&lt;code&gt;A&lt;/code&gt;&quot; and a &quot;&lt;code&gt;cache&lt;/code&gt;&quot; that contains &quot;&lt;code&gt;Z&lt;/code&gt;&quot; (it&#39;s what we will feed in to the corresponding backward function). To use it you could just call:&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&quot;codehilite&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;A&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;activation_cache&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;relu&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Z&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;For more convenience, you are going to group two functions (Linear and Activation) into one function (LINEAR-&amp;gt;ACTIVATION). Hence, you will implement a function that does the LINEAR forward step followed by an ACTIVATION forward step.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Exercise&lt;/strong&gt;: Implement the forward propagation of the &lt;em&gt;LINEAR-&amp;gt;ACTIVATION&lt;/em&gt; layer. Mathematical relation is: $A^{[l]} = g(Z^{[l]}) = g(W^{[l]}A^{[l-1]} +b^{[l]})$ where the activation &quot;g&quot; can be sigmoid() or relu(). Use linear_forward() and the correct activation function.&lt;/p&gt;
&lt;div class=&quot;codehilite&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;c1&quot;&gt;# GRADED FUNCTION: linear_activation_forward&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;linear_activation_forward&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;A_prev&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;W&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;b&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;activation&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;sd&quot;&gt;&amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    Implement the forward propagation for the LINEAR-&amp;gt;ACTIVATION layer&lt;/span&gt;

&lt;span class=&quot;sd&quot;&gt;    Arguments:&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    A_prev -- activations from previous layer (or input data): (size of previous layer, number of examples)&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    W -- weights matrix: numpy array of shape (size of current layer, size of previous layer)&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    b -- bias vector, numpy array of shape (size of the current layer, 1)&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    activation -- the activation to be used in this layer, stored as a text string: &amp;quot;sigmoid&amp;quot; or &amp;quot;relu&amp;quot;&lt;/span&gt;

&lt;span class=&quot;sd&quot;&gt;    Returns:&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    A -- the output of the activation function, also called the post-activation value &lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    cache -- a python dictionary containing &amp;quot;linear_cache&amp;quot; and &amp;quot;activation_cache&amp;quot;;&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;             stored for computing the backward pass efficiently&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    &amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;

    &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;activation&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&amp;quot;sigmoid&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;c1&quot;&gt;# Inputs: &amp;quot;A_prev, W, b&amp;quot;. Outputs: &amp;quot;A, activation_cache&amp;quot;.&lt;/span&gt;

        &lt;span class=&quot;n&quot;&gt;Z&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;linear_cache&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;linear_forward&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;A_prev&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;W&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;b&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;A&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;activation_cache&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sigmoid&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Z&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;


    &lt;span class=&quot;k&quot;&gt;elif&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;activation&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&amp;quot;relu&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;c1&quot;&gt;# Inputs: &amp;quot;A_prev, W, b&amp;quot;. Outputs: &amp;quot;A, activation_cache&amp;quot;.&lt;/span&gt;

        &lt;span class=&quot;n&quot;&gt;Z&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;linear_cache&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;linear_forward&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;A_prev&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;W&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;b&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;A&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;activation_cache&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;relu&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Z&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;


    &lt;span class=&quot;k&quot;&gt;assert&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;A&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;W&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;A_prev&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]))&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;cache&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;linear_cache&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;activation_cache&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;A&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cache&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div class=&quot;codehilite&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;A_prev&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;W&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;b&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;linear_activation_forward_test_case&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;A&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;linear_activation_cache&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;linear_activation_forward&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;A_prev&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;W&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;b&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;activation&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&amp;quot;sigmoid&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;With sigmoid: A = &amp;quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;A&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;A&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;linear_activation_cache&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;linear_activation_forward&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;A_prev&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;W&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;b&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;activation&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&amp;quot;relu&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;With ReLU: A = &amp;quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;A&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div class=&quot;codehilite&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;With sigmoid: A = [[ 0.96890023  0.11013289]]
With ReLU: A = [[ 3.43896131  0.        ]]
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;strong&gt;Expected output&lt;/strong&gt;:&lt;/p&gt;
&lt;table style=&quot;width:35%&quot;&gt;
  &lt;tr&gt;
    &lt;td&gt; **With sigmoid: A ** &lt;/td&gt;
    &lt;td &gt; [[ 0.96890023  0.11013289]]&lt;/td&gt; 
  &lt;/tr&gt;
  &lt;tr&gt;
    &lt;td&gt; **With ReLU: A ** &lt;/td&gt;
    &lt;td &gt; [[ 3.43896131  0.        ]]&lt;/td&gt; 
  &lt;/tr&gt;
&lt;/table&gt;

&lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt;: In deep learning, the &quot;[LINEAR-&amp;gt;ACTIVATION]&quot; computation is counted as a single layer in the neural network, not two layers. &lt;/p&gt;
&lt;h3 id=&quot;d-l-layer-model&quot;&gt;d) L-Layer Model&lt;/h3&gt;
&lt;p&gt;For even more convenience when implementing the $L$-layer Neural Net, you will need a function that replicates the previous one (&lt;code&gt;linear_activation_forward&lt;/code&gt; with RELU) $L-1$ times, then follows that with one &lt;code&gt;linear_activation_forward&lt;/code&gt; with SIGMOID.&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;images/model_architecture_kiank.png&quot; style=&quot;width:600px;height:300px;&quot;&gt;
&lt;caption&gt;&lt;center&gt; &lt;strong&gt;Figure 2&lt;/strong&gt; : &lt;em&gt;[LINEAR -&amp;gt; RELU] $\times$ (L-1) -&amp;gt; LINEAR -&amp;gt; SIGMOID&lt;/em&gt; model&lt;/center&gt;&lt;/caption&gt;&lt;br&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Exercise&lt;/strong&gt;: Implement the forward propagation of the above model.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Instruction&lt;/strong&gt;: In the code below, the variable &lt;code&gt;AL&lt;/code&gt; will denote $A^{[L]} = \sigma(Z^{[L]}) = \sigma(W^{[L]} A^{[L-1]} + b^{[L]})$. (This is sometimes also called &lt;code&gt;Yhat&lt;/code&gt;, i.e., this is $\hat{Y}$.) &lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Tips&lt;/strong&gt;:
- Use the functions you had previously written 
- Use a for loop to replicate [LINEAR-&amp;gt;RELU] (L-1) times
- Don&#39;t forget to keep track of the caches in the &quot;caches&quot; list. To add a new value &lt;code&gt;c&lt;/code&gt; to a &lt;code&gt;list&lt;/code&gt;, you can use &lt;code&gt;list.append(c)&lt;/code&gt;.&lt;/p&gt;
&lt;div class=&quot;codehilite&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;c1&quot;&gt;# GRADED FUNCTION: L_model_forward&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;L_model_forward&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;parameters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;sd&quot;&gt;&amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    Implement forward propagation for the [LINEAR-&amp;gt;RELU]*(L-1)-&amp;gt;LINEAR-&amp;gt;SIGMOID computation&lt;/span&gt;

&lt;span class=&quot;sd&quot;&gt;    Arguments:&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    X -- data, numpy array of shape (input size, number of examples)&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    parameters -- output of initialize_parameters_deep()&lt;/span&gt;

&lt;span class=&quot;sd&quot;&gt;    Returns:&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    AL -- last post-activation value&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    caches -- list of caches containing:&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;                every cache of linear_activation_forward() (there are L-1 of them, indexed from 0 to L-1)&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    &amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;

    &lt;span class=&quot;n&quot;&gt;caches&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[]&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;A&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;L&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;parameters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;//&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;                  &lt;span class=&quot;c1&quot;&gt;# number of layers in the neural network&lt;/span&gt;

    &lt;span class=&quot;c1&quot;&gt;# Implement [LINEAR -&amp;gt; RELU]*(L-1). Add &amp;quot;cache&amp;quot; to the &amp;quot;caches&amp;quot; list.&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;l&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;L&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;A_prev&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;A&lt;/span&gt; 

        &lt;span class=&quot;n&quot;&gt;A&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cache&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;linear_activation_forward&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;A_prev&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;parameters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;W&amp;quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;l&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;parameters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;b&amp;quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;l&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;activation&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&amp;quot;relu&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;caches&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;append&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cache&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;


    &lt;span class=&quot;c1&quot;&gt;# Implement LINEAR -&amp;gt; SIGMOID. Add &amp;quot;cache&amp;quot; to the &amp;quot;caches&amp;quot; list.&lt;/span&gt;

    &lt;span class=&quot;n&quot;&gt;AL&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cache&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;linear_activation_forward&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;A&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;parameters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;W&amp;quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;L&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;parameters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;b&amp;quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;L&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;activation&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&amp;quot;sigmoid&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;caches&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;append&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cache&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;


    &lt;span class=&quot;k&quot;&gt;assert&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;AL&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]))&lt;/span&gt;

    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;AL&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;caches&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div class=&quot;codehilite&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;parameters&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;L_model_forward_test_case_2hidden&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;AL&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;caches&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;L_model_forward&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;parameters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;AL = &amp;quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;AL&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;Length of caches list = &amp;quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;caches&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)))&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div class=&quot;codehilite&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;AL = [[ 0.03921668  0.70498921  0.19734387  0.04728177]]
Length of caches list = 3
&lt;/pre&gt;&lt;/div&gt;


&lt;table style=&quot;width:50%&quot;&gt;
  &lt;tr&gt;
    &lt;td&gt; **AL** &lt;/td&gt;
    &lt;td &gt; [[ 0.03921668  0.70498921  0.19734387  0.04728177]]&lt;/td&gt; 
  &lt;/tr&gt;
  &lt;tr&gt;
    &lt;td&gt; **Length of caches list ** &lt;/td&gt;
    &lt;td &gt; 3 &lt;/td&gt; 
  &lt;/tr&gt;
&lt;/table&gt;

&lt;p&gt;Great! Now you have a full forward propagation that takes the input X and outputs a row vector $A^{[L]}$ containing your predictions. It also records all intermediate values in &quot;caches&quot;. Using $A^{[L]}$, you can compute the cost of your predictions.&lt;/p&gt;
&lt;h2 id=&quot;5-cost-function&quot;&gt;5 - Cost function&lt;/h2&gt;
&lt;p&gt;Now you will implement forward and backward propagation. You need to compute the cost, because you want to check if your model is actually learning.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Exercise&lt;/strong&gt;: Compute the cross-entropy cost $J$, using the following formula: $$-\frac{1}{m} \sum\limits_{i = 1}^{m} (y^{(i)}\log\left(a^{[L] (i)}\right) + (1-y^{(i)})\log\left(1- a^{&lt;a href=&quot;i&quot;&gt;L&lt;/a&gt;}\right)) \tag{7}$$&lt;/p&gt;
&lt;div class=&quot;codehilite&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;c1&quot;&gt;# GRADED FUNCTION: compute_cost&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;compute_cost&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;AL&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;sd&quot;&gt;&amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    Implement the cost function defined by equation (7).&lt;/span&gt;

&lt;span class=&quot;sd&quot;&gt;    Arguments:&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    AL -- probability vector corresponding to your label predictions, shape (1, number of examples)&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    Y -- true &amp;quot;label&amp;quot; vector (for example: containing 0 if non-cat, 1 if cat), shape (1, number of examples)&lt;/span&gt;

&lt;span class=&quot;sd&quot;&gt;    Returns:&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    cost -- cross-entropy cost&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    &amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;

    &lt;span class=&quot;n&quot;&gt;m&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Y&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;

    &lt;span class=&quot;c1&quot;&gt;# Compute loss from aL and y.&lt;/span&gt;

    &lt;span class=&quot;n&quot;&gt;cost&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Y&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;log&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;AL&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;log&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;AL&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;m&lt;/span&gt;


    &lt;span class=&quot;n&quot;&gt;cost&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;squeeze&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cost&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;      &lt;span class=&quot;c1&quot;&gt;# To make sure your cost&amp;#39;s shape is what we expect (e.g. this turns [[17]] into 17).&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;assert&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cost&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;())&lt;/span&gt;

    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cost&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div class=&quot;codehilite&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;AL&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;compute_cost_test_case&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;cost = &amp;quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;compute_cost&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;AL&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)))&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div class=&quot;codehilite&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;cost = 0.414931599615
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;strong&gt;Expected Output&lt;/strong&gt;:&lt;/p&gt;
&lt;table&gt;

    &lt;tr&gt;
    &lt;td&gt;**cost** &lt;/td&gt;
    &lt;td&gt; 0.41493159961539694&lt;/td&gt; 
    &lt;/tr&gt;
&lt;/table&gt;

&lt;h2 id=&quot;6-backward-propagation-module&quot;&gt;6 - Backward propagation module&lt;/h2&gt;
&lt;p&gt;Just like with forward propagation, you will implement helper functions for backpropagation. Remember that back propagation is used to calculate the gradient of the loss function with respect to the parameters. &lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Reminder&lt;/strong&gt;: 
&lt;img src=&quot;https://raw.githubusercontent.com/karenyyy/Coursera_and_Udemy/master/deeplearningai_coursera/Neural_Networks_and_Deep_Learning/images/backprop_kiank.png&quot; style=&quot;width:650px;height:250px;&quot;&gt;
&lt;caption&gt;&lt;center&gt; &lt;strong&gt;Figure 3&lt;/strong&gt; : Forward and Backward propagation for &lt;em&gt;LINEAR-&amp;gt;RELU-&amp;gt;LINEAR-&amp;gt;SIGMOID&lt;/em&gt; &lt;br&gt; &lt;em&gt;The purple blocks represent the forward propagation, and the red blocks represent the backward propagation.&lt;/em&gt;  &lt;/center&gt;&lt;/caption&gt;&lt;/p&gt;
&lt;!-- 
For those of you who are expert in calculus (you don&#39;t need to be to do this assignment), the chain rule of calculus can be used to derive the derivative of the loss $\mathcal{L}$ with respect to $z^{[1]}$ in a 2-layer network as follows:

$$\frac{d \mathcal{L}(a^{[2]},y)}{{dz^{[1]}}} = \frac{d\mathcal{L}(a^{[2]},y)}{{da^{[2]}}}\frac{{da^{[2]}}}{{dz^{[2]}}}\frac{{dz^{[2]}}}{{da^{[1]}}}\frac{{da^{[1]}}}{{dz^{[1]}}} \tag{8} $$

In order to calculate the gradient $dW^{[1]} = \frac{\partial L}{\partial W^{[1]}}$, you use the previous chain rule and you do $dW^{[1]} = dz^{[1]} \times \frac{\partial z^{[1]} }{\partial W^{[1]}}$. During the backpropagation, at each step you multiply your current gradient by the gradient corresponding to the specific layer to get the gradient you wanted.

Equivalently, in order to calculate the gradient $db^{[1]} = \frac{\partial L}{\partial b^{[1]}}$, you use the previous chain rule and you do $db^{[1]} = dz^{[1]} \times \frac{\partial z^{[1]} }{\partial b^{[1]}}$.

This is why we talk about **backpropagation**.
!--&gt;

&lt;p&gt;Now, similar to forward propagation, you are going to build the backward propagation in three steps:
- LINEAR backward
- LINEAR -&amp;gt; ACTIVATION backward where ACTIVATION computes the derivative of either the ReLU or sigmoid activation
- [LINEAR -&amp;gt; RELU] $\times$ (L-1) -&amp;gt; LINEAR -&amp;gt; SIGMOID backward (whole model)&lt;/p&gt;
&lt;h3 id=&quot;61-linear-backward&quot;&gt;6.1 - Linear backward&lt;/h3&gt;
&lt;p&gt;For layer $l$, the linear part is: $Z^{[l]} = W^{[l]} A^{[l-1]} + b^{[l]}$ (followed by an activation).&lt;/p&gt;
&lt;p&gt;Suppose you have already calculated the derivative $dZ^{[l]} = \frac{\partial \mathcal{L} }{\partial Z^{[l]}}$. You want to get $(dW^{[l]}, db^{[l]} dA^{[l-1]})$.&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/karenyyy/Coursera_and_Udemy/master/deeplearningai_coursera/Neural_Networks_and_Deep_Learning/images/linearback_kiank.png&quot; style=&quot;width:250px;height:300px;&quot;&gt;
&lt;caption&gt;&lt;center&gt; &lt;strong&gt;Figure 4&lt;/strong&gt; &lt;/center&gt;&lt;/caption&gt;&lt;/p&gt;
&lt;p&gt;The three outputs $(dW^{[l]}, db^{[l]}, dA^{[l]})$ are computed using the input $dZ^{[l]}$.Here are the formulas you need:
$$ dW^{[l]} = \frac{\partial \mathcal{L} }{\partial W^{[l]}} = \frac{1}{m} dZ^{[l]} A^{[l-1] T} \tag{8}$$
$$ db^{[l]} = \frac{\partial \mathcal{L} }{\partial b^{[l]}} = \frac{1}{m} \sum_{i = 1}^{m} dZ^{&lt;a href=&quot;i&quot;&gt;l&lt;/a&gt;}\tag{9}$$
$$ dA^{[l-1]} = \frac{\partial \mathcal{L} }{\partial A^{[l-1]}} = W^{[l] T} dZ^{[l]} \tag{10}$$&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Exercise&lt;/strong&gt;: Use the 3 formulas above to implement linear_backward().&lt;/p&gt;
&lt;div class=&quot;codehilite&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;c1&quot;&gt;# GRADED FUNCTION: linear_backward&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;linear_backward&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dZ&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cache&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;sd&quot;&gt;&amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    Implement the linear portion of backward propagation for a single layer (layer l)&lt;/span&gt;

&lt;span class=&quot;sd&quot;&gt;    Arguments:&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    dZ -- Gradient of the cost with respect to the linear output (of current layer l)&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    cache -- tuple of values (A_prev, W, b) coming from the forward propagation in the current layer&lt;/span&gt;

&lt;span class=&quot;sd&quot;&gt;    Returns:&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    dA_prev -- Gradient of the cost with respect to the activation (of the previous layer l-1), same shape as A_prev&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    dW -- Gradient of the cost with respect to W (current layer l), same shape as W&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    db -- Gradient of the cost with respect to b (current layer l), same shape as b&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    &amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;A_prev&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;W&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;b&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cache&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;m&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;A_prev&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;


    &lt;span class=&quot;n&quot;&gt;dW&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dZ&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;A_prev&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;T&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;m&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;db&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dZ&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;axis&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;keepdims&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;m&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;dA_prev&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;W&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;T&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dZ&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;


    &lt;span class=&quot;k&quot;&gt;assert&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dA_prev&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;A_prev&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;assert&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dW&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;W&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;assert&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;db&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;b&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dA_prev&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dW&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;db&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div class=&quot;codehilite&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;c1&quot;&gt;# Set up some test inputs&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;dZ&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;linear_cache&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;linear_backward_test_case&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;dA_prev&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dW&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;db&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;linear_backward&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dZ&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;linear_cache&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;dA_prev = &amp;quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dA_prev&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;dW = &amp;quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dW&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;db = &amp;quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;db&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div class=&quot;codehilite&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;dA_prev = [[ 0.51822968 -0.19517421]
 [-0.40506361  0.15255393]
 [ 2.37496825 -0.89445391]]
dW = [[-0.10076895  1.40685096  1.64992505]]
db = [[ 0.50629448]]
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;strong&gt;Expected Output&lt;/strong&gt;: &lt;/p&gt;
&lt;table style=&quot;width:90%&quot;&gt;
  &lt;tr&gt;
    &lt;td&gt; **dA_prev** &lt;/td&gt;
    &lt;td &gt; [[ 0.51822968 -0.19517421]
 [-0.40506361  0.15255393]
 [ 2.37496825 -0.89445391]] &lt;/td&gt; 
  &lt;/tr&gt;

    &lt;tr&gt;
        &lt;td&gt; **dW** &lt;/td&gt;
        &lt;td &gt; [[-0.10076895  1.40685096  1.64992505]] &lt;/td&gt; 
    &lt;/tr&gt; 

    &lt;tr&gt;
        &lt;td&gt; **db** &lt;/td&gt;
        &lt;td&gt; [[ 0.50629448]] &lt;/td&gt; 
    &lt;/tr&gt; 

&lt;/table&gt;

&lt;h3 id=&quot;62-linear-activation-backward&quot;&gt;6.2 - Linear-Activation backward&lt;/h3&gt;
&lt;p&gt;Next, you will create a function that merges the two helper functions: &lt;strong&gt;&lt;code&gt;linear_backward&lt;/code&gt;&lt;/strong&gt; and the backward step for the activation &lt;strong&gt;&lt;code&gt;linear_activation_backward&lt;/code&gt;&lt;/strong&gt;. &lt;/p&gt;
&lt;p&gt;To help you implement &lt;code&gt;linear_activation_backward&lt;/code&gt;, we provided two backward functions:
- &lt;strong&gt;&lt;code&gt;sigmoid_backward&lt;/code&gt;&lt;/strong&gt;: Implements the backward propagation for SIGMOID unit. You can call it as follows:&lt;/p&gt;
&lt;div class=&quot;codehilite&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dZ&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sigmoid_backward&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dA&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;activation_cache&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;&lt;code&gt;relu_backward&lt;/code&gt;&lt;/strong&gt;: Implements the backward propagation for RELU unit. You can call it as follows:&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&quot;codehilite&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dZ&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;relu_backward&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dA&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;activation_cache&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;If $g(.)$ is the activation function, 
&lt;code&gt;sigmoid_backward&lt;/code&gt; and &lt;code&gt;relu_backward&lt;/code&gt; compute $$dZ^{[l]} = dA^{[l]} * g&#39;(Z^{[l]}) \tag{11}$$.  &lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Exercise&lt;/strong&gt;: Implement the backpropagation for the &lt;em&gt;LINEAR-&amp;gt;ACTIVATION&lt;/em&gt; layer.&lt;/p&gt;
&lt;div class=&quot;codehilite&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;c1&quot;&gt;# GRADED FUNCTION: linear_activation_backward&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;linear_activation_backward&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dA&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cache&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;activation&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;sd&quot;&gt;&amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    Implement the backward propagation for the LINEAR-&amp;gt;ACTIVATION layer.&lt;/span&gt;

&lt;span class=&quot;sd&quot;&gt;    Arguments:&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    dA -- post-activation gradient for current layer l &lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    cache -- tuple of values (linear_cache, activation_cache) we store for computing backward propagation efficiently&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    activation -- the activation to be used in this layer, stored as a text string: &amp;quot;sigmoid&amp;quot; or &amp;quot;relu&amp;quot;&lt;/span&gt;

&lt;span class=&quot;sd&quot;&gt;    Returns:&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    dA_prev -- Gradient of the cost with respect to the activation (of the previous layer l-1), same shape as A_prev&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    dW -- Gradient of the cost with respect to W (current layer l), same shape as W&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    db -- Gradient of the cost with respect to b (current layer l), same shape as b&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    &amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;linear_cache&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;activation_cache&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cache&lt;/span&gt;

    &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;activation&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&amp;quot;relu&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;

        &lt;span class=&quot;n&quot;&gt;dZ&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;relu_backward&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dA&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;activation_cache&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;dA_prev&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dW&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;db&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;linear_backward&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dZ&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;linear_cache&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;


    &lt;span class=&quot;k&quot;&gt;elif&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;activation&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&amp;quot;sigmoid&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;

        &lt;span class=&quot;n&quot;&gt;dZ&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sigmoid_backward&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dA&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;activation_cache&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;dA_prev&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dW&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;db&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;linear_backward&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dZ&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;linear_cache&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;


    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dA_prev&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dW&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;db&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div class=&quot;codehilite&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dAL&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;linear_activation_cache&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;linear_activation_backward_test_case&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;dA_prev&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dW&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;db&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;linear_activation_backward&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dAL&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;linear_activation_cache&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;activation&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&amp;quot;sigmoid&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;sigmoid:&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;dA_prev = &amp;quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dA_prev&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;dW = &amp;quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dW&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;db = &amp;quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;db&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\n&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;dA_prev&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dW&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;db&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;linear_activation_backward&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dAL&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;linear_activation_cache&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;activation&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&amp;quot;relu&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;relu:&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;dA_prev = &amp;quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dA_prev&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;dW = &amp;quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dW&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;db = &amp;quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;db&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div class=&quot;codehilite&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sigmoid&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;dA_prev&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;[[&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.11017994&lt;/span&gt;  &lt;span class=&quot;mf&quot;&gt;0.01105339&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;]&lt;/span&gt;
 &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.09466817&lt;/span&gt;  &lt;span class=&quot;mf&quot;&gt;0.00949723&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;]&lt;/span&gt;
 &lt;span class=&quot;o&quot;&gt;[-&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.05743092&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.00576154&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;]]&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;dW&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;[[&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.10266786&lt;/span&gt;  &lt;span class=&quot;mf&quot;&gt;0.09778551&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.01968084&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;]]&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;db&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;[[-&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.05729622&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;]]&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;relu&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;dA_prev&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;[[&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.44090989&lt;/span&gt;  &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;        &lt;span class=&quot;o&quot;&gt;]&lt;/span&gt;
 &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.37883606&lt;/span&gt;  &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;        &lt;span class=&quot;o&quot;&gt;]&lt;/span&gt;
 &lt;span class=&quot;o&quot;&gt;[-&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.2298228&lt;/span&gt;   &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;        &lt;span class=&quot;o&quot;&gt;]]&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;dW&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;[[&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.44513824&lt;/span&gt;  &lt;span class=&quot;mf&quot;&gt;0.37371418&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.10478989&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;]]&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;db&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;[[-&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.20837892&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;]]&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;strong&gt;Expected output with sigmoid:&lt;/strong&gt;&lt;/p&gt;
&lt;table style=&quot;width:100%&quot;&gt;
  &lt;tr&gt;
    &lt;td &gt; dA_prev &lt;/td&gt; 
           &lt;td &gt;[[ 0.11017994  0.01105339]
 [ 0.09466817  0.00949723]
 [-0.05743092 -0.00576154]] &lt;/td&gt;

  &lt;/tr&gt; 

    &lt;tr&gt;
    &lt;td &gt; dW &lt;/td&gt; 
           &lt;td &gt; [[ 0.10266786  0.09778551 -0.01968084]] &lt;/td&gt; 
  &lt;/tr&gt; 

    &lt;tr&gt;
    &lt;td &gt; db &lt;/td&gt; 
           &lt;td &gt; [[-0.05729622]] &lt;/td&gt; 
  &lt;/tr&gt; 
&lt;/table&gt;

&lt;p&gt;&lt;strong&gt;Expected output with relu:&lt;/strong&gt;&lt;/p&gt;
&lt;table style=&quot;width:100%&quot;&gt;
  &lt;tr&gt;
    &lt;td &gt; dA_prev &lt;/td&gt; 
           &lt;td &gt; [[ 0.44090989  0.        ]
 [ 0.37883606  0.        ]
 [-0.2298228   0.        ]] &lt;/td&gt;

  &lt;/tr&gt; 

    &lt;tr&gt;
    &lt;td &gt; dW &lt;/td&gt; 
           &lt;td &gt; [[ 0.44513824  0.37371418 -0.10478989]] &lt;/td&gt; 
  &lt;/tr&gt; 

    &lt;tr&gt;
    &lt;td &gt; db &lt;/td&gt; 
           &lt;td &gt; [[-0.20837892]] &lt;/td&gt; 
  &lt;/tr&gt; 
&lt;/table&gt;

&lt;h3 id=&quot;63-l-model-backward&quot;&gt;6.3 - L-Model Backward&lt;/h3&gt;
&lt;p&gt;Now you will implement the backward function for the whole network. Recall that when you implemented the &lt;code&gt;L_model_forward&lt;/code&gt; function, at each iteration, you stored a cache which contains (X,W,b, and z). In the back propagation module, you will use those variables to compute the gradients. Therefore, in the &lt;code&gt;L_model_backward&lt;/code&gt; function, you will iterate through all the hidden layers backward, starting from layer $L$. On each step, you will use the cached values for layer $l$ to backpropagate through layer $l$. Figure 5 below shows the backward pass. &lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/karenyyy/Coursera_and_Udemy/master/deeplearningai_coursera/Neural_Networks_and_Deep_Learning/images/mn_backward.png&quot; style=&quot;width:450px;height:300px;&quot;&gt;
&lt;caption&gt;&lt;center&gt;  &lt;strong&gt;Figure 5&lt;/strong&gt; : Backward pass  &lt;/center&gt;&lt;/caption&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt; Initializing backpropagation&lt;/strong&gt;:
To backpropagate through this network, we know that the output is, 
$A^{[L]} = \sigma(Z^{[L]})$. Your code thus needs to compute &lt;code&gt;dAL&lt;/code&gt; $= \frac{\partial \mathcal{L}}{\partial A^{[L]}}$.
To do so, use this formula (derived using calculus which you don&#39;t need in-depth knowledge of):&lt;/p&gt;
&lt;div class=&quot;codehilite&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dAL&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;divide&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;AL&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;divide&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;AL&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;# derivative of cost with respect to AL&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;You can then use this post-activation gradient &lt;code&gt;dAL&lt;/code&gt; to keep going backward. As seen in Figure 5, you can now feed in &lt;code&gt;dAL&lt;/code&gt; into the LINEAR-&amp;gt;SIGMOID backward function you implemented (which will use the cached values stored by the L_model_forward function). After that, you will have to use a &lt;code&gt;for&lt;/code&gt; loop to iterate through all the other layers using the LINEAR-&amp;gt;RELU backward function. You should store each dA, dW, and db in the grads dictionary. To do so, use this formula : &lt;/p&gt;
&lt;p&gt;$$grads[&quot;dW&quot; + str(l)] = dW^{[l]}\tag{15} $$&lt;/p&gt;
&lt;p&gt;For example, for $l=3$ this would store $dW^{[l]}$ in &lt;code&gt;grads[&quot;dW3&quot;]&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Exercise&lt;/strong&gt;: Implement backpropagation for the &lt;em&gt;[LINEAR-&amp;gt;RELU] $\times$ (L-1) -&amp;gt; LINEAR -&amp;gt; SIGMOID&lt;/em&gt; model.&lt;/p&gt;
&lt;div class=&quot;codehilite&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;c1&quot;&gt;# GRADED FUNCTION: L_model_backward&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;L_model_backward&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;AL&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;caches&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;sd&quot;&gt;&amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    Implement the backward propagation for the [LINEAR-&amp;gt;RELU] * (L-1) -&amp;gt; LINEAR -&amp;gt; SIGMOID group&lt;/span&gt;

&lt;span class=&quot;sd&quot;&gt;    Arguments:&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    AL -- probability vector, output of the forward propagation (L_model_forward())&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    Y -- true &amp;quot;label&amp;quot; vector (containing 0 if non-cat, 1 if cat)&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    caches -- list of caches containing:&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;                every cache of linear_activation_forward() with &amp;quot;relu&amp;quot; (it&amp;#39;s caches[l], for l in range(L-1) i.e l = 0...L-2)&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;                the cache of linear_activation_forward() with &amp;quot;sigmoid&amp;quot; (it&amp;#39;s caches[L-1])&lt;/span&gt;

&lt;span class=&quot;sd&quot;&gt;    Returns:&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    grads -- A dictionary with the gradients&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;             grads[&amp;quot;dA&amp;quot; + str(l)] = ... &lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;             grads[&amp;quot;dW&amp;quot; + str(l)] = ...&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;             grads[&amp;quot;db&amp;quot; + str(l)] = ... &lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    &amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;grads&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{}&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;L&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;caches&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;# the number of layers&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;m&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;AL&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;Y&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Y&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;reshape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;AL&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;# after this line, Y is the same shape as AL&lt;/span&gt;

    &lt;span class=&quot;c1&quot;&gt;# Initializing the backpropagation&lt;/span&gt;

    &lt;span class=&quot;n&quot;&gt;dAL&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;divide&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;AL&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;divide&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;AL&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;


    &lt;span class=&quot;c1&quot;&gt;# Lth layer (SIGMOID -&amp;gt; LINEAR) gradients. Inputs: &amp;quot;dAL, current_cache&amp;quot;. Outputs: &amp;quot;grads[&amp;quot;dAL-1&amp;quot;], grads[&amp;quot;dWL&amp;quot;], grads[&amp;quot;dbL&amp;quot;]&lt;/span&gt;

    &lt;span class=&quot;n&quot;&gt;current_cache&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;caches&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;grads&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;dA&amp;quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;L&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;grads&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;dW&amp;quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;L&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;grads&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;db&amp;quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;L&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;linear_activation_backward&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dAL&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;current_cache&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;activation&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&amp;quot;sigmoid&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;


    &lt;span class=&quot;c1&quot;&gt;# Loop from l=L-2 to l=0&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;l&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;reversed&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;L&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)):&lt;/span&gt;
        &lt;span class=&quot;c1&quot;&gt;# lth layer: (RELU -&amp;gt; LINEAR) gradients.&lt;/span&gt;
        &lt;span class=&quot;c1&quot;&gt;# Inputs: &amp;quot;grads[&amp;quot;dA&amp;quot; + str(l + 1)], current_cache&amp;quot;. Outputs: &amp;quot;grads[&amp;quot;dA&amp;quot; + str(l)] , grads[&amp;quot;dW&amp;quot; + str(l + 1)] , grads[&amp;quot;db&amp;quot; + str(l + 1)] &lt;/span&gt;

        &lt;span class=&quot;n&quot;&gt;current_cache&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;caches&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;l&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;dA_prev_temp&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dW_temp&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;db_temp&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;linear_activation_backward&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dAL&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;current_cache&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;activation&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&amp;quot;sigmoid&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;grads&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;dA&amp;quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;l&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dA_prev_temp&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;grads&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;dW&amp;quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;l&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dW_temp&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;grads&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;db&amp;quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;l&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;db_temp&lt;/span&gt;


    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;grads&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div class=&quot;codehilite&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;AL&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Y_assess&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;caches&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;L_model_backward_test_case&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;grads&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;L_model_backward&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;AL&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Y_assess&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;caches&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;print_grads&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;grads&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div class=&quot;codehilite&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;dW1 = [[-0.38142895 -0.05436378 -0.12122851 -0.09345065]
 [-0.36454443 -0.04886266 -0.11465667 -0.08859687]
 [-0.36758766 -0.04958047 -0.11573455 -0.08940829]]
db1 = [[ 0.13978379]
 [ 0.12259085]
 [ 0.12471635]]
dA1 = [[ 0.12913162 -0.44014127]
 [-0.14175655  0.48317296]
 [ 0.01663708 -0.05670698]]
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;strong&gt;Expected Output&lt;/strong&gt;&lt;/p&gt;
&lt;table style=&quot;width:60%&quot;&gt;

  &lt;tr&gt;
    &lt;td &gt; dW1 &lt;/td&gt; 
           &lt;td &gt; [[ 0.41010002  0.07807203  0.13798444  0.10502167]
 [ 0.          0.          0.          0.        ]
 [ 0.05283652  0.01005865  0.01777766  0.0135308 ]] &lt;/td&gt; 
  &lt;/tr&gt; 

    &lt;tr&gt;
    &lt;td &gt; db1 &lt;/td&gt; 
           &lt;td &gt; [[-0.22007063]
 [ 0.        ]
 [-0.02835349]] &lt;/td&gt; 
  &lt;/tr&gt; 

  &lt;tr&gt;
  &lt;td &gt; dA1 &lt;/td&gt; 
           &lt;td &gt; [[ 0.12913162 -0.44014127]
 [-0.14175655  0.48317296]
 [ 0.01663708 -0.05670698]] &lt;/td&gt; 

  &lt;/tr&gt; 
&lt;/table&gt;

&lt;h3 id=&quot;64-update-parameters&quot;&gt;6.4 - Update Parameters&lt;/h3&gt;
&lt;p&gt;In this section you will update the parameters of the model, using gradient descent: &lt;/p&gt;
&lt;p&gt;$$ W^{[l]} = W^{[l]} - \alpha \text{ } dW^{[l]} \tag{16}$$
$$ b^{[l]} = b^{[l]} - \alpha \text{ } db^{[l]} \tag{17}$$&lt;/p&gt;
&lt;p&gt;where $\alpha$ is the learning rate. After computing the updated parameters, store them in the parameters dictionary. &lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Exercise&lt;/strong&gt;: Implement &lt;code&gt;update_parameters()&lt;/code&gt; to update your parameters using gradient descent.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Instructions&lt;/strong&gt;:
Update parameters using gradient descent on every $W^{[l]}$ and $b^{[l]}$ for $l = 1, 2, ..., L$. &lt;/p&gt;
&lt;div class=&quot;codehilite&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;c1&quot;&gt;# GRADED FUNCTION: update_parameters&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;update_parameters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;parameters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;grads&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;learning_rate&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;sd&quot;&gt;&amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    Update parameters using gradient descent&lt;/span&gt;

&lt;span class=&quot;sd&quot;&gt;    Arguments:&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    parameters -- python dictionary containing your parameters &lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    grads -- python dictionary containing your gradients, output of L_model_backward&lt;/span&gt;

&lt;span class=&quot;sd&quot;&gt;    Returns:&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    parameters -- python dictionary containing your updated parameters &lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;                  parameters[&amp;quot;W&amp;quot; + str(l)] = ... &lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;                  parameters[&amp;quot;b&amp;quot; + str(l)] = ...&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    &amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;

    &lt;span class=&quot;n&quot;&gt;L&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;parameters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;//&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;# number of layers in the neural network&lt;/span&gt;

    &lt;span class=&quot;c1&quot;&gt;# Update rule for each parameter. Use a for loop.&lt;/span&gt;

    &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;l&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;L&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;parameters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;W&amp;quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;l&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;parameters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;W&amp;quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;l&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;learning_rate&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;grads&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;dW&amp;quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;l&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)]&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;parameters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;b&amp;quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;l&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;parameters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;b&amp;quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;l&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;learning_rate&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;grads&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;db&amp;quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;l&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)]&lt;/span&gt;

    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;parameters&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div class=&quot;codehilite&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;parameters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;grads&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;update_parameters_test_case&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;parameters&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;update_parameters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;parameters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;grads&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;W1 = &amp;quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;parameters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;W1&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]))&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;b1 = &amp;quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;parameters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;b1&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]))&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;W2 = &amp;quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;parameters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;W2&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]))&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;b2 = &amp;quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;parameters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;b2&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]))&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div class=&quot;codehilite&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;W1 = [[-0.59562069 -0.09991781 -2.14584584  1.82662008]
 [-1.76569676 -0.80627147  0.51115557 -1.18258802]
 [-1.0535704  -0.86128581  0.68284052  2.20374577]]
b1 = [[-0.04659241]
 [-1.28888275]
 [ 0.53405496]]
W2 = [[-0.55569196  0.0354055   1.32964895]]
b2 = [[-0.84610769]]
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;strong&gt;Expected Output&lt;/strong&gt;:&lt;/p&gt;
&lt;table style=&quot;width:100%&quot;&gt; 
    &lt;tr&gt;
    &lt;td &gt; W1 &lt;/td&gt; 
           &lt;td &gt; [[-0.59562069 -0.09991781 -2.14584584  1.82662008]
 [-1.76569676 -0.80627147  0.51115557 -1.18258802]
 [-1.0535704  -0.86128581  0.68284052  2.20374577]] &lt;/td&gt; 
  &lt;/tr&gt;

    &lt;tr&gt;
    &lt;td &gt; b1 &lt;/td&gt; 
           &lt;td &gt; [[-0.04659241]
 [-1.28888275]
 [ 0.53405496]] &lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt;
    &lt;td &gt; W2 &lt;/td&gt; 
           &lt;td &gt; [[-0.55569196  0.0354055   1.32964895]]&lt;/td&gt; 
  &lt;/tr&gt; 

    &lt;tr&gt;
    &lt;td &gt; b2 &lt;/td&gt; 
           &lt;td &gt; [[-0.84610769]] &lt;/td&gt; 
  &lt;/tr&gt; 
&lt;/table&gt;

&lt;h2 id=&quot;7-conclusion&quot;&gt;7 - Conclusion&lt;/h2&gt;
&lt;p&gt;Congrats on implementing all the functions required for building a deep neural network! &lt;/p&gt;
&lt;p&gt;We know it was a long assignment but going forward it will only get better. The next part of the assignment is easier. &lt;/p&gt;
&lt;p&gt;In the next assignment you will put all these together to build two models:
- A two-layer neural network
- An L-layer neural network&lt;/p&gt;
&lt;p&gt;You will in fact use these models to classify cat vs non-cat images!&lt;/p&gt;spark with scala - practice 3: degrees of separation
&lt;p&gt;Goal:&lt;/p&gt;
&lt;p&gt;Finds the degrees of separation between two Marvel comic book characters, based
on co-appearances in a comic&lt;/p&gt;
&lt;div class=&quot;codehilite&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;org.apache.spark._&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;org.apache.spark.SparkContext._&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;org.apache.spark.rdd._&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;org.apache.spark.Accumulator&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;org.apache.log4j&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;scala.collection.mutable.ArrayBuffer&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;blockquote&gt;
&lt;p&gt;&lt;pre&gt;
import org.apache.spark.&lt;em&gt;
import org.apache.spark.SparkContext.&lt;/em&gt;
import org.apache.spark.rdd._
import org.apache.spark.Accumulator
import org.apache.log4j
import scala.collection.mutable.ArrayBuffer&lt;/p&gt;
&lt;/blockquote&gt;
&lt;div class=&quot;codehilite&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;// the characters we want to find the separations between&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;startCharacterID&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;5306&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;// spiderman&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;targetCharacterID&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;14&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;// ADAM&lt;/span&gt;

  &lt;span class=&quot;k&quot;&gt;var&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;hitCounter&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;Option&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;Accumulator&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;Int&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;]]&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;None&lt;/span&gt;

  &lt;span class=&quot;c1&quot;&gt;// some custom data types&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;type&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;BFSData&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=(&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;Array&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;Int&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Int&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;String&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;type&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;BFSNode&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=(&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;Int&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;BFSData&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;blockquote&gt;
&lt;p&gt;&lt;pre&gt;
&lt;console&gt;:101: warning: class Accumulator in package spark is deprecated: use AccumulatorV2
         var hitCounter:Option[Accumulator[Int]]=None
                        ^
startCharacterID: Int = 5306
targetCharacterID: Int = 14
hitCounter: Option[org.apache.spark.Accumulator[Int]] = None
defined type alias BFSData
defined type alias BFSNode&lt;/p&gt;
&lt;/blockquote&gt;
&lt;div class=&quot;codehilite&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;c1&quot;&gt;// convert input line to bfsnode&lt;/span&gt;

  &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;convertToBFS&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;line&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;String&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;BFSNode&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;var&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;fields&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;line&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;split&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&amp;quot;\\s+&amp;quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;var&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;heroID&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fields&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;toInt&lt;/span&gt;

    &lt;span class=&quot;k&quot;&gt;var&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;connections&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;ArrayBuffer&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;Int&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;ArrayBuffer&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;()&lt;/span&gt;

    &lt;span class=&quot;c1&quot;&gt;// extarct subsequent superhero&amp;#39;s ID into connections&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;&amp;lt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;to&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fields&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;length&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;))&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
      &lt;span class=&quot;n&quot;&gt;connections&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fields&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;toInt&lt;/span&gt;
    &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;

    &lt;span class=&quot;k&quot;&gt;var&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;color&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;String&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&amp;quot;WHITE&amp;quot;&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;var&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;distance&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;Int&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;9999&lt;/span&gt;

    &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;heroID&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;==&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;startCharacterID&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
      &lt;span class=&quot;n&quot;&gt;color&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&amp;quot;GRAY&amp;quot;&lt;/span&gt;
      &lt;span class=&quot;n&quot;&gt;distance&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;
    &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;

    &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;heroID&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;connections&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;toArray&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;distance&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;color&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;))&lt;/span&gt;

  &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;blockquote&gt;
&lt;p&gt;&lt;pre&gt;
convertToBFS: (line: String)(Int, (Array[Int], Int, String))&lt;/p&gt;
&lt;/blockquote&gt;
&lt;div class=&quot;codehilite&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;createStartingRDD&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sc&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;SparkContext&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;RDD&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;BFSNode&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;inputFile&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sc&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;textFile&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&amp;quot;Marvel-graph.txt&amp;quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;inputFile&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;map&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;convertToBFS&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
  &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;blockquote&gt;
&lt;p&gt;&lt;pre&gt;
createStartingRDD: (sc: org.apache.spark.SparkContext)org.apache.spark.rdd.RDD[(Int, (Array[Int], Int, String))]&lt;/p&gt;
&lt;/blockquote&gt;
&lt;div class=&quot;codehilite&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;bfsMap&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;node&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;BFSNode&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;Array&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;BFSNode&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;characterID&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;Int&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;node&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;_1&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;BFSData&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;node&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;_2&lt;/span&gt;

    &lt;span class=&quot;k&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;connections&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;Array&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;Int&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;_1&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;distance&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;Int&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;_2&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;var&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;color&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;String&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;_3&lt;/span&gt;

    &lt;span class=&quot;k&quot;&gt;var&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;results&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;ArrayBuffer&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;BFSNode&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;ArrayBuffer&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;()&lt;/span&gt;

    &lt;span class=&quot;c1&quot;&gt;// mark gray nodes for expansion:&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;color&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;==&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&amp;quot;GRAY&amp;quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;){&lt;/span&gt;
      &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;connection&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;connections&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;newCharacterID&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;connection&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;newDistance&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;distance&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;newColor&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&amp;quot;GRAY&amp;quot;&lt;/span&gt;

        &lt;span class=&quot;c1&quot;&gt;// reach the goal yet?&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;targetCharacterID&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;==&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;newCharacterID&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
          &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;hitCounter&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;isDefined&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;hitCounter&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;get&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;add&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
          &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
        &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;

        &lt;span class=&quot;c1&quot;&gt;// create a new node for this connection and add it to the results&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;newEntry&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;BFSNode&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;newCharacterID&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;Array&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;newDistance&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;newColor&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;))&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;results&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;newEntry&lt;/span&gt;
      &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;

      &lt;span class=&quot;c1&quot;&gt;// now the data has been processed, mark it black (black - processed, gray - to-be-processed)&lt;/span&gt;
      &lt;span class=&quot;c1&quot;&gt;// thus, remember to mark color as var after it is declared&lt;/span&gt;
      &lt;span class=&quot;n&quot;&gt;color&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&amp;quot;BLACK&amp;quot;&lt;/span&gt;
    &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
      &lt;span class=&quot;c1&quot;&gt;// after all its neighbours have been processed, mark the parent point and add to result&lt;/span&gt;
      &lt;span class=&quot;k&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;thisEntry&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;BFSNode&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;characterID&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;connections&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;distance&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;color&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;))&lt;/span&gt;
      &lt;span class=&quot;n&quot;&gt;results&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;thisEntry&lt;/span&gt;

    &lt;span class=&quot;n&quot;&gt;results&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;toArray&lt;/span&gt;
  &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;blockquote&gt;
&lt;p&gt;&lt;pre&gt;
bfsMap: (node: (Int, (Array[Int], Int, String)))Array[(Int, (Array[Int], Int, String))]&lt;/p&gt;
&lt;/blockquote&gt;
&lt;div class=&quot;codehilite&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;bfsReduce&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data1&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;BFSData&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;data2&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;BFSData&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;BFSData&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;

    &lt;span class=&quot;c1&quot;&gt;// Extract data that we are combining&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;edges1&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;Array&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;Int&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;data1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;_1&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;edges2&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;Array&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;Int&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;data2&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;_1&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;distance1&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;Int&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;data1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;_2&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;distance2&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;Int&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;data2&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;_2&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;color1&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;String&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;data1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;_3&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;color2&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;String&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;data2&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;_3&lt;/span&gt;

    &lt;span class=&quot;c1&quot;&gt;// Default node values&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;var&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;distance&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;Int&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;9999&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;var&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;color&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;String&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&amp;quot;WHITE&amp;quot;&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;var&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;edges&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;ArrayBuffer&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;Int&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;ArrayBuffer&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;()&lt;/span&gt;

    &lt;span class=&quot;c1&quot;&gt;// See if one is the original node with its connections.&lt;/span&gt;
    &lt;span class=&quot;c1&quot;&gt;// If so preserve them.&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;edges1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;length&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
      &lt;span class=&quot;n&quot;&gt;edges&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;++=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;edges1&lt;/span&gt;
    &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;edges2&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;length&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
      &lt;span class=&quot;n&quot;&gt;edges&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;++=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;edges2&lt;/span&gt;
    &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;

    &lt;span class=&quot;c1&quot;&gt;// Preserve minimum distance&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;distance1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;distance&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
      &lt;span class=&quot;n&quot;&gt;distance&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;distance1&lt;/span&gt;
    &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;distance2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;distance&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
      &lt;span class=&quot;n&quot;&gt;distance&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;distance2&lt;/span&gt;
    &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;

    &lt;span class=&quot;c1&quot;&gt;// Preserve darkest color&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;color1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&amp;quot;WHITE&amp;quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;amp;&amp;amp;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;color2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&amp;quot;GRAY&amp;quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;||&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;color2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&amp;quot;BLACK&amp;quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;))&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
      &lt;span class=&quot;n&quot;&gt;color&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;color2&lt;/span&gt;
    &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;color1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&amp;quot;GRAY&amp;quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;amp;&amp;amp;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;color2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&amp;quot;BLACK&amp;quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
      &lt;span class=&quot;n&quot;&gt;color&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;color2&lt;/span&gt;
    &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;color2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&amp;quot;WHITE&amp;quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;amp;&amp;amp;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;color1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&amp;quot;GRAY&amp;quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;||&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;color1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&amp;quot;BLACK&amp;quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;))&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
      &lt;span class=&quot;n&quot;&gt;color&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;color1&lt;/span&gt;
    &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;color2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&amp;quot;GRAY&amp;quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;amp;&amp;amp;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;color1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&amp;quot;BLACK&amp;quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
      &lt;span class=&quot;n&quot;&gt;color&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;color1&lt;/span&gt;
    &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;

    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;edges&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;toArray&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;distance&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;color&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
  &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;blockquote&gt;
&lt;p&gt;&lt;pre&gt;
bfsReduce: (data1: (Array[Int], Int, String), data2: (Array[Int], Int, String))(Array[Int], Int, String)&lt;/p&gt;
&lt;/blockquote&gt;
&lt;div class=&quot;codehilite&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;hitCounter&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Some&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sc&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;longAccumulator&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&amp;quot;Hit Counter&amp;quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;))&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;blockquote&gt;
&lt;p&gt;&lt;pre&gt;
&lt;console&gt;:97: error: type mismatch;
 found   : org.apache.spark.util.LongAccumulator
 required: org.apache.spark.Accumulator[Int]
       hitCounter = Some(sc.longAccumulator(&quot;Hit Counter&quot;))
                                           ^&lt;/p&gt;
&lt;/blockquote&gt;
&lt;div class=&quot;codehilite&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;var&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;iterationRDD&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;createStartingRDD&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sc&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;blockquote&gt;
&lt;p&gt;&lt;pre&gt;
iterationRDD: org.apache.spark.rdd.RDD[(Int, (Array[Int], Int, String))] = MapPartitionsRDD[7] at map at &lt;console&gt;:105&lt;/p&gt;
&lt;/blockquote&gt;
&lt;div class=&quot;codehilite&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;iterationRDD&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;collect&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;()&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;blockquote&gt;
&lt;p&gt;&lt;pre&gt;
res27: Array[(Int, (Array[Int], Int, String))] = Array((5988,(Array(748, 1722, 3752, 4655, 5743, 1872, 3413, 5527, 6368, 6085, 4319, 4728, 1636, 2397, 3364, 4001, 1614, 1819, 1585, 732, 2660, 3952, 2507, 3891, 2070, 2239, 2602, 612, 1352, 5447, 4548, 1596, 5488, 1605, 5517, 11, 479, 2554, 2043, 17, 865, 4292, 6312, 473, 534, 1479, 6375, 4456),9999,WHITE)), (5989,(Array(4080, 4264, 4446, 3779, 2430, 2297, 6169, 3530, 3272, 4282, 6432, 2548, 4140, 185, 105, 3878, 2429, 1334, 4595, 2767, 3956, 3877, 4776, 4946, 3407, 128, 269, 5775, 5121, 481, 5516, 4758, 4053, 1044, 1602, 3889, 1535, 6038, 533, 3986),9999,WHITE)), (5982,(Array(217, 595, 1194, 3308, 2940, 1815, 794, 1503, 5197, 859, 5096, 6039, 2664, 651, 2244, 528, 284, 1449, 1097, 1172, 1092, 108, 3405, 5204, 387, 4607, 4545, 3705, 4930,...&lt;/p&gt;
&lt;/blockquote&gt;
&lt;div class=&quot;codehilite&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;iterationRDD&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;map&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;=&amp;gt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;_2&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;collect&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;()&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;blockquote&gt;
&lt;p&gt;&lt;pre&gt;
res29: Array[(Array[Int], Int, String)] = Array((Array(748, 1722, 3752, 4655, 5743, 1872, 3413, 5527, 6368, 6085, 4319, 4728, 1636, 2397, 3364, 4001, 1614, 1819, 1585, 732, 2660, 3952, 2507, 3891, 2070, 2239, 2602, 612, 1352, 5447, 4548, 1596, 5488, 1605, 5517, 11, 479, 2554, 2043, 17, 865, 4292, 6312, 473, 534, 1479, 6375, 4456),9999,WHITE), (Array(4080, 4264, 4446, 3779, 2430, 2297, 6169, 3530, 3272, 4282, 6432, 2548, 4140, 185, 105, 3878, 2429, 1334, 4595, 2767, 3956, 3877, 4776, 4946, 3407, 128, 269, 5775, 5121, 481, 5516, 4758, 4053, 1044, 1602, 3889, 1535, 6038, 533, 3986),9999,WHITE), (Array(217, 595, 1194, 3308, 2940, 1815, 794, 1503, 5197, 859, 5096, 6039, 2664, 651, 2244, 528, 284, 1449, 1097, 1172, 1092, 108, 3405, 5204, 387, 4607, 4545, 3705, 4930, 1805, 4712, 4404, 247, 475...&lt;/p&gt;
&lt;/blockquote&gt;
&lt;div class=&quot;codehilite&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;var&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;iteration&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;Int&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;blockquote&gt;
&lt;p&gt;&lt;pre&gt;
iteration: Int = 0&lt;/p&gt;
&lt;/blockquote&gt;
&lt;div class=&quot;codehilite&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;iter&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;to&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
      &lt;span class=&quot;k&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mapped&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;iterationRDD&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;flatMap&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;bfsMap&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;

      &lt;span class=&quot;n&quot;&gt;println&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&amp;quot;processing &amp;quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mapped&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;count&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;()+&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&amp;quot; values.&amp;quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;

      &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;hitCounter&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;isDefined&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;hitCount&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;hitCounter&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;get&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;value&lt;/span&gt;

        &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;hitCount&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
          &lt;span class=&quot;n&quot;&gt;println&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&amp;quot;target reached!&amp;quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
      &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;

      &lt;span class=&quot;n&quot;&gt;iterationRDD&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mapped&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;reduceByKey&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;bfsReduce&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;

    &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;blockquote&gt;
&lt;p&gt;&lt;pre&gt;
processing 8330 values.
processing 220615 values.
processing 74146 values.
processing 34457 values.
processing 18830 values.
processing 11539 values.
processing 8368 values.
processing 7025 values.
processing 6638 values.
processing 6486 values.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;div class=&quot;codehilite&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;iterationRDD&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;collect&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;().&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;take&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;blockquote&gt;
&lt;p&gt;&lt;pre&gt;
res36: Array[(Int, (Array[Int], Int, String))] = Array((4904,(Array(5306, 880, 2639, 2031, 3805, 2923, 2650, 3632, 3601, 4240, 859, 133, 6168, 3907, 4015, 3329, 5504, 6283, 3670, 3652, 1050, 4801, 3231, 2340, 1773, 957, 1853, 6300, 5725, 2658, 1039, 522, 3802, 189, 3495, 6366, 1602, 5002, 632, 619, 6148, 5931, 2842, 3950, 6273, 3633, 5756, 5046, 1127, 3052, 5516, 4733, 4684, 967, 4871, 842, 2557, 5716, 2081, 1029, 4395, 867, 1381, 2390, 6235, 824, 1299, 4650),1,BLACK)), (1084,(Array(2713, 2659, 2548, 2960, 668, 3066, 2650, 768, 578, 5477, 2096, 135, 3329, 6084, 1196, 4212, 4707, 4908, 5823, 4704, 4703, 2746, 1773, 3550, 3122, 3794, 3712, 6066, 4670, 818, 3187, 403, 545, 1379, 2245, 2016, 285, 1317, 3495, 1313, 3832, 1310, 5388, 2852, 670, 1319, 1490, 3134, 5303, 5757, 3211, 5467, 1561, ...&lt;/p&gt;
&lt;/blockquote&gt;deeplearning.ai - Neural Networks and Deep Learning - Week 3 Assignment
&lt;h1 id=&quot;planar-data-classification-with-one-hidden-layer&quot;&gt;Planar data classification with one hidden layer&lt;/h1&gt;
&lt;p&gt;Welcome to your week 3 programming assignment. It&#39;s time to build your first neural network, which will have a hidden layer. You will see a big difference between this model and the one you implemented using logistic regression. &lt;/p&gt;
&lt;p&gt;&lt;strong&gt;You will learn how to:&lt;/strong&gt;
- Implement a 2-class classification neural network with a single hidden layer
- Use units with a non-linear activation function, such as tanh 
- Compute the cross entropy loss 
- Implement forward and backward propagation&lt;/p&gt;
&lt;h2 id=&quot;1-packages&quot;&gt;1 - Packages&lt;/h2&gt;
&lt;p&gt;Let&#39;s first import all the packages that you will need during this assignment.
- &lt;a href=&quot;www.numpy.org&quot;&gt;numpy&lt;/a&gt; is the fundamental package for scientific computing with Python.
- &lt;a href=&quot;http://scikit-learn.org/stable/&quot;&gt;sklearn&lt;/a&gt; provides simple and efficient tools for data mining and data analysis. 
- &lt;a href=&quot;http://matplotlib.org&quot;&gt;matplotlib&lt;/a&gt; is a library for plotting graphs in Python.
- testCases provides some test examples to assess the correctness of your functions
- planar_utils provide various useful functions used in this assignment&lt;/p&gt;
&lt;div class=&quot;codehilite&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;c1&quot;&gt;# Package imports&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;numpy&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;np&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;matplotlib.pyplot&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;plt&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;testCases_v2&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;sklearn&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;sklearn.datasets&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;sklearn.linear_model&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;planar_utils&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;plot_decision_boundary&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sigmoid&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;load_planar_dataset&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;load_extra_datasets&lt;/span&gt;

&lt;span class=&quot;o&quot;&gt;%&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;matplotlib&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;inline&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;random&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;seed&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;# set a seed so that the results are consistent&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;h2 id=&quot;2-dataset&quot;&gt;2 - Dataset&lt;/h2&gt;
&lt;p&gt;First, let&#39;s get the dataset you will work on. The following code will load a &quot;flower&quot; 2-class dataset into variables &lt;code&gt;X&lt;/code&gt; and &lt;code&gt;Y&lt;/code&gt;.&lt;/p&gt;
&lt;div class=&quot;codehilite&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Y&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;load_planar_dataset&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Visualize the dataset using matplotlib. The data looks like a &quot;flower&quot; with some red (label y=0) and some blue (y=1) points. Your goal is to build a model to fit this data. &lt;/p&gt;
&lt;div class=&quot;codehilite&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;c1&quot;&gt;# Visualize the data:&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;scatter&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;:],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;:],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;c&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;s&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;40&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cmap&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cm&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Spectral&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;img alt=&quot;png&quot; src=&quot;https://raw.githubusercontent.com/karenyyy/Coursera_and_Udemy/master/deeplearningai_coursera/Neural_Networks_and_Deep_Learning/images/week3/output_6_0.png&quot; /&gt;&lt;/p&gt;
&lt;p&gt;You have:
    - a numpy-array (matrix) X that contains your features (x1, x2)
    - a numpy-array (vector) Y that contains your labels (red:0, blue:1).&lt;/p&gt;
&lt;p&gt;Lets first get a better sense of what our data is like. &lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Exercise&lt;/strong&gt;: How many training examples do you have? In addition, what is the &lt;code&gt;shape&lt;/code&gt; of the variables &lt;code&gt;X&lt;/code&gt; and &lt;code&gt;Y&lt;/code&gt;? &lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Hint&lt;/strong&gt;: How do you get the shape of a numpy array? &lt;a href=&quot;https://docs.scipy.org/doc/numpy/reference/generated/numpy.ndarray.shape.html&quot;&gt;(help)&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;codehilite&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape_X&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;shape_Y&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Y&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;m&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# training set size&lt;/span&gt;


&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;The shape of X is: &amp;#39;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape_X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;The shape of Y is: &amp;#39;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape_Y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;I have m = &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;%d&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt; training examples!&amp;#39;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;%&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;m&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div class=&quot;codehilite&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;The shape of X is: (2, 400)
The shape of Y is: (1, 400)
I have m = 400 training examples!
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;strong&gt;Expected Output&lt;/strong&gt;:&lt;/p&gt;
&lt;table style=&quot;width:20%&quot;&gt;

  &lt;tr&gt;
    &lt;td&gt;**shape of X**&lt;/td&gt;
    &lt;td&gt; (2, 400) &lt;/td&gt; 
  &lt;/tr&gt;

  &lt;tr&gt;
    &lt;td&gt;**shape of Y**&lt;/td&gt;
    &lt;td&gt;(1, 400) &lt;/td&gt; 
  &lt;/tr&gt;

    &lt;tr&gt;
    &lt;td&gt;**m**&lt;/td&gt;
    &lt;td&gt; 400 &lt;/td&gt; 
  &lt;/tr&gt;

&lt;/table&gt;

&lt;h2 id=&quot;3-simple-logistic-regression&quot;&gt;3 - Simple Logistic Regression&lt;/h2&gt;
&lt;p&gt;Before building a full neural network, lets first see how logistic regression performs on this problem. You can use sklearn&#39;s built-in functions to do that. Run the code below to train a logistic regression classifier on the dataset.&lt;/p&gt;
&lt;div class=&quot;codehilite&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;c1&quot;&gt;# Train the logistic regression classifier&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;clf&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sklearn&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;linear_model&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;LogisticRegressionCV&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;();&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;clf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fit&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;T&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Y&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;T&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div class=&quot;codehilite&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;/opt/conda/lib/python3.5/site-packages/sklearn/utils/validation.py:515: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;You can now plot the decision boundary of these models. Run the code below.&lt;/p&gt;
&lt;div class=&quot;codehilite&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;c1&quot;&gt;# Plot the decision boundary for logistic regression&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;plot_decision_boundary&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;lambda&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;clf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;predict&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;title&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;Logistic Regression&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Print accuracy&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;LR_predictions&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;clf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;predict&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;T&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;Accuracy of logistic regression: &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;%d&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt; &amp;#39;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;%&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;float&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;((&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;LR_predictions&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;LR_predictions&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;float&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Y&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;100&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;
       &lt;span class=&quot;s1&quot;&gt;&amp;#39;% &amp;#39;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&amp;quot;(percentage of correctly labelled datapoints)&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div class=&quot;codehilite&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;Accuracy of logistic regression: 47 % (percentage of correctly labelled datapoints)
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;img alt=&quot;png&quot; src=&quot;https://raw.githubusercontent.com/karenyyy/Coursera_and_Udemy/master/deeplearningai_coursera/Neural_Networks_and_Deep_Learning/images/week3/output_13_1.png&quot; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Expected Output&lt;/strong&gt;:&lt;/p&gt;
&lt;table style=&quot;width:20%&quot;&gt;
  &lt;tr&gt;
    &lt;td&gt;**Accuracy**&lt;/td&gt;
    &lt;td&gt; 47% &lt;/td&gt; 
  &lt;/tr&gt;

&lt;/table&gt;

&lt;p&gt;&lt;strong&gt;Interpretation&lt;/strong&gt;: The dataset is not linearly separable, so logistic regression doesn&#39;t perform well. Hopefully a neural network will do better. Let&#39;s try this now! &lt;/p&gt;
&lt;h2 id=&quot;4-neural-network-model&quot;&gt;4 - Neural Network model&lt;/h2&gt;
&lt;p&gt;Logistic regression did not work well on the &quot;flower dataset&quot;. You are going to train a Neural Network with a single hidden layer.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Here is our model&lt;/strong&gt;:
&lt;img src=&quot;https://raw.githubusercontent.com/karenyyy/Coursera_and_Udemy/master/deeplearningai_coursera/Neural_Networks_and_Deep_Learning/images/week3/classification_kiank.png&quot; style=&quot;width:600px;height:300px;&quot;&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Mathematically&lt;/strong&gt;:&lt;/p&gt;
&lt;p&gt;For one example $x^{(i)}$:
$$z^{[1] (i)} =  W^{[1]} x^{(i)} + b^{[1]}\tag{1}$$ 
$$a^{[1] (i)} = \tanh(z^{[1] (i)})\tag{2}$$
$$z^{[2] (i)} = W^{[2]} a^{[1] (i)} + b^{[2]}\tag{3}$$
$$\hat{y}^{(i)} = a^{[2] (i)} = \sigma(z^{ [2] (i)})\tag{4}$$
$$y^{(i)}_{prediction} = \begin{cases} 1 &amp;amp; \mbox{if } a^{&lt;a href=&quot;i&quot;&gt;2&lt;/a&gt;} &amp;gt; 0.5 \ 0 &amp;amp; \mbox{otherwise } \end{cases}\tag{5}$$&lt;/p&gt;
&lt;p&gt;Given the predictions on all the examples, you can also compute the cost $J$ as follows: 
$$J = - \frac{1}{m} \sum\limits_{i = 0}^{m} \large\left(\small y^{(i)}\log\left(a^{[2] (i)}\right) + (1-y^{(i)})\log\left(1- a^{[2] (i)}\right)  \large  \right) \small \tag{6}$$&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Reminder&lt;/strong&gt;: The general methodology to build a Neural Network is to:
    1. Define the neural network structure ( # of input units,  # of hidden units, etc). 
    2. Initialize the model&#39;s parameters
    3. Loop:
        - Implement forward propagation
        - Compute loss
        - Implement backward propagation to get the gradients
        - Update parameters (gradient descent)&lt;/p&gt;
&lt;p&gt;You often build helper functions to compute steps 1-3 and then merge them into one function we call &lt;code&gt;nn_model()&lt;/code&gt;. Once you&#39;ve built &lt;code&gt;nn_model()&lt;/code&gt; and learnt the right parameters, you can make predictions on new data.&lt;/p&gt;
&lt;h3 id=&quot;41-defining-the-neural-network-structure&quot;&gt;4.1 - Defining the neural network structure&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;Exercise&lt;/strong&gt;: Define three variables:
    - n_x: the size of the input layer
    - n_h: the size of the hidden layer (set this to 4) 
    - n_y: the size of the output layer&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Hint&lt;/strong&gt;: Use shapes of X and Y to find n_x and n_y. Also, hard code the hidden layer size to be 4.&lt;/p&gt;
&lt;div class=&quot;codehilite&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;c1&quot;&gt;# GRADED FUNCTION: layer_sizes&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;layer_sizes&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;sd&quot;&gt;&amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    Arguments:&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    X -- input dataset of shape (input size, number of examples)&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    Y -- labels of shape (output size, number of examples)&lt;/span&gt;

&lt;span class=&quot;sd&quot;&gt;    Returns:&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    n_x -- the size of the input layer&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    n_h -- the size of the hidden layer&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    n_y -- the size of the output layer&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    &amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;

    &lt;span class=&quot;n&quot;&gt;n_x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;# size of input layer&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;n_h&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;n_y&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Y&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;# size of output layer&lt;/span&gt;

    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n_x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n_h&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n_y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div class=&quot;codehilite&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X_assess&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Y_assess&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;layer_sizes_test_case&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n_x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n_h&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n_y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;layer_sizes&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X_assess&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Y_assess&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;The size of the input layer is: n_x = &amp;quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n_x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;The size of the hidden layer is: n_h = &amp;quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n_h&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;The size of the output layer is: n_y = &amp;quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n_y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div class=&quot;codehilite&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;The size of the input layer is: n_x = 5
The size of the hidden layer is: n_h = 4
The size of the output layer is: n_y = 2
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;strong&gt;Expected Output&lt;/strong&gt; (these are not the sizes you will use for your network, they are just used to assess the function you&#39;ve just coded).&lt;/p&gt;
&lt;table style=&quot;width:20%&quot;&gt;
  &lt;tr&gt;
    &lt;td&gt;**n_x**&lt;/td&gt;
    &lt;td&gt; 5 &lt;/td&gt; 
  &lt;/tr&gt;

    &lt;tr&gt;
    &lt;td&gt;**n_h**&lt;/td&gt;
    &lt;td&gt; 4 &lt;/td&gt; 
  &lt;/tr&gt;

    &lt;tr&gt;
    &lt;td&gt;**n_y**&lt;/td&gt;
    &lt;td&gt; 2 &lt;/td&gt; 
  &lt;/tr&gt;

&lt;/table&gt;

&lt;h3 id=&quot;42-initialize-the-models-parameters&quot;&gt;4.2 - Initialize the model&#39;s parameters&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;Exercise&lt;/strong&gt;: Implement the function &lt;code&gt;initialize_parameters()&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Instructions&lt;/strong&gt;:
- Make sure your parameters&#39; sizes are right. Refer to the neural network figure above if needed.
- You will initialize the weights matrices with random values. 
    - Use: &lt;code&gt;np.random.randn(a,b) * 0.01&lt;/code&gt; to randomly initialize a matrix of shape (a,b).
- You will initialize the bias vectors as zeros. 
    - Use: &lt;code&gt;np.zeros((a,b))&lt;/code&gt; to initialize a matrix of shape (a,b) with zeros.&lt;/p&gt;
&lt;div class=&quot;codehilite&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;c1&quot;&gt;# GRADED FUNCTION: initialize_parameters&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;initialize_parameters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n_x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n_h&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n_y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;sd&quot;&gt;&amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    Argument:&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    n_x -- size of the input layer&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    n_h -- size of the hidden layer&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    n_y -- size of the output layer&lt;/span&gt;

&lt;span class=&quot;sd&quot;&gt;    Returns:&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    params -- python dictionary containing your parameters:&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;                    W1 -- weight matrix of shape (n_h, n_x)&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;                    b1 -- bias vector of shape (n_h, 1)&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;                    W2 -- weight matrix of shape (n_y, n_h)&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;                    b2 -- bias vector of shape (n_y, 1)&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    &amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;

    &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;random&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;seed&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;# we set up a seed so that your output matches ours although the initialization is random.&lt;/span&gt;


    &lt;span class=&quot;n&quot;&gt;W1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;random&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;randn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n_h&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n_x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.01&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;b1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;zeros&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;((&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n_h&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;W2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;random&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;randn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n_y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n_h&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.01&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;b2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;zeros&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;((&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n_y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;


    &lt;span class=&quot;k&quot;&gt;assert&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;W1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n_h&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n_x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;assert&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;b1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n_h&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;assert&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;W2&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n_y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n_h&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;assert&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;b2&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n_y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;

    &lt;span class=&quot;n&quot;&gt;parameters&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;W1&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;W1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                  &lt;span class=&quot;s2&quot;&gt;&amp;quot;b1&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;b1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                  &lt;span class=&quot;s2&quot;&gt;&amp;quot;W2&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;W2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                  &lt;span class=&quot;s2&quot;&gt;&amp;quot;b2&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;b2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;

    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;parameters&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div class=&quot;codehilite&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n_x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n_h&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n_y&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;initialize_parameters_test_case&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;parameters&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;initialize_parameters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n_x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n_h&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n_y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;W1 = &amp;quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;parameters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;W1&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]))&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;b1 = &amp;quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;parameters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;b1&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]))&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;W2 = &amp;quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;parameters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;W2&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]))&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;b2 = &amp;quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;parameters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;b2&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]))&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div class=&quot;codehilite&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;W1 = [[-0.00416758 -0.00056267]
 [-0.02136196  0.01640271]
 [-0.01793436 -0.00841747]
 [ 0.00502881 -0.01245288]]
b1 = [[ 0.]
 [ 0.]
 [ 0.]
 [ 0.]]
W2 = [[-0.01057952 -0.00909008  0.00551454  0.02292208]]
b2 = [[ 0.]]
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;strong&gt;Expected Output&lt;/strong&gt;:&lt;/p&gt;
&lt;table style=&quot;width:90%&quot;&gt;
  &lt;tr&gt;
    &lt;td&gt;**W1**&lt;/td&gt;
    &lt;td&gt; [[-0.00416758 -0.00056267]
 [-0.02136196  0.01640271]
 [-0.01793436 -0.00841747]
 [ 0.00502881 -0.01245288]] &lt;/td&gt; 
  &lt;/tr&gt;

  &lt;tr&gt;
    &lt;td&gt;**b1**&lt;/td&gt;
    &lt;td&gt; [[ 0.]
 [ 0.]
 [ 0.]
 [ 0.]] &lt;/td&gt; 
  &lt;/tr&gt;

  &lt;tr&gt;
    &lt;td&gt;**W2**&lt;/td&gt;
    &lt;td&gt; [[-0.01057952 -0.00909008  0.00551454  0.02292208]]&lt;/td&gt; 
  &lt;/tr&gt;


  &lt;tr&gt;
    &lt;td&gt;**b2**&lt;/td&gt;
    &lt;td&gt; [[ 0.]] &lt;/td&gt; 
  &lt;/tr&gt;

&lt;/table&gt;

&lt;h3 id=&quot;43-the-loop&quot;&gt;4.3 - The Loop&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;Question&lt;/strong&gt;: Implement &lt;code&gt;forward_propagation()&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Instructions&lt;/strong&gt;:
- Look above at the mathematical representation of your classifier.
- You can use the function &lt;code&gt;sigmoid()&lt;/code&gt;. It is built-in (imported) in the notebook.
- You can use the function &lt;code&gt;np.tanh()&lt;/code&gt;. It is part of the numpy library.
- The steps you have to implement are:
    1. Retrieve each parameter from the dictionary &quot;parameters&quot; (which is the output of &lt;code&gt;initialize_parameters()&lt;/code&gt;) by using &lt;code&gt;parameters[&quot;..&quot;]&lt;/code&gt;.
    2. Implement Forward Propagation. Compute $Z^{[1]}, A^{[1]}, Z^{[2]}$ and $A^{[2]}$ (the vector of all your predictions on all the examples in the training set).
- Values needed in the backpropagation are stored in &quot;&lt;code&gt;cache&lt;/code&gt;&quot;. The &lt;code&gt;cache&lt;/code&gt; will be given as an input to the backpropagation function.&lt;/p&gt;
&lt;div class=&quot;codehilite&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;c1&quot;&gt;# GRADED FUNCTION: forward_propagation&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;forward_propagation&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;parameters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;sd&quot;&gt;&amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    Argument:&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    X -- input data of size (n_x, m)&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    parameters -- python dictionary containing your parameters (output of initialization function)&lt;/span&gt;

&lt;span class=&quot;sd&quot;&gt;    Returns:&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    A2 -- The sigmoid output of the second activation&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    cache -- a dictionary containing &amp;quot;Z1&amp;quot;, &amp;quot;A1&amp;quot;, &amp;quot;Z2&amp;quot; and &amp;quot;A2&amp;quot;&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    &amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;
    &lt;span class=&quot;c1&quot;&gt;# Retrieve each parameter from the dictionary &amp;quot;parameters&amp;quot;&lt;/span&gt;

    &lt;span class=&quot;n&quot;&gt;W1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;parameters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;W1&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;b1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;parameters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;b1&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;W2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;parameters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;W2&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;b2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;parameters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;b2&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;


    &lt;span class=&quot;c1&quot;&gt;# Implement Forward Propagation to calculate A2 (probabilities)&lt;/span&gt;

    &lt;span class=&quot;n&quot;&gt;Z1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;W1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;b1&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;A1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tanh&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Z1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;Z2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;W2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;A1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;b2&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;A2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sigmoid&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Z2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;


    &lt;span class=&quot;k&quot;&gt;assert&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;A2&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]))&lt;/span&gt;

    &lt;span class=&quot;n&quot;&gt;cache&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;Z1&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Z1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
             &lt;span class=&quot;s2&quot;&gt;&amp;quot;A1&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;A1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
             &lt;span class=&quot;s2&quot;&gt;&amp;quot;Z2&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Z2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
             &lt;span class=&quot;s2&quot;&gt;&amp;quot;A2&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;A2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;

    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;A2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cache&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div class=&quot;codehilite&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X_assess&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;parameters&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;forward_propagation_test_case&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;A2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cache&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;forward_propagation&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X_assess&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;parameters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Note: we use the mean here just to make sure that your output matches ours. &lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mean&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cache&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;Z1&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mean&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cache&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;A1&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]),&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mean&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cache&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;Z2&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]),&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mean&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cache&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;A2&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]))&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div class=&quot;codehilite&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;0.262818640198 0.091999045227 -1.30766601287 0.212877681719
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;strong&gt;Expected Output&lt;/strong&gt;:
&lt;table style=&quot;width:50%&quot;&gt;
  &lt;tr&gt;
    &lt;td&gt; 0.262818640198 0.091999045227 -1.30766601287 0.212877681719 &lt;/td&gt; 
  &lt;/tr&gt;
&lt;/table&gt;&lt;/p&gt;
&lt;p&gt;Now that you have computed $A^{[2]}$ (in the Python variable &quot;&lt;code&gt;A2&lt;/code&gt;&quot;), which contains $a^{&lt;a href=&quot;i&quot;&gt;2&lt;/a&gt;}$ for every example, you can compute the cost function as follows:&lt;/p&gt;
&lt;p&gt;$$J = - \frac{1}{m} \sum\limits_{i = 0}^{m} \large{(} \small y^{(i)}\log\left(a^{[2] (i)}\right) + (1-y^{(i)})\log\left(1- a^{[2] (i)}\right) \large{)} \small\tag{13}$$&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Exercise&lt;/strong&gt;: Implement &lt;code&gt;compute_cost()&lt;/code&gt; to compute the value of the cost $J$.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Instructions&lt;/strong&gt;:
- There are many ways to implement the cross-entropy loss. To help you, we give you how we would have implemented
$- \sum\limits_{i=0}^{m}  y^{(i)}\log(a^{&lt;a href=&quot;i&quot;&gt;2&lt;/a&gt;})$:&lt;/p&gt;
&lt;div class=&quot;codehilite&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;logprobs&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;multiply&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;log&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;A2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;cost&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;logprobs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;                &lt;span class=&quot;c1&quot;&gt;# no need to use a for loop!&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;(you can use either &lt;code&gt;np.multiply()&lt;/code&gt; and then &lt;code&gt;np.sum()&lt;/code&gt; or directly &lt;code&gt;np.dot()&lt;/code&gt;).&lt;/p&gt;
&lt;div class=&quot;codehilite&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;c1&quot;&gt;# GRADED FUNCTION: compute_cost&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;compute_cost&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;A2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;parameters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;sd&quot;&gt;&amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    Computes the cross-entropy cost given in equation (13)&lt;/span&gt;

&lt;span class=&quot;sd&quot;&gt;    Arguments:&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    A2 -- The sigmoid output of the second activation, of shape (1, number of examples)&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    Y -- &amp;quot;true&amp;quot; labels vector of shape (1, number of examples)&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    parameters -- python dictionary containing your parameters W1, b1, W2 and b2&lt;/span&gt;

&lt;span class=&quot;sd&quot;&gt;    Returns:&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    cost -- cross-entropy cost given equation (13)&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    &amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;

    &lt;span class=&quot;n&quot;&gt;m&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Y&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;# number of example&lt;/span&gt;

    &lt;span class=&quot;c1&quot;&gt;# Compute the cross-entropy cost&lt;/span&gt;

    &lt;span class=&quot;n&quot;&gt;logprobs&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;multiply&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;log&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;A2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;multiply&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;log&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;A2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;cost&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;logprobs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;m&lt;/span&gt;


    &lt;span class=&quot;n&quot;&gt;cost&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;squeeze&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cost&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;     &lt;span class=&quot;c1&quot;&gt;# makes sure cost is the dimension we expect. &lt;/span&gt;
                                &lt;span class=&quot;c1&quot;&gt;# E.g., turns [[17]] into 17 &lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;assert&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;isinstance&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cost&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;float&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;

    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cost&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div class=&quot;codehilite&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;A2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Y_assess&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;parameters&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;compute_cost_test_case&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;cost = &amp;quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;compute_cost&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;A2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Y_assess&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;parameters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)))&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div class=&quot;codehilite&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;cost = 0.693058761039
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;strong&gt;Expected Output&lt;/strong&gt;:
&lt;table style=&quot;width:20%&quot;&gt;
  &lt;tr&gt;
    &lt;td&gt;&lt;strong&gt;cost&lt;/strong&gt;&lt;/td&gt;
    &lt;td&gt; 0.693058761... &lt;/td&gt; 
  &lt;/tr&gt;&lt;/p&gt;
&lt;/table&gt;

&lt;p&gt;Using the cache computed during forward propagation, you can now implement backward propagation.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Question&lt;/strong&gt;: Implement the function &lt;code&gt;backward_propagation()&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Instructions&lt;/strong&gt;:
Backpropagation is usually the hardest (most mathematical) part in deep learning. To help you, here again is the slide from the lecture on backpropagation. You&#39;ll want to use the six equations on the right of this slide, since you are building a vectorized implementation.  &lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/karenyyy/Coursera_and_Udemy/master/deeplearningai_coursera/Neural_Networks_and_Deep_Learning/images/week3/grad_summary.png&quot; style=&quot;width:600px;height:300px;&quot;&gt;&lt;/p&gt;
&lt;!--
$\frac{\partial \mathcal{J} }{ \partial z_{2}^{(i)} } = \frac{1}{m} (a^{[2](i)} - y^{(i)})$

$\frac{\partial \mathcal{J} }{ \partial W_2 } = \frac{\partial \mathcal{J} }{ \partial z_{2}^{(i)} } a^{[1] (i) T} $

$\frac{\partial \mathcal{J} }{ \partial b_2 } = \sum_i{\frac{\partial \mathcal{J} }{ \partial z_{2}^{(i)}}}$

$\frac{\partial \mathcal{J} }{ \partial z_{1}^{(i)} } =  W_2^T \frac{\partial \mathcal{J} }{ \partial z_{2}^{(i)} } * ( 1 - a^{[1] (i) 2}) $

$\frac{\partial \mathcal{J} }{ \partial W_1 } = \frac{\partial \mathcal{J} }{ \partial z_{1}^{(i)} }  X^T $

$\frac{\partial \mathcal{J} _i }{ \partial b_1 } = \sum_i{\frac{\partial \mathcal{J} }{ \partial z_{1}^{(i)}}}$

- Note that $*$ denotes elementwise multiplication.
- The notation you will use is common in deep learning coding:
    - dW1 = $\frac{\partial \mathcal{J} }{ \partial W_1 }$
    - db1 = $\frac{\partial \mathcal{J} }{ \partial b_1 }$
    - dW2 = $\frac{\partial \mathcal{J} }{ \partial W_2 }$
    - db2 = $\frac{\partial \mathcal{J} }{ \partial b_2 }$

!--&gt;

&lt;ul&gt;
&lt;li&gt;Tips:&lt;ul&gt;
&lt;li&gt;To compute dZ1 you&#39;ll need to compute $g^{[1]&#39;}(Z^{[1]})$. Since $g^{[1]}(.)$ is the tanh activation function, if $a = g^{[1]}(z)$ then $g^{[1]&#39;}(z) = 1-a^2$. So you can compute 
$g^{[1]&#39;}(Z^{[1]})$ using &lt;code&gt;(1 - np.power(A1, 2))&lt;/code&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&quot;codehilite&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;c1&quot;&gt;# GRADED FUNCTION: backward_propagation&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;backward_propagation&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;parameters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cache&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;sd&quot;&gt;&amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    Implement the backward propagation using the instructions above.&lt;/span&gt;

&lt;span class=&quot;sd&quot;&gt;    Arguments:&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    parameters -- python dictionary containing our parameters &lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    cache -- a dictionary containing &amp;quot;Z1&amp;quot;, &amp;quot;A1&amp;quot;, &amp;quot;Z2&amp;quot; and &amp;quot;A2&amp;quot;.&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    X -- input data of shape (2, number of examples)&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    Y -- &amp;quot;true&amp;quot; labels vector of shape (1, number of examples)&lt;/span&gt;

&lt;span class=&quot;sd&quot;&gt;    Returns:&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    grads -- python dictionary containing your gradients with respect to different parameters&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    &amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;m&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;

    &lt;span class=&quot;c1&quot;&gt;# First, retrieve W1 and W2 from the dictionary &amp;quot;parameters&amp;quot;.&lt;/span&gt;

    &lt;span class=&quot;n&quot;&gt;W1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;parameters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;W1&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;W2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;parameters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;W2&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;


    &lt;span class=&quot;c1&quot;&gt;# Retrieve also A1 and A2 from dictionary &amp;quot;cache&amp;quot;.&lt;/span&gt;

    &lt;span class=&quot;n&quot;&gt;A1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cache&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;A1&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;A2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cache&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;A2&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;


    &lt;span class=&quot;c1&quot;&gt;# Backward propagation: calculate dW1, db1, dW2, db2. &lt;/span&gt;

    &lt;span class=&quot;n&quot;&gt;dZ2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;A2&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Y&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;dW2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dZ2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;A1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;T&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;m&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;db2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dZ2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;axis&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;keepdims&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;m&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;dZ1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;W2&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;T&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dZ2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;power&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;A1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;dW1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dZ1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;T&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;m&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;db1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dZ1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;axis&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;keepdims&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;m&lt;/span&gt;


    &lt;span class=&quot;n&quot;&gt;grads&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;dW1&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dW1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
             &lt;span class=&quot;s2&quot;&gt;&amp;quot;db1&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;db1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
             &lt;span class=&quot;s2&quot;&gt;&amp;quot;dW2&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dW2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
             &lt;span class=&quot;s2&quot;&gt;&amp;quot;db2&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;db2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;

    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;grads&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div class=&quot;codehilite&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;parameters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cache&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X_assess&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Y_assess&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;backward_propagation_test_case&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;grads&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;backward_propagation&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;parameters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cache&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X_assess&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Y_assess&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;dW1 = &amp;quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;grads&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;dW1&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]))&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;db1 = &amp;quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;grads&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;db1&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]))&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;dW2 = &amp;quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;grads&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;dW2&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]))&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;db2 = &amp;quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;grads&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;db2&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]))&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div class=&quot;codehilite&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;dW1 = [[ 0.00301023 -0.00747267]
 [ 0.00257968 -0.00641288]
 [-0.00156892  0.003893  ]
 [-0.00652037  0.01618243]]
db1 = [[ 0.00176201]
 [ 0.00150995]
 [-0.00091736]
 [-0.00381422]]
dW2 = [[ 0.00078841  0.01765429 -0.00084166 -0.01022527]]
db2 = [[-0.16655712]]
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;strong&gt;Expected output&lt;/strong&gt;:&lt;/p&gt;
&lt;table style=&quot;width:80%&quot;&gt;
  &lt;tr&gt;
    &lt;td&gt;**dW1**&lt;/td&gt;
    &lt;td&gt; [[ 0.00301023 -0.00747267]
 [ 0.00257968 -0.00641288]
 [-0.00156892  0.003893  ]
 [-0.00652037  0.01618243]] &lt;/td&gt; 
  &lt;/tr&gt;

  &lt;tr&gt;
    &lt;td&gt;**db1**&lt;/td&gt;
    &lt;td&gt;  [[ 0.00176201]
 [ 0.00150995]
 [-0.00091736]
 [-0.00381422]] &lt;/td&gt; 
  &lt;/tr&gt;

  &lt;tr&gt;
    &lt;td&gt;**dW2**&lt;/td&gt;
    &lt;td&gt; [[ 0.00078841  0.01765429 -0.00084166 -0.01022527]] &lt;/td&gt; 
  &lt;/tr&gt;


  &lt;tr&gt;
    &lt;td&gt;**db2**&lt;/td&gt;
    &lt;td&gt; [[-0.16655712]] &lt;/td&gt; 
  &lt;/tr&gt;

&lt;/table&gt;

&lt;p&gt;&lt;strong&gt;Question&lt;/strong&gt;: Implement the update rule. Use gradient descent. You have to use (dW1, db1, dW2, db2) in order to update (W1, b1, W2, b2).&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;General gradient descent rule&lt;/strong&gt;: $ \theta = \theta - \alpha \frac{\partial J }{ \partial \theta }$ where $\alpha$ is the learning rate and $\theta$ represents a parameter.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Illustration&lt;/strong&gt;: The gradient descent algorithm with a good learning rate (converging) and a bad learning rate (diverging). Images courtesy of Adam Harley.&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/karenyyy/Coursera_and_Udemy/master/deeplearningai_coursera/Neural_Networks_and_Deep_Learning/images/week3/sgd.gif&quot; style=&quot;width:400;height:400;&quot;&gt; &lt;img src=&quot;https://raw.githubusercontent.com/karenyyy/Coursera_and_Udemy/master/deeplearningai_coursera/Neural_Networks_and_Deep_Learning/images/week3/sgd_bad.gif&quot; style=&quot;width:400;height:400;&quot;&gt;&lt;/p&gt;
&lt;div class=&quot;codehilite&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;c1&quot;&gt;# GRADED FUNCTION: update_parameters&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;update_parameters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;parameters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;grads&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;learning_rate&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;1.2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;sd&quot;&gt;&amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    Updates parameters using the gradient descent update rule given above&lt;/span&gt;

&lt;span class=&quot;sd&quot;&gt;    Arguments:&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    parameters -- python dictionary containing your parameters &lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    grads -- python dictionary containing your gradients &lt;/span&gt;

&lt;span class=&quot;sd&quot;&gt;    Returns:&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    parameters -- python dictionary containing your updated parameters &lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    &amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;
    &lt;span class=&quot;c1&quot;&gt;# Retrieve each parameter from the dictionary &amp;quot;parameters&amp;quot;&lt;/span&gt;

    &lt;span class=&quot;n&quot;&gt;W1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;parameters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;W1&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;b1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;parameters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;b1&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;W2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;parameters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;W2&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;b2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;parameters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;b2&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;


    &lt;span class=&quot;c1&quot;&gt;# Retrieve each gradient from the dictionary &amp;quot;grads&amp;quot;&lt;/span&gt;

    &lt;span class=&quot;n&quot;&gt;dW1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;grads&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;dW1&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;db1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;grads&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;db1&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;dW2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;grads&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;dW2&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;db2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;grads&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;db2&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
    &lt;span class=&quot;c1&quot;&gt;## END CODE HERE ###&lt;/span&gt;

    &lt;span class=&quot;c1&quot;&gt;# Update rule for each parameter&lt;/span&gt;

    &lt;span class=&quot;n&quot;&gt;W1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;W1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;learning_rate&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dW1&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;b1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;b1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;learning_rate&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;db1&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;W2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;W2&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;learning_rate&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dW2&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;b2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;b2&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;learning_rate&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;db2&lt;/span&gt;


    &lt;span class=&quot;n&quot;&gt;parameters&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;W1&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;W1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                  &lt;span class=&quot;s2&quot;&gt;&amp;quot;b1&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;b1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                  &lt;span class=&quot;s2&quot;&gt;&amp;quot;W2&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;W2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                  &lt;span class=&quot;s2&quot;&gt;&amp;quot;b2&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;b2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;

    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;parameters&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div class=&quot;codehilite&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;parameters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;grads&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;update_parameters_test_case&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;parameters&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;update_parameters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;parameters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;grads&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;W1 = &amp;quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;parameters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;W1&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]))&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;b1 = &amp;quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;parameters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;b1&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]))&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;W2 = &amp;quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;parameters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;W2&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]))&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;b2 = &amp;quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;parameters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;b2&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]))&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div class=&quot;codehilite&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;W1 = [[-0.00643025  0.01936718]
 [-0.02410458  0.03978052]
 [-0.01653973 -0.02096177]
 [ 0.01046864 -0.05990141]]
b1 = [[ -1.02420756e-06]
 [  1.27373948e-05]
 [  8.32996807e-07]
 [ -3.20136836e-06]]
W2 = [[-0.01041081 -0.04463285  0.01758031  0.04747113]]
b2 = [[ 0.00010457]]
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;strong&gt;Expected Output&lt;/strong&gt;:&lt;/p&gt;
&lt;table style=&quot;width:80%&quot;&gt;
  &lt;tr&gt;
    &lt;td&gt;**W1**&lt;/td&gt;
    &lt;td&gt; [[-0.00643025  0.01936718]
 [-0.02410458  0.03978052]
 [-0.01653973 -0.02096177]
 [ 0.01046864 -0.05990141]]&lt;/td&gt; 
  &lt;/tr&gt;

  &lt;tr&gt;
    &lt;td&gt;**b1**&lt;/td&gt;
    &lt;td&gt; [[ -1.02420756e-06]
 [  1.27373948e-05]
 [  8.32996807e-07]
 [ -3.20136836e-06]]&lt;/td&gt; 
  &lt;/tr&gt;

  &lt;tr&gt;
    &lt;td&gt;**W2**&lt;/td&gt;
    &lt;td&gt; [[-0.01041081 -0.04463285  0.01758031  0.04747113]] &lt;/td&gt; 
  &lt;/tr&gt;


  &lt;tr&gt;
    &lt;td&gt;**b2**&lt;/td&gt;
    &lt;td&gt; [[ 0.00010457]] &lt;/td&gt; 
  &lt;/tr&gt;

&lt;/table&gt;

&lt;h3 id=&quot;44-integrate-parts-41-42-and-43-in-nn_model&quot;&gt;4.4 - Integrate parts 4.1, 4.2 and 4.3 in nn_model()&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;Question&lt;/strong&gt;: Build your neural network model in &lt;code&gt;nn_model()&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Instructions&lt;/strong&gt;: The neural network model has to use the previous functions in the right order.&lt;/p&gt;
&lt;div class=&quot;codehilite&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;c1&quot;&gt;# GRADED FUNCTION: nn_model&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;nn_model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n_h&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;num_iterations&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;10000&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;print_cost&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;False&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;sd&quot;&gt;&amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    Arguments:&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    X -- dataset of shape (2, number of examples)&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    Y -- labels of shape (1, number of examples)&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    n_h -- size of the hidden layer&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    num_iterations -- Number of iterations in gradient descent loop&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    print_cost -- if True, print the cost every 1000 iterations&lt;/span&gt;

&lt;span class=&quot;sd&quot;&gt;    Returns:&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    parameters -- parameters learnt by the model. They can then be used to predict.&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    &amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;

    &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;random&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;seed&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;n_x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;layer_sizes&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;n_y&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;layer_sizes&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;

    &lt;span class=&quot;c1&quot;&gt;# Initialize parameters, then retrieve W1, b1, W2, b2. Inputs: &amp;quot;n_x, n_h, n_y&amp;quot;. Outputs = &amp;quot;W1, b1, W2, b2, parameters&amp;quot;.&lt;/span&gt;


    &lt;span class=&quot;n&quot;&gt;parameters&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;initialize_parameters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n_x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n_h&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n_y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;W1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;parameters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;W1&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;b1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;parameters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;b1&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;W2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;parameters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;W2&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;b2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;parameters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;b2&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;


    &lt;span class=&quot;c1&quot;&gt;# Loop (gradient descent)&lt;/span&gt;

    &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;num_iterations&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;


        &lt;span class=&quot;c1&quot;&gt;# Forward propagation. Inputs: &amp;quot;X, parameters&amp;quot;. Outputs: &amp;quot;A2, cache&amp;quot;.&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;A2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cache&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;forward_propagation&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;parameters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

        &lt;span class=&quot;c1&quot;&gt;# Cost function. Inputs: &amp;quot;A2, Y, parameters&amp;quot;. Outputs: &amp;quot;cost&amp;quot;.&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;cost&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;compute_cost&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;A2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;parameters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

        &lt;span class=&quot;c1&quot;&gt;# Backpropagation. Inputs: &amp;quot;parameters, cache, X, Y&amp;quot;. Outputs: &amp;quot;grads&amp;quot;.&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;grads&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;backward_propagation&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;parameters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cache&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

        &lt;span class=&quot;c1&quot;&gt;# Gradient descent parameter update. Inputs: &amp;quot;parameters, grads&amp;quot;. Outputs: &amp;quot;parameters&amp;quot;.&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;parameters&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;update_parameters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;parameters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;grads&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;learning_rate&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;1.2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;



        &lt;span class=&quot;c1&quot;&gt;# Print the cost every 1000 iterations&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;print_cost&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;and&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;%&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1000&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;print&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;Cost after iteration &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;%i&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;: &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;%f&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;%&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cost&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;

    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;parameters&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div class=&quot;codehilite&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X_assess&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Y_assess&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nn_model_test_case&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;parameters&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nn_model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X_assess&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Y_assess&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;num_iterations&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;10000&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;print_cost&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;W1 = &amp;quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;parameters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;W1&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]))&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;b1 = &amp;quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;parameters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;b1&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]))&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;W2 = &amp;quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;parameters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;W2&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]))&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;b2 = &amp;quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;parameters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;b2&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]))&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div class=&quot;codehilite&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;Cost after iteration 0: 0.692739
Cost after iteration 1000: 0.000218
Cost after iteration 2000: 0.000107
Cost after iteration 3000: 0.000071
Cost after iteration 4000: 0.000053
Cost after iteration 5000: 0.000042
Cost after iteration 6000: 0.000035
Cost after iteration 7000: 0.000030
Cost after iteration 8000: 0.000026
Cost after iteration 9000: 0.000023
W1 = [[-0.65848169  1.21866811]
 [-0.76204273  1.39377573]
 [ 0.5792005  -1.10397703]
 [ 0.76773391 -1.41477129]]
b1 = [[ 0.287592  ]
 [ 0.3511264 ]
 [-0.2431246 ]
 [-0.35772805]]
W2 = [[-2.45566237 -3.27042274  2.00784958  3.36773273]]
b2 = [[ 0.20459656]]
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;strong&gt;Expected Output&lt;/strong&gt;:&lt;/p&gt;
&lt;table style=&quot;width:90%&quot;&gt;

&lt;tr&gt; 
    &lt;td&gt; 
        **cost after iteration 0**
    &lt;/td&gt;
    &lt;td&gt; 
        0.692739
    &lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt; 
    &lt;td&gt; 
        &lt;center&gt; $\vdots$ &lt;/center&gt;
    &lt;/td&gt;
    &lt;td&gt; 
        &lt;center&gt; $\vdots$ &lt;/center&gt;
    &lt;/td&gt;
&lt;/tr&gt;

  &lt;tr&gt;
    &lt;td&gt;**W1**&lt;/td&gt;
    &lt;td&gt; [[-0.65848169  1.21866811]
 [-0.76204273  1.39377573]
 [ 0.5792005  -1.10397703]
 [ 0.76773391 -1.41477129]]&lt;/td&gt; 
  &lt;/tr&gt;

  &lt;tr&gt;
    &lt;td&gt;**b1**&lt;/td&gt;
    &lt;td&gt; [[ 0.287592  ]
 [ 0.3511264 ]
 [-0.2431246 ]
 [-0.35772805]] &lt;/td&gt; 
  &lt;/tr&gt;

  &lt;tr&gt;
    &lt;td&gt;**W2**&lt;/td&gt;
    &lt;td&gt; [[-2.45566237 -3.27042274  2.00784958  3.36773273]] &lt;/td&gt; 
  &lt;/tr&gt;


  &lt;tr&gt;
    &lt;td&gt;**b2**&lt;/td&gt;
    &lt;td&gt; [[ 0.20459656]] &lt;/td&gt; 
  &lt;/tr&gt;

&lt;/table&gt;

&lt;h3 id=&quot;45-predictions&quot;&gt;4.5 Predictions&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;Question&lt;/strong&gt;: Use your model to predict by building predict().
Use forward propagation to predict results.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Reminder&lt;/strong&gt;: predictions = $y_{prediction} = \mathbb 1 \text{{activation &amp;gt; 0.5}} = \begin{cases}
      1 &amp;amp; \text{if}\ activation &amp;gt; 0.5 \
      0 &amp;amp; \text{otherwise}
    \end{cases}$  &lt;/p&gt;
&lt;p&gt;As an example, if you would like to set the entries of a matrix X to 0 and 1 based on a threshold you would do: &lt;code&gt;X_new = (X &amp;gt; threshold)&lt;/code&gt;&lt;/p&gt;
&lt;div class=&quot;codehilite&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;c1&quot;&gt;# GRADED FUNCTION: predict&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;predict&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;parameters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;sd&quot;&gt;&amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    Using the learned parameters, predicts a class for each example in X&lt;/span&gt;

&lt;span class=&quot;sd&quot;&gt;    Arguments:&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    parameters -- python dictionary containing your parameters &lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    X -- input data of size (n_x, m)&lt;/span&gt;

&lt;span class=&quot;sd&quot;&gt;    Returns&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    predictions -- vector of predictions of our model (red: 0 / blue: 1)&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    &amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;

    &lt;span class=&quot;c1&quot;&gt;# Computes probabilities using forward propagation, and classifies to 0/1 using 0.5 as the threshold.&lt;/span&gt;

    &lt;span class=&quot;n&quot;&gt;A2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cache&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;forward_propagation&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;parameters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;predictions&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;round&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;A2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;


    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;predictions&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div class=&quot;codehilite&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;parameters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X_assess&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;predict_test_case&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;predictions&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;predict&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;parameters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X_assess&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;predictions mean = &amp;quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mean&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;predictions&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)))&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div class=&quot;codehilite&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;predictions mean = 0.666666666667
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;strong&gt;Expected Output&lt;/strong&gt;: &lt;/p&gt;
&lt;table style=&quot;width:40%&quot;&gt;
  &lt;tr&gt;
    &lt;td&gt;**predictions mean**&lt;/td&gt;
    &lt;td&gt; 0.666666666667 &lt;/td&gt; 
  &lt;/tr&gt;

&lt;/table&gt;

&lt;p&gt;It is time to run the model and see how it performs on a planar dataset. Run the following code to test your model with a single hidden layer of $n_h$ hidden units.&lt;/p&gt;
&lt;div class=&quot;codehilite&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;c1&quot;&gt;# Build a model with a n_h-dimensional hidden layer&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;parameters&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nn_model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n_h&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;num_iterations&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;10000&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;print_cost&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Plot the decision boundary&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;plot_decision_boundary&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;lambda&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;predict&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;parameters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;T&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;title&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;Decision Boundary for hidden layer size &amp;quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div class=&quot;codehilite&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;Cost after iteration 0: 0.693048
Cost after iteration 1000: 0.288083
Cost after iteration 2000: 0.254385
Cost after iteration 3000: 0.233864
Cost after iteration 4000: 0.226792
Cost after iteration 5000: 0.222644
Cost after iteration 6000: 0.219731
Cost after iteration 7000: 0.217504
Cost after iteration 8000: 0.219471
Cost after iteration 9000: 0.218612





&amp;lt;matplotlib.text.Text at 0x7f01dc0506a0&amp;gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;img alt=&quot;png&quot; src=&quot;https://raw.githubusercontent.com/karenyyy/Coursera_and_Udemy/master/deeplearningai_coursera/Neural_Networks_and_Deep_Learning/images/week3/output_50_2.png&quot; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Expected Output&lt;/strong&gt;:&lt;/p&gt;
&lt;table style=&quot;width:40%&quot;&gt;
  &lt;tr&gt;
    &lt;td&gt;**Cost after iteration 9000**&lt;/td&gt;
    &lt;td&gt; 0.218607 &lt;/td&gt; 
  &lt;/tr&gt;

&lt;/table&gt;

&lt;div class=&quot;codehilite&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;c1&quot;&gt;# Print accuracy&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;predictions&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;predict&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;parameters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;Accuracy: &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;%d&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;%&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;float&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;((&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;predictions&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;T&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;predictions&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;T&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;float&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Y&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;100&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&amp;#39;%&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div class=&quot;codehilite&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Accuracy&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;90&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;%&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;strong&gt;Expected Output&lt;/strong&gt;: &lt;/p&gt;
&lt;table style=&quot;width:15%&quot;&gt;
  &lt;tr&gt;
    &lt;td&gt;**Accuracy**&lt;/td&gt;
    &lt;td&gt; 90% &lt;/td&gt; 
  &lt;/tr&gt;
&lt;/table&gt;

&lt;p&gt;Accuracy is really high compared to Logistic Regression. The model has learnt the leaf patterns of the flower! Neural networks are able to learn even highly non-linear decision boundaries, unlike logistic regression. &lt;/p&gt;
&lt;p&gt;Now, let&#39;s try out several hidden layer sizes.&lt;/p&gt;
&lt;h3 id=&quot;46-tuning-hidden-layer-size-optionalungraded-exercise&quot;&gt;4.6 - Tuning hidden layer size (optional/ungraded exercise)&lt;/h3&gt;
&lt;p&gt;Run the following code. It may take 1-2 minutes. You will observe different behaviors of the model for various hidden layer sizes.&lt;/p&gt;
&lt;div class=&quot;codehilite&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;c1&quot;&gt;# This may take about 2 minutes to run&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;figure&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;figsize&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;16&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;32&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;hidden_layer_sizes&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;20&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;50&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n_h&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;enumerate&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;hidden_layer_sizes&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;subplot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;title&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;Hidden Layer of size &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;%d&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;%&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n_h&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;parameters&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nn_model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n_h&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;num_iterations&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;5000&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;plot_decision_boundary&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;lambda&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;predict&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;parameters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;T&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;predictions&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;predict&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;parameters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;accuracy&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;float&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;((&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;predictions&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;T&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;predictions&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;T&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;float&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Y&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;100&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;print&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;Accuracy for {} hidden units: {} %&amp;quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;format&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n_h&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;accuracy&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div class=&quot;codehilite&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;Accuracy for 1 hidden units: 67.5 %
Accuracy for 2 hidden units: 67.25 %
Accuracy for 3 hidden units: 90.75 %
Accuracy for 4 hidden units: 90.5 %
Accuracy for 5 hidden units: 91.25 %
Accuracy for 20 hidden units: 90.0 %
Accuracy for 50 hidden units: 90.25 %
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;img alt=&quot;png&quot; src=&quot;https://raw.githubusercontent.com/karenyyy/Coursera_and_Udemy/master/deeplearningai_coursera/Neural_Networks_and_Deep_Learning/images/week3/output_56_1.png&quot; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Interpretation&lt;/strong&gt;:
- The larger models (with more hidden units) are able to fit the training set better, until eventually the largest models overfit the data. 
- The best hidden layer size seems to be around n_h = 5. Indeed, a value around here seems to  fits the data well without also incurring noticable overfitting.
- You will also learn later about regularization, which lets you use very large models (such as n_h = 50) without much overfitting. &lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Optional questions&lt;/strong&gt;:&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt;: Remember to submit the assignment but clicking the blue &quot;Submit Assignment&quot; button at the upper-right. &lt;/p&gt;
&lt;p&gt;Some optional/ungraded questions that you can explore if you wish: 
- What happens when you change the tanh activation for a sigmoid activation or a ReLU activation?
- Play with the learning_rate. What happens?
- What if we change the dataset? (See part 5 below!)&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;You&#39;ve learnt to:&lt;/strong&gt;
- Build a complete neural network with a hidden layer
- Make a good use of a non-linear unit
- Implemented forward propagation and backpropagation, and trained a neural network
- See the impact of varying the hidden layer size, including overfitting.&lt;/p&gt;
&lt;p&gt;Nice work! &lt;/p&gt;
&lt;h2 id=&quot;5-performance-on-other-datasets&quot;&gt;5) Performance on other datasets&lt;/h2&gt;
&lt;p&gt;If you want, you can rerun the whole notebook (minus the dataset part) for each of the following datasets.&lt;/p&gt;
&lt;div class=&quot;codehilite&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;c1&quot;&gt;# Datasets&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;noisy_circles&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;noisy_moons&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;blobs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;gaussian_quantiles&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;no_structure&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;load_extra_datasets&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;datasets&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;noisy_circles&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;noisy_circles&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
            &lt;span class=&quot;s2&quot;&gt;&amp;quot;noisy_moons&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;noisy_moons&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
            &lt;span class=&quot;s2&quot;&gt;&amp;quot;blobs&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;blobs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
            &lt;span class=&quot;s2&quot;&gt;&amp;quot;gaussian_quantiles&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;gaussian_quantiles&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;


&lt;span class=&quot;n&quot;&gt;dataset&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&amp;quot;noisy_moons&amp;quot;&lt;/span&gt;


&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Y&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;datasets&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dataset&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Y&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;T&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Y&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;reshape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Y&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# make blobs binary&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dataset&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&amp;quot;blobs&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;Y&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Y&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;%&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Visualize the data&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;scatter&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;:],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;:],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;c&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;s&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;40&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cmap&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cm&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Spectral&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;img alt=&quot;png&quot; src=&quot;https://raw.githubusercontent.com/karenyyy/Coursera_and_Udemy/master/deeplearningai_coursera/Neural_Networks_and_Deep_Learning/images/week3/output_63_0.png&quot; /&gt;&lt;/p&gt;
&lt;p&gt;Congrats on finishing this Programming Assignment!&lt;/p&gt;
&lt;p&gt;Reference:
- http://scs.ryerson.ca/~aharley/neural-networks/
- http://cs231n.github.io/neural-networks-case-study/&lt;/p&gt;deeplearning.ai - Neural Networks and Deep Learning - Week 2 Assignment
&lt;h1 id=&quot;logistic-regression-with-a-neural-network-mindset&quot;&gt;Logistic Regression with a Neural Network mindset&lt;/h1&gt;
&lt;p&gt;Welcome to your first (required) programming assignment! You will build a logistic regression classifier to recognize  cats. This assignment will step you through how to do this with a Neural Network mindset, and so will also hone your intuitions about deep learning.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Instructions:&lt;/strong&gt;
- Do not use loops (for/while) in your code, unless the instructions explicitly ask you to do so.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;You will learn to:&lt;/strong&gt;
- Build the general architecture of a learning algorithm, including:
    - Initializing parameters
    - Calculating the cost function and its gradient
    - Using an optimization algorithm (gradient descent) 
- Gather all three functions above into a main model function, in the right order.&lt;/p&gt;
&lt;h2 id=&quot;1-packages&quot;&gt;1 - Packages&lt;/h2&gt;
&lt;p&gt;First, let&#39;s run the cell below to import all the packages that you will need during this assignment. 
- &lt;a href=&quot;www.numpy.org&quot;&gt;numpy&lt;/a&gt; is the fundamental package for scientific computing with Python.
- &lt;a href=&quot;http://www.h5py.org&quot;&gt;h5py&lt;/a&gt; is a common package to interact with a dataset that is stored on an H5 file.
- &lt;a href=&quot;http://matplotlib.org&quot;&gt;matplotlib&lt;/a&gt; is a famous library to plot graphs in Python.
- &lt;a href=&quot;http://www.pythonware.com/products/pil/&quot;&gt;PIL&lt;/a&gt; and &lt;a href=&quot;https://www.scipy.org/&quot;&gt;scipy&lt;/a&gt; are used here to test your model with your own picture at the end.&lt;/p&gt;
&lt;div class=&quot;codehilite&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;numpy&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;np&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;matplotlib.pyplot&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;plt&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;h5py&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;scipy&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;PIL&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Image&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;scipy&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ndimage&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;lr_utils&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;load_dataset&lt;/span&gt;

&lt;span class=&quot;o&quot;&gt;%&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;matplotlib&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;inline&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;h2 id=&quot;2-overview-of-the-problem-set&quot;&gt;2 - Overview of the Problem set&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;Problem Statement&lt;/strong&gt;: You are given a dataset (&quot;data.h5&quot;) containing:
    - a training set of m_train images labeled as cat (y=1) or non-cat (y=0)
    - a test set of m_test images labeled as cat or non-cat
    - each image is of shape (num_px, num_px, 3) where 3 is for the 3 channels (RGB). Thus, each image is square (height = num_px) and (width = num_px).&lt;/p&gt;
&lt;p&gt;You will build a simple image-recognition algorithm that can correctly classify pictures as cat or non-cat.&lt;/p&gt;
&lt;p&gt;Let&#39;s get more familiar with the dataset. Load the data by running the following code.&lt;/p&gt;
&lt;div class=&quot;codehilite&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;c1&quot;&gt;# Loading the data (cat/non-cat)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;train_set_x_orig&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;train_set_y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;test_set_x_orig&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;test_set_y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;classes&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;load_dataset&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;We added &quot;_orig&quot; at the end of image datasets (train and test) because we are going to preprocess them. After preprocessing, we will end up with train_set_x and test_set_x (the labels train_set_y and test_set_y don&#39;t need any preprocessing).&lt;/p&gt;
&lt;p&gt;Each line of your train_set_x_orig and test_set_x_orig is an array representing an image. You can visualize an example by running the following code. Feel free also to change the &lt;code&gt;index&lt;/code&gt; value and re-run to see other images. &lt;/p&gt;
&lt;div class=&quot;codehilite&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;c1&quot;&gt;# Example of a picture&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;index&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;25&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;imshow&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;train_set_x_orig&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;index&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;y = &amp;quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;train_set_y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[:,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;index&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&amp;quot;, it&amp;#39;s a &amp;#39;&amp;quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;classes&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;squeeze&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;train_set_y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[:,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;index&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])]&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;decode&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;utf-8&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;  &lt;span class=&quot;s2&quot;&gt;&amp;quot;&amp;#39; picture.&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div class=&quot;codehilite&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;y = [1], it&amp;#39;s a &amp;#39;cat&amp;#39; picture.
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;img alt=&quot;png&quot; src=&quot;https://raw.githubusercontent.com/karenyyy/Coursera_and_Udemy/master/deeplearningai_coursera/Neural_Networks_and_Deep_Learning/images/week2/output_6_1.png&quot; /&gt;&lt;/p&gt;
&lt;p&gt;Many software bugs in deep learning come from having matrix/vector dimensions that don&#39;t fit. If you can keep your matrix/vector dimensions straight you will go a long way toward eliminating many bugs. &lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Exercise:&lt;/strong&gt; Find the values for:
    - m_train (number of training examples)
    - m_test (number of test examples)
    - num_px (= height = width of a training image)
Remember that &lt;code&gt;train_set_x_orig&lt;/code&gt; is a numpy-array of shape (m_train, num_px, num_px, 3). For instance, you can access &lt;code&gt;m_train&lt;/code&gt; by writing &lt;code&gt;train_set_x_orig.shape[0]&lt;/code&gt;.&lt;/p&gt;
&lt;div class=&quot;codehilite&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;c1&quot;&gt;### START CODE HERE ### (≈ 3 lines of code)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;m_train&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;train_set_x_orig&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;m_test&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;test_set_x_orig&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;num_px&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;train_set_x_orig&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;### END CODE HERE ###&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;Number of training examples: m_train = &amp;quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;m_train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;Number of testing examples: m_test = &amp;quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;m_test&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;Height/Width of each image: num_px = &amp;quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;num_px&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;Each image is of size: (&amp;quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;num_px&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&amp;quot;, &amp;quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;num_px&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&amp;quot;, 3)&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;train_set_x shape: &amp;quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;train_set_x_orig&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;train_set_y shape: &amp;quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;train_set_y&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;test_set_x shape: &amp;quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;test_set_x_orig&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;test_set_y shape: &amp;quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;test_set_y&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div class=&quot;codehilite&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;Number of training examples: m_train = 209
Number of testing examples: m_test = 50
Height/Width of each image: num_px = 64
Each image is of size: (64, 64, 3)
train_set_x shape: (209, 64, 64, 3)
train_set_y shape: (1, 209)
test_set_x shape: (50, 64, 64, 3)
test_set_y shape: (1, 50)
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;strong&gt;Expected Output for m_train, m_test and num_px&lt;/strong&gt;: 
&lt;table style=&quot;width:15%&quot;&gt;
  &lt;tr&gt;
    &lt;td&gt;&lt;strong&gt;m_train&lt;/strong&gt;&lt;/td&gt;
    &lt;td&gt; 209 &lt;/td&gt; 
  &lt;/tr&gt;&lt;/p&gt;
&lt;p&gt;&lt;tr&gt;
    &lt;td&gt;&lt;strong&gt;m_test&lt;/strong&gt;&lt;/td&gt;
    &lt;td&gt; 50 &lt;/td&gt; 
  &lt;/tr&gt;&lt;/p&gt;
&lt;p&gt;&lt;tr&gt;
    &lt;td&gt;&lt;strong&gt;num_px&lt;/strong&gt;&lt;/td&gt;
    &lt;td&gt; 64 &lt;/td&gt; 
  &lt;/tr&gt;&lt;/p&gt;
&lt;/table&gt;

&lt;p&gt;For convenience, you should now reshape images of shape (num_px, num_px, 3) in a numpy-array of shape (num_px $&lt;em&gt;$ num_px $&lt;/em&gt;$ 3, 1). After this, our training (and test) dataset is a numpy-array where each column represents a flattened image. There should be m_train (respectively m_test) columns.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Exercise:&lt;/strong&gt; Reshape the training and test data sets so that images of size (num_px, num_px, 3) are flattened into single vectors of shape (num_px $&lt;em&gt;$ num_px $&lt;/em&gt;$ 3, 1).&lt;/p&gt;
&lt;p&gt;A trick when you want to flatten a matrix X of shape (a,b,c,d) to a matrix X_flatten of shape (b$&lt;em&gt;$c$&lt;/em&gt;$d, a) is to use: &lt;/p&gt;
&lt;div class=&quot;codehilite&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X_flatten&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;reshape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;T&lt;/span&gt;      &lt;span class=&quot;c1&quot;&gt;# X.T is the transpose of X&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div class=&quot;codehilite&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;c1&quot;&gt;# Reshape the training and test examples&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;### START CODE HERE ### (≈ 2 lines of code)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;train_set_x_flatten&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;train_set_x_orig&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;reshape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;train_set_x_orig&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;T&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;test_set_x_flatten&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;test_set_x_orig&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;reshape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;test_set_x_orig&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;T&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;### END CODE HERE ###&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;train_set_x_flatten shape: &amp;quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;train_set_x_flatten&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;train_set_y shape: &amp;quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;train_set_y&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;test_set_x_flatten shape: &amp;quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;test_set_x_flatten&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;test_set_y shape: &amp;quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;test_set_y&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;sanity check after reshaping: &amp;quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;train_set_x_flatten&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]))&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div class=&quot;codehilite&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;train_set_x_flatten shape: (12288, 209)
train_set_y shape: (1, 209)
test_set_x_flatten shape: (12288, 50)
test_set_y shape: (1, 50)
sanity check after reshaping: [17 31 56 22 33]
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;strong&gt;Expected Output&lt;/strong&gt;: &lt;/p&gt;
&lt;table style=&quot;width:35%&quot;&gt;
  &lt;tr&gt;
    &lt;td&gt;**train_set_x_flatten shape**&lt;/td&gt;
    &lt;td&gt; (12288, 209)&lt;/td&gt; 
  &lt;/tr&gt;
  &lt;tr&gt;
    &lt;td&gt;**train_set_y shape**&lt;/td&gt;
    &lt;td&gt;(1, 209)&lt;/td&gt; 
  &lt;/tr&gt;
  &lt;tr&gt;
    &lt;td&gt;**test_set_x_flatten shape**&lt;/td&gt;
    &lt;td&gt;(12288, 50)&lt;/td&gt; 
  &lt;/tr&gt;
  &lt;tr&gt;
    &lt;td&gt;**test_set_y shape**&lt;/td&gt;
    &lt;td&gt;(1, 50)&lt;/td&gt; 
  &lt;/tr&gt;
  &lt;tr&gt;
  &lt;td&gt;**sanity check after reshaping**&lt;/td&gt;
  &lt;td&gt;[17 31 56 22 33]&lt;/td&gt; 
  &lt;/tr&gt;
&lt;/table&gt;

&lt;p&gt;To represent color images, the red, green and blue channels (RGB) must be specified for each pixel, and so the pixel value is actually a vector of three numbers ranging from 0 to 255.&lt;/p&gt;
&lt;p&gt;One common preprocessing step in machine learning is to center and standardize your dataset, meaning that you substract the mean of the whole numpy array from each example, and then divide each example by the standard deviation of the whole numpy array. But for picture datasets, it is simpler and more convenient and works almost as well to just divide every row of the dataset by 255 (the maximum value of a pixel channel).&lt;/p&gt;
&lt;!-- During the training of your model, you&#39;re going to multiply weights and add biases to some initial inputs in order to observe neuron activations. Then you backpropogate with the gradients to train the model. But, it is extremely important for each feature to have a similar range such that our gradients don&#39;t explode. You will see that more in detail later in the lectures. !--&gt;

&lt;p&gt;Let&#39;s standardize our dataset.&lt;/p&gt;
&lt;div class=&quot;codehilite&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;train_set_x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;train_set_x_flatten&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;255.&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;test_set_x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;test_set_x_flatten&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;255.&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;strong&gt;What you need to remember:&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Common steps for pre-processing a new dataset are:
- Figure out the dimensions and shapes of the problem (m_train, m_test, num_px, ...)
- Reshape the datasets such that each example is now a vector of size (num_px * num_px * 3, 1)
- &quot;Standardize&quot; the data&lt;/p&gt;
&lt;h2 id=&quot;3-general-architecture-of-the-learning-algorithm&quot;&gt;3 - General Architecture of the learning algorithm&lt;/h2&gt;
&lt;p&gt;It&#39;s time to design a simple algorithm to distinguish cat images from non-cat images.&lt;/p&gt;
&lt;p&gt;You will build a Logistic Regression, using a Neural Network mindset. The following Figure explains why &lt;strong&gt;Logistic Regression is actually a very simple Neural Network!&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Mathematical expression of the algorithm&lt;/strong&gt;:&lt;/p&gt;
&lt;p&gt;For one example $x^{(i)}$:
$$z^{(i)} = w^T x^{(i)} + b \tag{1}$$
$$\hat{y}^{(i)} = a^{(i)} = sigmoid(z^{(i)})\tag{2}$$ 
$$ \mathcal{L}(a^{(i)}, y^{(i)}) =  - y^{(i)}  \log(a^{(i)}) - (1-y^{(i)} )  \log(1-a^{(i)})\tag{3}$$&lt;/p&gt;
&lt;p&gt;The cost is then computed by summing over all training examples:
$$ J = \frac{1}{m} \sum_{i=1}^m \mathcal{L}(a^{(i)}, y^{(i)})\tag{6}$$&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Key steps&lt;/strong&gt;:
In this exercise, you will carry out the following steps: 
    - Initialize the parameters of the model
    - Learn the parameters for the model by minimizing the cost&lt;br /&gt;
    - Use the learned parameters to make predictions (on the test set)
    - Analyse the results and conclude&lt;/p&gt;
&lt;h2 id=&quot;4-building-the-parts-of-our-algorithm&quot;&gt;4 - Building the parts of our algorithm ##&lt;/h2&gt;
&lt;p&gt;The main steps for building a Neural Network are:
1. Define the model structure (such as number of input features) 
2. Initialize the model&#39;s parameters
3. Loop:
    - Calculate current loss (forward propagation)
    - Calculate current gradient (backward propagation)
    - Update parameters (gradient descent)&lt;/p&gt;
&lt;p&gt;You often build 1-3 separately and integrate them into one function we call &lt;code&gt;model()&lt;/code&gt;.&lt;/p&gt;
&lt;h3 id=&quot;41-helper-functions&quot;&gt;4.1 - Helper functions&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;Exercise&lt;/strong&gt;: Using your code from &quot;Python Basics&quot;, implement &lt;code&gt;sigmoid()&lt;/code&gt;. As you&#39;ve seen in the figure above, you need to compute $sigmoid( w^T x + b) = \frac{1}{1 + e^{-(w^T x + b)}}$ to make predictions. Use np.exp().&lt;/p&gt;
&lt;div class=&quot;codehilite&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;c1&quot;&gt;# GRADED FUNCTION: sigmoid&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;sigmoid&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;z&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;sd&quot;&gt;&amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    Compute the sigmoid of z&lt;/span&gt;

&lt;span class=&quot;sd&quot;&gt;    Arguments:&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    z -- A scalar or numpy array of any size.&lt;/span&gt;

&lt;span class=&quot;sd&quot;&gt;    Return:&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    s -- sigmoid(z)&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    &amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;

    &lt;span class=&quot;c1&quot;&gt;### START CODE HERE ### (≈ 1 line of code)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;s&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;exp&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;z&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
    &lt;span class=&quot;c1&quot;&gt;### END CODE HERE ###&lt;/span&gt;

    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;s&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div class=&quot;codehilite&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;sigmoid([0, 2]) = &amp;quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sigmoid&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;array&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]))))&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div class=&quot;codehilite&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;sigmoid([0, 2]) = [ 0.5         0.88079708]
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;strong&gt;Expected Output&lt;/strong&gt;: &lt;/p&gt;
&lt;table&gt;
  &lt;tr&gt;
    &lt;td&gt;**sigmoid([0, 2])**&lt;/td&gt;
    &lt;td&gt; [ 0.5         0.88079708]&lt;/td&gt; 
  &lt;/tr&gt;
&lt;/table&gt;

&lt;h3 id=&quot;42-initializing-parameters&quot;&gt;4.2 - Initializing parameters&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;Exercise:&lt;/strong&gt; Implement parameter initialization in the cell below. You have to initialize w as a vector of zeros. If you don&#39;t know what numpy function to use, look up np.zeros() in the Numpy library&#39;s documentation.&lt;/p&gt;
&lt;div class=&quot;codehilite&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;c1&quot;&gt;# GRADED FUNCTION: initialize_with_zeros&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;initialize_with_zeros&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dim&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;sd&quot;&gt;&amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    This function creates a vector of zeros of shape (dim, 1) for w and initializes b to 0.&lt;/span&gt;

&lt;span class=&quot;sd&quot;&gt;    Argument:&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    dim -- size of the w vector we want (or number of parameters in this case)&lt;/span&gt;

&lt;span class=&quot;sd&quot;&gt;    Returns:&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    w -- initialized vector of shape (dim, 1)&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    b -- initialized scalar (corresponds to the bias)&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    &amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;

    &lt;span class=&quot;c1&quot;&gt;### START CODE HERE ### (≈ 1 line of code)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;w&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;zeros&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;((&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dim&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;b&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;
    &lt;span class=&quot;c1&quot;&gt;### END CODE HERE ###&lt;/span&gt;

    &lt;span class=&quot;k&quot;&gt;assert&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;w&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dim&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;assert&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;isinstance&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;b&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;float&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;or&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;isinstance&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;b&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;int&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;

    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;w&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;b&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div class=&quot;codehilite&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dim&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;w&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;b&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;initialize_with_zeros&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dim&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;w = &amp;quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;w&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;b = &amp;quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;b&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div class=&quot;codehilite&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;w = [[ 0.]
 [ 0.]]
b = 0
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;strong&gt;Expected Output&lt;/strong&gt;: &lt;/p&gt;
&lt;table style=&quot;width:15%&quot;&gt;
    &lt;tr&gt;
        &lt;td&gt;  ** w **  &lt;/td&gt;
        &lt;td&gt; [[ 0.]
 [ 0.]] &lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
        &lt;td&gt;  ** b **  &lt;/td&gt;
        &lt;td&gt; 0 &lt;/td&gt;
    &lt;/tr&gt;
&lt;/table&gt;

&lt;p&gt;For image inputs, w will be of shape (num_px $\times$ num_px $\times$ 3, 1).&lt;/p&gt;
&lt;h3 id=&quot;43-forward-and-backward-propagation&quot;&gt;4.3 - Forward and Backward propagation&lt;/h3&gt;
&lt;p&gt;Now that your parameters are initialized, you can do the &quot;forward&quot; and &quot;backward&quot; propagation steps for learning the parameters.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Exercise:&lt;/strong&gt; Implement a function &lt;code&gt;propagate()&lt;/code&gt; that computes the cost function and its gradient.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Hints&lt;/strong&gt;:&lt;/p&gt;
&lt;p&gt;Forward Propagation:
- You get X
- You compute $A = \sigma(w^T X + b) = (a^{(1)}, a^{(2)}, ..., a^{(m-1)}, a^{(m)})$
- You calculate the cost function: $J = -\frac{1}{m}\sum_{i=1}^{m}y^{(i)}\log(a^{(i)})+(1-y^{(i)})\log(1-a^{(i)})$&lt;/p&gt;
&lt;p&gt;Here are the two formulas you will be using: &lt;/p&gt;
&lt;p&gt;$$ \frac{\partial J}{\partial w} = \frac{1}{m}X(A-Y)^T\tag{7}$$
$$ \frac{\partial J}{\partial b} = \frac{1}{m} \sum_{i=1}^m (a^{(i)}-y^{(i)})\tag{8}$$&lt;/p&gt;
&lt;div class=&quot;codehilite&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;c1&quot;&gt;# GRADED FUNCTION: propagate&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;propagate&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;w&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;b&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;sd&quot;&gt;&amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    Implement the cost function and its gradient for the propagation explained above&lt;/span&gt;

&lt;span class=&quot;sd&quot;&gt;    Arguments:&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    w -- weights, a numpy array of size (num_px * num_px * 3, 1)&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    b -- bias, a scalar&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    X -- data of size (num_px * num_px * 3, number of examples)&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    Y -- true &amp;quot;label&amp;quot; vector (containing 0 if non-cat, 1 if cat) of size (1, number of examples)&lt;/span&gt;

&lt;span class=&quot;sd&quot;&gt;    Return:&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    cost -- negative log-likelihood cost for logistic regression&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    dw -- gradient of the loss with respect to w, thus same shape as w&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    db -- gradient of the loss with respect to b, thus same shape as b&lt;/span&gt;

&lt;span class=&quot;sd&quot;&gt;    Tips:&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    - Write your code step by step for the propagation. np.log(), np.dot()&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    &amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;

    &lt;span class=&quot;n&quot;&gt;m&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;

    &lt;span class=&quot;c1&quot;&gt;# FORWARD PROPAGATION (FROM X TO COST)&lt;/span&gt;
    &lt;span class=&quot;c1&quot;&gt;### START CODE HERE ### (≈ 2 lines of code)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;A&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sigmoid&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;w&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;T&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;b&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;                                    &lt;span class=&quot;c1&quot;&gt;# compute activation&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;cost&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Y&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;log&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;A&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;log&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;A&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;m&lt;/span&gt;                                 &lt;span class=&quot;c1&quot;&gt;# compute cost&lt;/span&gt;
    &lt;span class=&quot;c1&quot;&gt;### END CODE HERE ###&lt;/span&gt;

    &lt;span class=&quot;c1&quot;&gt;# BACKWARD PROPAGATION (TO FIND GRAD)&lt;/span&gt;
    &lt;span class=&quot;c1&quot;&gt;### START CODE HERE ### (≈ 2 lines of code)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;dw&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;A&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;T&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;m&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;db&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;A&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;m&lt;/span&gt;
    &lt;span class=&quot;c1&quot;&gt;### END CODE HERE ###&lt;/span&gt;

    &lt;span class=&quot;k&quot;&gt;assert&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dw&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;w&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;assert&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;db&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dtype&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;float&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;cost&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;squeeze&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cost&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;assert&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cost&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;())&lt;/span&gt;

    &lt;span class=&quot;n&quot;&gt;grads&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;dw&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dw&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
             &lt;span class=&quot;s2&quot;&gt;&amp;quot;db&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;db&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;

    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;grads&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cost&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div class=&quot;codehilite&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;w&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;b&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Y&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;array&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([[&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;1.&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],[&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;2.&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]]),&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;2.&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;array&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([[&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;1.&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;2.&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;1.&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],[&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;3.&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;4.&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;3.2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]]),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;array&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]])&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;grads&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cost&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;propagate&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;w&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;b&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;dw = &amp;quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;grads&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;dw&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]))&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;db = &amp;quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;grads&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;db&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]))&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;cost = &amp;quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cost&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div class=&quot;codehilite&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;dw = [[ 0.99845601]
 [ 2.39507239]]
db = 0.00145557813678
cost = 5.80154531939
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;strong&gt;Expected Output&lt;/strong&gt;:&lt;/p&gt;
&lt;table style=&quot;width:50%&quot;&gt;
    &lt;tr&gt;
        &lt;td&gt;  ** dw **  &lt;/td&gt;
      &lt;td&gt; [[ 0.99845601]
     [ 2.39507239]]&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
        &lt;td&gt;  ** db **  &lt;/td&gt;
        &lt;td&gt; 0.00145557813678 &lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
        &lt;td&gt;  ** cost **  &lt;/td&gt;
        &lt;td&gt; 5.801545319394553 &lt;/td&gt;
    &lt;/tr&gt;

&lt;/table&gt;

&lt;h3 id=&quot;44-optimization&quot;&gt;4.4 - Optimization&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;You have initialized your parameters.&lt;/li&gt;
&lt;li&gt;You are also able to compute a cost function and its gradient.&lt;/li&gt;
&lt;li&gt;Now, you want to update the parameters using gradient descent.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Exercise:&lt;/strong&gt; Write down the optimization function. The goal is to learn $w$ and $b$ by minimizing the cost function $J$. For a parameter $\theta$, the update rule is $ \theta = \theta - \alpha \text{ } d\theta$, where $\alpha$ is the learning rate.&lt;/p&gt;
&lt;div class=&quot;codehilite&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;c1&quot;&gt;# GRADED FUNCTION: optimize&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;optimize&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;w&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;b&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;num_iterations&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;learning_rate&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;print_cost&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;False&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;sd&quot;&gt;&amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    This function optimizes w and b by running a gradient descent algorithm&lt;/span&gt;

&lt;span class=&quot;sd&quot;&gt;    Arguments:&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    w -- weights, a numpy array of size (num_px * num_px * 3, 1)&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    b -- bias, a scalar&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    X -- data of shape (num_px * num_px * 3, number of examples)&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    Y -- true &amp;quot;label&amp;quot; vector (containing 0 if non-cat, 1 if cat), of shape (1, number of examples)&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    num_iterations -- number of iterations of the optimization loop&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    learning_rate -- learning rate of the gradient descent update rule&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    print_cost -- True to print the loss every 100 steps&lt;/span&gt;

&lt;span class=&quot;sd&quot;&gt;    Returns:&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    params -- dictionary containing the weights w and bias b&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    grads -- dictionary containing the gradients of the weights and bias with respect to the cost function&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    costs -- list of all the costs computed during the optimization, this will be used to plot the learning curve.&lt;/span&gt;

&lt;span class=&quot;sd&quot;&gt;    Tips:&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    You basically need to write down two steps and iterate through them:&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;        1) Calculate the cost and the gradient for the current parameters. Use propagate().&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;        2) Update the parameters using gradient descent rule for w and b.&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    &amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;

    &lt;span class=&quot;n&quot;&gt;costs&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[]&lt;/span&gt;

    &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;num_iterations&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;


        &lt;span class=&quot;c1&quot;&gt;# Cost and gradient calculation (≈ 1-4 lines of code)&lt;/span&gt;
        &lt;span class=&quot;c1&quot;&gt;### START CODE HERE ### &lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;grads&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cost&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;propagate&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;w&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;b&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;c1&quot;&gt;### END CODE HERE ###&lt;/span&gt;

        &lt;span class=&quot;c1&quot;&gt;# Retrieve derivatives from grads&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;dw&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;grads&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;dw&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;db&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;grads&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;db&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;

        &lt;span class=&quot;c1&quot;&gt;# update rule (≈ 2 lines of code)&lt;/span&gt;
        &lt;span class=&quot;c1&quot;&gt;### START CODE HERE ###&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;w&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;w&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;learning_rate&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dw&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;b&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;b&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;learning_rate&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;db&lt;/span&gt;
        &lt;span class=&quot;c1&quot;&gt;### END CODE HERE ###&lt;/span&gt;

        &lt;span class=&quot;c1&quot;&gt;# Record the costs&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;%&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;100&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;costs&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;append&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cost&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

        &lt;span class=&quot;c1&quot;&gt;# Print the cost every 100 training iterations&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;print_cost&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;and&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;%&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;100&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;print&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;Cost after iteration &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;%i&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;: &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;%f&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;%&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cost&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;

    &lt;span class=&quot;n&quot;&gt;params&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;w&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;w&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
              &lt;span class=&quot;s2&quot;&gt;&amp;quot;b&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;b&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;

    &lt;span class=&quot;n&quot;&gt;grads&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;dw&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dw&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
             &lt;span class=&quot;s2&quot;&gt;&amp;quot;db&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;db&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;

    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;params&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;grads&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;costs&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div class=&quot;codehilite&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;params&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;grads&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;costs&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;optimize&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;w&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;b&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;num_iterations&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;100&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;learning_rate&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.009&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;print_cost&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;False&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;w = &amp;quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;params&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;w&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]))&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;b = &amp;quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;params&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;b&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]))&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;dw = &amp;quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;grads&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;dw&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]))&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;db = &amp;quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;grads&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;db&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]))&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div class=&quot;codehilite&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;w = [[ 0.19033591]
 [ 0.12259159]]
b = 1.92535983008
dw = [[ 0.67752042]
 [ 1.41625495]]
db = 0.219194504541
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;strong&gt;Expected Output&lt;/strong&gt;: &lt;/p&gt;
&lt;table style=&quot;width:40%&quot;&gt;
    &lt;tr&gt;
       &lt;td&gt; **w** &lt;/td&gt;
       &lt;td&gt;[[ 0.19033591]
 [ 0.12259159]] &lt;/td&gt;
    &lt;/tr&gt;

    &lt;tr&gt;
       &lt;td&gt; **b** &lt;/td&gt;
       &lt;td&gt; 1.92535983008 &lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
       &lt;td&gt; **dw** &lt;/td&gt;
       &lt;td&gt; [[ 0.67752042]
 [ 1.41625495]] &lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
       &lt;td&gt; **db** &lt;/td&gt;
       &lt;td&gt; 0.219194504541 &lt;/td&gt;
    &lt;/tr&gt;

&lt;/table&gt;

&lt;p&gt;&lt;strong&gt;Exercise:&lt;/strong&gt; The previous function will output the learned w and b. We are able to use w and b to predict the labels for a dataset X. Implement the &lt;code&gt;predict()&lt;/code&gt; function. There are two steps to computing predictions:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Calculate $\hat{Y} = A = \sigma(w^T X + b)$&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Convert the entries of a into 0 (if activation &amp;lt;= 0.5) or 1 (if activation &amp;gt; 0.5), stores the predictions in a vector &lt;code&gt;Y_prediction&lt;/code&gt;. If you wish, you can use an &lt;code&gt;if&lt;/code&gt;/&lt;code&gt;else&lt;/code&gt; statement in a &lt;code&gt;for&lt;/code&gt; loop (though there is also a way to vectorize this). &lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;div class=&quot;codehilite&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;c1&quot;&gt;# GRADED FUNCTION: predict&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;predict&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;w&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;b&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;sd&quot;&gt;&amp;#39;&amp;#39;&amp;#39;&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    Predict whether the label is 0 or 1 using learned logistic regression parameters (w, b)&lt;/span&gt;

&lt;span class=&quot;sd&quot;&gt;    Arguments:&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    w -- weights, a numpy array of size (num_px * num_px * 3, 1)&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    b -- bias, a scalar&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    X -- data of size (num_px * num_px * 3, number of examples)&lt;/span&gt;

&lt;span class=&quot;sd&quot;&gt;    Returns:&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    Y_prediction -- a numpy array (vector) containing all predictions (0/1) for the examples in X&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    &amp;#39;&amp;#39;&amp;#39;&lt;/span&gt;

    &lt;span class=&quot;n&quot;&gt;m&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;Y_prediction&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;zeros&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;((&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;m&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;w&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;w&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;reshape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

    &lt;span class=&quot;c1&quot;&gt;# Compute vector &amp;quot;A&amp;quot; predicting the probabilities of a cat being present in the picture&lt;/span&gt;
    &lt;span class=&quot;c1&quot;&gt;### START CODE HERE ### (≈ 1 line of code)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;A&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sigmoid&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;w&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;T&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;b&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;c1&quot;&gt;### END CODE HERE ###&lt;/span&gt;


    &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;A&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]):&lt;/span&gt;

        &lt;span class=&quot;c1&quot;&gt;# Convert probabilities A[0,i] to actual predictions p[0,i]&lt;/span&gt;
        &lt;span class=&quot;c1&quot;&gt;### START CODE HERE ### (≈ 4 lines of code)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;Y_prediction&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;A&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.5&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;else&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;
        &lt;span class=&quot;c1&quot;&gt;### END CODE HERE ###&lt;/span&gt;

    &lt;span class=&quot;k&quot;&gt;assert&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Y_prediction&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;m&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;

    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Y_prediction&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div class=&quot;codehilite&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;w&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;array&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([[&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.1124579&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],[&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.23106775&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]])&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;b&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.3&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;array&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([[&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;1.&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;1.1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;3.2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],[&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;1.2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;2.&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]])&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;predictions = &amp;quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;predict&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;w&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;b&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)))&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div class=&quot;codehilite&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;predictions = [[ 1.  1.  0.]]
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;strong&gt;Expected Output&lt;/strong&gt;: &lt;/p&gt;
&lt;table style=&quot;width:30%&quot;&gt;
    &lt;tr&gt;
         &lt;td&gt;
             **predictions**
         &lt;/td&gt;
          &lt;td&gt;
            [[ 1.  1.  0.]]
         &lt;/td&gt;  
   &lt;/tr&gt;

&lt;/table&gt;

&lt;p&gt;&lt;strong&gt;What to remember:&lt;/strong&gt;
You&#39;ve implemented several functions that:
- Initialize (w,b)
- Optimize the loss iteratively to learn parameters (w,b):
    - computing the cost and its gradient 
    - updating the parameters using gradient descent
- Use the learned (w,b) to predict the labels for a given set of examples&lt;/p&gt;
&lt;h2 id=&quot;5-merge-all-functions-into-a-model&quot;&gt;5 - Merge all functions into a model&lt;/h2&gt;
&lt;p&gt;You will now see how the overall model is structured by putting together all the building blocks (functions implemented in the previous parts) together, in the right order.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Exercise:&lt;/strong&gt; Implement the model function. Use the following notation:
    - Y_prediction_test for your predictions on the test set
    - Y_prediction_train for your predictions on the train set
    - w, costs, grads for the outputs of optimize()&lt;/p&gt;
&lt;div class=&quot;codehilite&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;c1&quot;&gt;# GRADED FUNCTION: model&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X_train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Y_train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X_test&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Y_test&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;num_iterations&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2000&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;learning_rate&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;print_cost&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;False&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;sd&quot;&gt;&amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    Builds the logistic regression model by calling the function you&amp;#39;ve implemented previously&lt;/span&gt;

&lt;span class=&quot;sd&quot;&gt;    Arguments:&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    X_train -- training set represented by a numpy array of shape (num_px * num_px * 3, m_train)&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    Y_train -- training labels represented by a numpy array (vector) of shape (1, m_train)&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    X_test -- test set represented by a numpy array of shape (num_px * num_px * 3, m_test)&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    Y_test -- test labels represented by a numpy array (vector) of shape (1, m_test)&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    num_iterations -- hyperparameter representing the number of iterations to optimize the parameters&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    learning_rate -- hyperparameter representing the learning rate used in the update rule of optimize()&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    print_cost -- Set to true to print the cost every 100 iterations&lt;/span&gt;

&lt;span class=&quot;sd&quot;&gt;    Returns:&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    d -- dictionary containing information about the model.&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    &amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;

    &lt;span class=&quot;c1&quot;&gt;### START CODE HERE ###&lt;/span&gt;

    &lt;span class=&quot;c1&quot;&gt;# initialize parameters with zeros (≈ 1 line of code)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;w&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;b&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;initialize_with_zeros&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X_train&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;

    &lt;span class=&quot;c1&quot;&gt;# Gradient descent (≈ 1 line of code)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;parameters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;grads&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;costs&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;optimize&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;w&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;b&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X_train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Y_train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;num_iterations&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;learning_rate&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;print_cost&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

    &lt;span class=&quot;c1&quot;&gt;# Retrieve parameters w and b from dictionary &amp;quot;parameters&amp;quot;&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;w&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;parameters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;w&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;b&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;parameters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;b&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;

    &lt;span class=&quot;c1&quot;&gt;# Predict test/train set examples (≈ 2 lines of code)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;Y_prediction_test&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;predict&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;w&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;b&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X_test&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;Y_prediction_train&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;predict&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;w&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;b&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X_train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

    &lt;span class=&quot;c1&quot;&gt;### END CODE HERE ###&lt;/span&gt;

    &lt;span class=&quot;c1&quot;&gt;# Print train/test Errors&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;train accuracy: {} %&amp;quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;format&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;100&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mean&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;abs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Y_prediction_train&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Y_train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;100&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;test accuracy: {} %&amp;quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;format&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;100&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mean&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;abs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Y_prediction_test&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Y_test&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;100&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;


    &lt;span class=&quot;n&quot;&gt;d&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;costs&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;costs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
         &lt;span class=&quot;s2&quot;&gt;&amp;quot;Y_prediction_test&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Y_prediction_test&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; 
         &lt;span class=&quot;s2&quot;&gt;&amp;quot;Y_prediction_train&amp;quot;&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Y_prediction_train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; 
         &lt;span class=&quot;s2&quot;&gt;&amp;quot;w&amp;quot;&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;w&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; 
         &lt;span class=&quot;s2&quot;&gt;&amp;quot;b&amp;quot;&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;b&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
         &lt;span class=&quot;s2&quot;&gt;&amp;quot;learning_rate&amp;quot;&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;learning_rate&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
         &lt;span class=&quot;s2&quot;&gt;&amp;quot;num_iterations&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;num_iterations&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;

    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;d&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Run the following cell to train your model.&lt;/p&gt;
&lt;div class=&quot;codehilite&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;d&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;train_set_x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;train_set_y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;test_set_x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;test_set_y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;num_iterations&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2000&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;learning_rate&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.005&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;print_cost&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div class=&quot;codehilite&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;Cost after iteration 0: 0.693147
Cost after iteration 100: 0.584508
Cost after iteration 200: 0.466949
Cost after iteration 300: 0.376007
Cost after iteration 400: 0.331463
Cost after iteration 500: 0.303273
Cost after iteration 600: 0.279880
Cost after iteration 700: 0.260042
Cost after iteration 800: 0.242941
Cost after iteration 900: 0.228004
Cost after iteration 1000: 0.214820
Cost after iteration 1100: 0.203078
Cost after iteration 1200: 0.192544
Cost after iteration 1300: 0.183033
Cost after iteration 1400: 0.174399
Cost after iteration 1500: 0.166521
Cost after iteration 1600: 0.159305
Cost after iteration 1700: 0.152667
Cost after iteration 1800: 0.146542
Cost after iteration 1900: 0.140872
train accuracy: 99.04306220095694 %
test accuracy: 70.0 %
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;strong&gt;Expected Output&lt;/strong&gt;: &lt;/p&gt;
&lt;table style=&quot;width:40%&quot;&gt;

    &lt;tr&gt;
        &lt;td&gt; **Cost after iteration 0 **  &lt;/td&gt; 
        &lt;td&gt; 0.693147 &lt;/td&gt;
    &lt;/tr&gt;
      &lt;tr&gt;
        &lt;td&gt; &lt;center&gt; $\vdots$ &lt;/center&gt; &lt;/td&gt; 
        &lt;td&gt; &lt;center&gt; $\vdots$ &lt;/center&gt; &lt;/td&gt; 
    &lt;/tr&gt;  
    &lt;tr&gt;
        &lt;td&gt; **Train Accuracy**  &lt;/td&gt; 
        &lt;td&gt; 99.04306220095694 % &lt;/td&gt;
    &lt;/tr&gt;

    &lt;tr&gt;
        &lt;td&gt;**Test Accuracy** &lt;/td&gt; 
        &lt;td&gt; 70.0 % &lt;/td&gt;
    &lt;/tr&gt;
&lt;/table&gt;

&lt;p&gt;&lt;strong&gt;Comment&lt;/strong&gt;: Training accuracy is close to 100%. This is a good sanity check: your model is working and has high enough capacity to fit the training data. Test error is 68%. It is actually not bad for this simple model, given the small dataset we used and that logistic regression is a linear classifier. But no worries, you&#39;ll build an even better classifier next week!&lt;/p&gt;
&lt;p&gt;Also, you see that the model is clearly overfitting the training data. Later in this specialization you will learn how to reduce overfitting, for example by using regularization. Using the code below (and changing the &lt;code&gt;index&lt;/code&gt; variable) you can look at predictions on pictures of the test set.&lt;/p&gt;
&lt;div class=&quot;codehilite&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;c1&quot;&gt;# Example of a picture that was wrongly classified.&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;index&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;imshow&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;test_set_x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[:,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;index&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;reshape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;((&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;num_px&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;num_px&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)))&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;y = &amp;quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;test_set_y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;index&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&amp;quot;, you predicted that it is a &lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\&amp;quot;&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;classes&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;d&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;Y_prediction_test&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;][&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;index&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]]&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;decode&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;utf-8&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;  &lt;span class=&quot;s2&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\&amp;quot;&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt; picture.&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div class=&quot;codehilite&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;/opt/conda/lib/python3.5/site-packages/ipykernel/__main__.py:4: DeprecationWarning: using a non-integer number instead of an integer will result in an error in the future


y = 1, you predicted that it is a &amp;quot;cat&amp;quot; picture.
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;img alt=&quot;png&quot; src=&quot;https://raw.githubusercontent.com/karenyyy/Coursera_and_Udemy/master/deeplearningai_coursera/Neural_Networks_and_Deep_Learning/images/week2/output_44_2.png&quot; /&gt;&lt;/p&gt;
&lt;p&gt;Let&#39;s also plot the cost function and the gradients.&lt;/p&gt;
&lt;div class=&quot;codehilite&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;c1&quot;&gt;# Plot learning curve (with costs)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;costs&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;squeeze&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;d&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;costs&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;plot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;costs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ylabel&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;cost&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;xlabel&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;iterations (per hundreds)&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;title&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;Learning rate =&amp;quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;d&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;learning_rate&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]))&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;show&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;img alt=&quot;png&quot; src=&quot;https://raw.githubusercontent.com/karenyyy/Coursera_and_Udemy/master/deeplearningai_coursera/Neural_Networks_and_Deep_Learning/images/week2/output_46_0.png&quot; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Interpretation&lt;/strong&gt;:
You can see the cost decreasing. It shows that the parameters are being learned. However, you see that you could train the model even more on the training set. Try to increase the number of iterations in the cell above and rerun the cells. You might see that the training set accuracy goes up, but the test set accuracy goes down. This is called overfitting. &lt;/p&gt;
&lt;h2 id=&quot;6-further-analysis-optionalungraded-exercise&quot;&gt;6 - Further analysis (optional/ungraded exercise)&lt;/h2&gt;
&lt;p&gt;Congratulations on building your first image classification model. Let&#39;s analyze it further, and examine possible choices for the learning rate $\alpha$. &lt;/p&gt;
&lt;h4 id=&quot;choice-of-learning-rate&quot;&gt;Choice of learning rate&lt;/h4&gt;
&lt;p&gt;&lt;strong&gt;Reminder&lt;/strong&gt;:
In order for Gradient Descent to work you must choose the learning rate wisely. The learning rate $\alpha$  determines how rapidly we update the parameters. If the learning rate is too large we may &quot;overshoot&quot; the optimal value. Similarly, if it is too small we will need too many iterations to converge to the best values. That&#39;s why it is crucial to use a well-tuned learning rate.&lt;/p&gt;
&lt;p&gt;Let&#39;s compare the learning curve of our model with several choices of learning rates. Run the cell below. This should take about 1 minute. Feel free also to try different values than the three we have initialized the &lt;code&gt;learning_rates&lt;/code&gt; variable to contain, and see what happens. &lt;/p&gt;
&lt;div class=&quot;codehilite&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;learning_rates&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.01&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.001&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.0001&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;models&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{}&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;learning_rates&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;print&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;learning rate is: &amp;quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;models&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;train_set_x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;train_set_y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;test_set_x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;test_set_y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;num_iterations&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1500&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;learning_rate&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;print_cost&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;False&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;print&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\n&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&amp;quot;-------------------------------------------------------&amp;quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&amp;#39;&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\n&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;learning_rates&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;plot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;squeeze&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;models&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)][&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;costs&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;label&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;models&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)][&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;learning_rate&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]))&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ylabel&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;cost&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;xlabel&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;iterations (hundreds)&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;legend&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;legend&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;loc&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;upper center&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;shadow&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;frame&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;legend&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;get_frame&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;frame&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;set_facecolor&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;0.90&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;show&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div class=&quot;codehilite&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;learning rate is: 0.01
Cost after iteration 0: 0.693147
Cost after iteration 100: 0.823921
Cost after iteration 200: 0.418944
Cost after iteration 300: 0.617350
Cost after iteration 400: 0.522116
Cost after iteration 500: 0.387709
Cost after iteration 600: 0.236254
Cost after iteration 700: 0.154222
Cost after iteration 800: 0.135328
Cost after iteration 900: 0.124971
Cost after iteration 1000: 0.116478
Cost after iteration 1100: 0.109193
Cost after iteration 1200: 0.102804
Cost after iteration 1300: 0.097130
Cost after iteration 1400: 0.092043
train accuracy: 99.52153110047847 %
test accuracy: 68.0 %

-------------------------------------------------------

learning rate is: 0.001
Cost after iteration 0: 0.693147
Cost after iteration 100: 0.591289
Cost after iteration 200: 0.555796
Cost after iteration 300: 0.528977
Cost after iteration 400: 0.506881
Cost after iteration 500: 0.487880
Cost after iteration 600: 0.471108
Cost after iteration 700: 0.456046
Cost after iteration 800: 0.442350
Cost after iteration 900: 0.429782
Cost after iteration 1000: 0.418164
Cost after iteration 1100: 0.407362
Cost after iteration 1200: 0.397269
Cost after iteration 1300: 0.387802
Cost after iteration 1400: 0.378888
train accuracy: 88.99521531100478 %
test accuracy: 64.0 %

-------------------------------------------------------

learning rate is: 0.0001
Cost after iteration 0: 0.693147
Cost after iteration 100: 0.643677
Cost after iteration 200: 0.635737
Cost after iteration 300: 0.628572
Cost after iteration 400: 0.622040
Cost after iteration 500: 0.616029
Cost after iteration 600: 0.610455
Cost after iteration 700: 0.605248
Cost after iteration 800: 0.600354
Cost after iteration 900: 0.595729
Cost after iteration 1000: 0.591339
Cost after iteration 1100: 0.587153
Cost after iteration 1200: 0.583149
Cost after iteration 1300: 0.579307
Cost after iteration 1400: 0.575611
train accuracy: 68.42105263157895 %
test accuracy: 36.0 %

-------------------------------------------------------
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;img alt=&quot;png&quot; src=&quot;https://raw.githubusercontent.com/karenyyy/Coursera_and_Udemy/master/deeplearningai_coursera/Neural_Networks_and_Deep_Learning/images/week2/output_50_1.png&quot; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Interpretation&lt;/strong&gt;: 
- Different learning rates give different costs and thus different predictions results.
- If the learning rate is too large (0.01), the cost may oscillate up and down. It may even diverge (though in this example, using 0.01 still eventually ends up at a good value for the cost). 
- A lower cost doesn&#39;t mean a better model. You have to check if there is possibly overfitting. It happens when the training accuracy is a lot higher than the test accuracy.
- In deep learning, we usually recommend that you: 
    - Choose the learning rate that better minimizes the cost function.
    - If your model overfits, use other techniques to reduce overfitting. (We&#39;ll talk about this in later videos.) &lt;/p&gt;
&lt;p&gt;&lt;strong&gt;What to remember from this assignment:&lt;/strong&gt;
1. Preprocessing the dataset is important.
2. You implemented each function separately: initialize(), propagate(), optimize(). Then you built a model().
3. Tuning the learning rate (which is an example of a &quot;hyperparameter&quot;) can make a big difference to the algorithm. You will see more examples of this later in this course!&lt;/p&gt;
&lt;p&gt;Finally, if you&#39;d like, we invite you to try different things on this Notebook. Make sure you submit before trying anything. Once you submit, things you can play with include:
    - Play with the learning rate and the number of iterations
    - Try different initialization methods and compare the results
    - Test other preprocessings (center the data, or divide each row by its standard deviation)&lt;/p&gt;
&lt;p&gt;Bibliography:
- http://www.wildml.com/2015/09/implementing-a-neural-network-from-scratch/
- https://stats.stackexchange.com/questions/211436/why-do-we-normalize-images-by-subtracting-the-datasets-image-mean-and-not-the-c&lt;/p&gt;deeplearning.ai - Neural Networks and Deep Learning - Week 2 Notes
&lt;h3 id=&quot;logistic-network&quot;&gt;Logistic Network&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Logistic network is practically a binary classification&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Note: reshape each image as one single vector&lt;/strong&gt;
&lt;img alt=&quot;&quot; src=&quot;https://raw.githubusercontent.com/karenyyy/Coursera_and_Udemy/master/deeplearningai_coursera/Neural_Networks_and_Deep_Learning/images/8.png&quot; /&gt;
img&lt;src=&quot;https://raw.githubusercontent.com/karenyyy/Coursera_and_Udemy/master/deeplearningai_coursera/Neural_Networks_and_Deep_Learning/images/8.png&gt;
- Notation:&lt;/p&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://raw.githubusercontent.com/karenyyy/Coursera_and_Udemy/master/deeplearningai_coursera/Neural_Networks_and_Deep_Learning/images/9.png&quot; /&gt;&lt;/p&gt;
&lt;p&gt;$$\text{ Given the input feature x, where } x \in \mathbb{R}^{n_x}$$&lt;/p&gt;
&lt;p&gt;$$\text{  Goal: } \hat y = P(y=1 \mid x), \text{ where }  \hat y \in [0,1]$$&lt;/p&gt;
&lt;p&gt;$$\text{ parameter1: } w \in \mathbb{R}^{n_x \cdot ?}  $$&lt;/p&gt;
&lt;p&gt;$$\text{ parameter2: } b \in \mathbb{R}^{1 \cdot m}$$&lt;/p&gt;
&lt;p&gt;$$\text{ Output: } \hat y = \sigma( w^{T}x + b) = \sigma (z), \text { where } z= w^{T}x+b, \text { and } \sigma(z) = 
\frac{1}{1+e^{-z}}$$&lt;/p&gt;
&lt;p&gt;$$\text{ If z is large, } \sigma (z) \approx \frac{1}{1+0} = 1 $$&lt;/p&gt;
&lt;p&gt;$$\text{ If z is small (neg), } \sigma (z) \approx \frac{1}{1+\infty} \approx 0 $$&lt;/p&gt;
&lt;h4 id=&quot;alternative-notation&quot;&gt;alternative notation:&lt;/h4&gt;
&lt;p&gt;$$x_0 = 1, x \in \mathbb{R}^{n_x+1}, \hat y= \sigma (\theta ^{T} x)$$&lt;/p&gt;
&lt;p&gt;$$\text{ where } \theta = \begin{pmatrix} \theta_0
\ \theta_1
\ \theta_2
\ \theta_3
\ ...
\ \theta_{n_x}
\end{pmatrix}, \theta_0 \rightarrow b, (\theta_1, \theta_2,..., \theta_{n_x}) \rightarrow w $$&lt;/p&gt;
&lt;h3 id=&quot;logistic-reg-cost-function&quot;&gt;Logistic Reg Cost  Function&lt;/h3&gt;
&lt;p&gt;$$\hat y^{(i)} = \sigma (w^{T}x+b), \text{ where } \sigma(z^{(i)}) = \frac{1}{1+e^{-z^{(i)}}} $$&lt;/p&gt;
&lt;p&gt;Note: &lt;strong&gt;DO NOT DO THE FOLLOWING:&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;$$\text{ Loss(error) function: } L(\hat y, y) = \frac{1}{2} (\hat y - y)^2$$&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&lt;em&gt;Because when it comes to learn the parameters, we can find that the optimization problem would become non-convex, so we could end up with optimization problem with multiple local optima, so gradient descent may not find the global optimum&lt;/em&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;In Logistic Reg, the standard &lt;strong&gt;loss&lt;/strong&gt; function is:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Negative log-likelihood (cross-entropy error)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;$$L(\hat y, y) = - \left (y \log \hat y + (1-y) \log (1- \hat y) \right )$$&lt;/p&gt;
&lt;p&gt;$$\text { If y=1, } L(\hat y, y) = - \log \hat y, \text {so our goal: } \min (L) \rightarrow \max(\hat y) $$
$$\text { If y=0, } L(\hat y, y) = - \log (1- \hat y), \text {so our goal: }  \min (L) \rightarrow \min(\hat y) $$&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Total cost function&lt;/strong&gt;:
$$J(w,b) = \frac{1}{m} \sum^m_{i=1} L(\hat y^{(i)}, y^{(i)}) = - \frac{1}{m} \sum^m_{i=1} \left (y^{(i)} \log \hat y^{(i)} + (1-y^{(i)}) \log (1- \hat y^{(i)}) \right )$$&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Note1:&lt;/strong&gt;
- The loss function computes the error for a single training example; 
- the cost function is the average of the loss functions of the entire training set.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Note2: Other loss functions&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Hinge (SVM, soft margin) 
$$L(y) = \max(0, 1- y), \text{ where if } y&amp;gt;1, \text { then error = 0, the classification output is correct. }  $$&lt;/li&gt;
&lt;li&gt;Squared loss (linear regression) &lt;/li&gt;
&lt;li&gt;Exponential loss (Boosting) &lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&quot;gradient-descent&quot;&gt;Gradient Descent&lt;/h3&gt;
&lt;p&gt;Cost Function:
$$J(w,b) = \frac{1}{m} \sum^m_{i=1} L(\hat y^{(i)}, y^{(i)}) = - \frac{1}{m} \sum^m_{i=1} \left (y^{(i)} \log \hat y^{(i)} + (1-y^{(i)}) \log (1- \hat y^{(i)}) \right )$$&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Goal: find w, b that minimize J(w,b)&lt;/strong&gt; &lt;/p&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://raw.githubusercontent.com/karenyyy/Coursera_and_Udemy/master/deeplearningai_coursera/Neural_Networks_and_Deep_Learning/images/10.png&quot; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Initialization: for logistic regression&lt;/strong&gt;
- almost any initialization method works (&lt;strong&gt;usually init as 0&lt;/strong&gt;)
- random initialization also works&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;How Gradient Descent works?&lt;/strong&gt;
- start at the initial point and then takes a step in the steepest downhill direction&lt;/p&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://raw.githubusercontent.com/karenyyy/Coursera_and_Udemy/master/deeplearningai_coursera/Neural_Networks_and_Deep_Learning/images/11.png&quot; /&gt;&lt;/p&gt;
&lt;p&gt;$$\text{Repeated: } w=w-\alpha \frac{\partial J(w, b)}{\partial w},b=b-\alpha \frac{\partial J(w, b)}{\partial b}$$&lt;/p&gt;
&lt;p&gt;Eg: 
&lt;img alt=&quot;&quot; src=&quot;https://raw.githubusercontent.com/karenyyy/Coursera_and_Udemy/master/deeplearningai_coursera/Neural_Networks_and_Deep_Learning/images/12.png&quot; /&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;at this point, the slope here of the derivative would be negative &lt;/li&gt;
&lt;li&gt;so the gradient descent update would subtract alpha times a negative number, ending up slowly &lt;strong&gt;increasing w&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;so w gets bigger and bigger with successive iteration and gradient descent&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Vice Versa when you initialize w on the right side&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&quot;logistic-regression-gradient-descent&quot;&gt;Logistic Regression Gradient Descent&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Computing derivatives
&lt;img alt=&quot;&quot; src=&quot;https://raw.githubusercontent.com/karenyyy/Coursera_and_Udemy/master/deeplearningai_coursera/Neural_Networks_and_Deep_Learning/images/13.png&quot; /&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://raw.githubusercontent.com/karenyyy/Coursera_and_Udemy/master/deeplearningai_coursera/Neural_Networks_and_Deep_Learning/images/15.png&quot; /&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;GD on m examples&lt;ul&gt;
&lt;li&gt;pseudo code:&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://raw.githubusercontent.com/karenyyy/Coursera_and_Udemy/master/deeplearningai_coursera/Neural_Networks_and_Deep_Learning/images/14.png&quot; /&gt;   &lt;/p&gt;
&lt;p&gt;But, here, if there are too many features (when n not equal to 2), then to avoid the many for loops, should use vectorization.&lt;/p&gt;
&lt;h3 id=&quot;vectorization&quot;&gt;Vectorization&lt;/h3&gt;
&lt;p&gt;Vectorization is the art of getting rid of explicit folders in your code.&lt;/p&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://raw.githubusercontent.com/karenyyy/Coursera_and_Udemy/master/deeplearningai_coursera/Neural_Networks_and_Deep_Learning/images/16.png&quot; /&gt;&lt;/p&gt;
&lt;p&gt;Test:&lt;/p&gt;
&lt;div class=&quot;codehilite&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;numpy&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;np&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;time&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;number&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1000000&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;random&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;rand&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;number&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;b&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;random&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;rand&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;number&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# vectorized:&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;tic&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;time&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;time&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;c&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;b&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;# a^T * b&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;toc&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;time&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;time&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;toc&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tic&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div class=&quot;codehilite&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;0.00103759765625
&lt;/pre&gt;&lt;/div&gt;


&lt;div class=&quot;codehilite&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;c1&quot;&gt;# for loop:&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;tic&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;time&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;time&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;c&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;number&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;c&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;b&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; 
&lt;span class=&quot;n&quot;&gt;toc&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;time&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;time&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;toc&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tic&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div class=&quot;codehilite&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;0.4118075370788574
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;strong&gt;Note1: if &#39;number&#39; is significantly large, the difference of vectorization and for loop would also be enormous.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Note1: Both GPU and CPU have parallelization instructions, called SIMD instructions (single instruction, multiple data)&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;if you use a built-in function such as the &lt;strong&gt;np.dot&lt;/strong&gt; function, or any else that does not require explicitly implementing a for loop, it enables numpy to take much better advantage to do computations faster, and it is true for both computations CPUs and computations on GPUs(since GPU really good at SIMD)&lt;/p&gt;
&lt;h3 id=&quot;take-away-avoid-explicit-for-loops&quot;&gt;&lt;strong&gt;Take-away: Avoid explicit for-loops&lt;/strong&gt;&lt;/h3&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://raw.githubusercontent.com/karenyyy/Coursera_and_Udemy/master/deeplearningai_coursera/Neural_Networks_and_Deep_Learning/images/17.png&quot; /&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;A subtlety in python: here b is a real number (1 x 1 matrix), python automatically takes this real number B and expands it out to in this case, a 1 x M row vector, it is called &lt;strong&gt;Broadcasting&lt;/strong&gt; in python.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;ul&gt;
&lt;li&gt;Vectorizing Logistic Regression
&lt;img alt=&quot;&quot; src=&quot;https://raw.githubusercontent.com/karenyyy/Coursera_and_Udemy/master/deeplearningai_coursera/Neural_Networks_and_Deep_Learning/images/18.png&quot; /&gt;
&lt;img alt=&quot;&quot; src=&quot;https://raw.githubusercontent.com/karenyyy/Coursera_and_Udemy/master/deeplearningai_coursera/Neural_Networks_and_Deep_Learning/images/19.png&quot; /&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&quot;codehilite&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;c1&quot;&gt;# broadcasting example:&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;A&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;array&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt;
          &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;6&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;7&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;8&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt;
          &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt;
          &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;8&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;7&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;6&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]])&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;A&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;axis&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;# top to bottom sum&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div class=&quot;codehilite&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;array([18, 18, 18, 18])
&lt;/pre&gt;&lt;/div&gt;


&lt;div class=&quot;codehilite&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;A&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;axis&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;# left to right sum&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div class=&quot;codehilite&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;array([10, 26, 10, 26])
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://raw.githubusercontent.com/karenyyy/Coursera_and_Udemy/master/deeplearningai_coursera/Neural_Networks_and_Deep_Learning/images/20.png&quot; /&gt;&lt;/p&gt;
&lt;div class=&quot;codehilite&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cal&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;A&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;axis&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; 
&lt;span class=&quot;n&quot;&gt;cal_reshaped&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cal&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;reshape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;cal_reshaped&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div class=&quot;codehilite&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;array([[18, 18, 18, 18]])
&lt;/pre&gt;&lt;/div&gt;


&lt;div class=&quot;codehilite&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;A&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cal_reshaped&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;100&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;# calculate the precentage&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div class=&quot;codehilite&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;array([[ 5.55555556, 11.11111111, 16.66666667, 22.22222222],
       [27.77777778, 33.33333333, 38.88888889, 44.44444444],
       [22.22222222, 16.66666667, 11.11111111,  5.55555556],
       [44.44444444, 38.88888889, 33.33333333, 27.77777778]])
&lt;/pre&gt;&lt;/div&gt;


&lt;div class=&quot;codehilite&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;A&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cal&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;100&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div class=&quot;codehilite&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;array([[ 5.55555556, 11.11111111, 16.66666667, 22.22222222],
       [27.77777778, 33.33333333, 38.88888889, 44.44444444],
       [22.22222222, 16.66666667, 11.11111111,  5.55555556],
       [44.44444444, 38.88888889, 33.33333333, 27.77777778]])
&lt;/pre&gt;&lt;/div&gt;


&lt;h3 id=&quot;mle-neg-log-likelihood&quot;&gt;MLE &amp;amp; Neg Log Likelihood&lt;/h3&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;https://raw.githubusercontent.com/karenyyy/Coursera_and_Udemy/master/deeplearningai_coursera/Neural_Networks_and_Deep_Learning/images/21.png&quot; /&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;assumption: &lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;$$\text{ all training examples } \overset{iid}{\sim} $$&lt;/p&gt;
&lt;p&gt;$$P(\text{ labels in training set }) = \prod_{i=1}^m P(y^{(i)} \mid x^{(i)})$$&lt;/p&gt;
&lt;p&gt;$$\log P(\text{ labels in training set }) = \log \prod_{i=1}^m P(y^{(i)} \mid x^{(i)})$$&lt;/p&gt;
&lt;p&gt;$$\log P(\text{ labels in training set }) = \sum^m_{i=1} \log P(y^{(i)} \mid x^{(i)}) = \sum^m_{i=1} (-L(\hat y^{(i)}, y^{(i)}))$$&lt;/p&gt;
&lt;p&gt;$$\text{ Neg Log Likelihood : } L(\hat y^{(i)}, y^{(i)})$$&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;MLE here: &lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;$$\max (\log P(\text{ labels in training set })) = \max \sum^m_{i=1} \log P(y^{(i)} \mid x^{(i)}) = \max \sum^m_{i=1} (-L(\hat y^{(i)}, y^{(i)}))$$&lt;/p&gt;
&lt;p&gt;$$=&amp;gt; \min \sum^{m}_{i=1} L(\hat y^{(i)}, y^{(i)})$$&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;So:
$$ \min (\text{ cost function }) \rightarrow \min(\text{ Neg Log Likelihood } ) \rightarrow \max(- \text{ Neg Log Likelihood } ) \rightarrow MLE$$&lt;/p&gt;
&lt;/blockquote&gt;
&lt;div class=&quot;codehilite&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;a&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;random&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;randn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;# a.shape = (4, 3)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;b&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;random&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;randn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;# b.shape = (3, 2)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;c&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;b&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div class=&quot;codehilite&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;---------------------------------------------------------------------------

ValueError                                Traceback (most recent call last)

&amp;lt;ipython-input-41-20aba40ca292&amp;gt; in &amp;lt;module&amp;gt;()
      1 a = np.random.randn(4, 3) # a.shape = (4, 3)
      2 b = np.random.randn(3, 2) # b.shape = (3, 2)
----&amp;gt; 3 c = a*b


ValueError: operands could not be broadcast together with shapes (4,3) (3,2)
&lt;/pre&gt;&lt;/div&gt;


&lt;div class=&quot;codehilite&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;c&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;b&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;c&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;deeplearning.ai - Neural Networks and Deep Learning - Week 1 Notes
## Week 1

[Geoffrey Hinton interview](https://www.coursera.org/learn/neural-networks-deep-learning/lecture/dcm5r/geoffrey-hinton-interview)

### Intro to Neural Network

- how to start constructng a NN?
   - Eg: Housing Price Prediction: __By stacking together a few of single neurons (simple predictors) __
![](https://raw.githubusercontent.com/karenyyy/Coursera_and_Udemy/master/deeplearningai_coursera/Neural_Networks_and_Deep_Learning/images/1.png)

- what you input and what you get for output?
![](https://raw.githubusercontent.com/karenyyy/Coursera_and_Udemy/master/deeplearningai_coursera/Neural_Networks_and_Deep_Learning/images/2.png)

- finally we formalize the NN:
![](https://raw.githubusercontent.com/karenyyy/Coursera_and_Udemy/master/deeplearningai_coursera/Neural_Networks_and_Deep_Learning/images/3.png)

__Note: every input layer feature is interconnected with every hidden layer feature.__

### Neural Network Examples


![](https://raw.githubusercontent.com/karenyyy/Coursera_and_Udemy/master/deeplearningai_coursera/Neural_Networks_and_Deep_Learning/images/4.png)

- Supervised Learning

![](https://raw.githubusercontent.com/karenyyy/Coursera_and_Udemy/master/deeplearningai_coursera/Neural_Networks_and_Deep_Learning/images/5.png)

- Performance (highly dependent on the scale of data)

![](https://raw.githubusercontent.com/karenyyy/Coursera_and_Udemy/master/deeplearningai_coursera/Neural_Networks_and_Deep_Learning/images/6.png)

   -  __Eg: Algorithmic innovation to boost performance__
   ![](https://raw.githubusercontent.com/karenyyy/Coursera_and_Udemy/master/deeplearningai_coursera/Neural_Networks_and_Deep_Learning/images/7.png)
       - why RELU is better than Sigmoid for Gradient Descent Algorithm?
           - ___Sigmoid___: when x converges to neg infty anf pos infty, the slope of the function (gradient) is nearly 0 =&gt; gradient vanishing, so learning becomes really slow, or even stopped, because when we implement the gradient descent and gradient is 0, the parameters just change very slowly;
           - ___RELU___: the gradient is always equal to 1 for all pos value, so the gradient is much less likely to gradually shrink to 0.    t d   ,  ,|  & &  y $  = D  6   L )g R  Z[   +  X T  2 |   _  i